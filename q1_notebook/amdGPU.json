[
  {
    "brand": "amd",
    "generation": "6000",
    "tier": "low",
    "matched_keywords": [
      "6500xt"
    ],
    "title": "6500xt hits 17 FPS in Far Cry 6",
    "selftext": "",
    "comments": [
      "I mean, it's a pretty good upgrade. If you're upgrading from a GT 710.",
      "the human eye can't see more than 10 fps or 4gb ram",
      "I don't understand the decision-making process behind this graphics card. Amd has not only shot themselves in both knees, but also in ours.",
      "AMD's answer to the 1030 DDR4 edition",
      "$200, huh?",
      "I disagree.\n\nSome models of the GT 710 support 3 display outs, the 6500 XT only seems to support 2.",
      "Literally 499‚Ç¨ in the Netherlands...\n\nI'm fucking dying üòÇüòÇüòÇ\n\nEdit: there's a 399‚Ç¨ model in stock today! What an amazing bargain!!!!",
      "It's 360 Euros, I found the Sapphire model in stock in eastern Europe.",
      "This card can't be any more degrading huh?",
      "I really don't know why they only put 4 lanes and a 64 bit bus. It would have actually been an ok/decent card with even just 8 lanes. Everything else I would've forgiven if not for the 4 lanes.",
      "3080 12GB is faster than 3080 Ti and 3090? Lol",
      "Nvm guys, I found one for 400 euros... it's unbelieveable.",
      "This is a 6200xt in a sane world",
      "1030 D4 launched at $70 back then",
      "It's because the die is tiny.  Navi24 is only 107mm^2 vs 232mm^2 for Navi 23.  That's less than half.\n\nCheckout the annotated Navi 23 die shot (32 CUs), draw an imaginary line down the middle and you'll see why L3 cache and PCI lanes were cut in half:\n\nhttps://pbs.twimg.com/media/E20kNTuX0AMwsKg?format=jpg&name=large\n\nThis would have been a great low cost (<$150) GPU to market alongside Ryzen 6000 APUs (PCIe 4.0, built in HW encoders), however those are only coming to laptops this quarter.\n\nFor desktop they *should* have targeted a slightly larger die size to accommodate 8x PCI lanes, the encoders, and maybe 32mb of L3 cache.  Then it would have been worth the asking price (in this market).\n\nEdit: Navi14 annotated die shot for comparison:\n\nhttps://pbs.twimg.com/media/EPJshhYXsAUAfYI?format=jpg&name=large\n\nNavi 14 (AMD smallest GPU die last gen) is 47% bigger than Navi 24.  Navi 24 is the first to use the 6N process (18% higher density).",
      "it doesn't really matter, the human eye can't see more than pcie 3.0 anyway",
      "ive been laughing at this for 5 minutes straight",
      "The gtx 1650 super also has 4 GB the bigger issue is the pcie bandwidth. To quote gamers nexus you can sacrifice memory amount or bandwidth but never both",
      "They really should have sold this as 6300 XT at $150. It‚Äôs still pricy, but I bet people would be a lot less upset.",
      "[There are actually people who defend this shitty product](https://www.youtube.com/watch?v=ICnz6E7vux0)"
    ]
  },
  {
    "brand": "amd",
    "generation": "6000",
    "tier": "low",
    "matched_keywords": [
      "6500xt"
    ],
    "title": "AMD‚Äôs $199 Radeon RX 6500XT officially gets ‚Ç¨300/324 MSRP from ASUS [Videocardz.com]",
    "selftext": "",
    "comments": [
      "AMD: $200\n\nAIBs: $300\n\nScalpers: $400\n\nConsumers:\n\n‚¢Ä‚£†‚£æ‚£ø‚£ø‚£ø‚£ø‚£ø‚£ø‚£ø‚£ø‚£ø‚£ø‚£ø‚£ø‚£ø‚£ø‚£ø‚£ø‚£ø‚£ø‚£ø‚†Ä‚†Ä‚†Ä‚†Ä‚£†‚£§‚£∂‚£∂  \n‚£ø‚£ø‚£ø‚£ø‚£ø‚£ø‚£ø‚£ø‚£ø‚£ø‚£ø‚£ø‚£ø‚£ø‚£ø‚£ø‚£ø‚£ø‚£ø‚£ø‚£ø‚£ø‚†Ä‚†Ä‚†Ä‚¢∞‚£ø‚£ø‚£ø‚£ø  \n‚£ø‚£ø‚£ø‚£ø‚£ø‚£ø‚£ø‚£ø‚£ø‚£ø‚£ø‚£ø‚£ø‚£ø‚£ø‚£ø‚£ø‚£ø‚£ø‚£ø‚£ø‚£ø‚£ß‚£Ä‚£Ä‚£æ‚£ø‚£ø‚£ø‚£ø  \n‚£ø‚£ø‚£ø‚£ø‚£ø‚°è‚†â‚†õ‚¢ø‚£ø‚£ø‚£ø‚£ø‚£ø‚£ø‚£ø‚£ø‚£ø‚£ø‚£ø‚£ø‚£ø‚£ø‚£ø‚£ø‚£ø‚£ø‚£ø‚°ø‚£ø  \n‚£ø‚£ø‚£ø‚£ø‚£ø‚£ø‚†Ä‚†Ä‚†Ä‚†à‚†õ‚¢ø‚£ø‚£ø‚£ø‚£ø‚£ø‚£ø‚£ø‚£ø‚£ø‚£ø‚£ø‚£ø‚†ø‚†õ‚†â‚†Å‚†Ä‚£ø  \n‚£ø‚£ø‚£ø‚£ø‚£ø‚£ø‚£ß‚°Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†ô‚†ø‚†ø‚†ø‚†ª‚†ø‚†ø‚†ü‚†ø‚†õ‚†â‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚£∏‚£ø  \n‚£ø‚£ø‚£ø‚£ø‚£ø‚£ø‚£ø‚£∑‚£Ñ‚†Ä‚°Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚¢Ä‚£¥‚£ø‚£ø  \n‚£ø‚£ø‚£ø‚£ø‚£ø‚£ø‚£ø‚£ø‚£ø‚†è‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚††‚£¥‚£ø‚£ø‚£ø‚£ø  \n‚£ø‚£ø‚£ø‚£ø‚£ø‚£ø‚£ø‚£ø‚°ü‚†Ä‚†Ä‚¢∞‚£π‚°Ü‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚£≠‚£∑‚†Ä‚†Ä‚†Ä‚†∏‚£ø‚£ø‚£ø‚£ø  \n‚£ø‚£ø‚£ø‚£ø‚£ø‚£ø‚£ø‚£ø‚†É‚†Ä‚†Ä‚†à‚†â‚†Ä‚†Ä‚†§‚†Ñ‚†Ä‚†Ä‚†Ä‚†â‚†Å‚†Ä‚†Ä‚†Ä‚†Ä‚¢ø‚£ø‚£ø‚£ø  \n‚£ø‚£ø‚£ø‚£ø‚£ø‚£ø‚£ø‚£ø‚¢æ‚£ø‚£∑‚†Ä‚†Ä‚†Ä‚†Ä‚°†‚†§‚¢Ñ‚†Ä‚†Ä‚†Ä‚††‚£ø‚£ø‚£∑‚†Ä‚¢∏‚£ø‚£ø‚£ø  \n‚£ø‚£ø‚£ø‚£ø‚£ø‚£ø‚£ø‚£ø‚°Ä‚†â‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚¢Ñ‚†Ä‚¢Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†â‚†â‚†Å‚†Ä‚†Ä‚£ø‚£ø‚£ø  \n‚£ø‚£ø‚£ø‚£ø‚£ø‚£ø‚£ø‚£ø‚£ß‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†à‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚¢π‚£ø‚£ø  \n‚£ø‚£ø‚£ø‚£ø‚£ø‚£ø‚£ø‚£ø‚£ø‚†É‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚¢∏‚£ø‚£ø",
      "Honestly not surprised",
      "Its time to re-paste my RX580 for long run......",
      "This is an insultingly bad price for a very weak card. Even in an inflated market I'd rather pay more to get more. I truly feel for anyone that 'needs' a video card right now, any video card.",
      "#RX580gang\n\nBtw the thermal pad size is 0.5mm right? And what paste do you recommend",
      "Gamers have been appalled from the onset. Ain't shit changed. Everyone gets on Reddit and bitches about the prices then snags the first available card and posts \"Finally got one at MSRP\". MSRP is $2,000 so it don't mean shit these days.",
      "The problem is that you won't be able to upgrade the graphics card in the future.  You won't be able to upgrade to... to... haha...\n\nWho am I kidding?  Welcome to 2026.  Everyone is mining Cryptoethercoin.  It's $2,500 for an RTX 5050 Super Ti 24 GB Edition.  HashBlockMiner has a 93% unlock rate on LHR v4.  Consoles are being scalped for $1,200 and people are now mining with their Teslas.  AMD just released the RX 7100 for $400 with 1 GB of VRAM.  Slogan: \"Miner-Proof!  Perfect for 720p gaming!\" ^with ^FSR ^enabled  \n\nScrew it.  Laptop life ain't bad, mate.",
      "I guess Hardware Unboxed was pretty spot on: [https://youtu.be/jhtpUByiuIA?t=357](https://youtu.be/jhtpUByiuIA?t=357)",
      "Manufacturers and vendors have been absolute cunts. One of the biggest vendors in germany has 30 different RX cards in stock and hundreds, if not thousands sold, but they still don't budge in regards to price. No vendor wants to make the first step. They much rather comfortably scam you. This goes on for weeks. chip shortage my ass",
      "Yeah, why would they price it at $199 if they can sell it at $300? It's not like there are any alternatives. As long as mining+ship shortages is keeping all the GPUs pricing high, they can get away with it.",
      "This 4GB piece of e-waste is useless to the miners. Doesn‚Äôt seem useful to the gamers either...  Judging by the lackluster performance of the 6600/XT, this thing will barely beat a 6-year old GTX 1070, which at least has 8GB memory and is useful for mining. 6500XT is a $400-$500 display output.",
      "300‚Ç¨ to play 1080p medium/low settings? Just buy an Xbox Series S at that point, those are fairly easy to find.",
      "and where are all those  who kept saying  \"this card will at least be MSRP\" \"We should be glad AMD cut it down so much\" \"they made it bad so we could get it at msrp\" clowns\n\nThis is a surprise to no one, a garbage card at a garbage price.",
      "I sell a lot of PCs in my area, and a local kid heard about me from a friend who bought a PC from me. He reached out looking to spend no more than $500 on a PC. I somehow managed to snag a 980 Ti Founder's for $175 from a Facebook group, and built the PC around that with a 4790K, Z97 motherboard, 16GB RAM, 1TB SSD, 1TB HDD, nice case with lots of RGB. I even made money on it. I hope he knows how good of a deal he got in the current market lol",
      "Prices will drop when people quit buying. \n\nAnd with gamers appalled by the price and  poor mining performance that might happen...",
      "i dont think we will ever be able to upgrade anymore. this might be the end of pc gaming for many folks that cant take out 1k out of their wallets for a fucking gpu alone",
      "I believe so. I fixed a friends 580 by using the thermal pads from an asus motherboard m.2 thermal pads\n\nMx4 or attic silver 5 are my recs",
      ">attic silver\n\nWhy yes I still have tubes of thermal paste from the late 90s",
      "My friends all laughed when I bought a new  RTX 2080Ti for 800 euro a month before RTX30XX launched. Shop was trying to dump old stock expecting it to become unsellable. I bet they regret that now!\n\nMy 2 pc now sport a 2080Ti and 1080Ti and with current prices I'll be using both for a long time.\n\nI refuse to fund scalpers and now the AIBs have started acting like scalpers too. At this point I wont buy their overpriced products either.\n\nAMD seems to be the only one half decent in their own online shop. When supply gets to normal I'll buy directly from them and the AIBs can suck something of mine.",
      "THE 1070 IS ALREADY 6 YEARS OLD??\n\nWow do times go by quickly"
    ]
  },
  {
    "brand": "amd",
    "generation": "6000",
    "tier": "low",
    "matched_keywords": [
      "rx6600"
    ],
    "title": "Upgraded from Rx580 to Rx6600 after 6 years of usage; I love these budget graphic cards",
    "selftext": "",
    "comments": [
      "The Rx6600 is Rx580's true spiritual successor. \n\nTruly the best budget card you can buy in the current market, where good budget cards are in extinction.",
      "And it was an upgrade from what she had.  ![gif](emote|free_emotes_pack|grin)",
      "I just did something similar.  Went from a RX 480 to a 6600XT that I bought off of Marketplace.  Gave the 480 to my daughter to replace a potato she had in her PC.",
      "6650xt can be had for about 210 as well.",
      "It's about 6020 of a difference.",
      "Sure man, let's just build 7800X3D/4090 builds for everyone.\n\nOh your 10 year old sibling/kid wants to play Roblox on a 1080p 60hz display? You need at least a 4070Ti Super for that. \n\nYou want just a basic PC that can browse the web and play extremely light games? Sorry man you need 16 cores and at least a 7800XT.\n\nThe 2nd PC you see in my flair is what I made for my younger brother who's 10. For what he plays that RX 6600 is overkill. You heard me right, that card is overkill.\n\nRX 480 is still a viable GPU as long as you don't do much with your system. If you just wanna browse the web and play really easy to run games like most kids do it is still plenty of power.\n\nHeck I have an old R9 290 laying around here and I could comfortably play through the whole story of CP2077 at 1080p low preset on that thing.\n\nYour comment is pure elitism and as someone who grew up scraping together hardware just to play what  games I could I hate it a lot.",
      "I don‚Äôt think anyone would argue it‚Äôs a good GPU, but it‚Äôs fine man.\n\nIf you‚Äôre not playing BM:Wukong or God of War etc‚Ä¶ you can definitely get away with a 580/480, especially if it‚Äôs the 8gb‚Ä¶ and definitely use FSR.\n\nWatched a JayzTwoCents video recently where he used a 980 and ran cyberpunk. With medium-high settings and FSR 2.0 quality @ 1080p, he was getting ~70 fps. A 580/480 can probably get 60 frames depending on CPU and settings man. And if you‚Äôre only playing Esports titles and games like Minecraft, terraria? Defo good enough.\n\nA lot of people still use the 1060 6gb‚Ä¶ the 580/480 is better than or very similar to that.\n\nEdit: guy above me edited his comment, adding the (not considering esports titles) after my comment was made.",
      "I just went from a 1060 6gb to a 6600, life is good",
      "In Europe you usually pay 250+ compared to the 190‚Ç¨ to 210‚Ç¨ for an 6600.",
      "What everybody should be buying! Capable, inexpensive, and power efficient!",
      "Dude, i use a handheld pc with a 780m as its gpu, which is way worse than a 480. 480 is still a damn good gpu for the price\n\nAnd before you say \"ah but you only play esports game\"  no i dont. I play games like cyberpunk, doom eternal, elden ring, forza horizon 4/5, ghost of tsushima, and satisfactory (ue5 title) and run at a very playable 50+ fps\n\n480 is still good but might not be up to your \"120fps is only just playable\" standards",
      "Yeah man, I agree, he and his daughter are what‚Äôs wrong with PC gaming! I just talked to CD Projekt Red devs and they said they‚Äôre cancelling 4k textures and ray tracing in Witcher 4. \n\nAll because Perpetual98‚Äôs daughter still uses an RX480, I can‚Äôt begin to express how upset I am!!!",
      "Spiritual successor that unfortunately took 2 years to actually get to a price point where it can be said spiritual successor",
      "Wat fucking elitism. Polaris cards like the 480/580 and even 470/570 are still capable to run most recent games even on low medium settings you dont need to play at ultra 4k settings and raytracing to enjoy a game.",
      "using 6600 now, served me well. Will only upgrade when when I can get double performance for good price($3-400 USD)",
      "i recently got RX 6600 XT nitro+ for 170 eur from ebay. The jump from my old MSI RX 480 is immense. The card is so damn silent under load.",
      "Famous potatoes",
      "lol went from 1660 to rx6600 yesterday too !  it's such a huge jump for me",
      "Budget cards? They cost twice as much of what they are worth these days.",
      "I was looking into this card last night and saw people were able to get this card down to 50w on the core while losing only about 15% performance from stock. Absolute craziness in terms of efficiency"
    ]
  },
  {
    "brand": "amd",
    "generation": "6000",
    "tier": "low",
    "matched_keywords": [
      "6600xt",
      "6600"
    ],
    "title": "Deeply regret buying a 6600xt. The card have a lot of issues that no reviewer talks about",
    "selftext": "There is not a single stable driver for this card at the moment, all of them comes with issues like freezing, restarting, black screens, etc. All of the issues are related to windows power saving mode.\n\nWhenever your display goes into power saving mode (When the \"no signal\" message appears on display, after some time of inactivity), you will have some issue.\n\nThe only workaround atm is to set the \"Turn off display after\" in windows power settings to \"Never\".  \n\n\nI'm SHOCKED about how many people have this problem and AMD doesn't even recognize as a known problem in the last driver patch notes (21.9.2)  \n[https://community.amd.com/t5/graphics/problem-with-my-rx-6600-xt-nitro-and-it-s-weird-behavior/m-p/489727](https://community.amd.com/t5/graphics/problem-with-my-rx-6600-xt-nitro-and-it-s-weird-behavior/m-p/489727)\n\n[https://community.amd.com/t5/graphics/amd-radeon-6600xt-restart-pc-when-screen-timeout-is-turned-on/m-p/485223#M78484](https://community.amd.com/t5/graphics/amd-radeon-6600xt-restart-pc-when-screen-timeout-is-turned-on/m-p/485223#M78484)\n\n[https://community.amd.com/t5/graphics/rx-6600xt-rebooting-pc-after-display-goes-into-power-saving-mode/m-p/490282#M79535](https://community.amd.com/t5/graphics/rx-6600xt-rebooting-pc-after-display-goes-into-power-saving-mode/m-p/490282#M79535)  \n[://www.reddit.com/r/AMDHelp/comments/p5aa4w/pc\\_freezes\\_after\\_sleep\\_mode\\_with\\_rx\\_6600\\_xt/](https://www.reddit.com/r/AMDHelp/comments/p5aa4w/pc_freezes_after_sleep_mode_with_rx_6600_xt/)  \n\n\nI hope that AMD are already working on a fix for these issues...\n\nSpecs:\n\nCPU: R7 3700x\n\nMB: Asrock b450m Steel Legend\n\nRAM:16gb (8x2) XPG D41 Spectrix\n\nPSU: XPG CORE REACTOR 750W\n\nGPU: POWERCOLOR RED DEVIL 6600XT (21.8.2 WHQL Driver)\n\nEverything stock, including RAM.\n\nEDIT: I \"fixed\" the issue by disabling ULPS. However, i need to choose what function my pc needs the most: If i disable ULPS, the screen can turn off and be in idle mode for days just fine, BUT, if i do that, everytime that i suspend the computer, it comes back with a Driver Timeout message displayed by AMD Software.",
    "comments": [
      "RX5600xt launch experience",
      "Recently bought MSI 6600 xt gaming x, been working flawlessly with a qled tv since I got it.\nEven when the TV turns off/power saving mode and turns it works without a hitch or restarts.\n\nSorry you are having issues with yours.\n\nAnd probably why reviewers dont mention it is because they might not experience it?",
      "The 5700xt too.\n\nSource: used to own one",
      "I was looking for this comment. Man that card had serious driver issues",
      "I'm strongly suspecting some PCIe4.0 compatibility issue. Some B450 \"beta\" bioses accidentally enable PCIe 4.0 on the primary x16 slot which can cause major issues since the most B450 boards are 4 layer PCB without proper signaling for PCIe 4.0. Given that 6600 XT is a gen 4 GPU it'll force PCIe 4.0 if it's available. \n\nTry checking which PCIe version is used by the gpu using gpu-z. Try also checking the bios and see force PCIe 3.0",
      "I have a S. Nitro 5700XT since their launch day and didn't have a single driver issue, some games weren't working like Fortnite which was fixed out quickly and also had the same bugs as others like Guildwars 2 but other DX9 games working fine, really weird experience for a lot of people :/ Even faulty powerbrick extensions caused peoples GPUs to act up.",
      "Oh my god, I HAD THIS EXACT ISSUE! Drove me absolutely mad for a few weeks.\n\nReturned the card, no fault found. How I fixed it? I switched it over from the x570/3600 to an intel 11600k system. Not a single problem since.\n\nPlease tell which exact mobo + CPU you have?",
      "Bought my 6600 XT at lauch day. No issues, working perfectly with all drivers. Updated to 21.9.2 yesterday still no issues.",
      "When making such a post, you should elaborate a lot more on your setup: what are your system specs? Was the system stable prior to installing the new GPU? If it's a new build, what PSU and memory kit do you have? Have you ensured a fresh, clean installation of Windows? Cables? Have your tried different cables or tested with an alternate GPU to confirm whether the issue persists?  \n  \nJust crying about a problem and providing no context is seriously lame and shouldn't be allowed.",
      "yeah i think this scenario probably won't happen to a lot of reviews since they'll be using the card a bunch as they run through their benchmarks, so they probably will rarely, if ever, get to the point where their system idles long enough to go into power saving.",
      "I have two 6600XTs (My PC and my wife's) and zero issues to complain about. I use driver 21.8.2 for both systems. They run all games throw at them with rock solid stability, not a single crash, black screen or anything of the sort whatsoever. Before these 6600XTs, I had 3 Nvidia cards in a row and I can say that they feel as stable as Nvidia cards. Maybe overclocking, undervolting and tweaking in general I would give an edge to Nvidia. But for general play, I think AMD has done a hell of a job to achieve this level of stability that I am experiencing.\n\n\nAs for people who regret buying a 6600XT, the solution is simple: ebay it. You might even make a small profit.",
      "Well if your problems go away when u disable screen sleep, maybe the problems are Windows related.",
      "Yeah, it is kinda weird how some people have had 0 issues since launch, while others experience so many bugs. In my case, the entire system would crash and reset randomly under load and some games didn't launch at all (e.g. Hitman). Hopefully AMD will resolve the issues with the current gen quickly enough.",
      "Some other user here told me to force pcie3 on bios, i did that and pc is idling for 1 and a half hour, so far so good.. usually it would take less than 15 minutes to restart when monitor turned off.",
      "You say that, but I got a 3080 a few months after launch and it too had wake/sleep issues and also had some bug where it would freeze up loading a webpage randomly.  It all got fixed with a month or two after a number of updates, but still Nvidia isn't perfect either.",
      "I got a red devil 5700xt near launch, and was a nonstop poster on here as well as r/amdhelp As a sysadmin, I was sure that it was a \"me\" issue, and couldn't concede that I spent $450+ on a card that was essentially broken from the factory. It would blackscreen and restart my computer multiple times a day, and many posters would say that my 750w platinum rated PSU was the issue (lol). Along with countless other \"fixes\", OS wipes, drivers with DDU, etc.\n\nSo what did I do? I bought the highest rated power supply I could find at microcenter, wiped my OS, and it still failed. Fine. Maybe my motherboard has issues with the card. I built a second computer out of older parts and that power supply and guess what, it still failed. At this point, I have tried multiple hw configs, drivers, and countless OS wipes. At one point, an AMD employee recruited me to a dev discord and sent me new drivers and tools to record the issue. This went on for a few months but no beta driver helped me. To note, so many people on the two subs were having these exact issues - this was not an isolated issue.\n\nAbout 3 months later, I RMA the card to powercolor, who after 2 weeks, they find 0 issues with it. I get it back, furious, so I forgo ever putting it back into a system, and sell it at a good price with an obvious caution \"had issues with it, but Powercolor says there is nothing wrong with it\".\n\nI buy a 2070 super and have had 0 issues. No reboots, no black screens, no crashes, artifacts, anything ever. It's been about 6 months since then. I sincerely hope the person who bought that card has had 0 issues with it. I still love AMD as a company, but the entire experience left a terrible taste in my mouth because nobody took blame for it.\n\n&#x200B;\n\nedit: I now realize that I haven't posted since swapped cards, I still have the 5700xt as my flair lol.",
      "I have reference 6700 XT, running latest drivers, and absolutely 0 issues with 2 screens running different resolutions at different refresh rates. I had more issues with my GTX 1080 (mostly DOOM Eternal crashing), but 6700 XT has been smooth sailing.",
      "Both LTT and Hardware Unboxed mention this about PCIe4.0 x8.  \n\n\nHardware Canucks did a review of the PCIe4.0 vs 3.0 with x8:  \nhttps://www.youtube.com/watch?v=86pRe\\_GeT1I&t=361s   \nBut its bad that AMD or vendors doesnt mention this in specs/on box.  \nNot easy to catch up with demand and shortage of substrates to combat prices.",
      "It seems to be related to how ryzen cpus manage idle voltages.\nHowever, i don't think that my CPU is the problem, i tested my GPU in my gf setup and the same thing happens. Also, my old rx 570 runs fine.\n\nI have a r7 3700x + asrock b450m steel legend.",
      "Every single driver released since May is completely unable to properly render Motion Smoothing for ANYONE, an essential effect in some highly demanding VR games. And only after months they made the card even usable for that purpose, due to an occasional stutter causing nausea in all games. So yeah, they're clueless like that. As a VR user, I also deeply regret buying the card at launch."
    ]
  },
  {
    "brand": "amd",
    "generation": "6000",
    "tier": "low",
    "matched_keywords": [
      "6600xt"
    ],
    "title": "I recently bought a 6600xt but I seemed to have gotten a bonus item",
    "selftext": "",
    "comments": [
      "Cats do  not improve GPU thermals, no matter what they tell you.",
      "Finally, a GPU worth the inflated price!",
      "Mannn, they lied to me Qwq",
      "It was absolutely worth it",
      "Definately Furmark",
      "This card is really gonna purrrr.",
      "Extra Purrformance :3",
      "May contain cat.",
      "Was a joke because the GPU \"included\" a cat. But it depends on price.",
      "Which games do you play, and at what resolution and framerate? I have the exact same XFX Merc 308 card as you and I love it!",
      "What‚Äôs the hash rate of that cat?",
      "Graphics Cards come with cats now? No wonder they are so expensive.",
      "Dumb (but) Lovable Cat",
      "lol, nice pro-AMD cat!",
      "Looks like a DLC :D",
      "3 furballs/hour",
      "Go tell someone who cares. Try buying a used 5700xt for the price of a new 6600xt. You can‚Äôt because the the 5700xt is a good mining card. You act like it‚Äôs AMD‚Äôs fault the silicon shortage makes everything to expensive. It‚Äôs no different from a 3060 being no better than a 2070 and no cheaper. It‚Äôs normal for a new GPU to be basically equal to a model one tier higher but one gen older. The 3060, 2070 and 1080 are all basically equal.",
      "It's actually a thunderbird.",
      "Nvidia may work better in GPU rendering depending on what software you want to use. Look at compatibility lists for every software you need to see what's best.",
      "Is it? Deciding rn between a 6600/XT, a 2060/super or a 3060. Not only for gaming, but for 3d rendering too"
    ]
  },
  {
    "brand": "amd",
    "generation": "6000",
    "tier": "low",
    "matched_keywords": [
      "6500xt",
      "6600"
    ],
    "title": "RX 6500XT/6600 concept, done in blender. I had a lot of fun making this.",
    "selftext": "",
    "comments": [
      "Wireless GPU",
      "It turned out crap so I didn't add it in.  \n\n\nEdit: I made the PCIE connector and a proper I/O shield here  \n [https://imgur.com/a/1v5HxYv](https://imgur.com/a/1v5HxYv)",
      "Just connect it via sata",
      "I hear Molex is boppin‚Äô",
      "Bro, when was the last time you built a PC? SATA is dead. Shit is way too slow. Use Firewire.",
      "Criticism: You didn't add pcb, the io bracket looks it's 2 slot tall but has 3 fingers. \n\nReference: https://www.ekwb.com/shop/ek-fc7970-dcii-i-o-bracket",
      "yes.\n\nedit: I fixed it and added a PCIE thing  [https://imgur.com/a/1v5HxYv](https://imgur.com/a/1v5HxYv)",
      "Ahhh yeeees, misaligned molex connectors. That's my fetish.",
      "Imagine this, but even shorter and with a larger fan. That'd be amazing.",
      "Ahh so I'm not the only one remembering the R9 Nano",
      "Na. I‚Äôll just connect it via the hd audio header",
      "Sorry, this is going to connect via PS/2",
      "Nah, not enough bandwidth, stuff it into a ZIP drive",
      "dont forget the RX 5300",
      "Not bad, i think this would be a nice addition to some small case / Prebuild's.",
      "One day it shall be released (come on amd a good 250 bucks card to replace my 4gb rx 570)",
      "I think it seems like it since he didn't add a pcie connector",
      "That's not how this works, clearly gpu is connected through Infinity architecture",
      "i think this calls for an XLR connection",
      "AGP is pretty good too"
    ]
  },
  {
    "brand": "amd",
    "generation": "6000",
    "tier": "low",
    "matched_keywords": [
      "6500xt"
    ],
    "title": "PSA: RX 6500XT official release date is tomorrow. (1/19/22) Please dont support scalping!!",
    "selftext": "AMD have given an MSRP on this card and promised a few things--\n\n1.) $199 MSRP (actual available price targeted)\n\n2.) Large available quantity at launch.  Lisa Su:\n\n>We‚Äôre positioning the launch such that‚Äîand I know, you guys always say, ‚ÄôWell, yeah, they‚Äôre just saying that‚Äô‚Äîbut we really are positioning the launch at a $199 price point. It is sort of affordable to the mainstream. You know, we intend to have a lot of product out there.\n\n3.) Its no good for mining and according to AMD, that was an intentional part of the design.\n\nNumber 3 above is key.  If this is true (and it will be tested, I can assure you), then miners wont be buying truckloads of them-- they shouldnt actually be buying any at all.  Again, this means that anyone selling these tomorrow at above MSRP are outright scalping /scalpers.  In normal times, this is a $160 card, at best.  Its gimped in mem capacity, gimped in hardware video codecs, gimped in PCIe lanes/bandwidth.  Consider that if you are thinking of caving in and paying more than $200.  Dont do it.\n\nIf you purchase one of these cards for anything more than a penny over $200 USD, you are supporting  and encouraging scalping, period.  This should not be able to be blamed on miners. Do not pay more than that at Amazon, Newegg, Best Buy, Microcenter, etc, and for DAMNED SURE do not pay more than that on Ebay or some hardware swap forum.\n\nShow some backbone and say no to scalping once and for all.  Make the scalpers who purchased multiple cards with the intent of flipping them sell for a loss.  Send a message to the AIBs that its not OK to upcharge 50% of what a product should cost just because they slap a \"superclocked\" or \"OC edition\" label on it. If the community doesnt unite and take a stand against this BS it will never stop.\n\n&#x200B;\n\n**\\*\\*EDIT:  There are already some people trying to justify higher prices by saying that \"Oh, the AIB versions will have a bigger cooler, etc, so they will be more expensive.\"  BULLSHIT.  AIB cards are the only ones that are being sold and Lisa's comments about targeted street price of $200 already take this into account.  That means that AMD has sold these GPUs to AIBs at a low enough price that $200 should cover everything else they need to produce the card and still make a profit.  Dont fall for that BS.  This is a tiny die, on a tiny card, with a tiny amount of memory.  It doesnt need a  triple fan Arctic Frozr cooler or some exotic liquid cooling shit on it, dont be that gullible.**",
    "comments": [
      "Honestly? Dont support this gpu either.",
      "My dude, we don't live in a fantasy land where we can flip a switch and stop everyone from buying grapic cards.\nThey're sold for 2,3x the MSRP not because of the people supporting scalping and corporate greed,but due to the fact that people are willing to pay 1600 for 6900xt, 1500 for 6800xt, 1200 for 3070 ,and those are AIB prices caused by tarrifs, TSMC raising prices, AMD/Nvidia rising prices.\n\nWe might disagree all we want, but it is what it is, unless we have an enormous surplus in GPU supply prices are not coming back to \"normal\".",
      "> ETH going to PoS in June\n\nIsn't this the 4th time they have set a date to go to PoS lol",
      "How about you wait for reviews of the card cause you know, there are so many red flags on it?",
      "Dont need a review to understand its not worth more than MSRP.",
      "Really depends what you're coming from.  For some, they might be able to sell a multi-year old card near breakeven and get a brand new card that performs slightly better and at much lower energy, new warranty, and not have to worry about the old one crapping out and being stuck with nothing.\n\nNo it's not an amazing card everyone should be jumping out to buy, but might be a godsend for someone desperate.",
      "Almost anyone that buys this has been duped by AMD.",
      "There is no \"if\" about number 3 because there is only a 4gb version and cryptos such as eth needs more than that to even run never mind run well.",
      "Said multi year old card likely runs in a pcie 3.0 system which means this garbage when put inside it will run in pcie 3.0x4.",
      "It's not even worth it's MSRP imo.",
      "The 4x pci-e lanes will destroy this card for anyone not on pciE4.\n\nWhich the people in this budget range probably aren‚Äôt rocking newest Intel or AMD platforms‚Ä¶",
      "This post is filled with good intentions I'm sure, but really it's cringe as fuck.",
      "Sigh. I'd prefer they'd just put some \"fresh\" RX580's or 590's out instead. :(",
      "They're gonna be sold for higher than MSRP. Scalping is profitable so you're on some copium if you think the price people will sell this at isn't going to be at least 50% more than MSRP, regardless of how lackluster it is.",
      "There's too many desperate gamers willing to burn money for it.",
      "We'll see tomorrow.  Im sure you are right as Techpowerup said this is the first time in like 13 years that AMD has not sent them a sample prior to launch date.  Probably for the exacts reasons you are worried about.",
      "While the message *may* be good, it shows a real disconnect as to how supply and demand operates in a free market, and also gives off the impression you think you can influence anything with a simple Reddit post that got 175 likes.\nSmells a little desperate to me as well, but idk maybe I'm just reading too much into it at that point.",
      "People should also note here, this card is not worth MSRP, let alone above it, it has been gimped in too many ways, (Not to prevent mining, so they can cut costs producing it and increase the margin on it), AMD saying its to prevent mining is a PR stunt, nothing more (Unless someone fancies telling me how gimping the PCIE lanes and memory bus also help 'prevent mining' when the 4gb vram is already in place)\n\n&#x200B;\n\nIf you are a gamer on a budget (Which realisitcally if you're looking at this card, you are), don't bother, get a current generation console. These are easier to buy than GPUs, are more powerful than this GPU, and will cost less (Comparing total system cost).\n\n&#x200B;\n\nThe point of the PC platform is to give a premium experience over consoles for a premium price, this card represents a premium price for a worse experience \n\nYou aren't really getting the freedom of framerate and resolution here, even settings tweaks really, and you're below the XSX/PS5 performance tier so what's the point in buying it more than those systems cost",
      "Supposedly somewhere around RX 580-ish.",
      "Even MSRP seems like too much honestly. Unless they can get it to run at full speed at PCI-E 3.0 x4 and is meaningfully faster than the 5500 XT, this card is going to be terrible at 200, but with how messed up the market it, I'm sure it will sold out even at 400."
    ]
  },
  {
    "brand": "amd",
    "generation": "6000",
    "tier": "low",
    "matched_keywords": [
      "6400"
    ],
    "title": "Upgraded froman i5 6400 w/1050 ti to r5 3600 with a 2070 super",
    "selftext": "",
    "comments": [
      "How are you liking the Tomahawk?\n\nJust got mine running last night.",
      "The CPU upgrade alone should be monumental. Can't wait to upgrade from this ancient 4c to a 3600. I may finally see more than 30% GPU usage.",
      "yeah i bought the max verison",
      "I would have purchased that if I had known it had a 32mb bios chip.\n\nEdit: Max is not available in the US so it won't be an option.",
      "Fit more CPU microcode instructions and training tables. It allows the board to maintain compatibility al the way with Ryzen 1000 - Ryzen 3000 and beyond. However if you don't need / care for compatibility with old chips it\n\nI personally believe 16mb won't ve a problem if you are only dealing with Ryzen 3000 +",
      "That's quite an upgrade",
      "What's the advantage of higher chipset memory? What's the difference between a 16mb chipset memory VS 32mb",
      "Why was I downvoted for asking where?",
      "exactly",
      "How's the artic cooler? I'm planning a similar build but waiting for rx5700 AIB models to come out. Did you try the stock AMD cooler?",
      "That is one THICCC card",
      "I replaced my 7600K with a 3600. The 0.1% lows went more stable and higher. I get higher FPS in games and my cpu doesn't stay at 100% most of the time now.",
      "The 3470 has held me back in pretty much every game and application. Even BF3 stutters like mad and I can't break 90 FPS no matter what settings I run at. Got a similar framerate with my R9 285 which is significantly less performing. Ran fairly well with intermittent stutters but near 130 FPS with my old FX 8320. Userbenchmark test says it's performing as expected one minute and no where near expectations the next minute.",
      "Is that really an issue",
      "Where? Max isn't available in the US",
      "Cuz Reddit.",
      ">I personally believe 16mb won't ve a problem if you are only dealing with Ryzen 3000 +\n\nRight, it really only effects the bios user experience",
      "Im from slovenia",
      "Userbenchmark is not really a reliable source is it?",
      "Old flair, I have 3600 now on tamahawk non max. Difference between the two is chipset memory."
    ]
  },
  {
    "brand": "amd",
    "generation": "6000",
    "tier": "low",
    "matched_keywords": [
      "6600"
    ],
    "title": "Then and Now: Hardware Unboxed on RX 6600",
    "selftext": "",
    "comments": [
      "Things change and I'm glad that they can change their opinions based on new info!",
      "Well tbf to them, these videos are from different timepoints which you're omitting to put forward your narrative (And their review title is true, that is what the 6600 is) and I don't think you actually watched either of the videos\n\nThey say to buy it if you have no choice and need to buy a GPU, because it was the cheapest current generation GPU at the time of review (But in a normal market it's a joke and just an uninspiring product in general)\n\nThe second video is basically saying to buy it over the 6500xt/3050 because it has better 'value' than either of those cards, but again aren't actually recommending buy it\n\nat the time of the review, it was shit, and tbh it still is a bad GPU from an objective sense, and at the time of reviewing all reviewers don't know what the street pricing will be \n\nBut in the context of this market it is the best card from a price;performance perspective, that's not exactly saying much though when people are buying a 6600 for the price my 6800 cost",
      "I mean... it *can* be a really expensive 5600XT with really shit ray tracing *and* still be the best value GPU on the market.\n\nThe two aren't mutually exclusive...",
      "$$$",
      "It's almost like pricing changes, also watch the content. We said the success of the RX 6600 will heavily depend on pricing :S",
      "Exactly. It‚Äôs not like they said ‚Äúthis card is the worst price to performance card‚Äù on launch and then said ‚Äúthis card is the best value card‚Äù a few months later. Though with the current GPU landscape, even those statements wouldn‚Äôt be too unbelievable.",
      "Initial reviews always go off of MSRP. Which makes their price/performance conclusions practically useless.",
      "The 6500XT is freaking terrible, which would make the 6600/XT the best value.  The 6700XT is $900.",
      "Why would he have manipulated numbers to say the FX line sucked when the FX line objectively sucked?",
      "Their change in opinion has more to do w/ the lower tier cards (and their pricing) that have come out since then.  The 3050 is a decent card that is wildly over-priced while the 6500 XT is a complete shit show.  As of now, that makes the 6600 the \"cheapest\" card that's worth a damn.  If the 6500 XT wasn't so gimped or the 3050 was priced accordingly, this would be a completely different conversation.  \n\n\nWelcome to 2022, where \"best value\" basically means \"this purchase will dick you over the ***least ...*** but it will still give you the D.\"  Fingers crossed that Intel releases a reasonably priced budget card.",
      "You mean his opinions on the CPU line that all sane people think was garbage?",
      "The 6600xt is the only thing available at \"acceptable prices\" were I live since it goes for 5700xt prices. Its the only thing which I could recommend to one of my friends. Both the 3060 and 3060ti cost a lot more. The market changes and so most the perspective of reviewers. \n\nI would like to get a high end GPU for 350CHF (like my r9 fury), but it will take a lot of time for that to happen.",
      "As many have already pointed out in the comments, the thumbnails aren't mutually exclusive so you're making yourself look quite foolish here. Significant adjustments in retail pricing aside, the RX 6600 is still an expensive 5600 XT with shitty ray tracing performance, while the second thumbnail is now correct, dropping to $450 US makes it the best value GPU in the current market.\n\nUpon release the RX 6600 didn't look impressive, pricing didn't sound as though it was going to be remotely interesting and it wasn't, so what did you want the thumbnail to say? \"The probably crap value RX 6600 is here?\"",
      "What new info exactly? \nWhat has changed in the last three months?",
      "That's cause that's CPU is the biggest turd sandwitch in the world i remember it losing to a dual core 5ghz pentium lol in so many games.",
      "That's pretty funny coming from the guy choosing to avoid decades of people thinking the FX CPUs are garbage.\n\nGot a good deal on that copium?",
      "Objectively it is a poor value card (except the 75W pcie limit niche) \n\n\nWas out performed and was more expensive than the RX570 8GB but because it's basically the only \"cheap\" Nvidia card in the market (minus the super variant) and was in a shit ton of laptops and OEM systems it's nearly top dog in the hardware survey",
      "Except the 6600 and 6600 XT were both called bad value cards at launch by most reviewers, so them being bad cards as a result was indeed part of most of the launch reviews of those GPUs. It's only more recently that reviewers who shit on the 6600 XT are having second thoughts about it.",
      "But they don't recommend buying the 6600 in either video, they say in the second to buy it instead of a 6500xt/3050 if you have no choice, and they do say in their review to buy it if you have no choice\n\nBut that's it's a not a good buy, which it wasn't, just because it's gone up in price since launch does not mean the launch price was a 'good' buy, they don't praise it's value, they just say it's less shit value than the 3050 and 6500xt\n\nYou've basically done what they did, clickbait the clickbait to generate traffic",
      "I owned the FX 8350 and traded it in for a I3 haswell at the time every single game i had performed night and day better and that was just a placeholder until i got a 4790K at the time.\n\n&#x200B;\n\nFX 8350 was and will always be a POS CPU\n\nIPC and latency on the bulldozer line of CPU's were so terrible and it barely improved with Piledriver\n\n&#x200B;\n\nI actually even remember dolphin emulator performing faster on my 1100T at 3.9Ghz vs my 8350 which could only do 4.5 with the SAME cooling"
    ]
  },
  {
    "brand": "amd",
    "generation": "6000",
    "tier": "low",
    "matched_keywords": [
      "6600xt"
    ],
    "title": "Pricing stickers on 6600xt purchase yesterday for $400",
    "selftext": "",
    "comments": [
      "Not surprising unfortunately",
      "So it's not AMD that scalps but retailers.",
      "You take the cheapest gpu sticker and stick it on a 3080Ti box\n\nProfit\n\nEdit: DONT TRY THIS AT HOME",
      "There was [another thread](/r/Amd/comments/p39mi2/the_largest_dutch_tech_news_site_is_claiming_that/) that said AIBs basically paid rebates to retailers so the first batch of cards would be MSRP. \n\nIMO this is just a trick so that launch date reviews will position the card at $400 in price vs performance charts. So congratulations to everyone who got a 6600XT at MSRP, coz it's gonna be a quick price hike to $700 after initial stock is sold out.",
      "Do you mean your 5700xt? 6600xt is such a pointless upgrade for you unless ray tracing is really important ? It's barely any better you are best of keeping it for the next set of cards from AMD and NVidia.\n\nKeep that 5700xt going!",
      "You can't try at home, you need to try at store...",
      "Most you'd actually get is a dirty look from the employee before looking up the real price in the POS.",
      "I feel like they could turn that into a handful of crimes. Theft, defacing private property, attempting to defraud a company, damage to private property.... They could smack you with a whole list of things if they felt so inclined.",
      "bro i bought a 5700xt last december at MSRP, feeling pretty happy with my purchase rn",
      "Looks like the 5700xt is in for the long ride üò≠",
      "First, I am glad I got mine yesterday at $400. Micro Center had plenty available near MSRP, even had cards left at the end of the day. \n\nHowever, there is no guarantee this will continue to be the case in terms of both quantity and pricing. In fact, the pattern from the 3060 and 6700xt launches were that they had cards near MSRP on launch day but almost only expensive ones later on. Given that even the 6700xt is selling for $800+ from most board partners, I would not be shocked at 6600xt going above $600-650. \n\nWith all the reviewers‚Äô complaints about the $379 MSRP, they forget that getting this card actually at $379 is an absolute bargain in this market, and probably only likely to happen on launch day. The correct advise to their audience should have been to get one at MSRP on launch day if at all possible and just sell your RX580 or GTX 1060.",
      "I scored a powercolor 5700 red dragon open box for $280 in March of 2020. My timing was incredible.\n\nReceipt screenshot: https://i.imgur.com/ZbQ3zme.jpg",
      "> unless ray tracing\n\nI thought all reviews show how RT in AMD cards is completely out of the battle vs nvidia (for now)? So if RT is a thing for you, wouldn't you get a novideo? (Unless you're really anti nvidia)",
      "you can't blame everything on scalpers when we are watching, in real time, how everyone in the chain loads their pockets like peddling heroin is out of fashion now\n\nAMD has been flaunting how their profit margin has been ballooning since RDNA1/5700XT and they've been feeling their excess cash enough to do stock buybacks in a year of massive social upheaval and global economy dropping into massive recession\n\nAMD and NVidia realized they're in position to shake everyone who wants a GPU down and they aren't gonna stop until their junk stops selling, everyone else along the seller chain gets to have a lick\n\nthis is \\[current stage\\] capitalism in action and it's only gonna get more common as competition ever weakens",
      "You ruined my life. Where are the kids, kevin? WHERE ARE THE KIDS?!!!!",
      "Probably, and the board partners also taking as much profit as possible. I don‚Äôt blame them‚Äî why let eBay sellers make the profit.",
      "But the fact is you CAN get this card NOW for msrp.\n\nYou can't get 3060 or ti for anywhere near msrp.",
      "Try to find a miner over in r/minerswap who wants a 5700xt.... I did a flat swap for my 5700xt and got a 6700xt :)",
      "Im already starting to regret i didnt buy it.",
      "It is like saying you should have bought gold in 2007, if you are in the need of a card, check the present, inform yourself on the future and try to make the most out of it."
    ]
  },
  {
    "brand": "amd",
    "generation": "6000",
    "tier": "low",
    "matched_keywords": [
      "6600"
    ],
    "title": "Me and my dad just built this pc, any thoughts? Specs: Ryzen 7 5800X, 32 GB DDR4 RAM, PowerColor Red Devil Radeon RX 6600 XT",
    "selftext": "",
    "comments": [
      "Looks good man. I would suggest not daisy chaining the PSU to the graphics card. Run two separate cables to both of the 8pins.",
      "6600 XT probably won't draw enough power for it to be an issue, however, best practices are two separate dedicated cables.",
      "Great specs very nice PC.",
      "he's saying urs is shit",
      "This is the correct answer. Using 2 separate cables is the better practice and what I always do. However, the 6600 XT Thermal Design Power (TDP) is 160W. I can't imagine the AIB card using more than 225W excluding a few spikes, which a single PCIe power cable and the motherboard can safely supply (Motherboard provides 75W and single cable has a TDP rating of 150W). I personally would be comfortable daisy chaining this setup if I had to. Probably would slightly undervolt to be safe.",
      "That makes me feel better about my cable management",
      "Why are you using a 120mm AIO for 5800?. You could get a 240mm and mount it on top.\n\n120mm AIO, in my opinion, is only to be used when you're building a SFF build. Your 5800X *might* run a bit hot on that.",
      "Ok, thanks!",
      "Cable management is dissapointing (I don't care it's misspelled.)",
      "Thank you so much!",
      "You want a pic from a better angle? It‚Äôs not that bad. And if you still think it is, then I‚Äôm sorry. Me and my dad tried our best.",
      "Oh ok, thanks!",
      "It's not the capability of the PSU for the reasoning, it is how much power is coming from the cord to the GPU.",
      "Nice setup! Great CPU, decent graphics card, and plenty of RAM. üëç",
      "It‚Äôs how I was raised, thanks so much for the compliment!",
      "They should be included with your psu",
      "I‚Äôd do some cable management. Get the excess length bundled up in the backside of the case, behind the motherboard. Other than that, nice first build!",
      "Your dad's great.\n\nMy thoughts. I'd downgrade the cpu and ram to get a much better gpu. But if you're utlizing those 8 cores and 32gb ram with your workload then fair enough.",
      "I'm not sure the $130 you could save doing that would really result in much of a GPU upgrade, sadly.  =/",
      "PSU wouldn't come with daisy connectors if there was any reasonable chance that the power draw at maximum on both connections would cause a shutdown or melt the cables.\n\nThere's plenty of evidence showing daisy connectors are no risk at all to 3080/3090 power usage. There may be some GPU performance impact depending on the connector but it's so small you won't notice it anyway.\n\nEdit: for my own anecdote, I'm running a reference 6900XT and a corsair RM 850x that comes with daisy chain connectors. The wire from the PSU to the first connector is much higher gauge than the chained connector.\n\nI have no performance difference using either 2 separate 8-pin or a single daisy chain. The heat in the wire measured 1 degree higher which is not much and within error of the indirect thermometer I was using.\n\nSo it really depends on the PSU and again, I doubt any PSU maker would risk the liability of not having more than adequate daisy connectors."
    ]
  },
  {
    "brand": "amd",
    "generation": "6000",
    "tier": "low",
    "matched_keywords": [
      "6500xt"
    ],
    "title": "RX 6500XT doesn't have H264 Encoding, What does this mean for an average gamer/streamer like me?",
    "selftext": "",
    "comments": [
      "It means you will need to get a Nvidia card.",
      "basically mean you'll have to rely on cpu encoding, which is often recommended anyway in AMD lower end cards.",
      "This is the most realistic answer since OP never eluded to streaming using the CPU.",
      "someone with a 6500xt may not have a powerful enough cpu for decent quality recording **without loosing performance** though. This is where the hw can be great even if the quality is somewhat lacking, not having to loose FPS while recording is a godsend and why i don't use X264 for real time encoding (OBS).",
      "It depends, AMD's H264 encoder is kinda bad specially at a low bitrate, but their HEVC encoder is very good, so if you're recording gameplay it's better to use hardware encoding (GPU), but if you're streaming it's better to use software encoding (CPU).",
      "Basically since RTX launched, the nvenc on those cards can get reaaally close to x264 medium",
      "Don't buy it.  It's a downgrade from the RX480 / RX580 / RX 5500XT.  Get an RX 6600, RX 6600XT, RTX 3060, RTX 3060Ti, buy a used card, or wait for an RTX 3050.  AMD keeps shitting on the $200 market and has done so for the past few generations; no Vega model, RX 5500XT, and now the RX 6500.   It's sad when a 5-6 year old card outperforms a brand new offering that should blow it out of the water.",
      "It's *losing not loosing.",
      "You use software CPU encoding or Quick Sync Video if you have Intel integrated graphics. Other than that, a spare GPU just for that task (preferably Nvidia).",
      "or a good CPU.",
      "Well good news!  Your flair says you already have a 6700XT so really it won't affect you, just like 99.95% of commenters shitting on it that will never own one any way, this isn't aimed at ANY OF US it's just to get more cards out the door in shitty bottom barrel prebuilts, and NOBODY buying one of those is seriously contemplating \"streaming\".",
      "The issue is, if someone is buying a '$200\" GPU they likely have a really old, slow performing CPU. People aren't going to pair these with a modern Zen 3 or 12th gen CPU, but likely a 5+ year old budget one.\n\nSo it absolutely becomes an issue.",
      "But how does the performance get loose? Do you need a screwdriver or socket wrench to tighten it?",
      "Isn't part of the whole argument to buy 6-8 core Ryzen CPU's is to stream while gaming at the same time?  When did it become a big deal to use your GPU to encode, anyway, I always that was the inferior method...",
      "In the real world, your audience doesn‚Äôt care and will watch completely garbage video if your audio and content are tight.",
      "It means Radeon ReLive won't work and it's a huge dealbreaker for me.",
      "More than likely, imagine gaming and recording at high bitrates on a 4x interface lmao, i still cannot believe AMD made a X4 gpu, even for mobile i find it odd.",
      "The explanation I have seen is that both the x4 interface and the lack of hardware encoding is because it's a notebook GPU repurposed for desktop. Notebooks don't need a hardware encoder on the GPU because the iGPU already have one, and they use PCI-E x4.",
      "> But don't be surprised when this actually out performs the RX 590/GTX 1660.\n\nNot sure if you're being sarcastic",
      "I just need a gpu to play modern games at 1080p with decent frame rates. I don't stream or record anything and don't care to ever have the ability to. Does this fit the bill?"
    ]
  },
  {
    "brand": "amd",
    "generation": "6000",
    "tier": "low",
    "matched_keywords": [
      "6600"
    ],
    "title": "[HUB] Nvidia Gets OWNED: GeForce RTX 3050 vs Radeon RX 6600, 50 Game Benchmark",
    "selftext": "",
    "comments": [
      "I've owned a 3050, 5600XT, 6600 and 6600XT \n\n\nThe 3050 really doesn't have a place, it's noticeably slower than even a 5600XT, draws more power than a 6600XT, DLSS can't work it's full magic at 1080p and at higher resolutions the card doesn't have enough GO to make use of it \n\n\n\nIf it was a 170-200 GPU then sure but it's closer to 300 in a lot of cases",
      "I don‚Äôt understand how 3050 prices have stayed so elevated as everything else drops, the cheapest on Newegg is $330. That‚Äôs arguably even worse value than a $200 6500XT.\n\nMeanwhile the friend I just helped build is very satisfied with his $250 6600.",
      "the 6600 & 6600XT are pretty much the default choice for 1080p gaming right now, unless you can get a 3060Ti for around the same price as the former two cards.",
      "If you did the numbers at the MSRP, it's literally just a faster 6500xt. 20-30% faster for about 25% increased price. And that was *if* you could get it at Nvidia's MSRP, which we all know is a joke\n\nMeanwhile the 3060 and 6600 were practically 2 times more powerful for 50% increase in price. 3050 is genuinely a worthless card",
      "3060Ti could've been the people's card for this gen if not for fucking miners.",
      "I have a 3050. It lives in my unraid server and it transcodes plex and does some rendering work. It replaced a 1060 6gb with a net influx of 50 bucks in cash. So effectively a free upgrade.\n\n&#x200B;\n\nAMD didn't have anything that I could do this with. All their cards at that price range don't have proper encoders. OpenCL is also a joke and no proper rendering software really supports AMD over CUDA.\n\nThat's the realistic niche for this card. It's unfortunate AMD doesn't have much to compete with it.",
      "Yep the only thing new we learn from this video is that AMD card prices keep tanking even below MSRP and somehow 3050 prices still above MSRP. About the performance part from the moment they come out from all the review we already knew that 6600 1 tier above and closer to the 3060/3060Ti/6600xt (hence the name) than the 3050.",
      "Never underestimate that Nvidia mojo. People refuse outright to buy AMD GPUs. In my shop we get people all the time who refuse them. Almost afraid of them. Beats anything I've ever seen. The last Nvidia I bought was a 7800gt. I've had an hd4650, HD7770,R9390, Vega 56 and now 6750xt...I've never had anything but good experiences. I don't get it.",
      "Sadly HWU didnt mentioned that Nvidia silently replaces 3050 dies with 20% slower ones.\n\n\nI guess Nvidia plans to sell idiots the old 3050 as a 3050Ti lmao.",
      "I wouldn't say it's worthless, but it's probably worth about $150. It 'SHOULD' be a replacement for the 1650 Super in Nvidias product stack with similar performance but with RTX and DLSS features added (despite how fairly useless they may be in most games on this card, there are some low-demand games that will still work well with DLSS at 1080p like esports titles). \n\nBut at $300 it's ridiculous",
      "Mining is dead and nvidia cards still overly overpriced. RTX 3050 is 330‚Ç¨ for the most basic model, which is just absolutely nuts when you can buy RX 6600 for 300‚Ç¨. RTX 3060Ti is also pricy as hell here + it's quite power hungry for what it is which will start matter soon with skyrocketing electricity prices in Europe (which were already like double the US prices).",
      "Yeah, AMD would never do that! Radeon RX580 2048SP was OEM only! /s   \n\nIt is not only Nvidia, every company does this. Call them out and don't buy bad products.",
      "No company is your friend.",
      "The 3050 is pointless even compared to Nvidia's own RTX 3060 which costs just about 60$ more but offers 4gb more VRAM and about 35% higher performance.",
      "I'll just head to the comments and grab my popcorn, waiting for the more rabid elements of the Nvidia subreddit to brigade the video.\n\nIn other news, he's right. Objectively there is absolutely no reason to buy a 3050 that I can think of. Like, none.",
      ">I don‚Äôt understand how 3050 prices have stayed so elevated as everything else drops\n\nI would guess that AIB's sold them to retailers for higher costs, and now since the crypto crash and with demand dropping out hard, retailers are hoping to not have to discount cards below what they paid for them, seeing if they can get some suckers to clear out what they have now.",
      "I think any fanboy forgets that, be it Nv, Intel, AMD, Sony, Microsoft, Tesla, Nintendo... You name it.",
      "Sure buddy, why have the prices crashed in the last 2 months?",
      "I've flip flopped between both brands since the OG Radeon and GeForce 2. Never regretted a purchase either way. The only card I ever had issue with was a 7900 GT, that luckily I bought from EVGA, so it was a quick and easy RMA.\n\nI don't get the diehard siding with one brand over another. Each gen, I read reviews and chose the best bang for my budget. Sometimes its AMD and sometimes it is Nvidia.",
      "Isn't that just in prebuilts? Still very scummy, but not something the majority of people on a reddit like this are effected by."
    ]
  },
  {
    "brand": "amd",
    "generation": "6000",
    "tier": "low",
    "matched_keywords": [
      "6600xt"
    ],
    "title": "Upgraded my GTX 1080 to a 6600xt",
    "selftext": "",
    "comments": [
      "There is a lot to unpack here wow.",
      "1080 -> 6600xt?\nCable management???\n500watt no-name PSU?!?\nOptical drive (nice)\nWeird case",
      "doesnt much seems like an upgrade .",
      "AHHHHHHHHH! Please clean up your cables, have some decency.",
      "OTOH its so refreshing to see an actual normal everyday build pic instead of some RGB ONLY 240mm FANS PORNOGRAPHY that is your standard battle station build here. \n\nThe cables\n\nThe CPU cooler\n\nASrock 6600XT\n\nRust HDD\n\nSome sort of Optical Drive\n\nMissing brackets\n\nCase Speaker just... doing its thing\n\nI feel like I can just keep going. \n\nIts case photography IN THE RAW",
      "Replacing a card for a 20% performance boost is usually not really worth it. It is an upgrade, but not a very noticeable one.",
      "Brother, this man has 5w speaker sitting on PSU, what cable management you are looking for ![gif](emote|free_emotes_pack|laughing)",
      "[https://www.gpucheck.com/compare/amd-radeon-rx-6600-xt-vs-nvidia-geforce-gtx-1080/intel-core-i9-10900k-vs-intel-core-i7-6700k-4-00ghz](https://www.gpucheck.com/compare/amd-radeon-rx-6600-xt-vs-nvidia-geforce-gtx-1080/intel-core-i9-10900k-vs-intel-core-i7-6700k-4-00ghz) Big enough of a difference, the 6600-XT is comparable to a 1080 Ti.\n\nOne should never really expect colossal gains over going from a x80 GPU to a x60 GPU unless it's a massive time gap like you're going from a GTX 980 Ti to an RTX 3060.",
      "Brother your cables",
      "Yep, this is why people need to be really careful when you get someone ranting about how AMD's drivers need fixing or how their cards blackscreen or other such stuff.\n\nWhen you've worked in a PC shop you see the absolute horror of some people's DIY builds...",
      "I'm not sure he has a lot of spots to hide cables, that's a very cheap case",
      "Depends on how much you can get for your old card. I sold my Vega 56 for ~500‚Ç¨ a couple months ago (probably to a miner) and replaced it with a RX6600 for 380‚Ç¨. It's slightly faster and I got money out of it.",
      "More of these. The every day cable managed rgb this and that builds are boring. Reminds me of my PCs",
      "1080 -> 1080Ti is not a big difference, definitely not worth 300$.",
      "It still looks like theres a punchout on the rught sidepanel to stuff them into. Not neat, not easy but it d look much better",
      "I like it, reminds me of my own builds. I dont give a shit about cable management either, I just plug shit it and use opaque cases so no one can see it. Problem solved! I mean, mines not quite THIS chaotic...but this is art.",
      "Ahh the good old days when cases had solid sides and you didnt care what the inside looked like..until it got a tad warm in there.  \nJust do us all 1 favour, even if you have no inkling to redo the cables...flip the power supply over so it is sitting properly with fan down.  \nThank you",
      "Bro is that even an upgrade? Isn't it like the same?",
      "Word. I have a 4090 and instead of using a GPU support stick I jammed a piece of cardboard between the 4090 fan casing and the drive bays below. Works like a charm zero sagging. \n\nPeople get so hung up in aesthetics they forget that as long as air can flow and cables are not hanging in your coolers, the build will be fine.\n\nI see my pc as my millennium falcon. Tied together with ducktape but outruns imperial cruisers with RGB.",
      "Intel box cooler?"
    ]
  },
  {
    "brand": "amd",
    "generation": "6000",
    "tier": "low",
    "matched_keywords": [
      "6600"
    ],
    "title": "2022 Glow up. Finally left my FX 6300. Now running R5 5600X and ASUS RX 6600. Full Spec below!",
    "selftext": "",
    "comments": [
      "Old build - CPU: AMD FX 6300 OC to 4.7GHz RAM: 24GB of DDR 3 at 1866MHz Mobo: Gigabyte 970A-DS3P FX rev 2.1 GPU: Sapphire Nitro+ OC RX 480 4GB Storage: 1TB WD Blue HDD. 240GB Crucial SSD PSU: Corsair CX550M CPU Cooler: Arctic Freezer 7X Case: XPG Starker\n\nNew build - CPU: AMD Ryzen 5600X RAM: 16GB XPG D60G @ 3200MHz Mobo: ROG Strix B550-A GPU: ASUS Dual RX 6600(non XT) Storage: 1TB Silicon Power NVMe M.2 / 240GB Crucial SSD PSU: Rosewill SMG650 CPU Cooler: TH360 ARGB Snow Edition AIO Case: XPG Starker Case Fans: GIM KB-23 ARGB fans",
      "You definitely got the parts right for the best value out of a current mid range gaming rig. Good job!",
      "Beautiful build! I would be weary of the Thermaltake Aio though. They are known for super early failure. Unless they fixed their idiocy..",
      "From what I‚Äôve researched before buying it seems they have improved. Time will tell but so far I‚Äôm very impressed with how it performs. \n\nWith an overclock applied of 4.75GHz running intel burn test at its max the hottest it got was 83.3 degrees. Hopefully the AIO doesn‚Äôt let me down.",
      "Yeah initial performance wasn't their issue. It was the fact that they had multiple types of metals which caused galvanic corrosion and blockage. So yeah time will tell. Gl!",
      "That battle station will become dusty station after 3 months. Do not put on the floor directly.",
      "Paid $599 CAD",
      "If you learn to clean your space daily you won‚Äôt have that issue. Not to mention my place is air purified so not a whole lot of dust to begin with üòÇ",
      "Congrats on the upgrade, friend.",
      "beautiful build, i really liked my white build but you made this absolutely stunning. one of my favorite pc‚Äôs i‚Äôve seen by far.",
      "Is this case any dustproof? Do your floor absorb vibrations? These two questions keeps me from my pc sitting on the floor",
      "This mostly applies to carpet. I've had my rig on my floor ever since I built it over a year ago and it has barely built up any dust inside it. I also clean my room regularly as well.",
      "Don't over think it, just clean your room regularly and you won't have issues with dust",
      "2 counter points. Firstly, it won't fit flipped even if he wanted too. Secondly, the top of the loop is not the cpu block it's the radiator. Still not ideal of course as it still interferes with the flow but really it's not a big deal. Best way would be to top mount, assuming it can fit.",
      "Still with my old trustee FX 8370e at 4.6 ghz and my rx470 waiting for the prices to go down xD",
      "I would mount the radiator on top, so the pump\nis on a lower level as the radiator.\ntwo benefits: the air in the system stays in the radiator, so the pump will be less ‚Äûloud‚Äú, and you have more cooling capacity.",
      "Under full load the GPU struggles to get over 60 degrees",
      "Asus dual is a very good gpu, the cooler is over build.\n\nSame apply for gigabyte windforce.\n\nI can't comment on other aib.",
      "Parts are being sold on EBay",
      "I did! I must have forgot to put in my list of the new build. My bad, it‚Äôs in there though"
    ]
  },
  {
    "brand": "amd",
    "generation": "6000",
    "tier": "low",
    "matched_keywords": [
      "6500xt"
    ],
    "title": "As a casual tech enthusiast, the 6500xt launch has been absolutely fascinating",
    "selftext": "I've learned so much about gpu design from this launch!\n\n* The complicated relationship between memory bandwidth and onboard memory.  How do memory clocks and ram influence things?\n\n* The interaction between pci lanes and pci version.\n\n* The design differences between desktop and laptop silicon.  \n\n* How a tiny chip can boost super high and still sip power.  It made me think about the cost-efficiency tradeoff between that and a slab of silicon.  \n\n* That laptop chips don't tend to have as much pci bandwidth as desktops, or something.\n\n* How laptop silicon leverages features from a laptop APU.  \n\n* That game performance can be significantly impacted by exactly how/where they pull assets from memory.\n\nThe techtubers are roasting it, and i'm eating it up because it reveals so many interesting things i didn't realize i didn't know.  It's a weird gpu and it's fascinating.\n\nSo thanks amd, i guess.  Idk about the card, but the release has been awesome.",
    "comments": [
      "Great to see you've taken the glass half full side. :)\n\n> How a tiny chip can boost super high and still sip power.\n\nAlthough interesting, I think it's worth pointing out that a larger chip running at lower clocks can take less power for the same performance than a small chip running at higher clocks.",
      "Also interesting how the HD 7730 had video encoding in 2013, and that was a 60 dollar card. Meanwhile a 2021 GPU doesn't have encoding or decoding.",
      "I think the problem with this comment is that you didn't mention how larger chips have a higher defective to functional dies ratio per wafer than smaller chips, rendering them more expensive, also you failed to mention that running this chip ant high power could potentially reduce its lifespan as it was made to be efficient at lower voltages and clocks, pushing it this high certainly requires relatively high voltages than what it was designed for, which could lead to chip degradation and failure. Given all that I'd say that it seldom balances out, as a larger die with more cores would give the same performance at a lower voltage compared to this laptop die which is being pushed beyond its efficiency sweet spot. Now while higher voltage doesn't always mean lesser lifespan, it does usually mean less power consumed, which is always nice, if we assume that both dies would pull the same amount of current to achieve their targeted performance.",
      "Many of the techtubers are roasting it because they understand what is *possible* with current technology but seem to have little idea what current market conditions will actually *allow*.\n\nLinus put it well during a recent budget PC build using the 6500XT (the first budget PC build using new parts they've been able to do in a long while). He said \"it only adds a small amount to a total system build but offers 2x+ performance over integrated graphics\". It's a crap GPU but from that standpoint it is filling an important market segment.\n\nBrad Chacos at PC World also [has a handle on the situation](https://www.pcworld.com/article/606950/what-the-internet-got-wrong-about-amds-controversial-radeon-rx-6500-xt.html).\n\nSome are complaining that it's not as compelling as $200 GPUs of the past, which is true. It is horribly crippled. But it is crucial to remember that every single component on the card is in short supply or overpriced, even the copper used in the PCB traces is up substantially. Shipping is up substantially. Inflation is up. The design costs for a 6nm part are massive. TSMC has also raised their prices. \n\nI cannot see how it could cost any less.\n\nThe best price NVIDIA can do is $250 on their RTX3050. That is less compromised but it's also more expensive. And we'll have to see in time how availability and markups work out.",
      "Finally a post that sees reality for what it is, and has a purpose to exist",
      "To clarify, the 6500XT does have video decoding, they just removed the AV1 codex decoder which none of the older cards (RTX 20X0, Radeon 5X00 and older) had anyways.",
      "AKA, analyzing and discussing technology rather than simply criticizing even if it is justified. At a certain point, it is beating a dead horse even if the object in question indeed is horse poo.",
      "i still have a 380x and i cannot find 6500xt near its msrp price in Greece .... lowest is 399 euros from the official distributor in the country \"plaisio\"\n\nyes i am willing to give 200 for this \"low end\" card.",
      "Intel literally sells $40 12th gen Celeron CPUs with Xe IGPs that do encoding and have quicksync and can do 4 video outputs (if the motherboard has the connectors). \n\nObviously the performance is not even remotely the same, but it's also a $40 CPU with an IGP that has basic features the 6500xt doesn't.\n\nNo excuse for AMD to launch such a shitty gimped mobile GPU on desktop.",
      "In a laptop the accelerated video encode would be handled by the APU.  Navi 24 was meant for laptop, that‚Äôs why they skipped video encoding.",
      "Um this is from March 2021, we‚Äôre now in January 2022. Hardly recent, nothing wrong with admitting you‚Äôre at fault when called out instead of doubling down and challenging.\n\nEdit: for anyone curious before the user deleted they cited an article about lack of water in Taiwan from March 2021 over a local‚Äôs perspective on the improved situation, saying even though you may live somewhere it doesn‚Äôt make you an expert.",
      "Always thought it was super interesting how a 3070 mobile and 3080 mobile could use the same power but the 3080 would be faster. Or a 3070 could be faster if it had a higher power budget. \n\nSide note, but this finally clicked for me how Apple was able to push performance (per watt) on their M1 Max by making a HUGE chip on a very small node and optimizing for efficiency. 5900HX has 10 Billion transistors and a 3080 mobile has 17 Billion. M1 Max has 57 Billion, or double those two combined. They must have clocked that thing so far down the efficiency curve, and when they needed more performance they made the chip bigger rather than increasing clock apeeds. \n\nEdit: spelling and missed a word.",
      "Water is not becoming a problem in Taiwan. There was a dry spell with less than normal rainfall a while ago, but not any more. \n\nSource: I live in Taiwan.",
      "I agree, there is way too much whining for a thing most people dont even use, or did every gamer become a streamer in the past years?\n\nEdit: to add to this, im not saying this card is good, but just pointing out that people just like to whine for the sake of it.",
      "Taiwan semiconductor manufacturing company puts their fabs in Taiwan...",
      "Ya, that was under drought conditions. Those restrictions were lifted when the rains returned.",
      "Nice to see someone being realistic about this. Where I live 6500XT has managed to fill a huge gap in the GPU market. The only \"budget\" options that one can actually buy are 1050Ti for 230‚Ç¨, 1650 for 270‚Ç¨, 6500XT for 370‚Ç¨ and 1660S for 530‚Ç¨. 6500XT sits right between 1650 and 1660S in terms of both price and performance, so I don't really understand the outrage.\n\n3050 is going be \"better\", but I'm also expecting it to be priced above 500‚Ç¨ here. Assuming that it's even in stock.\n\nOf course I wouldn't buy a GPU at the moment, but if someone absolutely needs a GPU right now, 6500XT is not a bad option.",
      "Supported Rendering Format:\nHDMI‚Ñ¢ 4K Support Yes,\n4K H264 Decode Yes,\n4K H264 Encode No,\nH265/HEVC Decode Yes,\nH265/HEVC Encode No,\nAV1 Decode No\n\nIts a efficient gpu but coming with only 4GB VRAM and the poor performance over older PCIex Gen... just no, its not built for todays gaming \n\nI'd rather have a rx590 or oc a rx580 with a decent cooling solution like a sapphire nitro",
      "This is kinda what i was talking about with the OP.  It's not an expensive thing at all, but it's conspicuously missing.  That's interesting!  We'd never see these stupid compromises in a normal market.",
      "More expensive process, more complex encoding...\n\nAnyway, NVIDIA led the way with the GeForce 1030 and its derivatives (MX mobile GPUs). They were extremely successful, which suggested to AMD that an entry level GPU doesn't need encoding.\n\nI think that the fact that Navi 24 ended up as a $200 desktop GPU wasn't part of the original design."
    ]
  },
  {
    "brand": "amd",
    "generation": "6000",
    "tier": "low",
    "matched_keywords": [
      "6600"
    ],
    "title": "AMD announces Radeon RX 6600 with 1792 cores and 8GB memory for 329 USD",
    "selftext": "",
    "comments": [
      "Already at 490‚Ç¨ in Portugal lmao",
      "I had a chance to get a 5600xt for 239‚Ç¨ or a 5700 for 270‚Ç¨ back in mid 2020 and i thought to myself nah the performance upgrade isn't worth it over my RX 580. I'l just wait a for the next generation of GPU's.\n\nAnd now here we are a year and a half later and AMD has released another RX 5600XT/5700 GPU that costs more the old ones at MSRP and double that on the scalped market...",
      "AMD in 2016: Get the RX480 for the ultimate 1080p experience for just 200$\n\nAMD 5 years later: Get the RX 6600 for the ultimate 1080p experience for just... 330$\n\nMan GPU price is just crazy these day",
      "Here in France the main online stores are selling between 520 (pulse) and 580 (hellbound), one store even has one listed for 650 (asrock challenger) lol",
      "Same MSRP as the 12GB RTX 3060. It better end up being faster or else it'll be down on memory, speed and raytracing. At this rate we really are going to get another $200 card with RX 580 performance for the 4th time...",
      "Portugal is amazing, we have 1st world prices on everything and 2nd world wages",
      "they sell used 5700xt here for 800$. yep. used.",
      "\"$330\" ü§£ü§£ü§£ü§£ü§£ü§£ü§£ü§£",
      "The 6600 XT was cheaper at 490‚Ç¨ at launch lmao",
      "Bought my 6800XT and sold my Nitro+ 5700XT on eBay. Auction went up to $1150. I set the price floor at $300 which I‚Äôd have been happy to get and it kept climbing. I don‚Äôt feel bad about it, I didn‚Äôt start off asking for $1000+ like a lot of eBay listings.",
      "Those RX 480's used to be $110-140 for a long time. RX 470/570 new were even under $100 with rebates.",
      "The only thing the RX 6600 beats the RTX 3060 on is power consumption. That's literally it.",
      "More than that. I sold mine for $1150",
      "Every single model at microcenter is $450+. Some even $500.\n\nNot even worth it to consider at that point. Terrible card and terrible value",
      "If this thing is a $500 card, I wonder how much longer I can afford to be a pc gamer.",
      "Laughs in India, worse than 1st world prices with taxes and 3rd world wages.",
      "> RX 580 performance for the 4th time...\n\nRX 480 performance for the 5th time... *",
      "Crazy idea: a gpu that doesn‚Äôt cost 300+ and maybe doesn‚Äôt draw 3-digit watts\n\nThere‚Äôs a reason the 750Ti sold so well. Ffs give us a sub 200$ card",
      "its the same price as the 6600 xt was at launch, these cards are a joke in terms of value.",
      ">  we really are going to get another $200 card with RX 580 performance for the 4th time...\n\nWell yeah, we can't just give the poors a luxury product at a fair price. We have to milk them dry.\n\nSUPPLY AND DEMAND, BABBBBYYYYY\n\nGOTTA PUMP THOSE NUMBERS UP."
    ]
  },
  {
    "brand": "amd",
    "generation": "6000",
    "tier": "low",
    "matched_keywords": [
      "rx6600"
    ],
    "title": "XFX RX6600 arrived today - I am so happy",
    "selftext": "",
    "comments": [
      "A year ago I wanted to build my first PC - right during the GPU crisis. So I build a system with a Ryzen 5600G as a stopgap solution. An honestly the AMD integrated graphics served me extremely well. But as GPU prices are dropping in Germany I pulled the trigger on a 6600 for 277‚Ç¨ (Mindfactory). And this thing - even though it is mid-tier - is a beast. It pulls FPS close to my friends 1080ti.",
      "Perception on this card has changed a lot. It was poo pooed on launch but now that crypto has crashed it's being praised as the best overall value for this gen.",
      "Yeah I agree with you. I think it‚Äôs 2 factors: The MSRP was ever so slightly too high (330, should have been 299) and there was a general negative vibe in the reviewer community at that time",
      "I just got a RX6600 too a few days ago (same XFX model).\n\nI have a Ryzen 5 2400G and it bottlenecks heavily that poor RX6600 because of its poor PCIe controller... I'll need to upgrade that too :(",
      "We should never forget how hyped the 3060 got by reviewers while being actually shit woth no improvement over last Gen entry level cards.",
      "Here is the [RX6600XT PCIe3 vs PCI4](https://www.youtube.com/watch?v=OXWK1WlqoBU), the only game with more than a frame difference was Forza at about +10%, this is also the model above his GPU.\n\nEven on the [6900XT](https://www.youtube.com/watch?v=jthy_hYJn5k) it's next to nothing, I wouldn't buy any new hardware just for PCIe4 at the RX6600 level of GPU. The difference may improve more as Resizable Bar support improves, but even for now a good PCIe3 NVMe isn't much different for increased frames.\n\nPCIe Gen4 is being implemented now for increased storage speed, GPU's weren't at a bottleneck yet on PCIe3. Its only been an issue with newer x4 lane cards like the RX6400, which was more AMD using PCIe4's double the bandwidth to get away with releasing an x4 card.",
      "And let's not forget the 3050 hype train and the positive reviews on day 1 when there were still no stock in stores and therefore no pricing.\n\nA day later no reviewer bothered to revisit their conclusions based on the new pricing which was almost 2x the MSRP in some cases.",
      "I have an rx 6600 too. Insane GPU, have some fun with it man!",
      "its just because paying 5-600 for this was ludicrous. but at a sub 300 price point its seriously amazing. and it has lots of haters that speak many lies about it.   \n\n\njust max out the power limit for EZ maxed out 100+fps 1080p gaming xD",
      "Nice",
      "> Perception on this card has changed a lot. \n\nThat's because reviewers really love to give Nvidia the benefit of the doubt. rx6600 had a realistic MSRP for the market conditions at the time, while Nvidia used fake MSRPs which you couldn't get the competing cards for.\n\nAnd all the reviewers sided with Nvidia and praised their fake MSRP prices while trashing AMD's more realistic prices.\n\nrx6600 didn't change, it was always an excellent card, even when the prices were inflated you couldn't buy anything better for the price.",
      "It‚Äôs a mixed bag. I read a lot of reviews. Apparently, some of their 3-fan designs still suck - but the budget 2 fan design has good reviews for simplicity and thermal performance.",
      "Yeah I think 3050 reviews were significantly more deceptive as 3060 came out in earlier in the mining craze",
      "My friend has a 6600, really good value card !",
      "I picked up a sapphire pulse 6600 on sale for 260ish usd. I‚Äôve been using it in my low wattage machine for a little while now and I‚Äôm astounded by how beefy that little card is. I‚Äôve got it running faster than my old rx5700 and it uses around 120 watts after a little tinkering. Awesome card, great choice! My overkill primary build is almost exclusively a work machine now.\n\nEdit: The card OP is using is available for 259usd on BestBuy.",
      "It seems like that GPU is very popular, I was actually gonna purchase that today.",
      "The case is a Kolink International Citadel Mesh Micro-ATX. The tower cooler is a bequiet! Dark Rock 4 Slim",
      "I hear memory OCing helps alleviate the issue a bit. I recently picked up an RX 6600 as well (Powercolor Hellhound) and am using it with a R5 1600AF on a B450 board, so PCIe 3, and it only seems to bottleneck as far as I‚Äôm aware when the memory gets full. \n\nI have no PCIe 4 systems to test on though and any PCIe 4 system would probably have a beefier CPU so it wouldn‚Äôt be an accurate test. \n\nI seem to pretty regularly fill up the memory running things at 4K High, but I‚Äôm surprised by how well the card handles it. 40-60fps depending on the game, and with FSR/RSR scaling on my 32‚Äù monitor, scaling up from 1440p looks pretty great and will get me a locked 60 in most titles",
      "Is xfx good now? Because the rx4-500 series was so fucked up, and since then I didn't dare to buy xfx.",
      "Can you tell the name of the Case and CPU heatsink models?"
    ]
  },
  {
    "brand": "amd",
    "generation": "6000",
    "tier": "low",
    "matched_keywords": [
      "6400",
      "6500xt"
    ],
    "title": "AMD Radeon RX 6500XT and RX 6400 entry-level RDNA2 cards allegedly listed with 4GB GDDR6 memory - VideoCardz.com",
    "selftext": "",
    "comments": [
      "This is $99-$119 class GPU. Interesting to see how greedy AMD will be this time around",
      "Come on Low profile.",
      "As long as the 6400 is better than a 1050TI I can see this working, a lot of people want to upgrade from the 1030s they were stuck with for 2 years or so since everything went to shit (either they build their first pc and thought that would be a temp solution or their main GPU died).\n\nThat is as long as AMD doesn't decide to call this a \"consumer friendly\" $350 card or whatever.",
      "Calling 229 for 6500XT and 149 for 6400",
      ">Calling 229 for 6500XT\n\nFinally, a rx480 replacement. /s",
      "279 for 6500XT  \n199 for 6400   \n\n\nI doubt there will ever be sub $149 AMD card ever again as it would most likely be in an APU form onwards.",
      "The only thing that could make these cards interesting is having no power connector...",
      "> That is as long as AMD doesn't decide to call this a \"consumer friendly\" $350 card or whatever.\n\nMSRP: $350\n\nCurrent market price: $600\n\nCyber Monday/Black Friday deal: ~~$800~~ ‚ÜòÔ∏è‚ÜòÔ∏è‚ÜòÔ∏è $650",
      "If the 6600 was \"best for 1080\" what will these be? Best for SVGA? 100% better than the Amstrad CPC?\n\nHave we entered the era of \"creative uses of sand\"?",
      "Great, another 580 that will likely not beat again! Good job AMD! I love the stagnation! What a shitshow of a generation for both parties.",
      "Low profile and single slot are two separate things.",
      "The 580 will likely stomp this card.",
      "\"Best for entry-level-esports-games-since-we-stopped-manufacturing-all-other-budget-options\"",
      "At this point my performance per dollar recommendation is early GCN cards.  My old 270X is still alive and kicking in my friend's machine, and aside from only having 2 gigs of vram it otherwise performs in the 1050ti bracket.  \n\n\nA quick scroll through auctions ending soon on ebay suggests $100-150 will get you into 4 gig 380's and 290's.  Not the most energy-efficient by any means, but beats the hell out of an APU or paying $300 for a 1050ti.",
      "Best for someone who just wants a GPU to drive more displays.",
      "Finally oh my god, i buy my RX570 2018 for 110 and since then there no GPU taht match RX570 Price performance",
      "Making a weak GPU is fine as long as the price is reasonable.",
      "Welcome to the new normal :(",
      "RX6400 is most likely made just for that.",
      "Sounds too low for the 6400."
    ]
  },
  {
    "brand": "amd",
    "generation": "6000",
    "tier": "low",
    "matched_keywords": [
      "6600"
    ],
    "title": "[HUB] 2016 Flagship vs. 2022 Budget GPU, GeForce GTX 1080 vs. Radeon RX 6600",
    "selftext": "",
    "comments": [
      "Pascal is just too expensive on the used market to be a worthy consideration these days.\n\nFor the EU market. A second hand 1080 will set you back 250-350‚Ç¨ depending on the model. And a new 6600 will set you back around 280-350‚Ç¨ again depending on the model.\n\nAnd thats not even mentioning the lack of any real driver optimization these days for Pascal.",
      "6600 20% faster at 1080p, 13% faster at 1440p on the average of games he tested.\n\nSome games had the 1080 as being equal to the 6600, some games were 70% faster.",
      "...Pascal was released 6 years ago??",
      "6 years to save $330 and gain 20% more performance.",
      "Yes, released on may 2016, bought my GTX 1070 on September 2016. Still a nice performer at 1080p.",
      "TL/DW?",
      "Just shows how little GPUs have progressed. It is no wonder that even today the top 3 GPUs on Steam hardware survey are still non 2000/3000 GPUs. The rtx tax and lack of meaningful raster performance improvement per dollar means there is little reason to upgrade for most people.",
      "The 1080 launched at $700. $600 AIB models launched later, and it dropped to $500 when the 1080 Ti launched.",
      "Damn, here in the US I even see 1080ti cards go for like $250 or even less sometimes (got mine for $300 at the beginning of June)",
      "I saw windforce 1080 (I think it was even Ti version, the one with 3 fans) for 225‚Ç¨.",
      "Just to put this in prospective Nvidia didn't have anything worth upgrading from Pascal for around 4 years and part of it was Turing not delivering what users wanted.",
      "What impresses me the most is in the 51 games tested, there wasn't a single case where the RX6600 was 5% or more slower than the 1080 in 1080p resolution.\n\nI think that is evidence to say the RX6600 is a very solid release by AMD. Ofcourse at 1440p you can start to see some weaknesses but AMD has advertized this card as a 1080p thing from the very beginning, so I don't fault them for that. Yes, for 250-300 bucks this is the budget option that Nvidia doesn't have an answer to.",
      "At 1080p, the 6600 almost universally beats out the 1080 by about 25%.\n\nHowever, about 1/4 of games tested at 1440p actually ran the same or slower using the 6600.  The other 3/4 of the games are about 20% faster, on average.",
      "AIB models launched like 2 weeks after FE. I think it's correct to say the 1080 launched at $600 where you could get two weeks early access for $100 more. It was just Nvidia trying to make an extra buck.",
      "\"Budget\".",
      "You talking about the 1060 that went for $250 at least?\n\nI also got a $300 deal for a 1080 in 2018. Does that represent the general market or just the specific card from that specific seller in those specific circumstances?\n\nIt's a rhetorical question if that wasn't obvious.",
      "I can find 1080 for 200‚Ç¨ or less on a dedicated forum (where people are less likely to overprice)",
      "https://youtu.be/djeL6qUTDTo?t=655",
      "The 6600 in my country is priced very much with in what a 1060 6GB was back in its day, so include inflation and the 6600 is pretty damn good.",
      "It was. The 1080 Ti launched in 2017, about 10 months(!) after the 1080."
    ]
  },
  {
    "brand": "amd",
    "generation": "6000",
    "tier": "low",
    "matched_keywords": [
      "6600"
    ],
    "title": "JUST GOT MY RX 6600",
    "selftext": "",
    "comments": [
      "Solid choice! May It serve you long and well",
      "Welcome to the club, my guy <3",
      "1.5 years ago I bought a 6600 XT, serve well. I don't wanna upgrade it yet, still enough for 1080p gaming. \n\nEnjoy mate. :)",
      "heck, i use my 6600XT for 1440p and i'm doing just fine too.",
      "I got my rx 6600 2 days ago. But my psu doesn't have the power connectors to connect to the gpu, so I had to order a new psu. I'm still waiting for it to arrive üôÉ",
      "Yeah, for upcoming AAA games it's probably not gonna age well, since they're 50% more demanding for just like 10% better graphics.\n\nBut anyway, i'm just fine with playing on mixed/optimized settings on my games, so it works well for me. Besides, the amount of modern games that i can run on ultra/high with a locked 75fps is impressive.\n\nBut in the end of the day, AAA games just aren't my thing really, i run a few demanding games and emulators here and there (which run pretty well even on 1440p) but lately i've just been appreciating some indie and older games. I live in a third world country and i don't feel like wasting three minimum wages on a GPU that gives me some overrated ray tracing on mediocre games.",
      "Adrenaline allows +- %20 pwr. Given that the default is 100, I would turn it up to 120.\n\nI left fans on auto and kept zero rpm enabled. In Windows the card will remain cool and the fans stop entirely below 45c. General temp is 30-35C.\n\nWorks well. I have the xfx.\n\nStill on 23.11.*",
      "CONGRATS",
      "132W card with 3 fans =  overclocking potential  üòã",
      "6600's power efficiency is pretty crazy. At stock it's like ~100 watts for pretty solid performance.",
      "IT'S GREAT",
      "RT right now isn't really worth the performance hit in most games, even on RTX GPUs. I think the only real issue with the 6600 and the XT/6650 are that they only have 8gb VRAM. It should be fine for 1080p right now but would probably kill it's longevity.",
      "Undervolt until it either loses stability or performance goes down. That's the sweet spot. Amd uses the same voltage for each model of gpu to ensure they can reach the guaranteed performance. However, that is usually more than needed, and more voltage than necessary will increase temps. Undervolting, if you have headroom, will lower temps and allow you to maintain higher boosts.",
      "GPU looks good, enjoy!",
      "Congrats!!!! What a great card.",
      "In games it doesn't even draw that much power",
      "It's the current \"RX 580 / GTX 1060\", best price/performance ratio and you do not have to deal with high power use, temps, noise (and if you do, just undervolt+overclock lol).\nGood choice!",
      "Congrats. It is the outstanding bang-for-the-buck card of the last couple of years.",
      "ye it shares the same cooler as the 6700xt so 100w+ of heat headroom",
      "I Don't know overclocking sadly"
    ]
  },
  {
    "brand": "amd",
    "generation": "6000",
    "tier": "low",
    "matched_keywords": [
      "6500xt"
    ],
    "title": "Happy with my 6500XT so far",
    "selftext": "Bought it for my i3 12100 build for a bit over msrp and it is delivering good performance @ 1080p. Compared to the UHD730 that I was using, I am getting roughly 7-10x more frames. \n\nFor the price I paid, the other options would be 5 year old GPUs that offer the same or lower performance‚Ä¶\n\nI understand the frustration with the product and its limitations, but perhaps the hate towards the 6500XT is a bit overblown. For me, it definitely has a reason to exist in the current market conditions.",
    "comments": [
      "The i3 12100 is probably the most realistic/best CPU for this GPU since it has PCI-E 4 but is still relatively low budget. What motherboard do you have?",
      "So you built this machine to do light gaming  and basic computing tasks that your BEAST computer can already do. The logic makes no sense but more power to you.",
      "Kinda sad that the (market)price and performance is comparable to the R9 290X from like 2013/2014. But thats the GPU market today. Everything is inflated.",
      "Asrock B660-HDV. Got it for 110 Euros. My goal for this system was to get the cheapest new parts possible for light gaming and basic computing needs. I have another build with a 3080Ti for more hardcore stuff.",
      "Unless of course this second computer is in a different location?",
      "It's quite simple, it's an entry card at non entry price. Then again miners have been f****g the whole planet for over 2 years.",
      "I'd prefer the warranty over extra performance in some games, especially on a 6500xt budget. If a used card dies and you don't have the cash to replace it you're kinda stuffed",
      "Tbh if I was building a new budget system from scratch a 12100 and 6500xt is probably the way I'd go",
      "Without HEVC encode, I wouldn't recommend the 6500xt for media stations",
      "The hate isnt overblown but there will almost always be someone who believes they got their monies worth. Your previous card and the market the way it is ya good option for a bump without going to the used market. But the same time you mention 5 year old cards with similar performance. Alot of the hate stems from those 5 year old cards having more features and capabilities than the 6500xt and some were cheaper when they launched. The 6500xt is almost a regression. Not trying to put you down or anything cus for you was a good option, just laying some facts.",
      "maybe its for a family member?",
      "It's not about inflation here. Supply-side bottlenecks and crypto scum are bigger factors.",
      "R9 290X TDP is 290 watts, RX 6500 XT TDP is 107 watts.",
      "Life in general is inflated.",
      "OP has a 12100 with UHD graphics. Use Quicksync?\nThis might actually be one of the only system configs that makes sense with this card.",
      "What people cant have Media stations now?",
      "GPU prices from *entry* to high end makes little sense these days. Entry/mid range cards cost as much as higher end cards did a few years back.",
      "People who say they‚Äôd rather go used are probably the ones who got said cards",
      "entry level is APU level now.  There is no entry-level GPU anymore.",
      "Should I upgrade? I have a GTX770 and I don‚Äôt think it‚Äôll last me another year. 6500xt doesn‚Äôt sound too bad for $200 bucks. That should get me by hopefully until market fixes itself.\n\nEdit: I just ordered the 6500xt. I thank this sub for all the good information."
    ]
  },
  {
    "brand": "amd",
    "generation": "6000",
    "tier": "low",
    "matched_keywords": [
      "6400"
    ],
    "title": "AMD Radeon RX 6400 Benchmarks: 30% Slower Than the RX 6500 XT",
    "selftext": "",
    "comments": [
      "The only explanation is this: they reached too far with technology. We have to go back to the old ways before it's too late.",
      "do we really need any more gpus in the same perf bracket as gtx 780ti/970/290/290x/rx470?",
      "It‚Äôs literally an OEM only product that is like gt1030 tier. Why wouldn‚Äôt it have low performance, when it‚Äôs literally a low performance and low price product?",
      "If they're priced accordingly, sure.",
      "like 50‚Ç¨?",
      "Because the \"low price\" is terrible compared to even years-old products now.",
      "I understand the strong feelings behind the 500xt and now 400 but these gpus help anchor prices in the low end which does affect all gpu prices. This can only help.",
      "Yes.",
      "What's up with the whining?  This is card (53W) offers GTX 970 (160W) performance for a third of the power!!!  Yeah, pricing's bound to be bad, but pricing is bad everywhere.",
      "This.\n\nIIRC, people were complaining that they just wanted something, ANYTHING to finish their builds. Enter the 6500XT, and the 6400.\n\nWould anyone who wanted \"The Ultimate 1080p Battlestation\" go for these cards? No, obviously not. \n\nBut that's because they're not for the Ultimate 1080p Battlestation, they're for getting your Ryzen rig out of the door and into your hot little hands, for a price that is in the general ball-park of halfway-sensible.",
      "Lmao Nvidia's selling 1030's for 3-4x that....\n\nI saw 4gb 580's like mine going for like \\~60$ before the launch of rtx 3000 series while the leaks were hot like pancakes.\n\nOh how the mighty have fallen, someone bought a 4 gig 580 for 500 euro on one of the local re-sale sites.....\n\nMost of them are selling for \\~350, but that's still ***what I paid for it almost 4 years ago***.",
      "It's probably great for people who are using low-end prebuilts which only have \\~250-watt PSUs.",
      "3 months from now AMD announces the RX 6300 XT which somehow has negative performance and actually takes graphics away  from your games.",
      "I would think \"hey, at least it may have more VRAM\", but\n\n* The 6400 has 4GB. (It is more than the 3GB of the 780Ti)\n* The GTX 970 has \"4\"GB as well (3.5GB fast vs 0.5GB slow)\n* R9 290 and 290X had 4GB as well, but Sapphire did their things in the past and some 290X 8GB exist.\n* R9 390 has 8 GB VRAM.\n* RX 470 has 8 GB VRAM model as well.\n\nAnd all of the above have hardware encoders (R9 390 and before using NimeZ drivers), and you can kinda use high res textures at 1080p on the 290X 8GB, 390 and 470 8GB.\n\nSo the real advantage for the 6400 I guess it would be power consumption (53W) vs 150W (970), 120W (RX 470), and the really heating rooms 300W+ (290/290X/390)",
      "Why not just supply an APU at that point. Be waaay cheaper for low performance.",
      "While true, some businesses/schools need entry-level cards for hooking up additional displays to already-existing machines. They eat this stuff up, as it‚Äôs cheaper than a Quadro and gets the job done. For a completely new build though, would definitely be better to go with an APU in terms of cost and footprint.",
      "But its a raytraced 2 fps!",
      "Also these are 6nm, so they aren't taking production capacity from 7nm Navi2 products.\n\nEach 6400/6500 sold is one less consumer trying to grab the next product up the chain (freeing up more higher end GPUs for enthusiasts).\n\nSure the price is not optimal, but these GPUs are doing their part in getting the market back to normal.\n\nKeep in mind Best Buy has GT 1030's (in stock) for $115 to $150!",
      "Yeah, and a 6800 is over 2 times its MSRP so what's your point? Either MSRP is bad, or MSRP is good and literally no one can get it for that",
      "At 2 fps"
    ]
  },
  {
    "brand": "amd",
    "generation": "6000",
    "tier": "low",
    "matched_keywords": [
      "6600xt"
    ],
    "title": "Just got the 6600XT and the Radeon software is saying I'm only using 30-40W while playing Tomb Raider. That can't be right, right?",
    "selftext": "",
    "comments": [
      "1080p 60fps that probably right",
      "GPU utilization at 62% tells the story.  That card is not being pushed.",
      "That‚Äôs probably why, Tomb Raider isn‚Äôt going to stress out a GPU like that too much",
      "Are you capped at 60 fps?",
      "it's also at just 1100 MHz, which means lower power state, and even at that state only 62% of GPU time is used.",
      "This is correct.  Gpu is idling and saving power because it's capping at 60fps. Why frame capping or vsync is good for many games that don't need unlimited fps.",
      "Yeah",
      "That seems to be the consensus. I just switched from a 390 where I'm used to hitting 80c in Tomb Raider. A difference of -30c is baffling to me. Guess I'm not used to all the advances in the new cards. Cheers!",
      "Looks about right , your gpu util is only 60% so not even pushing the card. Plus 6600xt is a low wattage card.",
      "Time to swap back",
      "3 options:\n- Leave as-is, everything is fine\n- Up quality settings to utilize GPU more\n- Get a higher resolution and/or refresh rate monitor to utilize GPU more",
      "Thats one of the uses for vsync",
      "160W TDP doesn‚Äôt mean 160W in games at all times.",
      "We've come a long way that's for sure",
      "Lol no wonder then",
      "It's because the framerate is locked to 60fps, so the card and cpu doesn't need to push more.",
      "Correct me if I‚Äôm wrong, but high clock with low usages is not bad. \n\nHeat depends on load not clock. \n\nLook at CPU‚Äòs. When you overclock your i9 to 5Ghz it‚Äôs not running at 90 Degrees all the time. \n\nAnd the clock is always more stable with low usage. Like you can boot with 5.2 into Windows but Prime is only stable with 5.\n\nI myself cap my FPS to stay in G-Sync range. \nNever had any problems. And GPU Temps are way lower.",
      "Look at the FPS number to see the whole story. OP has vsync on or has manually capped the FPS to 60. Unlock that cap, OP, and your GPU will stretch its legs.",
      "Well that answers your question. If you had the frame rate uncapped, then it would use more power to render more frames.",
      "Tip: 60 is divisible by 120 but not by 144, so if you're going to play at 60 fps you're better off setting that 144hz monitor to 120hz so 60 fps look smooth on it instead if stuttery. Nothing can be done about the resolution though, if it were 2160p you could use Integer Scaling to get 1080p at the same quality of a 1080p monitor, but 1440 isn't an integer number of 1080.\n\nRSR would be perfect for this though, but I doubt the 390 is going to get it. Maybe with modded drivers."
    ]
  },
  {
    "brand": "amd",
    "generation": "6000",
    "tier": "low",
    "matched_keywords": [
      "6600xt"
    ],
    "title": "r/AMD wouldn't let me post here when it was relevant so here it is, my almost sleeper build. 6600xt and 5600x. My first proper build and took me 3 weeks to save up",
    "selftext": "",
    "comments": [
      "i see an optical drive... i like you already.",
      "Lmao thank you",
      "How in the fuck did you get a 6600xt?",
      "Luck really, here we're so used to there being a shortage and Radeon isn't that big of a name so Radeon are 2/3 the price of their Nvidia counterparts",
      "The fact that You're using euros means they won't ship. It's called umart and it's Aussie based. My 6600xt cost $849AUD which is 536.26 euros but if you have a friend in aus it'll be cheaper to buy it here and ship it than but it there",
      "Optical drive master race",
      "No one talked about Obama Delphine. I'm disappointed.",
      "I have one too! It's just not mounted in the front of my case, no bay for it, made a bracket and mounted it inside my case. That means I have to open the side panel to change discs, but it's a hinged glass panel so that's easy enough lol",
      "totally not me who thought that it was a printer üò∂",
      "Awesome case, nice build.\n\nThat Multiscore result seems a bit low for a 5600X, should be in the 11k neighborhood.\n\nWhat cooler you got on?",
      "Sleepers are supposed to look less impressive than they actually are. This build doesn't look less impressive than it actually is: it's a humongous case with RGB, it's just not a mini tower with a glass panel like most other builds you see on here.",
      "Im saving up for a pc my while life and am still not halfway done.",
      "Stock cooler",
      "Jesus, can you link me the shop you got it from? Maybe they ship to my country too. Over here the avg 6600xt is around 700 euros",
      "Damn, too bad. Well Nvidia did say that they expect the shortage to really start clearing up second half of 2022, I'll have to wait for that or maybe rtx 4000 series to come out for a price drop.",
      "Ye, good luck with that man",
      "To be honest, for most of use case scenarios it'll be quite alright.\nBesides, it looks like you've got decent airflow in the case which is also really important, so it should be all good.\nEnjoy your build and rock on.",
      "Trust me, my mates have called it everything from a printer to a microwave man, its honestly the best part about the case is its unique design",
      "Ye, I prolly shouldn't have added how long it took me cuz it sounds like humble bragging without context, the context is it was more hours than I should be legally getting, tax free cuz it's a short stint at an adult rate in construction (pays more on average (",
      "I thought I was the only one in the world still using one.\n\nEssential for doing blu-ray rips."
    ]
  },
  {
    "brand": "amd",
    "generation": "6000",
    "tier": "low",
    "matched_keywords": [
      "6600xt"
    ],
    "title": "6600xt Before and After Liquid Metal. -8c Hot Spot/Junction Temp",
    "selftext": "",
    "comments": [
      "You applied it to your CPU too?",
      "My guess, he let it run for much longer on the first screen. His numbers might not mean much.",
      "This is a good lesson of why we run multiple trials for good data samples",
      "Looks like the cpu in the first image is doing a lot more work than in the second. The graph shows it as does the temp. That‚Äôs quite a bit extra heat in the case in the first image and can definitely affect results. Of course a LM application should see lower temps regardless so nothing to really see here but not really a scientific process conducted here either.",
      "I thought about that too, but it takes literally seconds for your CPU to reach at least 80% of max temp during load, unless you have a very large cooler. He might just have run another program on the second pic.\n\nBut your theory could be correct as well. I'd just expect a higher CPU temp even for shorter benches.",
      "No idea why. Had the same background apps running. Just a spike I'd guess.\n\nEDIT: looking at that chart it looks like it was running something for at least a minute while taking that shot. Honestly don't know. Maybe Windows updates, or something else. But I don't think it effected GPU temps at all. The VRAM load is the same and they are both at 99% GPU load. Either way I'm not removing the LM to retest lol.",
      "You can run LM safely on a GPU if you know how to apply it correctly.\n\nI have ran and still do Thermal Grizzly Condactonout on all my Ryzen CPU's and Gpus, for years now perfectly fine.\n\nObviously it's not for everyone.",
      "I didn't say it took a few seconds to reach peak temp. I said you'll reach at least 80% of peak temp in a few seconds during load. For me it takes literally about 5 seconds to reach 85c on my CPU, it maxes out at 88C no matter how long I push it. It does however downclock about 100MHz after a while and stays that clock forever. But I have a weak cooler with exceptional fans, but they're loud as hell. With a larger cooler and weaker fans it'd take a bit longer to reach peak temperatures. The hotter the cooler/CPU gets the faster it'll disperse heat.\n\nNow I mainly reach 90% of my max temp in seconds due to PBO and a small cooler. But even using an I3 with a Noctua DH-15 will definitely net you 80% of peak temp after 30~ seconds stressing it.",
      "For sure, I ran Liquid metal on my Radeon VII for the whole time I owned it.  It made a big difference, but yeah just be careful.",
      "So, not worth it then?",
      "I don't get why graphics card manufacturers have to cheap out on paste so much. I'd be more than happy to pay another $10 for them to use a quality paste like MX-4 or NT-H1 for temperature reductions.\n\nEdit: 2.1k fan speed?! What did XFX do with the 6600 XT xD.",
      "Fun Fact - Sony uses liquid metal on the PS5.",
      "That's not exactly helping their argument though, since Sony went to a LOT of trouble to ensure it never leaked and wouldn't oxidise either. [link](https://www.reddit.com/r/PS5/comments/j7b732/sony_liquid_metal_degradation_solution/)",
      "There are lots of guides on LM - never use it with aluminum, nickel plated is best but it can work with copper as well in my experience with Thermal Grizzly Condactounaut. As it is not as reactive as some other brands.\n\nFor ex. - I've had it on a Noctua nh-d14 for 1.5years with the same exact temps. (on a Ryzen 2600)\n\nJust apply the correct amount properly. You can also install a small barrier of foam etc. around the cpu if you are paranoid of it leaking out. I never have and it has never 'leaked' for me anywhere.\n\n\nThe least reactive and most stable is Thermal Grizzly Condactonout.\n\n\nThat is all I've been using for last 5 years on all my cpu/gpus. 10/10 would recommend.",
      "I've got that card and 2k RPM doesn't sound bad at all, even considering you can only achieve that kind of fan speed with an overclock. Nice and quiet.",
      "Liquid metal can short circuit components, handle with care.",
      "Probably not. Runs cool enough already. I figured maybe lower temps would cause it to automatically boost higher, but not too a consistently measurable amount from what I can tell.",
      "My friend. The fucking graphs.",
      "It takes a bit of a while to actually hit peak temperatures. Usually takes my gpu and cpu about 20-30 minutes to hit an actual max temperature that's stabilized.\n\nThe first 5 minutes of your benchmarks mean jack shit because the cpu is still cold and going up in temps. It's kind of like putting a glass of cold water with ice in a room that's hot, obviously isn't gonna change much in a couple minutes.",
      "Same thing happens with my 5600x under Dark Rock 4. It hits peak temp ussualy 10sec after starting a MT test and holds that for a long time. It is called temp equilibrium, it's normal behavior. For some ppl it takes much longer because it all depends on what kind of cooler you have and how much air does your case push...\n\nAnyway, i do not recommend using liquid metal unless you (anyone) really knows what you are doing. LM can react with the aluminum in the cooler and you can easily end up with a dead Gpu... IMO, it is better/safer to use a high quality thermal paste like Thermal Grizzly..."
    ]
  },
  {
    "brand": "amd",
    "generation": "6000",
    "tier": "low",
    "matched_keywords": [
      "6600"
    ],
    "title": "[Gamers Nexus] Insultingly Bad Value: AMD RX 6600 $330 GPU Review & Benchmarks (XFX SWFT)",
    "selftext": "",
    "comments": [
      "In Spain this card is 650‚Ç¨ ($750). With its performance, this is a 150-200‚Ç¨ card sold for 650‚Ç¨.",
      "*Laughs in rx 580 golden sample*",
      "They are trying to get us all used with the bumped up prices. It‚Äôs a horrible tactic and very bad for the industry and the consumer",
      "Just like a rebranded 5700 but cost moreüòÖ",
      "Nvidia releases an overpriced product.\n\nAMD: \"hold my beer\"\n\nThe only good thing about it is the power usage, although if u underclock the 3060 it would probably be on par.",
      "Unless we get rid of mining, there is no hope for a fairly priced product. Let's face it.",
      "Ok that price is a little concerning... I paid $330 for a 5600XT (Power Color Red Dragon) in 2020.",
      "Have you looked at recent 5700 prices?\n\nIf you can get the 6600 for 330, it would be close to half the cost of a 5700.",
      "They're saying that \"the new ETH is coming VERY soon\" since 2018 lol",
      "Because it, on the long run, will reduce the upgrade frequency of their customers, reducing their profits. And it will push more people towards consoles, where profits are minimal.",
      "Since miners will buy cards at higher prices, why should AMD or Nvidia give a shit about anything else? It's not like there are dozens of competitors taking away their PC clientele.",
      "I paid 250 for mine at launch. Sold it for enough to buy a 3060 ti. Sold that for enough to get a 3070. Sold that for enough to get a 3080...\nPeople are crazy. \nI wasn't even trying. ü§∑",
      "290 ^choo ^choo ^choo",
      "Remember when 330usd was mid-range with decent performance? Papa Pepperidge remembers",
      "You mean less/same raster perfomance, less VRAM and less features?",
      "This is insulting. AMD hit a new low.",
      "Ya gotta be real about this. They're pricing for the current market and when the market returns to normal we'd be close to the rumored rdna3 navi33\n\nWhy'd amd price it low and let the scalpers and retailers make off with the margins from price gouging? They'd rather price gouge the scalpers themselves lol",
      "My rx 580 8gb runs out of muscle before it runs out of vram 99% of the time.",
      "My 390 died yesterday. However I'm buying a used 1080ti from a work colleague. The current gpu market sucks.",
      "Obviously nobody want to address the elephant in the room but the 5700XT also mines like a child cracked up on Mt Dew playing Minecraft at 2:00am in comparison.  Not a miner here but just figured I would add that to the discussion 5700XT > 6600."
    ]
  },
  {
    "brand": "amd",
    "generation": "6000",
    "tier": "low",
    "matched_keywords": [
      "rx6600"
    ],
    "title": "Amd quick build for a neighbors daughter 5600‚Ä¶. Rx6600 all eBay parts under $600",
    "selftext": "",
    "comments": [
      "5600 6 core processor  rx6000 gpu MSI B550M PRO-VDH WIFI 16 gb of ram t-force 2600‚Ä¶ 256gb NVME 120gb SSD 1TB hard drive 600watt psu case and lighting set up and monitor not bad",
      "it‚Äôll work just fine for a kids gaming rig",
      "Bro spent half the budget on RGB",
      "If possible move that top right exhaust to the back so that it doesn't eject the air before the cooler can take it through the fins\n\nI think I have the same case - is it the ancient Corsair one with the thick side panels",
      "Kids dig rgb",
      "If I was your neighbours daughter I would be happy. Ram can be upgraded down the line... Verry good build for the budget.",
      "Have had both the 5600x and 5600g and never felt that the stock cooler was bad. If you are gaming and nothing else it shouldn‚Äôt be a problem.",
      "It‚Äôs closed lol just tested before cable management",
      "I feel like a 5600 is ‚Äúcheaped out‚Äù. Its the absolute best bang for buck period, great choice imo",
      "should have cheaped out on the ram and gotten a closed case",
      "I actually ordered an extra fan for the rear it‚Äôs just not here yet‚Ä¶. Fan kit I got used for $14 with led strips ‚Ä¶. 6.99 for one extra fanüôÑ oh well",
      "They were ripped out of laptops getting tossed",
      "2600MT/s for ryzen?",
      "Power color fighter",
      "only change would be add a cooler, otherwise this looks amazing great work",
      "The stock cooler sucks.\n\nSource: 5600X, 5600G owner.",
      "sorry im just stupid and didnt notice",
      "> hdr\n\nHigh Dynamic Range, [this will explain it better than I can at 8AM with no coffee.](https://en.wikipedia.org/wiki/High_dynamic_range#Display)",
      "Of course he did, that's the most important part!",
      "hdr???"
    ]
  },
  {
    "brand": "amd",
    "generation": "6000",
    "tier": "low",
    "matched_keywords": [
      "6400",
      "6500xt"
    ],
    "title": "AMD Radeon RX 6500XT coming mid-January 2022, RX 6400 in March - VideoCardz.com",
    "selftext": "",
    "comments": [
      "Im waiting for a 3010 that‚Äôs just a rebranded 610. Sold for 299$",
      "on Nvidia side: RTX 3050ti 6/12GB, RTX 3050 8GB",
      "Yeah but with 12GB of VRAM",
      "It's a mechanical hard drive.",
      "Plot twist: it's ddr2",
      "Eh, the whole RNDA2 lineup apart from the 6800xt is uncompetitvely priced against Nvidia this generation\n\nI say this as a 6800 and now 3070ti owner, RDNA2 is uncompetitvely priced at MSRP (it's price matched on rasterisation performance), and in the actual retail market they're marked up higher than Nvidia with the exception of the 6600/6600xt\n\nAt MSRP, the cards to get are the 3060ti/3070/6800xt/3080\n\nThe 6700xt/3070ti/6800 are not ideal but not actually that and at MSRP, just worse compared to the good ones \n\nAnd I do want to stress, the MSRP of the above cards aren't even that good, they just look good up against Turing, which was a notoriously shit value generation\n\nEdit - Just thought I'd add to this, in my experience for anyone looking for an MSRP card, look for the 3070ti FE, it and the 3080ti FE are the easiest cards to get at MSRP (I do not recommend the 3080ti FE), admittedly still not easy",
      "In normal times, these would be great $100-150 options for new builders.",
      "Good talk",
      "It blows my mind that this generation going to be over a year and a half old, at least, before we get the entire product stack launched from either team. \n\nWhat a cursed gen, Jesus...",
      "I wouldn't worry about mining.  There are alt coins and actually there are some miners that allow you to mine ETH with 4GB cards. It is Ethash4G.  However, the 6500XT will be a $1/day at best.  Even if an OEM came out with an 8GB model, it is gonna do half what a 6600XT can do, which will barely put it over $1/day atm mining ETH. \n\nWhat is gonna happen is these will be in a combination of short supply, OEM markup, and the AMD branded cards will be scalped to OEM markup prices.  \n\nThe only way prices won't get inflated is if AMD can crank out so much stock that it would be impossible for any retailer to sell out. People using bots will find they ordered hundreds if not thousands of them causing these people to freak out and cancel all their orders.  No line would be long enough to sell out at brick and mortar even if the MSRP for it's performance is actually a really good deal.",
      "Care to elaborate?",
      "> Well AMD will get what they deserve with selling 128/64bit stagnation overpriced cards.\n\nBy \"what they deserve\" do you mean \"sell every piece of product they could put on the shelves?\". Because that's what would happen. \n\nPeople talk here like AMD has to be competitive with Nvidia in this generation to sell cards.",
      "Tape drive.",
      "I can't believe people still think this. It was supposed to happen this month, and it had already been pushed back multiple times.",
      "Who cares what AMD sets the MSRP at though?\n\nMSRP's don't matter at all for the consumer within a month after launch during normal times, and don't matter at all at the moment.\n\nit seems people are under the impression that MSRP's are set in stone or something. Actual prices will change depending on market forces. it doesn't matter what AMD sets the MSRP too, they'll end up at he price the market is willing to pay anyway. \n\nAll that chances with a higher MSRP is more money for AMD instead of scalpers and exploitive retailers.",
      "Well AMD will get what they deserve with selling 128/64bit stagnation overpriced cards.\n\nI think most consumers will remember all this behaviour from AMD since MOST AMD users always was Price to Perfomance users.\n\nAMD shareholders and fanboys are welcome to downvote me.",
      "Yet not everyone lives in the US, near Microcenter or stays 24/7 to snap something.\n\nIf I went last year on Newegg/Amazon at 2 PM in a Thursday, how many MSRP cards could I get?",
      "Stone tablet.",
      "Yeah, if only I could believe whatever MSRP they list is actually going to be what the price is. Instead of a massively inflated version of it.",
      "Cave painting."
    ]
  },
  {
    "brand": "amd",
    "generation": "6000",
    "tier": "low",
    "matched_keywords": [
      "6400"
    ],
    "title": "AMD launches Radeon RX 6400 low-power RDNA2 graphics card at 159 USD - VideoCardz.com",
    "selftext": "",
    "comments": [
      "i dont know why 2022 GPU without Encoding capability is feel like backward to 2009",
      "Guys i think they meant $59 USD.",
      "Never understimate how far people would go to defend trash from a company they like.\n\nBack in 2019 you could buy an RX 580 or 570 with full encoding capabilties, full PCIE bandwidth and 8GB or VRAM for the same price. Hell you could get used versions for around 100$.",
      "Wait til the \"nobody other than the streamers need video encoding\" crew figure out normal people screen share in zoom or other services sometimes and their dual core isn't enough for it.",
      "Seems to be pretty much equivalent to the gtx 1650 3 years later for the same price. Granted, there's been inflation and while the silicon shortage is better but still a thing. So I'm not too upset by the positioning and pricing of this product, it's about inline with what I expect.\n\n\nWhat sucks is it has the same PCIe bandwidth issues as the 6500xt and no video encoding. I get that the 6500xt was a last minute laptop card turned desktop but AMD has had more time to prepare for this card. Without these problems it would have been an acceptable card given the current market conditions.",
      "If priced at sub 100$, it would be an interesting replacement for the crappy gt730 that still flood the lower end market.\n\nNot sure how the pcie x4 will fare at this performance level. Thinking of my sandy bridge htpc, with pcie 2.0\n\n\nPS. Just saw [this](https://www.techpowerup.com/review/amd-radeon-rx-6500-xt-pci-express-scaling/29.html) 6500xt scaling review. Holy fk, 66% performance with pcie 2.0.",
      "GT 1030 does NOT has NVENC of any kind.",
      "> Im sorry but I‚Äôm pretty sure a gt1030 can capture its own clips in nvidia‚Äôs drivers\n\nUpvotes for being wrong, huh? GT 1030 can't make use of GeForce Experience in any capacity, so it has no recording capabilities without an external tool.",
      "Some people don't need encoding though. Not everyone is a streamer. As long as you have decoding 70% of people would be fine 99% of the time.\n\nAnd CPU encoding can handle stuff in a pinch, say 720p discord screen share or whatever.",
      "No it isn‚Äôt. \n\nIt also has less pcie bandwidth, vram, and no encoder.",
      "Hate to break it to you...but it's not 2019 anymore.",
      "AMD using a laptop GPU to fill a gap in desktop product stack.\n\nNot a bad product if retail pricing comes down a bit.\n\nI expect Intel to make a splash in the low end soon, which will shake things up.",
      "There is no good (or even acceptable) way of doing it which wouldn't be slower than CPU while also awful for quality.\n\nSource: I was an XviD developer back in the day and looked into using GPUs for *something*. It's just the wrong tool. And modern codecs are even more complicated in the GPGPU-is-the-wrong-tool direction.\n\nModern video cards wouldn't have completely separate encoding/decoding cores if they could avoid it.",
      "This isn't a 6500xt and this article has benchmarks showing it's roughly equivalent to a 1650. And depending on the bandwidth you can get performance substantially lower than a 1650.",
      "Im sorry but I‚Äôm pretty sure a gt1030 can capture its own clips in nvidia‚Äôs drivers (edit: as pointed ou, this is false, it does not have nvenc) and I know rx5xx cards can too. There is no reason for  the rx6400 and 6500 to not have an encoder. This is not the worst value in the current market but the moment the prices finally come down, these cards turn into e-waste, with the only use for the 6400 being retrofitting older systems with a gtx 1650 alternative from amd, but even then the PCIe x4 limitation will be a problem since‚Ä¶ well older systems don‚Äôt have PCIe gen4, and if you‚Äôre buying a system with PCIe gen 4, your integrated graphics won‚Äôt be much slower",
      "Very much this!\n\nMost people do not seem to understand where transcoding resources are required.\n\nFor people that get it, this forces them to go Intel. Quicksync is great and is widely supported, so pairing one of these only for gaming on a budget isn't a terrible option.",
      "tf you could buy a rx 570 years back for this price... is this piece of trash at least better than rx 570?",
      "Sure they can, but encoders take up space on the silicon die and thus have cost and power consumption. Given that this is a low-end laptop part being re-packaged for desktops, it's understandable why they eliminated it originally (laptops are obviously highly sensitive to power consumption and pricing).\n\nAnd again, lots of people would never use it, especially so for those who would be purchasing a 1030 or 6400. And if they needed it in case of a screen share, that's what the CPU is for.",
      "Another shit GPU at a shit price.",
      "Never said this was a good value, just pointed out that the lack of an encoder is hardly an issue for the target audience.\n\nI don't even have an amd product at the moment, not exactly a \"fan\"."
    ]
  },
  {
    "brand": "amd",
    "generation": "6000",
    "tier": "low",
    "matched_keywords": [
      "6600"
    ],
    "title": "AMD Radeon RX 6600 XT Review: Worse Than Expected, But Can It Be Saved?",
    "selftext": "",
    "comments": [
      "Let me get this right: due to the 6600 XT featuring PCI-E 8x rather than 16x, it will **perform worse** on PCI-E 3.0 systems - say, motherboards like B450 and X470, for instance?",
      "Yeah, Doom Eternal in particular was absolutely brutal in the performance drop.",
      "Overpriced by at least $100.",
      "> It even manages to lose out to the 5700 non-XT in Doom Eternal. Embarrassing.\n\n[Meanwhile AMD marketing](https://techgage.com/viewimg/?img=https://techgage.com/wp-content/uploads/2021/08/AMD-Radeon-RX-6600-XT-Generational-Performance-Uplift.jpg)",
      "Just a reminder this is supposed to be a 1080p card priced at almost 400 dollars and will 100% be priced higher than that on the actual market. Nobody should be paying 400+ for a card that's made for 1080p gaming in 2021. That's just a joke",
      "AMD are not your friend.",
      "Like others have said, in Doom Eternal the performance drop was so great that it was outperformed by an Rx 5600 XT.",
      "thats the most favorable review of this card showing only 10% difference at 1080p. Other reviews show 15% and over 20% at 1440p. This shouldnt have been priced more than the actual 3060 non Ti",
      "In normal times this is a $250 card at best.",
      "Congratulations AMD for bringing us RDNA1 performance for RDNA1 prices. \n\nScamdeon just lost all their price-perfomance reputation that they was building for years.",
      "128bit bus and 8 PCIE lanes at price of $380 msrp in 2021 üòÇ - fucking shitshow is that? It's specs for office crap like GT 1030. AMD became so disgusting. Personally - wouldn't buy this crap even at msrp. If the market wasn't in such state - it would be far more beneficial to get used 5700XT, especially for people on PCIE 3.0",
      "As GN Steve rightly said, material costs and other overheads don't qualify as a valid excuse when you're announcing record profits. And they are. Nvidia and AMD are creaming major profits.\n\nLet this generation be considered proof that any ideas that AMD were somehow consumer friendly was total nonsense. The second they got to within spitting distance of Nvidia's performance (a charitable assessment of their performance) they abandoned competitive pricing.\n\nAnyone who doesn't need a workstation computer or who isn't rich should forget PC gaming imho. Console killers are a thing of the past. $300-400 'budget GPUs' are the meta.",
      "That's because this is a $250 product parading as a $400 product. The MSRP for 3060ti was set sensibly before AMD and NVidia said \"fuck it, MSRP doesn't matter\". So now we have cards like this one, the 6700xt, 3070ti, (and to a lesser degree) 3060 with terrible MSRP.\n\nThese are going to go for above $500 anyway. MSRP just decides how much of that goes to the manufacturer.",
      "They are, so will 6600XT's in just few weeks. Especially when there is exactly zero reference models at MSRP. The strix is officially a 550 dollar card. It wont even be lower than that because its official price, there is not a single card released at MSRP.",
      "Everything about this screams \"$200 card\". I even think the PCIE x8 lanes were a last minute decision to save costs just because they can nowadays.\n\nOf course, with demand outstripping supply and shipping costs and raw materials costs being what they are, if this is actually available at MSRP, it will be the best deal of the year.",
      "That ray tracing performance is insanely bad compared to the 3060 ti. The 3060 ti was regularly 100+ percent faster not even including DLSS in a lot of cases dang",
      "Lol. Just yesterday people were applauding AMD on here for charging a premium for their products. The duality of r/AMD users üôà",
      "I would not have complained if this was a $300 card.  \n\nWhile not the $200 dream point many want, $300 isn't miles off what the better 580's and 1060's used to go for.  So it wouldn't be an amazing price, but I think at least acceptable.",
      "amd is banking on shortage to make their card look more palatable lol",
      "So I paid $400 for a 5700xt with a little more performance and then AMD themselves launch another newer gen card for $379 which will never even be sold at 379??? What are they doing lmfao"
    ]
  },
  {
    "brand": "amd",
    "generation": "6000",
    "tier": "low",
    "matched_keywords": [
      "6600"
    ],
    "title": "Performance summary: Radeon RX 6600 XT vs Radeon RX 5700 XT at 1080p, 1440p, and 4K",
    "selftext": "",
    "comments": [
      "$400 for a 1080p card.",
      "AMD should have given it 64mb of Infinity Cache. While it wouldn't prevent the large performance hit at 4K, it might have been enough to advertise it as a 1440p card instead of 1080p.",
      "Thanks, I hate it.",
      "Reminder this GPU is roughly the same size as Navi 10/5700XT. \n\nThis is a complete fucking dud of a product and the asking price is an insult.",
      "I'm sure they left enough space for an RX 6700 to fit in between the two XT cards.",
      "5700xt was prolly a gem of card. People who bought it in 2019 made an excellent choice.",
      "Well, its crap. \nThis is to expensive even at msrp. \nThe whole generation is simply #skip\nNo hope for mid range gaming. At this stage a console is the solution. PCMR isn't for people that factor money into equation.",
      "I‚Äôm seeing a lot of acrimony and bullshit going around about AMD‚Äôs marketing and 1440p, etc. here‚Ä¶\n\nI ran a 5700 XT until this year with a 1440p/144 Hz monitor, and it ran every title I threw at it on high settings at 1440p just fine.",
      ">5700xt was prolly a gem of card.\n\nIt wasn't even that great, it just had a big lead on Nvidia in terms of process technology.  It was still surprisingly inefficient and only looked good thanks to Turing being so crap.\n\nIt was still a 251mm¬≤ GPU being sold for $400+.  Nothing to celebrate at all.",
      "Wait till you see how much an rx580 costs",
      ">> 5700xt was prolly a gem of card.\n\n> It was still a 251mm¬≤ GPU being sold for $400+. Nothing to celebrate at all.\n\n[Barely 2x the performance of the RX 480, for 2x the price, after 3 years](/r/Amd/comments/g7ky62/unpopular_opinion_navi_is_an_overpriced_midrange/); that's just sad.",
      "That's more than I got it for new in 2017.",
      "Probably the infinity cache hit rate\n\nhttps://imgur.com/QfSB3bU",
      "I know I am on the AMD subreddit, but man, the RTX 3060ti is a better value. When the hell did Nvidia do that?\n(on paper, at least,because the chip shortage and inflated prices are still here)",
      "#I no longer allow Reddit to profit from my content - Mass exodus 2023 -- mass edited with https://redact.dev/",
      "I thought the 6700xt was advertised as the 1440p card though.",
      "Not capable enough for them to advertise it as a 1440p card I suppose",
      "Because that will kill the 6700 XT? Especially that the 6700XT is already in a bad spot, it's priced 80$ more than the 3060Ti for very little performance gain.",
      "Except in real life I can get a 6700xt much cheaper than a 3060ti",
      "It‚Äôs worse than the 5700xt at the same exact price point. Two(?) years down the line. \n\nHow is that not a dud"
    ]
  },
  {
    "brand": "amd",
    "generation": "6000",
    "tier": "low",
    "matched_keywords": [
      "6600"
    ],
    "title": "The AMD RX 6600 is currently going for 17‚Ç¨ bellow MSRP in my country",
    "selftext": "",
    "comments": [
      "This price is with 24% VAT",
      "At some point the basic power color model was being sold for around 280‚Ç¨. Which is still way too much for a tiny little 1080p card with 8gb of vram. For me this card is worth at most 250 at this point.",
      "Œ¶Œ†Œë = VAT",
      "VAT is included in listed prices in all of the EU though, isn't it? Unless it's different for Greece.",
      "I think that the messege was more of a note for people from US, so they don't think it's super overpriced, but just slightly overpriced",
      "Value added Tax.... In all products",
      "Calling it a tiny little 1080p card is underselling it. I play at 1440p at high settings and high FPS. It's a mid-range champion.",
      "I thought the same three years ago. 5700X, this card is 300‚Ç¨. I wait for 260‚Ç¨. Then it was 700‚Ç¨ and I bought a refurbished PS4 with a couple of games instead.\n\nThere is little chance that the 6600 will be dropping to any thing meaningful, not with this market and inflation. I bought one in a 'sale' for 280‚Ç¨ because it will never reach the 'real value' next years.",
      "Even with VAT included. This is a really bad deal atm. Paying MSRP for 18 monthes old technology isn't that smart. If you can wait, then do it until  the new generation GPUs to be released to see the prices go down even further.",
      "Ah now I get it",
      "What is VAT?",
      "I disagree with you. I think GPU prices are going to drop a lot. Because of \n\n1. Low demand caused by a bad economy. \n2. Overproduction, Nvidia has tried to postpone the production. But TSMC refused.\n3. Mining equipment change - I remember Ethereum won't be mined with GPU in the near future",
      "Skroutz the goat fr. Nearly as much as I paid for my rx 5700 XT",
      "Well my budget is 350, so as long as it doesn't go above that, I'll gladly buy it",
      "The 8GB PowerColor Radeon RX 6600 Fighter is like 275 EUR for weeks now. Where is the news?",
      "Its about in line performance wise at a GTX 1080. Which even today will do 1440p as low-mid. \n\nConsidering $300-$350 its a pretty decent card. \n\nBut considering price to where it lands on the current generations stack. Its not a value for your money till around $270-290\n\nCosidering the 6500xt is an MSRP of $200.",
      "I know, I just saw the price being bellow msrp so I decided to post about it",
      "Œ¶Œ†Œë",
      "<300‚Ç¨ in GER atm",
      "They are extremely good I have the XFX 6600 and it games very well in 3440x1440 2k ultra wide on a 10th gen i5"
    ]
  },
  {
    "brand": "amd",
    "generation": "6000",
    "tier": "low",
    "matched_keywords": [
      "6400"
    ],
    "title": "Leak confirms custom Radeon RX 6400 graphics card are indeed coming - VideoCardz.com",
    "selftext": "",
    "comments": [
      "...god this thing is just gonna be a bloody display adaptor given how anemic the 6500XT was...",
      "At this stage they could release a lump of coal with a HDMI and displayport and it would sell",
      "At least it'll probably be so slow it won't have the 6500Xt's issue of choking in a PCIe Gen 3 slot (unless it has only two Gen 4 lanes or something)",
      "Basically HD graphics for those without APU.",
      "Depending on the benchmark/metric the 6500xt is 3-3.8x the performance of the Vega 8 on the Ryzen 5000 APUs or the GT 1030 DDR5.\n\nThe 6400 has the same memory bandwidth but 3/4 the CU's and a 15% lower clock.  **At worst it would still be** ~~2.25-2.9x~~ **1.9x-2.45x the performance of the 5000 iGPUs/GT 1030.**\n\nThe 6500xt is about 2.1x the performance of the 1050ti.  So the 6400 would be at worst ~~1.5x~~1.3x the 1050ti.\n\nConsidering people have been buying 1030's and 1050's for ridiculous prices (seen $130-$150 for the 1030), the 6400 (at an expected $150) isn't a terrible proposition.\n\nCould it be cheaper?  Sure.  Will it?  In time.  Is it a good GPU for playing newer AAA games? Oh hell no.  But it does quite well with a lot of games at 1080p and med to low settings.  Several times better than an iGPU for sure.\n\nEdit: the 6400 does have a 15% slower clock speed so adjust the numbers above accordingly.  So the 6400 becomes 1.9x to 2.45x  the performance of the Vega 8/GT1030.\n\nIt's still an upgrade for those on an iGPU for those that want to play older games or games with modest GPU requirements.\n\nEdit2: Best visualized with this relative GPU performance chart.  A Redditor added lines for the minimum and recommended GPUs for Elden Ring.   Note where the 6500xt falls:\n\nhttps://i.redd.it/h8p5sk3o30i81.png",
      "AMD wanted to create a card that wouldn't be throttled by all the PCIe x1 slots that everybody has but almost nobody has a use for.",
      "We need something greener... coal is bad.  How about soft Peat moss.",
      "Bring back AGP for this turd.",
      "Imo the 6500XT was perceived as terrible mainly because of the x4 connector. It's about as fast as a GTX1650 Super at PCIe4 and around a regular GTX1650/RX570 at PCIe3. And here I can get it new for just a little cheaper than a 1650. Not a great deal, but everything else (new) looks like a worse deal. So it's actually kind of an ok card imo. In this shitty climate at least, if things get better, it's also gonna fall in price.\n\nI'd guess a 6400 would be somewhere around a 1050/1050ti. Even if it's slower than that, I still wouldn't call it a display adaptor. That's reserved for the GT710",
      "Yup it'll choke just by looking at it",
      "id like one of these for my file server just for basic vulkan opencl support",
      "Not true - the GT 1030 *also* dropped the hardware video encoders, similar to the RX 6400 and RX 6500 XT. It is also limited to 4 PCIe lanes - and only PCIe 3.0, at that.\n\nLike these AMD cards, the GT 1030 is effectively a laptop gpu put onto a desktop card. (In laptops, it's perhaps better known as the \"MX150\")",
      "The problem with that is that one of its biggest markets is people trying to eek one last upgrade cycle out of a machine with a GTX760/960 and almost every one of those people is on a PCIE3 board.  \"Can afford B550/X570/Z690\" has a very narrow crossover market with \"Can't afford 6600+\"",
      "It's the same chip as the 6500xt just cut down on CUs.  So 4x PCIe lanes and the same L3 cache, memory, and memory bandwidth.\n\nWith 3/4ths the CUs and lower clock speed it only needs 53w.  So this card will likely only need power from the PCIe ~~adapter~~ interface.",
      "Why not? People aren't buying generations, they're buying cards. If there's currently nothing on the market to fill a price point and the 6400 will fill it, then great. If the price isn't right, then not great.\n\nIt's kind of sad that prices, even now that they've gone down, aren't great, but I think it makes no sense to judge a card based on what's been available in the past. All you're doing is lamenting the current market, that's not a problem with the card.",
      "A 750 ti replacement with 750 ti performance",
      "So basically the equivalent of a GT 1030 now",
      "So much negativity in here. God forbid there are options. Also, I don't understand why everyone here complaining it's going to be weaksauce... I mean, yea...no shit. It's a god damn ultra low tier card. But if you don't like it then the card isn't designed for your needs. There are 7 more cards tiered above this one.\n\nI'm confused as to what the issue here is.",
      "At $750!",
      "It's not, just cheaper... but that's okay, we need a 750ti replacement."
    ]
  },
  {
    "brand": "amd",
    "generation": "6000",
    "tier": "low",
    "matched_keywords": [
      "6500xt"
    ],
    "title": "Today's launch of the 6500xt further cements the RX 580 as one of the greatest gpus of all time.",
    "selftext": "If you purchased a RX580 now 5 years ago for around 200 USD then you should be throughly pleased with the value that you received. Few other GPUs have delivered as much price to performance, and this kind of longevity. \n\nThe RX 580 is a hall of fame worthy GPU. \n\nWhat other GPUs would you elect to the GPU hall of fame based upon price to performance + longevity? \n\nThe 1080 Ti comes to mind for me, but I'm sure this AMD crowd will be able to name many more.",
    "comments": [
      "All the 10 series cards were really good. Th 580 was also great.\n\nGood times",
      "The problem is that the RX580 launched at the beginning of another crypto bubble and it wasn't available for $200 until late 2018. I mean, some people got it for that price, like some people managed to get cards this generation for MSRP, but those were the exception.",
      "I'm still using my 480 and that thing is still holding strong and kicking ass. Absolutely worth every penny.",
      "> cements the RX 580 as one of the greatest **midrange AMD's** gpus of all time\n\nFTFY.\n\nGTX 1060 cost roughly the same, had a similar performance yet it's a much more efficient and thus quieter card. And to this date it's been the most popular GPU ever released/produced: https://store.steampowered.com/hwsurvey/videocard/",
      "IMO, the HD7970 was the greatest gpu AMD made. It had an incredibly long lifespan, and it's still capable even today. The issue is really just driver support anymore. That was a top of the line GPU in 2012 and they continued to rebadge it for a few more generations IIRC",
      "I bought mine in February 2017 for $186 and sold it two weeks ago for $375. That thing performed on par with the S&P 500!",
      "No doubt the 1060 is in the hall of fame.",
      "I got my 480 (8GB) for 239EUR in release week (founders edition fromm saphire) and sold it couple of weeks later and purchased a 1060 with about 80EUR surplus.\n\n480 = 580 - 5% Performance",
      "R9 290",
      "everyone was angry at Raja for only shipping mid-range cards with polaris. all these years later and AMD ships a gpu that barely holds up against it. CPU industry got back on track but GPUs have just been going straight into the toilet since the polaris/pascal days.",
      "The 580 was not the top end of AMD. It was a rebranded 480, which was slower than previous AMD GPUs (easiest to name being the Fury/Fury X).\n\nThe RX 580 was never positioned as a top end card. AMD completely abandoned the high end until the release of Vega. It was always a GTX 1060 competitor.",
      "When I got my RX 570. The 580 I could find for as low as $160-$175 after MIR.  My RX 570 I got for $115 and I believe I got it near its lowest point.",
      "RTX 2060 and 5700 XT were still very impressive. I reckon they'll be remembered well\n\n1660 Super was also a great 1080p card too.",
      "RX 580 might only be the greatest hall of fame worthy GPU because its successors just have been overpriced garbage. This is a bad thing, not a positive thing.\n\nEither way I think this was the RX 470/480 not the 570/580 personally.",
      "Let's be honest, navi lineup was quite good. 5600xt, 5700 and 5700xt have aged extremely well despite all driver issues they initially suffered from.\n\n5500xt however was a disappointment",
      "These are the gpus that were pretty damn awesome for it's time and provided a relatively long term solution newest to oldest:\n\n&#x200B;\n\n1: RX 570/580/470/480\n\n2: R9 380/380x 4GB.. though the R9 285 2gb was still solid\n\n3: HD7870\n\n4: HD 5770\n\n5: 4850/4870/3850/3870\n\n6: HD2600xt\n\n7: Literally ANY Radeon 9500-9800 non pro, but arguably even the pro were too.\n\n8: 8500LE",
      "Why not rx480 by the way? Basically same card but released earlier. Price? Clocks?",
      "My list:\n\nGeforce2 GTS 32MB\n\nRadeon 9700 Pro\n\nGeforce4 4200\n\nRadeon X800 XL\n\nGeforce 8800GT\n\nRadeon 4870\n\nRadeon 6950\n\nGeforce 970\n\nRadeon 7970\n\nGeforce 1080 Ti\n\nRadeon Vega56\n\nRadeon 5700XT\n\n*Forgot the Radeon 6950.",
      "I just hope people bought the 6GB variant and not the 3GB one.\n\nhttps://youtu.be/ySmMb4X7qbA",
      "1060, 1080 Ti, and RX 580 seem to be THE GPUs of that generation."
    ]
  },
  {
    "brand": "amd",
    "generation": "6000",
    "tier": "low",
    "matched_keywords": [
      "6600xt"
    ],
    "title": "The fact that the 6600XT will not be available on AMD Direct Buy ends many people‚Äôs chances at getting a card at MSRP",
    "selftext": "During this global chip shortage, OEM‚Äôs and retailers in the EU have been forced to mark up their GPU prices leading to buying at retail not being an option because of how ridiculous the prices are. (For example my local store is selling their cheapest RTX 3060 at 699‚Ç¨). In the midst of this, AMD Direct Buy has been a way to get cards at actual MSRP, even if the website is flawed and it may take a while, everyone I know that has tried to get a card, has gotten one, even if they had to try for 2-3 months. Here comes the 6600xt, a card that I finally can afford and that isn‚Äôt overkill for my type of gaming. And I find out that any small chance I had at getting this card at MSRP is gone because it does not have a ‚Äúfounders edition‚Äù or reference version that is sold on AMD Direct Buy, so I‚Äôll keep rocking my R9 380 until RDNA3 I guess. I‚Äôm sorry if you read this, I just needed to vent a little.",
    "comments": [
      "Many people won't be able to buy this gpu period.\nThe manufacturing will be bleak at best.\nThis is going to lead to poor allocation.\nIf by chance you see one in the wild, you had better snag it if you want it.",
      "> so I‚Äôll keep rocking my R9 380 until RDNA3 I guess.\n\nHaha he thinks they‚Äôll be any stock of rdna3 cards when they drop. \n\n\nThis shortage is gonna last a lot longer than they want to admit.",
      "> I think Nvidia has out done them on the goodwill\n\nUnfortunate but goodwill ain't gonna sell cards. Pricing low is something you do when there's massive silicon supply and when there's low demand for gpu. Nvidia overcharged with turing and the result is a 80% market share. The gpu market's sayin that people buy cards based on performance leadership marketing and not price\n\nGoodwill ain't a thing in business, the prices are all strategic and goodwill's somethin people say only when they want more for themselves\n\n1. Are the people ranting about 6600xt's price appreciating the \"goodwill\" of 6900xt costing $500 less than the 3090? Probably not \n\n2. If amd's next gen products are shit tier and they'd ask fans for some \"goodwill\" to buy their products would people do it? Probably not \n\nIt's cut throat business where it's every man for himself, consumers or corporations all the same",
      "Well, to be fair, i think that rdna 3 will be massively overpriced aswell. If stock is being sold out mostly now for as much as 100 to 150% msrp.. Why wouldn't they be able to ask for that next round?   \n\n\nI am curious though about rdna 3.. I mean, graphics already look amazing. What would that be in the future? 4k 165hz+  8k 60fps? Huge improvements on raytracing? What technology is next?",
      "GPU's are just stupid now, almost $400 MSRP for a 1080p card when you can get a series x game pass machine for $500,  that can do 4k 60 with compromises.  \n\nWhat's the point in DIY for average gamers at this point, valve could just bring  out another unlocked console with ps5/Xbox like specs with access to everything and that would be a killshot for most of this market.",
      "This is so disappointing to me. As much as I love AMD, I think Nvidia has out done them on the goodwill torwards gamers front. Nvidia released limited hash cards and EVGA has a wait list. Nobody on AMDs side can say this. At least not to my knowledge.",
      "I like day dreaming, what can I say?",
      ">\tI mean, graphics already look amazing.\n\n\nCompared to the past, sure. Compared to the endgame of photorealistic without severely limited draw distance? We‚Äôre not close.",
      "We have different incomes in different countries. For example my month income after taxes is 200$ approximately. And no, this \"issue\" cannot be \"addressed\" in any significant way.",
      "EVGA having waitlist is their decisions not nvidias right? so more like props to EVGA and shame on other aibs",
      "I am so glad AMD hasn't put artifical limits on what their GPUs are allowed to run like Nvidia has. Thanks to their open source Linux drivers, they probably couldn't either, which is good.",
      "Not quite becoming less demanding on hardware, but I think that once GPUs are good enough to raster 4k at high refresh rate then they can start dedicating more hardware to RT and ML features since the other side of the problem is basically \"solved\".",
      "Is the lower hash rate cards really accomplishing that much though?  Seemed more like a marketing gimmick than anything.  Especially with ethereum trying to move to a model that doesn't involve proof of work anyways.",
      "There were some discussions regarding the current gen's wafer allocation.  Obviously this is speculation so don't take it as if it was taken from an official statement.   RDNA2 for PC's is speculated to receive the least amount of wafer allocations, the bulk going to consoles and Zen 3 as its currently the money maker.   My point being is that I'm extremely hopeful that when 5nm products come around that its less of an issue and that RDNA3 gets a more aggressive push as Radeon has really come a long way, and apparently wafer capacity will match 7nm without consoles cannibalizing the wafer capacity.",
      "I think native rendering 4k high refresh rate is the new goalpost. After that idk. Maybe just thinks like raytracing becoming less and less demanding on hardware",
      "nVidia introducing LHR only hurts the market further. With mining boom, there is more demand than supply until the prices get to current crazy price levels. But limiting cards to either mining (no display outputs) or gaming (LHR) means you can not shift the cards between those markets, so have to produce enough for both, further increasing demand.",
      "Yeah, I don't think that account is real at all.",
      "Bye Bye PC gaming.",
      "Crypto to the moon again, be prepared we are going back to May market pricing...",
      "Really you think the overpriced 3080ti was good willed? Lol if you want to get a card in 2021 without paying 200% MSRP you pretty much have to go AMD. Demand for nvidia cards is way too high right now unfortunately"
    ]
  },
  {
    "brand": "amd",
    "generation": "6000",
    "tier": "low",
    "matched_keywords": [
      "6600"
    ],
    "title": "MXM form factor RX 6600 teardown",
    "selftext": "",
    "comments": [
      "Cool stuff. \n\nNot related MXM modules or anything, but there are quite a few 6600M desktop cards being sold at AliExpress for a while now, and for $200 or less. Looks good, at least based on reviews.",
      "Man I love this, I wish MXM was more accessible",
      "Got my hands on an MXM form factor RX 6600 and tore it down yesterday.\n\nWhat a lovely compact design using Micron GDDR6 (4x 16Gb modules), OnSemi power stages/voltage controllers, and high quality capacitors. Notes:\n\n- There are two NCP81022 4+1 voltage controllers with 10 phases in total (7 for VCore and 3 for GDDR6/SoC?)\n- Each phase is handled by an integrated OnSemi 55A power stage\n- VBios is set to 75W TDP, but I was able to push it past 130W with MorePowerTool and survive Furmark stress indefinitely. With the tiny heatsink, it matches my Desktop RX 6600 performance which has a 3X larger heatsink and two fans.\n- Curiously, there is no fan header on the board. Instead, the fan plugs into a host controller board on the other side of the MXM interface.\n- Manufacturer is Hightech (HIS)\n\nSo MXM is not dead yet....",
      "Where?  Wow thats nuts!  Surely configured for edp and not lvds?",
      "Why is this not marked nsfw? This is easily porn",
      "Quad DP with this VBIOS but surely configurable for anything. All connected via a host controller board ;)\n\nManufactured by Hightech (HIS)",
      "ok i'm going to check this out it looks like the 6600m is faster than 1070m and i'm seeing a parity in the desktop gpus as well. this could be half the cost to upgrad a form a 980m to a 1070m and faster and have better linux support.",
      "Its for a Thunderbolt eGPU. But I think there are higher-end models intended for some sort of Server or ETHmining application.",
      "It's not MXM, that's why I said it's not related. It's a 6600M chip on a pcb made for 6600s and XTs. Sorry if I made you think they were MXM modules.",
      "ƒ∞s it a laptop?",
      "Honestly, I thought that it was dead for years now, dropped before MXM3",
      "Interesting, ive been wondering which modern cards would get MXM treatments. I've heard of but not yet seen Ampere MXM cards in Clevo and Eurocomm documentation and im glad to see RX 6000 is getting the same treatment. I wonder if any 5600m MXM or other RDNA 1 MXM cards exist",
      "Nah, the government and some workstations still take this standard. Companies like Dell/Alienware used them up until 2014, clevo I believe still use a modified version of it that can be supplied their own power.\n\nPNY still designs GPUs for this form factor! It‚Äôs rare but you can find RTX 2060s and RTX 3000/4000/5000.\n\nI‚Äôm looking to get a GTX 1070 MXM in the next couple of months for my Alienware 17. Such a cool concept; too bad people want thin and light BGA crap",
      "I missed MXM",
      "According to this post, yes. Though I do wonder if the MXM fingers on this card support PCIe 4, since the latest MXM 3.1 spec explicitly supports PCIe 3 x 16 lanes.",
      "Oh the Turing Quadro, I see.\n\nI was gonna say that you shouldn't link webpages from the future cause that's an easy way to get your time traveler's license revoked..",
      "I didn't know mxm was still a thing for laptop gpus.\nLast time I remember hearing about mom was in 07. That was when I was trying to fix an Alienware for my at then boss.",
      "\"RTX3000\" exists in MXM but I'm not sure if its Turing or Ampere as the naming for Quadro and server applications is weird. Regardless its super low TDP.",
      "it sure looks like an MXM connector, whats the difference?\n\nEDIT: as to say that PCB looks like it would fit in my laptop with little issue.",
      "RTX 5000 is a GPU that‚Äôs already out. You‚Äôre getting it confused with the series, which is not what I was referring too."
    ]
  },
  {
    "brand": "amd",
    "generation": "6000",
    "tier": "low",
    "matched_keywords": [
      "6600xt",
      "6600"
    ],
    "title": "My experience going from 5700 XT > 6800 > 6600 XT",
    "selftext": "So I had the reference 5700 XT since launch for about 18 months. It served me ok, but the card would get so hot / loud (even tried an aftermark cooler) that I had to use it at about 90% of its clocks with some undervolting. Also had issues with HDMI audio that never got fixed (hw issue apparently). So while satisfied, I was eager to upgrade to RDNA2.\n\nThen the 6800 launched here in NZ for a reasonable price, I was even able to get it on \"special\". Powercolor Fighter, boy, this is the best GPU I've ever had. No RGB BS, ultra quiet, such a performer. With some undervolting (as my HTPC case isn't great), card used about 160-180W and you couldn't hear it. The \"useless\" 16GB of memory have seen up to 15GB used!!! when playing at 4k plus AA. Seriously, highly recommend.\n\nNow, I haven't been playing for months and such amazing card being idle was a discomfort to me. Decided to see for how much they were going - miners and all - and was surprised with what I saw. Long story short, sold it for \\~25% more than what I paid 7 months ago.\n\nOf course I had checked what was available - plenty of 6600 XT here for the same price 5700 XT were sold 2 years ago - so I grabbed one right away. XFX Speedster QUIK 308, screw RGB.\n\nComparison with 6800\n\n\\> testing here at 1080/1440p and it has between 65 and 75% of the 6800's performance, while costing 53% of that 6800's sale price. I'm happy. Noise wise, with overclocking and no undervolting (2750@1150mv and 2200+fast timings), it's maybe a notch above the awesome 6800 Fighter, but still a great and quiet card.\n\nComparison with 5700XT\n\nAs stated above, due to case constraints, the 6600XT is about 20-25% faster and MUCH quieter. The HDMI audio issue was fixed in the 6000 gen so there's that too.\n\n&#x200B;\n\nFor overall desktop use and Youtube/Media Player Classic, this card is amazing. Fans always idle, uses so little power to play even 4k videos, just perfect.\n\nVery happy with my awesome HTPC card + single player gaming here and there.\n\n\\>>> Is it worth the upgrade from a 5700XT?\n\nYes, as 5700XT are going for crazy prices (mining) you may get a 6600XT for $0 or even make a profit",
    "comments": [
      "I've had my RX 5700 XT since November 2019, and despite some driver issues early on, it's worked pretty much perfectly for me. I admit I don't game a lot anymore though. I'm afraid to sell it in case I can't find anything to replace it with.",
      "I thought it is going to be something negative since most people post about problems.",
      "I've never felt such a strong connection to a card before. From 6200 OC, to 9800GT, to GTX 460, RX380, RX480, (5700XT here) and with the 3070 now. 5700XT was such a good card for the price. Definitely felt bad letting it go for ~$950 after my buddy snagged an extra 3070.",
      "Great to hear your experience with those 3 cards!",
      "nah it has been great on me, nothing to complain :)  \n\"oh but it's soooo expensive\", well, here in NZ a high end 6600 XT is going for \\~70 USD less than an entry level 3060 non TI",
      "hell you can get a 6700 xt with how much 5700 xts are selling for. That's what I did",
      "Considering it was twice as expensive as 480 and twice as fast, I wouldn't consider it a good card for the price, it only looked good compared to the equally overpriced Turing.",
      "What is the HDMI audio issue you are referring to?",
      "So true. The 6700XT is a \"mediocre\" card according to everyone, but I fucking love mine. It's a beast for 1080p 165hz and does everything I need it to.",
      "Upgrades for free are the best upgrades",
      "I think we live in a buy now think later market. Of course unless you‚Äôre buying something from zotac that is borderline scalper prices",
      "This is awesome.",
      "There was nothing to be impressed about when you had twice the performance for twice the money 3 years after 480.\n\nWhen I upgraded my 270X to 580, I got double the performance for almost the same money - but well, I guess those days are over, especially since people are pleased with anything right now.\n\nOh, and we're discussing about periods where GPUs **weren't** money printers, now it's a different story altogether + COVID, inflation and all that.",
      "since when a \"3070 with 12GB of memory\" is mediocre? these people",
      "In NZ they are just that much cheaper, and I'm also a long date AMD fan. I had heard that other 5000 series models (5500,5600,5700 nonXT) didn't have the issue so I was confident on the 6000 series.",
      "Yeah, I have a 5700 and haven't noticed any issues with HDMI audio on the rare occasions I use it.",
      "5700XT has some audio drops through HDMI, like a second long drop every few minutes. Not sure if it's only triggered with some specifics devices (Sony and Yamaha here), but if you research you'll see a lot of people talking about this particular issue. Fixed on 6000 gen (5700 non xt was ok I think)",
      "Really depends on what 5700XT you have tho, I own gigabyte 5700xt aorus and not only it is super quiet and with low temps, but it also basically run 2020MHz 24/7\n\nNot to say 6600xt is not great if you can swap for free (not possible where I live and most place's), but it‚Äôs not that simple conclusion and also depends on what exactly are the two cards in question. Mine is basically a lot faster vs reference that was a lot faster vs how you ran yours + no issues like hdmi audio and 4 years warranty - won‚Äôt swap it for just any 6600xt and ofc - I will not swap it for 6600xt at all as this will be not any upgrade performance wise (potentially it will be overall a downgrade). Would swap for 6800xt or up, but I am planning to wait for the next gen.",
      "May I ask why did you decide to stick with AMD GPU despite the issues you had with the 5700xt ?\n\nIn the end it paid off, but still out of curiosity.",
      "Do you have a link to these issues being actually acknowledged or documented?\n\n\nI had ZERO issues with my reference card while using HDMI audio to a Denon receiver also a Sharp TV."
    ]
  },
  {
    "brand": "amd",
    "generation": "6000",
    "tier": "low",
    "matched_keywords": [
      "6600"
    ],
    "title": "AMD Starfield bundle starts on July 11th, will include Ryzen 7000 CPUs and Radeon RX 6600+ GPUs. - VideoCardz.com",
    "selftext": "",
    "comments": [
      "so if I buy starfield I get a ryzen 7000 and a radeon rx 6600 for free? \n\nnice.",
      "I wouldn't trust Amazon to honor the promotion even if they listed it, they never honored the 7900XTX \"The Last of Us\" bundle when I purchased a XTX earlier this year.",
      "That's exactly what the article title says, so lets go with yes!\n\n&#x200B;\n\nI'll take 10 please.",
      "So HUB makes one video taking sides with the consumer and calling out anit consumer practices, and all of a sudde they're the bad guys now?\n\nWell I personally don't like siding with a corporation so I will \"whine and complain\" if that's what having principles makes you.",
      "They still owe me a copy of Company of Heroes 3 I was supposed to get for my 5800X3D I got months ago",
      ">Okay boys, let's hear it. Let's hear the complaints and the whining about why this is bad. I hear Hardware Unboxed already has a video in the works on this topic.\n\nVery mature. Why are you getting so emotional over your beloved company getting called out for having committed to a very anti-consumer move possibly for years now?\n\nThe argument has nothing to do with game codes that are bundled alongside hardware. At no point was this issue with AMD's sponsorships about the actual games being some extra freebies that you get with your hardware. Clearly, that's not the problem here.",
      "I mean, I wish could use DLSS in this game.\n\nRIP\n\nit looks way better than FSR to me",
      "LOL the same day I bought a 7800X3D and never got Jedi Survivor either üòÇ",
      "Yeah but it's epic games store",
      "If I knew it would be that early, I would wait out instead of getting RE4.",
      "I'm 99.999999999999999999999% sure that people **don't** have a problem with games being bundled alongside hardware purchases.\n\nBut sure, pretend like that's what people have been complaining about, if lying to yourself makes you feel better.",
      "That would be evil",
      "At least a rx6600, they might even throw in a Rx 7900xtx if you're lucky.",
      "You have to register your product with the company offering the promotion. It's not Amazon giving away the game.",
      "Retail price for the game, in Taiwan dollars. Because that's the source.",
      "Won't it be harder to mod? I get that you'd be saving money on Gamepass but for a Bethesda game you'd want it on Steam surely",
      "We don't know for sure but going by the last game the steam version is the one you want for modding.",
      "Hmm the bundle will only be available on Newegg, Amazon...? Or does it apply even when I buy from a local retailer?",
      "game is already on gamepass day 1 anyway",
      "This is bad because I should have waited before getting my 7800X3D."
    ]
  },
  {
    "brand": "amd",
    "generation": "6000",
    "tier": "low",
    "matched_keywords": [
      "6600"
    ],
    "title": "Sold a 5-year-old 1080ti for $220, bought a used XFX RX 6600 XT Speedster QUICK 308 Black for $150, this sidegrade makes me happy with power consumption and noise (virtually silent even at max load)",
    "selftext": "",
    "comments": [
      "people see \"NVIDIA 1080 Ti used\" for sale and they will throw their wallets at you. \ngood bucks to be made by switching...",
      "All hail XFX and their Qick cards, such high quality construction.\n\n\nEDIT, auto correct to Quick, the naming is really not the best",
      "Yep, the card is 5 years old already.",
      "But a good card, though! The 1080Ti still holds serious chops in many aspects! \n\nSo, what kind of games are you looking forward to playing with this newly redefined rig? :)",
      "Personally I prefer the Swoft to the Qaick.",
      ">But a good card, though! The 1080Ti still holds serious chops in many aspects!\n\nDefinitely. But it's just old and could be failing anytime soon. So, time to say goodbye.\n\n>So, what kind of games are you looking forward to playing with this newly redefined rig? :)\n\nJust CS:GO on my new 1440p 165 Hz ultrawide and some not too demanding RPG games in general. The 6600XT is just right.",
      "I got 150W max power on stress test. Not only power difference, but noise as well since this is a more efficient card, and then there's the price.",
      "The performance is similar to the 1080ti: faster in some games, slower in some games, but overall it's the same. For power consumption and noise, it's huge upgrade in this department.",
      "so how's performance? is it the same/better/significantly better? I got no clue and I think about switching myself from 1070 to either 6600xt or 6700",
      "Swft<Core<Qick<Merc<Zero for RX6000",
      "Remember when the budget cards were awesome, and 200 bucks, and the top tier enthusiast cards were 500? and were a fraction of the PC build cost, and not a multiple of it?\n\nSigh.. good ol days..",
      "Played Divinity Original Sin 2 yet, maybe? Deserves a playthrough if you're kinda into DnD :)",
      "cooperations are simply not your friend, you really need to learn that. so there is no reason to treat them like that. no madness involved at all, that would be kinda shizophrenic since companies are not only not your friend, they also are not persons to have feelings towards - of what sort ever.",
      "How does the naming scheme for XFX cards work?\n\nLike, I know with Asus that ROG STRIX is their higher end stuff, with TUF below that, and usually a TURBO model that is a reference card with a blower cooler.\n\nAnd I recently learned about Sapphire, with their Nitro+ and Toxic models at the top of the range, with the Pulse etc being below those.\n\nI've seen XFX have cards like the MERC, SWFT and QICK, with different numbers attached too. What's that all about?",
      "Don't think people buying this kind of performance are often above 1080p, and the 1080 Ti is still quite powerful to his day (was a match for the 5700XT/RTX 2070, which aren't any slower than the 6600XT). It's probably losing steam in DX12 games but still, it's no slouch. ?ot sure why one would buy one at this price though",
      "Actually above 1080p is where the 1080ti claws back some ground. It's kinda hard to find good comparisons since the 1080ti is pretty old now, but Hardware Unboxed did a revisit a few months ago comparing it to a 3060 and 5700xt. \n\nWhen compared to the 3060 the 1080ti was 3% faster at 1080p but 5% faster at 1440p. When compared to the 5700xt the 1080ti was 3% slower at 1080p but equal at 1440p.\n\nI would imagine the same would hold true when compared to a 6600xt, probably due to the 6600xt's anemic memory setup.\n\nI think the 1080ti's memory config is really helping it's longevity. The 1080ti has 11GB GDDR5X on a 352bit bus which is good for 484.4 GB/s. Meanwhile the 6600xt is 8GB GDDR6 on a 128bit bus, good for only 256GB/s",
      "Agreed, my 1080ti is still going strong at 3440x1440 hoping to upgrade eventually with 7000 series assuming prices are reasonable, but not actually in any hurry to upgrade as I can still run most games on medium/high at 100+ fps (except bf2042 lol). On most older games (which is what I normally play, games like BFV, BF1, Destiny 2, Dayz) you can max out all settings and still easily hit 144+",
      "Which is bizarre because those cards are going to require some maintenance and are seriously showing their age at resolutions above 1080p",
      "Heh, even in games like Star Citizen, the 1080Ti is still a champ. The only exception being when you turn cloud settings to... Well, \"on\". \n\nOther than that, you only need a Schwarzenegger-CPU, then you're fine (I'm drooling over the 5800X3D, heh). \n\nWell, and preferably more than 16GB of RAM. \n\nWell, and you definitely need to have the game on an SSD. \n\nWell, and the page file of your OS on an SSD too. \n\nAnd THEN you're fine... Well, as fine as anyone can be.\n\nSo yeah, I'm glad plenty of games exist that are being continually optimized for older GPUs :) \n\n(In a sense, that's true for Star Citizen as well, as they basically based their performance target around the 1060 6GB card. Pre-cloud tech, anyway.)",
      "Not yet, but surely in my list, along with Pillar of Eternity and Trine series. Hopefully I can play these games at 144 fps with APU in the future."
    ]
  },
  {
    "brand": "amd",
    "generation": "6000",
    "tier": "low",
    "matched_keywords": [
      "6600xt"
    ],
    "title": "Small upgrade - 2600 + 1070 Ti to 5600 + 6600XT!! And still rocking a B350 board.",
    "selftext": "Managed to get a 6600XT for ~$190 USD from a miner and a 5600 for ~$140 USD. I sold my old parts so not much money spent!\n\nSpecs:\nRyzen 5 5600\nGigabyte Ab350m gaming 3 mATX motherboard\nScythe Fuma 2 Cooler\n16gb DDR4-3200 Trident Z RGB\nSeasonic Core GX650 PSU\nSama IM01 Case\n1TB NVMe, 2TB HDD and 1TB SATA SSD for games\n2x Arctic P12 Slim PST Case Fans",
    "comments": [
      "No such thing as overkill when it comes to air/water cooling. It means you can either run quieter, cooler, both and means your CPU goes through lower temperature differences thus preserving the life of it.",
      "5900x and 6700xt on a B450 board here, runs great!",
      "For a 65w cpu, that cooler is a bit overkill imo, but those 2 fans do create additional airflow. Its a neat build. Good job.",
      "Yeah, I went 5900x over the 5800x3D for the cores for vms and such. Bought the cpu before the gpu here. Impulse bought the 5900x to replace my 2600x when the prices first dropped, so it was paired with a RX 580 4gb for awhile. (Surprisingly, the 5900x got a tiny bit for performance out of the rx 580 that was noticeable in some games, like being able to up graphics settings).\n\nAs for the 6700xt‚Ä¶‚Ä¶I was originally looking at a 6800 non-xt, then settled with the 6700xt cause I only have a 2560x1080p ultrawide monitor. Also the price was right when I got it, got mine for $420 while the 6750xt was still in the $500 range and 6800 non-xt was in the $550s at the time",
      "How much did you sell the 2600 for? I just got a 5600 as well. Enjoy your new upgrades!",
      "Just curious, why did you get a 5900x if you \"only\" have a 6700 XT. Did you just need more cores for CPU workloads?",
      "Yep. But if peak temps stay below 80s, its a smooth sailing. I've had a 1600x running in 75-80c always under load in office pc, never had any issues until now. Though silicon lottery might also be in play.",
      "Upgraded a friends MSI B350 Tomahawk + 1600x system to a 5800x using the same motherboard. Quite amazing we can do that!",
      "No, I'm not. I'm just curious. Not sure why you had to come at me like that but I can see why you did.",
      "Isn't AM4 bloody amazing?\n\nI've been from...\n\nGTX1080 with a Ryzen 1700\nThe. A 3700X\nThen recently I upgrade to  5800X3D and RTX 4080.\n\nWhat a platform I have like 185+ % increase to CPU performance on the same damn socket!!\n\nASUS crosshair 6 hero board here :)",
      "I did the same upgrade and I sold my 2600 on eBay in July for $75 without the cooler. If you‚Äôre doing eBay put the 2600 in and make sure to select ‚Äúcompleted/sold‚Äù auctions to see how much it really sells for.",
      "Ngl I bought it cause it looks cool, but its also real quiet even on load",
      "Mostly gaming and VR. I mod a lot of games like Rimworld and Skyrim, which is quite straining for single threaded CPU performance so the upgrade is pretty nice",
      "That last bit is grade a pure BS but yes quieter is better.",
      "Downvote. Temperature changes is what damages the silicon.",
      "One percent lows should be better, as well.  Also depends on the game.  30% could mean difference between playable and unplayable.",
      "Well scientifically you are right (it'll probably be way more than 10ks) , but what I'm saying is cpu are designed to handle such swings for upto 5 years. And as i mentioned, silicon lottery affects the failure rate to. And on 5600, everything other than its stock cooler is great( that thing was shit)",
      ">just benchmarks great \n\nWhat lol.\n\n5800x3D wipes the floor with every other 5000 series CPU in gaming, and I haven't heard of a single person saying they were disappointed by it's gaming performance.",
      "Same board upgraded 1600 to 5500, 1070ti to 7900xtx",
      "It will after bios update"
    ]
  },
  {
    "brand": "amd",
    "generation": "6000",
    "tier": "low",
    "matched_keywords": [
      "6400",
      "6500xt"
    ],
    "title": "AMD Radeon RX 6500XT and RX 6400 to be the first 6nm graphics cards - VideoCardz.com",
    "selftext": "",
    "comments": [
      "Exactly. The only one sub-75W GPU \"available\" will be in OEM hands.",
      "That 6400 sounds great. 53W low profile is certainly something I'd consider buying if it was available. Hopefully it won't be OEM-only forever.",
      "What, does Airbus manufacture GPUs now? Whose card is that?",
      "How's it a waste?\n\nIt's literally the opposite on a newer wafer with lower yields.\n\nIf your wafer will have an estimate of 20 defects and you make 20 big chips out of it chances are more than half will be defective and a 50% yield.\n\nIf you make 400 chips and you have the same defect ratio then you get 380ish good chips. 95% yield.\n\nThat's why they're producing the small ones first.\n\nAlso, budget market (sub 300$) hasnt seen any major revolution since what, 2016 Polaris? We're in 2022 and if I spend 200$ today I won't even get 580 performance.",
      "A380 is shaping up to be quite a market killer at this point.\n\nThe name still sounds ridiculous by the way.",
      "A fan-less passive 6400 GPU!? now that's talking!!! :)",
      "I cant wait for a small formfactor card that isn't the gt710.",
      "RX 480 for $200 is still a good deal 5 years later. smh",
      "Intel",
      ">A380\n\nNo way I'm fitting this in my case!",
      "pipecleaner cards to push the way for bigger badder faster cards",
      "For desktops it will certainly be better than currently available APUs by a significant margin. Rembrandt's 12 CU RDNA 2 is expected to be GeForce 1050 Ti level or so. That's a lot faster than any current iGPU. The 6400 is likely to be somewhat faster.",
      "As if you were going to be able to buy them for less than a million dollars if they went retail.",
      "Bet it sounds like a jet.",
      "Interested to see how it would stack up against my 570. Though if 6600s were a decent price, I'd already have one.\n\nAlas, matters are as they are, and 6600s are rare, snapped up by greedy miners, or selling for a King's ransom.\n\nStill, I can dream of a future where a Mid-tier 1080p card runs cool, quiet, and above all, Efficient.",
      "The best value card I ever bought was a used RX460-4GB just before things went north last year for AU$80 (US$60), with its 75w no extra power. Played REre2/3 at 1080p/60 on High with Capcoms early equivalent of FSR.\n\nI would be interested in another mITX 75W card if it wasn't so profitable to only do cards that everyone wants for mining.",
      "50W are 50W, irrespective of nm process.\n\nLess RAM and lower TDP does of course mean the non-GPU part of the board should be simpler indeed.",
      "Does it really matter if they are not available or affordable?",
      "A380 should be official GPU for Microsoft Flight Simulator.",
      ">Ah, yes. The budget gamer arrives. Tell me, how much have you mattered to AMD or NVIDIA? They know you‚Äôre so irrelevant that they‚Äôve neglected the budget segment altogether. NVIDIA will be using TSMC 5 nm for their next GPUs. Can‚Äôt wait to buy an RTX 4090 to keep destroying budget gamers in every game. Everyone knows frames win games.\n\nQuoting your dumb reactions in case you sober up and feel like an ass.  /u/lizardpeter"
    ]
  },
  {
    "brand": "amd",
    "generation": "6000",
    "tier": "low",
    "matched_keywords": [
      "6600"
    ],
    "title": "The RX 6700 (non XT) got real cheap ... for those looking for RX 6600 XTs look no further!",
    "selftext": "",
    "comments": [
      "I envy US pricing and... don't get it.\n\nMid/low range GPUs are promised in summer.\n\nWhat is going to replace RDNA2 GPUs once current inventory is sold out???",
      "Damn, I bought my 6600xt for $600. More than the rest of my pc.",
      "They'll keep making rDNA 2 alongside rDNA3 to keep utilizing their 7nm capacities",
      "Those non xt 6700 cards are cheaper than 6600xt/6650xt in my country so they're no brainer here. More vram, proper x16 interface and more power.",
      "The RX 6600XT got phased out.\n\nNavi 23 is now:\n\n* RX 6600 - $189\n* RX 6650XT - $259",
      "Nah, this time Canada got the best deals\n\nThey got 6750 XT reference model from AMD direct store for $293 USD. I was one of them üòÉ",
      "According to TechPowerUp's database and [this guy's review](https://www.youtube.com/watch?v=6FkQdAViLIs) (cross-checking with his data because TPU didn't actually have a review of the 6700).\n\nThe 6700 is around 6% to 13% faster than 6600XT. The 6600XT itself is [7% to 20% faster](https://www.techpowerup.com/review/msi-radeon-rx-6600-xt-gaming-x/28.html) than the 5700 non-XT and \\~6% faster than the 5700XT (depending on resolution).\n\nThat means that the 6700 is around \\~36% faster than the 5700 non-XT, that's a significant margin.",
      "I didn't even know AMD released a non XT 6700.",
      "I paid $1200 for a new 3070 TI at the peak of prices, now AMD has the 6900 XT on sale for $629. I knew prices would come down, I just never expected it ti be that fast",
      "Or....Ebay, 6700XT for $310 shipped. used of course.",
      "Ever so slightly faster and two extra vram! Not a bad deal at all.",
      "I mean you can, but you end up with the GTX 970",
      "US pricing is a hell of a thing...",
      "Still waiting for 6600 XT for under 200 or 6700 under 300 (‚Ç¨). Thats what these cards should cost. The current lineup is trash, with the 6500 XT being actually worse than a 2016 card for the same price.\n\nUsed marked prices are sick, they for example demand 150+ for a Vega 56.",
      "the 320 price is in dollars, I see also ‚Ç¨380. You can't compare prices in different markets.",
      "That's unreal. I paid about the same for my 580.",
      "It was a pricing error that was only up for a short bit, site was down by the time I tried to buy one",
      "I got a used 6700xt that still has warranty until 12/2024 for 185$",
      "How does the SWFT309 say ‚Ç¨320 for you and for me it's 380?\n\nI'll also disregard that you have free shipping too.  \n\nEDIT: Misread the currency",
      "Canada =  Little USA"
    ]
  },
  {
    "brand": "amd",
    "generation": "6000",
    "tier": "low",
    "matched_keywords": [
      "6600"
    ],
    "title": "Are these temps normal on an RX 6600 XT running Heaven Benchmark, the Tjunction temp will go up to 85c while the normal temps stays below 61c.",
    "selftext": "",
    "comments": [
      "I would say yes considering my 6900XT got to 94¬∞C Junction real quick.",
      "Doesn't AMD specify that junction temp up to 110¬∞C is fine/even normal? Or was that just the 5000 cards?",
      "[\"Operating at up to 110C Junction Temperature during typical gaming usage is expected and within spec.\"](https://community.amd.com/t5/gaming/amd-radeon-community-update-more-control-over-gpu-power-and/ba-p/418629)\n\nThey said that about the 5k cards but I guess it's still applicable here, as I've seen pretty high temps from 6k cards aswell.\n\nAs long as they don't reach throttling territory it shouldn't really matter. The cards shut off as they get too hot anyway.",
      "Same. I don‚Äôt worry unless 95+",
      "At TPU they have data for a few models. Hotspot/Junction temps go from 80¬∞ to 98¬∞: https://www.techpowerup.com/review/asrock-radeon-rx-6600-xt-phantom-gaming-d/32.html",
      "The junction temp is the hottest part of the die. If you're coming from an Nvidia card they keep that number hidden by default (probably so they don't have to deal with people freaking out about it), but you can expose it with 3rd party monitoring programs and the behavior is exactly the same as AMD with the junction temp anywhere from 10 to 20 degrees higher.",
      "Tjunct temp is supposed to be higher than core temp so 80c is really good. personally i would let it run at 90c+ for lower fan speed tho",
      "Water",
      "I am so happy with my 6800 Merc319. Even under full load the Tjunc never exceeds 75¬∞ C",
      "Well within tolerances.\n\nIt won‚Äôt kill itself either.",
      "Isn't that rpm loud af?",
      "Sounds like you need to up your clock",
      "I know this is an obvious thing but you could try to lower the rpm to have it like at 25% at 69¬∞ and then 35% for 79¬∞ and like 55 or 54% for 90¬∞ and it should still be able to cool it down unless you are trying to run games at highest on 4k that is ofcourse. Otherwise i think with the config i have you should have an solid rpm below 2000 or so under full load and temperature waging near 80¬∞ junction temp and 60¬∞ somewhere for normal temp.",
      "No problem. Try to use Unigine Superposition or the 3D Mark suite though. They are a bit more modern than Heaven, which is ancient at this point.",
      "My 5700xt used to go to 112¬∞C before watercooling. Normal though. AMD says limit at 120¬∞C or smth (at least for mine). I'd imagine the other RX series cards now are built similarly",
      "thanks for the info.",
      "Yes sir it is.",
      "For junction? Yeah totally. That chip gets hot.",
      ">AMD says that up till 110 degrees it's fine but we all know it really isn't \n\nAnd what evidence do you have to say this? Presumably AMD's official statements are based on their own knowledge of how they've engineered it as well as their own testing data, which we're not privy to. Meanwhile, anything arbitrary we as consumers can say such as \"90C is safe\" or \"80C is too high\" (and I've heard both of those in the same thread before) come from nothing more scientific than our own personal *comfort levels* with various temps. Much of that is based on historical conventions that don't apply anymore (after all, at one point a 50C CPU was considered hot).\n\nIt's just like the old R9-290X debacle, where AMD officially stated they were designed to be run at 95C, and everyone freaked out because they were convinced that 95C would kill it in a matter of weeks. Lo and behold, I have an R9-290 that's been run on the stock cooler at 95C under full load still alive and kicking today, 8 years later.\n\nI won't say no to cooler temps when they're available. But in the absence of conflicting data, I'd be inclined to trust any manufacturer's official statement.",
      "For the temperature? Any good monitoring utility with a temperature chart (not just a number) will visibly show when it's leveled off. I'm not sure about Radeon Software, but MSI Afterburner and GPU-Z both have charts.\n\nIf you're talking about overclocking stability, that's a different story. I try to run through all of Time Spy, Fire Strike, and Port Royal stress tests, then 12-24 hours of Superposition."
    ]
  },
  {
    "brand": "amd",
    "generation": "6000",
    "tier": "low",
    "matched_keywords": [
      "6600"
    ],
    "title": "So about those 6600 XT prices...",
    "selftext": "",
    "comments": [
      "Sapphire Pulse can be had for ¬£380 here in the UK, has been in stock since release.",
      "Just don't buy it. Problem solved.",
      "Genuinely amazes me how they've held up, or overclockers just took in the entire European shipment of cards",
      "Hey, it's free market. When my ancestors wanna buy GPUs at MSRP, they made USSR.",
      "In my country they did land at around the MSRP in the first days after the launch.",
      ">$560\n\nI'm not sure if you can consider yourself lucky :)",
      "Still significantly cheaper than the 3060 in my country.",
      "I got downvoted into oblivion and people thought this would land around the msrp lmao",
      "Feels more like the latter (to an extent at least - more likely OCUK got a strangely large supply of them if nothing else) because the Pulse has always been a super popular card, would be extremely odd for it to barely be selling (especially given the price) when other models are selling out as expected.",
      "Because it was near MSRP in many countries outside of the US.",
      "I'm just as amazed that oc aren't bumping the pricing up on them like everybody else. We both know that oc is selling a boat load of them and they love to pump up the pricing, I'm wondering if there was a deal made where they could have a boat load of stock but had to keep it at a pricing sapphire wanted",
      "#I respect you for saying that.\n\nIf you don‚Äôt want cards over MSRP then stop spending more than MSRP.\n\nAnd cards we want aren‚Äôt ever at MSRP anyways, they‚Äôre usually higher by $100(+/-).",
      "Yes you could also use an AMD APU in the meantime. And less gaming and more learning (e.g. videos) is good for the career. ;-)",
      "Overclockers isn't selling them to anyone outside of the UK anyway",
      "In Norway the prices are more or less MSRP, but still not worth it!",
      "So much complaining MSRP, and didn't grab MSRP cards at launch day when had a chance.  \nAnd here is the real street price, so keep waiting folks.",
      "That by itself is a miracle",
      "Price fixing is where different parties agree not to sell lower than an agreed price so they aren't fighting against each other and ends up worse for the consumer. Setting a maximum price that a card can be sold for is a completely different matter and is actually good for consumers. I'd take bets that this is what has happened with overclockers this time around, they usually aren't shy of bumping up the price if they think their customers will pay it, I bought a MBA Sapphire 6800 at release and overclockers were charging about ¬£50 over the MSRP for it at the time.\n\n&#x200B;\n\nEdit: I spoke too soon, the Sapphire Pulse has gone up by ¬£15 today, cheapest now is the PowerColor Fighter at ¬£390.",
      "I got mine for ¬£330 including VAT (Net of VAT it is ¬£275 which is $380).\n\nThey were actually available for MSRP for a short while and in the UK they are still cheaper than 3060's",
      "I would never consider Amazon prices to be a real judgement of the current state of the market. GPUs have always been overpriced there, and have the most egregious examples of price gouging."
    ]
  },
  {
    "brand": "amd",
    "generation": "6000",
    "tier": "low",
    "matched_keywords": [
      "6600"
    ],
    "title": "RX 7600 review roundup demonstrates disappointing performance/price vs RX 6600 despite RDNA 3 GPU performing 27% better",
    "selftext": "",
    "comments": [
      "The RDNA2 is clearance stock, great while it lasts but will dry up\n\nClassic Radeon, it's a poor buy at $270, but will be fantastic at $200-250 in 6 months when it's been forgotten about",
      "If the two only positive/best things that can be said about your GPU is that you'll stop producing the other better ones to increase margins, and that it'll come crashing down in price soon enough... Well, you're probably AMD. Then again there's nothing positive to say about Nvidia's except the 4090 is a huge leap... When's intel dropping some new hotties?\n\nAnyone in this price tier should either grab a 6700 10 GB while they still exist, or go used. I got a 6700 xt for 220 with 2 years warranty left a couple days ago. And sales tax here is 15% so even more savings there. Receipt price is 1265 from the scalpocalypse... Oof.",
      "I think it‚Äôs aimed at new buyers on a budget or people who skipped a gen or two who are also on a budget.",
      "This. I know it's a poor gen on gen upgrade, it's quite a boring GPU for guys like us but if you already own a 6600/xt/50xt you don't really need an upgrade. \n\nNew people building PCs in a few months will appreciate the 7600. People still on a RX 580 or GTX 1060 who finally decide to upgrade, it's good for them.",
      "I doubt you will ever find a card to buy, with that expectation.",
      "27% faster than the 6600 is a decent gen-on-gen upgrade, *especially* for this market segment.",
      "it's not (just) about margins, it's about getting rid of old stock",
      "4060ti was dunked on by majority of reviewers. What",
      "In the used market he very easily can",
      "It's 100‚Ç¨ more my man, I'm not spending that money.\n\nEDIT: proof, before I get any shit for this. https://amzn.eu/d/fs9LMWP",
      "The used market has its own drawbacks.\n\nDue to AMD's aggressive new pricing, I don't find used RDNA2 cards to be worth it tbh. The price is slightly lower than new, but you still have to pay sales tax and likely much more for shipping.\n\nFor example, after shipping the *cheapest* BIN 6600 on eBay is 160, when you can get a brand new one with a game and free shipping for 180.\n\nHWS is an option, but imo any legitimately good deal gets purchased so quickly that you pretty much have to F5 to actually get anything. And Facebook Marketplace is complete fucking garbage frankly and a huge PITA in my experience.\n\nYou could buy a gen older used, but that has its own clear disadvantages too.",
      "I honestly think that the 7600 is an impressive step forward for a card that performs quite a bit better than the 6600 and 6600xt. \n\nFor the price you are paying for, along with more modernized core architecture, its a good buy. And as per always, AMD normally makes their cards very competitive as time goes on with better drivers altogwther.",
      "Reviewers yes, we'll see what consumers think.",
      "After seeing the 7600's price/performance I just bit the bullet and bought an RX 6600 for 206‚Ç¨  \n\n\nWill keep it for as long as I can, next purchase will probably be with an entirely new build.",
      "The more you buy, the more you saveüòé",
      "Production of those cards stopped a while ago lol. It's being phased out now hence the bargain bin prices for remaining stock. Not really a fair comparison.\n\nCompare it to the $400 4060Ti instead.",
      "Usually new gen offers better value than old gen even if it's on its way out. At least if it's interesting. To get better value on a 2080 ti than a 3070, you had to buy used. 980 ti was also terrible value when 1080 ti was launching same for 780 and 980, etc. Otherwise why launch it? Just keep giving us rdna 2 if it's better value. It's not like there's new tech even on offer. Like how is your launch supposed to be exciting if all it's making me wanna do is buy your older stuff?\n\nAnd what's worse is 6650 xt's have been available around this price for like 6-12 months. So who's this card for? Anyone who wanted this type of performance at this type of price could've had it for the last year and been gaming away. It would've been substantially better value, if you buy it now it's more of a giving in \"ughhhh fine\" than exciting.",
      "under $200 is where this card will shine, 8GB above 200 is just a stupid purchase.",
      "I'm not denying that, but it's clear that RDNA2 is going to sell out soon enough that the reviews will age like milk.\n\nI just don't like the idea of thrashing an AMD product solely because they cut prices on older products. Pragmatically, AMD is going to see that feedback, and we'll end up with either of these:\n\n1. They ignore it\n\n2. They artificially hold pricing high like Nvidia did. Then, when they launch the 8600 for the same price, it'll look like a good deal.\n\nI'd rather have the current situation than the 6650 XT being 330+ dollars so the 7600 looks better.",
      ">It's not our position to bitch verbally about new products being worse\n\nWhos position is it then if not the customers? The dudes working at AMD? TSMC?\n\nAnd yeah, for the past 25-30 years we have expected and gotten 20% increase in perf each generation for same price cards. \n\n\"When the 6000 series is gone you have no other choice...\"\n\nYes we do. Buy used or don't buy at all.  Which is exactly what consumers are doing right now."
    ]
  },
  {
    "brand": "amd",
    "generation": "6000",
    "tier": "low",
    "matched_keywords": [
      "6600"
    ],
    "title": "AMD Radeon RX 6600 XT with 2048 cores and 8GB G6 memory officially launches on August 11th - VideoCardz.com",
    "selftext": "",
    "comments": [
      "This MSRP is just a very bad joke.",
      ">This MSRP is just a very bad joke.\n\nThey just pretty much rereleased the 5700XT with poor Ray Tracing support.",
      "380$ lol. Rather spend the 20$ (when comparing msrp) and get the 3060 ti.",
      "40% faster, 39% more expensive.  1% savings passed on to gamers.  Thank you progress. Thank you.",
      "$379, fuck that lmao",
      "Even the 6700xt isnt good at msrp compared to its siblings. It has 20 less CUs compared to the 6800 but clocked way higher to lessen the gap  (which leaves no oc headroom and if you oc the other cards the gap widens), even then is still 30% weaker than 6800 at stock clocks in Doom with RT ([https://www.reddit.com/r/Amd/comments/obo98s/doom\\_eternal\\_4k\\_raytracing\\_benchmark/](https://www.reddit.com/r/Amd/comments/obo98s/doom_eternal_4k_raytracing_benchmark/))\n\nHas less Vram and way worse cooler (by 10 degrees according to Techpowerup ). \n\nFor 100$ more you get 30% uplift (by far the biggest jump for 100$), 4gb more VRam and way better cooler (which many people already pay for to get better AIBs)\n\n6700xt should have been 400$.",
      "1080p card in 2021.. 379$\n\nLOLLL",
      "This person curb stomping the 6700 value proposition.",
      "I expect AMD to adjust MSRP when this shortage is over. rather pay +20 for 3060ti or stick with 3060 for 50 savings + dlss.",
      ">**Nvidia settles price-fixing lawsuit**\nOut-of-court deal cut with plaintiffs  \nTony Smith Tue 30 Sep 2008 // 08:06 UTC  \nNvidia has settled a class action lawsuit that alleges it conspired with AMD to fix graphics chip prices.  \nThe proposed settlement, outlined in the company's latest filing with the US Securities and Exchange Commission (SEC), offers initial plaintiffs $112,500 and a further $1.7m to all the others who subsequently signed up when the lawsuit attained class-action status.\n\nhttps://www.theregister.com/2008/09/30/nvidia_settles_lawsuit/\n\nI hope none of this is currently happening again",
      "Yup. I'd rather wait for 6700xt at a good price. Probably not this year...",
      "On retailers is going to be much higher. MSRP doesn't mean anything since January.",
      "Hey hey now. Our cult leader Lisa needs her margins.",
      "AMD themselves are even positioning it closer to the 3060 than the 3060 Ti yet the MSRP is closer to the 3060 Ti.\n\nIn a world where MSRP was normal for everything, I don‚Äôt really see the advantage of getting this over a 3060 Ti or 3060. \n\nOf course, right now it‚Äôs practically impossible to get a 3060 for MSRP, even if you joined the EVGA queue soon after launch and nearly impossible for the 3060 Ti. I‚Äôm sure this won‚Äôt be much different though especially since this won‚Äôt have a model sold by AMD directly.",
      "Imagine making the 3060 and 3060ti look like good value.",
      "Yeah, with the RDNA II cards, I find it suspicious with the MSRP pricing.\n\n$379 RX 6600 XT\n\n$479 RX 6700 XT\n\n$579 RX 6800\n\n$649 RX 6800 XT\n\n$999 RX 6900 XT\n\nFrom the RX 6600 XT to RX 6800 XT, the $100 difference seems to be bait to lure people, who can afford it, up the stack. In real world pricing, the price difference makes it weirder. For example, ASUS RX 6700 XT ROG STRIX ($929.99) vs. XFX RX 6800 XT MERC319 ($1499.99) looks disgustingly debatable (both in-stock regularly at Newegg). At 61% higher price, the 6800 XT has 55% more silicon, 50% more VRAM, 33% more memory bandwidth, and 80% more CUs as well as solid 4K gaming performance.\n\nEven the RX 6800s are popping up in-stock on Newegg, the MSI Gaming X Trio version is going for $1219.99. At 31% higher price vs. 6700 XT STRIX, the MSI RX 6800 has 55% more silicon, 50% more VRAM, 33% more memory bandwidth, and 50% more CUs plus decent 4K gaming.\n\nThis whole situation looks like AMD wants people to buy RX 6900 XT. It's been rumored that AMD want to sell as much high-end stuff as possible and push aside the entry to mid-range market. AMD's first card to come back in stock were the RX 6900 XTs and followed by RX 6700 XTs (also $1700-$2000 price tag means low sustained demand). RX 6800/6800 XTs are coming back last because AMD's solid yields at TSMC mean that most Navi 21 dies can be 6900 XTs, so why disable CUs for lower margin RX 6800 series GPUs? At the end of the day, value and price-to-performance are no longer AMD's intention or goal. In contrast, NVIDIA's RTX 3060 and 3060Ti cards are this generation's price-to-performance leaders when in-stock.",
      "What a piece of crap, the 3060 have the same price/performance while having a lot of extra goodies like 4GB more vram, better rtx performance & support, DLSS, more memory bandwith to handle 1440p gaming without relying on cripplingly small cache.",
      "The biggest joke outside of the terrible \"MSRP\" is that it's AIBs only. So while before, a lucky few are able to get cards at MSRP from AMD's website, for this one... Not a chance. Least Nvidia still sells a 3060 Ti at MSRP on bestbuy when available which is a better buy even under normal circumstances.",
      "A worse 5700xt for more money, this is literal regression.",
      "Regardless of the current market prices, this MSRP is a joke."
    ]
  },
  {
    "brand": "amd",
    "generation": "6000",
    "tier": "low",
    "matched_keywords": [
      "rx6600"
    ],
    "title": "Rx6600 in 2025",
    "selftext": "Built this all AMD system in December 2024,\nAMD ryzen 5 7600x\nAMD Radeon Rx6600\nMSI Pro B650S wifi\n16GB DDR5 RAM 5200Mhz Cl40 (Since Upgraded to 64GB DDR5 RAM 6000Mhz CL30 with Expo)",
    "comments": [
      "bizarre build ngl, that low end of a gpu with 7600x and 64gb of ram + the back fan and cooler fan are working against each other lol.",
      "Not super wierd, if your still on 1080p this is a boss build ready to be upgraded whenever you jump to a higher resolution.\n\n** oh wait yeah 64gb is wierd. 32gb more than enough for virtually any gaming.",
      "Wasted money on 64gb ram instead of improving other parts of it\n\nAnd yeah that silly back intake fan, what were you thinking",
      "6600 XT here with Ryzen 7 5700 and 32gbs of ram\n\nI play mostly older games. Modern games arent really fun much anymore.",
      "It's set to intake",
      "6600 is still good for medium settings, and is excellent for many older games",
      "Ddr5 32 vs 64 is not cheap lol. Especially when your rocking a typical budget gpu. \n\nGet real braaaa",
      "The rear case fan is facing the wrong way, air comes out of the side with the grills. It‚Äôs a simple fix, just flip the rear fan front-to-back.",
      "Don‚Äôt mind the haters, they just want to feel better than someone else. \n\nDef flip the exhaust fan to push air out instead of back at your heatsink. Just moved off a 6600xt good little card. If you upgrade gpu definitely pay attention to how big the card is.",
      "Sometimes there is an arrow on the side of the fan to indicate the direction of air",
      "Did you buy that card secondhand?",
      "Case is probably too small for any meaningful upgrade on the gpu side. Friend has that very same card, and it‚Äôs a fair bit shorter than my TUF 9070xt",
      "If air is coming out then don‚Äôt worry about it, you have it right. \n\nIt‚Äôs just very common for the side that has the plastic that holds the fan is the exhaust.",
      "you installed your exhaust fan in the wrong direction\n\nthe internal parts of this build will not last long",
      "Money wasted on 64gb, 32 is enough for gaming and spare. Could've put the budget into more roomy case. The back fan should be exhaust, its just fighting with the front intakes currently.",
      "Can you tell me the correct orientation? Because for a while i have had questions on the fan arrangement",
      "Oh shit thank you this is by far the best explanation. Really thank you. \n\nActually the system fans were pre installed but during building, I removed the back fan (idk why I was building for the first time) and maybe I put it on the wrong way, ofc I didn‚Äôt know any better at that time but I will change it soon asap.",
      ">The back of the fan (4 black pillars converging on the round black spot in the middle)",
      "Ok thanks, many were saying things about cpu cooler so thought it had some problems too.\n\nWill do so today thanks",
      "Everyone thank you for your comments, even if they were insulting. I did put the fan in the wrong way at didn‚Äôt even bother to check it. I just felt some air movement and didn‚Äôt think much. \n\nNow after seeing all the comments, yesterday I opened up my case, Inverted the fan and then booted the pc. I checked the airflow by dangling a piece of flimsy paper behind the exhaust fan to see it was blowing out the air instead, and it was blowing it out. \n\nOf course as the system fan came with the cabinet, it is not the best. But now it is better and also looks better because it had rgb haha. I hope I could have posted a photo without imgur.\n\nBut thank you all for the help"
    ]
  },
  {
    "brand": "amd",
    "generation": "6000",
    "tier": "low",
    "matched_keywords": [
      "rx6600"
    ],
    "title": "Always wanted a full red build! Went for the budget value meta R5500/RX6600.",
    "selftext": "",
    "comments": [
      "Adorable pig! Where is it from?",
      "Looks great! Enjoy the gaming!",
      "Is that an ITX board???",
      "I have an R7 with 6600 XT and im still pretty happy with it. However be warned of brand new games with Raytracing. Our cards dont handle it well.",
      "i was gonna say that the pc isnt red i think im stupid",
      "NOOOO, WDYM YOU DIDNT SPEND $5000 ON A RYZEN 9 9800X3D AND A 5090 ARE YOU DUMB‚ÅâÔ∏è‚ÅâÔ∏è‚ÅâÔ∏è /s\n\nNice build! I fw the fps/$ for sure",
      "Tons of performance, reasonable amounts of $. This is a nice daily driver!",
      "Asrock B550m-HDV. Cheapest B550 I was able to find, not the greatest VRMs but enough for 65w.",
      "No. No, you are not, I was about to point out that it is white, but then I noticed it was on AMD‚Äôs thread",
      "Corporate only approved a $700 budget!\n\nAnd by Corporate I mean the wife.",
      "I'm coming from an i5-3470 with an RX550, imagine my joy!",
      "Have fun!",
      "You messed up bro. That PC is black, white and pinkish. The ethernet cable is a good start.",
      "It looks a lot like some of Poogie's costumes. (Poogie is a pig character in Monster Hunter. You can dress it up with little costumes, several of which are much like the one on this pig, just in different patterns. You can also pet it, and if you do it right, it'll sometimes give you materials.)",
      "Thanks! I'm trying, but this thing people call job won't let me!\n\nExcel runs really fast tho xD",
      "Love that !! Haha, great value build man, for $700 that's a 1080p beast. My 5500 served me well for sure",
      "The pig ... ‚ù§‚ù§‚ù§‚ù§",
      "i like that pig so much ü§ßüò≠üò≠",
      "That‚Äôs not red at a-whoops",
      "its great for 1080. was my build until last year and im still banging the asrock b350 pro4 (currently on 5700x)"
    ]
  },
  {
    "brand": "amd",
    "generation": "6000",
    "tier": "low",
    "matched_keywords": [
      "6600"
    ],
    "title": "RX 6600 render (my concept) created in blender, what do you think?",
    "selftext": "",
    "comments": [
      "WccfTech: RX 6600 OFFICIAL RENDER LEAKED",
      "Looks great, I love it! I think the font weight on your Radeon and R is a bit too high.",
      "You forgot gamer meld and his ‚ÄúaMd CoNfIrMs rx6600‚Äù. I might have seen the thumbnail with ‚Äúbig NAVI with .... confirmed‚Äù at least a 100 times since last year. Don‚Äôt know why YouTube keeps recommending these trash channels.",
      "I know everyone is hyped for big navi but what about small navi?",
      "I just want medium Navi. Something around 5700XT raster perf (or a little better) with ray tracing. I just want good (up to 100FPS) 1440p performance and experiment a little with ray tracing.",
      "[Clearing your watch history](https://www.youtube.com/feed/history) should help with that.",
      "I like it",
      "I read somewhere that the dual fan config for Radeon 6000 has been abandoned and they're all going to be triple fan. It's probably bullshit, but just an FYI.",
      "The chamfered edges on the sides of the gpu look amazing.",
      "We will see",
      "it's actually emissive, but only a little bit, and there is no bloom so it's not as visible",
      "You‚Äôre an asshole. You should delete your account.",
      "The problem is these YouTubers like gamer meld have no integrity and low standards. They don‚Äôt even bother checking the validity of the rumour and even a random Reddit post could be their ‚Äúsource‚Äù. Also those click bait thumbnails. Can‚Äôt count  the number of times I‚Äôve seen sensational titles like ‚Äúbig NAVI destroys nvidia‚Äù or ‚Äúampere/NAVI confirmed‚Äù",
      "gigabyte rx580 gaming 8g, but i had few issues with OpenCL rendering and it took a while....",
      "I like the leak channels occasionally, and they have been pretty accurate lately, but I‚Äôm honestly sick of them jerking off ‚Äúbig Navi‚Äù. Sure, the leaks about Zen 3 were right, but it was a slightly better improvement than Zen 2 was, so believable. I do not believe that Radeon will have some ‚Äú3080 killer‚Äù. People had doubts they would have a 2080ti killer. I really hope I‚Äôm wrong, but the hype for no reason by these channels is annoying.",
      "The surface of the fan hubs look amazing, pretty much the only thing I'd change about the render would be to make the radeon logo emissive just to give it a little glow on the surrounding areas",
      "> and they have been pretty inaccurate lately\n\n\"Lately\" isn't the correct word to use here.",
      "No wonder why you gave yourself a dog's name...",
      "Damn, somebody has some sand their vagina...",
      "What card did you use for the render?"
    ]
  },
  {
    "brand": "amd",
    "generation": "6000",
    "tier": "low",
    "matched_keywords": [
      "6600"
    ],
    "title": "AMD Radeon RX 6600 XT allegedly launches in August - VideoCardz.com",
    "selftext": "",
    "comments": [
      "What the article doesn't mention is that \"$399 MSRP\" is pure speculation on Coretek's part. He specifically says there's \"no word on pricing yet\".",
      ">To be fair, you can't find those GPUs at MSRP as well, and there's no guarantee you will ever find them at MSRP ever again.\n\nBased on 6700 XT's pricing, there's no chance this costs less than 349$, sorry.\n\nPC gaming is not value oriented anymore.",
      "$399 is a bullshit price for a low-tier GPU.\n\nthat is about 33% more expensive then the RX 480 which was a mid-tier GPU!",
      "Funny thing is AMD don't have the features unlike nVidia to charge more than them, if you've got the option of buying at RRP 80% of users will still go with nVidia, even when AMD beat nVidia on price with the R9 290 vs GTX 970 many people went with the 3.5GB GTX 970 that was slower while costing more.\n\nAMD has to be careful with pricing, the good will they've gotten from consumers can easily be lost, bought my 3700x to support AMD even though I could've gotten a 10900k but wanted to change, hope Intel come good again for some real competition once again to keep AMD honest.",
      "$400 would be awful. That card is not worth this much. I won't pay more than $300 for it. And if you do pay more than $300 for it, then you are partially responsible for the market being bad.",
      "$399 would be a horrible price. It's sad to see AMD take advantage of the current market like this",
      "Thanks for adding this, I don't watch Coreteks so wouldn't have known. $399 would be garbage pricing for a card like this (I mean, when else have you been able to pay like 50% more to get nearly double the cores, double the VRAM, etc, like this looks vs. the 6800 MSRP..?).",
      "Ya mean \n\n>\"Rdna2 tops out at 2080ti performance and i'm tripling down on it\" \n\n>\"Rdna3 is gonna have only 40% performance increase over 6900xt\"\n\n> -Coretek\n\nand \n\n>\"Nvidia jebaited amd to think they need only 2080ti performance. My aib insiders confirmed it\"\n\n> -Videocardz\n\nThose dudes?",
      "My rx 570 wanna die amd \n\nMy current hope is a 3060 6gb or 3050ti ‚Ä¶.",
      "And what's even worse, I guarantee you that in September, you will see at least one post like \"RX 6600 XT is amazing!\".",
      "400 dollars is a joke. AMD is scamming people at this point",
      "5600XT succesor for 5700XT pricing that should have been cost 249\\~299?\n\nThats when AMD GPU market share goes from barely existing to not existing for all budget majority AMD fans. \n\n\"84% buys only 300USD gpu\" - AMD words\n\nBye AMD and Radeon group.",
      "unfortunately me too, i refuse to getting shafted by gpu companies. Used market is a alternative aswell, a lot riskier but plenty of deals going to appear on the market soon. I hope so atleast.",
      "From what I found, the MSRP for the RX 480 8 GiB was $‚ÄØ239, so that‚Äôs almost 67‚ÄØ% more expensive, not 33",
      "There wont be any 3060 6gb",
      "\"Corporations have more power than the government. The old rules no longer apply\".\n\nI'm pretty sure they're pulling a 5700 XT here (how ironic, considering the performance), \"taking our feedback into consideration\" to only release this RX 570 4GB replacement at 349$ instead of 399$ - which is still ridiculous but people will swallow it much more easily.",
      "RX 5500 XT offers no better value whatsoever for 480/570/580 owners. Same performance/price as in 2016/2017.",
      "5700xt was the successor to rx 480 and it costs 2x",
      "This is the worst time to buy a graphics card ever. The future doesn't exactly look bright, but it looks a helluva lot brighter than the present.",
      "So a $400 MSRP for a card roughly on par with a $330 card. Cool.\n\nPlease, sir, may I have another?"
    ]
  },
  {
    "brand": "amd",
    "generation": "6000",
    "tier": "low",
    "matched_keywords": [
      "6600xt"
    ],
    "title": "R5 5600X - RX 6600XT",
    "selftext": "",
    "comments": [
      "That's a sweet build!\n\nI'm curious, what are those characters on the bottom part of the cap?",
      "It's Thai alphabet, still can't do touch type on this.",
      "No, 500W is more than enough for this build. The CPU max out at 75W and GPU is 148W.\n\nCurrently I've only one M.2 drive on the M/B but I can fit 2 SSDs into the case.",
      "The GPU and CPU pull 220w together. I think he'll be fine even if he manages to shove 10 drives into it.",
      "How noisy is the Flex ATX PSU? I've been considering a SFF build that uses one of those, but from what I've heard they're either mostly fine but noticeable or extremely whiny.",
      "wtf are you talking about? 500W can supply even R7 5800X + RX 6700XT no problem with still optimal 80% load, as long as it's good quality PSU. Not to mention PSUs peak their power efficiency above 50% load :) In this case expected load is around 250W - so tell me, how on earth this is underpowered PSU? Are you one of those people using 850W in mid-range level builds?",
      "The one I'm using is Dark Forest, it's not too noisy comparing with other FLEX PSU I've used. I think the fan run at 6500-8500 RPM. The Thermalright AXP-90 CPU cooler is louder.\n\nIf you're looking for the most quiet Flex PSU, it would be Silverstone FX600, that one the fan spin at only 1800 RPM.",
      "I also have Pluse 6600XT, it's exactly the same cooler as Nitro + but it runs 6C  cooler due to  more aggressive stock fan curve.",
      "Pluse and Nitro+ have identical score in benchmark, but Pluse is 45 USD cheaper.",
      "that's because your system would eat ~70W more, and any OC on GPU or Even PBO can push to 100W more. RX 6700 XT is 230W TDP, yours is 295W TDP - that is quite a bit of difference.",
      "You can view the build BLOG here https://en.minicomputers.net/post/gecko-xs-flex-psu-pc-case",
      "Damn is that flex unit crammed with barely any space for cables on the bottom.... Would be better if they used an sfx unit",
      "needs some more 7nm power like a 6950 xt",
      "Your welcome",
      "Yes, DDR 4",
      "It's 92mm slim fan. The P12 won't fit. But I have Noctua A9x14 Chromax, I'll swap that later.",
      "I manually set the fan curve for CPU so it's not noisy with slight load. But the Flex fan is audible.",
      "I use it with 2k monitor, +200 on CS GO and max out 165 Hz screen refresh rate on most lower end FPS game.",
      "Is that you, Mini Me?",
      "I want to do a similar build so bad"
    ]
  },
  {
    "brand": "amd",
    "generation": "6000",
    "tier": "low",
    "matched_keywords": [
      "6400"
    ],
    "title": "G.SKILL introduces DDR5-6400 CL30 2x48GB low-latency memory for Intel Z890 and AMD X870 platforms",
    "selftext": "",
    "comments": [
      ">CL30-39-39-102\n\nThe values after CL (TRCD, TRP and TRAS) are quite high. So slower than current kits on the market right? \n\nI know Cas Latency on DDR5 aren't significant in gaming performance (small FPS difference), but the other timings have more impact.",
      "You mean 96GB.",
      "Where can we buy it?",
      "That‚Äôs what I NEED to know. They keep posting about it. Is it for sale or no?",
      "Dual rank is way harder stabilize than single rank. The same can be seen in dual rank 64gb kits, also hitting 8000mhz is essentially impossible on dual rank kits currently.",
      "That‚Äôs the neat part, you don‚Äôt. Just like cl26 6000mhz. At least not yet.",
      "the M and A die are getting good lol. \n\nJust a few more years and we should hopefully see some 7000+ for AMD on the new memory controller.",
      "From what I understand 8000 MHz is possible with CUDIMM DDR5 kits for latest Intel motherboards.",
      "With respect to Hynix A-Die specifically, some XMP kits run at 1.5V out of the box, 1.55V doesn't seem super high to me. From what I've gathered the consensus in overclocking communities it you should avoid exceeding 1.65V for daily usage, but YMMV. You'll want a fan blowing on your RAM if running at 1.65V to prevent errors caused by high temps.",
      "here is values of previous 24x2 48gb kit DDR5-6400 CL32-39-39-102 1.35V . They give safe values for timings. Important one is how far can you push on overclock. my 24x2 kit is set to CL28-38-36-72 at 1.55V. Real question is this kit capable cl28 at lower voltage or cl26 at 1.55V",
      "It just says Q1 so they probably haven't launched them yet",
      "How long have you been running the kit at 1.55V? Do we know the safe maximum voltage for Hynix M/A die? 1.55V seems really high.",
      "I would love this kit, where is it lol",
      "Waiting for buildzoid to review these and talk about them for 3 hours straight.",
      "Lol.. he has a video up actually üëç he took cl26 kit and ran it at 8000, cl30 I think it was.. he hadn't done stability test yet, but maybe now he's got an updated video.. I think I'll check, hahaüòÖ",
      "I expect zen 6 to be able to do 8000 at 1:1",
      "C28",
      "96 but 4 held back for iGPU?",
      "There are 8000mt/s sticks that are on the QVL list for my AMD motherboard",
      "You don't need cu dimms for 8000. You just need good binned a die ( to make your life that much easier ) such a the xtreems 8000 or 8200, and great board with amazing training and a non dogshit imc."
    ]
  },
  {
    "brand": "amd",
    "generation": "6000",
    "tier": "low",
    "matched_keywords": [
      "6600"
    ],
    "title": "Can someone help identify this GeForce 6600?",
    "selftext": "There isn't any sticker who manufactured it, I can't read VBIOS because I don't have compatible ROM reader and GPU doesn't power up.",
    "comments": [
      "Ah, a most intriguing conundrum you have presented to us! After an exhaustive and most diligent examination of the evidence at hand‚Äînay, after peering into the very depths of technological history itself‚ÄîI am left with but one inescapable conclusion. Brace yourself, dear OP, for the revelation I am about to bestow upon you may shake the very foundations of your understanding: it is, with all certainty and beyond the shadow of a doubt, a GeForce 6600. I do hope this revelation serves you well in your noble quest for knowledge.",
      "Looks like a geforce 6600 to me",
      "I would show you a zoomed in photo of your capacitors popped but it doesn‚Äôt allow it",
      "This is a Redditor",
      "Yeah, you're right. It's Forsa but non-GT and 256MB variant",
      "Happy to help",
      "Fired capacitors, it's a waste of effort.",
      "Its a Forsa 6600GT 128MB DDR",
      "This exact heatsink screams Forsa. They made GPUs since about 2001 and up until Nvidia Pascal architecture, then they stopped. You'll see a number of these Geforce 6600 cards, some in GT variant, from versions A and B like yours, up to version I.",
      "rozpierdolona",
      "lol those caps look like shit",
      "I believe it's GeForce 6600",
      "Aside from the blown caps, a gpu not posting is mostly related to a missing voltage",
      "Caps are messed up. Writing in tape shows something like ‚Äúdamaged‚Äù. Cooler is in style of asus cards but without decorative cover. Repair is for 3-5 hours of life messed. Value - 0.15$. Nice Thinkpad tho",
      "This guy definitely GPUs",
      "Tldr: GeForce 6600 confirmed!",
      "No way. I didn't know this",
      "It s the X on them?",
      "I'd imagine OP knows, the sticker on the back says it's damaged.",
      "Talk about ancient"
    ]
  },
  {
    "brand": "amd",
    "generation": "6000",
    "tier": "low",
    "matched_keywords": [
      "6400"
    ],
    "title": "[HUB] Tiny RDNA2, The Best LP Single Slot GPU: AMD Radeon RX 6400 Review",
    "selftext": "",
    "comments": [
      "its only competition in single slot, low profile, no external power gpu space is the gt 1030. it better fucking win lmao (iirc there is no single slot low profile gtx 1050/ti/1650, there are single slot but tall, and low profile but 2 slots, not both together)\n\nedit: forgot about the quadro Ts and WXpro line oops but theyre also more expensive for similar performance.",
      "Nvidia is overcharging for the 1600 series so AMD has free reign to make a huge margin on its products. The cheapest 1650 at Microcenter is $210 and goes up to almost $300. The cheapest 6500XT at Microcenter is $200 \n\nAMD is getting so much bad press with the PCIe nerf that Nvidia basically ignored it. I believe we needed AMD to lower the price enough to justify the card on its own and only then would the space become competitive again.",
      "Problem is - the use case involves proprietary office PCs that are basically all PCIE 3.0 by which this card gets massively gimped in already quite disappointing performance under PCIE 4.0. Also the price is absurd for what it is - you buy cheap office PC on some sale - and have to then pay very NOT budget figure for superiorly basic GPU. It would make whole another sense, for example, at $100 msrp.\n\nIn other words - market is nuts, and especially in ultra budget segment - it's completely unreasonable.",
      "The only sensible use case I can think of is someone want to build a low profile entry gaming machine, you basically cram a i3 12100F with 6400 and you will get playable performance, as for whether such niche actually exist or not.... well lets see what the actual street price of the monstrosity would be.",
      "Another use case scenario: having a secondary lower power single slot GPU to drive Linux while you pass the much more powerful GPU to windows vm to game with. Currently doing this with a Gt1030 and a Rtx 3080",
      "Complete garbage. Performance in pcie 3.0 comparable to the 1050ti that uses around the same power and it's like 5 years old",
      "The issue is that if you put 6400 into pcie 3.0 system it will get cancer, and I imagine most 560 equipped system is pcie 3.0 base.",
      "Paper specs mean jack shit, power consumption in game is measured in the video and the results are near identical between the 1050Ti, 1650, and 6400.",
      "Until PCIe 4.0 is standard and this whole issues becomes moot, it will never go away. The old ‚Äúoffice PCs‚Äù might die, but ‚Äúnew‚Äù (off-lease or retired 3-4 yr old) ones are constantly showing up for purchase by home users.\n\nFor example, Dell is still shipping the Optiplex 7090 SFF. The available 8c/16t i7-10700 will be relevant for years and the system only supports PCIe 3.0.",
      "6400 (and its similarly cursed sibling 6500XT) both have pcie 4.0 x4 connection, thus only accessible to pcie 3.0 x 4 speed in pcie 3.0 base system, moreover, 3080 have 10GB as buffer, 6400 only have 4GB, the less buffer you have, the more pronounced will the loss of pcie bandwidth be felt.",
      "There is an RX 560 4 GB GDDR5 single slot/low profile from Yeston. Not sure how that would compare to this 6400, but I guess the 6400 might beat the 560 in a Pcie 4.0 system and the 560 would win in a Pcie 3.0 system.\n\nEdit: Based on comment replies before, it looks like the 6400 is definitely better in almost all gaming use cases.",
      "That is a good point. The RX 6400 does have the advantage of having proper open source drivers. Before that your \"best\" option for that use case was to get an RX 550/560.",
      "It baffles me that even on recovering market, AMD still has enough greed for them to release a overpriced product like this.\n\nHeck even on the worst market this product still makes absolute no sense, as a used GTX 1050 Ti just costs around $80 - $100 anyway compared to this which will cost $160 - $200 at least basing from my own country's market pricing back on mid 2021 where i managed to get a 1050 Ti for under $100 as a backup temporary GPU.",
      "If +18% and 53W are the same perf and power as the 75W 1050Ti, then yeah.  If not, then no.",
      "Msrp should have been 80$",
      "Honestly I'm very curious how long these old office PCs will be relevant. With CPU performance finally leveling up and getting a good 15-20% uploft per generation the old CPUs are seriously starting to hold you back. Especially as these system are also getting quite long in the tooth, so they'll start dying left and right sooner or later.",
      "There is asl g1504, a gtx 1050ti single slot low profile card.\n\nAnd there's yeston rx550.",
      "> Nvidia is overcharging for the 1600 series\n\nHow do you know that it's the fault of Nvidia? It could easily be the fault of the retailer.",
      "There's also the ASL GTX 1650 War Knife: https://videocardz.net/asl-geforce-gtx-1650-4gb-war-knife",
      "Apparently they do. The video shows decent drop in performance when changing from 4.0 to 3.0. I wouldn't think they'd saturate it either, but I guess they do, situationally."
    ]
  },
  {
    "brand": "amd",
    "generation": "6000",
    "tier": "low",
    "matched_keywords": [
      "6500xt"
    ],
    "title": "Price of 6500xt is close to 450‚Ç¨ in Greece!",
    "selftext": "",
    "comments": [
      "I hoped I could get it as a temporary solution cause my GPU is dead but 450‚Ç¨ is clearly ridiculous.\n\nHope by summer we get better prices as Ethereum gets to POS",
      "When/IF Ethereum goes proof of stake, miners will just move to the next crypto. People seem to forget that Bitcoin was originally mined on GPUs, then asics came and ended that, miners moved to Ethereum and other cryptos.",
      "I swear you could put a pci-e slot on a pile of real dogshit and sell it for 400 Euros / $300/usd plus.",
      "Don't underestimate the stupidity and greed of crypto dickheads",
      "I swear to god an Xbox Series S is just 250 atm. For 450 I could get that and Gamepass for 20 months",
      "Actually (and I know I probably being a bit pedantic here), but bitcoin was originally mined on CPUs (it‚Äôs been around for a long time). It was developed on 2009. At the end of 2010, GPUs took over, then of course FPGAs and ASICs.",
      "Yeah but it would take years to catch up with Ethereum in terms of profitability",
      "Didn't think it was possible to beat a worse priced card than a 3080Ti, but here we are!  \nSituation is completely fucked!",
      "Bro u just proved urself wrong",
      "Looking to trade my 5600 XT with a 2 bedroom apartment and a cat, PM me with your offers",
      "The balkans have fucked prices but im sure OP can get a series S and some months of game pass for that money.",
      "RX 580 8GB goes for 450+ EUR",
      "Kalitera pare Xbox or PS5. Don‚Äôt it. Crappy card. Super malakia me 4GB kai xoris hardware acceleration.",
      "You're missing the point you doughnut",
      "Good luck building a pc that can play games like a Xbox series S can for 450 lmfao xDD",
      "At one point in around 2010 I went to college with someone who was mining bitcoin on their macbooks cpu, they had something like 20-30 bitcoin at one point and sold it all when the value got to about ¬£30 a coin...",
      "The Xbox series S in Greece costs 275‚Ç¨. I know that cuz i consider buying one right now",
      "900¬£ in college is not bad to have though.",
      "PoW crypto dickheads*",
      "Of course. If AMD wanted to sell these for $/‚Ç¨200 they would order millions of 6500XT ref cards and set a maximum retail price\n\nIt‚Äôs obvious AMD (like Nvidia) doesnt give a shit"
    ]
  },
  {
    "brand": "amd",
    "generation": "6000",
    "tier": "low",
    "matched_keywords": [
      "6600xt"
    ],
    "title": "Just switched 6600xt for 6900xt",
    "selftext": "I don't know what's more wild, performance boost, size of this beast or fact that 6900xt still can get kick 4070s/ ti ass in raw  performance lol. ",
    "comments": [
      "Why does your 6600 XT have a knob on top right ?",
      "I thought that's obvious. Fan control!",
      "Sounds kinda bullshit. 6800xt should be happy with 750w .",
      "Are you sure that you made a good deal? \nLooks like a keyboard to me",
      "I did this same upgrade. Pretty good performance boost",
      "If you got it used I think it was a good deal, new I don‚Äôt think so, but definitely the 6000 series ado be aging great on the used market",
      "What keyboard is that?",
      "I've bought a 6800xt red devil second hand, but it won't display :(   \nI can hear windows startup sounds through my headphones, but I have no image.   \nSeller told me he had the same problem and fixed it by buying a 850W PSU, I've got a cheap 750",
      "Sick!",
      "The best part is that it is compatible with macOS!",
      "I know the 6900XT should be more efficient and lower power, so I hope you have a better experience. \n\nMy Asrock Phantom Gaming 6950XT has been the worst card I've purchased in a long time. The fan closest to the PCI-E bracket wobbled, then stopped working, and I had to strap a 120 mm case fan to it. Now the middle fan wobbles and will stop turning sometimes. Can only lower the power usage 6% making it hard to keep temperatures reasonable and I've already re-pasted it.",
      "Yup. Pre owned with changed thermal paste + pads.",
      "Cooler master ck 720",
      "I mean, not having a powerful enough PSU could make this problems show up, also not every 750W PSU is the same, mine is a cheap one, so I'm not very confident on it, also Powercolor suggests a 850W PSU. If it still doesn't work I can still sell it as broken and still get some money back",
      "It's mechanical"
    ]
  },
  {
    "brand": "amd",
    "generation": "6000",
    "tier": "low",
    "matched_keywords": [
      "6600"
    ],
    "title": "Should I buy a PS5 or a RX 6600 XT",
    "selftext": "Trying to figure out on which I should save for, and im having a second thought on which I should buy first\n\nI'm saving for the RX 6600 XT so my pc will run much smoother on high end games (since I already got high end games on my steam library but my CPU can't run them alone)\n\nbut for PS5 I wanna try a Console (and just wanna play DBZ sparking zero) since I never had a console before, aside from the switch but I don't really use it\n\n  \nWhich is more worth the price?",
    "comments": [
      "Counterpoint, my AMD cards have always been fine.",
      "Counterpoint, my AMD cards have always been fine.",
      "AMD GPUs are currently the best overall in terms of fps/$ and are comparable to similarly priced Nvidia GPUs if not better in some cases. The 6600xt is not the best but if he have the budget for the PS5 I recommend at least the 7600xt/6650xt or 6700/6700xt",
      "Probably bad luck man\n\nI've had issues with both amd and nvidia",
      "Maybe it's a you problem?",
      "Actually I've bought a few, some used, some new, gave a rx 580 to my friend, best thing he's ever had, had problems at first when windows amd everything would just get corrupted for no reason, changed his motherboard with one of mine, and he's been golden ever since.\n\nLike i said, more often than not, it's a compatibility issue or bad hardware, luck can be funny sometimes.",
      "For me l choose PC as l got a great deal last year for 3060ti new for a price even lower than 6600xt now. \n\nI was considering between PC and PS5 and cheap parts l got for great deals sway me to PC again. Also PS5 are more expensive than normal in my region. My old pc can't really game anymore and l have been gaming on series S bought during the GPU,series X and PS5 shortage scalpers period.\n\nAs you still can play most former PS5 exclusives and those that are not one yet will be eventually. Unless you really have to play exclusives on day one then get PS5.",
      "Wrong, either it's a user error, compatibility problem somewhere or you got a bad card. Never had a problem with my 6600xt, going for 7900xt soon",
      "I got the 6600xt when i sold my Xbox series X, no regrets whatsoever, better bang for your money, outperforms the Series X and PS5 it's not even close",
      "I would recommend if you really wanna play some games that come out first on console (like GTA6 next year for example) but for multiplatforms I would stick to the PC. It really depends on what  you wanna play at the end.",
      "I'd definitely gor for a pc but that's me, 6600xt is similar to ps5 performance with lower vram, maybe go for a used 6700xt",
      "almost all or all games, that release on the ps5 are also going to release on pc after a year or so.\n\nso i would rather recommend to just NOT get a ps5 at all and instead get a better graphics card instead than an rx 6600 xt.\n\nwhat makes the ps5 special and worth getting? it isn't the games, as it is just a waiting, until you get them on pc anyways.\n\nif you want to play online with a ps5 you also have a subscription you gotta pay for it. sth, that the pc community wouldn't accept, because we got choices here, so that won't work.\n\nthe rx 6600 xt also has a major issue by not having enough vram.\n\nthe rx 6600 xt has less vram than the ps5.\n\nthat is if we normalize for the unified memory, that is available to a game for the ps5. the ps5 has 16 GB of unified memory of which 12.5 GB can be used for the game alone.\n\n12.5 GB unified in a ps5 translated to a 12 GB vram requirement roughly. we know this by people benchmarking hardware including hardware with different vram, but otherwise the same or almost the same gpu power.\n\nso i would recommend to you, if it fits in the budget to get a new 350 us dollars (on newegg available for example) rx 6800 with 16 GB vram, or wait till q1 2025 to get an rdna4 16 GB vram graphics card, that will match the ps5 pro the closest in features.\n\nthere is also the rx 6700 xt/6750xt, that has at least 12 GB vram.\n\nand again from my understanding, the ps5 controller works just fine on pc and the games from sony and playstation come to pc eventually. so just take some of the money for the ps5, which isn't cheap with blu ray drive + stand + subscription to play online, and get a better graphics card and you get the bettter experience overall for cheaper overall (compared to buying both) and have a great time and just buy dbz sparking zero on pc.",
      "Do you want to play GTA VI same year or do you want to have a kick ass computer? Your choice.",
      "You can play DBZ on PC ? But for the price of a PS5 even a used one you could get a 7800xt or a 7900 GRE especially if you're willing to buy them second hand",
      "DBZ sparking zeroq",
      "All I wanna do is play DBZ sparking zero all day",
      "My PC is Ryzen though",
      "Skill issue",
      "Just switched from NVIDIA to team red and holy my 7800xt runs amazing. Great temps, no crashes, runs everything as expected ie it absolutely crushes games at 1440p (competitive games like warzone I get easily around 200fps; Star Wars Jedi Survivor I get ~100+fps w optimized high settings, often more depending on the location).",
      "Isn't that game on PC too?"
    ]
  },
  {
    "brand": "amd",
    "generation": "6000",
    "tier": "low",
    "matched_keywords": [
      "6600"
    ],
    "title": "Unpopular Opinion: At the moment, the 6600 XT is one of the best value cards on the market.",
    "selftext": "Let me get this started by saying I dont like the MSRP either. You're basically getting a 5700 XT for 5700 XT prices. This is not generation to generation progress.\n\nBut... In the current market we're in, MSRP is almost meaningless. All the negative reviews and comments from everyone on launch for the 6600 XT seemed to have forgotten that the 3060 and 3060 Ti are virtually impossible to get for MSRP. The 3060 founders doesnt exist and I have yet to see **anyone** get one for its MSRP price. I have seen the occasional 3060 Ti for below 500, but they're extremely rare.\n\nAt the end of the day, it wouldnt have mattered if AMD set the MSRP at $379 or $250, the price is dictated by the supply and demand. What we have here is a realistic MSRP which matches the current market.\n\nBy the looks of it (at least here in the UK, the sapphire pulse has been sitting at ¬£375 **in stock** all day at overclockers) the 6600 XT has immense supply. Many retailers have received more 6600 XT's than **all** Nvidia cards put together over the last week.\n\nEveryone was saying the 6600 XT is the end of the budget card. But I would argue otherwise. The 6600 XT has been by far the easiest card to buy at near its \"MSRP\". To the point where it will start pushing down RTX 3060 prices. Even if the 6600 XT only matched the 3060's performance, the fact that almost everywhere it can be found for $100-200 less is definitely taking away some of demand from the 3060.\n\nRight now, we simply need prices to drop. Not crazy low MSRP's that wont be achieved. And the 6600 XT is the card doing that.\n\nSure, lets say 6 months from now the 3060 and 3060 Ti can easily be had for MSRP, yes the 6600 XT is bad value. But who honestly thinks it wont drop in price? Remember what happened with Vega? A $400 Vega 56 and $500 Vega 64 were going for as low as $250 and $300 respectively, just over a year after release. I would not be surprised if we see this happen. Heck, I managed to pick up a Vega 64 Nitro+ brand new from scan for ¬£250 in 2019.\n\nThe reason as to why the 5700 XT never dropped in price was because it was so competitive to start with. It punched in the same performance tier as the 2070 Super, a card which cost more than $100 more. The 5700 XT had no reason to be cheaper.\n\nTLDR: The 6600 XT is *currently* our saviour. Not the enemy.",
    "comments": [
      "I do agree in the context of 'need something badly right now'.\n\nThe 1660TI , 1650, 2060, 5600xt, 5700xt, 3060 etc. are all crazily high priced right now. The 3060 Ti is near double in many cases here in the UK. \n\nNot sure how prices will look after a month though?",
      "In a market where used Polaris are north of $300, a $379 card with 3x the performance is a no brainer. It's disappointing that things are like that, but it's a harsh reality.",
      "Considering it's almost half the price of the 3060 Ti here yes, even though it's still above MSRP.",
      ">MSRP? The fuck is that?\n\nMostly Satirical Recommended Price",
      "For who? Few countries? Rest of the world dont have any chance for founders at msrp.",
      "Agreed about the 6600XT. If you can get it at MSRP it‚Äôs not bad at all. All the 3060‚Äôs I‚Äôve seen are $500 or more. People just wanted a $250 card I guess",
      "In Aus, the market is absolutely, completely fucked.   \n\n\nRight now, I can get a Sapphire Pulse for around AU$599. This compares to a 3060, which is DOUBLE the price. It's a no brainer.\n\nI'm just hoping that there's still some in stock by the time I get paid.",
      "Thank you for the constructive take. Comparing by MSRP is simply missing the point, it's the actual prices that one is paying that matters.\n\nIt's a similar concept to buying a property, which has a government assessed value that is often different from the real market value. You won't see people basing their purchases on the government assessed value either, as that isn't the amount they will be paying.",
      "At the moment, it is at MSRP. In UK and AUS at least. At the moment, ofc.",
      "Not for those of us that can't afford to toss money around endlessly it isn't. That's exactly why I care about making sure my purchase lasts.\n\nLike who in their right mind would spend several hundred dollars on building a new computer just to make a gimped and overpriced GPU a little less gimped?",
      "What a bullshit statement. Boards running only PCI-E 3 are still able to push CPUs that‚Äôll last well into the decade. You can‚Äôt tell me a 10900K or whatever isn‚Äôt going to fly through everything for years and years.",
      "Woah there, thank you for bringing me to my senses. Just checked and in my country, the 6600XT is basically the only card I can find at 10% off its MSRP.\nPrices are so jacked that I had scratched my \"build a PC in 2021\" plan and was already planning to buy a laptop. This card makes building a PC feasible now.",
      "I know it's hard to get into the minds of people who don't live in the world of trust funds and the bank of mummy and daddy, but some people don't build new systems every time they buy a new GPU. I'm just replacing an old, dead graphics card and looking to get something I'd want to use, and that won't fall badly behind because of a stupid limitation.\n\nAnd using that logic even high end GPUs are gimped because they could always carry more memory, have bigger dies ETC but that isn't the point here. I don't expect them to perform the same as top end cards but design decisions that reduce performance to save a couple of bucks on substrate to me are not a necessary compromise, that's just AMD being cheap.",
      ">By the looks of it (at least here in the UK, the sapphire pulse has been sitting at ¬£375 in stock all day at overclockers) the 6600 XT has immense supply.\n\nAlternatively, they don't have immense supply and there isn't much demand. We have seen that people are more willing to pay up for green cards than red cards, and people are more willing to pay up for top end cards than low end cards.\n\n>Right now, we simply need prices to drop. Not crazy low MSRP's that wont be achieved. And the 6600 XT is the card doing that.\n\nYup. Any card AMD is willing to produce in volume is great news for the market.\n\n>Sure, lets say 6 months from now the 3060 and 3060 Ti can easily be had for MSRP, yes the 6600 XT is bad value. But who honestly thinks it wont drop in price? Remember what happened with Vega? A $400 Vega 56 and $500 Vega 64 were going for as low as $250 and $300 respectively, just over a year after release. I would not be surprised if we see this happen.\n\nIt strikes me that the 6600xt is bad value at MSRP. Of course, if its street price stays close to MSRP, it's far from the worst value on the market. It remains that very few gamers should be buying at market prices, particularly since this card is basically a half-gen card in terms of release cadence.",
      "If you want to argue that it's the least crappily priced card, maybe. But as someone who will be impacted by the decision to cheap out on PCI-E lanes I'll wait for a 3060 I can afford.",
      "Looking at the issue with Doom Eternal tells me the future. It loses 25% performance in 3.0 x8 mode which puts it behind a 3060. With the new consoles carrying 16GB of memory games are only going to get more memory intensive, so I don't expect this card to hold up well, as someone who doesn't upgrade regularly that would be a problem for me.",
      ">At the end of the day, it wouldnt have mattered if AMD set the MSRP at $379 or $250, the price is dictated by the supply and demand. What we have here is a realistic MSRP which matches the current market.\n\nTell me you know how capitalism works without telling me that you know how capitalism works. \n \nPricing is not mathematical, it's social, prices are determined by *perceived* value.  Is the 6600XT a good value? Maybe not. Is it a good value *in the current GPU market?*  Unfortunately, yeah, it is. \n \n>\"You should buy a 3060 or a 3060Ti instead.\" \n \nThat just *isn't* a viable option right now, it probably won't be a viable option for months to come.",
      "Like an AMD card is going to be priced more reasonably than an Nvidia card in thsse climates. Especially not when it's supposedly a great mining card.",
      "Yup it's currently $200-$300 dollars cheaper than a RTX 3060, so I bought a 6600xt this morning for $700 inc gst.",
      "Well, considering the 6600 XT has been in stock all day **and** is incredibly efficient at mining, wouldnt that suggest that it does have high supply?\n\nAlso, many retailers have come out and said that supply is very strong."
    ]
  },
  {
    "brand": "amd",
    "generation": "6000",
    "tier": "low",
    "matched_keywords": [
      "6400"
    ],
    "title": "AGESA 1.0.0.7b Gaming benchmarks: DDR5-8000 CL 38 1:2 vs 6400 CL 26 1:1",
    "selftext": "&#x200B;\n\n[Testing was done with  7800X3D PBO, -30 CO on all cores  watercooled 4090 with galax bios, 666W power limit, +100 core, +1000 mem  fixed fan speeds](https://preview.redd.it/scw50vhglcdb1.jpg?width=1454&format=pjpg&auto=webp&s=126d63f5aa5a68f58b7000a49d8f73c5670f50f9)",
    "comments": [
      "looks like margin of error... but tbh this is probably because of the extra cache. Would be interesting to see the same test done with a 7700x instead.",
      "I mean I guess I'm glad there's no change so I dont feel compelled to blow money on faster ddr5.",
      "I‚Äôm really curious if running 2:1:1 MCLK:FCLK:UCLK makes any positive difference here. If Zen 5 supports these kinds of speeds in Gear 1, it‚Äôd be incredible.",
      "Thanks for the kind words. A lot of dedicated engineers worked to pull this off.\nTo me, this is good to show that if you're running DDR6000-7200, you've got lots of headroom and margin for good stability.  For now, I'll be running 7200CL32 with FCLK 1800 (1:1:2) - boot times are excellent and gaming has been flawless.  Take care!",
      "Not exactly true. Latency will remain the same between those two settings, but a higher speed means higher bandwidth, so 8000C40 is preferable to 6000C30.",
      "It will be similar: https://img2.quasarzone.com/editor/2023/07/21/60c0d651bdad4574ff5cbe98139b2005.png",
      "This.",
      "The memory controller is reasonably fast, but you run into the limitations of FCLK which starts to impact the latency.  I have a Cezanne system in my rack running DDR 4400 24/7 (FCLK 2200 is easy since there is no GMI), and running 4600-5200 on air/water is perfectly reasonable with a bit of luck).\n\nFor a while we did have the DDR4 frequency world record. I worked with Micron and OGS, and provided some CPU samples for Matisse and Renior (Zen2) to get it done. Zen3 Vermeer had the same IOD / memory controller.",
      "Damn those are some insanely tight timings on the 6400CL26. Which configuration was easier for you to stabilize?",
      "Simple, they never claimed to be stable. Buildzoid always does extensive stress tests before he says something is stable. Most reddit overclockers don't.",
      "I'm currently running the Asrock Taichi x670e (already had Asus x670e Hero; will cycle through all the brands for home dogfooding over the next 8-12 months).  Both of these boards are DDR7200 stable in my testing with several samples of each, and various CPUs.  As for 1DPC boards, it just depends on which tier/price-point. The Asus Gene can run DDR7200-7800 easily and you've probably seen >8000 on that one. I thoroughly tested it at 7600 and it was legit daily-driver stable.  I haven't had a chance to test many of them, but I'd generally expect x670/B650 boards to be faster than something like A620 just because the latter would likely have less PCB levels, and is less likely to use low/med-loss PCB material, among other design choices.\n\nAll of the x670e boards that I have personally tested are DDR7200 stable (mostly 2DPC boards).  I'm excited to see the new coverage and reviews that are surely coming over the next couple of weeks.",
      "I would recommend FCLK for gaming at 8000MT/s, which would yield 1:1:2 clock ratio.  For 6400, faster FCLK is fine.",
      "Anything with hynix chips cans do high speeds and they're available on cheap kits too. No need to spend much to get the best.",
      "I spent more time on 6400 CL26.   \nThe 8000 CL38 config isn't as optimized. Just wanted something stable (This has passed 10000% / 3 hours Karhu) for benchmarks. Primary timings are probably as low as they go in my case, secondary and tertaries have room for improvement I guess, but are way better than auto values.",
      "I have the kit that micro center was giving away with cpus for a bit. Gskill 6000 but cl36. I've tuned my 7700 but I just enable expo on the ram and called it a day. I'm just not experienced enough with ram overclocking and timings to really mess with it.",
      "Exceptional work there dude.\n\nI'm just looking forward to better overall memory support and also a fast boot option. My MSI MPG CARBON WiFi board doesn't have a fast boot option yet so it trains the memory on every boot which doesn't take as a long as the first initial train but still has quite long boot times compared to my old X570 board which booted in a mere 8 seconds to windows.",
      "Sounds like there's not much reason to go beyond 6000c30, then.",
      "As OP said, dual CCD will scale better. My 7200CL32 setup at home is >100GB/s for Read/Write BW. I'll try for DDR8000 1:1:2 next (that's why I installed 8000MTs rated modules afterall üòÄ ).",
      "I'm pretty sure my model has Samsung. Again I'm not super bummed about it.",
      "But only if you can run it in 1:1 sync with the memory controller."
    ]
  },
  {
    "brand": "amd",
    "generation": "6000",
    "tier": "low",
    "matched_keywords": [
      "6600"
    ],
    "title": "AMD Radeon RX 6600 XT review: solid 1080p performance, but falls away fast at higher resolutions",
    "selftext": "",
    "comments": [
      "Thats 128bit for you. Hurts at high res/qualy modes.\nRdna2 is sure great speedy arch for high refresh gaming at moderate/low resolutions, but stalls a bit when going gets tough.\n\nThat said, at current prices, its complete robbery.",
      "Yeah looks like a great card for $280 but paying more than $400 for this is absolutely ridiculous.",
      "Keeping my 580 8GB still!",
      "Honestly i think it's amazing what AMD's been able to do with a 128bit bus and 'just' 32mb of cache. I mean it keeps up very well with the 5700xt at 1080p and 1440p, which is a GPU with twice the bus width, and almost twice the bandwidth.\n\n>That said, at current prices, its complete robbery.\n\nYes, but it is the mildest robbery available at the moment. if you absolutely need a new GPU now, you can do a lot worse then this one.",
      "Will we ever again get a 1080P gpu at 250$ mark? These prices will kill me!",
      "Yeah, falls away at ultra details... I used RX580 to play @ 1440p and this will be muuuch better.",
      "In their defense, are those the compromises we should be making when we're paying $400 or more? Especially if we can't secure it at MSRP? I say that desperate to replace my reference RX 480. It runs hot and loud and I'm starting to come to terms with the possibility that if I want anything in the next year remotely approaching some pretense of value, this might be it.\n\nMy \"new\" 5600X has been hampered by my ancient GPU for almost a year now. I don't know that I have the patience for another. If I  wait, I'm facing the real possibility that the majority of my current computer's life will have been spent underutilized.",
      "China's Blockchain yuan (if it happens) will definitely not be associated with mining on consumer GPUs. China is interested certain benefits of Blockchain technology, but distributed and independent control of the financial system is not one of them.\n\nI also imagine that if they do roll out a digital currency, not only will it not be private or distributed, but they will also outlaw any type of competing digital currency that is.",
      "Yeah if it was at least less than 350 I'd go for it and upgrade my whole system. And when i eventually get a 1440p (or UHD) monitor i can get a new GPU down the line.\n\n  \n\n\nBut paying close to 4900 SEK (550 USD) is just not reasonable for a 1080p GPU i don't intend to use for myself very long.",
      "This should be a sub-$200 card.",
      "Yeah double the performance! *just bought earlier and replaced my RX580\n\nWhat the reviewers though havent tested or shown and now i am just finding out, is that lowering the setting to just medium with some high makes 1440P at high frame rates possible.\n\nI really want to compare it to a 3060 and 3060 Ti but the tests are at 1440P at med settings",
      "Looks like a great 1080p 144fps buy. It beats the shit out of 3060 and comes close to 3060ti at 1080p.",
      "Yeah. Infinity cache scales poorly. \n\nAt 1080p 32mb is roughly equal to an additional 128 bit bus making it equal to a 256 bit bus total, or what the old 5700xt had, but with faster 16gbps memory.\n\nAt 1440p it's more like 64 bit and, or 192 bit total which is still somewhat acceptable, and usable. \n\nAt 4k it's only acts like an additional 32-42 bit if you do the math, or like 160 bit total, which is why it chocks so hard.\n\nAt least that seems to be roughly what the AMD [cache hit rate chart](https://static.techspot.com/articles-info/2151/images/2020-12-03-image-4.png) implies.",
      "Same.   Wish the market wasn't this absolutely mad right now",
      "How much is a second-hand 5700xt or a 1080ti - I am assuming more than $ 380?\n\nThis seems to beat it in pretty much all tests, it sucks that the graphics card market is ridiculous but are people going to be able to get better performance at that price point in the real world?",
      "Thats why you wait. Paying $450+ for this crap isnt the way to go",
      "So these guys keep hammering the RT argument despite reviewing a (MASSIVE AIR QUOTES) budget 1080p card. Anyone with half a brain has noticed that with the market at the current inflated prices aiming for a tech that [barely changes](https://www.youtube.com/watch?v=nAfsJc_LNjU) the visuals of most games where it's implemented and is EXTREMELY RESOURCE INTENSIVE should not be advocated by any respectable reviewer. Were I buying a 1080p constrained budget card today, RT would be the least of my worries. Looking at the 100 most played games on Steam, it appears it's the least of everyone's worries. Nevertheless, DF continue to choose to use 6 NVIDIA sponsored games, give too much emphasis to RT, ignore that upscaling/reconstruction below 4K is REALLY sub par and more egregious of all, being called EUROgamer, ignore that the 6600XT is the only fucking card you can buy since launch throughout Europe without selling a kidney. Would I advise anyone buying it? Fuck yes, if you need a card and have the money and don't want to pay 150% MSRP, otherwise sit this, the 3060 and 3060ti out, they are absolutely garbage tier value historically, a fact which apparently does not merge well with the very NVIDIA friendly (heavily sponsored) DF editorial direction.\n\n&#x200B;\n\nedit: this should be, at best, a 200‚Ç¨ card. Fuck the current market!",
      "The 6600XT is basically the same performance as a 5700XT -IF you have it running in a PCI-e 4.0 slot. If you stick it in a 3.0 slot it‚Äôs slower than a 5700XT, so it‚Äôs actually less-desirable for the crowd that it should be aimed at (people holding on to their older cards and hardware as long as possible). \n\nPlus you‚Äôre paying the same price or more than a 5700XT cost right before the launch of RDNA2. I got my XFX THICC II 5700XT for $336 a couple months before RDNA2 launched for example. I reckon if the market weren‚Äôt compromised by crypto and the pandemic that the 6600XT would have been a sub-$300 card, and for under $300 it would have been a great buy. $380 for essentially a more flawed version of a 5700xt though? Years later? Yeah not so sure about that.",
      "Its over",
      "if you can find it at \\~3060 prices, its a no brainer"
    ]
  },
  {
    "brand": "amd",
    "generation": "6000",
    "tier": "low",
    "matched_keywords": [
      "6600"
    ],
    "title": "RX 7600 vs RX 6600 XT at 1Ghz (architecture test)",
    "selftext": "",
    "comments": [
      "Description API Overhead test from 3Dmark says \"Do not use it to compare graphic cards\" and \"You should not use those scores to compare systems or graphic cards.\".",
      "Doesn't RDNA3 have separate clock domains between shaders and front end, and the latter can't be changed by the driver? \n\nIf they only set the 7600's shaders to 1GHz while the front end is still on \\~2.5GHz, this is obviously going to give a massive advantage to the 7600.",
      "Compare different API's such as dx11/12 and vulkan for the given gpu.\n\n> Dubbed the 3DMark API Overhead Feature Test, this benchmark is a purely synthetic benchmark designed to showcase the draw call benefits of the new API even more strongly than earlier benchmarks. \n\n> . . . \n\n> The end result, as we‚Äôll see, showcases just how great the benefits of DirectX 12 are in this situation, allowing for an order of magnitude‚Äôs improvement, if not more.\n\nhttps://www.anandtech.com/show/9112/exploring-dx12-3dmark-api-overhead-feature-test",
      "So what does the overhead value indicate?",
      "So the 7600 is about 15-20% faster.  Just have to ignore the api tests as they are not valid for comparison of graphics cards",
      "In case of the RX 7600, the clock speed is synced between shaders and front end.",
      "It's to indicate relative performance between APIs on your PC. Judging by ratio between DX11 and DX12/Vulcan I think it test some scenario of being CPU-bound.",
      "Title says 6600, chart says 6650",
      "It indeed is likely clocked higher still. This would make rdna2's cache performance terrible compared to rdna3.",
      "Sounds like that feature that was supposed to be available in the Vega 56 but was never enabled. I do not recall what the feature was, other than it was supposed to boost performance.",
      "> So the 7600 is about 15-20% faster. \n\nWith 13,3/11,06=~ 1,2x the transistor budget. Which is pretty much what you would expect.",
      "You would expect rdna3 to clock higher though.  So IPC increase + clock speed increase should equal a bigger performance delta than what we are seeing right now.  Looks like finewine is back on the menu.",
      "Actually, the dual issue shaders take up relatively little space for the possibility of more shading throughput as only the small execution unit has to be doubled up (it scales well to smaller nodes), while leaving the scheduling and such largely the same. Also RDNA 3 does have quite increased performance per WGP so it is working, though the compiler is not optimal at finding dual issue possibilities.\n\n  \nNvidia also does the same thing although calling it just extra cores, when they made ampere so there must be some logic to it.\n\nAnd looking at the number of transistors, the 7600 has just a bit more than the 6600xt on a similar node, so the \\~15% perf increase is not bad from architecture ipc alone.",
      "It's technically interesting.",
      "Yes this is my mistake. I apologize.\n\nThe difference between the 6650 XT and 6600 XT is the memory bandwidth, the clocks (slightly) and power limit. And all 6650Xts are AIB cards.\n\nNow in this specific case it being a 6650 XT is good since it means the memory situation is close between the two. The 6650 XT has 280 Gbps, the 7600 has 288. Almost equal.",
      "Primitive shaders?\nWe use them since VII/RDNA",
      "Check the source link, the author mentioned that both frontend and shader are running at around 1GHz. The frontend clock is only \\~10MHz higher than shader clock.",
      "The point is to see what differences in performance come specifically from architecture.  Why this seems lost on so many people here is bewildering.",
      "Nice metrics! Can you add power draw or consumption please?  üôè",
      "Thanks for posting."
    ]
  },
  {
    "brand": "amd",
    "generation": "6000",
    "tier": "low",
    "matched_keywords": [
      "6600xt"
    ],
    "title": "I don't understand the people angry with the 6600XT MSRP",
    "selftext": "The GPU market is absolutely insane right now. \n\nA bit shy of 2 years ago, I bought a Sapphire Pulse 5700 for $370. This week, I sold it for more than $800. I could have sold it for more because it went in like 2 hours. Probably Could have gotten $860+\n\n$379 is too much for a midrange card, yes, in theory. In practice, these cards will be sold out at $500 as an incredible deal -- because that's almost what a used RX580 costs these days -- and you'll actually be seeing them sold closer to $600+, still being sold out.  I'm 100% going to buy one if I see a $500 price, because I'll get more performance than my 5700 and a few hundred in spending cash as the net result, even if the card isn't worth half of that $500 under normal circumstances. \n\nBoth Nvidia and AMD are selling every single card they make, and they're selling them way cheaper than their actual market value. \n\nBecause, again, $379 is way, way below market value for an 6600XT right now. \n\nHow are AMD or Nvidia greedy fucks for selling below market value? And why would it matter in the first place if the MSRP price is fake bullshit in the first place? \n\nI understand the people who are worried that this is the new normal, but those people are complete idiots. In a competitive market, prices aren't dictated by tradition or expectations. They are dictated by how much it costs to bring something to market (i.e. the margin) and the supply and demand for the thing being made. Supplies are constrained, demand is crazy stupid, the whole market doesn't make a single lick of sense in terms of the resulting prices.",
    "comments": [
      "My economics prof once told me.\n\nIf an product is sold out, it was too cheap.\n\nThe second hand market is actually the price people are willing to pay for such a card.\n\nI don't even dare to look at the market right now what my simple rx 5700 is worth.",
      "Picked up my RX 590 for ¬£150 last January. Will be keeping it for a while given current prices.",
      "You are actually right. Most of us won't able to afford to buy a new GPU in near future. I'll probably just skip this generation and will get myself a new GPU in 2022 or 2023. My 570 is struggling but I'm not willing to pay 600 euros for a midrange card.",
      "At this point they could sell it for 6000$ and raise the price of all their other cards too with this fanboy logic",
      "You re right. Vegas were $250 new by 2019, available everywhere while going for $1000+ with no availability in 2017. Same with Polaris right now. In late 2019, 570s were below $150 regularly (even $99 in same cases). Now, good luck finding any new Polaris below $300... Miners are the ones effing up the market, not manufacturers. And that's not trying to defend AMD or Nvidia, it's simply reality.",
      "I guess I am dumber than a rock for not wanting people to charge me a minimum of $400 for 1080p. I am so dumb for hating the price increase trend",
      "Here, scalpers! Ask OP for 3x MSRP",
      "I‚Äôm convinced that there are people on this sub that don‚Äôt actually use high-end graphics cards, they just buy and sell them like stocks and other investments. That‚Äôs why they snub their nose at people who actually care about buying these things at a reasonable price.",
      "My 5600XT for $290 last year is starting to feel like one of my best purchases in years. \n\nI truly feel for everyone that‚Äôs either trying to build their first gaming PC or those who need to upgrade/replace their GPUs this year.",
      "Well, second hand market is actually below what people would be willing to pay for a NEW product with WARRANTY. AMD could probably sell the cards 200$ above second hand market price.",
      "If one thing this gpu shortage has made it clear is the number of people who don't understand basic economics",
      "People aren't mad because of this card's msrp, they are mad because this msrp means that when the market does stabilize, in the next generation they are going to raise the prices again, and there won't be a gpu crisis by then. That's how we got 1500$ gaming GPUs, and, while I believe the GPU market will continue to creep up its prices, that should really come with an increased performance per dollar, at least sub 1000$, like the guitar market, for example. If they market a 1080p card at 400$ now, next gen will be 450-500$, so what resolutions are fit for a hypothetical 200$ card? 360p?\nNot to mention this card is about the same performance as the 5700 xt at 1080p, will be slower at 1440p, because of the bus limitation and small infinity cache, has bad almost to the point of unusable rt capabilities and has less CUs, for about the same msrp.",
      "There's no low end, nor mid range. the prices start at high end, then go to hoverboard money tier.",
      "32CU 2048 shader ~320mm^2 die size is literally specs of RX 470/RX 570 that launched at around $180. The only world where $380 MSRP makes sense is when you compare AMD to literal scalpers and in that case they can fuck themselves.",
      "Overpaying for a card and telling yourself you understand why you did does not make you an economist.  Also, it is fallacious to correlate a \"good big strong\" economy with increased level of quality.  I think those two things are part of the misunderstanding as well.",
      "i argued with someone yesterday who unironically told me companies will keep inflating prices to $10000 and make more profit off rich people alone. \n\nlike they literally think prices are set by companys' goodwill\n\nand the anti-capitalism 'corporation = evil' meta on reddit doesnt help",
      "Company interest =/= Consumer interests\n\nAMD and Nvidia are making a killing, there's tons of demand, and they can raise prices. Nobody reasonable is trying to argue against that. The point you're missing is that none of that matters for the consumer.\n\nIt doesn't matter to a consumer if AMD is making more money, or if they're \"justified\" in their actions. All that matters to the consumer is if they're being offered a good product at a good price. 379 MSRP for a card that compares to a 3060 is NOT good value. After scalper pricing, it's even worse value. \n\nYou can say that given the totally fucked pricing it makes sense, but that's ignoring that 99.9% of people are not willing to pay 800 dollars for a card that's going to lose to a 3060ti.\n\nIf you keep defending companies actions without considering your own interests, you're just going to keep getting fucked on prices.",
      "I bought a used RX 570 4GB for about $80 back in 2019.\n\nThat was when eBay sellers were listing 8-20 of RX 570/580 GPUs in boxes and would not allow individual sales. It was either buy the entire box or nothing.",
      "what SOME people are willing to pay...higher price less demand.",
      "Yes, just the latest example- Ryzen 5600X, 5800x, 5900X can now be found at -20% from MSRP. Same was for Zen, Zen+, Zen2, Polaris, etc."
    ]
  },
  {
    "brand": "amd",
    "generation": "6000",
    "tier": "low",
    "matched_keywords": [
      "6400"
    ],
    "title": "Does Ryzen 7000 benefit from DDR5 6400+? Is it even possible? Like, could I theoretically slap a 7200 MHz kit and see a noticeable difference?",
    "selftext": "Title",
    "comments": [
      "Hardware Unboxed YT channel tested 6400 Mhz RAM, he said the hassle to get it working properly aint worth it even if it yeilds more performance, the best is 6000 Mhz and thats what they have been using in all of their testing.",
      "Beyond a certain point (around or shortly after ~DDR5-6000) the memory *controller* clock can't keep up any more and has to drop to half clock (e.g. 1600mhz to drive DDR5-6400, instead of 3000mhz to drive DDR5-6000). That hurts performance much more than any increase in memory frequency, especially because such frequency gains can't get meaningfully more bandwidth across the limited IF links.\n\nThose IF links are sized for ~DDR-4000 bandwidth. Running memory at higher speeds helps to keep those links full and reduce bubbles and downtime, but with diminishing returns.",
      "DDR5 6000 is the sweet spot, 6200 can be stable 6200+ forget about it.",
      "Nah this is for intel. amd's memory controller isn't great.\n\nPersonally I'd buy the cheapest DDR5 I could find and make sure there is budget for an x3d CPU ASAP.\n\nThere aint a fucking thing 8000mhz DDR5 can do to compete with a huge cache. Something to keep in mind for intel and amd buyers alike.",
      "ngl the sweet spot is *whatever memory lets you put left over budget into an x3d*",
      "\"Infinity\" Fabric more like Finite Fabric amirite",
      "if you have cash khajit has wares! Although you will benefit more from buying high quality ram, leave it at \\~6ghz and just tighten the timings and subtimings. Its just going to take work no matter the money.",
      "with uclk:memclk 1:1?",
      "I run 6400 stable.",
      "Then you buy a 13900k system, a 5800X3D system, and a 7950X system all with 4090's and play on whatever one has 5% more FPS in your given game. All of this stuff is basically irrelevant right now outside of edge cases, and in 12 months the landscape is going to be different anyway with new gens of memory, CPUs, and GPU.",
      "It isn‚Äôt really unfair if the intel chips can run the ram far higher than AMD.",
      "Yet here are your guaranteed supported stick configurations:\n\n* 2x1R DDR5-5200\n\n* 2x2R DDR5-5200\n\n* 4x1R DDR5-3600\n\n* 4x2R DDR5-3600\n\nYour memory can support any speed it wants, the IMC ultimately decides what speed you really end up using.\n\nDo I have to mention how ryzen 2000 series often, but not always could do 3000-3200Mhz, but neither are supported and there was no guarantee? \n\nAlso you're on a new platform, people are going to get duds here and there.\n\nRead the fucking spec sheet.",
      "A 7200 kit will use Hynix A-die, which can't do as tight subtimings as Hynix M-die. Stick to DDR5-6000 kits rated for AMD EXPO\n\nSince AGESA stops training memory beyond DDR5-6600, aiming for A-die is pointless.",
      "Dont know why I have been downvoted. Guess jealous people dont like others good OC settings. Here a pic for proof of 120+ gb bench.\n\nhttps://ibb.co/YDfnbNP",
      "Yeah this is right take. 5800x3d showed that with the extra cache you can have a 3200mhz based rig beating the hell out of rigs with memory twice as fast.",
      "The spec ranges from DDR5-3600 to DDR5-5200 depending on the memory configuration.",
      "6400MHz provides 102.4GB/s maximum theoretical bandwidth. You're using MSI motherboard and have enabled the \"high bandwidth\" mode, or whatever it was called?",
      "Could you please elaborate why? Will it change in the future or are we stuck at 6000 while Intels will be flying at 10000 soon?\n\nIs it a problem of the CPU or do we have to buy a new motherboard too?\n\nFor example I buy a 7700X today with 6000 ram. But once 8800X shows up and supports 8000 ram can I just buy new ram and cpu and my motherboard will support it (after a bios upgrade for new CPUs)?",
      "You have keep mclk sync with uclk to get the benefit",
      "Agreed, I was trying to say it seemed unfair until you learn about the infniity fabric limitations. It's counter intuitive since AMD CPUs are relying more on memory bandwidth than Intel is too."
    ]
  },
  {
    "brand": "amd",
    "generation": "6000",
    "tier": "low",
    "matched_keywords": [
      "6600"
    ],
    "title": "Buying an AMD card after 14 years of separation (RX 6600)",
    "selftext": "Hi guys,\n\nMy EVGA RTX 2060 Gaming SC started to have some major heat issues just 3 months after I bought it. Hot spot had nearly 110 Celsius degrees and the card fan noise was similar to the starting airplane. It was working with max RPM all the time (3400) in any games that would make the card warmer than 73 degrees (I read that the issue is related to a faulty temp controller because I was not able to change the fan curve in the MSI Afterburner). So I was told that I will get my money back and now I am looking for a new GPU. My budget is limited and RX 6600 seems to be the best option. My CPU is 12400f, I have a 550W PSU and 16GB of RAM. My MOBO has a PCI 4.0 slot.\n\nAs I mentioned in the title, the last time I used the AMD card was 14 years ago and it was the Radeon HD 4850. I had so many driver issues with it that I just didn't want to have an AMD card in the next years. \n\nNow we have 2022 and I know 2 things:\n1. I don't want another 2060 (I read too many things about how bad the 20xx series is)\n2. I also read many things about how good performance/price you get with the RX 6600.\n\nThe problem is no matter where I go I find lots of people complaining about the AMD drivers. There are users who had no issues at all, there are users who experience some issues for a week or two after releasing new drivers and then they are fine for a month and also there are users who had so many driver issues that they gave up and rebought NVIDIA card.\n\nI mean it happens both ways. All I want is peace. I play a lot. Would you give a shot to RX 6600? I can get the XFX SWFT 210 Speedster with Dead Island code 2 for the price of returned RTX 2060. I saw that it will give me around 10% performance boost on average but all I care about is not looking for another card in the next months after buying this one due to some issues.",
    "comments": [
      "AMD drivers are in a much better state in 2022.",
      "Honestly, with how much they've improved, it gives me hope for Intel's graphics drivers too.",
      "I highly recommend using the AMD Driver Cleanup over DDU if you ever do have troubles. DDU still sounds the best to clean your Nvidia drivers out before the AMD driver is installed. Optional driver updates are really optional, but I still pick them up right away if they targeted a new game I'm going to play.",
      "It's funny because I just picked up a second hand rx 580 for my second machine (1060 in my main machine) and I am really impressed by amd's software so far. It tells you the actual gpu power draw! I had to change the default fan curve, put a cap on power draw to limit it to the same 120w max as my 1060, used radeon chill to lock fps to 60 with supposedly reduced latency compared to vsync, got some really good looking sharpening going on too and it's super responsive. \n\nThere's so many features in adrenalin and so much real-time data that you don't get with nvidia\n\nEdit: the power limiter lead to a bluescreen during darktide, and my fan curve adjustment caused an overheat in darktide after 4-5 hours. My own fault for slapping those values in without stress testing it. Default seems to be OK and power draw was near enough 120 under load anyway",
      "Yup, the entire problem with Arc is 100% drivers - and intel knew it would be, i'm pretty sure that is why they only tried to compete midrange on silicon.\n\nthe reason the amd and nvidia driver packages weight half a gig is because there is an entire library of game specific fixes and optimizations (rewritten shaders, etc) in them.\n\nthe arc is also not even running D3D11 or D3D9. They're doing JIT translation of all non-D3D APIS to D3D12.  That is going to take some time for them to mature that code and get it up and good.\n\ni expect by the end of the decade intel gpus might be competing at the top end",
      "The only time you can probably get some errors is when pushing oc too much, Nvidia doesn't even have a built-in feature like in order to play safe, then people tend to blame AMD for \"bad\" drivers for their own mistakes when in reality AMD is giving you a little bit more freedom to play with graphics card settings, oc'ing, fans speed, etc\n\nAdrenalin is a full feature software, easy to use once you understand how to use it.\n\nI've been using Radeon graphics since the R9270X era exclusively, it's been a great journey for me so far, so much that I have never considered buying into Nvidia at this point.",
      "4850 was my first card in my first build in 2008!\nYes the 6600 cards have no problem with heat and are a bit stronger than the 2060.",
      "Drivers often is user errors.  \nUnstable computers and then blame drivers.  \nDidnt clear out old software and have driver conflicts.",
      "AMD drivers are more sensitive to unstable memory/CPU overclocks. Aside from that, they are on par with Nvidia.",
      "I've still never had a driver issue in 7 years of using Radeon GPUs. \n\nThere were a couple releases where radeon settings was a bit buggy, mainly UI stuff. But always solid performance. \n\nJust stick to the most recent recommended driver and you'll be good.",
      "i used a rx 580 for almost 6 years, and finally switched to a 6800 3 days ago. timeout drivers  is the only issues i got in all this years.\n0 problems with 6800 for now",
      "That works too because of very large chunk of people that have AMD driver issues are people that have switched over from Nvidia and haven't done a clean install or they haven't used ddu",
      "I had a 5700XT before the current 3080FE and never had any issues even during the peak of the black screen driver complaints. It was a Sapphire Nitro+ which was one of the top of the line models which maybe why it was faultless. Also had good quality HDMI cable and EVGA power supply.",
      "And has no warranty. Used cards without warranty are like lottery tickets. There is no point in buying them unless you have 200+ USD to take a risk.",
      "I will just go with a clean installation.",
      "Run the stable driver (not the optional driver) and I doubt you'll find a single instability. Been rock solid",
      "If you are just a gamer, and dont do heavy streaming and content creation, imo AMD has the better drivers by now (simply because of modern looking UI that gives you ton of options you dont have with stoneage nv ui). I joined AMD 1,5 years ago (6800XT) after 17 years NV only and didnt regret it once. More the contrary, i wonder how NV still has this ugly ui and so much less utility in their drivers. The last issue AMD drivers had were their huge DX9/11 overhead. But the pretty much fixed it a couple of months ago.",
      "I don't know who needs to hear this but I was getting pretty regular timeout errors in almost every game I played with my 6900xt.  I tried underclocking it maxing the fans running older driver versions etc.  Turns out it was my RAM the entire time, even though it was on XMP it wanted more voltage.  Every crash seemed like a GPU related crash (adrenaline error or GoW was saying GPU temp errors) but it was RAM in the end.",
      ">Yup, the entire problem with Arc is 100% drivers \n\nOh, the hardware has big issues too.   Awful idle power usage, even in the best case scenario (DX 12 game, higher res) the performance isn't very good for something with that much die are and power usage.\n\nIntel has a long way to go hardware wise as well.",
      "My 6900xt is the first AMD card I've owned since the 290x in 2014. Got it a few months ago.\n\nIn the 4 months I've had it I haven't had any issues. It replaced a 3080."
    ]
  },
  {
    "brand": "amd",
    "generation": "6000",
    "tier": "low",
    "matched_keywords": [
      "6600"
    ],
    "title": "AMD RX 6600 stock runs dry in China, the company shifts focus to Radeon RX 6750 GRE 10GB",
    "selftext": "",
    "comments": [
      "This is still pretty much the only card most people need, it runs Doom Eternal at 100+ fps and most modern games on high with RT off at 60fps.",
      "Doom eternal runs at 60FPS on an Xbox One & PS4. 100 FPS is an extremely easy feat\n\nYou also need to specify a resolution if you're talking GPU performance",
      "You can't.  The reference 6600 was never manufactured.  It's just a rendered image only.",
      "Doesn‚Äôt fix everything. Even though it‚Äôs smoother it isn‚Äôt that responsive.",
      "Probably nowhere. The RX 6600 didn't have a reference design, so it's likely just a 3D render made by AMD for illustrative purposes.",
      "60fps isn‚Äôt high enough when a lot of people have 144+ hz monitors now a days.",
      "Where can we buy that single fan RX 6600 from the OP's picture?",
      "I think it's just a mock up. It looks like an AMD design but they never released anything below the 6700 xt for purchase directly on their site.\n\nIt's too bad. It has a great aesthetic.",
      "I've been using a 6600 since early 2022, it does everything you need it to.\n\nZZZ @ 1440p, Eve Online, MH:W, Elden Ring, all the esports. I've even tried LLM's on them(not great, but usable). UE5.3, Blender, Clip Studio, again, it's not a great card, but if you're just starting out, it does enough!\n\nGreat value, low power usage, and cheap!",
      "With mouse and keyboard I just do not find 60fps to be playable. Even drops down to 90/100 from 140/50 sorta range is extremely noticeable.",
      "Same, except late 2022. I feel like it's the 1060 / 580 of its generation. Not the best, but good enough for what most people play, and probably the best bang for the buck out there.\n\nFSR / XESS / etc. are helping me with the few games it struggles with, and honestly, those games generally tend to be poorly optimized anyway.",
      "Ok since people are downvoting me I guess I gotta post sources...\n\n[https://www.youtube.com/watch?v=NdoxEaySXis](https://www.youtube.com/watch?v=NdoxEaySXis)\n\n[https://www.youtube.com/watch?v=EOBE-Ade9MQ](https://www.youtube.com/watch?v=EOBE-Ade9MQ)",
      "I wonder if 60FPS or 120FPS is 'standart' these days",
      "I recently got the Asus Dual 6600 and man this card punches! Playing Warhammer 3, le mans ultimate and ACC all maxed out 1080p with no issue",
      "This. Idk why ppl act like 1080p60fps is the bar to meet in 2024. That ship sailed. \n\nThe new standard is 1440p120fps.",
      "Lemme guess what those \"few\" games might be. AW2, star wars jedi whatever, hellblade 2",
      "By that logic we should have all been happy with 20fps then right?",
      "I would be more interested in the 12GB version wich is basically a cloned 6750 XT so with faster 18Gbps VRAM\n\n2 more GB is welcome for using extra features like frame generation / afmf with texture-heavy games like console ports\n\nI also wish there was a small 2slot model like the PowerColor Fighter series ... guess im expecting too much",
      "ü§ì",
      "I don't know what AW2 is, you're correct with Star Wars Jedi whatever, and another one is Starfield, which I had to use FSR2 just to be able to play with a decent frame rate.\n\nHonestly, if devs optimized their games right, I'd say that the 6600 would probably be relevant beyond 2025, but if Ubisoft is any example, this might not be the case, unfortunately."
    ]
  },
  {
    "brand": "amd",
    "generation": "6000",
    "tier": "low",
    "matched_keywords": [
      "6400"
    ],
    "title": "AMD Ryzen 9 9950X DDR5-6000 / DDR5-6400 / DDR5-8000 Memory Performance",
    "selftext": "",
    "comments": [
      "1:2 past 6400 so pointless now. Also this: ‚ÄúThe Corsair Dominator Titanium RGB 2 x 24GB DDR5-8000 CL38 CMP48GX5M2X8000C38 memory kit was the only one problematic and yielding sporadic segmentation faults under some demanding workloads‚Äú. \nDamn you, Corsair /s\nBasically wait for x870e and gskill.",
      "Expo I for each kit",
      "1:2 was always pointless unless you can achieve at least 7800MT",
      "Unfortunately I don't review RAM too much on Phoronix and thus typically end up buying kits on my own. With limited budget that is why there weren't any 4x32 or 2x48 kits tested among other interesting kits.",
      "Interesting results, but the article does not state how the bios was configured.  Was this set to Auto, Expo I, Expo II, Expo Tweaked or custom?",
      "It looks like DDR5-6400 2x32 is the sweet spot.  Would like to have seen 2x48 and 4x32.\n\nDDR5-8000 didn‚Äôt give that much an improvement in most benchmarks and in a few cases was worse.",
      "Unlikely. I don't typically review RAM much unless a vendor proactively comes out to offer review samples for some interesting kit... So usually just look at a few kits I buy myself with my limited budget. I don't think I've heard from anyone at GSKILL in like \\~15+ years, so rather doubtful; IIRC their response way back then was not offering review samples due to few kits performing so exceptionally well while granted these days they seem to be much more robust. The other GSKILL units I have were received from AMD in prior review kit bundles.",
      "the memory controller is the same as last gen i dont think x870e is gonna do much",
      "2200 MHz fCLK is around a 3-sigma deviation on Zen 4, meaning very few CPUs can actually do 2200 MHz fCLK without memory errors. Zen 5 might be a little better, but there aren't enough sample to be sure yet. \n\nWith Zen 4, above 6000 MT/s fCLK is more important for real-world performance than the memory frequency - assuming timings are already tuned. \n\nFrom my experience, unless specified otherwise, motherboards will usually drop the uCLK to 2:1 above 6000 MT/s. In most cases, 1:1 should work up to 6600 MT/s, again, if the CPU can handle it. \n\nSo the absolute highest you can go on Zen 4 would 2x32GB 6600 MT/s (\\~CL28, \\~120ns tRFC) 2200 MHz fCLK, 3300 MHz mCLK and uCLK. This configuration should outperform a 8000 MT/s tuned configuration that is running at 2000 MHz uCLK and 4000 MHz mCLK and 2200 fCLK, since the IMC is running slower and also since tREFI cannot be raised above 65635, meaning that higher mCLK values reduce memory performance due to the memory doing refresh cycles more frequently. This is an artificial limitation on the Zen 4 memory controller / UEFI.",
      "The kit will most likely do 6400 just fine",
      "Another nice test, thanks!\n\nI do have one question about the 6400MHz RAM on your board, was your UCLK set to AUTO, which could be in a non \"native\" mode because apparently above 6000, while Fclk can be stable above 2000MHz I heard Uclock doesn't like >6000MHz ram and goes down a notch.\n\nIE: 6000MHz is 2000Mhz Fabric + 3000MHz UCLK + 3000MHz MCLK(\\*2 = 6000MHz)\n\nIt should say FCLK 2133 (or 2200?) + 3200UCLK + 3200MCLK for 6400? Dunno what the board will output but AIDA64 has that info\n\nand 8000MHz is 2000Fclk (1:4) + 2000UCLK + 4000MCLK",
      "From the PR the only changes seemed to be to AGESA to maybe get 8000 to be simpler for xmp, otherwise the claimed 8000 MTs was possible for a while now with a not very complicated custom tune",
      "tRFC and tREFI are the most important, IMO. You can have a kit that is stable at 8000 MT/s with CL10, but if set tRFC close to tREFI, the RAM is unusable. More realistically, good kits can push tRFC really low (Hynix A-die is around 120ns, or ~360 cycles at 6000 MT/s, M-die is around 160ns, or ~480 cycles at 6000 MT/s, while most Samsung kits are around 800 cycles at 6000 MT/s. Obviously, cutting the refresh cycle by half is going to improve performance noticably. The rest of the secondary timings are also quite important, you can get some nice performance with them. Tertiary timings are interesting when you have dual rank memory, otherwise most of the timings are not really used. Primary timings are the least impactful, apart from scoring well on memory benchmarks that are doing artifacial, burst-y memory operations. Just imagine how often a real game or app, using 8-20 GBs of memory at a time, will access 8 bytes of memory. As in only 8 bytes. No more. In that case, primary timings are super important, but if you need more memory than 4 Unicode characters, secondary timings are in play already, and there you have tFAW and tRRD (S and L) and tWTR (S and L) timings in play, governing the vast majority of memory operations.",
      "trusty ol' phoronix",
      "Add it to the pile of tests that showcase latency is more important than total bandwidth for Zen processors.\n\nCL 28-6000 seems to be the go to, CL32-6400 and CL30-6000 look like cheaper alternatives.",
      "Corsair is the worst ram manufacturer by far.",
      "The primary timings you listed don't really matter. If the memory controller is interleaving commands correctly, those timings are only used at around 5% of total memory requests. What matters more is tRFC (how long a refresh cycle lasts), tREFI (how often the memory is refreshed), and tFAW (how long is the interleaving window) and the corresponding read and write timings for command interleaving.",
      "Hey OP ‚Äî /r/AMD is in manual approval mode, this means **all submissions are automatically removed and must first be approved before they are visible**, this is done to prevent spam, scams, excessive self-promotion and other rule-breaking posts.\n\nYour post will be approved, provided it follows the subreddit [rules](https://www.reddit.com/r/Amd/about/rules/).\n\n**Posts regarding purchase advice, PC build questions or technical support will not be approved.** If you are looking for purchasing advice, have a PC build question or technical support problem, please visit the [Q3 2024, PC Build Questions, Purchase Advice and Technical Support Megathread](https://www.reddit.com/r/Amd/comments/1dsetov/pc_build_questions_purchase_advice_and_technical/).\n\n\n*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/Amd) if you have any questions or concerns.*",
      "I've ordered the 6000 kit for my new 9950x build, arriving tomorrow. Regretting my life choices now.¬†\n\nTough call to return and wait an extra couple of days for the 6400.\n\n\n\nThe Corsair vengeance 6000 I've ordered are tighter (30-36-36-76) than the tested gskill (30-38-38-96). I wonder how that might narrow the gap.",
      "damn, CL28-6000 is out already? I swear I couldn't find any lower than CL30-6000 around a year ago when i built my rig"
    ]
  },
  {
    "brand": "amd",
    "generation": "6000",
    "tier": "low",
    "matched_keywords": [
      "6600"
    ],
    "title": "My Ryzen 7 5800X3D & Radeon RX 6600 housed in an Ncase M1",
    "selftext": "Other specs:\n\nRAM: 16GB (G.Skill)\nSSD: 2 x 1TB (Samsung)\nCPU cooler: Noctua NH-U9S\nCase fans: 2 x 140mm BeQuiet!\nMotherboard: Asus B550-I",
    "comments": [
      "Shoulda went for less bling bling and more gpu ngl.",
      "Good point! A GPU upgrade is probably next on my list, but it's hard to justify, considering most of my gameplay recently is Grand Strategy Games.",
      "Looks cool! Which rgb strips are those?",
      "Linux MasterRace",
      "If you get 6750xt close to the price of a 7600 then its a fantastic choice, region prices are always different.\n\nDepends on what gaming you do because in higher gpu heavy games you will be more gpu limited with a 6750xt, that means a 5600x is still gonna be good. However more competitive games like CS and such then x3d CPUS  are gonna be a fantastic upgrade.\n\nSo in general gaming 5600x with a 6750xt is a fantastic pairing. I had 5600 with 6750xt and upgraded to 5800x3d. Thats because i wanted more fps in games like CS but also a more future proof CPU. The 5800x3d is really good in gaming that it will last for a while and you can just upgrade the GPU and it will still hang with that. In gaming at least. Other things it might hang back but it is very future proof for gaming. If it wasnt for something like CS2 and me wanting future proofing then a 5600 would still have been good and i would have upgraded GPU instead.\n\nHowever i decided to get CPU and upgrade GPU later as 6750xt is pretty good for now.\n\nAs AMD has extended their AM4 support, I would even suggest that you get a better future proof GPU right now. It will do fine paired with the 5600x, unless you want higher performance in competitive games then obviously go with 6750xt and x3d CPU, in that case 5700x3d is gonna be a great choice as well.\n\nHowever if you play more graphics heavy games and such. Then i would even suggest not upgrading CPU just yet(wait to upgrade CPU). Instead put money to get 7800xt or better as GPU. Save up a bit again and buy a x3d CPU later on. That way you will be even more future proof set.\n\nYou could get a 5700x3d as well save that money and put it into GPU. But 5600x or 57/8x3d both will do great paired with a 6750xt.",
      "How is the 6600? I was thinking of getting 6700xt . And thinking of upgrading my 5600x to 5800x3D. I have a 1080GTX right now. Only game I really play much is CS2",
      "Nice build! I've got a 5800x3d in my mid-tower and a 5600x in my M1 with the same cooler, mostly because I thought the 5800x3d would get too toasty in there!",
      "Thanks! I forget the name and brand of the light strips, but they look similar to these https://www.ebay.de/itm/386871643763 .\n\nBasically, it's a flexible rectangular tube, with the top being the light bar. The set comes with the guide pieces to shape the corners etc.",
      "Newest stable (using Wayland), running on Arch Linux.\n\nHowever, I do most of my gaming in a separate VT, running Steam on a minimal X.org-based WM.",
      "look at used gpus, wayyy cheaper than new.",
      "I got the 6600 new in 2022. As I recall, at that time, the used GPU market was dominated by ex-mining cards of questionable value.\n\nBut things might have changed now. I'll probably look at used cards too once I'm itching for an upgrade.",
      "Oh you already had the mobo yea it's a perfect upgrade",
      "I played The Witcher 3 (next gen), Doom Eternal, Spider Man, Spider Man Miles Morales, Red Dead Redemption 2, Assassins Creed Odyssey and Baldur's  Gate 3 on it at 1440p with pretty high settings and it handled it pretty well. Obviously a better gpu would have given me more fps and prettier graphics, but all of them were perfectly playable.\n\nI am thinking about getting a 7900gre or something similar soon, but it's honestly still a pretty good gpu.",
      "Nice, have a 6600 too :)",
      "Which version of GNOME and distro?",
      "It's a Logitech MX Mechanical Mini. If you're interested, you should try out the feel of it in a shop. Note that there are two versions in the same form factor, one with membrane keys, the other with mechanical.",
      "Hey, thanks for looking closely! It's an optical illusion of the spinning fan blades, they're mounted using the heatsink clips in a push-pull configuration on the tower cooler, but the back one is offset due to clearance for the VRM heatsink.\n\nI've experimented with having the back fan as an exhaust too (which would just be a couple of cm further back, almost in the same position) but it basically choked the VRMs, with the tiny, noisy VRM fan spinning up constantly.",
      "Honestly the 6600 still performs decently so it's not that bad",
      "Mini itx am5 motherboards are insanely expensive and rare. So it‚Äôs not exactly comparable.",
      "Yeah well I think the 6700xt is a decent bit better than the 6600 rx. And I think lately it's only like $10 more for 6750xt on Amazon so been thinking of possibly going for that"
    ]
  },
  {
    "brand": "amd",
    "generation": "6000",
    "tier": "low",
    "matched_keywords": [
      "6600"
    ],
    "title": "AMD Radeon RX 6600 XT with 8 lanes on PCIe 3.0 and without Resizeable BAR - Dream or nightmare for upgraders? | igor¬¥sLAB",
    "selftext": "",
    "comments": [
      "I would ask what the cost of enabling x16 would be, but that feels kind of ridiculous when we're talking about a $380+ GPU.",
      "Still can‚Äôt see how people defend AMD on this issue. I like AMD but this is just absurd especially on a pricey GPU.",
      "On silicon- it is minimal, the cost is about 1mm^2 area. Surely it would be beneficial. However, when designing the RDNA2 chip lineup several years ago, AMD likely expected N23 GPU to sell at ~$200, including the memory, cooler, board, etc.- and were cutting everything possible to save on costs. The market has changed, but honestly- during the mining boom this is not hurting them, as they sell everything they make and have not even made artificially cut down N22/N23 SKUs for segmentation. The only place this is (mildly) hurting them is in laptop GPU performance- AMD Cezanne is PCIe 3.0 only, and AMD's GPUs are likely to be coupled only with Cezanne, not PCIe 4.0 Intel. So this affects the performance of their laptop GPUs, till they refresh next year with PCIe 4.0 laptop APUs.",
      "AMD and Nvidia are using the fine print to rob us blind, every card now has a small detail . But prices keep going up.",
      "I don't think there is anyone defending it. People might still defend the 6600XT as a good buy in the current market. But I haven't seen anyone defending AMD's decision making when it comes to the 8 lanes issue.",
      "Because it‚Äôs 16x, the 6600xt is 8x.",
      "This card seems intentionally crippled.",
      "That's a fair point, though I think the reality is still the same from the consumers perspective regardless.",
      "Especially when the RTX 3060 has an x16 connector.",
      "Even the 5600XT has x16. This card would have been 6500XT in a normal market, just like the RX 550 and 5500 XT were both x8.",
      "im not a fan of raising amount of asterisks on new gpu performance. Sure ~5% per loss in most cases with pcie 3.0 is not much, but these things adds up",
      "RX 6900 XT also has 16GB of VRAM instead of 8GB on a two times wider bus and it has a PCIe x16 connector.",
      "Because the 6900 XT is likely not totally saturating PCI-E 3.0 x16's bandwidth of 15.754 GB/s. Whereas when you stick the 6600 XT in a PCI-E 3.0 slot it's likely exceeding the 7.877 GB/s of bandwidth at x8, whereas in PCI-E 4.0 it's running at 15.754 GB/s even at x8, so it's like 3.0 at max speed. I mean a 3090 hits like 11.5-14 GB/s usually. A 6800 XT, much the same.",
      "Without PCIe 4.0 it would be limited to PCIe 3.0 x8 and as we can see in the test results that results in lower performance.\n\nAlso at this point it probably doesn't increase the cost at all for this card to support PCIe 4.0.",
      "The lower end the GPU the less it matters, actually. I doubt the 6600XT would show any performance scaling under 16X gen4\n\nCan run a 1060 on 4x.\n\nI ran a 660Ti on 1X gen2 for years (eGPU) with no loss.",
      "440 for the 6600XT, 850 for the 6700XT, at my local microcenter.  I have no idea what you're talking about.",
      "It's probable that they designed this particular GPU around the assumption of mobile variants.",
      "It‚Äôs fine regardless of your board, it doesn‚Äôt cause any problems. People are just upset over design choices that COULD have been, compounded by current pricing, making every little detail scrutinized even more.",
      "The 6600 XT itself is wired for only up to x8. The connector is there for x16, but it is only x8 capable. What people are discussing is the performance loss of the card running PCIe 3 x8 vs PCIe 4 x8.\n\nAMD did the same thing with ther 5500 XT last gen.",
      "Why does this matter?\n\nWhat we're talking about is why the RX 6600 XT loses performance when running at PCIe 3.0 speeds while the RX 6900 XT doesn't and the reason is because 1. the RX 6900 XT has enough VRAM to not run out and 2. it has an x16 connector which has two times more bandwidth than a PCIe x8 connector in 3.0 mode."
    ]
  },
  {
    "brand": "amd",
    "generation": "6000",
    "tier": "low",
    "matched_keywords": [
      "6400"
    ],
    "title": "7800X3D and 6400 ram cl32",
    "selftext": "hey there fellow reditors!\n\ni am just fine with using my 7800x3d with 4800mhz safe with all these news with bios updates\n\nupdated my bios and wanted to try the actual potential of my ram\n\nso i tried 1.25 of SoC and 6400 xmp, it was okay for like 2 hours and then my game started crashing, i started panicking because this build wasnt so cheap and easy for me to get where i live\n\ni was waiting on this cpu so bad and finally upgraded to ddr5\n\nim full in team red when it comes to cpu, 2600>5600x and now this..\n\nthis feels awkward being worried about to do or what not to do with all these crazy unfair burns people had trusting everything is fine \n\nsomeone said that he is using 7800x3d with 1.15 SoC and runs 6400mhz. is that fine to use? or should i wait for another bios updates, im using gigabyte b650 gaming x ax btw",
    "comments": [
      "6400mhz is about the limit on many memory controllers at reasonable voltages. Some will not even boot at that speed.\n\nYou would likely have to loosen the timings, increase the RAM and MC voltages or both.\n\nOr just go the easy way and settle at 6000mhz which pretty much all CPUs can do.",
      "6400mhz will be pushing it on most CPUs.",
      "6000 Mhz is the sweetest spot for your CPU... try 6000 for stability and watch SoC v not to be over 1.30. \n\nYou should be fine.",
      "Memory Controller. You may as well see it as VDDIO in the BIOS.",
      "6000mhz also sits at a sweet spot for AMD CPUs as it matches the infinity fabric rate. You'd likely see slightly worse performance at 6400mhz unless you can also overclock the infinity fabric to the same.\n\nTldr: go for 6000mhz",
      "Don't worry so much about the memory voltages - just use the rated value, which is probably 1.35v for that kit. DDR6000 will run with SOC @ 1.2V or lower.  You want to run the lowest stable SOC voltage to reduce waste heat and shift more of the socket power budget to the CPU cores.  1.15V is stable on many/most CPU samples with DDR6000. The reason DDR6000 is the \"sweet spot\" is because it is about the fastest speed you can run while keeping UCLK at 1:1 ratio (3000MHz instead of 1500MHz in this case).  Good luck, take care!",
      "As far as voltages go:\nI and many others are finding 1.1 VDDSOC to be sufficient for 6000C30 using Hynix Adie. I run 6000/2133 using the following voltages, 100% stable, 100% safe. SOC drawing 7 watts at idle and 13 watts under heavy load...\n\nVDDG (both) - 0.85\nVDDSOC -1.07\nVDDIO - 1.35\nVDDMEM/VDDQMEM - 1.43\nVDDP - 0.95\n\nAIDA MEM results - 67500/94000/67500/59.6\n\nZen4 does not require high voltage for 6000C30. The gains from 6000C30 to 6400C30 are almost nil, is less than 1% in synthetics and a 0% gain in almost every game. \n\n6400 is not the way.\n\nYou gain zero on read/copy and about 4000mb/s in write speeds as well as -1ns first word access time going from 6000 to 6400.\n\nThe gains for 7800X3D should target IF instead. Each step of stable IF over 2000 is about 1000mb/s read/copy and -0.5ns first word, up to 2133. Above 2133 you will have latency performance regression whilst still gaining bandwidth, so it's still a gain, but the gain is so small it's not worth pumping any voltage to get.\n\n7800X3D is not limited by IO at 6000C30, it's limited by AMD SMU programing to target 1.08 VDDCPU and 80 watts before pulling core speed back instead of letting the CPU actually boost to 1.15 like it should be. \n\nYou can confirm this yourself, go run OCCT CPU benchmarks or look at the database of results and look at sustained VDDCPU/PPT during high load. The outliers are the people who've been able to coax more voltage safely to VDDCPU like tcclaviger (generally it's people with extreme cooling setups).",
      "Well, for most AMD cpus yes.",
      "Limit both Soc and vddr to 1.26/1.27 and use Expo I.",
      "Thx!  I'm on the AMD OC team and helped develop EXPO :-)\n\nEnjoy your system - I'm sure it's great as-is!  Some folks want to chase down that last 0.5% of performance, even if they would never notice it in real-life.  I think a lot of peoples favorite PC game is \"BIOS Tweaking\" .. i guess that's one of my favorites too :-)\n\nTake care!",
      "Tell us how it is going..",
      "Have you tested for an actual advantge, if any, of 6400 over 6000 in real use? If you are GPU bottlenecked or limited by minitor refresh rate, the only difference would be higher  system temps. I have stable 6000 with SOC 1.15 with Buildzoids timings, but am actually running memory on default 4800 for lower voltages and temps. I noticed 0 practical difference with 3080ti at 4K.",
      "Use 6000 instead",
      "Yeah I guess. What is MC?  \n\n\nThank you for ur answer dude",
      "yeah maybe i just should try 6000, thank you",
      "The 2033 fclk thing is outdated. He mentioned in a late video that it was due to an early bios bug and now scales as expected.",
      "AMD is putting limit on SOC and Mem oc with new agesa updates....as gamers nexus said there are lot of underlying issues....just limiting  voltage and mem oc will not completely solve the issue but that is a  start. ...my suggestion is just wait until AMD fixes it completely...dont play with voltages, mem oc and expo until than\n\nEven at 4800mhz jedec spec ram is still pretty fast....if you xmp maybe you will gain 10 to 20 fps at max depending on game which is not worth the risk.\n\n[https://www.techpowerup.com/308330/latest-amd-agesa-that-nerfs-ryzen-7000x3d-voltage-control-also-limits-memory-overclocking](https://www.techpowerup.com/308330/latest-amd-agesa-that-nerfs-ryzen-7000x3d-voltage-control-also-limits-memory-overclocking)",
      ">Or just go the easy way and settle at 6000mhz which pretty much all CPUs can do.\n\nTurns out there's a very fine line between \"can do it\" and \"will cook itself doing\" it.\n\nThe last few weeks were wild.",
      "yeah probably",
      "Why EXPO I and not II ?"
    ]
  },
  {
    "brand": "amd",
    "generation": "6000",
    "tier": "low",
    "matched_keywords": [
      "6400"
    ],
    "title": "MSI X870(E) motherboards now support up to 192GB of DDR5 memory at 6400 MT/s - VideoCardz.com",
    "selftext": "",
    "comments": [
      "Enough RAM for Google Chrome.",
      "Wow with that much RAM you will never need to download more again.",
      "To put it simply:\n\n48gb sticks are readily available. It's doable to do 4x48gb (well good luck on timings/speeds) to get 192gb.\n\n64x4 for 256gb is absolutely possible... But it is very very niche on consumer platforms without registered memory. I do think concepts and designs have been made, I am not sure if there's a consumer product out yet.",
      "‚ÄúAMD does not support 64GB modules‚Äù. \n  \nAre these a thing for unbuffered DIMMs?   \n  \nIt‚Äôs not clear to me if they are improving some sort of training to improve speeds or if there is a new DIMM model being sold that they now ‚Äúsupport‚Äù.",
      "I thought the limitation was in the memory controller of the CPU, not in the MB?",
      "And Microsoft Teams",
      "No, not guaranteed. Even 6000mhz only has a very high chance that it will work.",
      "idk bout 192, but I could use 96 no problemo",
      "And Cities: Skylines II",
      "Is 6400 guaranteed now? Last I checked is still 6000.",
      "They are being released very soon",
      "Is just what you're looking at specifically, the common 6000CL30 kits have been 80-100 bucks for many months now, pretty static.",
      "Notice the CL48 latency in the CPU-Z screenshot though..   :(",
      "It's a setting in your BIOS my dude. Off by default.",
      "Memory prices have been rising with like 10-15% lately (anecdotal, just the kits I've been looking at), so hopefully higher capacity sticks will move the prices a bit again.",
      "And Minesweeper.",
      "Come to think of it the X670E master supports 256GB but I think the earlier versions was less than that ü§î",
      "Speaking of X870E, have any of you had any luck finding ASrock mobos in stock?",
      "I can‚Äôt even get my carbon WiFi to update bios, it doesn‚Äôt read the files. And also my usb ports no longer have power with my pc shut down, on the old Intel asus board i had my ports still had power so i could charge things. \n\nNot having a good time",
      "Anything about AMD's spec sheet is not guaranteed technically. Zen 4 was officially speced 5200 mt/s for example.\n\n\n¬†Zen 5 is 5600 mt/s¬†https://www.amd.com/en/products/processors/desktops/ryzen/9000-series/amd-ryzen-9-9950x.html"
    ]
  },
  {
    "brand": "amd",
    "generation": "6000",
    "tier": "low",
    "matched_keywords": [
      "6600"
    ],
    "title": "AMD Radeon RX 6600 XT and RX 6600 to launch on August 11th - VideoCardz.com",
    "selftext": "",
    "comments": [
      "I hope the rumors about $400 will be wrong. We need $250-$300 1080p good card for normal people. On the other hand, prices in stores will be very high anyway. Still the cheapest 6700xt cost over $1200 in my country...",
      "This is a 200usd graphics card tops. a good 480/580 upgrade... fuck those prices. 400usd was the 2nd best model back when prices actually made sense and titan price-boosting series did not exist!",
      "$500+  \nmarket still fudged",
      ">The singe-fan reference model pictured below is said to be used only for marketing purposes, as AMD is allegedly going to launch this card exclusively through its board partners.\n\nTranslation: The 6600 and 6600 XT will have a higher MSRP than the 6700 XT",
      "3060 is technically 330$, but good luck with that.",
      "when on earth has there ever been a point in gpu history where people just went \"the old stuff is plenty\" and then just exit the market",
      "I like how everyone these days just pretends like 1080p gaming and the $200-$300 market doesn't exist. And then also complain about runaway pricing. Great going, guys.",
      "It's a little wrong considering back in 2015 a R9 290 could be had for ¬£300 new and that is still fine for 1080p gaming even today, by now 1080p gaming should be possible on a ¬£100 card, my HD 7850 was a perfect 1080p card back in 2012 and it cost all of ¬£180...\n\nWhat got me into PC gaming was I wanted a Desktop anyway and all it cost was an extra ¬£180 for the GPU + ¬£20 extra for an upgraded PSU, if I was buying today it wouldn't be a gaming PC because of the ¬£600+ cards.",
      "Exactly that is the point. Prices are stupid high nowadays. 1080p gaming few years back was easy for 200 bucks. Technology has advanced. 200 should bring 1440p on the table today.",
      "You must be rich then bro \nAt this point $200-$300 should be a 1440p gpu",
      "Ah yes, the magical $399 \"entry level\" gpu...\n\nJokes aside, this entire generation AMDs been increasing prices to the next segment, for the same price you could've paid 2 years ago you're getting the same performance, just on a lower SKU, reminds me of nvidia's 2000 series, which everyone hated for that exact reason (The 2080 having the same performance as the 1080ti at the same price).",
      "This is by far the worst part about this, if it's true.\n\nIt's bad enough that AMD will likely have MSRPs that are barely undercutting Nvidia. And without reference models, there's no chance they'll be anywhere close to MSRP. AIB 6600s will likely be more or equally as expensive as the reference 6700 XT. \n\nThe mainstream market segment may as well not exist this generation. Anyone looking for a $200-300 GPU should just wait for the next generation.",
      "The 6700 xt is meant to be $479 so I wouldn't be surprised if they market these at $399 and $349. \n\nI would bet the 6600xt is around the same mark as the 5700xt too so if they do market around those msrp's it will mean no improvement in value.",
      "Not like it matters what the MSRP is.",
      "*They're. You can remember it as being a shorter contraction of 'they are'.",
      "If the 6600 XT is better value than the 3060 *at all*, I‚Äôll have to recommend it, but I won‚Äôt call it good unless it beats/matches the 3060 for $299. That‚Äôs the kind of value we deserve.",
      "Yup. Only hope of any of these making it to the market at under $500 would be if AMD launched a reference version. AIB partners will straight up scalp it. When the shortage rolls over, try to remember the worst companies.",
      "The price is 100% correlated with how well it mines.  That's why 5700XT's cost more on ebay than 6700XT's.  As far as \"MSRP\" goes, it really doesn't even matter.  No one's gonna see that.",
      "I have been eagerly awaiting for the 6600XT (as I am after a sub-450$ card for a secondary PC), but the more I read about it, the more it sounds to be a tough sell. With its 128-bit bus and 32mb of Infinity Cache (versus 96mb on the 6700XT) seems like this card is crafted for 1080p and hardly any resolution above it. I hope to be wrong, though.  \n\n\nI would have preferred a 6700 non-XT, but apparently that card is not happening, as all Navi 22 chips are going to mobile versions, as well as the 6700XT.",
      "This may be a comeback chance for affordable pricing in the entry level gpu segment."
    ]
  },
  {
    "brand": "amd",
    "generation": "6000",
    "tier": "low",
    "matched_keywords": [
      "6600"
    ],
    "title": "Radeon RX 6600 Linux Performance Rising Even Higher With Newest Open-Source Driver",
    "selftext": "",
    "comments": [
      "Michael does run Linux-vs-Windows comparisons periodically. They used to be of limited value because games would typically use older OpenGL backends on Linux and newer, highly tuned DX backends on Windows, but with the arrival of Vulkan the ability to make useful comparisons has improved quite a bit.\n\nIn the meantime the \"Geometric Mean\" comparisons between graphics cards at the end give a pretty decent picture of relative performance despite the game set being different.",
      "You've just described the entire GPU market. By comparison, it's a good card for the price, if for no other reason than you can maybe find it for less than $500 and it isn't 8 years old.",
      "~~Poorly Optimised Launch Drivers~~\n\n**Finewine‚Ñ¢**",
      "Even if the games did use older backends I'd say there is still value in comparing the two as an overall platform.\n\nIf you just want to know which platform a game runs best on, or what compromises you will need to deal with for your OS choice then it's still useful information.",
      "I'll have a fresh windows vs. linux comparison sometime soon... Only have so much time in a day for all the articles, benchmark development, etc :/",
      "For linux users, since nvidia drivers are closed source and do not always work well, amd cards tend to be a good choice",
      "I just WISH that we can actually buy one at MSRP but Noooo.",
      "[deleted to prove Steve Huffman wrong] -- mass edited with https://redact.dev/",
      "Yes it has awful MSRP/performance but its street price/performance isn‚Äôt as bad as much of the rest of the market.",
      ">Even if the games did use older backends I'd say there is still value in comparing the two as an overall platform.\n\nAgreed, my post was too short. What I should have said was that they were of limited value in terms of comparing the OS/driver ecosystem between Linux and Windows, but still useful in terms of understanding what a typical user is going to see.",
      "It's hilarious/horrifying that a 6900 XT at 1500‚Ç¨ is better value than the 6800 XT which for some reason is also 1400-1500‚Ç¨",
      "Bought mine 6600 XT at MSRP when they first launched and no one seemed interested. \n\nThen the miners found out they'd do 32Mh/s for Ethereum at 60W and suddenly they were all gone.",
      "AMD's software engineers must truly be third rate compared to their main competitors.",
      "[Always has been](https://i.imgur.com/CdG9Lvs.png)\n\n^^^this ^^^has ^^^been ^^^an ^^^accessibility ^^^service ^^^from ^^^your ^^^friendly ^^^neighborhood ^^^bot",
      "Yeah but 3070 is also shit for the price/performance ratio right now",
      "Always has been",
      "Ok yeah, agreed.",
      "FlightlessMango in YT. Also made a great HUD for stats like FPS/FT and sensor values",
      "Totally. I'm sure it will be closer and closer especially for native titles.",
      "I play X4 (Vulkan native) on Linux (Steam) which is faster overall. Not only on just GPU but also CPU. On windows the game hovers around 6-8 cores and the perf issues are noticeable when the playthrough matures with thousands of ships etc. \n\nOn Linux, same system, can clearly see the 3900X been used to 90%+ all 12 cores  and there are people with 5950X saying all 16 cores are been used. Ofc the game runs much better."
    ]
  },
  {
    "brand": "amd",
    "generation": "6000",
    "tier": "low",
    "matched_keywords": [
      "6600"
    ],
    "title": "Will FSR be better on the future? Should I get a Rx 6600 instead of RTX 2060?",
    "selftext": "Where I live, Rx 6600 and RTX 2060 are in the same price, even though 6600 is much powerful. But when you count NVIDIA's dlss, the gap closes. And FSR is in really rough shape right now. Even on ultra quality, ƒ± can see the blur. But when it launched, dlss wasn't in much a better place either. So do you think FSR will be better in the future, close the gap to dlss? \n\nShould I get a Rx 6600 instead of RTX 2060?",
    "comments": [
      "People do know FSR is not specific to AMD and runs on Nvidia also ?",
      "This is just my general opinion buy stuff based on what is there not what you think may happen. Even when companies promise stuff, they can disappoint. Just my opinion the 6600 is a lot more powerful, which in a lot of cases I think makes more sense. Dlss 2.0 is pretty great but who knows how many games will implement it long term. Personally I got a 3000 nvidia card with that being one of the reasons like a year ago, but it is important to have expectations for vendor locked features like dlss that needs to be implement on a per game base atm.\n\nPersonally I would take the 6600 vs 260p. If we where comparing to 3000 series maybe the discussion can be different cause the gap is not the same, plus you get newer ray tracing cores.",
      "6600 rasterization performance is significantly more than 2060 and has more VRAM. That's enough reason for me to go for that over the 2060 tbh. I don't care much about upscaling techniques especially DLSS as it's proprietary. Yes it's good but so is FSR and i prefer to play at native resolution. As for RT, ray-tracing performance isn't that relevant at this class of hardware, regardless both have similar ray-tracing performance anyways.\n\n6600 is the obvious option IMHO.",
      "Oh, people...",
      "why would Nvidia write an article about their own basic image scaler (NIS) if they wanted to hide anything to old owners ?\n\n[https://www.nvidia.com/en-us/geforce/news/nvidia-image-scaler-dlss-rtx-november-2021-updates/](https://www.nvidia.com/en-us/geforce/news/nvidia-image-scaler-dlss-rtx-november-2021-updates/)\n\nhaters are ridiculous lmao",
      "[https://youtu.be/EFY7\\_H6rvEw?t=330](https://youtu.be/EFY7_H6rvEw?t=330)\n\n&#x200B;\n\nIdk about you, but as viewed in this video, both are pretty fuckin similar, nvidia one works with all games and unfortunately affects the UI, FSR has a better sharpening filter and doesn't affect the UI\n\n&#x200B;\n\nBoth get destroyed whenever DLSS is in the picture, sure FSR is the second in the competition, but its closer to NIS than DLSS.",
      "6600",
      "Th XMX version of XeSS which will be more similar to DLSS will only be supported on Intel Arc cards . \n\nThe other cards will only run the lower quality DP4a version\n\nhttps://www.digitaltrends.com/computing/intel-xess-is-answer-to-nvidia-dlss-one-big-advantage/",
      "Why are you asking if you should buy an outdated, weaker GPU?",
      "FSR 1.0 will work in anything so I wouldn't really have that be a deciding factor. Consider DLSS as a selling point of the RTX card however, should that be of any merit to you.\n\nThe 6600 is likely the better buy at this point in time regardless, but the market is rapidly settling it seems and things might be more palatable very soon.",
      "Add to that that RSR is driver level... It's gonna be nice.",
      "Nvidia's own spatial scalar is not even close to being any good compared to FSR. DLSS may be better than any of them but FSR is definitely the second in the competition, with no one coming any close.",
      "I would appreciate the source on that.",
      "I have tried FSR on many games with my Gtx 1060, and I can definitely see the difference between native and FSR quality. I ended up choosing native because of its blurness.",
      "No we don't. They're a multinational corporation, not a family run corner store.",
      "XeSS has yet to be implemented and tested, and the 6600 will use the worse version of XeSS and it's pretty unclear if XeSS outside of Intel dGPUs will be any good. I don't expect miracles, generic solutions often come at a cost.\n\nBesides, even nvidia hardware (at least from Pascal) will support XeSS, so it's not an argument.",
      "The amount of time between DLSS' announcement and FSR1.0 being released has nothing at all to do with the progress or current state of FSR2.0. There is no logical reason to connect these very different moments in time. \n\nFSR2.0 *exists* now and is working well internally. The work of getting studios onboard with FSR (which took time) has already been done. \n\nFSR2.0 will come out this year. How it compares to other systems at the time is anybody's guess right now. However, given FSR2, DLSS2, and XeSS use similar techniques they should be more or less similar in results with minor pros/cons split between them.",
      "Don't buy with future expectations. Buy for what's good now. What would fit your needs better now?\n\nI never expected my rx 580 8gb to be worth double then the 1060 a year ago. When I bought the 580 it was basically the same price as the 1060.\n\nYou can try to assume AMD will update and future proof the 6600 longer then NVIDIA the 2060. You can see this currently when most AMD features work on the 580 while some nvidia features do not on the 1060.",
      "So there's been zero information on XeSS and you come swinging for not the fences, not the clouds, but for the crab nebula my guy.\n\nWhere and the actual hell do you get this information?",
      "You're the SAME dude that talked about it last time i think clamiing the same thing.\n\nSuch specifics like \"1.3x\"  and exaggerations like 1000% cleanup of ghosting and shit.  Hilarious dude, let me go ahead and chalk this up as a joke and some subtle AMD shilling because this would put them in the game without them having to spend a dollar."
    ]
  },
  {
    "brand": "amd",
    "generation": "6000",
    "tier": "low",
    "matched_keywords": [
      "6400"
    ],
    "title": "Just a FYI: AM5 integrated graphics should make the RX 6400 obsolete",
    "selftext": "The RX 6400 has:\n\n* 3.57 TFLOPs of single precision performance\n* 128GB/sec of memory bandwidth\n\nAM5 should have:\n\n* APUs at least as powerful as the Ryzen 9 6980HX, which has 3.686 TFLOPS of single precision performance.\n* 134.4GB/sec of memory bandwidth from dual DIMM DDR5-8400 RAM. Overclocked memory like DDR5-12600 (which has been announced) would give AM5 201.6GB/sec of memory bandwidth.\n\nThe RX 6400 should become obsolete when AM5 APUs launch. I would not be surprised if AMD ships AM5 APUs that make the RX 6500 XT obsolete at some point too.",
    "comments": [
      "Specs are fun, but it will depend. # of CUs sometimes play a role, sometimes not. \n\nMy 2nd self built PC had an onboard hd 4310? Chipset 780G for am3. Llano blew that out of the water easily.\n\nProgress! But old systems will usually need something cheap to replace dead cards, or newish ones to reuse existing.",
      "Except for that the 6980HX and its Radeon 680M GPU is a 12 CU APU Product, whereas \"Raphael\" seems to shape up to have a 4 CU Design, that in anything but the top end SKUs seems to be binned to 3 CUs for the vast majority of first wave Desktop APUs for AM5.  \n\nYes we heard rumors about \"Phoenix APUs\" being potentially 24 CU Parts, but nobody yet knows if those are meant for Desktop Sockets, when they will come, or what kind of Tradeoff will be made on their CPU side to make enough spacial and thermal \"room\" to fit them there.",
      "Yep, gonna be interesting in three years.",
      "It's worth pointing out that the RX 6400 is out now while the AM5 APUs are still at least half a year or longer away.\n\nI don't see what's so mind blowing about a future APU outperforming an existing low end card.",
      "There are both Raphael and Phoenix. Raphael is the Zen 4 with just some not-too-fast iGPU, kinda Intel UHD.",
      "All APUs we got on AM4 were repurposed Laptop Chips, in which offering \"powerful graphics\" makes sense for single chip thin & light / cheap designs that are space and power constrained, that were put in Packages that allowed them to run on Desktop Boards, but they all were monolithic designs that sacrificed CPU Performance by taking some space from the CPU portion to fit the GPU parts in.  \n\nFrom what we know so far, the reason \"all AM5 CPUs will be APUs\" is because AMD tries to streamline their lineup, by getting rid of monolithic designs, and making the iGPU part of the IO Die, to still be able to offer multi chiplet chips without wasted duplicated resources.  \n\nthose IO Die iGPUs will not necessarily always be on the same process as the CPU chiplets. AMD is trying to get to the \"good enough for basic tasks\" APUs intel has basically had since 2nd Gen Core.  \n\nYes, they might still do \"more powerful\" APUs, but you can only make integrated graphics so good until you run into space, power and cooling issues, because whatever iGPU you decide on still shares the same contact surface and cooler on top other stuff that fits into the socket does.",
      "The rumours out there, for example this one from a leaker that has atleast in the past been reasonably accurate (Komachi) points to a 4CU 0.5Tflop iGPU for Raphael (Zen 4). https://videocardz.com/newz/amd-ryzen-7000-raphael-rdna2-igpu-could-offer-a-third-of-steam-decks-graphics-performance\n\nSome APU's probably will have more CU's, if we get designed for mobile APU's to desktop again (like the Cezanne based 5x00G we have now) as we  but at least, but i wouldn't expect the full AM5 lineup to have powerful gpu's for now. There seems to be a good chance that the desktop parts get a Intel like iGPU, and not something more powerful as for example Rembrandt has in mobile (Ryzen 6000).",
      "Even if that rumour will end up being true IIRC those iGPUs are supposed to be very weak and even then that won't suddenly add iGPUs to all of the AM4 CPUs and other CPUs lacking iGPUs.",
      "Construction Wise, with how Chip and Memory are layed out on the PCB, and how much space and attachment points they have for putting a cooling solution onto it, it much more resembles a GPU that happens to contain CPU cores too than the other way round.  \n\nThe size you have to work with to fit everything is the CPU socket, the heat transfer is not direct Die cooling but is an IHS, and the amount of power you can push through it is determined by how the motherboard VRM is layed out, all this restricts an APU on a PC motherboard far more than the chip of a console.",
      "Presumably, there will be more CUs in future APUs than the 6400 has.",
      "and yet the rx 6500 xt is born as a companion of ryzen 6xxxu/h for cheap(ish) thin& light with discrete gpu",
      "You can only plug so many things into a motherboard. Do you think they're going to start making motherboards with like 8 display outputs?",
      "I wouldn't be so sure. There are still plenty of CPUs on the market without iGPUs which will require \"display adapter\" level graphics card for people who don't game and I don't see Intel's iGPUs making a similar leap at this time.",
      "Something this subreddit never seems to remember is that all the Ryzen generation APUs support displayport multi signal transport, ie multiplexing. You can plug a DP-MST splitter into any of the motherboard outputs and split one port into 3 to 4 independent outputs.  I've been using one for years now.\n\nExample:  https://www.arrow.com/en/products/b156-004-v2/tripp-lite",
      "The PS5 is cooled with liquid metal, a big chunk of solid metal and a fairly large fan though.",
      "There are a few form factors where that's actually a good idea, but that's not true for most.",
      "The market segment that the card occupies is \"inexpensively upgrade Small Form Factor \"Office\" Desktop PCs that only have low profile expansion slots and come with PSUs that provide 0 PCIe Cables, so limits upgrade choices to sub 75 Watts Cards that can be entirely powered via the PCIe Slot itself.\n\nAnd considering you currently find mostly intel 3rd and 4th gen Core Series Chips in Machines that fit that bill being turned into \"cheap entry level gaming PCs\" with cards like that, there will be VERY much time until iGPUs advance enough in these types of system until they make this type of card obsolete.",
      "I've only seen one mostly baseless rumor of a >6 CU desktop AM5 APU, and even that at 20-24 CUs would only put it around a 6500XT with good RAM. If we do get stronger APUs for Zen 4, I can't imagine them coming out in the first run",
      "No, we don't want to pay for a $5000 CPU just to get 64GB ram...",
      "6000 mobile series doesn't just support ddr5 but it's only ddr5"
    ]
  },
  {
    "brand": "amd",
    "generation": "6000",
    "tier": "low",
    "matched_keywords": [
      "6500xt"
    ],
    "title": "AMD Radeon RX 6500XT with 6nm Navi 24 GPU to feature 2815 MHz boost clock",
    "selftext": "",
    "comments": [
      "Well, at least that's confirmation that it shouldn't be slower than a 5500 XT. Looking forward to reviews.",
      "This GPU is a joke.  \nNo AVI1 decode, zero hardware encoder (the only media capability is decode for h264 , h265 and vp9 )  \nOnly Pciex 8x, only 4Gb with 64 bits (only 2 memory chips).",
      "the only thing clear from this is it's not gonna cheaper than 5500XT. imagine >$250 MSRP for a 4GB new gpu in 2022...",
      "Wasn't it AMD who proclaimed that \"4GB GPU VRAM ‚ÄòNot Enough‚Äô for Today‚Äôs Games\", and just look at them now, hilarious.",
      "I'm more interested, how bold AMD will be with MSRP. My bet is $249 which should translate into around $400 in actual retail",
      "> No AVI1 decode, zero hardware encoder (the only media capability is decode for h264 , h265 and vp9 )\n\nHas feature parity with my budget phone lol.",
      "> Is the 6500XT supposed to be similar in performance to the 5600XT?\n\nNo. It should be somewhat faster than a 5500 XT, but nowhere near a 5600 XT.",
      "What has been driving the scalper prices is every card's effectiveness in mining. Since this card will only have 4GB (not enough for good mining) it will help keep the card price more realistic for gamers. For example, see the scalper prices for rx 580 8GB vs rx 580 4GB.",
      "In terms of traditional rasterisation performance ,this will be a downgrade from your GPU since this will probably be somewhere between an RX 5500xt and RX 5600xt while your card is already faster than a 5600xt (even upgrading to an RX 6600 from your card would be a side-grade)",
      "It is not just about some specific card's effectiveness in mining. It is about the whole market- if miners can pay 2x price for cards (choosing the ones that are best for them first)- then the gamers are left with depleted market, and prices go up for the rest of the cards too.",
      "and I'm very realistic about AMD's greed. Just look at Zen 3 pricing, Or lower 6600 -/XT pricing.",
      "The only thing that would really irk me is if there's no encoding support at all. Still, most consumers have very little interest in encoding.\n\nFor the rest, AV1 seems like a rather dead standard, PCIe x8 shouldn't be too much of an issue, and 4GB is great if it makes the card less attractive to miners.\n\nSure, in a normal market that would have indeed not even be worth a desktop release, being relegated to entry level laptops, but beggars can't be choosers, and if the market price of this is good enough, I'm sure there will be takers.",
      "Imagine how bad we got that it's **optimistic** to think entry-level GPUs will cost 199$ ...\n\nThese guys are selling us almost \"nothing\" for 200-300$ nowadays...",
      "I miss the days when you could buy a 60 quid cpu and a 120 quid gpu and be on par with consoles.",
      "2815mhz boost clock is nice, as long as we do not see too much price \"boost\" I would assume üôÑ",
      "First paper launch in 2022 comming soon..\n\nRDNA2 and Ampere are \"lost\" generations.",
      "You are way to optimistic in my opinion. Given the 6600 MSRP i fully expect this card to be 249$.",
      "If AV1 is dead, what do you see as being the future? Are we just going to be stuck on H.264 forever? H.265 is dead because of the HEVC Advance guys, Google has moved all development of VP9 to AV1 as its replacement, and nobody trusts the MPEG process anymore so nothing is likely to come out of there.\n\nI think AV1 is still the the coming thing, it is just that the pandemic has delayed things a bit.",
      "man the fucking 1650 super is only 4gb vram, and it gets scalped everywhere. fucking thing is sell for over 450 usd. dunno why people pay that much for that card, that is not even for mining. is the scarcity and demand that makes high prices.",
      "Btw, you can claim the tomb raider trilogy for free on Epic Games (till January 6)"
    ]
  },
  {
    "brand": "amd",
    "generation": "6000",
    "tier": "low",
    "matched_keywords": [
      "6600"
    ],
    "title": "RX580 upgrading to RX 6600 challenger D",
    "selftext": "I have an R5 5600G, RX580, and 16gb of ram. I play a game called, ‚Äúcounter strike‚Äù which is a hard game to run and my rx 580 is starting to lose its performance. So I found the 6600 and was wondering how good it would perform and if it‚Äôs a good gpu for my system. I get around 146-170 fps on my current graphics card so what would be the estimate of fps I would get on the 6600",
    "comments": [
      "I need a new gpu because it will drop below my refresh rate and cause stutters and I need something that will stay above my refresh rate",
      "6600xt  is best value compared ,, to 6600 and 6650 xt. Go for 6600 xt if u can",
      "\"starting to lose its performance\"\n\n\"170 fps\"\n\nwtf kind of monitor do you have on an old ass card for this to not be good enough?\n\nbesides, counter strike is generally CPU bound anyways.",
      "it purely depends on area. new in my area rx 6600 is 250-300 but the xt is 500+ and only through amazon. used the 6600 is 200 and the xt being 200-250. so location is a big factor.",
      "165 hz Koorui 24E3",
      "I agree,, m just goin off their msrp price..it launched for 329 vs 379 for xt. For 8gb cards, i would not buy new.. since they are bout to be faced out soon like the 6gb ones\n\nI would also go for 6600xt for 250 other than 6600 for 200 (same $50 difference). Its 20% faster with only 30watts more.",
      "I see. Understandable have a nice day. Usually people with a 580 are 1080p and not super high refresh rate so yea def time for an upgrade",
      "For sure, I‚Äôm hoping that I can get pretty stable 200 frames with the 6600 because I don‚Äôt want to waste 200 dollars on a gpu to get similar performance to the rx 580",
      "Ok, I‚Äôll look into that. Thank you for the suggestion"
    ]
  },
  {
    "brand": "amd",
    "generation": "6000",
    "tier": "low",
    "matched_keywords": [
      "6400"
    ],
    "title": "ASRock launches Radeon RX 6400 Low Profile GPU - VideoCardz.com",
    "selftext": "",
    "comments": [
      "Got an RX6400 for a server as AMD is easier with fully open source Linux. Absolutely trash for almost anything but HTPC or server video output. The PCIe interface really hobbles it.\n\nEdit: It does what it is made for really well. Cheap video output in low profile systems.",
      "Arc A380 is better for HTPC because of encode support and AV1 decode/encode cost about the same to biggest con is power consumption and it's a 2 slot card.",
      "That's where the A310 comes in",
      "No AV1 encode/decode really hurts this card. I wish AMD would come out with a better half height card. The Sparkle A310 ECO is the better buy for people looking for a discreet HTPC setup.",
      ">Absolutely trash for almost anything but HTPC or server video output.   \n\n\nWere you expecting much more from such a card?",
      "the video outputs are also cripped on the RX 6400/6500XT, AMD segments the UHBR20 to the workstation versions of the cards.\n\n(yes, there is a W6400, crazy but true, that's how much of an \"only intended for laptops\" chip it is! and as it turns out, there is nothing wrong with putting an encoder on a laptop dGPU either, intel does it too!)",
      "Nope, it does exactly what I wanted it to do for ¬£60. :) I cannot complain at that price point.",
      "Seems like the pace of GPU improvements has really slowed.  \n\nI have an ancient GTX 1050 in my HTPC, and am trying to find an excuse to upgrade it, but can't really find one.   I think I bought the card in 2016 or 2017, and yet it still seems to be comparable to low end power efficient cards in '24.\n\nBack in the day using an 8 year old card would be unfathomable.",
      "An rx6400 is actually one of the few decent low power (& low profile) GPUs out there. There's definitely a void in that segment of the market. It wasn't that long ago that the rx570/580 cards were popular, this rx6400 performs similarly to those cards.\n\nIt's not the card you'd pick up for mid or top tier gaming, but it's not marketed for that. This is one of the few choices for people with OEM or slim PCs that don't have available PCIe power connectors.",
      "More low-profile, single-slot, PCIe-powered GPUs are always welcome.",
      "Seems late to the party. I bought a Sapphire one almost exactly 2 years ago.\n\nI hope that AMD introduces at some point a better low end low power GPU.",
      "Don't need to just say 6500xt. All the cards up to 7900xtx don't use uhbr20.  The latter uses uhbr13.5",
      "I have detected a link to UserBenchmark ‚Äî UserBenchmark is a terrible source for benchmarks and comparing hardware, as the weighting system they use is not indicative of real world performance. For more information, [see here](https://www.reddit.com/r/AMD/wiki/userbenchmark) - This comment has not been removed, this is just a notice.\n\n*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/Amd) if you have any questions or concerns.*",
      "The ceiling has been raised, but the floor has remained stagnant. From 2016 to 2023 we had the RX 480, RX 5500XT and RX 6500XT all performing similarly for the same $200 price.",
      "Given that they never released a low-end low-power RDNA 3 GPU, and they're supposedly only going to target the mid-range & low-end for RX 8000 series, we may ideally get it in 2025 or 2026.",
      "Sorry, I've been very confused this whole time and meant RX6300... DOH!",
      "How does this compare to an RX 550?",
      "Frame gen support saves this card really. Most games prefer some FSR.\n\nStill, the best low profile option for sensible money.\n\nPlz rx 6600 low profile anyone??",
      "True, especially when paired with an old office PC.",
      "~~Well its around similar performance to an RX 580, or a GTX 1060.~~"
    ]
  },
  {
    "brand": "amd",
    "generation": "6000",
    "tier": "low",
    "matched_keywords": [
      "6600"
    ],
    "title": "RX 6600 fan curve suggestions.",
    "selftext": "is this a good fan curve for this card? I don't have a lot of experince with gpu fan curve tuning so asking for some suggestions & yeah I keep zero rpm feature turned off all the time.",
    "comments": [
      "Looks good, actually you need to tinker it yourself. Boot a game then test whats the quietest curve you can get without the card heating too much",
      "Why the hell are you going this high? Set it to max 50% and forget it. My 6800xt draws twice as much power as yours and tops at 48%",
      "I I personally prioritize my stuff running cool so I set the final slider to 90¬∞ and 100% and the fourth slider to 75¬∞ and whatever percentage you need to maintain that temperature under full load I think mine‚Äòs at like 50% on my 7800xt the rest from there I slowly have it ramp up only being at like 10% at idle I personally don‚Äôt like running zero fan\n\nI just don‚Äôt like seeing my GPU at anything higher then 80¬∞ it starts to thermal throttle but at the same time I don‚Äôt need it running at 100% at 80 that‚Äôs ridiculous",
      "thanks! I will try.",
      "My 4070 super maxes out at 40% above 90 and is mostly forced to stay at 30 (minimum). \n\nI‚Äôm with you, lower it all the way",
      "alright I will try that too."
    ]
  },
  {
    "brand": "amd",
    "generation": "6000",
    "tier": "low",
    "matched_keywords": [
      "6600"
    ],
    "title": "Are these ~$300 6600 xt prices the new norm or is this something that I should jump on now?",
    "selftext": "I won‚Äôt need one for at least a month but I always want to take advantage of the prices. Are miners going to buy these out or is it likely safe to hold off a couple weeks?\n\nEdit: can anyone tell me whether the 6600 CT‚Äôs performance is actually $300 good? I‚Äôve never had a gaming Pc. My monitor is 144hz and it seems like I may max out playing on med-high?",
    "comments": [
      "With the crypto market essentially in free fall right now, you won‚Äôt have to worry about miners for the time being.",
      "More like for the upcoming 2 years.. \n\nThen another crypto boom could happen",
      "Futureproof? You'll be buying a 7800XT in November like the rest of us.",
      "In Europe they are all over 400‚Ç¨.",
      "8 years ago, a, AMD x600 / Nvidia x60 series card would run you $150-250. Let's hope we can get even closer to that.",
      "Exactly, look at Bitcoin‚Äôs historical price: peaking in late 2017/early 2018 and immediately cratering in April that year. It spent 2 years below its 2018 peak before eventually recovering in late 2020 and growing for the next year. It‚Äôs been dropping again since November, but crypto is the poster child for volatility - there‚Äôs no way of knowing if/when it‚Äôll start gradually recovering or if it‚Äôll explosively regain its value like it did in 2020.",
      "No, not forever lol.  It's taking a dive as of late but it's not going anywhere.  The stock market has crashed and sucked a lot over the years as well.  Markets like this need to find their bottom and bear markets can suck, but they don't last forever.",
      "Not with currency inflation being what it is. Your dollar is now worth like 70-80% of what it was worth 8 years ago thanks to the crazy inflation over the last two years. $250 in 2014 money likely = $330 in today's money. So you still can get a x600 series today for $330, or $250 in 2014's currency. \n\nThere is inflation calculators out there that use 2% per year, but it's been closer to 5-10% for the last two years.",
      "Ah yes, cratering and mooning is exactly what you want in a stable currency‚Ä¶ right? Right‚Ä¶?\n\nHilarious, this shit will never become a legit currency.",
      "Oh awesome. Maybe I should hold off and 6700‚Äôs might come down in price with the decrease in demand?",
      "Not sure how much prices will go down, so that‚Äôs a game you choose to play. The demand may be lower but that may only mean items stay in stock a while longer. There is still a chip shortage going on into late 2023 I think is the last I heard. Depending on recessions, inflation, lockdowns, etc., demand may spike again as people look for entertainment at home. Not trying to scare you, but there are many variables that could change the demand overnight. With your short timeframe though, it may be ok to wait.",
      "The dollar and euro have been quite stable.\n\nUnlike cryptocurrency ü§≠",
      "rx 6600 for $300, rx 6600 xt for $360, and rx 6650 xt for $380 are the normal now, pretty much mining has died down for a while now",
      "> I *paid* 700 for\n\nFTFY.\n\nAlthough *payed* exists (the reason why autocorrection didn't help you), it is only correct in:\n\n * Nautical context, when it means to paint a surface, or to cover with something like tar or resin in order to make it waterproof or corrosion-resistant. *The deck is yet to be payed.*\n\n * *Payed out* when letting strings, cables or ropes out, by slacking them. *The rope is payed out! You can pull now.*\n\nUnfortunately, I was unable to find nautical or rope-related words in your comment.\n\n*Beep, boop, I'm a bot*",
      "Except this low could be tomorrow's high.",
      "Some of the 6600XT, from Sapphire and Gigabyte fell about 50‚Ç¨ last month. We see price movements, but as long people buy 5700XT cards used for 400‚Ç¨, nothing will happen there much. When the used market drops, the prime market will drop with them. But it might take another month.",
      "Lol when crypto devalues at 50% a year you aren't winning.\n\nInflation, until 2022, was about 2% a year or less.",
      "> ,for the time being the cards are below MSRP and well priced ,surprisingly\n\nThese \"MSRPs\" are well above what they'd be in a normal market, in a normal market the 6600 would probably have *around* a $200-220 msrp while the 6600 XT would be around $250-280, I would expect prices to continue to fall as they've been doing since earlier this year, Although inflation might help keep the prices up.\n\nhttps://pcpartpicker.com/trends/price/video-card/\n\nhttps://i.imgur.com/N9MTdDL.png",
      "The 6600 XT is good at $300, but it‚Äôs never even remotely deserved to be $379. I‚Äôd say get it.",
      "Depends what happens with crypto once Eth merges fully. I think they will stay down for a couple of years though, then we will likely see another shortage.\n\nDon‚Äôt be surprised if new cards try to keep the high prices and blame economy though."
    ]
  },
  {
    "brand": "amd",
    "generation": "6000",
    "tier": "low",
    "matched_keywords": [
      "rx6600"
    ],
    "title": "Is there any game I can play at a decent framerate with Ray Tracing in my RX6600 (I know it has the weakest ray tracing hardware)?",
    "selftext": "So far I've managed to enable ray traced shadows in Shadow of Tomb Raider, but in any other game I've enabled it, the performance drops to unplayable.\n\nAlso, my eyes can barely tell the difference when enabled in Tomb Raider. So I will also appreciate to know if there's any game I can enable ray tracing in my RX6600 that doesn't feel like a gimmick.\n\nWhat about ray tracing in Mario 64 port? Is it possible in AMD?",
    "comments": [
      "Doom Eternal?",
      "Surprised nobody else mentioned this. Doom Eternal runs extremely well with RT on. Control at 1080p with some lower settings, maybe. Metro Exdous should be a decent one as well. Cyberpunk will struggle",
      "Deathloop using FSR 2.0 maybe? The thing is that any game which has good RT effects that make a clear difference also makes use of DLSS to remain very playable with nvidia hardware; To have a chance at a similar experience, you'd need adoption of FSR 2.0 to pick up the pace and even then the performance impact is going to be more severe.\n\nI guess you could try Metro Exodus Enhanced Edition too, but I'm not sure how playable it is without DLSS.",
      "I'm an early RTX adopter.\n\nCurrently I have a 3060ti - I disable RTX in all games.\n\nI prefer higher frame-rates and most of the times, RT doesn't really stand out,",
      "At 1080p I get above 40 FPS in Metro Exodus, Control and Battlefield 5 with a 6600 XT on high to max settings. You should be able to at least test it out on those titles. At higher resolution you would certainly need FSR to get anything playable. Ray tracing hits cards from both vendors heavily. AMD more so than Nvidia currently. I was able to turn it on for long enough to realise it doesn't add nearly enough value to take the performance hit. Next gen cards will hopefully be far superior in performance from both red and green but I'm not personally sold on it just yet. Also, it depends if you consider 40 FPS a decent frame rate. üòÅ",
      "It is because it‚Äôs path traced, no traditional rendering.",
      "Ever since I tried raytraced things stuff like crappy screenspaced reflections sticks out like a sore thumb\n\nRt reflections are underrated. Honestly rt shadows or rt illumination is nice but rt reflections just make everything look right.",
      "I'm pretty sure that rx 6400 is the weakest ray tracing hardware.",
      "An RDNA2 APU, perhaps.",
      "\"RT doesn't stand out\" \n\nYou probably haven't tried metro Exodus enhanced, Dying Light 2, Cyberpunk, Control, ghostwire, Wolfenstein...",
      "Forza doesn't do Ray-tracing in game. It's only in the showroom, which makes it completely pointless.",
      "It is metro exodus low 540p-720p can run on steam deck at 30fps where 6500xt no matter what settings or resolution u gonna put it it's gonna be 15-20fps at most. Digital foundry tested it.",
      "I have a 3090 and although I like RT, it‚Äôs not a game changer for me yet",
      "Minecraft bedrock. Runs better than I thought",
      "Always nice to see a game apparently 'coded well' like Doom Eternal that runs well on older hardware!",
      "Even DLSS looks bad upscaling from under 1080p, disabling RT is a better compromise",
      "Imagine dropping below 90 fps for glossy blood puddles lol.",
      "How about you forget about ray tracing and just play games at 1080p. \n\nCard will never let you down there",
      "Quake II RTX..?",
      "You need to accept the possibility of locked 30 or 40 fps gameplay, using FSR or resolution scaling to play at under 1080p. Also possible lower presets of RT or generally lower presets for the game (Medium or High instead of Very High / Ultra)\n\nDefinetely do-able. Depends on the game of course.\n\n\nThe reflections in Hellblade look amazing. Metro Exodus Enhanced Edition and Control are transformative as well.\n\nResident Evil 7/8/RE2R/RE3R using FSR and maybe interlacing should give a 60 fps experience, depends on you what resolution / clarity you would accept.\n\nModern Warfare 2019 and Cold War have good optimization and RT shadows.\n\nAlso Godfall I think.\n\nThe Crysis Remastered trilogy has RT implemented. Nothing too amazing, but it looked nice. Your 6600 is slower than my 5700 XT and I played Crysis 1 Remastered with RT on Medium + Boost, at 900p (TAA is extremely clean), 40 fps, at High Settings (with LOD, Shadows and Vegetation on Medium)\n\nGuardians of the Galaxy might work.\n\nCyberpunk 2077 also is transformative, but might be entirely too heavy, even at 30 fps and reduced settings and resolution.\n\nThere are also a few other games that aren't AAA, with RT, you may try (Ghost Runner, Observer System Redux, Bright Memory, there was one Soulslike game I'm forgetting)."
    ]
  },
  {
    "brand": "amd",
    "generation": "6000",
    "tier": "low",
    "matched_keywords": [
      "6600"
    ],
    "title": "Mid-Range is Dead: AMD RX 6600 XT Review & Benchmarks (PowerColor Fighter)",
    "selftext": "",
    "comments": [
      "Holy shit what a disaster of a card in both performance and value.\n\n2 whole years later and you get a card that performs the same as a 5700xt except it has weak raytracing and costs 20$ less than the 5700XT's launch price. \n\nThe card also gets downright humiliated by the 3060ti which costs just 20$ more msrp to msrp.\n\nThis is the definition of a fuck it anything will sell these days card.",
      "When I first heard of the 6600 series I thought it would be a great stopgap gpu. Buy a good rig with a decent cpu and use this until next gen comes out... Well atleast I got a good laugh out of the reviews. Amds any% ruin the budget market is of to a great start.",
      "AMD is getting greedy boys, it's over, pack up.",
      "The 5700xt is in it for the long run boys. üò≠",
      "I know I'm repeating myself, but I really should've bought the 5700XT when I had the chance to.\n\nBut no. \"Hold off the purchase\", my mind said then. \"RDNA 2 will be amazing\", it said.",
      "Intel, save us, but unironically, huehuehuehue.",
      "The performance is meh and the price is absurd. \nBut with our current GPU market, this will be sold out.",
      "I disagree. Not everyone watches every single GN video. I'm willing to bet most casual people on the market have no idea what's going on, hear about a \"mid range\" card like the 6600x, and Google around for some reviews. GN has to appeal to those casuals who are coming in blind.",
      "miner's and the silicon shortage have already done that, they could have listed this card at an msrp of $199 and gamers still wouldn't have them and they would be scalped on ebay for $5-600",
      "I cant believe it has really come to this. Where my hopes for a decently priced 1080p card now lie with Intel.",
      "Yup, since RX480 I've been runnig AMD gpus for their great value, but the last generations are getting worst every time pumping those prices Nvida style.\n\nBudgets went from $150-$200 up to $350-$500, f-ing stupid.",
      "amd is still increasing profits from the shortage. they're not just selling these things high because costs are up, they're moving into nvidia profit territory. they may actually pass intel's gross profit soon since intel's chips are so far behind and they're dumping money to expand and compete with TSMC.\n\ncould blame miners for destroying the original MSRP last year, but AMD is 100% pumping you for more profit this year. weird seeing people trying to justify \"supply and demand\" for the stupid prices when that was intel's whole BS argument back when nobody wanted AMD chips and it was god awful for the market. just because they're selling out doesn't mean people should be fine with a price hike, especially when AMD and nvidia were playing games with prices even before the shortage and already hiked prices up a tier.\n\nbetter pray to god that there's a market crash or else this is just going to be the new standard pricing.",
      "Yes but Bitcoin value overall affects other cryptos that can be mined",
      "$5 + $500 shipping?",
      "Also:\n\n* 3060TI and 3060 have DLSS - if even some games you want to play  have support but no FSR support then that is a definite benefit (since you can still use FSR on the nvidia cards for other games).\n* Better RTX - depends if you care (personally don't give a shit about RTX and on the 60 cards you might end up with questionable FPS)\n* 3060 has 12G ram (hard to say if that will be a real benefit down the line)\n* 6600XT being a x8 card (see Hardware unavailable review doom results near end) can bite you in the ass if you are on a PCI-E 3 Mobo even now in some games, let alone in a few years... and people who try to get \"cheap\" (AMD probably wont go much cheaper this generation) GPU probably want them to last a few years...\n* encoding and other features - depends if you care\n\nEven at MSRP this card seems like a very poor offering (even vs other AMD cards not just vs Nvidia competition)",
      "I mean, the video has labeled time codes for a reason. If all you care about is the benchmark results you can easily skip the intro and get straight into the numbers.",
      "they cut the infinity cache too",
      "I bought mine last summer 2020 brand new on Amazon for $350 (after $25 rebate). I got lucky",
      "Even if you're not a casual, you have to start somewhere right? Most of GN's videos tell the whole story of a product without the need of prior knowledge and honestly is what draws me to their channel",
      "Damn. The worst years ever for videocards in many ways, with the bitcoin/covid shortages turning the prices to insane gouge levels too."
    ]
  },
  {
    "brand": "amd",
    "generation": "6000",
    "tier": "low",
    "matched_keywords": [
      "6600xt",
      "6600"
    ],
    "title": "I think it's weird how the 6600 XT was marketed for 1080p only",
    "selftext": "I really don't get why AMD (and everyone else) said this card isn't for 1440p. Just look at the marketing for it. They pretty much never mention 1440p, ever. People will tell you that the 6600 XT is mediocre at QWHD, they never\n\nI'm gonna go out and say that i'm satisfied with my 6600XT and I play at 1440p. It's run every thing i've thrown at it well at high settings, Insurgency Sandstorm, Battlefield 2042 (I only played it just so I could benchmark it at 1440p, that game sucks), Forza Horizon 5, CoD, etc. I've seen benchmarks of it at 1440p from other people and it did fine. Now the obvious exception is Cyberpunk but that game doesn't run very good on anything, and i'm fine with lowering to medium (which I think gives the 6600XT around 65FPS from what I saw from RandomGamingInHD's video on the card) and I don't really understand how it's lackluster for 1440p when it can run most stuff just fine even at high.\n\nSome people argue that the 3060 TI is superior in every single way and I do agree. The problem is, that it's just much harder to find one. Didn't find no 3060 TIs at my Microcenter but I found two 6600 XTs for just $540. Looking at eBay I find 3060 TIs at like 850 but i've regularly seen 6600 XT deals on r/buildapcsales.\n\nAlso the 6800 (non-XT) is marketed as a 4K card but it performs about the same at 4K as a 6600 XT would at 1440p which is really confusing as to why AMD says you should just stick to 1080p. If the 6800 is a 4K card then the 6600 XT is a 1440p card IMO.\n\nTLDR: I have a 1440p monitor, and i'm satisfied with my 6600 XT, and I think it gets too much hate.\n\nEdit: Lot of people tell me \"the 6700 XT is the 1440p card. Not 6600 XT\" the problem is, that NVIDIA has not one but two 1440p cards: 3060 TI and 3070 were both marketed for 1440p.\n\nHere's how I would've marketed:\n\n6500 XT: 1080p60 medium\n\n6600: 1080p144\n\n6600 XT: 1080p144/1440p60\n\n6700 XT: 1440p144\n\n6800: 1440p144/4k60\n\n6800 XT+: 4k60",
    "comments": [
      "Just my 2 cents here...\n\nFirst appreciate the feedback. It's interesting to market to gamers especially as it grows more popular. I always felt like \"1440p\" was this grey area where your average gamer might not know what it is and an informed gamer might do their own research beyond the marketing. What really matters to me is connecting to people with their use case. \n\nDo you feel like more people are aware of resolutions outside 1080/HD and 4k?",
      "But isn't the 6700xt marketed for 1440p?  I mean, it says right there on the boxes. https://images.offerup.com/y3PtGNMpbiTrdUH4FC5xmRyMKS0=/888x1920/38d6/38d6140b46994885b969b5f7cf6cc071.jpg",
      "Sure does. There is no silver bullet for marketing and there can be reasons to do or not do something without ruling it out. For instance on a shelf I think it can help quickly demonstrate what product class something is in, so putting it on the box seems pretty useful here! On the internet I think research is a quick search away, so on-the-box features seem less important to me personally.",
      "I just find it dubious how the 5700 XT was marketed as a 1440p card, and the 6600 XT, which performs like a 5700 XT, was marketed as a 1080p card.",
      "On some level I can understand the reason for it being marketed as a 1080p 144hz card, and I also doubt that the average PC gamer will go for 1440p by comparison.\n\nThe thing is that there definitely IS an audience for 1440p and i'm a part of it. The problem I have is how AMD priced this card only 20 dollars lower than the 3060 TI, which is a true 1440p performer and as a result this turned many people off from it. Paying close to 400 dollars for something advertised as a 1080p class card is really not the best look for your it, but once I look past that I could understand why one would want this card for 1440p. It's a big leap from 1080p in quality and many enthusiasts say it's the real sweet spot for gaming, not too taxing like UHD and better quality than FHD. In 5 years time I can see 1080p going the way of 720p today.\n\nHonestly I look at the 6600 XT as the ultimate 1080p card with an asterisk for 1440p next to it.",
      "I think the reason is product segmentation. 6700XT -> 1440p, 6800XT -> 4k, so to not mix up with 6700XT, it seems reasonable to put 6600XT in \"Premium\" 1080p, with 6600 non-XT being \"standard\" 1080p and 6500 series as \"entry\" 1080p. FullHD get bit crowded, but realistically no one uses lower resolution anymore.\n\n6800 non-XT is in similar spot, its neither fully 1440p, nor fully 4K.",
      "It mainly boils down to the memory subsystem of the card.  In order for GPU's to churn out rendered frames, they need to keep the shader registers fed with data to calculate from.  That data comes from the graphics memory on the card.\n\nUntil RDNA2, over the past 6 years or so, there have basically been two choices to keep those shaders fed with data.  \n\nOne is to still use GDDR memory but increase the number of memory channels.  This increases throughput, at the expense of die real estate and power consumption, because you need more memory controllers on the GPU, and more memory chips on the board.  It's actually a compounded problem.  Not only do more memory controllers on the chip take up space that might otherwise be used for more shaders, the extra power consumption of those controllers, as well as the chips on the board, might prevent the GPU from running as fast as it could due to power budget limitations.\n\nThe second is to skip GDDR and use HBM instead.  It uses a lot less power, and is a lot faster, because it has a much wider bus and a much shorter distance between the memory and GPU.  It's also a lot more expensive.\n\nAMD did something pretty innovative with RDNA2, however.  They added a whole lot of cache instead of extra memory controllers.  This greatly increases the effective throughput of the memory, while using less power.  It's not saving any die space (might be losing a bit), because the L3 cache takes up room by itself, but you're getting more performance from using that die area for L3 than more memory controllers.\n\nBut it's not a silver bullet.  How effective cache is depends on how big it is and how much distinct data passes through it.  The amount of data goes up with resolution (more pixels to render, with all the associated memory costs of that).  So as resolution goes up, the cache hit rate for a given amount goes down.  \n\nThe 6800, 6800 XT, and 6900 XT have 128MB of L3 cache, which gives those cards a good hit rate at 3840x2160, and an excellent hit rate at 2560x1440.  Combine that with a 256-bit bus, and the effective memory speed is in HBM territory.  The 6700 XT has 96MB of L3 and a 192-bit bus, which basically shifts the performance adjectives down a resolution tier.\n\nThe 6600 XT drops all the way down to 32MB of L3 with a 128-bit bus.  That means its memory performance is merely good for 1920x1080, and not quite adequate above that.\n\nSo while the card, computationally, is easily capable of handling 2560x1440 most of the time, it's going to spend more time than it should *not* computing anything while waiting on data from memory.\n\nYou can also run games at 3840x2160 with that card, and if they're old enough or graphically light enough, they'll work fine.  Just not as well as they would with a better memory subsystem.\n\nSo AMD was correct to market the card to the resolution it provides the best results in.",
      "Cards are marketed based on games being released today, not two year old games.",
      "If you look at the competitor, the 6600 GT/Ultra, it's made for 1024x768. Even 1080p is a huge win for AMD.",
      "It's just to promote the 6700xt",
      "6600XT is 100% capable of 1440p gaming in the 60-90FPS range that 90% of people would describe as a \"great experience\", below 60 is where I feel like upgrading is justifiable.\n\nSo AMD created this whole marketing thing to sell users on \"high frame rate\" gaming to convince users that 120-144FPS is the \"new 60FPS\", in an attempt to give the massive quantity of 1080p gamers a reason to buy a GPU this powerful. \n\nIn their defense, 120-144FPS gaming is a very different experience than 60FPS gaming so their is some truth in their claims, even if the motive is 100% to sell more and more GPUs. And ultimately a GPU being a luxury product anyways makes the entire purchasing decision a product of \"wants\" rather than \"needs\". \n\n6600XT is only \"bad at 1440p\" if your definition of bad is below 120FPS. \n\nFor reference, this card can be around twice as fast as an RX580.",
      ">it's weird how the 6600 XT was marketed for 1080p only\n\nIs not entirely true, is marked as the ultimate 1080p experience, 1080p max settings, and so on. So obviously, is not like you put 1440p and then is shit.\n\n>i'm satisfied with my 6600XT and I play at 1440p\n\nNobody say you wouldn't, just that the card is not so strong at 1440p and AMD is putting all their bets on it being capable to do max settings at 1080p, and this is what they want to sell. Perhaps to don't compete against themselves in the \"1440p market\", who knows, you could argue that it is or it isn't a good marketing strategy, just that they never said is 1080p only.",
      "üíØ\nHere is the thing : it is 1000% a 1440p card. The last year getting back into the PC hobby has shown me how aggressively branded and upsold the PC community is. It's insane what happens in PC communities with people buying these absurdly overspec'd GPU and CPU. A totally killer 1080p card that can easily play modern titles at totally reasonable frame rates in the 2019 GTX 1650 - these days PC marketing treats this like a extinct dinosaur. A 6600 XT is 100% a high performance 1440p card and anyone who doesn't think so has been endlessly brainwashed by the marketing and YouTube / social media influencer community",
      "That was a few years ago. Games were a bit less demanding.",
      "Yeah the RX 6800 is made for 1440p Ultrawide ;) Does pretty great at the resolution for me anyway. Apart from with RT on of course.",
      "totally agree\n\nmy old 5700xt was a 1440p card t6600 xt is 10% faster\n\nhttps://www.techpowerup.com/gpu-specs/radeon-rx-6600-xt.c3774",
      "Mickey I think one of the biggest misses in the PC gaming community as a whole is the value of 1440p/60hz. \n\n1440p60 should be talked about more when demonstrating rich single player story driven games like the Assassins Creed, God of War,  and Horizon Zero Dawn. \n\nThe conversation around these game is almost always driven by 4k because of the television market, but PC users have much more flexibility than the console user. \n\n1440p marketing in general needs an overhaul. It's the best price to performance resolution and AMD could help change some of the mindset around frames per second. Not every game needs to run at 120+ FPS for wonderful experience.",
      "I think they decided to market it rather as 1080p cause you can see clearly scaling issues compared to the nvidia cards 3060/3060ti when u go up in resolution in higher demanding games. But like you for me its perfectly fine at 1440p cause it handles the games i play.\nedit: and that probably was the right move as you can see in the rewiews for this card when it came out. This was its main critic point.",
      "Because they want you to buy the 6700 XT+ cards",
      "It‚Äôs definitely playable on 1440p, but it‚Äôs 1440p results aren‚Äôt that impressive compared to its Nvidia counterparts. \n\nThe 3060 is very close behind (5%) in 1440p and if on PCIE 3.0, it might end up being slower than the 3060. I know MSRP doesn‚Äôt matter much these days but people still do comparison based on MSRP and that wouldn‚Äôt seem nice to market as. \n\nNot to mention at 1080p, it‚Äôs right in the middle between a 3060 and 3060 ti, which makes it super attractive for 1080p gaming as it can run high refresh rate monitors."
    ]
  },
  {
    "brand": "amd",
    "generation": "6000",
    "tier": "low",
    "matched_keywords": [
      "6400",
      "6500xt"
    ],
    "title": "AMD entry-level RDNA2 Radeon RX 6500XT to feature 1024 Stream Processors, RX 6400 with 768 - VideoCardz.com",
    "selftext": "",
    "comments": [
      "Can't wait to see $500 price tag in my place, for low end 64bit bus card.",
      "Finally - 560X/550X replacements for double the price and double the performance - after more than 5 years.",
      "Nice to get more details and I'm sure that quite a people will be happy if we get a GPU without a power connector. If there are half height versions, I might even be tempted (as long as the price isn't exorbitant).",
      "RX 580 performance for double the price 5 years later. Incredible\n\nEdit: 4gigs of ram too lmfao",
      "Hey, that's my videocardz comment. :D",
      "but 4gb will cripple a lot of games too",
      "He's stealing your videocardz commentz. üòé",
      ">I made this.\n\nI made this.",
      "If this is true then the RX 6400 might dethrone the GTX 1650 GDDR6 as the most powerful graphics card that doesn't require a PCIe power connector (with possible exception of some workstation cards).",
      "27%VAT + greedy distributor..\n\nCheapest Rx 6600 sold at $600, and I can see this card might go $500. Haha",
      "So these are the RDNA2 succesors to Polaris RX 460 and 560.",
      "Mockup Scalper Raised Price",
      "GTX 1650 is based on the 12nm TU117 Turing GPU while the GTX 1050 Ti is based on the 14nm GP107 Pascal GPU.\n\nAlso the GTX 1650 is 25% faster on average than the GTX 1050 Ti and is closer to the RX 470 in terms of performance.",
      "no, same class of cards but 1050ti is pascal while 1650 is turing.",
      "Considering they're only 4GB, this might be the first GPU that isn't completely bought by bots.",
      "With this limited supply even these will be scalped if the supply isn't plenty.\n\nAnd be honest, I doubt AMD will sacrifice many wafers for these entry products when their top of the line chips sell out immediately.",
      "Generally only with ultra-high textures, where mid-low textures should have the game working just fine. Not ideal, but these are low end cards (likely, at mid tier prices).",
      "What about it? 128EU Xe is likely similar performance to the 12CU RDNA2 here, probably slightly worse. If the full 512EU DG2 competes with the 6700XT on performance, then I don't see how the 128EU (1/4 the size of the bigger DG2) will be able to pull out any significant wins against the relatively larger rx 6400 (1/3rd the size of Navi22).",
      "After what, like a year of the first RDNA2 release? I am glad we are getting any low end GPU release at all. Hopefully the stock is better but its highly doubtful and the MSRP will be comically high as a result as well.",
      "I was thinking maybe it'd be nice to upgrade my RX460 2GB, but not for these prices."
    ]
  },
  {
    "brand": "amd",
    "generation": "6000",
    "tier": "low",
    "matched_keywords": [
      "6600xt"
    ],
    "title": "From 6600XT to 7800XT and couldn't be happier.",
    "selftext": "",
    "comments": [
      "This shouldn't be allowed. Someone shouldn't be this happy.\n\nIs there any way I can sue you or effectively ruin your day? \n\nPlease, let me know.",
      "Their wallet surely would not have been. And maybe not even themselves if they had to skip some meals. And don‚Äôt get me started on the piss-poor Linux support for the inevitable install when Windows 12 rolls around to stuff some new ads down your throat.\n\nAll in all, mind your own business mate. Your circumstances ain‚Äôt theirs.",
      "Did the exactly same jump, from an xfx 6600xt to a sapphire pulse 7800x, and finally i can enjoy maxed out vr games and can i use my 144hz monitor to the max!",
      "Just remind them Nvidia exists and that they obviously made the wrong choice because even the base 4060 is the future with frame gen, and that RT is impossible on AMD.",
      "This is roughly my upgrade. 5700xt to 6800xt. It's a huge upgrade! Congrats!",
      "How can it be sarcasm, it‚Äôs very true that the ~~4050~~ 4060 is the better choice because it can definitely ray and path trace, and get all the AI generated frames, and has the better upscaler, and also can be powered by a hamster wheel.\n\nJust don‚Äôt ask about performance or price plz.",
      "Zero issues after one week. I never ever had a single crash with an AMD card in 5 years.",
      "This is sarcasm, right? I legitimately can‚Äôt tell.\nEdit: Judging by the responses, it is sarcasm",
      "I'm 90% sure that 95% of the Linux users are using Linux because they want to, not because they need to. Otherwise they would've already migrated to Windows and would be using WSL2 instead.",
      "Hahahaha come on PastaMasta09, enjoy life.",
      "I'd wager 95% of Linux users aren't using Linux because they want to, but rather they need to. Otherwise there wouldn't be extensive WSL support on Windows. Just like how most of the GPUs in existence aren't used for gaming.",
      "what a fucking man-child",
      "I moved today from an APU  to the 6650xt.",
      "They are not out of reach, we just have to play at 540p!",
      "What a card!\n\nRdna 3 has treated me well so far. Enjoy, dude üëç",
      "And amd‚Äôs drivers were written by some freelancer amd paid 200$ 5 years ago, and amd cards are made of potato chips compared to nvidia despite often being made entirely by the exact same manufacturers",
      "Man it would be hilarious if that wete true. Worlds most capable and cheap freelancer ever.",
      "Hey OP ‚Äî Your post has been removed for not being in compliance with Rule 3. \n\nBe civil and follow side-wide rules, this means no insults, personal attacks, slurs, brigading, mass mentioning users or other rude behaviour\n\nDiscussing politics or religion is also not allowed on /r/AMD\n\nPlease read the [rules](https://www.reddit.com/r/Amd/about/rules/) or message the mods for any further clarification",
      "Yeah if you're sure its only a stopgap then I guess its fine, just weary about buying used GPUs that were around during the mining craze. Most black friday deals are already out right now, there might be something extra on cyber monday.",
      "Congrats man"
    ]
  },
  {
    "brand": "amd",
    "generation": "6000",
    "tier": "low",
    "matched_keywords": [
      "6500xt"
    ],
    "title": "AMD Radeon RX 6500XT to cost 299 EUR in France - VideoCardz.com",
    "selftext": "",
    "comments": [
      "I hope my rx 570 isn't gonna die anytime soon ... fuck\n\n&#x200B;\n\nIntel, please be aggressive\n\n&#x200B;\n\nedit : it's the price of a freaking xbox serie s ...... i am really considering to go back to console like what the heck",
      "<< AMD did not communicate the pricing for Europe yet, which is typically the case when the card is not released. >>\n\nClickbait.",
      "Really doesn't matter what Intel's ARC ends up being priced at, it'll all get up bought up instantly and prices will double straight away. \n\nAs for AMD abandoning low end, they're pretty much saying that they want you to buy a console instead, seeing as they made money off the consoles too.",
      "When you can get a Series S (8+2GB 128bit VRAM) for 270 EUR.",
      "intel arc desktop likely postponed, no mention of q1 release anymore.",
      "on them not making a huge fuss over it?\n\nThink about it lol, do you really think Intel would not have made a whole carnaval about it if they had it ready for the next month?",
      "Anandtech's Ryan Smith twitter: ['At this point the company is still targeting the first Alchemist products to be in market in Q1 2022. But they aren't offering any additional details at this time, such as mobile or desktop'](https://twitter.com/RyanSmithAT/status/1479272782017925120).",
      "This is the price of a Xbox Series S. Sorry but computer parts are too expensive right now to justify the pc master race",
      ">The issue is more that 7nm is a very mature process. As a result the failure rate on their chips is very low. So in order to make low end product, they need to take good chips and deliberately cripple them.  \n>  \n>So if you are AMD or Nvidia, what do you do? You keep selling those 700/70/800/80 series where you have a lot of margin, because who cares ( for now ) that miners buy in bulk. Your CEO bonus is looking really great this year (remember its tied to stock and profits ) .\n\nNavi 21/22/23/24 are physically different chips, in order to make a low end product, AMD make Navi 24 chip, instead of making Navi 21 chips then intentionally cripple its performance.\n\nYou make it sounds like RX6000 consist of a singular die and singular configuration, no, it doesn't work like this.",
      "At this point buying a series X and gamepass and waiting till 2024/5 seems like the best bet.",
      "I just bought a ps4 pro for $290 and jailbroke it. fuck em all lol",
      "Shit sucks(Sorry for the foul language). This card is literally perfectly tuned for the current situation, but it sucks so much. It's so cutdown that it's almost shit. No AV1, PCIe 4 x4, 4GB VRAM, Slower than the RX 5500 that is replacing,etc. And now this insane pricing for a card that would otherwise be $99. Sigh.............................................",
      "1650-s are going around that price, and this is according to their benchmarks better then that, again AMD has made a lackluster card that somehow manages to be for a week or two the best card in that price range. Can't wait for crypto to die, luckly it's dropping",
      "My backup PC uses an RX 470 8GB which I got used for 80‚Ç¨ (must've been ~2019) before the supply crisis. The chip is pretty good - it does 1320Mhz at 1075mV and the vRAM can do 2000Mhz, all while staying at or below 110W.\n\nAdditionally, it does have support for video encoding+decoding and doesn't crap itself when data has to be moved over the PCIe bus. The price when new was at or below 215‚Ç¨ (2016, MSI Gaming X model). Don't let yourself get ripped off.",
      "Launch price $335 in JP, so that means $450+ actual retail price.",
      ">AMD/Nvidia do not understand that any card that goes to miners, is a potential customer they are loosing out on.\n\nI'm pretty sure AMD/Nvidia know their businesses much more than we do. \n\n>And no, its in Nvidia and AMD their hands to put limits on the prices, they control the supply chain and can literally dictate terms.\n\nNeither company can afford to piss off their customers that much and demand price caps.",
      "Well, yes, but it's likely laptop limited release.",
      "That's about ‚Ç¨150 too much, if you ask me.",
      "You're too optimistic",
      "> As for AMD abandoning low end, they're pretty much saying that they want you to buy a console instead, seeing as they made money off the consoles too.\n\nThe margins that AMD gets on consoles is extreme low. Its always been like that. Their profit is in the bulk amount but their mainline GPU's is where the real profit is at.\n\n> As for AMD abandoning low end, \n\nThe issue is more that 7nm is a very mature process. As a result the failure rate on their chips is very low. So in order to make low end product, they need to take good chips and deliberately cripple them.\n\nSo if you are AMD or Nvidia, what do you do? You keep selling those 700/70/800/80 series where you have a lot of margin, because who cares ( for now ) that miners buy in bulk. Your CEO bonus is looking really great this year (remember its tied to stock and profits ) .\n\nThe fact that you may turn a lot of customers away to (low margin) consoles, is a issue for later. A lot of companies prioritize short term profits, the fallout is a issue for the next guy while they go on \"pension\" with loads of cash in their bank accounts."
    ]
  },
  {
    "brand": "amd",
    "generation": "6000",
    "tier": "low",
    "matched_keywords": [
      "6400",
      "6500xt"
    ],
    "title": "PowerColor confirms Radeon RX 6500XT/6400 4GB through EEC filing, AMD BC-2235 mining card spotted - VideoCardz.com",
    "selftext": "",
    "comments": [
      "4gb in 2021/2022 is a bit silly. I would think 6gb would be the new minimum for a gaming focused card. Even if that focus is on 1080p or more entry level gaming.",
      "I wonder what the MSRP and eventually retail prices are gonna be",
      "real world price $400 and $500 respectfully then",
      "People are still selling 1650's for over 300 on Amazon. Mining performance is irrelevant, if they don't stop scalpers from getting them the price will be artificially inflated. They have literally bought out the market to the point where normal retailers and resellers are using scalper pricing too because they can.",
      "Man, imagine being able to get some new life into your 980ti by just throwing like 8gb of GDDR5 in it.",
      "MSRP: $159-179 for the 6400,\n$200-229 for the 6500 XT",
      "Glad that I got my RX 590 in 2019. Good luck to those still actively looking for a GPU.",
      "I can't help wonder if it is related to the ongoing fab situation driving up the cost of RAM. Makes me wish GPU RAM was as upgradable as CPU RAM.",
      "If the 6600 cards considered 1080p cards, then these must be the 1024x768 cards",
      "Probably not quite that much, depending on availability, since these won't mine well and are too low level for that many people to be interested.",
      "There are a lot of games you can play on a 4GB card. Not everyone is laser focused on playing the latest AAA games.",
      "So get a 710? This will be faster than a 580/1060.",
      "Is the rx 560 still relevant today? Should we still be comparing budget cards to it? This thing should be at least as good as RX 580, which has a 256 GB/s bandwidth.",
      "Halo Infinite is showing us what a lack of optimization can do.\n\nOn the consoles, it runs on a R7 260X with DDR3 and a RX 580.    Yet on a superior spec'd PC it runs abysmally.   \n\n 343 pulled 120 FPS support from XBS, which pushes my suspicion further towards lack of optimization/bloat.",
      "Relatively a bargain. Relatively a really fucking bad price, too.",
      "Are these meant to be gaming focused cards though? 6500xt likely but the 6400 sounds like a prebuilt card especially seeing low profile models and no power connectors. \n\n4gb cards are still holding up ok. My bedroom rig uses a 4gb rx470 still enjoyable. Not every new title is a graphic powerhouse that needs the best of the best and tons of vram.",
      "I think that was XFX that did the Fat Boy",
      "This.\n\nOnce again, My 4 gig 570 is quite happily chewing through a lot of the id software back-catalogue right now, and even manages to keep up in the new Doom games (2016 and Eternal).",
      "Is it though? With 14 Gbps GDDR6 it will have 112 GB/s of memory bandwidth which is the same as the RX 560 which had a 128-bit memory bus while consuming less power as a wider memory bus requires more power.\n\nWith 16 MB of L3 the effective memory bandwidth will most likely be higher than that of the RX 560.",
      "i wish AMD would release a Rx 6700 (non xt) but that won't happen anytime soon"
    ]
  },
  {
    "brand": "amd",
    "generation": "6000",
    "tier": "low",
    "matched_keywords": [
      "6500xt"
    ],
    "title": "The 6500xt really is a message to the Polaris gang",
    "selftext": "The message says: \"There will never be an upgrade for you in this price class. Never.\"   \n\nThey want you (and me) to upgrade to higher price tier, preferably before crypto crashes. And it's tempting. It really is.  \nI'm not sure if they even meant this card to be sold in large numbers, other than to desperate people who have no gpu at all. It's really meant to push the people who are waiting for a cheap upgrade, to go for higher tier, right now.  \n\n(Well I'd be upgrading to higher tier card anyway if there was a perfect one, like 16GB(or more) of vram, cuda, blender performance, gaming performance and at msrp (or below)) \n\nBTW, a large computer parts store here in Finland got a batch of Asus 6500xt's, 5+5 cards, ones for 329,90‚Ç¨ and others for 369,90‚Ç¨.  \nThe $199 msrp converts to 217.50‚Ç¨ with 24% VAT. Someone is pocketing 110-150‚Ç¨ extra from these cards. They have sold 3 of them so far. Doesn't feel too popular.",
    "comments": [
      "Well, I just moved to lower tier: I use iGPU and mostly content with that. I'll play cyberpunk in 10 years when in will comfortably run on the iGPU. Not a big deal. \n\nI won't pay those crazy prices for dGPUs. Just no.",
      "If you bought a 1080 TI in 2017, you got the greatest card to ever exist period. Maybe not objectively (3090 TI is obviously better), but that thing was the king of performance to value. It still runs well at 1440p.",
      ">  I'll play cyberpunk in 10 years\n\nHopefully they will have delivered what they promised by then, and maybe the free DLC too!",
      "Anyone with RX580, RX480, Vega56 and so on should be strong right now and keep lowering settings..",
      "MSRP for those cards don't exist and arguably never did.",
      "Not just the Polaris gang. All the cards below the mid to high segment. Neither vendor seems interested in offering serious entry or entry to mid level cards any longer.",
      "Thank god there's more to life than gaming, or so i heard",
      "They did for FE/Reference, but as we know those are were sold at extremely limited supply.",
      "The 1600 series was not really a big enough upgrade to justify. Would say the closest thing to a good upgrade was the RTX 2060 at $350",
      "Pretty much what I've been doing the last few years on a 1060 6GB.",
      "What the hell are you talking about?",
      "When they can get this much more for mid and high end cards and while Gddr6 is scarce and expensive, of course they aren't.",
      "You know it's not only USA on the world map right? Eastern Europe doesn't even have a authorized seller for Nvidia FE for example and what drops on west-central Europe is not nearly enough.\n\nSo I can pout and cry as much as I want because the stock is non-existent or if aib exists it's overpriced by 2.5x.\n\nAlso \"they did sell some\" smells more like a reason for the people to say it exists but don't fool yourself and don't try to come up with motives. People shouldnt protect corporations anyway, doing that it's their job not yours as a customer, I haven't heard anything from them with regards to the situation because it can backfire but by god the community does it pro-bono",
      "I said with DLSS...",
      "Bitcoin used to be mined on GPUs, then asics came along and ended that. But guess what? new cryptos popped up like Etherium and used GPU mining.\n\nEtherium going PoS wont change anything, people will just move to something else. The entire crypto market has to decline for years to put an end of it.",
      "Right, but one can only expect an incremental upgrade after just 1-2 years. I was also staying within the general budget. RX 580 released at $229, so to have a 1660 SUPER performing 28% faster and still at $229 was okay progress after 2 years. (And more than okay if you accept the Nvidia premium for lengthier support cycles.)",
      "I usually only upgrade components when I get a four fold performance increase at the same price point... So I guess at this rate I'll upgrade in maybe 2030? xD\n\nSeriously tho. Last GPU I had before 1060 6Gb was a HD5850 bought in 2009. 7 years for that upgrade. I guess this one'll go close to 10.\n\nSo I'm giving as much TLC to the 1060 as I can. Undervolting, keeping it cool, cleaning it at least once a year, making sure the PSU is top notch clean current wise, having a wall plug with surge protection, etc.",
      "Best buy for FE, and AMD direct buy.\n\nYou can pout and cry about low stock, but they still did sell some and some people did get them at MSRP. Not to mention EVGA has been selling their 3080s +50 to +100 over MSR (ok a bit more Now, but for a long while it was 50-100 above MSRP).",
      "The 3060Ti at $400 would have been THE gpu to get. Insane value at that price. Which means AMD, to compete, would have had to price the 6600XT at $300-325.",
      "*hodl* til the storm passes, everyone. \n\nI'd be happy to pick one up for what it's worth to me, around $130- considering it bottoms out around where a RX 470 does, it's missing some major features, and it's fair to account for both money and technology inflation; I'd say this ought to be in the neighborhood of RX 460-470 money."
    ]
  },
  {
    "brand": "amd",
    "generation": "6000",
    "tier": "low",
    "matched_keywords": [
      "6400"
    ],
    "title": "is a RX 6400 to gtx 980 ti for 75$ a good upgrade?",
    "selftext": "My current system has a ryzen 5 5600 and an rx 6400 gpu.\n\nI found a gtx 980 ti (6gb) for 75 bucks.\n\nI used the video card comparison tool on passmark to compare the two and it looks like I get double the raw performance with the 980, and I'm hoping that FSR will help me with playing modern games at decent frame rates. My only concern is that it's an older card and I'm unsure how much its age would affect me if at all?",
    "comments": [
      "On paper, yes. In practice, hell no. Way higher power draw, it‚Äôs about to lose driver support as well (and maxwell is already‚Ä¶iffy in some games). If you‚Äôre going to go with an old cheap card, get a GTX 1080 for 100-120. More vram, more performance, much lower power draw. Still on the chopping block for driver support, but If you need SOMETHING for dirt cheap it‚Äôs a decent option.\n\nIf drivers are a concern, look for an rtx 2070 or RTX 2060 super for 140-150.",
      "It's hella old, the minimum for a GTX series in 2025 should be a 1080",
      "No.",
      "Save and go 1080 at a minimum.",
      "alright, thank you so much for the input!",
      "980 Ti is definitely faster, just far from the best option.",
      "That‚Äôs a down grade .aim for a 6700xt, 5700xt, 7600 or better 2080ti, 3070, 3060",
      "save up some more money and get a functional graphics card",
      "Won‚Äôt be faster when none of your games have compatible drivers. Just get a 2080 Ti."
    ]
  },
  {
    "brand": "amd",
    "generation": "6000",
    "tier": "low",
    "matched_keywords": [
      "6500xt"
    ],
    "title": "Why are posts about current 6500XT pricing removed?",
    "selftext": "http://www.reddit.com/r/Amd/comments/s97kgb/gnam_gnam_what_a_deal_and_for_this_price/htlzn50\n\nhttps://www.reddit.com/r/Amd/comments/s8tnzo/price_of_6500xt_is_close_to_450_in_greece/\n\nThese aren‚Äôt breaking rule 7. They aren‚Äôt shitposts nor are they memes/\n\nAnd these posts are especially relevant in light of Dr. Su statements:  \n>We‚Äôre positioning the launch such that ‚Äì and I know, you guys always say, ‚ÄôWell, yeah, they‚Äôre just saying that‚Äô ‚Äì but we really are positioning the launch at a $199 price point. It is sort of affordable to the mainstream. You know, we intend to have a lot of product out there.",
    "comments": [
      "I don't care if these types of posts are allowed or not but can we group them into a single megathread? There's only so much that can be said about the prices, it's not like they're going to change in the current economy unfortunately.",
      "thanks for your work and the prompt response",
      "There's at least three of them. But one of them stands out since he's on reddit 24/7 it seems",
      "At least one of them is a massive fanboy.",
      "Wow mods actually doing they're jobs thank you",
      "cause mods are amd fanboys",
      "Absolutely, but what we should be defining as the minimum for a \"shitpost\" should be much higher effort than the posts removed.",
      "I guess whether something is a \"shitpost\" varies from person to person.",
      "Needs discussing further, but we don't have an official rule against them so they should remain for the time being. Posts of this type usually tone down a little while after a launch.",
      "Posts have been re-approved. Thanks for raising.",
      "Sorry to hear that, I do personally try to engage a bit more in an official capacity, but everybody is to their own on moderating style.",
      "No problem :)",
      "This would be my preference as well. It was fine for a while, but it's annoying when they hide all other topics, so grouping them would be ideal.",
      "You can‚Äôt change the title it have to be the same thing.",
      "Because this sub is getting flooded by people all posting about the same exact thing. I don't know why the discussion can't all be had in whatever the top post is pertaining to that topic.",
      "NGL, this is the first mod I see in this sub.",
      "Very sorry about your post being removed, wasn't removed by me personally and sadly don't have an exact reason to give you. In the future, please do mod mail us to let us know, then all of the mods can take a look in to it.",
      "I start thinking whether some AMD employees are the mods of this subreddit so they could \"influence\" public opinion toward favoring AMD, while removing posts that expose their dark side of corporate greed.",
      "then it‚Äôs on them for not ordering ref. cards so they do have control (through maximum resale price contracts), aint it?",
      "5950X/3090 gigachad: \"peasant price discussions concern me not\"\n\nLul"
    ]
  },
  {
    "brand": "amd",
    "generation": "6000",
    "tier": "low",
    "matched_keywords": [
      "6600"
    ],
    "title": "New AMD Radeo Raise the Game Bundle Offer - Dead Island 2 & Callisto Protocol for select 6000 series (RX 6600 to 6900 XTX get both games)",
    "selftext": "",
    "comments": [
      "Sorry, my editing skills are way off today.  I got COVID-19 at the AMD Event in LV last week. . . . Unfortunately, not *everything* that happens stays in Vegas ![gif](emote|free_emotes_pack|dizzy_face)",
      "Call BB and tell them you want to do a \"paper return\" and rebuy to get the promo.  They are very good about it and have done it for me  in the past.  You probably won't have to physically return the card.",
      "how about you get absolutely nothing....",
      "Wow, I ordered a 6950XT less than 10 days ago and they add them.\n\n&#x200B;\n\nGuess I'll see if company will honor it or ill just return and reorder.",
      "Video killed the radeo star‚Ä¶",
      "Wish I knew if these were Epic or Steam keys.",
      "I only see checks on 6950, 6650 and one check for 6500.",
      "I see both games checked for all cards except for 6500 XT & 6400.  Those cards only get Dead Island 2.  That's what I meant by *RX 6600 (and above) to 6900 XTX* get both games ;)\n\n**UPDATED** with image of the promo bundle\n\n[https://imgur.com/a/UALMiR7](https://imgur.com/a/UALMiR7)",
      "Thank goodness you didn't say nVideo.",
      "There is no 6900 XTX btw",
      "Thats what I got when I bought my 6900xt.",
      "Then it just means that you aren't the target audience. Many people want the new MWII game, which comes with the Intel Arc card. That game is \"worth\" almost a quarter of the card cost here in Canada, which could definitely be appealing to some people. Just some food for thought.",
      "I don't know....I never really cared for these bundles.  \nI know this is a great way for GPU manufacturers make the hardware more attractive without reducing the price.  \nBut I am pretty selective with the games I am interested in. Especially since you can't even resell these games this just pretty much adds zero value for me.",
      "For uncharted bundled with my ryzen processor I got last week it was a steam key so I guess this will be the same. You had to download a verification tool to see if you didn¬¥t sell it where you needed to login to your steam to get the key. I don¬¥t think epic allows this kind of stuff even.",
      "And why exactly would they do that? Digital goods are literally worthless, the developer/publisher can generate an infinite amount of redeemable keys at no cost and sell those for a fraction of the retail value or in exchange for whatever they're receiving from a hardware manufacturer (marketing partnership etc).\n\nSo instead of increasing the sales of their products at very low cost to themselves, they should reduce their MSRP by probably at least like 10x whatever they paid for the bundled games? lol",
      "That's fair considering the 6400 would be only 30 bucks if you got both lol.",
      "Can you? Idk how it is with AMD, with Nvidia you need the card to redeem it",
      "That's how I see it. These games are a personal taste thing. Now if you gave me 2 games from a studio, with options, then there's value. This is not the case.",
      "Assuming it works like CPU's, the bundle code only checks if you have *any* hardware that's eligible for the promotion. So you can sell it to someone who has one of these cards.",
      "Anyone know when the Callisto codes go out on the rewards accounts?"
    ]
  },
  {
    "brand": "amd",
    "generation": "6000",
    "tier": "low",
    "matched_keywords": [
      "6500xt"
    ],
    "title": "AMD 6nm Navi 24 GPU pictured, coming soon to Radeon RX 6500XT graphics cards - VideoCardz.com",
    "selftext": "",
    "comments": [
      "Why are some GPU die's rotated at a 45 degree angle? More efficient path tracing to the memory or what's actually going on here?",
      "100‚Ç¨ GPU that will sell for 300‚Ç¨...",
      ">More efficient path tracing to the memory\n\nYep.",
      "Everybody complaining about the 4gb of vram but the fact you can‚Äôt mine eth on it will help it being in stock. A bunch of people are buying 1650s at stupid prices cause they need a card. A 6500 at 200$ is miles better than a 1650 at 250.",
      "Oh man, what times we're living in. I upgraded to RX 6600 XT which is what I would optimal 1080p card for almost 2022 now. RX 6600 is what I would say is bottom of what can handle AAA games in 2022 and near future.\n\nNow TX 6500 XT with just 4GB of VRAM - half as much CUs and cores seems like bad joke. It smells literally of 2GB RX 460, but at much higher msrp, and definitely higher retail price. It's just extreme gap even from non-XT RX 6600...",
      "and people will buy",
      "These would be great $99 GPUs in regular times. This section has been ignored for a long time with bad offerings like gt 1030 and rx 560",
      "My RX580 came defective from factory. My best friend had his die within 1 year and Asus didn't honour warranty: now in judicial process. Meanwhile he had to buy GTX1650 because it was the most affordable thing available with better performance than an iGPU. I'm stuck with an underclock/undervolt card I can't upgrade due to low availability and scalping prices. What choice do I have once this card dies? People either buy or don't play games.",
      "You seem to be missing the fact that the RX 580 is extremely overpriced due to its high mining performance, especially the 8GB version.",
      "RX 550 is the equivalent to the 1030.  a 560 was actually a decent entry level gaming GPU when it was new, 1030/550 not so much.",
      "There's no bad product, only bad pricing.",
      "6500 XT at $200? üòÇ what are you smoking dude? Must be strong stuff.",
      "I'm not saying it's impossible to find them at somewhat reasonable prices. It's just very unlikely because most sellers know they can ask for a higher price.\n\nI just checked the used market prices of RX 580s and the cheapest RX 580 4GB cards go for around 300 Euro (including VAT).\n\nThat's a similar price to what I paid for a new RX 580 8GB from an official retailer back in 2017 when the previous mining boom was starting.",
      "6nm isn't really a new node.  It doesn't need a 'pipe cleaner' product.  AMD are using 6nm cuz it helps them make more.  This wont help prices currently, but it'll help AMD make more money.",
      "Except Polaris cards are overpriced due to their mining performance as well.\n\nIf you have a choice between a 4GB Polaris card and a 4GB RDNA2 card then at least you know that the RDNA2 card will have longer driver support.\n\nThe only downside of the RX 6500 XT is that it will only have 8 PCIe lanes which will make the performance drop when running out of VRAM worse on PCIe 3.0 platforms. If you have a PCIe 4.0 platform there's no reason to consider a card like the RX 580 4GB unless it's significantly cheaper.",
      "Well that would be an exceptionally rare circumstance. \n\nIt's like saying that everybody paying $500 for a PS5 are suckers cuz I won one in a sweepstakes.",
      "A few things you're ignoring:\n\n1. the RX 580 in question is likely to be used and that means that it may require you to refurbish it (clean, repaste and in particularly bad cases replace the fan(s)). It will also likely not last as long as a card in a factory new condition.\n\n2. The RX 6500 XT will likely perform better than the RX 580 if only because the RX 5500 XT was already at the performance level of the RX 580. \n\n3. The RX 6500 XT will receive better driver support and it will receive driver support for a lot longer than Polaris cards. AMD dropped support for GCN 1.3 half a year ago and Polaris is next on the chopping block.",
      "I mean... even at $150 or so, it's not the worst option in the world.\n\nThese days you can get a decent enough CPU for around $150. But getting anything that actually plays games reasonably well at that price range is a complete fantasy. The GT 1030 is a fucking *terrible* GPU.\n\nThis thing's not very good, but at least you could get some decent medium/low 1080p gaming out of it for 3 years or so.",
      "not much sense talking MSRP when retails is 2x that on average, even more with some nvidia cards. Also my bet MSRP will be $249 on this one, so expect retail at over $400 if availability is similar to other cards.. And shit won't get any better in 2022, maybe in 2023 if lucky. It's just mining and silicon crisis combined makes GPU market especially totally absurd these days. So you either sit with your Polaris for till 2023 or pay premium scalp and grab the upgrade - that's simple reality we're living in right now. But good luck playing most AAA games with Polaris - Halo Infinite is basically unplayable even at low. Dying Light - don't think 60fps will be achievable. Elden Ring - maybe as game isn't much more visually impressive than Dark Souls 3, tho it's open world so who knows and optimization is always a question mark with Japanese games. So basically Forget AAA 60fps with polaris.\n\nAlso, at least here RX 6600 XT is around 200‚Ç¨ cheaper than base RTX 3060, lol. So it's good card in that sense, actually RX 6600-series is the only \"budget\" option right now at least in most countries at at least can play any AAA game in 1080p.",
      "Console. PC gaming  has been dogshit thanks to covid + mining hitting us at once. Fun."
    ]
  },
  {
    "brand": "amd",
    "generation": "6000",
    "tier": "low",
    "matched_keywords": [
      "6400"
    ],
    "title": "This might sound dumb but, has and ever made a non low profile version of Rx 6400?",
    "selftext": "I meant amd",
    "comments": [
      "Edit: Misunderstood, corrected comment:\n\n[https://pcpartpicker.com/products/video-card/#c=521&slotw=2,5](https://pcpartpicker.com/products/video-card/#c=521&slotw=2,5)¬†7 on this page (ignore the Gigabyte low profile one)",
      "Yes, it's called RX 6500 XT.",
      "They are asking about rx 6409 that are NOT low profile.",
      "oops that's my bad. u/Any_Restaurant_4953  [https://pcpartpicker.com/products/video-card/#c=521&slotw=2,5](https://pcpartpicker.com/products/video-card/#c=521&slotw=2,5) 7 on this page (ignore the Gigabyte low profile one)"
    ]
  },
  {
    "brand": "amd",
    "generation": "6000",
    "tier": "low",
    "matched_keywords": [
      "6600"
    ],
    "title": "[HUB] Radeon RX 6600 XT vs. GeForce RTX 3060, 50 Game Benchmark",
    "selftext": "",
    "comments": [
      "They cost roughly the same in Europe so its not really a discusion. The 3060 gets you DLSS, better raytracing, 12GB of ram and NVENC. The 6600XT is a really hard sell at a comparable price.",
      "TLDW:\n\nRX 6600XT - 50 games head to head vs RTX 3060\n\n**3% faster @ 1080p**\n\n**2% slower @ 1440p**\n\n*SAM was enabled for the RX 6600XT and Resizable BAR was enabled for the RTX 3060",
      "The 6600xt should be sub $200 and the 3060 $250. It's taking so long...",
      "duopoly bros wont budge",
      ">\" budget card benchmarks \"\n\nThese cards both launched at 329-379$ MSRP and are curently selling for 400$+. There is nothing budget here and it makes perfect sense to include atleast some RTX performance metrics.\n\nEven without DLSS and FSR both can do RTX although Nvidia is obv superior. With FSR and DLSS both are very capable of decent to good RTX performance.",
      "funny thing to say when you have AMD sponsored games like ac:valhalla and far cry 6 on the other side\n\nand since when is RE:Village Nvidia sponsored? That‚Äôs an AMD title as well",
      "Considering 3060 and 6600XT is pretty much at price parity in many market, 3060 is probably a safer bet for a GPU that stays relevant somewhat longer.\n\nI wonder when will 12GB VRAM actually start to net some benefit? Or maybe higher bandwidth will become useful first?\n\nBTW am I remembering it wrong...? I swear when 6600XT and 3060 launch my impression is 6600XT is significantly faster in raster only title, and somehow a few months after launch it no longer is the case?",
      "Basically, the regular AMD \"fan\" functions like this:\n\nPlease do not test any game that doesnt run well on amd. Pease remove all of them. Then cherry pick all the titles that are broken on nvidia and run disproportionately fast on amd. \n\nIm an amd fan damn it, don't give me real results, give me the ones that show amd winning",
      "I just checked and the cheapest 3060 here in Germany is 449‚Ç¨, cheapest rx6600xt is 430‚Ç¨, so yeah they are priced about the same.\n\nEdit: cheapest rx 6600xt is 420‚Ç¨",
      "That is not how you calculate the average, there are at least 3 better ways of going about it. As clearly stated in the video, we leave RT enabled when enabled by default which it is in F1 2021 (2022 isn't out yet), Resident Evil Village and Metro Exodus Enhanced Edition.",
      "Completely unbiased person right here lol. \n\nThe thing about RSR and NIS is a lie, both work the same but AMD has a better GUI switch for it. Quality the same as well.\n\nNow tell us how raytracing is useless and dlss is stupid.",
      "8-10%? Did you do the math ? Removing all 3 RT titles (and keeping all amd sponsord titles as well), only amounted for 1.4% \n\nRemoving all 3 RT titles, the 6600xt is 4.4% faster at FHD, 0.6% slower at 1440p.",
      "> Because ofc people buying this tier of GPUs are all about ray tracing.\n\nThe 3060 runs all those games fine with RT enabled. What's the problem? Wait, you are upset because the 6600xt has terrible RT performance so the 3060 shouldn't do it either? lol.",
      "Don't discuss with this guy, no point. \nHe's just upset that his GPU with about the same price isn't able to do the same in raytracing and has less features so he's mentally justyfing his purchase by telling himself that rt performance doesn't matter for this GPU tier and that those features aren't usable.",
      "I have my doubts if the RTX 3060 will be able to effectively utilize its additional 4GB of VRAM considering its performance level.\n\n> BTW am I remembering it wrong...? I swear when 6600XT and 3060 launch my impression is 6600XT is significantly faster in raster only title, and somehow a few months after launch it no longer is the case?\n\nThese tests have been done with updated drivers. That can change the result quite significantly especially when comparing GPUs that were close in performance to begin with. This is where the \"FineWine\" meme came from as GCN GPUs have gained a lot of performance over time due to improvements on the driver level.",
      "If they are enabled by default then i see no problem, Ray Tracing is the future of graphics and it will only get implemented in future games more often than ever before.",
      "Here in Japan:  \n\nRTX 3060: $370  \nRX 6600XT: $390  \n(before 10% sales tax)",
      "That would only be possible if the 7nm TSMC dies and G6 memory chips and components and shipping were all the same costs as 14nm Glofo and G5 chips and the rest 6 years ago. And the dollar worth the same as 6 years ago, too.\n\nUnless 7nm costs halved since 2019 then Navi23 is about $40 die, and G6 spot price is $10, so a 6600 costs like $100 just for the gpu+mem, so $200 is not a possible \"should\"",
      "We're not including older GPUs in these head to heads but if we did we'd probably show both results. FYI the second highest quality preset in F1 2021 also enables the same level of RT effects by default.",
      "I literally tried WD legion yesterday on my 3060 and on high settings and mid RT it almost never dropped below 60. No DLSS involved.\n\nYou can see in the video the 3060 does 90 fps on Metro Exodus with mid RT. No DLSS involved.\n\nF1 2020 ultra high q with rt also 90 fps, no DLSS.\n\nDLSS at 1080p depends heavily on the title, on some games is completely unusable, like in Warzone or God of War, in others like Cyberpunk or Watch dogs it is unnoticeable."
    ]
  },
  {
    "brand": "amd",
    "generation": "6000",
    "tier": "low",
    "matched_keywords": [
      "6600"
    ],
    "title": "ASUS says \"2x Fans. 2x Fun\": intros Radeon RX 6600 DUAL V3 graphics card - VideoCardz.com",
    "selftext": "",
    "comments": [
      "It's not like they have anything else for the lower mid-range. Anything newer is on more expensive nodes, and they don't seem very keen to lower prices on those until new nodes and products arrive.\n\nThe $200 price point being served by previous gen cards is probably the new normal.",
      "At least the RX 6600 is fine enough at $200 - the RX 5700 was the same performance for $350 five years ago, and that‚Äôs not great, but it‚Äôs about what we should get from two generations.",
      "Passively cooled GPUs reading the fans to fun equation üòê",
      "\"A good upgrade when new\" hasn't been a feature of *any* GPU for a long time now.",
      "It's more like a return to normal id say\n\nBack in the day this used to be pretty common to get rebadges of last gen nodes. It only stopped being common in the last decade or so.",
      "\"2 fans 1 chip\" an HBO special.",
      "Didn't realise so much vitriol for this card. It's a pretty good card on a budget. I'd argue that if you don't have the money for the RX6600/50/XT or the 6700/XT, this is a steal. It runs everything that's out with a less than 2 titles in the 30fps range.",
      "I actually think they gonna get replace by RX7600/7600XT. These are make on N6 node, pretty similar to N7 node. And RX7600 die size is actually slightly smaller. 204 vs 237mm^(2)",
      "It would make more sense to make a SSF oriented card with this sku at this point. I know the SSF community would appreciate more options in that space. If they made a low profile or low profile single slot if possible, that would be great.",
      "I recently purchased an Asus RX 6600 and I think it's fantastic for a budget card. Running all the games I play in Ultra at 1080p",
      "2x the RMAs.",
      "What an idiotic response lmao\n\nSpeak for yourself, but not everyone play those AAA rubbish that's released year after year.\n\nLots of people are PERFECTLY fine playing older classics like Total War, Mount & Blade and Skyrim, especially when the modding community for these are massive and guarantees tons of great new contents for free.\n\nThese games have never been demanding on the GPU but always extremely CPU limited, and Frame Gen have been the perfect tool to alleviate this bottleneck.\n\nPerhaps you should grow a brain and understand there are different gamers out there, ones that do not buy yearly trash release from Ubisoft or whatever COD games get pumped out lol",
      "Smaller shroud = less material.\n\n9 blade fan vs 11 blade = cheaper fan?\n\nSo, either more profit or get closer to $199 like Powercolor, Sapphire, and ASRock?",
      "might as well make a single fan version with target GPU temp at higher temp @ 80-85c. \n\nGPU like these need to be as small as possible & fewer fan and heatsink also contribute to cost saving, therefore can sell even cheaper.",
      "I understand where you're coming from, but at the same time this is also a subjective topic. For instance, if someone happens to still be running something akin to a RX 580 / GTX 1060 / GTX 1650 in their rig ( *and there are still plenty of these cards being daily driven today* ) and they are looking for the absolute best bang for their budget upgrade that's not only on newer architecture but will also provide a performance increase they'll easily be able to see - then the RX 6600 fits that bill perfectly while still fulfilling a spot in the ~$200 and below price range.\n\nNow one could argue \"Well, if the prospective buyer could just *add another ~$100* to their available budget that would open up the RTX 3060, RTX 4060, RX 6600 XT, RX 7600 / XT, Arc A770 as potential and even better upgrade options.\" An I agree, the caveat is that there are a lot of PC owners out there that are strictly budget buyers, they're pinching pennies, and they have absolutely no desire or need to spend any more then the hypothetical $200 + tax budget that they have set regardless of the benefits they would see, and the RX 6600 as well as the Arc A750 for that matter fit the narrative perfectly for these kinds of buyers.",
      "Now days they don't rebadge, they just fill the lower price points with old gens.",
      "Ppl are holding onto their hardware for longer too... Bet out there there's a person laughing with their 750TI.",
      "Asus Dual fills a certain use case. For example, the Intel NUC mini gaming PC range are a perfect fit for these cards",
      "\"We noticed a scratch on the PCIe bracket, that will be $75 please or we unsolder your VRAM and burn down your house, thankyoucomeagain\"",
      "For those curious, the Asus Dual range primarily exists to fit in the mini PC's offered by various OEMs. The most prominent that comes to mind is the Intel NUC gaming systems."
    ]
  },
  {
    "brand": "amd",
    "generation": "6000",
    "tier": "low",
    "matched_keywords": [
      "6400"
    ],
    "title": "MSI overclocker teases AMD Ryzen 7000 CPU running DDR5-6400 CL32 memory - VideoCardz.com",
    "selftext": "",
    "comments": [
      "I want to know if they did it with 2 dimms or 4. You cant do this with 4 dimms on z690 but with two dimms its nothing sprcial.",
      "Of course they cut off the \"NB\" frequency... would love to know what the fabric clock was at DDR4-6400.  Hopefully 3.2GHz.",
      "Ya get penalized if you show the fclk. That's a controlled leak",
      "amd said ddr5 would be OC a lot so, its happening",
      "> Where in the screenshot does it indicate 4 dimms?\n\nNobody said anything about 4 DIMMs.\n\n>Just because it‚Äôs 64gb‚Ä¶? Yeah, no.\n\nYes.\n\n>All are either 2x16gb or 2x32gb\n\nThe 32GB sticks require 2 ranks per stick and per channel to reach that capacity as they use 16gbit IC's.\n\nThey clock far lower than single-ranked setups.",
      "Its not really anything new though. XMP 6600 CL32 already exists on Z690, and overclockers have pushed into DDR5-10552 (with obviously looser timings). \n\nAnd with a sample size of 1, its hard to know how well AM5/Zen 4 will handle DDR5, because just like on Z690, most people definitely arent going to get insane speeds, these top end results are from $1500 motherboards, with binned CPUs and RAM.",
      "Disclaimer: I'm not very knowledgeable about DDR5.  \nDDR5 has a different design vs DDR4, with two smaller data channels, sort of like a dual-channel design but with half the bandwidth per channel (2x32 bits instead of 1x64 with DDR4). This helps reduce real-world latency where there are many data accesses at the same time, as you get twice the amount of simultaneous accesses.  \nWith that in mind, DDR5-6400 CL32 should have lower latency than DDR4-3200 CL16 in real-world situations. Though I have no idea by how much, if this even holds up.",
      "PC manufacturers will still find a way to disable the second channel on budget PCs and laptops, just out of spite.",
      "I am surprised there are no leaks on this at all.",
      "That's with half as many memory ranks per channel",
      "so IF = 1600 mhz ? OC 7600mhz would be possibly 1900mhz.",
      "There are 2 ranks per channel",
      "So the rough equivalent in latency with DDR4 is 3200 MHz CL16, just the DDR5 has double the bandwidth?",
      "DDR5 has 2 RPC by default afaik (because it's 2x32 bit). So 4 dimms would be quad rank (harder to drive, minimal benefit).",
      "It has 2 channels per DIMM, but each still has 1 rank",
      "Matisse and Vermeer run JEDEC 2133 to 3200 at stock with synced IF which is 1067-1600mhz",
      "The memory controller is a client of the fabric, it is not part of the fabric.  You can swap or remove the IMC and the fabric remains as it is.\n\nAMD links the fabric and IMC clocks together to reduce latency, but they could technically implement a full decoupling and allow them to run at fully independent clocks.  The 1/2 ratio is a demonstration of this simple fact.",
      "in Ryzen 3000/5000 the problem was the I/O at 12nm, Ryzen 7000 will use I/O at 6nm, IF should be able to exceed 2500Mhz",
      "I mean is this supposed to be impressive? G.skill has kits that run 6400 MHz CL-32 out-of-the-box with XMP on z690 \n\nG.SKILL Trident Z5 Series 32GB (2 x 16GB) DDR5 6400 Intel XMP 3.0 Desktop Memory Model F5-6400J3239G16GX2-TZ5S https://www.newegg.com/g-skill-32gb-288-pin-ddr5-sdram/p/N82E16820374360?Item=N82E16820374360&Source=socialshare&cm_mmc=snc-social-_-sr-_-20-374-360-_-08022022",
      "Fabric running at x2 bandiwth but new \"gear1\" mode is 1:2 ratio. Highest leaked me oc is 6600 so far, but no info on dual rank perf"
    ]
  },
  {
    "brand": "amd",
    "generation": "6000",
    "tier": "low",
    "matched_keywords": [
      "6600"
    ],
    "title": "AMD Software: Adrenalin Edition 24.9.1 Release Notes",
    "selftext": "# Highlights\n\n* New Game Support\n   * ¬†Frostpunk 2\n   * God of War Ragnar√∂k\n   * Warhammer 40,000: Space Marine 2\n   * The Sims‚Ñ¢ 4 DirectX¬Æ 11 Update ¬†\n* AMD Fluid Motion Frames (AFMF) 2\n   * A major advancement in frame generation technology for AMD HYPR-RX.\n      * **Lower Latency and Higher Performance**\n      * **Fast Motion Optimization**\n      * **Improved Borderless-Fullscreen Support**\n      * **Expanded API Support**\n      * **Radeon‚Ñ¢ Chill Interoperability**\n      * **Optimized AMD Ryzen AI‚Ñ¢ 300 Series Support**\n   * Check out our new blog¬†[HERE](https://community.amd.com/t5/gaming/boost-gaming-performance-by-2-5x-with-amd-software-adrenalin/ba-p/711458)¬†to learn more about AFMF 2 and this driver release.\n*  \n* AMD Radeon‚Ñ¢ Anti-Lag 2 Vulkan¬Æ Support for Counter-Strike 2\n   * AMD Radeon‚Ñ¢ Anti-Lag 2 now supports the Vulkan¬Æ API, offering additional responsive gaming options. AMD Radeon‚Ñ¢ Anti-Lag 2 introduces an in-game option to optimally pace frames, further reducing input lag on AMD RDNA‚Ñ¢ architecture-based graphics products.\n      * Users looking for a way to measure response time can use our¬†[Frame Latency Meter (FLM)](https://gpuopen.com/learn/frame-latency-meter-flm-1-0/)¬†or the built-in latency monitor in AMD Radeon‚Ñ¢ Anti-Lag 2.\n      * Check out our new blog¬†[HERE](https://gpuopen.com/learn/integrating-amd-radeon-anti-lag-2-sdk-in-your-game/)¬†to learn more about the AMD Radeon‚Ñ¢ Anti-Lag 2 SDK.\n\n* Geometric Downscaling for Video\n   * Improved image quality by reducing artifacts during downscaled video playback.\n      * Geometric Downscaling is supported on AMD Radeon‚Ñ¢ 800M integrated graphics, as well as AMD Radeon‚Ñ¢ RX 7000 series desktop and mobile discrete graphics cards.\n\n* Expanded AMD Radeon‚Ñ¢ Boost Support\n   * FINAL FANTASY XVI¬† ¬†\n* Expanded HYPR-Tune Support\n   * HYPR-Tune support allows HYPR-RX to enable in-game technologies like AMD FidelityFX‚Ñ¢ Super Resolution and AMD Radeon‚Ñ¢ Anti-Lag 2.\n   * Support has been added to automatically configure AMD FidelityFX‚Ñ¢ Super Resolution 3 with frame generation in:\n      * Black Myth: Wukong\n      * Creatures of Ava\n      * Frostpunk 2\n      * God of War Ragnar√∂k\n   * Support has been added to automatically configure AMD Radeon‚Ñ¢ Anti-Lag 2 in:\n      * Ghost of Tsushima DIRECTOR'S CUT ¬†\n* Expanded Vulkan Extensions Support\n   * [VK\\_AMD\\_anti\\_lag](https://registry.khronos.org/vulkan/specs/1.3-extensions/man/html/VK_AMD_anti_lag.html)\n   * [VK\\_KHR\\_maintenance7](https://registry.khronos.org/vulkan/specs/1.3-extensions/man/html/VK_KHR_maintenance7.html)\n   * [VK\\_KHR\\_pipeline\\_binary](https://registry.khronos.org/vulkan/specs/1.3-extensions/man/html/VK_KHR_pipeline_binary.html)\n   * [VK\\_EXT\\_shader\\_object](https://registry.khronos.org/vulkan/specs/1.3-extensions/man/html/VK_EXT_shader_object.html)\n   * Click¬†[HERE](https://www.amd.com/en/resources/support-articles/release-notes/RN-RAD-WIN-VULKAN.html)‚ÄØfor more information about other Vulkan¬Æ extension support. \n*  \n* Mesh Nodes in Work Graphs via Microsoft Agility SDK 1.715.0 Preview\n   * Microsoft DirectX¬Æ 12¬†[Work Graphs with Mesh Nodes](https://devblogs.microsoft.com/directx/d3d12-mesh-nodes-in-work-graphs/)¬†support for AMD Radeon‚Ñ¢ RX 7000 Series graphics cards.\n      * View our accompanying blog post on¬†[GPUOpen](https://gpuopen.com/learn/work_graphs_mesh_nodes/work_graphs_mesh_nodes-intro/)¬†to learn more about Mesh Nodes in Work Graphs and how to enable it.\n      * Find our Work Graphs Mesh Nodes samples on¬†[GitHub](https://github.com/search?q=topic%3Ameshnodes+org%3AGPUOpen-LibrariesAndSDKs&type=repositories).\n*  \n* Fixed Issues and Improvements\n   * Intermittent driver timeout or application crash while playing¬†*Warhammer 40,000: Space Marine 2*.\n   * Intermittent driver timeout or application crash during certain cutscenes while playing¬†*FINAL FANTASY XVI*¬†on some AMD Graphics Products, such as the Radeon‚Ñ¢ RX 6600 XT.\n   * Overly dark shadows or desaturated colors may be observed while playing¬†*Black Myth: Wukong*¬†when Global Illumination is to Medium or higher.\n   * Intermittent in-game corruption may be observed while playing¬†*Ghost of Tsushima DIRECTOR'S CUT*¬†with AMD Software: Adrenalin Edition‚Ñ¢ Record & Streaming and HDR enabled.\n   * AFMF may become inactive after enabling certain on-screen overlays.\n   * AMD Software: Adrenalin Edition may unexpectedly initiate upon system wake from sleep mode.\n   * Audio and video may intermittently become out of sync while recording using the AV1 codec in AMD Software: Adrenalin Edition.\n\n# What to Know?\n\n**AMD Fluid Motion Frames (AFMF) 2**\n\nAFMF is a state-of-the-art frame generation technology exclusive to AMD. It enhances frame rates and gameplay smoothness and is integrated into AMD Software: Adrenalin Edition‚Ñ¢. As part of¬†[AMD HYPR-RX](https://www.amd.com/en/products/software/adrenalin/hypr-rx.html), our one-click performance solution, it delivers exceptional gaming experiences on AMD Radeon graphics cards.\n\n* **How to Enable AFMF 2**\n   * AFMF 2 can be enabled for any OpenGL^(NEW), Vulkan^(NEW), DirectX¬Æ 11, and 12 title using HYPR-RX or the AMD Fluid Motion 2 Toggle.\n      * AFMF 2 is supported on AMD Radeon‚Ñ¢ 700M and 800M integrated graphics, as well as AMD Radeon‚Ñ¢ RX 6000 and RX 7000 series desktop and mobile discrete graphics cards.\n      * AFMF 2 currently requires the game to be played in exclusive or borderless fullscreen mode with VSync disabled.\n      * Use the in-game overlay (ALT+R) in AMD Software: Adrenalin Edition‚Ñ¢ to check AFMF‚Äôs frame generation status.\n   * AFMF 2 adds frame generation technology to boost FPS outside the game‚Äôs engine. Users can enable the AMD Software Performance Metrics Overlay to see the resulting FPS. \n      * Users looking for a way to measure the response time of games can make use of our¬†[Frame Latency Meter (FLM).](https://gpuopen.com/learn/frame-latency-meter-flm-1-0/)  \n* **How to Optimize AFMF 2** \n   * AFMF 2 introduces new modes that are automatically tuned for the best experience based on your configuration. These can be manually adjusted to your preferences if needed \n      * AFMF 2 adds a new ‚ÄúHigh‚Äù Search Mode setting for improved frame consistency during fast motion, enabled by default for resolutions of 2560x1440 and above. \n   * AFMF 2 adds a new Performance Mode setting to reduce frame-generation overhead, enabled as ‚ÄúPerformance‚Äù by default for integrated graphics products.\n      * Integrated graphics users may switch back to the ‚ÄúQuality‚Äù performance preset for better frame-generation quality during fast motion. The ‚ÄúQuality‚Äù preset is the default when using discrete graphics cards.\n      * Users can manually enable this ‚ÄúPerformance‚Äù mode on discrete graphics cards to hit even higher frame rates when GPU bound to maximize the FPS uplift.\n   * Users can find these tuning options within the ‚ÄúAdvanced View‚Äù of HYPR-RX. ¬†\n* **AFMF 2 Support for Multi-GPU Configurations**\n   * For any hybrid-graphics configuration, AFMF 2 will use the displaying GPU for frame generation, allowing the render GPU to focus on the game. \n\n# Known Issues\n\n* Intermittent performance when entering certain areas while playing¬†*DayZ*. \\[Resolution targeted for 24.10.1\\]\n* Intermittent driver timeout or crash may be observed while playing¬†*Warhammer 40,000: Space Marine 2*¬†on some AMD Graphics Products, such as the AMD Ryzen‚Ñ¢ AI 9 HX 370. Users experiencing this issue can enable Variable Graphics Memory in AMD Software: Adrenalin Edition as a temporary measure (AMD Software: Adrenalin Edition -> Performance -> Tuning -> Variable Graphics Memory).\n\n# Important Notes\n\n* AMD is collaborating with the developers of¬†*Frostpunk 2*¬†to resolve an intermittent issue causing in game flicker while using AMD Software: Adrenalin Edition Record and Stream.\n* AMD is collaborating with the developers of¬†*Warhammer 40,000: Space Marine 2*¬†to resolve an intermittent issue causing black flickering around certain water areas",
    "comments": [
      "I Hope the bug when the app is opening after the sleep fixed",
      "It's fixed üëç",
      "Polaris and VEGA:\n\n**Fixed Issues and Improvements**\n\n* Increased memory usage may be observed while playing certain versions of Minecraft Java Edition.\n* Some DirectX¬Æ 12 applications may experience an app crash with Windows usernames containing certain non-English characters.\n* Intermittent flicker around the borders of windows placed over Microsoft Teams.Highlights Fixed Issues and Improvements   Increased memory usage may be observed while playing certain versions of Minecraft Java Edition. Some DirectX¬Æ 12 applications may experience an app crash with Windows usernames containing certain non-English characters. Intermittent flicker around the borders of windows placed over Microsoft Teams.",
      "\"AMD Software: Adrenalin Edition may unexpectedly initiate upon system wake from sleep mode.\" \n\n\nGood. This was annoying me more than it should.",
      "Holy shit they fixed the AV1 issue",
      "Does anyone know more information about the Geometric Downscaling stuff for video? I'm curious on what its like versus regular scaling algorithms.",
      "Yea we finally get a September update in - *checks calendar* - October.",
      "Finally üëçüëçüëç",
      "Not mentioned in the notes but they added a new ‚ÄúFreeSync Color Accuracy‚Äù toggle under Display Options for my FreeSync Premium Pro monitor that fixed my HDR‚Äôs washed out colors.\n\nEdit: It doesn‚Äôt seem to have fully solved the issue. Still getting washed out colors in some apps.",
      "9.1 but on 10/1 ü§î",
      "I thought I was just going crazy. I tend to have the app open on a monitor for metrics but I could have swore I closed it, and it somehow kept being there.",
      "Finally.",
      "Good to see that they are working with the devs to fix issues!",
      "lets hope its actually fixed, been waiting a year+ for it",
      "Bit off topic, but I also have the 6900 xtxh. I'm curious as to what your temps are under load. As in when the card is really being pushed.",
      "wow lots of stuff fixed",
      "It was just excited to see us when we came back :)",
      "The blog post has a little more info on it\n\nhttps://community.amd.com/t5/gaming/boost-gaming-performance-by-2-5x-with-amd-software-adrenalin/ba-p/711458",
      "Shouldn't it be 24.10.1? XD",
      "it was packaged before today"
    ]
  },
  {
    "brand": "amd",
    "generation": "6000",
    "tier": "low",
    "matched_keywords": [
      "6600"
    ],
    "title": "Neowin: Radeon RX 6600 XT MSRP is 349 USD, RX 6600 to cost 299 USD - VideoCardz.com",
    "selftext": "",
    "comments": [
      "Ohh look we'll finally get GTX 1080 class performance for sub 300 USD. 2 years after it actually supposed to happen.",
      "You already got GTX 1080 performance at 280 dollars last year with the RX 5600 XT.",
      "Radeon RX 5600 XT already delivered that for $279",
      "The GTX 1080 performs about the same as the RX 5600 XT and the RTX 2060 in general, or slightly worse in newer games where Pascal falls behind. In general, the 5700 ranges between 5% to 10% faster than these other 3.\n\n[Source: the last TechPowerUp review that still included the GTX 1080 numbers, dated from March 5th.](https://www.techpowerup.com/review/zotac-geforce-rtx-3080-amp-holo/28.html)",
      "AMD is done being the budget vendor. They buy high end silicon from TSMC and turn it into high end products. They don't have the supply to serve the volume market, anyway.",
      "If you have to hope that Intel comes to your rescue, you have to be pretty desperate.",
      "6600xt has a slightly smaller die size than the $279 5600xt yet is $70 more expensive lol. \n\nThank you AMD and Nvidia. Thank you for abusing your duopoly",
      "I don't get how it's meaningless, this is AMD charging  $349-$399 for a supposedly low-mid range card. Not any greedy retailers or scalpers, that's AMD themselves. And this price may very well be the standard price for low-mid range cards from now on. $350 for 6600 XT though? That's $50 more than it should be. At least.",
      "So it‚Äôs safe to say that we will no longer see a sub $200 price tag for entry level GPUs?",
      "It's also important to note that not all RX 5600 XT cards have the 14 Gbps memory out of the box. Only the most high end models does so and the lower end cards have to get their BIOS [manually](https://www.tomshardware.com/news/amd-encourages-radeon-rx-5600-xt-owners-to-upgrade-memory-to-14-gbps) by end users. I get your point with the 5600 XT can achieve GTX 1080 level of performance but the ones with the 14 Gbps memory generally costs more than \\~320 USD two years ago.",
      "There's a team of financial analysts who says it is.\n\nOr more accurately, they know it's not and it'll sell out anyway.",
      "TSMC hasn't been making high end silicon for all these years. Most of the time in their company history, they've been behind. They are the first team to really figure out EUV, and now they are the high end player.\n\nRight now, team red is using better silicon than team blue and team green, at least in the consumer market. That better silicon comes at a premium price, and it's why red products are so attractive. As long as this is the case, AMD products will not be cheap.",
      "Nope\n\nRadeon RX 5600 XT is slightly faster than GeForce GTX 1080\n\nhttps://www.techpowerup.com/review/powercolor-radeon-rx-5600-xt-red-devil/27.html",
      "Good point, I completely forgot about that whole memory debacle back on launch.",
      "Man I'm really not looking to pay for 300+ for a 8gb VRAM card. I really really don't want to buy NVIDIA because I have a NVIDIA card and it runs like shit on LINUX, but the competition from AMD is so bad.",
      "Agreed, its about the same size as an RX 580 die, but that's a different process node, so comparing to the 5600xt is an even better comparison, especialyl requiring similar power targets.\n\nGamers are getting F'd in the A.",
      "Dang, not really worth :+",
      "I think both of them are testing the waters with the more \"aggressive\" pricing. \n\nIt definitely looks like Nvidia regretted not pricing the 3080 and 3070 higher so they released the TI versions lol.",
      "I think it's the line you draw from when it's entry level. Some might say anything below 1440p ultra settings is entry level while others would see an integrated mobile gpu as entry level. GTX 1080 level is pretty decent, it's twice as fast as my RX480 (for roughly 260$ back in 2016), but on the other hand we had RX 5700 (XT) in the range from 300-400‚Ç¨ some time ago on the market which was also pretty neat. I wish I didn't miss the Superbowl event in Germany, 5700xt sapphire top notch model for like 370‚Ç¨ incl taxes with the best cooling solution from all the 5700 models. Right now is such a sad time being a pc gamer that I rather went for the XSX.",
      ">Right now is such a sad time being a pc gamer that I rather went for the XSX.\n\nI think it's only a sad time to be a DIY PC gamer. Gaming laptops are the best they've ever been. Prebuilts are trending somewhat more expensive than you'd like, but SIs aren't anywhere near DIY prices. Typically, they can get you a PC with a 3080 in it for close to 3080 street price. In shortage conditions, retail eats last.\n\nThat being said, XSX is the best Xbox ever. They are finally building systems that offer a gaming experience I'd actually want. What's more, Xbox Game Pass is a phenomenal value that really addresses the game cost problem Xbox had compared to PC gaming."
    ]
  },
  {
    "brand": "amd",
    "generation": "6000",
    "tier": "low",
    "matched_keywords": [
      "6600"
    ],
    "title": "AMD Radeon RX 6600 Final Specifications and Official Performance leaked - VideoCardz.com",
    "selftext": "",
    "comments": [
      "Hard to be excited about GPU these days. Would have been interesting, at $250.",
      "I received an email promo from Newegg the other day for a **$250 Geforce 1050 ti**. I was shocked... That card should be $50. Hell, if things were normal you couldn't even buy one of those new anymore.",
      "IF we were in normal times the 6600 would likely be 200 and the 6600xt only 250, :(",
      "Not that MSRP makes any difference these days.\n\nBut this really needs to be priced below the 3060. It offers similair performance, less in RT and has less features. Aswell as less VRAM.\n\nIn a normal market this card would have been 250-270$-ish. But since the market is fucked AMD will just prices it the same as the 3060 and the scalped prices will be over 400$ anyways.",
      ">This card should represent close to 2X performance of a RX580, which is a huge uplift for those holding to their RX580 or 1060.\n\n2x the performance for 2x the msrp is not exactly an improvement, also considering that the actual price will be even higher.",
      "I actually think this is a GPU worth being very excited about. Depending upon availability, this could be the most important GPU release this year. It is worth remembering that the 6600XT had pretty good availability, particularly in Europe, Australia and the UK. \n\nThis card should represent close to 2X performance of a RX580, which is a huge uplift for those holding to their RX580 or 1060.\n\nAs for the price, my advice is to buy it early. Buy in the first 5 minutes.  That is how I got a 6600XT for 400‚Ç¨.",
      "Only AIB models, no reference card, so will not be on AMD's shop.",
      "Its the only one in stock? Besides, amd can simply drop $80 off its price once stock fixes itself. No big deal.",
      "RT performance is not that  bad because all of the games in the list have very light RT effects compared to other games with RT.\n\nWhen games with heavy RT effects like Watch Dogs : Legion or Cyberpunk 2077 is used , performance will drop badly if I have to guess .",
      "It's essentially the same die size as the RX580, but instead of GloFo 14nm, they're now using TSMC 7nm.   I wouldn't be shocked if the die cost is literally double what it was for the 580.  Of course this is a cut down version, so it wouldn't be the full cost difference, but probably still a good chunk more.  And then it has GDDR6 over GDDR5.  Perhaps if memory prices had actually come down a lot since 2016, it wouldn't be such a big deal, but they sadly haven't.  \n\nI'd be very surprised if this was actually cheaper to make than a 580.",
      "Why do you think it will be more expensive? Because of the MSRP? How many 3060's have you found at MSRP.",
      "This will be cheaper to build than RX580.",
      "379 vs 329. it's priced 20$ below the 3060 tie, but the 3060 tie is definitely worth the 20 bux",
      "The RX580 had a MSRP of $229. The MSRP of the 6600 won't be $458. It will most likely be $329 or lower. As for how to get it at a decent price, I have already outlined: buy it early.\n\nBesides, owners of RX580s are sitting on top of $400-450 (value of a RX580 to miners), and could get an upgrade to the 6600 pretty much for free, provided that they are fast enough.",
      "Yea, it will cost less, mine the same and use like 5w less power than the xt so yea pretty attractive.",
      "I bought a 3060 for 320 from EVGA. The cheapest 6600xt I have ever seen was at Microcenter for 560 dollars.",
      "RT perf is not bad at all. 132W is really good................for mining",
      "The 6600 XT is already priced lower than the 3060, you mean it needs to be priced below the 6600 XT?",
      "First of all you yourself know this wont be 250.\n\nSecond i would actually pay 350 for this if its at MSRP launch day.Because im starting to believe there wont be a 6500xt or 3050ti except when the next gen cards launch.But i also doubt this will be 350 launch day, so i doubt ill even get that.Maybe rising prices in energy,in the EU will mean that this wont be bought up by miners literally in the first 2 seconds and so i might get 1, but i doubt it.\n\nI just want to play Warzone and my rx 570 4gb cant really do that, it looks very bad.So its fine.Ill prob keep this for a few years and then sell it for 100 euro and add 150-200 more and get a normal card when prices come down and im willing to take this kind of hit.",
      "6600 more expensive than the 3060? In what world is that? Not even the 6600XT is more expensive than the 3060."
    ]
  },
  {
    "brand": "amd",
    "generation": "6000",
    "tier": "low",
    "matched_keywords": [
      "6600"
    ],
    "title": "AMD Radeon RX 6600 Review: The Best/Worst GPU You Can Buy",
    "selftext": "",
    "comments": [
      "Hot garbage...  I thought maybe if they drop it close to MSRP where I live, but after seeing this... in some games slower than RTX 2060 / 5600XT at +$30 MSRP compared to 2+ year old cards... Oh man, situation sucks ass and retailers will likely launch this crap at 500‚Ç¨ here making it even worse than it is on paper.\n\nEdit: even worse: https://www.komputronik.pl/product/737159/msi-radeon-rx-6600-mech-2x-8gb.html which is 570‚Ç¨, fucking lul",
      "This is such a never-ending nightmare",
      "This is just depressing. 5700 could be found regularly in the US for less then this MSRP. I bought a 5700xt for 350 with a rebate and it came with 2 games literally a year and a half ago. \n\nAt least the 3060 ti and above were leagues better for their predecessor. A 3060 ti for 400 outperforms a 2080 super by 10 percent. So at least paying twice MSRP isn't horrible compared to getting a 2080 at launch for the same price. \n\nBut this is literally a regression in performance for more money...",
      "Welcome to 2021.",
      "There's a simple solution: don't buy a card unless you have to. Get the most that you can out of the card you already have.",
      "Don't be fooled, there is always an initial stock of GPU's that's subsidized by the AIB's so they can advertise the MSRP. This was uncovered by Tweakers.net during the launch of the 6600XT. After the initial batch is sold out (the batch is very small), the prices will go up significantly. For example the 6600XT launched very close to MSRP in Western Europe with seemingly decent stock, but less than a week later all of those subsidized cards were gone and the only ones in stock now are well above MSRP (the 6600XT is over 750 USD in the Benelux and Germany right now). NVIDIA isn't doing any better, the 3060 is around that price as well.",
      "10% faster than the 5600XT, 14% slower than the 6600XT. More-or-less on par with 3060, 5700 and 2070 performance-wise. It is worth remembering that HUB doesn't use SAM, so results with SAM might be more favorable.\n\n330 USD *\"MSR-LOL-P\"*\n\nThis card, its performance and its price, surely is not for everyone, but for RX 580 and 1060 owners, this represents a massive upgrade, about 2X raw performance and DirectX12 Ultimate support.\n\nNow I know the argument: *\"I paid $230 for my 580 4 years ago, I am not paying 400+ bucks for an upgrade for 1080p gaming!\"*. The solution to that is: *\"why not sell your 580 for 400+ bucks, in the second hand market?\"* At least back in August, you would find a buyer in a heartbeat. Not sure how the second hand market is now, but I assume it hasn't changed much. As bad as new GPU prices are nowadays, so are the prices of used GPUs, and anyone looking for an upgrade should use that to their advantage. If done timely, an upgrade like this could cost very little, if anything.\n\nAh, and for the \"no chance in hell the 6600 will land in the stores for less than 2X MSRP\", it actually did. 349 euros in a local store, in stock. I checked again 15 minutes later, it was still there, 20 minutes later, gone. Still, I took a [screenshot as proof](https://ibb.co/1bxTb4q). If you are actually dead interested in buying a GPU, you can't wait a month, you have to pull the trigger the moment it drops. This is true for the most recent releases as well as for GPUs releasing in the foreseeable future.",
      "Not sure why you are getting downvoted... the current market dictates the price, AMD could have priced it at $199 and the market would re-adjust it to $500 in 2 weeks.\n\n\nIt's a 1080p card with DX12 ultimate support and 8GB of vram, while using only 120watts. Add to that HDMI 2.1, AV1 decode and most models are really compact.\n\n\nThis is the reality, but people have hard time listening to reason when they are angry...",
      "‚Ç¨349 here in Finland. In stock. Not for long, I am sure.",
      "I'm kinda past that point with RX 470 I never ever thought I'll have it for 5 years... best 220‚Ç¨ ever spent and it was premium model (Gaming X) and still was dirt cheap..",
      "Assuming it works, a GPU is never simply \"bad\" by itself, it depends on its pricing. If the performance was close to 5600XT but at a significantly lower price than the 5600XT, then it would be a very interesting product. However, if you're releasing a similar product at a similar price, that shows no progress whatsoever. So people aren't simply trashing its performance... they are thrashing its performance considering how much you have to pay for it.",
      "There are lots of benefits for having 2.1 - you should read up..",
      "[Article on techspot.com](https://www.techspot.com/review/2343-amd-radeon-rx-6600/).\n\n#Timestamps:\n* 00:00 - Welcome back to Hardware Unboxed\n* 04:52 - Test System\n* 05:33 - F1 2020\n* 06:28 - Cyberpunk 2077\n* 07:10 - Death Stranding\n* 07:53 - Horizon Zero Dawn\n* 08:25 - Rainbow Six Siege\n* 08:51 - Watch Dogs Legion\n* 09:20 - Power Consumption\n* 09:38 - Average 1080p\n* 10:13 - Average 1440p\n* 10:27 - Final Thoughts",
      "I trued to get 6800xt at launch. I had multiple bots alerting me of stock but it was always out of stock as soon as I would try to buy. Randomly at 2am on a Tuesday, i found a xfx 6800 non XT. It was 150 over MSRP because it was their Merc series with a big cooler. After taxes and shipping I paid $800 for a 6800. I felt a bit ripped off but  whatever. This was in Dec 2020. I can now sell that card for 1200 easy. I feel that cards are harder to find and for as \"low\" as 150 over MSRP is literally not possible. Everything is like 250-1000.",
      "I think people, most reviewers included, think that we live in 2019, and that MSRP is set in stone, and perhaps even that AMD is a non-profit organization.",
      "Indeed, I know about these early subsidized batches. That is how I got a 6600XT for 409 euros. One should take advatange of them while they last.",
      "Immoral? The fuck lol. What on earth is immoral about basic economics.\n\nI guess it‚Äôs also immoral to sell your nvidia stocks for 4x 2019‚Äôs stock price.",
      "Whoever is buying a 580 for 400 bucks in 2021 is a miner. You would be ripping off a miner. What is morally wrong with that?",
      "There is more to it then just 1080p gaming, I would recommend you read an article on why 2.1 is great to have in a gpu.",
      ">\"why not sell your 580 for 400+ bucks, in the second hand market?\" \n\nThis is how I was able to get a 6900xt. Sold my Vega 64 for $700 which almost paid for the 6900xt which is still crazy to me."
    ]
  },
  {
    "brand": "amd",
    "generation": "6000",
    "tier": "mid",
    "matched_keywords": [
      "6700xt"
    ],
    "title": "RTX 3060 will be mining limited to 50%. Will AMD do the same with 6700XT?",
    "selftext": "Nvidia annunced CMP (Cryptocurrency Mining Processor) and stated that RTX3060 will be limited in mining algorithms by -50% to make the card substantially useless to miners, so there is hope that all the cards will be purchased only by gamers.\n\nI think that AMD should do the same with 6700XT / NAVI22 as today is too late to block NAVI21 by drivers\n\nI know that AMD want to sell all its cards nevermind where they go, but if they *really* care to gamers, that's what they should do imho. What do you think?",
    "comments": [
      "AMD's drivers are open source on Linux, so no driver level limitation will be effective, unfortunately.",
      "Pros of open-source software:\n\n* The company can't control the software\n\nCons of open-source software:\n\n* The company can't control the software",
      "Assumption: If Miners buy Mining cards and Gamers buy Gaming cards, everyone wins.\n\nReality: Scalpers buy all of the cards.",
      "Let's face it. It's a matter of time for when miners write a BIOS that unlocks the 3060's full crypto mining power.",
      "This is such a marketing exercise and will probably be either mitigated within days or just completely avoided by shifting the miners to buy higher priced products",
      "In all seriousness, I'd give it a month *tops* until that happens. It's similar to how NVENC is limited to two HW-accelerated encodes on consumer hardware (unlimited on Quadros), but a quick driver patch eliminates that. It's just a matter of time, and an absolute waste of resources on Nvidia's part. It's like DRM all over again (and we all know how well DRM works - it doesn't).",
      "Win",
      "Not with RDNA, but it used to be god tier, Rx4\\*\\*/5\\*\\* 8GB and Radeon VII were so good they are worth more today than 2 years ago.",
      "AMD's mining performance are not even that good compared nvidia",
      "Scalpers can only buy when there is ample supply, usually before the supply problems are evident. So essentially they're taking a gamble before there is a problem with supply.\n\nHowever, especially with Nvidia, there is just such a massive problem with manufacturing and supply that NO ONE is getting cards, and the few that are out there do not match the demand. You can't scalp if there are no cards to scalp, lmfao.",
      "Nvidia want to cater miner but at the same time dont want to hurt gamer. So they release gpu for miner and please gamer by announced driver limitations. Imagine if they announced only gpu mining today? Many will upset and mock them. This is just pure marketing.",
      "5700/5700xt are excellent for mining. RDNA2 is just not that good because of the bandwidth but still good enough to mine with at current crytpo prices.",
      "Yeah, it is all marketing.  And the real reason for them doing it is because it is more profitable for them to segregate the market.  They really don't care about gamers, but they can spin it to get in good graces.  They did something similar back during the first mining craze.  They released a statement saying mining bad, we love gamers, but were selling their supply directly to farms.",
      "You're talking about an ASIC, most crypto algorithms are now developed with one of the goals being to fuck with ASICs e.g. being caching resistant and memory intensive or being able to modify it's algorithms while retaining the rest of the infrastructure so developing an ASIC is not feasible. It really underlines how fucked up the entire concept is - we are *deliberately* making the processing as fucked up and power intensive as possible because if specialized hardware could do it for a fraction of the power and time *it wouldn't be worth doing*.",
      "They can't really do that, firmware does not get that degree of control.",
      "Yes, I'm all for open source and I find this a weird movie by Nvidia. I haven't found yet what they're going to do to hurt miners...\n\nI mean mining software just uses CUDA but CUDA is used for A LOT of stuff. I think machine learning is likely a much bigger market than mining. Even if you add 3D rendering or CFD programs. GPU's these days have enough ram so you don't have to buy the more expensive business ones. (yeah ECC ram is still a thing but a lot of workloads can work just fine with the occasional wrong output)",
      "What is stopping Nvidia or AMD from stopping at mining? \n\nThis game wasn‚Äôt sponsored by Nvidia/AMD. It‚Äôll only perform 80%.\n\nThis game might be cracked, so you‚Äôre locked to 15 fps. \n\n\nThis is a dangerous path to go down and it is concerning the amount of people jumping on board. \n\n\nYes, fuck the big miners buying up all of the supply, but this is not the way to solve this problem.\n\n\nEDIT: checked the specs for the new mining cards from Nvidia. The 30HX is less efficient than a 2017 RX580 omegalul",
      "Watch the custom driver someone puts out funnel 1% of the processing power to the themselves.",
      "Why is it unfortunate that things aren't artificially limited?\n\nThis is like bizzaro world.",
      "beside the 3060, if someone will produce mining hardware that cost LESS than a VGA the job is done"
    ]
  },
  {
    "brand": "amd",
    "generation": "6000",
    "tier": "mid",
    "matched_keywords": [
      "6700xt"
    ],
    "title": "Yeston 6700xt",
    "selftext": "",
    "comments": [
      "Weeb XT.\n\nOnii chan approved edition.",
      "I remember seeing this card being reviewed at Gamer's Nexus and they said it smelled of perfume. Is it true?",
      "If anime girl feet smells like strong perfume, than yes it does",
      "Yes",
      "These GPUs are so pretty, I just wish they didn't cost as much as a 6800XT.",
      "Yeah man, waifu tax is crazy. Their 6800XT is more than what my red devil 6900XT cost.\n\nThe design is very good though (IMO)",
      "Dawid Does Tech Stuff calls cards like this \"Waifu cards\" lol",
      "I can smell the perfume over the internet",
      "Honestly the card looks infinitely better than the usual, generic GPUs with edgy and gamer design. Wish they'd produce more cards like this one.",
      "I like how Yeston at least tries something different than the rest. Yeah it's not to everyone's taste, but it's different",
      "GN too lol",
      "With jizz-resistant cooling shroud for easy cleanup.",
      "More like there ain't a whole lot of these",
      "Cause they know neckbeards will pay anything.",
      "Meanwhile cards in the west be like \"ASUS TUF GIGABYTE EXTREME DRAGON GAMER\"\n\nCards in the west are cringey as fuck.\n\nGive me some variety. At least Yeston has personality to the cards.",
      "Fully commit.",
      "Cookies+Trackers",
      "Is it difficult to make a whole build around it? Cause the color scheme of the backplate and the fan side looks rather difficult to put together with a proper looking mobo and case, at least I couldn't think of something fitting",
      "The amount of hate because someone has variety is crazy üòÇ \n\nSub is ridiculously toxic \n\nEnjoy your card man. It's way better than the usual bland graphics cards.",
      "redditors say the word woman challenge (impossible)"
    ]
  },
  {
    "brand": "amd",
    "generation": "6000",
    "tier": "mid",
    "matched_keywords": [
      "6700xt"
    ],
    "title": "Goodbye to my dear RX 570 that kept me afloat during the GPU price pandemonium. Time for 144fps with the 6700XT!",
    "selftext": "",
    "comments": [
      "In 2017 I splurged $600 for a brand new EVGA 1080TI with Destiny 2 from Newegg because I needed a new card and wanted the game. At the time I thought to myself what a mistake spending so much on a video card, and hoped it would last long enough to justify it.\n\nHere I am 5 years later seeing top of the line cards going for $1000+ during the dark times, my card still kicking and looking to maybe get something new towards the end of the year, happy that AMD offerings are much more viable now as well!",
      "I went from an r9 390x to an 6700XT and the difference in performance is absolutely insane. Great GPU for sure.",
      "Gtx 1080ti is one of the few that justified it's price",
      "Congrats. The 6700XT is a great card. I had one for a while and loved it.",
      "I recently swapped out my 6700 XT for my old 570 4 GB just to see how well it holds up. I was surprised just how badly it struggles today. The 6700 XT basically gets exactly 3x the fps in most titles. \n\nI used the 570 for 1440p gaming for a while in 2019. And now you get like 20 fps at that resolution. Although Elden Ring managed to run at 30 fps at high settings.",
      "Ironically I actually bought an even more powerful power supply after watching a linus tech tip video. The idea is even if I only use 50% of its capacity it will run cooler and be more efficient than a lesser wattage power supply running at 90% all the time. Seemed logical to me so I'm giving it a shot.",
      "Meet the new sapphire, *very different from the old sapphire*",
      "Nice upgrade, I‚Äôm running a 5700xt and have been toying with the upgrade to the same card as yours for a while. Enjoy it",
      "I went a couple of steps lower, with a 6600, but Still a salute for the 570, a Magnificent card that carried us all through Mining-mania.\n\nHere's to the GPU that could!",
      "Is the 570 that much worse than the 580? I'm running all my games at 1440p fine on a 580, even AAA titles like far cry 6 and whatnot, though obv at max medium settings.",
      "[But what a lifespan it was.](https://imgflip.com/i/6ofycb)",
      "The 1080ti was an absolute beast of a card, especially for it's price. It still works just fine for 1080p gaming, although it's definitely nearing the end of it's lifespan.",
      "A third of the power? Nah.\n\nSure, 390X is 275W (or 350W when OC'd. Or 200W when undervolted), but 6700 XT are also 220W GPUs.\n\nIt would take a 6500 XT to use a third of the power of a 390X. Or a 6600 when undervolted.",
      "He upgraded. I had one too and it was great for me as well",
      "I had the opportunity to get a 6800XT Gaming X Trio and jumped. My first high end card and its amazing. Flipped my 6700XT Mech2X to offset cost. It's a pretty significant performance increase. I wanted the extra performance for the long term, as this card will go into my sons PC down the road. Nothing wrong with the 6700XT, it's an awesome performer and super efficient",
      "o7 \n\nI upgraded from a 580 to a 6800XT a few months back, and it was a heck of an upgrade. You're gonna love the new card!",
      "That card's got at least another year in it. Maybe two :)",
      "I have the 8gb 570 still in my desktop, and while its showing its age it still holds up pretty well even in recent AAA games. Medium settings for most at 1080p is fairly consistent 60fps.\n\nI use it mostly for streaming older games to my laptop that I havent bothered installing on it though. GF plays AC Valhalla with it too, 50-60fps with settings turned down a bit. It isnt terrible...",
      "Massive upgrade.",
      "Yea everyone loses their minds over nvidia cards (not knocking because I know the reputation precedes) but act like AMD is nothing. I was lucky to snag an MSRP 6800xt in spring 2020 from the direct sale site, upgrading from a Sapphire HD 5870. I‚Äôve loved every minute of it, and look forward to AMD staying in competitive in the GPU market."
    ]
  },
  {
    "brand": "amd",
    "generation": "6000",
    "tier": "mid",
    "matched_keywords": [
      "6750xt"
    ],
    "title": "I painted my new XFX RX 6750XT for a white/violet build.",
    "selftext": "I've a white and violet/pink build in a Lian Li 011D Snow Mini and recently received my new XFX 6750XT and decided to give it a new paint job to fit the theme. I am by no means an expert when it comes to spray painting and, honestly, after those first coats I realized I should've done way more prep.\n\nPaint job's not perfect, but I call it good enough for my first attempt at it. \n\nFor those wondering, I'm upgrading from an RTX 2060. I wanted to go for the RX 6800 or RX 7700XT but the prices on those were astronomical everywhere I looked. ",
    "comments": [
      "I've always wondered if painting backplates hurts the thermals.",
      "I read that painting backplates does lose you some heat dissipation unless it's a specific kind of paint that helps with thermal transfer. Basically the same stuff they have there originally. I'm not too worried because this GPU will have plenty of fresh air.",
      "Do you loose warranty? I would buy a separate shroud for that",
      "Yeston card would fit right in the theme. Glory to the waifu card.",
      "I do lose warranty because I scuffed the original surface before applying spray paint.",
      "most backplates do nothing for thermals anyway because almost no manufacturer puts thermal pads on the back.",
      "Ayy also upgraded from a 2060 to a 6700xt, I couldn't get anything betterüò≠\n\nPaint looks lovely!",
      "There's really not much to it, teardown the GPU and use a scotch brite to scuff all the parts, then use some compressed air or a microfiber towel to get the loose debris off and wipe each part down with isopropyl alcohol.\nBe sure to wear gloves so the salts, sweat and grime from your hands don't leave traces. \nAfter that use some wire or whatever you have lying around that can fit through the holes in the plastic pieces so you can hang them, I hung mine on a clothes drying rack inbetween coats.\nWhen painting the first two-ish coats are very light, you just want some paint on the pieces so your next layer has something to grab on to. After that you give it a tiny bit more paint each time but overall you're shooting for at least 5 coats. Wait until each coat dries, should be about 20 minutes.",
      "I'm sure it'll be negligible for us regular folks. Unless ur trying to hit some record OC on the card, I would not worry at all.",
      "I came to mention the waifu card as well.\n\nThen OP replies and skirts right over the topic...",
      "Not sure what OP used.. but use plasti dip and it peels right off. No mess and no damage.",
      "Oh the 6700xt is WAY better than the 2060, I was getting 50%+ more frames. Part of it is the 2060 only had 6gb of vram as opposed to 12 with the 6700xt. Also my CPU seems to be less bottlenecked, it used to be my GPU could be pinned at 100 and my CPU's only running at 40-50%, and now my CPU consistently can get to 85-100% depending on the game",
      "It was a full teardown. The front shroud comes in two pieces and the backplate has 3.",
      "Montana Colors - Hardcore series, graffiti paint.",
      "IKR. I don't even know what to reply...",
      "One caution, I used white plasti dip on my 2080ti, and within 3 months the white had yellowed to a really ugly off-white/beige color. \n\nSmoke-free environment too. Just something about the white plasti-dip that doesn't hold its color over time.\n\nFlex Seal didn't have this problem but it has a slightly different consistency and is a bit shinier. YMMV.",
      "For anyone interested in what the build looks like currently as it's still got a bit of progress to go [Lian Li 011 Dynamic Mini](https://imgur.com/rscrq2H)\n\nI went with an air cooler because there's no pump that can die and waste 80 euros. As of right now there are no top exhaust fans because I've given my spare Lian Li fan to an acquaintance to 3D print fan shrouds that will offset the chassis fans by 15mm because they are obnoxiously loud due to air resistance from the chassis mounts.",
      "a very well done paint job makes me leave a comment everytime. someone hire this person !",
      "It's a decent card but I'd only buy it if it was closer to 350 euros. Currently it's about 410, but you can get a 7800XT for 470 which is much better. Really, it all boils down to your needs and how much you wish to spend. \n\nI could've gone with a 7700XT or a 7800XT, but after looking over benchmarks and asking around, I realized I'd much rather get a 6750XT and save myself a 100 euros that I can invest somewhere else in the build. I don't play on 4K and I don't have a 1440p monitor either. I also don't plan on getting a new monitor in the upcoming years so I'm playing at 1080p and for my needs the 6750XT is plenty and then some.",
      "I did try to fly over the waifu cards. Here's my problem with them, it's not that they hare colorful or have anime girls on them - it's the fan shroud on the Yeston. It's so bad."
    ]
  },
  {
    "brand": "amd",
    "generation": "6000",
    "tier": "mid",
    "matched_keywords": [
      "6700xt"
    ],
    "title": "The RX 6700XT isn't just a $20 cheaper RTX 3070.",
    "selftext": "I keep seeing people say that the RX 6700XT is just a cheaper RTX 3070, but it's not as simple as that.\n\n1. The RX 6700XT does not have a viable DLSS 2.0 alternative. Some people may argue that DLSS is irrelevant, but I think not. DLSS has come to a point where it is a viable feature to use in order to achieve smoother frames and higher resolutions when your hardware can't do so. For example, I have a 3060 Ti and I use it in Cyberpunk. Without DLSS, I am unable to reach a steady 1080p 60FPS with everything (including RT) on Ultra/Psycho settings. With Fidelity FX still being quite lackluster, AMD needs to launch a DLSS alternative soon.\n2. The RX 6700XT also has a lower memory bandwidth. The RTX 3070 has a 256-bit BUS and the RX 6700XT has a 192-bit BUS. I know this is not important to most people, but it still can be useful to have a higher bandwidth. (Edit: I forgot about the 96MB of Infinity Cache, so don't take this point as seriously.)\n3. The RX 6700XT is expected to have noticeably lower Ray Tracing performance than the RTX 3070. Of course, this is due to AMD being on its first generation of RT cores, while Nvidia is on their second. While not everyone uses RT, it has become more and more popular in games.\n4. The RX 6700XT has an extra 4GB of memory. This will make the 6700XT better in some tasks that require more VRAM, such as higher resolution gaming and workstation tasks.\n\nAm I saying that the RX 6700XT sucks? No. I actually plan on switching back to AMD Radeon and buying a 6700XT or 6800 for SAM and Radeon Software (note: Radeon Software ‚â† Drivers), but I will say that the 6700XT is slightly overpriced. With that said, if you manage to find a 6700XT for a reasonable price, you should definitely buy it. I don‚Äôt need to explain why.\n\nEdit: As u/Excsekutioner and u/HaloLegend98 said, the absence of a good video encoder like Nvidia's NVEnc is also a point.\n\nEdit 2: I‚Äôm not trying to start a war between Nvidia and AMD users or start an argument about whether DLSS, NVEnc, and/or RT is important. Some people use and like DLSS and RT, and some people don‚Äôt like DLSS and RT. Some people like AMD cards and some people like Nvidia cards. We should respect each-other‚Äôs opinion and not force or criticize people into changing their opinions. I‚Äôm just laying out the facts on the 6700XT compared to the 3070 and why‚Äôs the 6700XT is not just a $20 cheaper 3070. And again, I‚Äôm not an AMD hater, I use or have used both Radeon and Ryzen and had decent experiences. I‚Äôm also not a Nvidia or Intel hater, and I have used Intel and Nvidia products before as well and had decent experiences.",
    "comments": [
      "Nothin real interesting about these announcements, the performance's kinda expected. It'd be something if they showed superresolution a lil but nope",
      "As a 5700XT owner, I'm skipping this generation. On both sides + the mining shit show.",
      "No super resolution info Is a disaster",
      "Thanks to Infinity Cache, the effective bandwidth of the RX 6700 XT is actually higher than it seems. I agree with your other points though.",
      "If I‚Äôm being honest, the 5700XT will still be solid for another 2-3 years for 1440p or 4-5 years for 1080p. Look at the Vega 56. That GPU is like 4 years old now but still solid at almost any title @ 1080p with high settings.",
      "You don't really need the \"tensor cores\" or \"ai hardware\" to do DLSS, the inferencing work doesn't need to be matrix based and if anything the reliance on convolutional/DL math is less in DLSS 2.0 than it is in original release DLSS (if any at all). It is clear there was a paradigm shift in how DLSS was being designed and implemented - from being actually Deep Learning network that compares scene elements to a model and determines \"what belongs here\" to a pattern based sharpening effect. \n\nSince DLSS is black box we will never know how much it actually relies on \"tensor cores\", but I would be very surprised if end users are really gaining much benefit, if any at all, from the tensor cores. I would instead postulate it is artificially locked behind tensor-core-having cards.\n\nI do think the original DLSS release did legitimately use matrix networks to do content matching.",
      "Without the AI hardware (Tensor cores doing the job) I don't expect their FidelityFX super resolution be on par with DLSS 2.0, anyway, tbh.",
      "Better and open source drivers on Linux.\n\nThat's the main reason why I bought a RDNA2 GPU over any of the NVIDIA cards.\n\nThe hardware isn't everything.",
      "**you forgot a very important point!** and it is that at least Nvidia offers you good Video encoding performance while AMD is straight up horrible; for example a 1650S is better at video rendering, encoding, streaming and timeline performance for both H.265 and H.264 than a 6900xt thanks to cuda support and Nvenc... That is insane.\n\nEdit: I forgot the 1650S also offers really good Fusion performance while AMD cards are just bad, my 5700xt is the living proof of this :(",
      "I think we can safely assume there won't be anything coming this gen. I thought Raja was an expert in false promises but this new guy is far far worse.",
      "5700xt gang once again they called us madmen for how drivers acted look at us now!",
      "Did people forget the memory bandwidth of the Vega cards? It‚Äôs not a significant performance determinant alone",
      "Or look at rx 480",
      "Please go read up on tensor cores, they are actually different and you can‚Äôt do dlss as quickly without them. https://www.techspot.com/article/2049-what-are-tensor-cores/",
      "> The RX 6700XT also has a lower memory bandwidth. The RTX 3070 has a 256-bit BUS and the RX 6700XT has a 192-bit BUS. I know this is not important to most people, but it still can be useful to have a higher bandwidth.\n\nThis isn't really a positive if the performance ends up the same or similar. Unless you mine.\n\nAgreed on the rest though.",
      "Look at the rx 570",
      "And funnily enough Raja might pull a pretty decent Xe lineup this year.",
      "Something, something, fuck you Nvidia, something",
      "Oh great, here we go again.\n\nI swear, these \"hear me out\" opinionated posts are worse than the battlestation ones.",
      "My main uses are gaming and debugging, I also use it for study/work and watching multimedia\n\nThe AMD drivers are open-source, on [Mesa](https://www.mesa3d.org/) which is a set of community driven implementations for APIs such as OpenGL and Vulkan. You have `radeonsi` which is an implementation of the OpenGL API and `radv` which is an implementation of the Vulkan API. \n\nOther than that, there's the [amdvlk](https://github.com/GPUOpen-Drivers/AMDVLK) (note: the actual code is on a different repository) implementation, which is an implementation of Vulkan by AMD and also open-source. It's similar to the implementation of Vulkan they use on Windows, so this is useful to debug driver bugs that occur on the proprietary drivers in Windows but not in radv for example.\n\n**For developers**, these are important so as you can accurately report and fix driver issues quickly. Reporting issues on proprietary drivers is hell, as they may take years to fix even the simplest issues or just never fix them at all. I've reported a few issues on `radv` that I found while debugging RPCS3 (a PS3 emulator project I work on) and they were very helpful and fixed these issues in a very reasonable timeframe.\n\nDebugging is also a pain in the ass on proprietary drivers as you don't have the source code nor symbols (which essentially allow you to see the function's names so you can better understand what that code does when you're debugging instead of only memory addresses). When you hit a driver bug, you have a hard time even trying to work it around on your software, let alone figuring out what's wrong.\n\n**For gaming**, you can get faster and more optimized drivers since they're scrutinized by the community, implementations are discussed on public issues and not decided behind closed doors where you have timelines to meet and may just need to fix things quickly as possible. \n\n**I can give a practical example:** when Cyberpunk 2077 released, it was immediately Playable on Proton (I completed it in 12 December, just 2 days after release, only playing on Linux almost non-stop). \n\nThe catch: **only if you had an AMD card with Mesa drivers**. This is because CP2077 has an engine bug that makes the game crash (seemingly randomly, and that doesn't crash the game on Windows by luck) which was worked around thanks to a Vulkan extension made by Valve called `VK_VALVE_mutable_descriptor_type` (drafted way prior to the game's release, it wasn't created for that issue), and Valve's developers had implemented it on Mesa before the game's release (because CDPR gave Valve developers a review copy of the game prior to launch so they could fix issues on Proton) in order to make the game work.\n\nWhy wasn't this possible on NVIDIA drivers? Because they're closed source. Fast forward two months after the release of CP2077 and that extension is still unimplemented in NVIDIA's drivers, and the only way for you to play the game on Linux without the risk of crashing is with an AMD GPU.\n\nI hope this wasn't too confusing, I tried to keep it simple but maybe I can further explain some things that perhaps weren't explained very well."
    ]
  },
  {
    "brand": "amd",
    "generation": "6000",
    "tier": "mid",
    "matched_keywords": [
      "6700xt"
    ],
    "title": "My tight Ryzen 3600 and RX 6700XT builld, with a gpu and cpu cooler that are technically too big for the case (h210i).",
    "selftext": "",
    "comments": [
      "Deepcool is killing it with this cooler.",
      "Man, that's a squeeze! I'd be concerned about proper air circulation, but you could always just fire it up and watch temps! I've ordered that same (although white) cooler for a new white themed build I'm doing this winter!  \n\n\nWhat ram do you have in there? Looks like the cooler completely dwarfs the memory, so wondering if the memory I'm looking at (Trident Z neo) is going to be too tall.",
      "It's the AK620, I absolutely love how it looks and it's also quite competitive with the top Noctua and Be quiet! air coolers, while being substantially cheaper.",
      "Temps are absolutely fine, gpu core maxes out at around 67c in furmark and cpu sits at around 70. The deepcool AK620 is quite freakin cool, basically the size of the itx board and looks epic in a small case. \n\nI can't say for sure, but I think it would fit fine with almost any memory kit, when I installed it there was quite a bit of space for the memory left over.",
      "Deepcool is such an underrated brand. Just rebuilt my PC with a CL500, gorgeous, huge and cheap case and their LS500 Water Cooler, also quite cheap but exquisitely made.",
      "I was wondering what it was, it looks good.",
      "I run this setup ( ryzen 5 3600x cpu, radeon rx 6700xt gpu)\nI run a full size case however. It does me very good! How do u find it so far?",
      "Probably ok in an air con room. A heatbox otherwise",
      "As I said in another comment, gpu core maxes out at around 67c in furmark and the cpu has a completely overkill cooler for it. No aircon needed ;)",
      "I absolutely love it, pretty much runs anything I want at 1440p, stays cool while doing so and looks dope af IMO.\n\nAlso I did undervolt the gpu very slightly and that improved the temperatures quite nicely. Honestly would recommend everyone to do that because they have put quite a lot of voltage headroom on the card from the factory.",
      "That's good to know. \n\nSometimes we get so caught up in the tiny world of tech youtubers like GN, HUB, JzTC, that it feels like there's only Corsair, NZXT, Lian Li and Cooler Master out there, but no, there's gold in them there brands if we look.",
      "Welcome to the ITX rabbit hole. \n\nI have the same build (3600/6700xt) but in a Coolermaster NR200. Stays just as cool. This CPU makes like no heat, so my next step is a 5800x3d, which I think should stay plenty cool based  on my 3600's temps.\n\nGo smaller ;)",
      "There are holes in the bottom of the psu shroud, max core temp after 30min in furmark is 67c and max junction is 85c at around 1500rpm, which is very quiet on this card :)",
      "That's phenomenal, really slick looking build!",
      "There's definitely not enough clearance for your GPU to get enough airflow. Might be worth just getting a new case, even if it's 2nd hand.",
      "My lord the owner has already said his gpu runs cool and quite and people still crying over the gap.",
      "Wdym?  Gamers Nexus covers Deepcool stuff when it comes out/has issues.  They‚Äôve got AK 400, AK 620, Assassin III.  They‚Äôre also all in the charts for cooler reviews/end of year recaps for ‚Äúbest coolers‚Äù.\n\nThey even went on a factory tour for Deepcool‚Äôs case fans lol",
      "That‚Äôs like a third of the price of the cooler. Not irrelevant at all.",
      "Problem is with the gpu, the air cooler looks fine",
      "AK620 works really well in almost any case esthetics"
    ]
  },
  {
    "brand": "amd",
    "generation": "6000",
    "tier": "mid",
    "matched_keywords": [
      "6700xt"
    ],
    "title": "My all amd build, 6700xt and ryzen 5 5600g.",
    "selftext": "",
    "comments": [
      "Bro you can't have the Yeston 6700 and not show off the Waifu on it!!",
      "I think you could use some more fans in this build.",
      "I didn't have a gpu at the time",
      "Iirc it's more comparable to the 3600 not the 5600x.",
      "ton",
      "I can assure you that many fans are not necessary to keep the temps low. It is aesthetic. And there is nothing wrong with that. It is beautiful. OP is just trying to justify the purchase to himself. It‚Äôs ok OP. You have built a beautiful machine. There is nothing wrong with spending money on unnecessary items for the sake of aesthetics.",
      "Why did you get a 5600G to combine it with a 6700 XT?",
      "would be interesting to see the airflow path and turbulence with a smoke machine.\n\nLTT recently has shown that even a case full of fans can have dead spots due to either bad intake/exhaust balance or placement. populating all fan slots is not always the best.",
      "Nice build.  How much did you shell out for the 6700 XT?",
      "What's that liquid cooler you have?",
      "its much closer to the 3600 than the 5600x/12400f",
      "Smells like your Waifu's perfume?",
      "Right?!?!? That's the whole point of the card IMO lol.\n\nI think the front looks... Cheesy.. but the bottom with the waifu actually looks sick as fuck.\n\n\nBut, that's just my opinion! It looks great in this build tho, I must admit.",
      "Yes",
      "$1100",
      "Nzxt z63",
      ">what would be like the best motherboards for AMD ryzen\n\nThere is no \"best\", there are different motherboards with different feature sets and different price tags.\n\nWhat do you want to fit onto that board? Are you going to overclock any components? How many USB ports do you need? Do you need Thunderbolt ports? M.2 drives? What's your budget? These are the questions you should ask yourself, and depending on the answers, look at what fits and what's available in your region.",
      "Damn, glad you could swing that. I've been so tempted to buy one but I can't bring myself to do it.  Really don't want to give in to these insanely marked up prices.",
      "Yes but no.\n\nThat many fans means you can run each fan slower.. So overall the noise made is easier to blend into background noise than fewer fans running at a higher RPM.",
      "Don‚Äôt just scream stuff you hear other people say. \n\nIf you don‚Äôt know what you‚Äôre doing, don‚Äôt advise other people on it.\n\nBesides, how is high voltage a good thing?"
    ]
  },
  {
    "brand": "amd",
    "generation": "6000",
    "tier": "mid",
    "matched_keywords": [
      "6700xt"
    ],
    "title": "Traded my 5700XT for a 6700XT",
    "selftext": "",
    "comments": [
      "Yeah. I think because of miners rx 5700 xt are expensive. Sold mine rx 5700 xt for 930 dollars and bought rtx 3060 ti with premium cooling for 720. Amazing part is that i have 210 dollars left",
      "Hash rate on the 5700XT is higher, so they are going for $900-1100.",
      "Trying is free.",
      "Post an ad on your local craigslist, lego, kijiji, Facebook marketplace etc.\n\n\"5700XT - will straight trade for 6700XT\" \n\nAnd let the interested miner contact you, thats what I did.",
      "A miner would buy that off of you in a heartbeat. \n\nJust post it on FB and/or craigslist, It'll sell for great money within 2 weeks.\n\nI upgraded from my 5700xt to a 6900xt 2 months ago, it only cost me an extra $450 USD.",
      ":( \n\nHow's everyone finding such deals and not myself :/ \n\nI have an AE and giving the waterblock and the blower cooler.",
      "Yeah i feel really happy and lucky because the pc costed 900 and sold just the gpu for 930. The owner of the pc is regreting now... I guess. that means i got every part for free and gained 30 dollars.",
      "Is selling a gpu online safe? I've been tempted to sell my 5700xt, however I'm slightly worried about being scammed, which would really suck because then I couldn't afford a replacement.",
      "Not the OP, but r/hardwareswap is pretty handy for selling PC parts.\n\nI've both bought and sold things there. I'm not exaggerating when I say you could post a 5700XT tonight and probably have payment for it by tomorrow morning.",
      "No one cares about the box.",
      "People live in other countries?",
      "People absolutely will buy it. Between miners and gamers the demand is there. I just sold my dusty old 980 ti for $350, your 5700xt will be worth more for its mining.",
      "I sold mine for 815‚Ç¨ and got a rx 6900xt for 1k‚Ç¨ got really lucky :D",
      "or they‚Äôre japanese",
      "Yes it's the hellhound. I'm noticing 20-30% more fps. Love that the fans don't spin at idle. Max temperature hit 78 (junction) temp.",
      "Where did you sell it if you don‚Äôt mind me asking?",
      "5700xt is much better in mining than the 6700xt",
      "I sold my old card on eBay, and I was nervous about it at first. Now I wouldn't hesitate to do it again. There are mixed reviews with eBay but they have tons of protections in place for both buyer and seller. They do take a chunk of the money so expect to not get full asking price. They will also ban/lock your account until you physically contact them to verify yourself. At first I was frustrated with it but it definitely goes the extra mile to ensure people aren't being scammed.",
      "Driver issues at launch were a mess but most if not all the issues have been resolved now.\n\nI bought my 5700XT near launch and debated reselling. I just tossed it in a spare computer and used it as a dedicated miner instead. Got lucky with queues for a new GPU",
      "Oh I know about r/hardwareswap. I have something like 20 confirmed trades atm. I was curious if there was somewhere else to post to find someone willing to do a straight trade as I have a 5700xt as well and would love a free upgrade."
    ]
  },
  {
    "brand": "amd",
    "generation": "6000",
    "tier": "mid",
    "matched_keywords": [
      "6700xt"
    ],
    "title": "Yesterday one person bought 79 x 6700XT and 14 x 6900XT during the EU AMD drop (no joke, with proof).",
    "selftext": "",
    "comments": [
      "I think that's the Dutch browser extension\n\nIt shares the unique queue ID between the subscribers, I saw that in many forums in the web since (at least) 3 months from now so I think AMD/digital river is well aware of that\n\nThat's the new era of scalping: scalp BEFORE the purchase",
      "That was patched months ago nowadays it's way more complex, the guy has thousands of instances open and the more people solve captchas the more different queue IDs are made, his script also has a priority list where people who haven't had a chance as much get picked first.\n\nI'm glad for his script as months of trying manually didn't lead to anything mostly because cards were gone in 2 minutes as the bots shared the same no queue ID but it felt scummy and most of the people in the forums where they discuss this are the scum of the earth\n\nFor those unaware one guy didn't farm 70 cards, those are divided by the people using a dudes paid script which has about a thousand users by now",
      "He sells subscriptions which gives people a position on his waitlist. You need to have PayPal to do this. Yesterday 93 PayPals bought a GPU through this system in 10 seconds making it nearly impossible for others to buy. Earlier this bot was succesful, but not this succesful now it's probably has become the only option if you wan't to buy a GPU from AMD in the EU.\n\nI say \"PayPals\" because there's a lot of people who sign up for this service with multiple PayPal accounts.",
      ">This is the future of pc gaming. Get used to it.\n\nOnly if people keep paying way over msrp for the cards. If the scalpers can't sell their product, they will stop buying it. Problem solved.",
      "Whoever thinks the same thing won't happen when the new gen is out, is out of his mind lol.\n\nThis is the future of pc gaming. Get used to it.",
      "So what you're telling me is that this guy has a better queue (at least from a consumer perspective) than AMD does?",
      "A year ago i subscribed by EVGA for a 3080 at msrp. Still waiting, and shops have plenty evga in stock. The reality is that manufactures want to sell fast at the highest possible price‚Ä¶ thats a part of the problem too",
      "Wouldn't he need a different address for each card?",
      "Except this mentality is part of why prices are still where they are, and if people continue paying the prices that's where it'll stay\n\nThe victims aren't the people paying scalped/inflated pricing (They can afford it) and are only paying the price due to their own impatience\n\nThe victims are those who can't afford the inflated prices and are priced out of PC gaming entirely",
      "people here can't get cards because of other bots and this kind of things\n\nDR must find a way to avoid that\n\nmaybe an early email subscription with lottery will be better than thousand of millions of people and bots going to [amd.com](https://amd.com) only in those 3 minutes\n\nif things will not change we will never be able to buy upcoming gpu",
      "Yeah definitely.\n\nSounds like his queue is super convenient and hassle free. Plus I think it's brilliant that customers who weren't able to buy a card the week before get increasingly higher priority the next round.",
      "this is what happens when AMD picks the worst unreliable partner to run theirs shop ...  \nfrom perspective of customer who attempted to buy anything via AMD shop in past 12 + months  \ni would never ever buy AMD product again ... so bad the experience was and is ...",
      "This was always going to happen\n\nPeople have been paying scalped prices for years now, that is why scalpers are still here, they're opportunists, and they've been given this opportunity (They don't do it just because, they want to make money)\n\nAnyone who has bought from a scalper cannot be angry about this, because you helped create this situation in your own small way, And tbh it's your fault if you payed an inflated price because you chose to do it out of impatience \n\nThe actual victims are those who can't afford the inflated prices and cant build a PC now because they've been priced out",
      "EVGA still has their queue and people have been waiting since launch to see their name pop up still",
      "It‚Äôs trivial to register a bunch of emails so scalpers still win in that case.\n\nIt‚Äôs not an easy problem to solve and no idea you came up with in five minutes is going to work, otherwise it would have been solved by now. It‚Äôs not for lack of trying, it‚Äôs really hard to do without some kind of external reputational signal. For steam, that signal can be your spending history and wallet, AMD doesn‚Äôt have that sort of data for you.\n\n(The one thing AMD/NVIDIA have access to that could legitimately be useful is driver telemetry data tied to your account but nobody wants to talk about that.)\n\nBut seriously, things that are not actually good ways to ensure one-per-person:\n\n* emails\n* credit card numbers\n* shipping addresses\n* billing addresses\n* names\n* phone numbers\n* ip addresses\n\nTime and again every baby redditor thinks they‚Äôve solved the scalper problem by ‚Äújust limiting one per credit card‚Äù or ‚Äúone per billing address‚Äù and they don‚Äôt realize the sneaker market tried that like 15 years ago and scalpers trivially worked around it and found a solution. This is big business, the people who sell the tools make hundreds of grand per year enabling scalping, they have worked around ideas you haven‚Äôt even come up with yet.",
      "Its been 2 years and everything still out of stock,i don't blame people for paying way over MSRP at this point",
      "Friend of mine got his 3080 yesterday from EVGA email listing, almost 9 months after he signed up for it.",
      "Definitely? How did you come to this conclusion because it definitely is not. He just doesn't have to deal with what AMD is dealing with. It does not solve anything: It's first come first serve and thats being botted as well. Of course once you're subscribed to his services you have a very convenient experience but that is not what you need to compare to the AMD queue.\n\nHe only let's about 50 people buy a subscription once every while (allthough he has strongly oversold because of technical issues). Combine that with a high successrate and yes, customers will be satisfied.\n\nIf this wasn't exclusive it would be the same mess AMD is dealing with now. The only thing he is doing is moving the issue from the AMD queue-it queue to the people paying him for a subscripion, he actually started using some \"bot protection\" himself because people (scalpers) want a subscription.",
      "I've been on there since later 2020. The cards I signed up for are discontinued so I guess I'm not in any sort of real queue anymore.",
      "Of course they care. If they didn't care they wouldn't be setting up this complex system with all kinds of protections that make it hard to get anything."
    ]
  },
  {
    "brand": "amd",
    "generation": "6000",
    "tier": "mid",
    "matched_keywords": [
      "6700xt"
    ],
    "title": "Accidentally upgraded my rig. I7 9700 & 2070 -> 5600x & XFX 6700XT ü§ì The GPU makes this case look tiny.",
    "selftext": "",
    "comments": [
      "There is no such thing as accidentally upgraded build sure you can build a shed or end world hunger but not upgrade rig. Nice rig BTW.",
      "I guess I just \"accidentally\" bought a PS5 bundle from Sony too...",
      "Shhh don't tell the wife lol, thank you good sir ‚úåÔ∏è",
      "Specs:\n-Coolermaster masterbox Q300L (moving onto Corsair 4000D/275R airflow soon)\n\n-Ryzen 5 5600X (cooled by H100i)\n\n-Asrock b550-m pro4\n\n-Kingston HyperX fury 16Gb 2666mhz running @3200mhz\n\n-XFX speedster Qick RX 6700XT\n\n-Corsair CX-750M psu\n\n-Kingston 480gb SSD boot\n\n-1TB WD disk and 1TB m.2 SSD (can't recall brand) for storage.\n\n-I probably could've gone for a better GPU, but I like how well the Ryzen works with this one, it gets pretty much all out of it.",
      "I accidentally bought two bowling balls instead of a 3080 lol",
      "Poor us, right? üòÇ",
      "[shhh, it's a wifi router](https://youtu.be/cEN00wMFB2A)",
      "True, I only bought the PS5 that \"accidentally\" bundle with a 55\" TV and a spare controller, not my fault!",
      "You *could* join the Meshify gang [just saying ](https://imgur.com/a/k2b5Ves)",
      "Sidegrade",
      "That sounds like one big happy accident, have fun with it ‚úåÔ∏è",
      "I hella recommend the 4000D case. It's so fun to cable management in it.",
      "[50%](https://static.techspot.com/articles-info/2216/bench/1080p.png) faster at 1080p without SAM and with release drivers. It's faster now.",
      "Sidegrade",
      "Must have ‚Äúaccidentally‚Äù put it on the credit card?",
      "This does appear to be an accident because it's almost a sidegrade not an upgrade.",
      "Nice! I got an MX Ergo for Christmas :-)",
      "I accidentally bought myself a test bench that I'm not gonna use",
      "Accidentally paid too?",
      "This feels like a side grade more than an upgrade"
    ]
  },
  {
    "brand": "amd",
    "generation": "6000",
    "tier": "mid",
    "matched_keywords": [
      "6700xt"
    ],
    "title": "I actually managed to get into the store today, and even added a 6700XT to my cart, but when I tried to pay there was nowhere to enter my payment information. I expect nothing, and yet I‚Äôm continually disappointed.",
    "selftext": "",
    "comments": [
      "Congrats on at least getting that far lol.",
      "I feel your pain - made it through processed order for 6700XT and BOA decided the charge was fraudulent and declined the transaction so I got booted to back of the line... feels like we can't win.",
      "For all the good it did for me ¬Ø\\\\\\_(„ÉÑ)\\_/¬Ø",
      "You‚Äôve got an ad blocker running. Same thing happened to me last fall. Had uBlock on and it removed all of those fields. Turned it off and got a card the next week.",
      "punch busy chief agonizing advise versed observation wine adjoining mindless\n\n *This post was mass deleted and anonymized with [Redact](https://redact.dev)*",
      "That exact same thing happened to me months ago, except it was Chase bank",
      "Maybe, but it‚Äôs too late to try it now",
      "Hmmm‚Ä¶I have the Firefox focus content blocker enabled on Safari. I wonder if that caused the problem.",
      "I managed to get through this morning.\n\nI used paypal and got a 6700xt. My buddy tried getting a 6900xt and his popup blocked ruined his day.",
      "Honestly dude, you‚Äôve got a 6700xt and by the end of the year, the 7600xt is supposed to be faster than a 6900xt. You should probably hold fire till the new cards come out.",
      "I think this was my issue as well. Ad blocker on Firefox. Rippppppp",
      "I had the same issue and it was due to Firefox and uBlock. I ended up making my purchase using Chrome.",
      "Same happened to me with another National bank a few months ago. It actually happened on my birthday which almost ruined my day.",
      "For the OP, be careful with this, some checkout processes send you to multiple individual sites along the way, for example order processing and payment processing may be under different individual sites. Each time you need to disable the protection for each individual site you add another factor that risks you not making it out of checkout successfully. Probably better to disable this globally or use a different browser with no adblock when you are specifically attempting to nab a card.",
      "I got my 6800xt on mobile, auto fill is really fast and helps a lot.",
      "Not really, you have to pay to be apart of their program to get a chance at MSRP prices. Scumbaggery",
      "You can also click the shield icon in the Firefox address bar and switch off \"Enhanced Tracking Protection\". It's site specific.",
      "This is the second reason why edge exists.\n\nNumber 1 obviously to install any other browser, number 2 for when shit's broken.",
      "I got in, put in my payment information, hit checkout and got booted back to the queue. Oh well. I don't really NEED a card anyway.",
      "I feel your pain. I managed to buy one and it was stolen by USPS mid transit, and \"they don't know how it went missing\" üôÑ"
    ]
  },
  {
    "brand": "amd",
    "generation": "6000",
    "tier": "mid",
    "matched_keywords": [
      "6750",
      "6750"
    ],
    "title": "Massive AMD Zen5 Leak Reveals 20% Single-Core Uplift, Sarlak 'Strix Halo' Achieves RX 6750 XT Levels of Performance at 95W-125W",
    "selftext": "",
    "comments": [
      "This feels like a lie",
      "> RedGamingTech\n\n> MLID\n\nThis can safely be ignored.",
      "I don't think performance would be that far. PS5 (Zen 2, RDNA 2) draws up to 210w according to Sony for the whole system which is close to an RX 6700. 125w just for the APU (Zen 5, RDNA 3.5?) seems reasonable to me after all those years of advancements.",
      "Which part?\n\n  \nWe know AMD has been working on Zen5 for a long time, they've [announced it](https://www.extremetech.com/computing/amd-confirms-am5-socket-will-extend-to-2026-zen-5-to-use-rnda-35-gpus). We know it'll be the 8000 series, we know it'll be AM5 platform, we know it launches [next year](https://www.forbes.com/sites/antonyleather/2023/06/05/amd-confirms-2024-launch-for-ryzen-8000-zen-5-processors/?sh=3787e4d56099), and we know the iGPU will be RDNA3.5 based. It's almost certain to use TSMC's 4nm process node.\n\nThere's nothing new or controversial in any of that. \n\nAs to having an APU variant with 6750xt levels of performance I see nothing strange or implausible there. \n\nThe 67050XT is a 17 billion TX chip built with TSMC 7nm and pushing \\~13 TFLOPs with board power \\~250 watts.\n\nThe move from 7nm to 4nm brings an \\~80% boost to transistor density and a decrease in power consumption of around 30% (for same clocks). Plus the architectural improvements between RDNA2 -> RDNA3.5 are quite substantial. \n\nCombine that with the rather hefty efficiency gains from unified memory and I can see it fitting within that power envelope.\n\nSo if this is a lie they've decided to go with a perfectly reasonable one.",
      "But isn't that what 'leaks' mostly mean? It's people from the inside that can \"leak\" information far in advance, not outsiders",
      "Because even RDNA4 and nvidia (4060ti) can‚Äôt get 6750xt levels of performance at 95-125 watts. I‚Äôm glad if I‚Äôm wrong of course. But it just doesn‚Äôt seem to add up.\n\nEdit: got my RDNAs and Zens mixed up. RDNA 3*",
      "Dropping an 8800x3D into my existing 7700x's mobo is gonna be a great day.",
      ">Has RedGamingTech ever been right?\n\nYes, with his name.",
      "RDNA 4 isn't out yet. Do you mean RDNA 3?",
      "Here's a laptop with a 105W RTX 4080: https://www.notebookcheck.net/MSI-Stealth-17-Studio-review-A-laptop-with-a-quiet-RTX-4080-for-almost-every-occasion.708750.0.html\n\nIt seems to be pretty close to a 6750 XT desktop in terms of performance, possibly a bit quicker.",
      "The answer is memory bandwidth. A 6750 has +400GB/s, while ddr5 6000 has around 90GB/s. It would be memory starved to have  similar performance",
      "amd said along the lines of 10-15% ipc lift.  \nquestion is frequency and whenever x3d version is out.",
      "It‚Äôs funny now we are not happy with 20% single core IPC jump from gen to gen lmao.",
      "I'm surprised he didn't also \"leak\" Metal Gear Solid Remake for the 17th time.",
      "Notably he was the first to talk about infinity cache and he was pretty much exactly right about RDNA 2 performance expectations. Otherwise I have no idea.",
      "Even if it turns out to be correct I still think it's a lie. It's reasonable sure, but I don't think one person outside amd has all that working silicon.\n\nIf someone says they know something when they don't, it's still a lie even if it turns out to be mostly true.",
      "- Zen 1 -> Zen 2 : +27-28% (4.0->4.6/4.7Ghz and +15% IPC)\n- Zen 2 -> Zen 3 : +29% (4.6->4.9/5Ghz and +19% IPC)\n- Zen 3 -> Zen 4 : +25-26% (4.9-> 5.6/5.7Ghz and  +8% IPC)\n- Zen 4 -> Zen 5 : +20%",
      "\"RedGamingTech\"\n\na truck of salt",
      "My dumbass spent $900.ü§¶üèæ",
      "Source: MLID\nClose the thread. \nZen 5 rumored performance is as real as MLID sources."
    ]
  },
  {
    "brand": "amd",
    "generation": "6000",
    "tier": "mid",
    "matched_keywords": [
      "6750xt"
    ],
    "title": "AMD Direct 6750XT sale (CAD $403)",
    "selftext": "",
    "comments": [
      "price error ? the price is simply too good, and it is 400 CAD not even USD, wtf.\n\nedit : hopefully this is an indication that RDNA 3 will be affordable",
      "European prices still at MSRP and out of stock for anyone curious.",
      "It's a pretty normal price drop when moving to a new generation, when crypto isn't relevant:\n\n    Vega 64     500 USD\n    RX 5600 XT  280 USD",
      "For those who like great prices, this is about as good as it gets. The Canadian AMD store has the 6750xt reference model on sale for CAD $403, which works out to about USD $295.\n\nNot sure if other regions have the same deal.\n\nEdit: The price is back to CAD $608 now...guess it was too good of a deal. Hope some of you were able to get it at least!",
      "AMD just brutally discounted combos and GPUs even for EU, check the site.\nMan if would have the money for that right now.\n5800x3d + 6950 combo for 1000 EUR only.\n\nhttps://www.amd.com/de/direct-buy/de",
      "It is only \"normal\" if the next gen GPUs are supposed to hold the price brackets of current gen MSRP +100/200$, not like Nvidia's 700 USD to 1200 USD for an 80 class GPU. Hence why I'm actually looking forwards to it.",
      "definitely, RDNA3 will probably take over the RDNA2 price bracket with slight inflation adjustment while RDNA2 will be on clearance",
      "That is a fucking deal, even in yankee money.",
      "Are you sure that the price is in CAD$?  \n\n\nEdit: Ok, I tried with the Paypal option (just to see, I didnt buy) and indeed it was asking for $403 CAD! Wow, its a REALLY big sale...",
      "Can only be shipped to a Canadian address. Just tried.",
      "*cries in europe*",
      "Netherlands here. No combo deals either. Also the RX 6750 XT is ‚Ç¨678.87 and out of stock.",
      "I don't see any combo deals. Do they have their own page? Or maybe they're country specific? \n\nAlso not super relevant for those of us that already bought a CPU :/",
      "This shit‚Äôs fantastic, it‚Äôs been four years but we finally have a $300 2080 Ti equivalent.",
      "They must be dividing up by country or sub region then, bit hard to check without using a VPN since they force redirect to a local page.\n\nI see:\n\n    RX 6950 XT  1358.98 EUR\n    RX 6900 XT  1235.31 EUR\n    RX 6750 XT   678.87 EUR\n\nall out of stock.\n\nIf you're getting prices in USD, maybe you're covered by the US warehouse?",
      "hope you are right but my predictions are closer to:  \n7900XTX - 1499  \n7900XT - 1199  \n7800XT - 899  \n7800 - 749  \n7700XT - 599",
      "Yeah tried it out myself in Canada. Didn't post the link because it will just redirect depending on the region you are in.",
      ">I wouldn't be surprised if the 7700XT was available this month.\n\nI will be, I don't think they have enough chips to meet the demand.",
      "Yes, but unfortunately it doesn't show any combo offers to me",
      "FUCK IT! \n\nI PULLED THE TRIGGER!\n\nThis is WAY too good of a deal to skip out on, fucking hell üò±üò±üò±"
    ]
  },
  {
    "brand": "amd",
    "generation": "6000",
    "tier": "mid",
    "matched_keywords": [
      "6650"
    ],
    "title": "AMD Radeon RX 7600 XT Specs: 8GB VRAM & 2.6GHz Boost; Only 11% Faster than the RX 6650 XT at Same Power [Report]",
    "selftext": "",
    "comments": [
      "Needs to be under $300 or dead on $300 realisticly.",
      "Arguably it should be cheaper than that. For 300, it would have the same appeal as 4070. It needs to be max 250 in order to be a viable product at all. \n\nIf this rumor is true, this would mean that RDNA3 is one huge flop though.",
      "Then it's a pointless card. The 6700xt could be had for around $300-350ish for months and is already around 10% faster than a 6650. Plus they're 12gb cards.\n\nAt the rumored specs/performance the only way this card is a success is if it's a $200-250 card for the masses.",
      "It's not delusional when you consider current price/performance. A $400 7600XT would fucking suck",
      "I thought that 8gb vram wasn‚Äôt enough for games according to amd",
      "8 GB is officially considered low end now.",
      "What an utter disappointment. This thing needs to be $299 to not suck, and it might even be bad *then*.",
      "It must launch for less than $300",
      "Brother u are delusional. 6650xt was priced at $399 so I imagine 7600xt would be priced the same.",
      "8GB VRAM for 399 USD  in 2023 makes it meh",
      ">the card will be paired with¬†8GB of GDDR6¬†memory via a 128-bit or 192-bit bus\n\nIf someone manages to get 8GB of vram working on a uniform 192-bit bus I will eat my shoe. The numbers don't number and the person who wrote this article has no clue.",
      "6700 XT is between 20% to usually more around 33% faster than 6650 XT.",
      "Each vram memory module uses 32-bit bus to communicate with the GPU. These modules are made in capacities in the powers of two due to how binary addressing works, most commonly in 8Gbit or 16Gbit  densities or with 1GB and 2GB capacity respectively. To have a uniform access to the entire addressing space you have to use the same modules for the entire vram. That means for a 192bit bus you have total of 192bit/32bit = 6 modules that can either be 1 or 2GB capacity so 6GB or 12GB total. For 128bit bus that is 4 or 8GB. Other capacities on these buses are impossible unless you use uneven/non-uniform addressing space by mixing modules. Something similar was once done by Nvidia on a GTX 970 and received a backlash. Basically you would lose bandwidth once you fill up the capacity of the low density modules.",
      "nobody will buy it over a 6650 xt unless they curb the supply. Historically, AMD drivers aren't quite polished either for new product support.  \nHeck even 6700 xt are available for $320-$340",
      "u can get a 3070 for 300 on ebay",
      "I don‚Äôt think it‚Äôs possible for new cards to compete with clearance priced last gen stuff from AMD. If you want a $325 6700xt you‚Äôd better buy it before they sell out.",
      "It'll launch at $349 and then drop to $329 and then $299 sales once nvidia release their lower end\n\nIt will be noticeably better bang/buck and the vast majority of reviewers will call it the better buy over the 4050 Ti/4060\n\nThe 4050Ti/4060 will still outsell it 5:1 or worse, as is tradition\n\nAMD need to wake the radeon division the fuck up. Nvidias trash pricing and stupid decisions this generation is the best chance they have had in a decade of clawing back market share and they're just doing the same thing they've been doing over and over again",
      "You can also get Intel's A750 with 16GB VRAM.",
      "if you play games at cranked out settings yes\n\nbut 99.99% of people turn them down and hover around 5-6gb VRAM usage so we have 1 gen worth of time before 8gb becomes actual mandatory\n\nand old games exist which look pretty for the VRAM usage they have so i don't know whether to laugh or not at people thinking this is the problem XD",
      "The RX 480 was a mid range card available with 8GB six years ago. 8 is insufficient."
    ]
  },
  {
    "brand": "amd",
    "generation": "6000",
    "tier": "mid",
    "matched_keywords": [
      "6750xt"
    ],
    "title": "Went from a 1060 6gb to a rx 6750xt, only my cpu 3600x struggles at 1080p, any recommendations?",
    "selftext": "",
    "comments": [
      "Updating w the boisssss",
      "update the bois. it runs much smother. i have that board.",
      "Definitely need to update the *bois* for the best performance",
      "Me and the bois updating to get the best performance out of our hardware",
      "Ikr, the lads arent as good as they used to be.",
      "1.update mpbo bios.\n2.update ryzen chipser drivers\n2. In amd driver sw, turn off everything except anti lag.\n3. Play the games a bit and see what happens. For example in Fortnite, after each update there seem to be some extra work needed so fps drops, but after a few hours fps is again stable.",
      "Can you first tell us what games you struggle on? Your current pc should be enough to rip trough 1080p with ease.\n\nAlso check the lateny and speed of your rams, cpu temperature and could this be some sort of driver issue. How long passed before you did a clean win install.",
      "3600x should be fine for pretty much anything and everything even in 1080p. If your trying to get 240hz in everything you play all the time then you'll have to pay that kind of money though",
      "That‚Äôs cuz the game needs rebuilding of shaders",
      "Bro, I'm on R5 3600 and 6700XT no problem at 3440X1440, you should be getting a lot of FPS with that card on 1080p.",
      "Make sure it's not a skater Boi, or I'll see you later boi",
      "I can confirm this. I had a micro stuttering in games on my 3600 which i figured was due to my rx 580 not keeping up. Updated bios for memory compatibility and the stuttering went away in all of my games.",
      "That sounds more like a storage issue -- you wouldn't happen to be playing from a hard-drive would you?\n\nI have a non-X 3600 and AssCreed Origins (a nototious CPU hog) runs like butter installed in my nvme drive.",
      "The gpu isn't the problem, I have these microstutters and framerate going all over the place sometimes, especially in cpu heavy scenarios. All in all the performance is good, don't get wrong though.",
      "3600 is a beast at 1440p too.",
      "So you are saying it happens in multiple games. I'm 100% sure that this CPU is enough for gaming without problems with that card. The way this sounds is you get high CPU usage and stutters when loading assets and other in game objects means that your disk drive is actually having difficulties. I only get stutters on NFS Heat on 1-2 seconds once the game is loaded. I'd definitely check the disks.",
      "Just out of curiosity, did you try using DDU to uninstall evrything nVidia related and then doing a clean install of AMD drivers?",
      "The 3600x isn't that hot",
      "It is fine normally, but sometimes I have these annoying micro stutters when I think games are loading assets or so, like assassin's creed origins, war Thunder or BFV",
      "Under full synthetic load assuming case airflow isn't complete crap it's will hover between 70c-90c \n\n\nNot thermal throttling but may not boost as much, with PBO enabled it will thermal throttle \n\n\nGames will probably be around high 60-70 \n\nStock cooler is fine just loud"
    ]
  },
  {
    "brand": "amd",
    "generation": "6000",
    "tier": "mid",
    "matched_keywords": [
      "6750",
      "6750"
    ],
    "title": "AMD announces two Radeon RX 6750 GRE models at $269 (10GB) and $289 (12GB)",
    "selftext": "",
    "comments": [
      "Hold on. This sounds like RX580, RX580 2048SP and RX590 all over again.",
      "More decently cheap midrange GPUs? Nice.",
      "The 10GB 6750 GRE is more or less an RX 6700, no? For $270 that‚Äôs really not a bad card. I should look into buying an RX 6700 soon lol‚Ä¶",
      "Its just the 6700 and 6700xt at a cheaper price. Which is nice since they offer very good value for money. Especially the sub 300 6700xt(6750 GRE 12GB)",
      ">except TDP is down 5W somehow.\n\nProbably just node maturity and better binning.",
      "Apparently there was also an RX 580**X** but I can't find any information beyond the TPU entry and an [AMD driver page](https://www.amd.com/en/support/graphics/radeon-500-series/radeon-rx-500x-series/radeon-rx-580x).",
      "All the specs are the same, except TDP is down 5W somehow.",
      "**G**olden **R**abbit **E**dition *(from Chinese Zodiac's Year of the Rabbit, 2023-01-22 to 2024-02-09)*.",
      "I think those Polaris X versions were used in Apple iMac models around 2017/2018, if I remember correctly.",
      "This is just for the Chinese market so it doesn't matter",
      "Literally every single company re-releases and refreshes chips like this. Zero point to mock radeon specifically.\n\nSilicon lottery isn‚Äôt gonna have a 99% perfection rate, there‚Äôs tons of times where this happens.",
      "That is ***not at all*** how that works.\n\nYour PC hardware should operate at 100% of it's specifications, *for years*, with zero degredation in performance.\n\nMicroprocessors generally either work or they don't. You won't lose performance to \"wear and tear\" of the silicon. (Degredation from overclocking / overvolting is a different discussion).\n\nStuff like the thermal paste can degrade, which can affect performace, but this is easily remedied.\n\nAn engine in a car is subject to lots of friction and wear of the moving parts, and so will age and degrade due to many factors such as corrosion, seals wearing out and leaking etc, which can all harm efficiency and thus performance.\n\nI'm afraid in this case, it's a terrible analogy.\n\nu/DoomGuyIII certainly shouldn't have been getting errors from a card as new as an RX 6600; RMA that thing!",
      "Perfect upgrading from my aging RX 5500 XT(8GB)...",
      "How many 3080 variants has Nvidia released?",
      "6700XT performance for under $300. Sounds good to me.",
      "So‚Ä¶ basically discounts on the 6700 and 6700 XT? The 10GB model is priced too close to the 12GB one, but the 12GB model would be a nice little addition to the market if it wasn‚Äôt an OEM-only product.",
      "Why did nobody tell me I owned a country",
      "Only for the Chinese market.",
      "Just like MREs, GREs = **G**raphics **R**eady to **E**at.",
      "Yeah it was only a performance uplift, literally an hour ago i found out what was causing my system to constantly stutter and shit the bed was a faulty NVME."
    ]
  },
  {
    "brand": "amd",
    "generation": "6000",
    "tier": "mid",
    "matched_keywords": [
      "6750xt"
    ],
    "title": "5700X with 6750XT!",
    "selftext": "",
    "comments": [
      "Now there's a PC case I can get behind.",
      "I was contemplating getting one since the price is so nice as of late",
      "Let's be honest here, you probably won't be able to get behind that case without moving the table",
      "> highest end upgrade now on the AM4 pathway\n\nIt really depends on what you're doing. If your main use for it is productivity work, then yes it would be the highest end upgrade for AM4. However, if you're mainly gaming, then a 5800x3d will provide better framerates, not to mention at a cheaper price",
      "I'm thinking similar with the 5950x, It's basically the highest end upgrade now on the AM4 pathway and I don't want to go to AM5 so early, so figure I might just cap my rig out and then relax for another couple years.",
      "True, I am mostly doing stuff that needs high core counts (video editing/rendering and CAD for work) but also when it comes to gaming I typically play MMOs and multi-box them, so need more physical cores for the clients than I need per core performance.",
      "It's an amazing build. Lately i was thinking of making a small PC. What's the name of the case and the specs?",
      "Amd version, i think you can get in in their store",
      "Yeah, but AM4 and DDR4 are price champs. I don't believe ryzen 7xxx series can compete against ryzen 5xxx with new mobo and DDR5 pricings. If you got the cash it is a different story of course.",
      "It's the Formd T1 without its side panels for the summer :)",
      "What 6750XT is this?",
      "for $200 it's a steal imo",
      "The AMD made ones are SO nice in person. That whole outer shroud is a (CNC‚Äôd?) single block of aluminum. They feel utterly premium and have way better aesthetics than the cheaper RGB plasticky partner cards.",
      "love SFFPC. fun fact, amd reference 6700xt, 6750xt, and 6800 are the only two slot AMD cards this gen (excluding 6650xt and below cards)",
      "OP wants the decoration without the hassle and I'm fully onboard with that.",
      "Here‚Äôs my little Type R\n\n5800x3D \nRX 6800 \nnzxt h1 v1 \n\nhttps://i.imgur.com/DtntENF.jpg",
      "If I can get one that cheap, great! I saw them at around 240 which is still pretty good by my estimation",
      "We must've been reading very different reviews, because I remember them saying get the 5700X or the 5800X3D and the 5800X is basically redundant with those two around.",
      "yeah GN even said that 5700x is what 5800x should be",
      "I don't know why but I thought amd reference cards didn't exist and they were just renders"
    ]
  },
  {
    "brand": "amd",
    "generation": "6000",
    "tier": "mid",
    "matched_keywords": [
      "6750",
      "6750",
      "6650"
    ],
    "title": "AMD Radeon RX 6000 Refresh Gaming & Raytracing Benchmarks Leaked: 6950 XT Faster Than RTX 3090 For $1099, 6750 XT Faster Than RTX 3070 For $549, 6650 XT Faster Than RTX 3060 For $399",
    "selftext": "",
    "comments": [
      ">The following results are based on AMD's official data which has been presented to the media.¬†\n\nWill probably need to wait till independent reviews come out",
      "Considering the regular 6600XT beats the 3060 and the non XT 6600 trades blows the 6650XT beating it for $400 isn't anything to write home about \n\n\nIf it beat or matched the 3060ti then that would be interesting but I don't think it will making a kinda obsolete product especially as stock is more and more readily available",
      "I'd like to see 6950xt vs 6900xt @ 1440p and 1080p",
      "RX 6650 XT vs RX 6600 XT = 2% Faster\n\nSo this justified a price increase according the AMD, ridiculous.",
      "Accurate isn't the same as representative.  \n\nCompanies pick benchmarks that show their products in the best light.  That doesn't mean they aren't accurate.",
      "Yeah, whatever, wake me up when anyone makes a video card under $200",
      "I know right. Never trust this until you get independent reviews",
      "Just look at those ray tracing results for the 6950 vs 3090. They're trying to give the impression that AMD 6000 series is a few % behind, or even trading blows with NVidia for raytracing performance. We all know that that is simply not an accurate summary. I think the article was EXTREMELY charitable to AMD when they stated:\n\n>...there's a reason why AMD didn't focus that much on raytracing performance...\n\nThey cherry picked the few results that show AMD cards in a decent light (pun intended) and attempted to pass that performance on as typical. It's disingenuous and just further reinforces the reality that none of these companies are your friend and they all participate in misleading marketing. Early/Mid Ryzen was such a breath of fresh air. A defeated AMD came out and said the truth: \n\n>We got these chips that are \\[OK to great, depending on the generation\\] for gaming, they're really great for productivity and multi-tasking, and we're sellin' 'em cheap enough to be compelling. Also, we're going to have 5 years of socket support so that'll be nice.\n\nThat was enough for me to buy a Ryzen 5 1600, Ryzen 5 2600x, Ryzen 5 3600, Ryzen 7 3700x, Ryzen 9 5900x, Ryzen 9 5950x over that period. The BS marketing is a turn off after being spoiled by a relatively honest 6-7 years from AMD.",
      "They're probably accurate - AMD's benches for the RX 5000 and 6000 GPUs, to date, have been accurate. It is, however, common sense that you wait for independent third-party reviews from people who aren't sponsored by the vendor.",
      "Or when any RT is used.",
      "Because there'd be a huge uproar of gamers who have pre-RT hardware. Considering the (admittedly recovering but still...) state of the gpu market it's good that hasn't happened yet.",
      "That'd be interesting but to be quite frank the 6950XT performs as well as I expect it to. The Infinity Cache does too good of a job that it's up to core clocks to make the rest.\nAMD's focus on memory architecture/hierarchy makes it easy to find where performance is limited.\n\nEdit: By performing well I meant the weak performance increase on the refresh. Memory was never a bottleneck for RX 6800 and up; just like the Radeon VII and R9 Fury series.",
      "Which makes sense, since it's the only AAA title so far which requires RT to function. Everything else just uses RT as optional window dressing for their rasters, rather than an integral part of the rendering pipeline.",
      "the 6800 msrp was $580 and beats a 3070ti and AMD wants you to think a 6750xt which is supposedly faster than a regular 3070 is $550 is a good deal??  Literally I cannot stand AMD the past year",
      "To be fair, it‚Äôs looking like the 6650xt will hang with a 3060ti at 1080p, but it obviously will lose ground as resolution goes up.",
      ">Beats the 3090 at what though? At 4K? At 1080p? At ray tracing?\n\nCherry picked AMD sponsored games.",
      "Correct. Fully raytraced lighting is actually simpler to implement and compute in realtime than the compounded layers required for a good raster. Adding RT effects on top of a good raster kills performance, but replacing the raster entirely improves performance on adequate hardware.",
      "According to Hardware Unboxed , the RTX 3060ti and the RX 6700XT have around the same performance\n\nhttps://youtu.be/pnZRuY-jFVM\n\nI doubt that the RX 6650XT would match the RX 6700XT\n\nAlso , according to data provided to reviewers through AMD's official guide , the RX 6650XT is just 2% faster than the RX 6600XT on average\n\nhttps://videocardz.com/newz/official-radeon-rx-6x50xt-series-gaming-performance-leaks-out-rx-6950xt-is-4-faster-than-rx-6900xt",
      "Beats the 3090 at what though?  At 4K?  At 1080p?  At ray tracing?  \n\n6900xt already beat the 3090 most of the time at 1080p and 1440p.  But at 4K or ray tracing the 3090 ran away.  I can‚Äôt imagine a minor clock bump changes that much at all.",
      "Can‚Äôt argue with that. What‚Äôs crazy though, is even though it‚Äôs fully ray traced, it still runs better than most of the half assed implementations."
    ]
  },
  {
    "brand": "amd",
    "generation": "6000",
    "tier": "mid",
    "matched_keywords": [
      "6750xt",
      "6650xt"
    ],
    "title": "AMD launches Radeon RX 6950XT, 6750XT and 6650XT graphics cards - VideoCardz.com",
    "selftext": "",
    "comments": [
      "Another difference is the price tag, but not in a favorable way..\n\nNotice how none of those charts AMD made actually compare against their predecessors?",
      "But where is the difference other than power draw and slightly more memory bandwidth?",
      "6650 xt for $400 and the 6750XT for $550\n\nLMAO.\n\nTHis means the 7700xt will be $550.\n\nThe 5700xt was $400 ffs.",
      "My 5700 non xt was 329 before tax. FFS. A full PCIE 4.0 16x card with 8 Gigs of VRAM that could drive anything at 1080p and most games easily at a 1440p. Compared to 2021 / 22 pricing, it seems almost insane.",
      "Its quite telling they are not comparing it to the regular 6600XT, 6700XT and 6900XT because the uplift is probably 5% at most and would make the price incease compared to the models that launched over a year ago comical.\n\nWe're probably in for a trashing in the reviews once the embargo lifts in a few hours.",
      "Sadly yes",
      "well ofc there's msrp bump, why wouldn't it be. That was whole point entire time. 18Gbps memory is barely more expensive - otherwise they wouldn't be putting it on RX 6500 XT.",
      "The MSRP reflects that AMD is in their position to keep increasing margins and milk the desperate consumers a bit more.\n\nAMD keeps pulling one highest profit year after another. Production costs increases are negligible, especially third year on the same GDDR, the same core fabrication which got cheaper with long ago not being the cutting edge node, and with yields continuously improving.\n\nThere's not a single proof manufacturing got meaningfully more expensive for AMD, inflation completely notwithstanding.",
      "Oh no, with his 6900 XT, what a nightmare.",
      "The pricing is likely reflective of what AMD views at the least medium term outlook for GPU pricing to be and they have much more data than consumers/media/etc. to work with. The rumored pricing of Intel's roughly 3060 competitor being $380 also supports similar predictions.\n\nThis means it seems like they feel that the RTX 3060 will likely stall around the $400 mark as opposed to falling down to MSRP range in the low $300s. Likewise the 3060ti will remain around the $500 mark versus falling down to the low $400s. In other words the overall downward price trend for GPUs has reached a stall point.",
      "God, why is AMD so fcking shit again? Why do companies build their reputation up for years and then say \"You know what? Let's forget about that and take the most stupid business decisions we ever could\"",
      "Buying a 5700XT for 400‚Ç¨ felt like the best purchase ever made. Strong card for comparably cheap price. I always thought it would be a stopgap for the next gen big card. Oh how wrong I was. \n\nI hope the 7700XT will be cheaper but I'd guess Nvidia is raising prices and for some reason AMD just doesn't want to compete on price.",
      "7xxx series will probably be positioned way higher performance-wise and price-wise. Only the 6950XT is probably in the same performance tier as N33, but others are higher.",
      "I wonder if they gave salary increases relative to inflation to all their workersü§î",
      "Well... as nVidia, this is just a cash grab.\n\nI'm tired of this stuff.\n\nThe prices are still a joke, even for the older models...",
      "The point is not the performance, absolutely isn‚Äôt. The ONLY point for their existence is to refresh the MSRP. No more, no less.",
      "topkek - poor AMD should launch Patreon, so people like you can give them all the money üòÇ",
      ">Don't always whine about businesses\n\nWhat's with the boot lickers in this thread trying to sympathize with a multi billion dollar corporation and defend this blatantly obvious cash grab? We all understand how businesses work, no one expects them to be a charity. If I feel like I'm getting bad value for the price I'm supposed to pay, of course I'm going to point that out.",
      "One of the best purchases I made, gamed like all hell during the pandemic, bought a 3080 at MSRP and sold the 5700xt for like a grand during the craziness",
      "The 6950 is actually up on Newegg for $1100. The cheapest 3090ti is $2000. I think it is a win simply based on being $900 cheaper for nearly the same performance."
    ]
  },
  {
    "brand": "amd",
    "generation": "6000",
    "tier": "mid",
    "matched_keywords": [
      "6750",
      "6750"
    ],
    "title": "It finally came! From 6750 XT to 9070...This things a beast!",
    "selftext": "",
    "comments": [
      "It released 3 days ago.. lol, it finally came!!  Grats regardless.",
      "It‚Äôs nearly twice as powerful. \n\nhttps://www.techpowerup.com/gpu-specs/radeon-rx-6750-xt.c3879",
      "I have a 9070 on the way to replace my 6700XT, pretty stoked.",
      "I'll pass for now, 2 years of waiting - RTX 50-series is a scam and RX 9070 is 750‚Ç¨ at the cheapest. I'm not paying that much for a midrange card - the shit is going too far.",
      "Op has some connections",
      "Lol, I was in a panic for the majority of the day yesterday because I'd heard of people having their orders cancelled from other stores and mine had said \"order confirmed\" since Thursday but it finally shipped yesterday evening and then came early this morning. \n\nFeels good to have it here now safe üòÇ",
      "Yea I dont think people realize 70 tier cards from AMD are now $600+. Yea these are fine cards but mid range cards going up in price means the 80 and 90 tier will also go up in price.\n\nThis is what normalization is when it appears most people are generally happy with a product and the price just because the alternative has just gotten so shitty.",
      "Don't worry dude, you're lucky getting that even haha.\n\nI was thinking about an XT at first and the site crashed where I was browsing and then when it came back up the prices had changed to ¬£539 for the 9070 (only ¬£10 more than before) but the 9070 XT had gone from ¬£569 to ¬£629 which is way too much and apparently that's going to be the new MSRP. Which imo makes the 9070 the better value card since it gets within 10fps on average of the XT and is ¬£100 less almost.\n\nIt's very close to the XT, only \\~11% difference. \n\nEither way it's a massive upgrade from a 6700 XT, you'll be pleased, trust me.",
      "Yeah as u/xxxxwowxxxx said, it's almost twice as fast in raster but WAAAYYYY better than it in RT.\n\nAfter a bit of testing and playing around it wipes the floor with my friends 4070 in the MH Wilds benchmark with no upscaling/FG and settings maxed out including ray tracing. \n\nHis score was: 11782 - Average 24.76 fps - Playable\n\nMine was: 26480 - Average 78.19 fps - Excellent",
      "Night and day difference mate, which model did you get?",
      "What sort of change are you getting?",
      "Man I wish this sapphire version of 9070 could be available as msrp in my place. Love the inoffensive boxy design like this",
      "That's what I'm planning to do as well.... I currently have a 6750 which is a very nice card. The 9070 will be a very good update...",
      "Take a shot every time someone refers to their GPU as a \"beast\"",
      "I‚Äôm pretty sure they said that the 9070 XT is the strongest GPU this time around, only a 9060 is coming",
      "Got the same card. Love it! Lots a head room to tweak also.",
      "Have the exact same setup as you down to the CPU and RAM. I'm honestly kinda shocked at how efficient this 9070 Pulse is. Don't think I've seen it break 55c yet, and it's practically silent.\n\nFor a basic MSRP model (not that I got it for that...) with dual fans that's really impressive. My old Gigabyte 3060 Ti was a higher end triple fan model and it was much louder and hotter.\n\nI'm not much of a tinkerer anymore these days but it makes me wonder what kind of gains could be had with some trivial UV/OC on this model.",
      "Agree. Sapphire 9070 is so clean.",
      "Based. These past GPU prices have been a fucking ripoff. $700 used to be the price for the 80ti tier of Nvidia GPU's. The cream of the crop and now it's mid range? Absolute nonsense.",
      "It'll be somewhere near 90%-100%-ish depending on the game, resolution, and settings they're using.\n\nIf he paid the MSRP then its a real solid jump for a decent price."
    ]
  },
  {
    "brand": "amd",
    "generation": "6000",
    "tier": "mid",
    "matched_keywords": [
      "6700xt"
    ],
    "title": "This kept me from getting a 6700xt at MSRP today. My disappointment is immeasurable, and my day is ruined.",
    "selftext": "",
    "comments": [
      "I cancelled a card because of this back in January.",
      "Bruh my heart goes out to you",
      "I recommend not paying interest on a credit card just buy to computer parts. Seems like that's step 1 or 2 of financial hardship/disaster.",
      "If they only knew the pain they've caused you. They basically replied \"Sorry, not sorry... Peace.\"",
      ">\tjust have the merchant reprocess this transaction!\n\nSure! I‚Äôll just wait through the queue again and oh look at that the queue is over because they‚Äôre out of stock‚Ä¶",
      "If I could get another card with the same interest rate I probably would, too",
      "If someone fraudulently uses my debit card my money is gone, and I have to wait to get it back, if I get it back at all. If there‚Äôs a fraudulent charge on my credit card I can just dispute the charge and not lose my money.",
      "I mean‚Ä¶they borrow money from the government for almost no interest and then loan it to people and charge a lot more interest, so yeah I guess they kinda are",
      "This is the definition of getting cock blocked",
      "Oh for sure. I really just use the card for online purchases so I don‚Äôt have to use my debit card. I just want the lower interest rate for that possible rainy day when I might need to spread out a big purchase.",
      "Fucking *digital river*.",
      "I mean the Chase bank part is already sorted out since I verified it‚Äôs not fraud. I guess I could contact AMD to see if they can do anything about me not getting to buy a card ü§∑‚Äç‚ôÇÔ∏è",
      "I wonder if OP's credit card provider had a lot of charge backs to DRI, hence the flagging.\n\nThat happened to me when I was purchasing some in game goodies ($5!!) and it got blocked until I responded to the text, then I had to do it again, which resulted in a double charge.\n\nOP, that sucks. My new full AMD build is waiting for a GPU, and seeing that hurts .",
      "wait a bird blocked him?!",
      "Chase fucking sucks as a bank.",
      "Heart breaking. I know this doesn't help, but I've got two cards using my Chase account. Both were processed through PayPal though. In fact I can't remember a single PayPal charge ever get fraud denied since I've used it.",
      "Why not use debit for online purchases? Am I missing something US sepcific?",
      "It's a thing all over the world. Credit card companies typically offer $0 liability fraud protection guarantees.",
      "You never want someone with direct access to your bank account. Never use your debit card online.\n\nIt's funny. In US, banks will give you the run around when it's your money, but when it's their money (i.e. a credit card) they'll bend over backwards to solve the issue.\n\nSo, yeah, use a credit card, but pay off the amount within 25 days to not accrue interest.",
      "As far as I know the sales in Amd.com are not handled by Amd."
    ]
  },
  {
    "brand": "amd",
    "generation": "6000",
    "tier": "mid",
    "matched_keywords": [
      "6750",
      "6750"
    ],
    "title": "Finally upgraded from my 1660 super to 6750 xt ",
    "selftext": "",
    "comments": [
      "Be sure to use ddu to get rid of any nvidia drivers, deleting itself doesn‚Äôt work the way you‚Äôd think",
      "I did *almost* the exact same upgrade (1660ti Mobile > 6750XT) and I'm very happy. Nice pickup.",
      "You must use ddu to uninstall old drivers if your moving from nvidia to amd or amd to nvidia I believe",
      "Get it off the damn carpet!\n\nOtherwise, congrats",
      "DDU is a \"must have\" in any amd gpu, right?",
      "Had to make sure I rub it on the carpet for 5 minutes before installing it into my pc üòâ",
      "Yes. And you might need to use it even upgrading within the same brand, since drivers vary between generations. DDU is the safest bet basically no matter what.",
      "Went from an rtx2060 base model to an rx6700xt, absolute game changer",
      "Because the 6700xt wasnt available for me personally or more expensive \n\nAlso no idea what u mean so much power i havent seen it pull more then 180W with a 1.170 from 1.2 undevolt",
      "Just took my whole pc into the shower with me cheers üôÇ",
      "I asked around and people said get the 6750 if its similar price managed to get it for ¬£310",
      "Lol madlad... Just make sure you throw it in the shower for a few minutes too",
      "As a 1660s user I approve of this post. Nice upgrade sir. Hopefully I'll be upgrading soon too. The 1660s is a great card, but I feel it doesn't have a lot of life left.",
      "Probably the same reason I upgraded to the xfx 6800xt merc about 1.5 years ago.\n\nThe closest nvidia performance in raster would of cost at minimum about $150-$200 more and actually loses in raster and thats the 4070. The cheapest nvidia card to consistently beat mine is the 4070ti, which would of been at minimum $450-500 more than my 6800xt, and it doesn't win by double not even close. For the record I play in 4k.\n\nI paid a little over $500 for my card new.\n\nNvidia can pound sand with its current price to performance.  In the past their premium was worth it because it really wasnt much more price wise and performance was solid, that is not the case today their prices are ridiculous. \n\nThat said my card has been fantastic, no driver issues, has worked great since Ive owned it and a much better menu system with adrenaline. \n\nNvidia is finally getting around to copying adrenaline after a fair number of people shamed them for how poor their software was in comparison. They used two different very slow and old menu interfaces and rely on third party vendors for OC/undervolting tools.",
      "Good man, lots of soap. Pro tip, throw some corn meal in there. Really lubes up those contacts.",
      "Dude welcome! I just did the same thing but to 6700XT. It will change your life completely. Enjoy :)",
      "It's price and availability.\n\n\nBasically the 6700XTs stock is running dry or I would¬†say is nonexistent¬†and whatever left from the overpriced 6750XT is being sold cheaper or at the same price as the 6700XT to clear inventory.\n\n\nThat's how i got mine cheaper than the highest models of the 6700XT.",
      "In many places the 6700 isn't available anymore",
      "Unlikely according to literally all marketing data your average consumer is effectively a herd animal, or tribal in nature.\n\nPolitics, gaming consoles, marvel vs dc and on an on.\n\nYour thoughtful consumer that shops by what actual value they need/want/get are a minority. \n\nJust in these subs the majority boils down to \"no my team is better\" or \"nuh uh, your team is terrible\".\n\nAt 4k raster 6800xt is a better card than the 4070 while costing far less, the cheapest nvidia product to barely beat mine costs nearly double.\n\nLastly as someone who has been running a business for a long time now I can asure you, your average consumer basically needs their handheld just on simple things.",
      "Did the same thing went from 1660ti to 7800xt a few weeks ago, congrats ‚å®Ô∏èüñ±Ô∏è."
    ]
  },
  {
    "brand": "amd",
    "generation": "6000",
    "tier": "mid",
    "matched_keywords": [
      "6700xt"
    ],
    "title": "Couldn't be happier with this Red Devil 6700xt.",
    "selftext": "",
    "comments": [
      "I just installed a RX6700XT from XFX, the QICK 319. Looking good",
      "nice ram tho",
      "Gskillz trident royal red devil aesthetics for my ram",
      "I picked up a red devil 6750xt and I can‚Äôt wait to install it later! Officially switched over to the Red side",
      "That's Dirt Devil",
      "Meant for you to choose a colour?\nThough I agree it often looks best, it‚Äôs ‚Äúmeant‚Äù for you to do whatever you want to do with it.",
      "Fine whine",
      "Such a sexy card... I REALLY want to get a 7900 XTX Red Devil! \n\nEnjoy your card it is awesome!",
      "Eyyy same here! Its a fantastic card.",
      "still silent even overclocking",
      "I got the SWFT 309!",
      "Nice nice, my local Microcenter has one been tempted to buy one.",
      "Isn‚Äôt the red devil a vacuum?",
      "That or a Toxic 7900XTX",
      "I paired it with 5700g for the meantime.",
      "I'm very happy with mine and have no idea how many years it'll be before I want an upgrade.",
      "Dang, my red devil 6800xt whines a lot",
      "Hot",
      "Any coil whine with that card?",
      "got the exact same card yesterday, it's a beast!"
    ]
  },
  {
    "brand": "amd",
    "generation": "6000",
    "tier": "mid",
    "matched_keywords": [
      "6700xt"
    ],
    "title": "R9 5950x/6700xt",
    "selftext": "",
    "comments": [
      "Ah a fellow 5950x enjoyer. The rare unicorn cpu of the 5000 series (i \"upgraded\" to 5800x3d when it came out)",
      "Marvel movies need a high-end CPU to process everything being CGI.",
      "ah a fellow 550M Steel Legend! Gotta love the logo",
      "You built this to watch movies?",
      "I got it for a steal from a buddy also! Paid 150usd for it!",
      "I like this answer üòÇü§òüèº",
      "Good setup, the aesthetics of the fans are very well done too!",
      "Looks Sharp! Which AIO is that? How's your temps? What kind of fps do you get in your fave games?",
      "Nice fans",
      "Very nice. I‚Äôve been running that combo for a few years now and it‚Äôs awesome.",
      "Good looking build man!  I have an rx 6700xt as well.  Do you play at 1440p?  Also, are you running Plex for your movies?",
      "Love my Steel Legend board! Never had any issues with them I‚Äôve used a few of the b450 ones on other builds also",
      "Thermalright frozen infinity 360mm, temps stay around 60-65c while gaming! Around 140-150 fps on BO6 at 1440p, 75-100fps 1440p high settings with Ray Tracing on.",
      "No? But I do watch movies lol Why would I build it and not use it for movies also? I play a variety of games",
      "It could be a reverse airflow fan. Looks like a Montech and they do have a reverse fan in this style (I have some)",
      "Good to know!",
      "Correct! It‚Äôs an intake just one of montechs reverse fans",
      "Oh I reread you're comment. You're talking about gaming rather than stress test. My bad. If you run Prime95 or OCCT you will probably hit 90C. Gaming isn't nearly as stressful in terms of heat as it's lightly threaded work.",
      "Why such an overkill CPU with such a \"low\" gpu? I just bought a 6700 with a friend, and upgraded from a 7100 to 7700k (max supported)",
      "Is that bottom fan installed as an exhaust, fighting your graphics card's airflow?"
    ]
  },
  {
    "brand": "amd",
    "generation": "6000",
    "tier": "mid",
    "matched_keywords": [
      "6700xt",
      "6750xt"
    ],
    "title": "AMD Radeon RX 6750XT shows up on GFXBench website, 2% faster than RX 6700XT - VideoCardz.com",
    "selftext": "",
    "comments": [
      "Can't wait for the flood of reddit posts asking if upgrading is worth it...",
      "Hey man, I need that 2 more fps to increase my cod kd ratio!!!",
      "Hey guys, I just bought a 6700XT a week ago but the 6750XT just came out and I'm wondering if it's worth buying it, selling my old one, going through the hassle of swapping the cards, and reinstalling my drivers for one more FPS? Any help appreciated :)\n\nEdit: It's already started https://www.reddit.com/r/Amd/comments/uai72h/gpu\\_6900xt\\_vs\\_6950xt\\_opportunity/",
      "so I take it 6900xt to 6950 xt will be minor",
      "The purpose of these cards is just to change the MSRP. Just like how the 3080 12GB resets the mouth watering $699 price point.",
      "A 2% increase that will make the price 10% higher",
      "You might get the headshot in that extra frame... I'm seriously considering it. You will also have extra bragging rights about owning the 6750xt. Win - win",
      "\"lol\" said amd, \"lmao\"",
      "I mean I think the 6900xt with the oc chip will trade blows with a low end 6950xt",
      "I think they mean Navi 21 xtxh",
      "As a bonus, you'll feel validated that some random people on the internet told you that your stupid purchase was a good idea",
      "Bruh, Nvidia has been doing this for years. Super, Ti cards literally have 5% or less performance difference between. Hell, they released an entirely new 3080 sku with 2 more gigs of vram.",
      "I'd be shocked if it's only 10% more.",
      ">Bruh, Nvidia has been doing this for years. Super, Ti cards literally have 5% or less performance difference between\n\n2070 vs 2070 Super  \n2060 vs 2060 Super   \n3060 vs 3060Ti  \n3070 vs 3070Ti  \nthose are 5% differences ? They are not cause Nvidia atleast has the dignity to change the core count as well as memory speed or bus width while at it.",
      "The 3060ti, 1080ti, and 1070ti are the real stand outs from these types of cards. The 3060ti is basically a 3070 and a performance tier above the 3060, the 1070ti is basically a 1080 and the 1080ti is the GOAT and smokes the normal 1080. The 3070ti is ass not even in the same convo as 3060ti.",
      "I am a very PRO AMD but what is up with AMD coming up with slight variation of AMD GPU. Are they enabling small subset of features in the GPU just to keep their sales going and 'launching products'? \n\nWith the hype around Ryzen 7 5800x3D and its pricing close to Ryzen 9 5950x, why haven't they released Ryzen 9 5950x3D with it to put 5950x totally obsolete. Or is their excuse, \"still in research and design phase\".\n\nMy gut feeling tells me they are trying to get rid of 5950x before releasing 3D version or successor to 5000 series. Afterall, AMD is a corporation and I have strong fanboyism towards them.",
      "Honestly - I don't know what the hell people expected? 10-15% gains from tiny bit faster memory? It's just there so they don't sell different spec GPUs under same name - like nvidia likes to do. That's all there is to it. At worst - maybe it's their shoddy attempt to bump msrp. Do we know if these cards will have the same MSRP as vanilla cards? Because for sure it shouldn't be higher, if anything - same or lower, because it's end of the gen as next gen GPUs are launching this fall already.",
      "Just wait till the 6770xt it‚Äôll be a whole half a percent faster than the 6750xt",
      "Except they‚Äôre not 6nm. Still on 7",
      "AMD -20 percent faster and 20 percent more expensive 5 years later"
    ]
  },
  {
    "brand": "amd",
    "generation": "6000",
    "tier": "mid",
    "matched_keywords": [
      "6700xt"
    ],
    "title": "Repasting my first GPU I got back in 2019: the RX5700! Feat. my newer 6700XT on the left.",
    "selftext": "",
    "comments": [
      "Pray that you never learn the fear of repasting an AMD graphics card with HBM1.",
      "Its pretty loud when the fans ramp up and it can get toasty yeah. But its not really a problem for me cause I wear headphones and its only loud and hot when you oc and push it to 99%.\n\nTune the card, undervolt with a custom fan profile and a good repaste, and its a pretty capable and decently quiet card. The performance uplift of the 5700 should be massive over the 470 esp if its cheap. Worth going for imo.",
      "HBM1 is extremely fragile.",
      "Why did you repaste? Was the temps getting higher than normal? Kinda curious how long the paste lasts.",
      "What's up with HBM1 cards haha. Only know that they're faster but more expensive than GDDR.",
      "Nice mate...its msi mech 2x its the same card im using now...i dont have any problems using that card..",
      "A buddy offered me a vanilla 5700 cheap, I was thinking of getting it to upgrade my son's 470 so we can coop in Space Marine 2 lol. Is the blower noise all that bad like people said? Things like new paste and pads, I can manage just fine",
      "I bought used GameRock 3070. Its manufacturing started late 2020 (don't know when it was purchased though). Paste was dried and hotspot was ~108 C. I repasted and now hotspot is ~78 C. It's three months since repaste and hotspot is still ~78 C under hard stress. I used MX-6.\n\nEdit: checked the receipt: it was bought july 2021. So it was used less than two years and paste was dried. Let's see if MX-6 is better than the original.",
      "That's a very aggressive repaste schedule. I've used cards for 5 years straight and had no issues with thermals and did absolutely nothing to them. My server hasn't had any thermal issues and that thermal paste is going on 10 years old, but that's a CPU. Generally, you only need to repaste if you notice thermal issues, which you might have, but otherwise it's probably not necessary.",
      "I did a fury repaste and Vega 64 repaste both were fine except the Vega now is a little weird about how tight the cooler has to be after going from a blower>morpheus II>water block> blower again. The reason I went back to a blower was to shove it in a friends pc after I upgraded to a 6900xt.",
      "How much more fragile was HBM1 compared to HBM2?  I skipped the Fury cards (I bought a house in 2014 so I rode out my 7970 3GB for six years from 2011 to 2017).  I did get a Vega 64 shortly after building a Ryzen 1700 new build at launch.  I repasted my Vega a year or two ago and was really worried I'd chip/flake the HBM2 trying to clean off the old TIM.  I had heard that HBM1 was even more fragile though.",
      "Always Sapphire. They overengineer their cards to the point where they often are both cooler and have slightly higher boost clocks than the competition. I hear they have great customer service but don‚Äôt take my word for it, I‚Äôve had two Sapphire cards and never had any problems with them.\n\nThey didn‚Äôt pay me to say any of that by the way, but I will be more than happy to accept money, Sapphire‚Ä¶",
      "Now it is overheating more than before!!",
      "Oh and I forgot to mention. Has risk to it, but if you like tinkering and playing around with hardware, you can flash a 5700XT bios on it and see how much further yer silicon can go if ya want to.\n\n5700s' are capped at 1800Mhz. With the bios flash I can run it at 2000-2050ish Mhz. Adds a bit more fun to owning the card.",
      "Haha, i threw together an old parts build for my parents a few years ago, so i tossed in my old gtx285 blower card, since they didn't need a good gpu (just basic browsing and taxes, etc). Started it up, and the idle was at 80c, lol.  OG paste was brittle and dry AF.  Repaste got it down to around 50 idle.",
      "While the Sapphire is better yes, especially if they can be had at the same price point, the MSI Mech is popular for a reason. It was the first to drop to the current price point and I've not seen really anyone say anything bad about it who owns one. It's a very good card for 1440p at 120-165 fps. I'd know since I use mine every day.",
      "This can be a fun process üòÅ\n\nI remember repasting my old 1060 a few years back.",
      "my first gpu was a voodoo 2 back in 1998 I wish I still had it.",
      "The current 5700 XT I have I bought in Oct 2019. So I'm at 3.5 years now. .\n\nI never opened the card, but I did clean it of dust by blowing on it or using a thin paint brush.\n\nWith a tiny undervolt/underclock, temps are 55C core and some 70C TJunction at ~70% fan speed during max load.",
      "It's the 5700XT reference that have a loud blower fan. The non XT model's blower fan runs much quieter due to having a lower TDP. I've used the reference RX 5700 for a year and hardly noticed the fan noise."
    ]
  },
  {
    "brand": "amd",
    "generation": "6000",
    "tier": "mid",
    "matched_keywords": [
      "6700xt"
    ],
    "title": "6700xt Red Trim delete.",
    "selftext": "",
    "comments": [
      "Looks better - Looks \"factory clean\"\n\nNice job :)\n\nMaybe check if the paint does not affect/attacks the plastic, after a while (i do not know the paint)",
      "Thanks! \n\nTestors paints are made for plastics (think model airplanes or gunpla) so Im confident there will be no issues.",
      "First I was like: \"Why?\"\nBut then saw the result, looks good.",
      "Looks really clean, nice work. Wanted to black out my 6800 non-XT when I had it, but didn‚Äôt have the confidence that I‚Äôd do it right lol",
      "Used some Testors Metallic Aluminum paint to get rid of the red trim that just didn't jive with my PC. Hopefully I can figure something out for the Radeon logo.",
      "i like this kind of content",
      "Redeon logo should be red you bastard.",
      "uuu, nice.\n\nWell, if you mod your logo too, I will upvote it when I see it :)",
      "I'm restaining a cabinet with a gel stain. It's supposed to be mostly  idiot proof... Heh",
      "can't agree more. It would have looked killer with that red stripe as an ARGB strip.",
      "Lol. It's not the biggest deal.",
      ">amd radeon rx 6000 rgb tool\n\nUnfortunately the 6700xt is red only :/",
      "Looks much nicer aesthetically. I think AMD should have used an adjustable RGB led strip in their reference cards instead of their mandatory red. It would have allowed people to slightly tune the cards color scheme with the rest of their layout.",
      "Its pretty easy, Id recommend the Testors paint and some of their thinner for clean-up. Black would be even easier.",
      "unfortunately that doesn't work for the 6700xt. It's red only :/ thanks though.\n\nTool is only for 6800 and above.",
      "lol i made a post wishing i got the regular colour theme more but got roasted",
      "Thanks buddy\n\nEdit: This is just me wishing I got the midnight black card, lol.",
      "Such an uncivilized weapon.",
      "I didn't know you could change the colour! I thought it would be just lame AMD red. You just made my day, buddy!",
      ">amd radeon rx 6000 rgb tool\n\ndamn why they call it 6000 tool then so misleading :("
    ]
  },
  {
    "brand": "amd",
    "generation": "6000",
    "tier": "mid",
    "matched_keywords": [
      "6750",
      "6750"
    ],
    "title": "Amazon Deal: AMD RX 7800 XT 16GB, 6750 XT 12GB prices puts Nvidia RTX 4070, 4060 to shame",
    "selftext": "",
    "comments": [
      "Should be comparing the 7900 GRE for $550, most people forget it exists lol",
      "They're talking about the 4070 non super...Did you even read the article?",
      "So where in the UK is this price updated?",
      "Here is the breakdown if you compare a $480 7800XT against a $600 4070 Super:\n\n* 4070 Super +25% more expensive\n* 4070 Super [+14-38% faster in RT](https://www.techpowerup.com/review/nvidia-geforce-rtx-4070-super-founders-edition/35.html)\n* 4070 Super [+8% faster in aggregate gaming benchmarks](https://www.techpowerup.com/review/nvidia-geforce-rtx-4070-super-founders-edition/32.html)\n* 4070 Super [significantly faster in these common compute tasks](https://www.techpowerup.com/review/nvidia-geforce-rtx-4070-super-founders-edition/37.html)\n\n\n\nI guess it's not that clear cut. One is a better product, and there is a 25% premium for it.",
      "If you don't care about upscaling, yeah. I love the 7800xt and if DLSS isn't a factor for you it blows the 4070 super out of the water in value but it needs to be mentioned.",
      "The 6800/6800XT late adopters were the real winners if you have to make a fuss about a $480 7800XT years later.",
      "That one compares less favorably. The 4070 Super is clearly the better buy there IMO. [Deadheat in aggregate gaming](https://www.techpowerup.com/review/sapphire-radeon-rx-7900-gre-pulse/32.html), 4070S retains its clear RT/compute/feature advantage while drawing 40-60w less at just $40-50 more.",
      "> So even if I believe you (I dont)\n\nNobody cares, you literally have a nonexistent CPU in your flair, touch grass",
      "It depends, to be fair. If it's a cheap 2 vent card, then the heat and noise will destroy any positives. I know that.\n\n\n7900 gre has pretty cool stuff with not much price that is very efficient. And that makes them more attractive.\n\n\nRT stuff isn't a clear winner here, btw. 12gb hurts 4070s a lot, since you have to sacrifice something to get a decent performance.¬†\n\n\nIn short. The only clear advantage is production in CUDA specific apps (there are lots of them though). If that's important - 4070s is better. Everything else is not worth the premium here",
      "True gAmErS render at native resolutions",
      "You turn DLSS off now? With your 6900XT?",
      "Calling it an article is a reach. They're generating revenue from what is essentially an ad. I was providing more context/performance figures.  Though TIL the non super is still being sold, I thought it was discontinued.",
      "Yeah, sure, but your post isn't relative to what they're discussing...So yeah.",
      "Shame? This \"article\" is a joke. It's just a click-through affiliate ad for $15-20 of a 9-month-old GPU that wasn't even a meaningful upgrade from its predecessor. The laziness of using Nvidia's poor pricing to excuse AMD's poor pricing is so tiresome.",
      "The driver thing is a red herring.  I honestly don't know why Nvidia has been given a pass on driver issues when they've had plenty over the years. I can name quite a few I've personally experienced, even up to today. AMD drivers have been fine for a while. *Shrug*",
      "The 4070S will shortly become the new 3070. Limited by its VRAM. There are currently plenty of games that use over 12Gb at 1440P. Give it another year or two and people will be saying 12GB isn‚Äôt enough for 1440P.",
      "Hows your 9800x3d running? xD",
      "7900 GRE is better at rasterisation which is all most care about though",
      "There really aren‚Äôt any today. It‚Äôs just VRAM-crazed ranting. That why the reply is ‚Äúoff the top of his head‚Äù. The extra 4GB will surely make 16GB cards ready for 2044 and beyond.",
      "Its only my personal experience, but this has not been the case at all for me."
    ]
  },
  {
    "brand": "amd",
    "generation": "6000",
    "tier": "mid",
    "matched_keywords": [
      "6700xt"
    ],
    "title": "my all white pc v2 - 6700xt, 5900x",
    "selftext": "",
    "comments": [
      "I don't think you have enough fans",
      "Did you just spend $400 on Lian Li fans?",
      "That GPU sag is making me nervous",
      "I‚Äôve learned 2 things from this.\n1) you can actually have all things white \n2) you can actually have enough fans to allow the tower to hover and heat your room efficiently lol",
      "The primary focal point is fuck my wallet. That‚Äôs like 500 bucks for fans",
      "So glad my humongous gpu came with a support arm, I was worried about that too lol",
      "6 fans on an AIO. Ok‚Ä¶ but why",
      "when cosmetics become the primary focal point, practical, or even function deteriorate potentially significantly.",
      "I got the gpu last year when the market was still horrible",
      "Could have gotten a better gpu if you didn't spend all that money on fans. Looks clean though!!",
      "Push pull configuration",
      "Nice build but holy hell is that many fans!",
      "The case is very wide, it's effectively in the \"back panel\" cavity. See this image, it's the right hand corner. https://lian-li.com/product/pc-o11-dynamic/",
      "I think you have too many fans. It's been proven that having too many will blow through the case and be exhausted before the airflow has a chance to properly cool the components. I would lose the row above the radiator and the fans along the bottom. It is a good thing to have positive case pressure. Just my .02",
      "I don‚Äôt see a problem with his choice?",
      "And holy hell the position and direction of those fans. R.I.P airflow",
      "Not worth buying, had three of them burn themselves. So basically like most NZXT stuff",
      "6700xt, 5900x, 32 gb 3600mhz cl18 ram, 1200w psu, nzxt n7 b550, 16 al120 fans, lian li strimer plus v2 cables, lian li o11 evo, nzxt z73 white aio",
      "Humongous gpu sack",
      "3 of the fans push air through from the bottom side of the radiator, 3 fans pull air from the top side, so it improves airflow.\n\nDebatable if it's needed in any standard setup, unless you're OC'ing your chips to their limit and even then, 360mm rad should be enough (excluding extreme OC with liquid nitrogen etc)"
    ]
  },
  {
    "brand": "amd",
    "generation": "6000",
    "tier": "mid",
    "matched_keywords": [
      "6750xt",
      "6650xt"
    ],
    "title": "AMD Radeon RX 6950XT to cost $1099, RX 6750XT $549, RX 6650XT $399 - VideoCardz.com",
    "selftext": "",
    "comments": [
      "AMD marketing : 7700 XT faster than 6950 XT for only $899.",
      "Bruh this gives me no hope for next gen. It‚Äôs sucks that the low mid range segment is basically gone. No more 200-250 dollar price to performance king",
      "I'm guessing this pricing model will reflect RDNA3?",
      "Finally GPUs were dropping prices and these companies start raising MSRPs again.",
      "I'm not buying any of this crap 100%",
      "This is literally exactly what I said and predicted would happen. So many posters over the past month or two were on this tangent about how prices would return to pre-2016 levels including the MSRP's and I knew that was never going to happen.\n\nThe mfg's know that people are more than willing to pay these higher prices for these cards, and they have perfect justification for the high MSRP's. Inflation, shortages, R&D costs for the process technology, etc etc. People need to stop buying them at inflated prices in order for the prices to drop, and you cannot get enough people on board with that for that the happen. What we are seeing now with the prices dropping is about as low as its going to get IMO. + or - 10% of the MSRP's until supply is used up before the next gen release.",
      "'budget friendly mid range offer!'",
      "$400, literally same MSRP of the 3060 Ti, for a x8 lane GPU. Can't wait to see this thing be torn to shreds in the reviews.\n\n$550, price is nipping at the heels of the RX 6800, which has 20 more CUs / RAs, 4 more GB of VRAM, a 256-bit bus, and 128 MB infinity cache. With this kind of pricing structure, will AMD stop production of RX 6800s and replace it with RX 6750s?\n\nThe 6950 XT already exists - 6900 XTXH models, which are being panic-sold for less than $1100 because GPUs are available again at sane prices.\n\nI think this is even worse than the Ryzen 3000 XT refresh.",
      "Looks like the gtx980/1060 performance tier is never going to leave the 200 dollar price point. I'd kill for even 2060 performance reaching down there now.\n\nWhen it possibly comes, it's gonna be on x2 and x4 slots, so I'll still end up getting the same performance. Remember when $400 was considered the most you reasonably needed? Now, it's the bare minimum.",
      "Terrible pricing, I thought these were supposed to replace the existing cards as refreshes? \n\n**Bad AMD, bad.**",
      "overpriced for the current climate.. \n\n&#x200B;\n\npeople are cutting spending and stocks are dropping like flies today..",
      "According to leaks , they are stopping production of RX 6700XT , RX 6600XT and RX 6800 . So , the prices probably won't decrease much",
      "Here is my opinion on these prices:\n\n6950 XT at $1099 is asking a bit too much for an overclocked 6900 XT. If AMD ships the XTXH chip for all 6950 XTs it wouldn't be horrible since the premium Navi 21 cards are already more expensive than this.\n\n6750 XT at $549 is BAD, really really bad. %15 price pump would only be justified by a 15% or more increase in performance, which is highly unlikely by only adding faster memory and high clocks without core count change. At this price, the card is approaching the current 3060 Ti market price, the 6700 XT competitor. NVIDIA's feature set is superior and makes a 6750 XT at the same price look very dumb.\n\n6650 XT at $399 is fine I guess. But again, this increase in price should be justified by a proportional performance gains.\n\nAnd a reminder, these prices as shown in the posters aren't \"MSRP\", but the price of the reference models, which definitely are going to be fewer in quantity than AIB models and certainly cheaper.",
      "Was considering the 6750xt but $549 seems a little steep.  I was hoping for $500 or same $479 as the 6700xt would have been better.",
      "yeah, its a damned shame theres no budget friendly entry cards, if you want somthing \"okay\" for that price its secondhand market or nothing.\n\nYou could buy a xbox or ps5 for whats \"good\" right now and thats never been the case historically",
      "Yup - looks like budget game is dead. Unlesss.... perhaps I could interest you in YET ANOTHER sub rx580 level performance budget piece of crap with gimped specs for only 250 dollars in 2022?????",
      "Even with MSRP 6750XT‚Äôs pricing doesn‚Äôt make sense.",
      ">will AMD stop production of RX 6800s and replace it with RX 6750s?\n\nYes. \n\nhttps://www.hardwaretimes.com/amd-radeon-rx-6750xt-to-replace-the-rx-6800-lower-performance-same-price-for-better-profits-report/\n\nObviously this is just info from an inside leak, but we've no reason not to believe it.",
      "That's ridiculous. Guess I'm gonna be using a 1070 for a decade..",
      "It's the same thing as the 3070ti, 3080 12GB, and 3080ti, now the GPU has higher yields they rebrand the card for an higher price and this way they can get more money out of that silicon"
    ]
  },
  {
    "brand": "amd",
    "generation": "6000",
    "tier": "mid",
    "matched_keywords": [
      "6700xt"
    ],
    "title": "XFX Speedster SWFT309 6700XT - $329.99 ($100 Off) with Starfield Key ($69 Value)",
    "selftext": "[XFX Speedster SWFT309 AMD Radeon RX 6700XT 12GB GDDR6 PCI Express 4.0 Gaming Graphics Card Black RX-67XTYJFDR - Best Buy](https://www.bestbuy.com/site/xfx-speedster-swft309-amd-radeon-rx-6700xt-12gb-gddr6-pci-express-4-0-gaming-graphics-card-black/6513905.p?skuId=6513905)\n\n**Update:** Many people mentioned that this was actually the Premium version of Starfield. This turned out to be true. I activated my code this evening and it is Premium. This makes the savings more impressive (Provided you wanted Starfield as I did).\n\nIf you click \"Overview\" in the product details you'll see Starfield information. Puts the overall value of card at $260 new. Picked mine up today and already received Starfield code. Seems like a good deal for my 1440p comrades.",
    "comments": [
      "1440p a gimmick. Okay...",
      "Did you receive starfield premium or the base $70 version? I thought the premium version came with the 6700 and up.",
      "I'm no psychic but I think we already know the answer",
      "1440p is the literal sweet spot for gaming, it‚Äôs not too demanding and looks the best. I visually can‚Äôt see a difference between 1440p and 4K plus 4k is way too demanding for the not so much visual uplift to me. I sold my 4k monitor and went to a 3440x1440p ultrawide and it‚Äôs amazing for gaming. \n\nBoth of my friends have a 6700xt and game on a 3440x1440p ultrawide at max settings without any issues so 1440p being a gimmick is ridiculous to say.\n\nEveryone always uses cyberpunk as a benchmark and it‚Äôs ridiculous because it‚Äôs one of the most unoptimized clunky games. Plus it‚Äôs a sponsored nvidia title so of course amd will have issues with it",
      "Don't undersell it 1440p/60+ is very possible. It says 1440p on the box.",
      "6700xt gives you premium , so it‚Äôs worth $100",
      "You can also get Starfield Premium with the Radeon 6700 non-xt. Starfield Premium is $100 MSRP.\n\n[Newegg](https://www.newegg.com/xfx-radeon-rx-6700-rx-67xlkwfdv/p/N82E16814150874?Item=9SIAD2CJUE7407&nm_mc=AFC-RAN-COM&cm_mmc=afc-ran-com-_-PCPartPicker&utm_medium=affiliate&utm_campaign=afc-ran-com-_-PCPartPicker&utm_source=afc-PCPartPicker&AFFID=2558510&AFFNAME=PCPartPicker&ACRID=1&ASID=https%3a%2f%2fpcpartpicker.com%2f&ranMID=44583&ranEAID=2558510&ranSiteID=8BacdVP0GFs-.RmOPs3FZgmsicMHI7.MPQ) $269.99\n\n[Amazon](https://www.amazon.com/dp/B0BCL3L6ZG?m=ATVPDKIKX0DER&ref=psp_pc_a_ACHKWB63YKPQJ&th=1) $271.43",
      "*demo\n\nBethsoft isn't fixing anything in 6 days. (Or at all)",
      "What do you mean by gimmick?",
      "i got a sapphire 6700xt for 340 euros like 2 weeks ago on a spanish online store, we get deals like that in europe, at least in my county we do",
      "If you don‚Äôt have the hardware to play 1440p high refresh then why are you saying 1440p is a gimmick? 1440p is not that demanding by todays standards if you have the hardware capable of running it. 1440 high refresh can be had in esports games with low settings on a 1050ti at 1440p lol. No one cares about eye candy in those games anyways.\n\nIf you want to talk gimmicks RT is a total gimmick to sell rtx cards. When you get a good title that‚Äôs pre baked with lighting and screen space reflections you see how much RT is a gimmick.  \n\n4k is a waste and not worth the step over 1440p",
      "I think the reason he's getting frustrated with you is your insistence on calling 1440p a 'gimmick'. It clearly is not a gimmick, it is  a significant increase in visual quality.\n\nIf you mean you think 1440p is not worth the tradeoff in terms of loss of performance, then that is an entirely valid opinion. A gimmick however it is not.",
      "Ya I switched from 1080p 60hz to 1440p 144hz it's awesome.  I would never go 4k it's too expensive and the framerate isn't there. \nAfter that I changed to an ultrawide and I love it!\n\nI'd pick ultrawide over 4k any day of the week",
      "Comparing my 4k TV to my 1440p monitor I can't even tell much difference while gaming full res. The step up in resolution to 1440p is much more noticeable from 1080p than 1080p to 4k.",
      "Imo the reason 1440p is used is because 4k is kind of overkill at typical monitor sizes for gaming, while 1440p still being a noticeable uplift from 1080p (it's about 78% more pixels). It also isn't nearly as demanding.\n\nPersonally, I like 3440x1440 the most for gaming.",
      "I honestly don't know because I haven't activated it through AMD rewards. I just assumed it was the base version ($70).",
      "Yes this isn‚Äôt new at all. Stupid post",
      "The terms and conditions from AMD state that it'll be steam\n\nhttps://www.amdrewards.com/terms",
      "Yeah most resellers also give the game too.",
      "Yeah but that's the whole point, 1440p is a balanced reasonable middle ground. The pixel density is much higher than 1080p, without being 4x as much as 1080p therefore easier to run at high refresh rates\n\nIt allows users to have a higher resolution without completely tanking their frame rate\n\nIMO your point kind of sounds like \"the 6700 xt is just there to fill the gap between the 6600xt and 6800, it's kind of a gimmick\", when the whole point is that there is a huge gap between the two"
    ]
  },
  {
    "brand": "amd",
    "generation": "6000",
    "tier": "mid",
    "matched_keywords": [
      "6750xt",
      "6650"
    ],
    "title": "AMD Radeon RX 6950X, RX 6750XT and RX 6650 XT pictured, release date moved to May 10th - VideoCardz.com",
    "selftext": "",
    "comments": [
      "Gotta' hand it to AMD, they've really knocked it out of the park with their new reference cooler designs, I like the way these look more than most of the AIB offerings.",
      "Can‚Äôt wait to see how they get priced",
      "\"Moved\" lol. They never announced any date, videocardz just doesn't want to admit their last rumour was wrong.",
      "Indeed, Nvidia too - I'm really glad that at least the first party cards don't have any of that l33t g4m3Rz nonsense.",
      "calling $530 - 550 for the 6750X\n\nedit: called it https://videocardz.com/newz/amd-radeon-rx-6950xt-to-cost-1099-rx-6750xt-549-rx-6650xt-399",
      "I hate the fact there is no all black 6800 non-xt",
      "people who missed out on the all black 6800XT can now rejoice",
      "You have some really weird cheese graters.",
      "I'll eat my hat if it doesn't sell for at least 700 euros in Netherlands",
      "I still wish one of the aibs would just sell a reference card with no cooler and discount it by the material cost of the cooler.  As someone who has a low maintenance custom water cooling loop on my main rig, I hate that I always have to buy cards that I immediately remove the cooler from.  I prefer the reference cards because they are the easiest to find a water block for at a reasonable price. I also avoid the special edition models that already include a waterblock not just because of steep price markup that comes with such limited production run SKUs but the issues with everything from QA to likely hood of any firmware issues being addressed after launch.\n\nLet me buy a reference model without a cooler and knock a few bucks off the MSRP.\n\nI really do prefer my custom water cooling loop because it's lower maintenance than air cooling.  I just occasionally run a vacuum over my case air intakes and am good. Years back I got tired of all the enthusiast water cooling hardware and decided to copy data center water cooling by going to AutoZone for [EPDM](https://en.wikipedia.org/wiki/EPDM_rubber) rubber hoses, [crimp clamps](https://m.media-amazon.com/images/I/616u4IFDAvL._AC_SL1000_.jpg), and [gasoila thread sealant](https://www.jmesales.com/gasoila-soft-set-thread-sealants-w-ptfe) .  I just add 30% pure propylene glycol to filtered water and the coolant level never drops due to zero leaks ever. No water reservoir needed because no loss of coolant. No dye or additives and hoses are EPDM rubber so coolant never becomes fouled. Always use fittings and water blocks that are nickel plated so no chance of galvanic issues. I change the coolant every 3 years when I upgrade my system.",
      "I don't mind the edgy gamer cards (I actually think the Aorus ones look quite nice), and I think it's cool that Yeston is making some unique designs (even though none of them really appeal to me, personally), but AMD's \"Fuck you I'm a graphics card\" approach is a kind of sweet spot.  Obviously a lot of design time went into it, it's detailed, but it's still simple.  \n  \nIt's a really good middle ground, it'll work in a gamerz build, it'll work in a professional build, or you can put a solid panel over it and not feel like you're hiding something that's supposed to be attention grabbing.  \n  \nUnfortunately aesthetics matter, it's why I'll probably never get anything made by ASrock; they have good to fantastic hardware, but I don't like the way it looks.",
      "Higher clock/power limits, too. Let's see a 3GHz/21Gbps OC on a 6950XT water",
      "I got a reference 3070 (when such a task was difficult but not impossible) and I couldn't imagine why you would want to get an AIB. The reference cooler is so good and it's the cheapest version. Some of the 3070s were approaching or surpassing 3080 pricing which is just silly.",
      "They look badass with the stealth black.",
      "I mean, it's not rocket appliances.\n\n1. They'll go slightly faster.\n2. They can charge slightly more.\n3. It's fuck all engineering work to make them.",
      "At least you can get a 6800XT blackout, we can't get them at all in Australia, never have - unlikely to ever get them here either.\n\nReference navi21 cards ended Jan 2021 and haven't been seen since. AMD lied about further stock for distributors.",
      "Or just a price cut on the 6600",
      "Sucks that we can't get them in most of EU.",
      "Gonna hold out until next gen, hopefully I can get a good deal on a 7800/4070.",
      "It's a typo."
    ]
  },
  {
    "brand": "amd",
    "generation": "6000",
    "tier": "mid",
    "matched_keywords": [
      "6700xt"
    ],
    "title": "Chonky boi upgrade today Vega 56 to Asus 6700XT OC",
    "selftext": "",
    "comments": [
      "Wait, vega 56 is old already?\n\nIm crying here with my rx 580 I bought from some miner in August 2019.",
      "I got my vega 56 back around then too its not old but its a stock blower one and I really did not want to after market it. The vega architecture was good but sadly not that good",
      "Its on EBAY atm, im uk based so seeing what happens with it, it is a hairdryer tho :)",
      "Any plans to sell the 56? \n\nI was planning on building a new rig for my wife.",
      "To be honest my Rx 580 is still fine, even with 4 gb of VRam it kills everything.\n\nRecently I bought 4k screen since I moved to work from home and need 2 screens (some people did it at the start of pandemic, I just decided to take it slow :P )\n\nAnd it lags a bit but it might be because of the HDMI cable they gave me, need to replace it with Display port and see if it helps. If not then I guess it will be time for new GPU ;/",
      "I just ordered my 6700xt too! Had an vega 56 as well. Sold the 56 to a miner for 500‚Ç¨ and bought the 6700xt from an amd drop for 500‚Ç¨. Will arrive next week.",
      "So far its been good Timespy more than doubled from 6,625 to 13,355 at 1080p 144 HZ no longer do I have a small hairdryer taking off when gaming.\n\n&#x200B;\n\nGot the GPU for ¬£779.99 from Scan UK. Its marked up but it was in stock\n\n[https://imgur.com/a/Px9EwJV](https://imgur.com/a/Px9EwJV) here is the Chonky boi in the case\n\nalso shoved another 16GB of ram in while I was at it",
      "Nothing wrong with a RX580 I've had mine since April 2017",
      "well I have more than doubled the Timespy score, Overwatch is locked at a solid 144FPS now with my free sync monitor can get like 250+ if I uncap it but that's not needed. the main thing that is good now is that its no longer like standing outside an airport when gaming :D",
      "Removed the link ... i guess it was not listed about linking to Ebay even tho I checked",
      "Holy fuck! They're so big now!",
      "Current gen hardware is really something, especially the higher end. I have a NH D15 cooler on my 5900x and an EVGA 3080ti, I can't even see my motherboard (ATX).",
      "Love my Strix 6700xt! I overclocked and undervolted it, and it beats most of the 3070 benches I‚Äôve seen.",
      "Mine is up on Ebay atm, if I get ¬£300+ for it I'm happy looking at what is available right now It should go for that easy",
      "Was the upgrade truly worth it? I'm eyeballing a 6700xt and I'm coming from a Vega 56 on 1080/144. My Vega is on custom water though...",
      "Link to the page?",
      "got the wife a 3070ti which comes in a couple of days I was toying with the idea of one but I have liked AMD updates etc since I got the vega 56, and recently went to 5800x from an i7 4790k so its not too bad now, the price was over the top but got it on paypals 4 months interestifree so that will be paid before thats up",
      "aye my vega 56 was fine too, but new job and all that so why not get myself something shiny :)",
      "I love the reference vega design, soooo slick",
      "Did the same yesterday from a gtx 970 to 6700 xt"
    ]
  },
  {
    "brand": "amd",
    "generation": "6000",
    "tier": "mid",
    "matched_keywords": [
      "6700xt"
    ],
    "title": "Pretty much done. Excuse the GPU sag sigh. 6700xt with a Ryzen 7 3800x. Future hardware swap for chip and GPU. Most importantly I did it myself.",
    "selftext": "",
    "comments": [
      "In before Sag",
      "Just get some white plastic rod and cut it to length to make a support-strut.\n\nI personally use carbon fiber with a little black heat-shrink on the ends.\n\nhttps://flic.kr/p/2mgR3jv",
      "GPU sag excused üëç. But seriously that‚Äôs gna break either the card or PCIe slot on your motherboard. If it were me I wouldn‚Äôt leave it like that at all I would take the card out, grab a GPU bracket before I even use it.",
      "Looks good man! GPU sag brackets are pretty cheap on Amazon for a decent one. \n\nOther than that amazing work!\n\nOn the next iteration of your build, plan your cables on the top left a little more and it will be perfect. üëåüëè",
      "heatsinks usually have weight",
      "It doesn't have to have a serious weight. Your long-ass card is being held in the air by 2 screws and a filmsy connector that won't be a able to carry a lot of weight.",
      "More of a small gpu person. I think big gpu tend to sag despite looking nice when new. Not a serious opinion but just wanted to share.",
      "Any more I just build cube PCs so I can avoid the sag, well that and it lets me mount the motherboard upside down quite often so if there is a watercooling leak incident it is likely to miss the motherboard entirely.",
      "You can guarantee they aren't selling as many brackets as they used to ü§£",
      "Where did you get those cables... also what case is that",
      "Bad advice. This will make the air bubbles trap right at the tube interface and get frequently sucked into the tubes and at least pass through the pump.\n\nIdeal mounting would be to switch the rad with one of the horizontal fans at top of the case, but what you're proposing is worse than what OP has done. As it's in OP, the bubbles should mostly settle in the top part of the radiator and stay there, as the much lower velocity flow through the radiator won't be drag them through the rad to the bottom.",
      "your radiator is fine don't move it.",
      "If you have money to buy a brand new 6700XT, you have $10 for a GPU holder.",
      "The stupid part is that there is ZERO weight on this card. I've checked 1000 times. I just checked again as I was typing this. I can only think that I bent something when I installed. I ordered the bracket, it's on the way. Thanks",
      "Look for a GPU Support Bracket. Don't cost much. :)",
      "flip the rad it‚Äôll look much better and won‚Äôt rest the tubes on your card. Jayz2cents and gamers nexus both say as long as the pump isn‚Äôt the highest point in the loop you‚Äôre safe",
      "Good, clean build! Get yourself a GPU bracket for that sag. I have an MSI 3090 Suprim X and that shit is sooooo heavy. Cooler Master has a good one that I currently use for like $20 off Amazon.",
      "If you have a friend with a 3d printer, they can print you an adjustable anti-sag part for under 50 cents.\n\nThis is the one I use: https://www.thingiverse.com/thing:3033580",
      "Thank you!! So after looking at what you said it occurred to me that I never actually finished tucking those wires away.",
      "The cables are Lian Li strimers. I love the 24 pin into the motherboard but hate the VGA one. I'm going to play around with the bend more. The case is a basic Thermaltake. Can't remember the actual"
    ]
  },
  {
    "brand": "amd",
    "generation": "6000",
    "tier": "mid",
    "matched_keywords": [
      "6750xt",
      "6650xt"
    ],
    "title": "AMD Radeon RX 6950XT, 6750XT, 6650XT RDNA2 refresh with 18Gbps memory now expected to launch on April 20/21 - VideoCardz.com",
    "selftext": "",
    "comments": [
      "More like 1st April.",
      "These are 7nm I presume (although they could be 6nm in which case a clock bump + memory speed bump would make a reasonable refresh with +10% perf or so).\n\nN31 is 5nm GCD + 6nm MCD so they are using different nodes which means they can be built alongside each other without really impacting on capacity.\n\nFurther if N31 is the 1st RDNA 3 part and 2.5x performance is true expect a new price tier for 79xx series parts rather than a replacement of the $1,000 tier 6900XT.",
      "Why, when the 7000 series is supposedly around the corner. With a chip shortage, isn‚Äôt it better to concentrate on getting the 7000 series out?",
      "Same chip, better memory ICs, this is not a new product, but a minor refresh.",
      "tl;dr: based on AMD's behaviour over the last 7-ish years of GPU launches, AMD will service lower price points with older cards based on RDNA2. RDNA3 will only be used for premium SKUs for maybe 6-12 months.\n\n---\n\nRDNA3 will probably follow AMD's tried and tested strategy of, when they have fast products which can compete with Intel/Nvidia, only having high-end and upper-mid range products at launch. They thus use last-gen parts to service the lower-end market segments for 6-12 months. Recent examples include:\n\n* Ryzen 3000 desktop (Ryzen 2000 was lower-end))\n* Ryzen 5000 desktop (Ryzen 3000 was lower-end)\n* Ryzen 5000U (Zen 2 based APUs were lower-end, not Zen 3)\n* Ryzen 6000U (Zen 3 based APUs were lower-end, not Zen 3+)\n* Threadripper 3000 (TR 2000 and the 3950X were lower-end)\n* Radeon RX Vega series (RX 500 series was lower-end)\n* Radeon RX 5000 series (this didn't even have a top-end, and Vega and RX 500 filled in the gap until the 5600/5500 series)\n* Radeon RX 6000 series (gaps filled by RX 5000, Vega and RX 500, until the 6600 / 6500 XT launched)\n\nAMD aren't Intel; they have about a quarter of the manufacturing capacity, so aren't in a position to flood the market with SKUs top to bottom. AMD have, in fact, not done a top-to-bottom SKU launch on desktop within a launch window since maybe 2010 for CPUs (Phenom II) and 2015 for GPUs (RX 300 series). Every other launch since has either been top-heavy (e.g. Threadripper 3000) or bottom-heavy with no real flagship that can compete against Intel (e.g. 1800X and 2700X were still far slower than the i7-7700K and i7-8700K in gaming).\n\nExpect AMD's late 2022 GPU product stack to look something like this:\n\n* Titan-class prosumer card: \"Rage Fury RX Turbo\" with 2.5x the performance of the 6950 XT\n* Ultra-enthusiast: \"7990 XT\" - 2.2x the 6950 XT\n* High-end enthusiast: \"7900 XT\" - 2.0x the 6950 XT\n* Enthusiast: \"7900\" - 1.7x the 6950 XT\n* Lower enthusiast: \"7800 XT\" - 1.5x the 6950 XT\n* Upper mid: \"7800\" - 1.2x the 6950 XT\n* Mid-range: no 7700 XT at launch, just a cut-down 6950 XT\n* Lower-mid: no 7600 XT at launch, just the 6750 XT\n\nProblem is, all SKU tiers will move up in price. I'd expect the 6750 XT, for example, to be far more expensive than the 6600 XT despite filling the same relative performance tier.",
      "new gen every 2 years\\~ish?",
      "Demand is still very high for these parts, new parts are a way off (six months or more), and releasing a very slightly updated existing product doesn‚Äôt detract from anything upcoming. It‚Äôs really just ordering different memory chips.",
      "Tsmc have a certain manufacturing capacity agreed with amd. That capacity needs to be met at all times for both companies profits and future business. Rdna3 may not have been in manufacturing when these refreshes began to be made. Stopgap cards like these arent just to fill a small hole in the market but a small hole in manufacturing capacity too",
      "*excuse to raise msrps",
      "What are the \"7000 is around the corner\"expectations that I see in comments based on?",
      "Around the corner probably means at the end of the year; October or later. Plenty of demand to fill in the meantime.",
      "They are only refreshing the highest SKUs of Navi 21,22 and 23. \n\n6800XT is a cutdown Navi 21.",
      "5nm process, MCM, refinement of the architecture (RDNA3 is a bigger departure from its predecessor than RDNA2 was). Major improvement to perf/watt once again.\n\nThe 6900XT is a less than 300W card. Efficiency improvements brought by the process and the architectural changes could bring it down to 200-225W. Put two of them together thanks to MCM, and you're at 400-450W, for 2x the perf. And finally add the RDNA3 improvements and you get a 2.2x or so monster of a GPU. Really not inconceivable, it's just that years of +5% yearly by intel and +30% every couple years by Nvidia made us believe we had reached some sort of wall. That was never the case, the issue was always the lack of incentive for any of these companies to really push the envelope. Now we have AMD delivering on both CPU and GPU sides and look, intel just dropped one of the biggest performance leap in CPU perf of the past 5 years. Of course that wasn't just because of AMD, these architectures take many years to develop but it's no coincidence such a big perf jump happens when they have to defend their marketshare.\n\nNvidia Lovelace is also rumored to be a giant leap (but not quite to the level of RDNA3 because of the lack of MCM)",
      "I don't see the point.  How much extra fps does 2 more gbps give?  My 6900 xt toxic LE is already 18 gbs.\n\nEdit:  That good silicon could be put to use on next gen or bettering the 6500 xt.",
      "The 6900xt is pretty much a 6800xt with faster clocks so it makes sense why there isn‚Äôt",
      "Navi 31 is projected to be 2-2.5x the performance of the 6900 XT. There's no way the 7900 XT will be $1000 (the same MSRP as the 6900 XT) unless the 7900 XT is only about 1.2x the performance of the 6900 XT.\n\nBeing realistic, the actual 7900 XT will be about $2000. 2.5x the performance, for 2x the price...",
      "It's working for Nvidia with the 12GB 3080, 3080ti, 3070ti, and rumoured 3090ti.",
      "7900XT is enough for me, $999 only plz thanks. They have prosumer to take the higher brackets now, leave the $999 bracket for the 7900XT to pair with a Zen 4 7800X for maximum gaming.",
      "> Also pls fix ur drivers amd\n\nA tale as old as time.",
      "I have no such crashes with a 6800 xt. Their drivers have been solid, maybe try a clean install of them using DDU to remove the old."
    ]
  },
  {
    "brand": "amd",
    "generation": "6000",
    "tier": "mid",
    "matched_keywords": [
      "6750",
      "6750"
    ],
    "title": "[HUB] Lining Their Pockets: AMD Radeon RX 6750 XT Review",
    "selftext": "",
    "comments": [
      "The TLDW; Compared to the 6700xt it is 5-6% faster, uses 13% more power, and the costs 15% more.",
      "waiting for hardcore fanboys trying to justify these numbers ü§°",
      "Actually this subreddit is suprisingly full of Nvidia fanboys. It's funny when here people are saying that RTX 3060 is a better choice than RX 6600 XT / 6650 XT in the same price range, but everywhere else AMD card wins.",
      "Are you the person that writes the userbenchmark reviews?",
      "It's because this sub allows open discourse and dissent; try taking an opposite position on r/Nvidia and they'll soft ban you - you can post, but it isn't actually published unless a mod approves it - and you can't tell unless you browse reddit anonymously and notice your post isn't present.",
      "> It's funny when here people are saying that RTX 3060 is a better choice than RX 6600 XT / 6650 XT in the same price range\n\nBecause it is? Sort of.\n\n\n\nThe 3060 definitely performs slightly worse, but at the same price i'd still go for the 3060 over the 6600 XT/6650 XT due to having more vram, NVENC, better RT performance, and DLSS**. But the catch is, you cant buy them at the same price right now, checking pcpartpicker and the cheapest 3060 is $70 more than the cheapest 6600 XT.\n\nDLSS**, yes FSR 2.0 is out, and its pretty good, but the caveat is its in one title so far, DLSS is in 100+ titles today, and FSR 2.0 games will work on the 3060. Eventually this feature benefit will erode, but right now its still a feature.\n\nCurrent pricing 6600xt is better, same pricing or MSRP the 3060 is better.\n\nPS. HUB came to the same conclusion in their video on this topic, so its not clearly not just fanboys.",
      "reply concerned slave six special door public boast person oil -- mass edited with https://redact.dev/",
      "Yes, the 3070 at that price is \"highway robbery\". The AiBs who charge a $200 premium for a 2% overclock and a worse looking design are right to be criticized. And when AMD sets an MSRP that is closer to what those AiBs charge, they should receive the same criticism (EDIT: Because I know people are going to point this out, yes, Nvidia started doing the same thing, and yes, they should be criticized for it too).",
      "I honestly don't understand why people use NVENC or RT performance as an offset against worse general performance. It's just not comparable like that, people who don't care about those things don't have a reason to factor them in, and people who do care about them should be picking Nvidia regardless of some small AMD performance advantages.",
      "I am already done with this generation of cards. I dont see the point of buying a 6750 or 6950 at this point.",
      "If this card is a cash grap, than 3070 is a highway robbery: https://i.imgur.com/hIiMUsT.png Not to mention you get ~~16Gb~~ 12Gb of VRAM vs only 8Gb.\n\nIf you want slightly more performance and faster RAM and can stretch the budget for $50 more, I don't see an issue. Or else just get a 6700xt, it's an excellent GPU.",
      "It costs the same as regular 6700XT in Australia.\n\nOur prices down here are still inflated.",
      "That's not how this works, that's not how any of this works.\n\n2060 has 336 GB/s to VRAM and PCIe3 16x to RAM ( ~16GB/s ).\n\nIt's much faster as long as you stay in VRAM. The moment each frame must access system RAM to render because it can't store it locally you'll see a major performance drop as the GPU is twiddling its thumbs waiting for data from the slow system RAM.\n\nCyberpunk 2077 with RT enabled comes to mind. See: https://youtu.be/U0Ay8rMdFAg?t=643\n\nHad the 2060 been a 8GB card, you would never see that performance drop because the content in VRAM wouldn't be overflowing to the system RAM.\n\nAnd mind you, that's in 1080p. 2060 is also a 1440p card and there the problem would be even worse.\n\nMore VRAM is always good if you can have it.\n\nIt's the same principle when your system RAM is full and your CPU must access the much slower SSD/HDD storage.",
      "> 11 game average 6600xt is 45% faster\n\nReally!? I remember HUB retested 3060 vs 6600XT in 50 game benchmark recently and their conclusion is performance parity, sometimes these game benchmark gives really wack result.",
      "In Europe it's actually ‚Ç¨40 cheaper than the 6700XT",
      "offend aloof wasteful scale steep bow zonked snobbish quarrelsome berserk -- mass edited with https://redact.dev/",
      "Yea, that's not true at all. People have been putting nvidia on blast over there since the 2000 series came out.",
      "TPU has the 6600xt as only 12% faster than the 3060. Where are you getting 45% from?",
      "Maybe the 11 games he's talking about are all Assassin's Creed Valhalla",
      "because a 6700xt in my region is 500 dollars cheaper than a 3070 and 300 dollars cheaper than a 3060 ti?"
    ]
  },
  {
    "brand": "amd",
    "generation": "6000",
    "tier": "mid",
    "matched_keywords": [
      "6750",
      "6750"
    ],
    "title": "Upgraded to RX 6750 XT and 5800X from 1660Super and 3600.",
    "selftext": "",
    "comments": [
      "AMD is so much easier to work with on Linux compared to Nvidia, it's ridiculous. Enjoy!",
      "Kde üëç",
      "Darknet Diaries, I love that podcast!",
      "(Rant)  \nAfter seeing the kind of stuff Nvidia users have to deal with on Linux, I'm so glad to not be using one. I wouldn't care if Nvidia was twice as fast, I'm not subjecting myself to that nor am I going to support a company that manages to be such a pain for no other reason than to save some money on development. Not to mention their seemingly anti-open-source stance leaving a bad taste in any Linux or BSD user's mouth who ever has to deal with it, probably discouraging a decent amount of users from ever buying another Nvidia GPU. AMD and even Intel GPUs both offer far better support and Nvidia is embarrassing. \n\nThen don't even get me started on them holding people back from using Wayland with their awful drivers, causing even more trouble for users and developers who now have to spend more time to deal with Nvidia's nonsense and trying to make Wayland work properly with those GPUs.",
      "How are you liking Plasma 6 so far?",
      "KDE 6 rules!",
      "Well, 5700x was just 10-15‚Ç¨ difference and 5800x3D was 280‚Ç¨ at the time and I don't really need the performance of the 3D. I am really satisfied with the 5800x.",
      "Way less bugs and I dont have to wait 10 min on every kernel update for dracut to finish. Love it.",
      "It's really stable and smooth, I am using Xorg because I want to set saturation on my monitors manually but Wayland is also really stable and I have not encountered any bugs....",
      "Do you need support for a gpu of that size? Asking for myself",
      "AM4 POWER!",
      "I guess yeah, ‚Ç¨173.26 from [amazon.de](http://amazon.de)",
      "Not bad!\n\nDon't see many builds with a new 5800x since the 5700x and 5800x3D released.",
      "What monitor is that? I want one",
      "After upgrading to a 5800x3d and 6700xt thats probably one of the best mid range $/performance combo out right now. The 5600-5800x3d range cpu and that gpu is just so good for the money. Im sure it was a solid upgrade for you! GLHF! \n\nI also had 2 8gbx2 kits of ram too. Worked flawlessly.",
      "I have the 6750 and a 5600x, doing great at 1440p 144Hz.",
      "It's a heave boy, I think this one needs a support...",
      "Indeed, the performance is amazing!",
      "üòÖ This is a normal 24' 1080p monitor, but it looks on the photo like [LG Dualup](https://www.lg.com/us/monitors/lg-28mq780-b-dualup-monitor) because the photo is taken with 0,5x camera üòÖ",
      "Casual computing temps are 30-40¬∞, while gaming is about 70-80¬∞, depends on the game, sometimes is below 70¬∞.\n\n  \nThis temps are with PBO enabled and Curve Optimzer set to Negative with -20 magnitude."
    ]
  },
  {
    "brand": "amd",
    "generation": "6000",
    "tier": "mid",
    "matched_keywords": [
      "6700xt"
    ],
    "title": "It has been MONTHS, when is this going to end. Its not even the games fault. My older drivers never had this problem and my card is perfectly healthy in all regards. What the hell! (6700xt)",
    "selftext": "",
    "comments": [
      "Not your issue.\n\nWar thunder has been having issues with models bugging out for a couple months now... most noticeably it was tank tracks (which was fixed a few weeks ago) but some stuff in ships is still messed up since they don't care about the game mode.",
      "Its war thunder of course it's the games fault. I used to have the same issue with my intel and nvidia system back years ago.\n\nThe games known for bug regression for a reason",
      "it's a game problem for a long time now.  \nfor me it is basically fixed when i run the game in borderless window.",
      "Nah sorry bruv but that glitch is age old on WT and they give zero fucks on fixing it.",
      "Hey look, my glame glitches... let's blame it on the drivers!",
      "This could be a graphics glitch. Was there an update recently?",
      "Nah, this is definitely just a War Thunder thing, Gaijin are just terrible devs. Every time they \"fix\" 1 thing, they break 17 other things.",
      "Not playing naval, but havent seen anything like this recently while playing GRB using 22.5.1 and 6900XT.\n\nLike a month or two ago there were many graphical glitches similar to this. That time it  was the game and not hardware. All my friends on Nvidia experienced it too, maybe more than I did.",
      "That's 100% a wt bug.",
      "you have to choose \"previous drivers\" or check link if it doesnt get blocked:\n\n\nhttps://www.amd.com/en/support/previous-drivers/graphics/amd-radeon-6000-series/amd-radeon-6700-series/amd-radeon-rx-6700-xt\n\n\nI have no experience with this game but I'm running 22.3.1 (whql) on my 6800xt.\n22.4 and 22.5 had hdmi issues with my tv and 22.7 froze my pc",
      "Such a misconception.  Cards from both companies have issues at times",
      "It is not ages old, it just recently started happening and I‚Äôm on Nvidia.",
      "Sabaton simulator",
      "It's War Thunder. Every match is a new 'game'",
      "Never had a issue with amds drivers.",
      "So, did you try installing the old drivers again and see if the issue is gone or still there?\n\nNormally you have a copy of older drivers under C:\\\\AMD from where you can reinstall an older version. Or you could redownload it on the AMD website.",
      "its a common bug in wt",
      "As a long term Nvidia owner I can 100% confirm that Nvidia has bugs too.  Took them 6 months to fix VR stuttering.  Of course there was also New World bricking cards and space invader 2000 series.  Course those are just the bigger ones, Nvidia just released a hotfix driver this week for graphical artifacts in select popular first person shooters like Apex.\n\nI don't update my drivers often specifically to avoid bugs introduced by Nvidia and I don't install GeForce experience.  Then again if I were using AMD I'd do the same too.  Let other people test the new stuff.",
      "Revert to the old drivers would be my suggestion.",
      "ever since 22.5.1 I have had bad performance on multiple things. I currently reside on 22.7.1 which has been the smoothest for me all save for this game. And each time I do I click factory reset and I have even used DDU."
    ]
  },
  {
    "brand": "amd",
    "generation": "6000",
    "tier": "mid",
    "matched_keywords": [
      "6750",
      "6750"
    ],
    "title": "Anyone else annoyed that AMD removed all the reference models and replaced them with the 6750 and 6950 XT instead?",
    "selftext": "I was eager on buying the reference 6700 XT from them because it was cheaper than all the AIB models here in Canada and then poof... gone.\n\n6700 XT was around $610 and the 6750 XT is selling at $710, for what is a marginal performance boost.\n\nEdit: here in Canada only the 6750 and 6950 XT are being sold on AMD's website store, all the other cards are gone.",
    "comments": [
      "Yep, Hardware Unboxed hit it on the mark, should not have replaced existing cards, and should not have such a huge price hike (region dependent) in comparison to the paltry performance gains.\n\nAlas, the pandemic broke the mold, now AMD is following suit of the rest and just seeing what they can milk out of consumers wallets with continuing price hikes.\n\nThere is making profit, then there is this...",
      "AMD was planning to kill the reference models back in 2020 but didn't due to COVID.  I think if you want a remaining reference design, you may have less than 3 months to get one.\n\n[https://www.notebookcheck.net/It-s-all-AiBs-now-AMD-reportedly-discontinuing-production-of-Radeon-RX-6800-RX-6800-XT-RX-6900-XT-reference-design-cards.508693.0.html](https://www.notebookcheck.net/It-s-all-AiBs-now-AMD-reportedly-discontinuing-production-of-Radeon-RX-6800-RX-6800-XT-RX-6900-XT-reference-design-cards.508693.0.html)",
      "No they are worse than NVIDIA, they at least still sell their old cards even with the stupid Ti versions out you dont need to buy a 3090 ti or 3080 ti 3090s and 3080 10gs are still being made and are readily available now. \n\nAMD went a step above that and just completely nuked their non XT versions to leave these price bumped same performance versions",
      "As much as some people forget about it, companies/executives/CEOs/etc. aren‚Äôt our friends. Cash is king.",
      "The Rx 6800 and 6800 xt have also just disappeared",
      "Jeah they just pulled an \"Nvidia\" , because they are just the same. A big corporate with the ability to print money ;)",
      "Pretty much making the choice for consumers that if you don't want to spend money on expensive dGPUs but still want to game, you buy a console instead, which is fine for AMD cause it's their hardware too.",
      "> Alas, the pandemic broke the mold, now AMD is following suit of the rest and just seeing what they can milk out of consumers wallets with continuing price hikes.\n\nIt's not the pandemic though, AMD consider themselves to be a premium brand now. It's why they increased the Ryzen prices across the board by around $50 originally with Ryzen 5000, it's why they didn't ship lower end models of Ryzen CPUs because they can simply milk their customers to buy a more expensive product and it's why they continue to push out graphics cards with prices of $1000+ now. They actually believe that they're a premium brand that can charge those prices. The days of AMD being the \"cheap alternative\" to NVIDIA and Intel are over. In some ways, Intel and NVIDIA provide better value than AMD in a lot of segments now, think 12400F vs R5 5600 and RTX 3050 vs RX 6500 XT. It wasn't until Intel started shipping 12400F's and 12600KF's in droves that AMD pushed the panic button and released the 5700X and 5600.\n\nI get AMD has been successful under Lisa Su, especially architecturally, but mostly business wise. But they're leaving behind their fans that really have been dedicated to them for eons because of their value-oriented approach in the past. If AMD's not careful, a lot of their old fans might abandon them if they keep pushing prices higher and trying to milk every dollar. The Ryzen 5000 price hike was pretty sickening to me, considering that the node was super mature and the die size only very slightly increased on each product compared to Ryzen 3000. I would have bought a R5 5600X but that $50 hike and the fact they took away box coolers just showed me they were doing bean counting to make profits, rather than willing to give their customers value. And yes, I know, the box cooler sucks for products like the 5800X, but that doesn't matter, it was included in the 3800X, so why was it removed? I think purely for bean counting to take $5 off each product's margin for AMD to increase profits. But I want the box cooler in case, I dunno, my cooler has some problem I have some sort of backup, even if the thing is junk, or perhaps, my new cooler takes a while to come or if I need a bracket for AM4 to come in the mail, I can use the box cooler for a while. It's $5 to them, but that $5 translates to a lot of value for consumers.",
      "AMD: watch this magic trick!",
      "Early adopter is a bit of a stretch. It's just optimizing an existing product.",
      "I‚Äôll be honest‚Ä¶they don‚Äôt give us a shit about us, even if their marketing departments creatively make it seem so.\n\nThey say ‚Äúfor gamers‚Äù this, ‚Äúfor gamers‚Äù that, blah blah blah, but their bottom-line is money. Their executives and investors don‚Äôt care how they get the money, as long as they get it. It‚Äôs the same for any major business.\n\nDo they have a ‚Äúgamer‚Äù on the inside with a bit of soul who feels for us? Maybe, hopefully, but they didn‚Äôt get to C-suite or major investor level at those corporations without putting those feeling aside when it really mattered. They‚Äôre not going to risk their 6-7 figure salary and careers doing stuff ‚Äúfor gamers‚Äù if the rest of the execs and investors only see a monetary loss.\n\nSad‚Ä¶but, Hey Siri, play ‚ÄúThat‚Äôs how the world works‚Äù by Bo Burnham.",
      "Yep. \n\nIf you're not happy with the current price point for products, you have a great method of expressing that to companies. \n\nDon't buy their products.",
      "The thing is, \"time\" is running out. It's what? Maybe 4 months before RDNA3 and Lovelace from NVIDIA are announced. Whoever's waiting for 6950 XT prices to come down are basically wasting their time because the new cards will be basically around the corner. Waiting is a smart move, you'll only win if you wait long enough. But it's also stupid if you buy into a 6950 XT in August, only for RDNA3 to come out in September/October for around the same price. These cards should've launched like last September if they wanted to make a splash, back when NVIDIA was launching the 3080 Ti and 3070 Ti etc. The 3090 Ti was extremely late and is a completely dumb product, hell NVIDIA missed their own announcement window in January about more information because the product was so late.",
      "U do realize that going from 93fps to 98fps is more than 5% right?",
      "The only games that saw a +5% increase in that infographic were Fortnite and Far Cry 6. The 5 fps metric I stated comes as an average of all they showed. \n\nThe breakdown is as follows:\n\nVanguard: 3.1%\nF1: 3.4%\nGotG: 4.6%\nFC6: 5.5%\nDeathloop: 4.0%\nApex: 3.7%\nFortnite: 5.3%\nR6: 3.7%\n\nHardly worth the estimated $100+ price increase IMO",
      "Crypto is going down, so expect some good deals on older GPUs.",
      "What the fuck?? I was still trying to get a 6800xt.\n\nThis is extremely anti-consumer and I expected this shit from Nvidia, but never AMD. But I don't think Nvidia did this, but AMD did??\n\nedit: i'm sorry AMD, but this is the type of shit that loses market share.",
      "The price hike is awful.",
      ">Early adopters have to pay more.\n\nIt's a 2 year old product that has been refreshed with cheaper memory and faster clocks.",
      "Says someone that actually purchased a 3090 and is proud of it... lmao"
    ]
  },
  {
    "brand": "amd",
    "generation": "6000",
    "tier": "mid",
    "matched_keywords": [
      "6750",
      "6750"
    ],
    "title": "5800X3D RX 6750 XT",
    "selftext": "The last iteration of my personal build",
    "comments": [
      "Love the color scheme",
      "Pretty similar to my system.\n\nJust upgrade to 5800X3D from 3900X. My gpu is RX 6800XT and case is H510.",
      "It‚Äôs an nzxt 210i but I wouldn‚Äôt suggest it because of GPU clearance",
      "I had one, the glass shattered randomly one day, and NZXT said, \"ahhh, that sucks bro.\"\n\nAnyway, i bought a bigger case.",
      "Thank you",
      "What case is that",
      "Whoever designed this case should be shot, that GPU clearance is a travesty",
      "Nah the whole all team red bs is only for fanboys",
      "Love the red color! Hopefully you get to enjoy it. I've recently ordered a 6950XT with a 13600KF but I'm really wondering if I should have gone with an AMD CPU too.",
      "Why didn't you? Isn't the 7600x cheaper, more power efficient and faster in games? And gives access to 3d chips as well as long term support.",
      "There are some games where the performance gains can be upwards of 30% or higher, SAM it‚Äôs not a joke. The gains on AMD cards is insane.",
      "Hold up, I've seen this before... On my desk! XD\n\nhttps://www.reddit.com/r/pcmasterrace/comments/12sa707/updated_battlestation/\n\n5700G & 5700XT in mine.",
      "Beautiful colour scheme, cleanly done. But your GPU can't breathe",
      "5800X3D RX 6800 build here. My first full AMD build.",
      "Hows the GPU? Seems VERY close to the bottom shroud :D Is it getting enough air?\n\nA clean build, though.",
      "Oh cool, I upgraded this over the last few years all the way from a 3600 and 5700XT reference card. I can‚Äôt believe what this CPU is capable of sometimes and really makes my GPU shine.",
      "That's a NZXT H210",
      "Why?\nIs the 13600KF holding you back in anyway?\nThe 13600KF is a terrific cpu, and won‚Äôt need to be replaced for a long time",
      "It‚Äôs unbelievable. Major improvement over 5600x. In Escape From Tarkov it‚Äôs incomparable.",
      "I guess I'm slightly worried about the compatibility, I'm 99% sure using an AMD GPU with an Intel CPU will be perfectly fine, but still... most users with AMD GPUs usually have AMD CPUs as well. This is my first high-endish build too, so it's normal to be worried at least a bit I guess."
    ]
  },
  {
    "brand": "amd",
    "generation": "6000",
    "tier": "mid",
    "matched_keywords": [
      "6700xt"
    ],
    "title": "Out of the Box Image Quality 6700XT vs. 3070",
    "selftext": "I recently acquired 2 cards at MSRP - an EVGA 3070 FTW3 and Rog Strix 6700XT (Shout out to Memory Express in Canada). \n\nMy plan was to use them both for a couple weeks and compare decide on the card I wanted to end up keeping knowing that resale of either wouldn't be difficult.\n\nI used the 3070 for the past 2 weeks and was extremely happy with everything about the card. It looked great, ran cool and quiet and kept my frames at 240 no matter the scenario in Dota 2 @ 1440p on a 32 inch TN LG panel. (Using a DP cable).\n\nI just plugged in the 6700XT last night. I immediately did a double and triple take. I was floored by the image, I couldn't put my finger on it, but the sharpness and color, both in games and Windows made me feel like I had just got a new contact lens prescription and a new monitor at the same time. I didn't even know this was a thing until I hopped on Reddit to take a look.\n\nPurely anecdotal evidence but I came in with no knowledge that the image quality would be different on different brands - but out of the box score a BIG win for AMD.\n\nReviewers make huge deals about the software support like DLSS and Ray Tracing, but the number one job of the Graphics Card is to produce an image - and to see that one brand is clearly superior was shocking to me. I'm sure there are many variables and things that you can do to an NVIDIA setup to improve upon this gap, but it made my choice of what card to keep an easy one. I'm surprised this isn't a bigger deal in the review landscape.",
    "comments": [
      "Could be the RGB setting (limited/full) or something similar.",
      "I have both a 3090 and a 6900. I notice no appreciable difference.",
      "* Your monitor uses a TN panel. Most TN panels have banding issues and require dithering for smooth color transition. AMD enables dithering by default, [Nvidia requires a registry tweak](https://old.reddit.com/r/nvidia/comments/aghfqk/dithering_can_now_be_enabled_via_registry_tweak/)\n\n* AMD driver's default settings has slightly higher saturation than Nvidia \n\n* People are way overthinking this",
      "I had a 5600 XT and now I have a 2070 Super, same display, same cables, same everything. I see no difference either.",
      "I got a 1060 and my gf has a 5500xt. Her image looks better, but I thought that was just differences in monitors or image sharpening maybe? But I've heard people talking about this long before AMD implemented RIS, so I have no clue",
      "Depending on the connecting he's using, this is probably it... I've had many AMD GPUs on the past, as well as Nvidia ones and now I mostly use Nvidia cards and when I connect displays through HDMI in a Nvidia card it defaults to a worse color config everytime, and I have to set it manually on the Nvidia Control Panel...\n\nAfter setting it up, the image quality is the same as AMD when compared on the same display, IMO",
      "washed out colors and blurry image on nvidia back in the days it was said that AMD had fulll RGB color support while nvidia had only limited RGB support that you needed to tweek manually but has not been the case since i belive 1000 series. There was another theory that AMD gives you full 10bit color on the card while Nvidia uses 8-bit and keeps their 10bit for their quadro range or something. Another quess was that nvidia has been using compression to save on memory so maybe that. Maybe it's all of them combiined all i know is AMD gpus put out a more pleasing image for my eyes while Nvidias looks like everything has color washed right out.",
      "Since they are taking about \"out of the box experience\", I don't think they are overthinking it.",
      "This.\n\nI've had both AMD and nVidia and I've never seen a diference in image quality. But recently I connected my monitor through HDMI and it looked pretty bad, then I found out it was defaulting to limited RGB. Changing it back tu full RGB fixed it.",
      "Nvidia claims that it doesn't affect image quality, and because Nvidia would never tell a lie you sir are a scoundrel.",
      "AMD doesn't compress textures the same way, the same image will require more bandwidth and a larger footprint in vram. This is measurable but reviewers don't talk about it much. Nvidia says that memory compression doesn't affect image quality, so I guess this whole post is a figment of my imagination. \n\nScroll to the bottom, it started with Pascal and got more aggressive in Turing:\n\nhttps://www.anandtech.com/show/13282/nvidia-turing-architecture-deep-dive/8",
      "I am not an engineer nor I have studied anything in the direction  \nof GPU architectures.  \nSome time ago someone explained it and the essence is, that  \nAMD/Radeon manages the data a bit different and doesn't  \ncompress the shit out of it.  \nThe result is a better picture.",
      "When you use lossless compression - you don't lose anything. That is what both AMD and Nvidia use in their vram compression.\n\nThese posts about image quality being different tend to come from users that don't install the proper color calibrated profile for their monitor - when doing the driver swap, the resulting image might look wrong.\n\nOr have another setting enabled/disabled that affects it.\n\nThere have been multiple articles written about this - at this point in time, you will have the exact same experience at least on the desktop with a properly calibrated/setup monitor.\n\nObviously ingame, with dlss etc. things will differ.",
      "Good post!\n\nThis was evident 20 years ago, as well, believe it or not.  It was plain to see even then.  It goes all the way back to when 3dfx introduced FSAA to the industry--no one else had it, including nVidia.   Right after 3dfx imploded, ATi came on the scene from literally nowhere with the darkhorse ArtX acquisition GPU, R300, and the GPU did FSAA & general image quality so much better than nVidia that *of course nVidia criticized it heavily* for a couple of years until it could begin to field competitive FSAA GPUs to compete with R300 and beyond.  Despite nVidia's adamant protestations at the time, FSAA became a staple in the industry and is a checkbox feature today for all 3d GPUs, including nVidia's. \n\n nVidia has always been a company absolutely obsessed with frame-rate benchmarks to the exclusion of the best image quality possible.  Considering the number of people who aren't very demanding about their image quality, that approach has sold a ton of GPUs for nVidia.  But you are right--and you aren't the first to have noticed what is often the stark difference between the competing families of GPUs.\n\nIf you care about your image quality, imo, and it's as important to you as frame rates, or even more important (that's me),  you are going to go with AMD.  DLSS is really sort of amusing to me...;)  I game at 4k with a 5700XT (which I will be keeping until I can land a 6800XT at MSRP, and so that might be a long time to come...;))  Anyway, if I want \"DLSS\" I just drop the res to 1440P, pour on the FSAA to a desirable degree--and I'm there...;)  Frame rates go up appreciably and the image quality is but a tad lower than native 4k.  RayTracing?  It is 100% optional in all of the tiny number of games that support it--and many people don't really understand that when you use ray-traced shadows and/or reflections in a given scene/frame, and even ray-trace a few object surfaces, *maybe as much 95% of everything else* rendered on the screen *is still rasterized*, anyway! For instance--every object in every scene is rasterized--none are fully ray traced.  None.    \n\nI don't have anything against DLSS or D3d ray tracing...but as you say, how many game reviewers ever bother to go that deep into the differences between D3d ray-tracing and the kind of ray-tracing special-effects companies rely on for movie production, in programs like Lightwave, for instance?  I cannot think of a single one who really understands the enormous differences.   The differences are *vast*.  But that's OK--D3d RT is what it is.  What's not OK is the idea that D3d RT'ing is *a lot more* than what  it actually is...;)\n\nSo in the final analysis, all of these perceived differences boil down to marketing hyperbole--but you know, it's all in the eye of the beholder in terms of DLSS and D3d RT'ing.  Shown the same exact frames, one guy will opine on how he has never seen anything quite so beautiful, while another will say, \"Meh!  I prefer to turn those features off, myself.\"  \n\nBut in terms of general IQ--comparing the two GPUs on the same monitor in the same games with the same settings on the same desktop--is about as clear as it gets!  Yep, the win is definitely AMD's.",
      "I had a similar experience switching from a 1080 to a 6900xt, something about the image from the amd card is just better and I can't really put my finger on it, obviously the performance is miles better in my case too but even in low motion scenes like just walking around the city in cyberpunk the amd card just made it look more like the trailer than the actual gameplay I got from the 1080",
      "i can't for the life of me find the damn video.. but there was a diagnostic tool for HDMI output bandwidth that measured what was ACTUALLY being sent from the device to the display. And the reason the test was initially conducted was to determine what the problem was with the cables and the display problems to explain them. Coincidentally the person conducting the test was using set top boxes and got a bit curious about graphics cards. Suffice it to say, they discovered that nvidia's hdmi bitrate being spat out to the displays was lower than what AMD's cards were doing which raised a few questions as well as explained why some of the cables were working fine on nvidia's cards while having issues on amd's. 144hz display requiring more data, but nvidia somehow managing to spit out less data while producing the \"same\" refresh rates at the same resolution while AMD was requiring more and resulting in a bad cable producing blanking/flicker/multiple hand shakes or failing to even produce a signal (black screening even). Replacement of the cable with a better own would resolve AMD's issue.\n\n&#x200B;\n\nGranted it's merely a variable. But there is consistently a difference in colour and clarity between the 2 products and always has been. Since the days of the TNT, and nvidia's introduction of Digital Vibrance to combat their lack of shall we say, colour accuracy, kinda like nvidia was stuck with a \"slightly washed out appearance\" is still today a common statement from people.\n\n&#x200B;\n\nColour profiles are irrelevant if nothing was setup to begin with and simply attaching one card to the display and another even at the same time (in the case of a highend tv for example) and swapping between both or doing side by side you can CLEARLY see there is differences even at the desktop level.\n\n&#x200B;\n\nNvidia often opts to go with a limited range via hdmi, 16-255 rather than amd's default 0-255. Manually changing this in the nvidia control panel can/will help but it still doesn't quite match the output amd delivers.\n\n&#x200B;\n\nIt's rather strange to be honest. It's certainly not placebo as you get enough customers in which a swap too or from one or the other gets the common utterances when i call in or they do about the displayed image colour/quality differences.\n\n&#x200B;\n\nI've sold an nvidia user and AMD product and they occasionally report that the display looks richer but they can't put their finger on it, and in the opposite case, i sometimes get a complaint from a user that has bought an nvidia card to replace their amd about the display looking washed out somewhat (to which i point to digital vibrance and while it does help, it doesn't usually look right to them)\n\n&#x200B;\n\nMeanwhile we see posts on even this subreddit from users asking where AMD's \"digital vibrance\" is and i can't help but laugh a bit.\n\n&#x200B;\n\nIn terms of texture quality and such, AMD certainly tends to have and historically always has had the lead in that, not to mention other effects, Nvidia's often touted frame rate leads can be traced back to things they've done in the past that were proven to be short cuts or optimizations that have impacted visuals either significantly (easily called out), or rather difficult but once compared fairly obvious.\n\n&#x200B;\n\nI owned a 3080 before getting a 6800xt.... i tried out DLSS and RT and then had the opertunity to compare it to the 6800xt. Honestly no matter how much calibrating i did on the nvidia card, i could never get quite that pop that AMD's cards consistently deliver out of the box every time. I REFUSE to adjust my displays colours and settings to make a video card spit out an image that's comparible, as calibrating the display for nvidia's cards buggers up the other devices and settings i may already have configured. I only had the card for a week and a bit roughly before i dumped it, as i wanted to see how DLSS mostly did and personally seeing the trash it produced on a 65\" 4k display made it completely irrelevant and grossly overhyped. Maybe DLSS3.0 might fix it's glaring problems but it's most definitely not a selling point for me. I'm perfectly happy with a 6800xt spitting out 90-120FPS @ 4k in most of the games i play (or higher).",
      "Back in the day, early 2000's, reviews used to rate 'image quality' and ATi regularly won out by a healthy margin. Rocking a Nvidia card usually led to more washed-out colors and everything looking a bit drab and not as sharp. Never understood why but perhaps that's still the case? I've never done a back to back but I wouldn't be surprised if it was still the case.\n\nI mean, some people have TN monitors and think their colors and image look great. A LOT of people wouldn't be bothered by a slight lowering in image quality for higher performance",
      "Nvidia compresses colors to make up for sloppy optimization. That's why AMD cards have better IQ.",
      "I'm not sure either, but how things look out of the box is important. Might be worth flipping monitors to see but I suspect the difference is in the cards.",
      "It's because amd applies temporal dithering by default on everything while nvidia does not, on windows (works for linux on nvidia)\n\nThe excuse nvidia uses is \"compression is ok as long as the graphics card run faster\"' or something along these lines.  \n\n\nSearch google for nvidia/amd dithering and the same picture quality difference threads will pop up by dozens."
    ]
  },
  {
    "brand": "amd",
    "generation": "6000",
    "tier": "mid",
    "matched_keywords": [
      "6650xt"
    ],
    "title": "AMD reportedly halts production of Radeon RX 6650XT, expected to be sold out in China by end of September - VideoCardz.com",
    "selftext": "",
    "comments": [
      "Yep, why shouldn't they lol.\n\nIts fine for 7600 to take over that segment.\n\nIf you really want a 6650xt grab it now, maybe as a backup card or for a budget build. You get a Starfield code with it too.",
      "If the rest of the market follows suit like MicroCenter, bringing down 7600 to $230, I think that'd be the no brainer",
      "The problem they have is that they overproduced RDNA 2 graphics cards during the cryptocurrency bubble and a lot of the cards were being bought up and hoarded by miners. Once the cryptocurrency bubble burst, the used market was flooded with used cards and retailers have to get rid of any stock they have.",
      "Most likely price drops once they get rid of the old inventory.",
      "I find it odd that they continue to produce RDNA2 cards with clear RDNA3 replacements. Don‚Äôt they want to sell their new stuff?",
      "From a general business perspective, it is actually quite difficult (and even expensive at times) to make immediate short-term changes. For example, it is hard for a business to immediately lay off many individuals, make last-minute changes to inventory orders, alter contracts, etc. \n\nAMD might have been slowing it down all this time, and ceasing altogether now/soon as per the rumour. \n\nAlso have to consider: AMD doesn't want to compete with themselves for this segment. Basically, AMD would rather have both cards sell than just people buying 7600s and leaving a large inventory of 6650 xts, or vice versa. People want to buy whatever is the best value. If the 7600 is worse value, it won't sell as well. Hence, AMD wants the 6000 series cards to finish selling.\n\nSome people believe this is why lower segment cards have taken so long to arrive. Of course they want to sell the new stuff, but it may be inconvenient for them.",
      "Yep. You can also get a 6700XT and OC it to match the 6750 XT.",
      "Just get the cheapest 6700XT/6750XT you can get. They're all the same card pretty much. You can get pretty much same performance out of a 6700XT.",
      "Because for mid-range cards they probably want more sales numbers.",
      "Did you read what I said?",
      "does it come with that on a 6750 XT cuz I wanna get one of those",
      "How dare a company stop producing an old product in favor of a new one!",
      "Considering how bad graphics card pricing right now, I don't think a shortage will happen anytime. Especially those 4060s are low demand and overflowing with stock everywhere.",
      "Uh it's a lot worse actually. Slower GPU, slower memory, less memory. There's even a whole SKU between them, the 6700 10GB.",
      "The 7600 is better by 5% more or less. Passmark isn't a reliable benchmark for GPUs because it is more a measure of compute performance. R9 390 scores higher than RX 580 for example.\n\nThe price you listed is still high though, but that's just how it is, some regions have it better, some worse.",
      "To increase sales?",
      "What? You're telling me they've kept production going up to now? I thought they would have stopped months before the 7600 dropped.",
      ">Or just for the Starfield bundle tbh, good value way to get a copy\n\n  \nNote that you need at least the RX 6700 to get premium version ($99). 6650 & 6600 get standard ($69)",
      "Perhaps the chips were just in inventory. The boards were still being manufactured though.",
      "Why would they drop the price if the main competitor of rx7600 is their last gen's products."
    ]
  },
  {
    "brand": "amd",
    "generation": "6000",
    "tier": "mid",
    "matched_keywords": [
      "6700xt"
    ],
    "title": "Repasting Reference RX 6700XT with PTM7950, before and after",
    "selftext": "",
    "comments": [
      "Frame rate stability tightened up to 99.5%. Waiting on my sheet to arrive this week for my nitro 6700 xt, hotspot temps are around 87c with Mx6 applied.",
      "Had 30¬∞ Delta before on my 6800 xt red devil, like 68¬∞ GPU Temp and 95-98¬∞ Hotspot, switched to PTM7950 and now my temps range between 10-20 and the temps in general are down 5-8¬∞ so it was worth it for me.",
      "6750xt ptm7950 repaster here. I absolutely can confirm. Good job. Welcome to the club.",
      "Seems accurate. Lower delta and better temps than thermal paste.",
      "13 degrees lower CPU temp.",
      "Its underrated on benchmarks how important this stat is along with %1 lows. Its ok to play at 40fps flat rather than 60 that goes back and forth to 30's for exampel",
      "Good results. I was thinking of getting some for my 6700XT since my delta is 25¬∞, with the hotspot being 98-101¬∞ in very demanding loads... Quite toasty",
      "Did you replace the termal pads as well? I'm thinking about repasting mine but I'm worried that the pads gonna break and I'll have to replace them.",
      "There's only one legit PTM7950 thickness, can't remember which one it is right now but you can get it from moddiy.\nEDIT: 0.25mm is the correct thickness. Anything else is fake.",
      "It's meant to be applied by screen printing machines (hence \"SP\"). It has a solvent to keep it liquid at room temp, but you are supposed to let it completely evaporate before mounting the cooler. Ideal thickness is \\~0.3mm, and they recommend 15 hours at room temp. The thicker the application, the longer it takes to evaporate.\n\nI wouldn't recommend the paste version.",
      "TG-PP10 is good stuff, but there's even better and cheaper putties these days. Here's some VRAM thermal testing from Snarks Domain, mining with a 3070Ti (GDDR6X) : https://drive.google.com/file/d/1pVga9tnnxTEf1-kJZzaUPgd9WGn6eaqI/view",
      "Where do you guys buy  ptm7950?",
      "Did this on my 7900xt, significantly dropped my hotspot temps. And i bought mine off Amazon so who knows if it is legit ptm but still happy!",
      "No I didn't. I moved them back in place a little. No further issues.\n\nExchanging that would have been to complicated (different thickness) and expensive for me.",
      "I have my ref 6700xt underclocked but still gets hot under load. Might be doing this soon",
      "I‚Äôve been building for almost 15 years, but earlier this year was the first time I ever repasted a GPU. Gotta say my results were incredible. Highly recommend for anyone who is having trouble with hotspot temps.",
      "Please update us, mx6 user here",
      "I would try undervolt from 1.200v to 1.120v. From 90c to 80c hotspot in my case.",
      "doesn't that messier than normal paste? Wonder if you need to freeze a bit too",
      "Don't bother... warranty won't do anything, because hotspot up to 110¬∞C are normal/ expected...thermal paste pump out is an issue, so open it and slap a ptm on it and be done..."
    ]
  },
  {
    "brand": "amd",
    "generation": "6000",
    "tier": "mid",
    "matched_keywords": [
      "6700xt"
    ],
    "title": "Small upgrade. Was it worth it? [6700XT]",
    "selftext": "",
    "comments": [
      "Now change the cpu maybe a 5800X3D üòÑ",
      "If you want to buy a new mainboard I would by a AM5 board with the new 3d series in february",
      "Hmm... 6600 - 5450  \nThat's only 1150 better. Mine is a 6440 improvement. Definitely a smaller upgrade.",
      "Was my smaller upgrade from a HD5450 to a RX6600 worth it?",
      "That's the plan. 5800X3D and a new mobo to have all features. I'm waiting to see if I can get it on a sale.",
      ">HD5450  \n\nbruh that's like a cellphone processor from 2015 lol",
      "Indeed, either that or simply a 5600 cpu upgrade while keeping the same motherboard",
      "Deleted by user, check r/RedditAlternatives -- mass edited with redact.dev",
      "But I would be paying full price for that plus I would need new RAM.",
      "SAM was been allowed via BIOS updates on all AM4 boards, including X/B/A 300 boards as well.\n\nSAM works on Zen+ or newer and officially on Intel 10th gen or newer (though there have been reports of working on previous Intel gens). It definitely does not work on Zen1 tho.",
      ">Was it worth it? \\[6700XT\\]\n\nLemme werk it. I put my thang down, flip it and reverrrse it.",
      "It's badly limited right now. I'm gonna upgrade to a 1440p 144hz monitor . Currently on a 15yr old 1080p60hz display. Everything is holding it back. It's chilling right now.",
      "It‚Äôs possible you‚Äôd need new ram anyways. I used to run the 3000 series which was unstable without 3200mhz + ram. I‚Äôm not sure if the 5000 series is the same as I‚Äôve now got 3600mhz with the 5800x. The new processors are such an unnecessary expense right now. New processor, new ram which is overpriced, new motherboards which are also overpriced. Upgrading to the 5800x3d would be a better option and just sell your ram and get 3600mhz",
      "Hell even a 5600 or 5700 would be a huge upgrade.",
      "Just buy the cpu first. If you're satisfied then, you won't need to buy a new mobo, but if you're not satisfied then a new mobo it is.",
      "what resolution are u at with that ryzen 1700? i think u would be limiting this beautifull card at 1080p",
      "Just get a 5600 and wait until next year for a full upgrade.",
      "just get a 5800x3d with no other upgrades. 3000mhz ram is fine, b350 is fine.",
      "I see you‚Äôre on a ryzen 7 1700, you could just do a BIOS update and make any of the latest AM4 processors including the 5800x3d work. That‚Äôs your cheapest route. If you plan on upgrading to a different motherboard you might as well move on to AM5. If you got microcenters close to you, they are giving out free 32GB DDR5 kit of ram with the purchase of an AM5 CPU, and $20 off a compatible mobo. Good luck!",
      "You made a bigger jump than OP with 260X to 6700 XT, lol."
    ]
  },
  {
    "brand": "amd",
    "generation": "6000",
    "tier": "mid",
    "matched_keywords": [
      "6700xt"
    ],
    "title": "price for 6700xt",
    "selftext": "this guy listed his used 6700xt for 225 in my area should i jump on it now, or is it just an ok deal.",
    "comments": [
      "6700xt is about 30% faster, but if need Nvidia features such as DLSS or video editing, the 3060 is the better GPU. Both come with 12gb of VRAM variants.",
      "It's a fine deal imo",
      "Yes, it‚Äôs a good deal for $225.",
      "Great deal, snag it.",
      "Pretty good.  I would definitely consider a 2080ti though, which gets dlss transformer while the 6700xt is not getting fsr4.  Definitely a bit faster of a card.",
      "Great deal, but test it with a steel nomad run using 3d mark demo",
      "I just bought an asrock challenger dual fan 6700xt for 250, so not bad",
      "That is a steal if it's working correctly. Avg price is 3-350",
      "It's an ok deal. RX 6800 a year ago-18 months, were retail 333-350, and 6700XT/6750XT less than 300(260-280).¬†\n\n\nTake pre-owned factor over the course of time, and age of the GPU tech, a 6700XT 12GB should be 175, and not over 200.",
      "6700xts used have never been under 200 dollars.",
      "200 tops imo, but what's an extra 25 just to get a GPU if don't need Nvidia features. Else would say 3060 12gb for less only if needing the features.",
      "what‚Äôs the performance difference between a 3060 and 6700xt?",
      "6700xt is faster",
      "Quite alot. 3060 has 8gb (I think)of vram and as such is slowly fading as being usable.¬†\n\n\nThe 6700xt can max out most games at 1440p",
      "If you are just using it for gaming and nothing else, the 6700xt is probably the better choice. If you will be using your GPU for content creation, video editing, productivity or machine learning/ai, etc., then the 3060 is objectively the much better choice. Of the two, I think the 3060 is the better GPU for most people.",
      "The RTX 3060 has 12gb of gddr6 vram over a 192-bit bus with a bandwidth of 360 GB/s, per techpowerup.",
      "no. The 3060 has (or had, it seems they stopped making the 8gb) the 3060 12gb has 12gb",
      "Fair enough, as they did have 5 different versions of the 3060, all with different configurations, though the 12gb model on the GA106 is much more common than the other 4 versions, two of which were 8gb models, at least here in the States. It looks like the 8gb models were released in the fall of 2022, nearly two years after the 12gb models which were released in early 2021. There was also a 6gb model released in 2021 with the fully unlocked GA106 utilizing all 3840 shaders of the GA106, according to techpowerup. I think it‚Äôs fair to say, though, at least here in the USA, that the 12gb model on the GA106 with a 192-bit bus and 48 ROP is the most common model, and it‚Äôs what most people are going to think of when you refer to the 3060. However, it would behoove the consumer to ensure they are getting either of the 12gb versions."
    ]
  },
  {
    "brand": "amd",
    "generation": "6000",
    "tier": "mid",
    "matched_keywords": [
      "6700xt"
    ],
    "title": "Went Full AMD! Upgraded from an i7 6700k & 1060 6GB to a R5 5600 & 6700XT",
    "selftext": "",
    "comments": [
      "Tried to go for a teal and purple aesthetic. Huge performance uplift from my system I built 6 years ago.\n\nProud of the cable management to keep it neat and tidy, used USB3 header extensions and daisy chaining fan cables to tuck everything in the back chamber.\n\nStill considering if I want to use a vertical GPU mount as apparently airflow would be better in that scenario where i'm pulling air from the bottom and side and exhausting at the top.  \n\n\nSpecs:  \nCPU : Ryzen 5 5600  \nGPU : Sapphire 6700XT Pulse  \nMOBO: B550 Aorus Eilte AX v2  \nSSD: Samsung 980 m.2 500GB + PNY 500GB SSD  \nRAM: Klevv Cras X 16gb 3600mhz CL18  \nPSU: EVGA Supernova 750 G2  \nCPU AIO: NZXT Kraken X61  \nCASE: Tecware VXC",
      "welcome on the good side dude",
      "Thank you! Can't wait for the new AMD product line up! Kinda bummed I got in on AM4 so late as my old PC suddenly died but I can still upgrade to a 5800x3D in the future or sell the whole system and upgrade to AM5. Here's to hoping for a good future and prices for hardware \\*fingers crossed\\*",
      "Welcome to Red team and to the 6700 XT gang !",
      "It's a Tecware VXC, I didn't want something too big and I like the easy hinged panel design and the dimensions fit right for me for an ATX board.\n\nCase does not come with any fans.\n\nI recommend the LianLi O11 mini if you want a similar case but higher quality and more flexibility. Granted the price I paid was 1/3 of that so... Yeah, also my PSU couldn't fit you need an SFX or SFX - L to fit that case.",
      "I recommend TechPowerUp for GPU comparisons.\n\nFor example:\n\nhttps://www.techpowerup.com/gpu-specs/geforce-gtx-1060-6-gb.c2862\n\nAccording to the relative performance chart, the 6700 XT is 140% faster than the 1060 6GB.",
      "Cant say exactly since I transplanted some parts from my old build but I would say total value for both the new hardware and equivalent things I transplanted new would be around $SGD 1500 or about $USD 1000 at current exchange rates :)",
      "Very nice, I ended up with an AMD cpu and nV gpu but this most recent 4xxx release has me doubting nvidia wants to continue competing in the gaming space. Hope AMD lays the smack down this gen",
      "Sry for dumb question, what is this case? looks sick.  \n\n\ndo these cooling fans come with it?",
      "That's the same combo I have! Was able to play anything smooth as butter at 1440p.I don't have an aio unfortunately though I'm trying to get a new case that can fit one.",
      "Was a little worried about replacing AMD with AMD cause my 5700xt had a lot of black screen crashes until I reflashed the memory timings with Apple straps. There was always an issue to solve. Got a 6700xt for 150 after selling my 5700xt. It's amazing, cooler, more frames, everything runs flawless.",
      "How much did it all total up too?",
      "RDNA2 is beast just think how much better it would have done if RDNA1 wasn't so plagued with issues and bad reputation it's really sad to think about.",
      "Thank you for the kind words, validates the time spent working on it :)  \n\n\nWell, maybe a fan curve setup might help with noise, honestly building PCs LOOK intimidating but instruction manuals and YouTube videos are your best friend! Try it out for your next build! Also, hardware is much more durable than you think!",
      "I've just ordered a 5600 too, can't wait. Your build looks great!",
      "awesome photo!",
      "I just got a red devil 6750xt, so I‚Äôll have to go red if I follow this. But man this really looks clean wow.  I am totally copying you bro üò≠üò≠ü§ùüèæ",
      "Good for you my dude, I made a simalar upgrade recently,  hope you have a good time",
      "*AMD is the way to be.*\n\n**Welcome**",
      "I read fuck instead of tuck, was kinda confused, maybe a bit overly enthusiastic"
    ]
  },
  {
    "brand": "amd",
    "generation": "6000",
    "tier": "mid",
    "matched_keywords": [
      "6700xt"
    ],
    "title": "Switched from my 5 year old 1060 to the rx 6700xt and i've tried it for only 5 minutes.. Its so much better",
    "selftext": "",
    "comments": [
      "Went from 6700k/1060 to 5800x/6800xt what a massive jump. Enjoy that upgrade dude I sure the he'll am.",
      "You are mad brave when you hang a dart board above your pc",
      "Can we all agree than Radeon cards all basically look premium no matter what, unless it‚Äôs an rx 6400 of course",
      "This is the jump I wanna make, but I also wanna go one step higher (6800xt) so that I never worry about 1440p 60fps gaming.",
      "I went from the GTX 1060 to the RX 7900 XTX and boy what a massive jump that is in performance.\n\nNice upgrade enjoy bro.",
      "Haha you went from a ‚Äúentry‚Äù level card from 7 years ago all the way to the top of the line flagship!",
      "Hell yea they do :D",
      "Ya its an electronic one my parents put there like 8 years ago. I should take it down cus we dont even use it",
      "I've been playing for hours now and had 0 problems",
      "Yes. I know. Was just suprised by just how much better it is",
      "Went from gtx960 2gb to 6600xt and it was so nice to have games just work no fiddling.",
      "My fps went from 80 with lowest settings in apex to 165+ with max settings",
      "What time do you live in? The average user can plug in an AMD graphics card and never have to touch a setting and have zero issues.",
      "Going to be doing the same going from 1660 super to 6800xt",
      "So worth it. I just upgraded from my GTX 1080 to the 6800xt. Getting like 160fps ultra settings on Call of Duty with that card at 1440p",
      "To the moon and beyond it right there lol",
      "oh ye of course.   \nApex legends at pretty much max settings 165+ fps absolutely no problems  \nLast of us part 1 roughly 60 with almost max settings. i gotta try to drop the graphics settings a bit tho cus my cpu is bottlenecking really badly  \nRocket league roughly 200 fps almost max settings  \nOverwatch... 10 fps even in the lobby and it takes 5 minutes to even load the game but its not because of the gpu. its cus my cpu (i5 8400) cant keep up with it",
      "Sure are a lot of people upgrading specifically to Ryzen 7000s and Radeon 6000s/7000s from specifically ye olde Core 7000s and GeForce 1000s. I guess the PC market really was that bad for so long.\n\nIt is good to see people realizing all the AM5 whining is just that though. If you're building a new PC, you might as well go AM5 at this point. Such is the growing pains of a new board, and this is exactly why AMD did not want to do a new board for so long.",
      "In summer of 2021 I went from a 1060 6GB to a Radeon RX6600XT and I thought that was a great upgrade. Couldn't believe how much faster it was, all those stream hardware charts must be lying.",
      "I had a 1070 and went to a 6700xt and was blown away at how fast it is. Then I got spoiled and got a 6950xt lol. Still have the 6700xt I'm gonna put in a PC for my son. I'd imagine it will be good for at least 4 or 5 years."
    ]
  },
  {
    "brand": "amd",
    "generation": "6000",
    "tier": "mid",
    "matched_keywords": [
      "6650xt"
    ],
    "title": "Looking to upgrade from a 6650xt. 1080p 60fps with some future proof capability. Any recommendations?",
    "selftext": "",
    "comments": [
      "really depends on the GPU. I'd be willing to pay more for a 9070 than a 7800xt, you know? I'd say Roughly $700",
      "7800xt maybe. Its about a 40% jump in performance boost from the 6650xt.",
      "If you can get your hands on it a 9070 xt but for 1080p there aren‚Äôt too many upgrade paths that make sense without more context like cpu",
      "What's your CPU? I could recommend a 9070 or 7800XT but maybe your CPU will bottleneck it if it's too weak",
      "What's the budget, that's the most important thing",
      "With 700 you might be able to score a 9070xt :) I'd said anything RDNA4 would be better because of better RT and fsr4 if you want to stretch the life out of the card even more",
      "The 9000 series are RDNA4 cards hahaha",
      "I upgraded from a 6600 xt to 4070 ti super been playing games pathtracing no problem",
      "Oof this has me worried about following some budget pc build stuff from YouTube. I‚Äôve got a ryzen 5 5600 with a 6600xt coming‚Ä¶ I‚Äôm not a big gamer and just want to game at 1080p and be able to play most games without any huge flaws. Guess I might have to pull the trigger on a 6700xt and send the 6600xt back‚Ä¶",
      "7600x (dogshit pairing I know lol) I mainly said 1080p because I wanted to stress I don't need to run 4k. I just noticed that I'm struggling to run a lot of new games now",
      "Not OP but would a 7500f be bottlenecking either cards?",
      "7600x",
      "Tf is rdna4? And yeah $700 is enough to get a 9070xt at MSRP. Good luck finding one though haha. Cheapest 9070 (nonxt) I see is $800",
      "Made the same upgrade. Somehow it's worth more now than what i payed msrpüòÇ",
      "I mean it depends on the games you're going to play. Certainly now that games are getting more graphically intensive, I wanted a better gpu",
      "Wow what‚Äôs struggling if you don‚Äôt mind me asking",
      "Check gaming benchmarks, but I'd say yes",
      "Yeah for now I think the 6600xt is fine. Not going to get ahead of myself just going to build it and see how long it suites my needs. Worst case it sounds like AMD4 will be supported for some time and I won‚Äôt be looking at a complete overhaul anytime soon (if it makes it 4 or 5 years with maybe one GPU upgrade I‚Äôll be happy)",
      "Uncharted, Spider man 2, GoW ragnarok.",
      "saw a few benchmarks and a bunch of posts, the 7500f is pretty good. Very little bottleneck to none at all apparently. It's competitive with the 5800x3d."
    ]
  },
  {
    "brand": "amd",
    "generation": "6000",
    "tier": "mid",
    "matched_keywords": [
      "6750xt"
    ],
    "title": "Should I even upgrade from my 6750xt?",
    "selftext": "Title says it.  \n\nCPU - 7 7700x\n\nRAM - 32 5200 Mt/s\n\nGPU - 6750xt\n\nSSD - I have two, one 990 pro and a slower one CT1000P3SSD8\n\n  \nI have a 1080p 165 Hz monitor. Really, I'm just second guessing myself on getting a 7800xt or just putting the money elsewhere in my pc or monitor. \n\n\n\n",
    "comments": [
      "Prob not, unless can get a RX 9070 or 9070 XT at MSRP. Hopefully new shipments coming in when the 9060 XT releases.",
      "No the jump from a 6750xt to a 7800xt isn't big enough imo. Just keep saving money and wait for a msrp 9070xt",
      "Not right now, definitely keep a look to see if 9070 XT prices come back down in a few months though.",
      "Get the 9070 XT. If you wanna stay on 1080p a 12700k+ or 5700x3d+ could push some high fps for you. For 1440p can't go wrong with the 9070 XT at MSRP. 5070 ti is comparable. Do not get the 5070. It's a bad price to performance.",
      "Msi Pro B650-P? I have the same board. Are you on the newest bios?",
      "I was sayin that the cpu‚Äôs you mentioned are slower then the one he has his gpu could use an upgrade",
      "Ram would be the upgrade id reccomend too i have a 7600x and a 6750xt and im pulling around 100 fps on 1440p high/ultra settings in helldivers 2",
      "A 7800 XT will be a good upgrade but why exactly are you looking to upgrade?",
      "The 5070 is just a reskin of the 4070 Super with roughly a 10% uptick in performance. \n\nhttps://youtu.be/ntSylZ1Bp1Y?si=tGW6CLLmXil29iRO\n\nIt received a fairly scathing review from most big reviewers. Here is Gamers Nexus one but even LTT said sort of similar stuff. It just isn't worth the cost.",
      "The 6750 will serve you well at 1080p. I moved to a 7800 after purchasing a 1440p monitor. Honestly, the 6750 was doing fine but I needed just a few more frames to be satisfied. If you plan to move to 1440p in the near future then it may be a good investment. If you're going to stay on 1080p for the foreseeable future stick with the 6750.",
      "If you need more Raytracing performance then 7800xt, if not then a 6800XT deal might be good, if its around 300-400, performs very similarly to 7800xt for a lot less money (6800 can do raytracing too, just not as good)",
      "Do you think I should get the 9070xt over either of the 5070's I've been with AMD for a while, so I'm used to getting them for the price to performance, but I've heard the 5070's are not as good?",
      "Well I was wanting to go to 1440p but then I'd have to wait longer to get the money for the monitor",
      "Since it only costs around $90, I‚Äôd get a better ram kit. 5200 is really slow. I‚Äôd get a 2 x 16 kit of 6000 cl30-36-36-76.  Ram actually makes a big difference at 1080p.",
      "Absolutely the 9070xt is only 2-5% slower than a 5070ti and the 9070xt has 16gb of vram while the 5070 only has 12.",
      "Dude he has an am5 7700x those suck comparativly",
      "Actually I have a set of cl40-40-40-84, but I tried for like an hour or so and I couldn't fix it with my bios maybe it's my motherboard, but I have no idea (PRO B650-P )",
      "They are the white t force delta ones they are supposed to run at 6400hz",
      "Personally had a 3700x and went to 7800x3d for 700$. Yeah not really worth as the FPS increase and 1% lows don't justify it compared to my GPU upgrade to a 7900 xtx. Not even close. I'm not playing comp games at 1080p either which a cpu upgrade benefits the most.",
      "You might want to manually lower them down to 6000. But yeah even still, you bought the wrong die looks like."
    ]
  },
  {
    "brand": "amd",
    "generation": "6000",
    "tier": "mid",
    "matched_keywords": [
      "rx6750"
    ],
    "title": "What GPU to upgrade from RX6750 XT Dual",
    "selftext": "Hey, so i currently have the asus RX6750 XT Dual and I am thinking about upgrading. I am mainly playing CS2 and Overwatch 2 and I would like to also livestream these games. I currently own a 240hz monitor but want to upgrade soon to 360 hz or maybe higher. My Processor is a AMD 7800X3d.\n\nLet me know you recommendations please, I would buy a used one, since I don¬¥t have a unlimited budget",
    "comments": [
      "6750xt is still a really good card. . . but. . . if you are using an ultrawide or a 34\" 2k then yeah, you will want to upgrade that card.  My suspect is you are going to want to be in the 9070xt range or a 5070ti.  I normally went AMD for price but since 9070xt and 5070ti cost the same. . . 5070ti this generation.  \n\n5080 would be ideal, but. . . . that jumps from $900 range to $1500 range.  Up to you though.",
      "for streaming purpose i advice 5070ti overall the cheaper models you find not msi ventus/shadow\n\nif you find a 4070ti super cheaper than a 5070ti is very good. .. also 4080/4080s\n\n\nminimun a rx  9070 but if you streaming in twitch nvidia is better encoder.. not for amd fault beacuse amd h265 and av1 are very good encoder but h264 amd econder is way worst than nvidia.. it Just twitch using ancient codecs like h264\n\nwhat s you budget?\n\ni will  advice to not go lower than a 4070s 3080ti  raw perfomsnce.. 12vram can be a problem in the future but not for overwatch and Cs \n\nif you can go for a 16gb card. \n4070s super does a +50% from 6750xt\n\nhttps://www.techpowerup.com/gpu-specs/radeon-rx-6750-xt.c3879",
      "i mean i'm not seeing much of a performance jump for you unless you buy into the $1000.00\\~$3,800.00 card range so you already know what to shop for.",
      "The best value card at that fps will be the 6950xt or 7800xt with the latter being slightly slower but also a little more expensive",
      "Isn‚Äôt your GPU the 7000 dollar editing one? Or I might be getting it mixed up with something else",
      "What is your budget?",
      "Depends on your budget and what your goals are. The 9070 and 9070xt are the winners this generation, IMO. Several issues, including drivers, causing problems with Nvidia 50 series.",
      "9070 and 9070 XT are the successors to your card and have also better quality for streaming purposes.",
      "ya 5080 is a scam.. too much price difference from 5070ti for too low perfomsnce gap",
      "The price is around 360‚Ç¨ now and its for gaming",
      "Unreasonably priced is not the same as a scam. Stop making words lose their meaning.",
      "legal scamüòÇ",
      "For it to be a scam, there needs to be some form of deception.  High prices are not deception."
    ]
  },
  {
    "brand": "amd",
    "generation": "6000",
    "tier": "mid",
    "matched_keywords": [
      "6750",
      "6750"
    ],
    "title": "AMD RX 6600 stock runs dry in China, the company shifts focus to Radeon RX 6750 GRE 10GB",
    "selftext": "",
    "comments": [
      "This is still pretty much the only card most people need, it runs Doom Eternal at 100+ fps and most modern games on high with RT off at 60fps.",
      "Doom eternal runs at 60FPS on an Xbox One & PS4. 100 FPS is an extremely easy feat\n\nYou also need to specify a resolution if you're talking GPU performance",
      "You can't.  The reference 6600 was never manufactured.  It's just a rendered image only.",
      "Doesn‚Äôt fix everything. Even though it‚Äôs smoother it isn‚Äôt that responsive.",
      "60fps isn‚Äôt high enough when a lot of people have 144+ hz monitors now a days.",
      "Probably nowhere. The RX 6600 didn't have a reference design, so it's likely just a 3D render made by AMD for illustrative purposes.",
      "I've been using a 6600 since early 2022, it does everything you need it to.\n\nZZZ @ 1440p, Eve Online, MH:W, Elden Ring, all the esports. I've even tried LLM's on them(not great, but usable). UE5.3, Blender, Clip Studio, again, it's not a great card, but if you're just starting out, it does enough!\n\nGreat value, low power usage, and cheap!",
      "Where can we buy that single fan RX 6600 from the OP's picture?",
      "I think it's just a mock up. It looks like an AMD design but they never released anything below the 6700 xt for purchase directly on their site.\n\nIt's too bad. It has a great aesthetic.",
      "Ok since people are downvoting me I guess I gotta post sources...\n\n[https://www.youtube.com/watch?v=NdoxEaySXis](https://www.youtube.com/watch?v=NdoxEaySXis)\n\n[https://www.youtube.com/watch?v=EOBE-Ade9MQ](https://www.youtube.com/watch?v=EOBE-Ade9MQ)",
      "Same, except late 2022. I feel like it's the 1060 / 580 of its generation. Not the best, but good enough for what most people play, and probably the best bang for the buck out there.\n\nFSR / XESS / etc. are helping me with the few games it struggles with, and honestly, those games generally tend to be poorly optimized anyway.",
      "With mouse and keyboard I just do not find 60fps to be playable. Even drops down to 90/100 from 140/50 sorta range is extremely noticeable.",
      "I wonder if 60FPS or 120FPS is 'standart' these days",
      "I recently got the Asus Dual 6600 and man this card punches! Playing Warhammer 3, le mans ultimate and ACC all maxed out 1080p with no issue",
      "This. Idk why ppl act like 1080p60fps is the bar to meet in 2024. That ship sailed. \n\nThe new standard is 1440p120fps.",
      "Lemme guess what those \"few\" games might be. AW2, star wars jedi whatever, hellblade 2",
      "By that logic we should have all been happy with 20fps then right?",
      "I would be more interested in the 12GB version wich is basically a cloned 6750 XT so with faster 18Gbps VRAM\n\n2 more GB is welcome for using extra features like frame generation / afmf with texture-heavy games like console ports\n\nI also wish there was a small 2slot model like the PowerColor Fighter series ... guess im expecting too much",
      "ü§ì",
      "I don't know what AW2 is, you're correct with Star Wars Jedi whatever, and another one is Starfield, which I had to use FSR2 just to be able to play with a decent frame rate.\n\nHonestly, if devs optimized their games right, I'd say that the 6600 would probably be relevant beyond 2025, but if Ubisoft is any example, this might not be the case, unfortunately."
    ]
  },
  {
    "brand": "amd",
    "generation": "6000",
    "tier": "mid",
    "matched_keywords": [
      "6700xt"
    ],
    "title": "Huge FPS gain after 21.12.1 GPU driver in Forza Horizon 5. 114>>148fps, 6700xt",
    "selftext": "",
    "comments": [
      "There was a big Forza update as well. Are we sure it was drivers that did this? Note how the game version has changed between runs.",
      "I noticed really big boosts in Halo Infinite also. Well in excess of the 15% they claimed.",
      "I rerun the benchmark in latest game build with 21.11.2 after DDU. Even worse FPS than before. So its definitely driver related.\n\n[https://imgur.com/a/12RfBRK](https://imgur.com/a/12RfBRK)",
      "I haven't tested this new driver but just wanted to share my findings with RX 6800. So since launch I had massive fps drops in races (especially cross country) and didn't know the cause. Changing overall settings didn't seem to matter, but actually particles quality is the culprit. So with high or ultra, the drop is absolutely massive when there are lots of cars on screen emitting smoke or dirt (like going from 100+ fps to 40) it's a slideshow. With medium there's a big gain and it goes at like 70-80 in those moments. At low it basically stays over 100 but then the smoke starts to look like ass when you drift on asphalt.\n\nI also found out that terrain deformation isn't actually active because there should be deep tracks in the sand, all I see are faint tyre marks.",
      "Did you have the ‚Äúready for halo infinite‚Äù drivers before that? Or just the previously available through the amd software",
      "I can personally confirm this on my own system.\n\n21.11.2 (82 FPS): https://i.imgur.com/2MmaqvZ.jpg\n\n21.11.3 (88 FPS): https://i.imgur.com/nzNQa0H.jpg\n\n21.12.1 (98 FPS): https://i.imgur.com/twgn9Fu.jpg\n\nI was GPU-limited in all three benchmark runs and used identical graphics settings.\n\nEDIT: Performance uplift in RDR2 as well. \n\nBenchmark Scene #| Avg. FPS (21.11.3) | Avg. FPS (21.12.1)\n---|---|----\nScene 1 | 71.647758 | 78.857147\nScene 2 | 85.386040 | 88.528145\nScene 3 | 105.904663 | 109.190758\nScene 4 | 82.836662 | 86.451599\nScene 5 | 81.112938 | 86.385429",
      "Damn that is an insane boost!!",
      "Amazing boost. And no mention in driver releases. Congratulations to amd. Performance like forza horizon 4 with the latest drivers.",
      "That's absolutely nothing like the 30% gain that OP is suggesting.",
      "Likely the improvements from the beta Halo driver now in a stable version. Can anyone beat my +42% improvement with ultra settings at 1080p? :P",
      "Not op but i have an rx 570 +r5 1600 and was getting 20-25 fps. Turns out i havent updated my drivers since 2020 so i downloaded the new one and now i am at ~70",
      "Raja was right after all",
      "Excellent, that‚Äôs really impressive.",
      "RX 6800 was around 85-90 FPS at 1440p High and is now at 120-130 FPS same settings",
      "Completely off topic, but any Rush fans out there?  If so I love the drivers version for this month 21.12  !",
      "Does anyone know if RX570 would gain any FPS in FH5 from this driver update?",
      "Yes, I also have RX5700 and installed the latest driver. \nOn WHQL driver, 1080p and same video settings as Xbox performance mode, I had 70-90fps with dips to 60fps in places like Guanajuato. \nNow, with settings unchanged, I have around 100-110fps with dips to 90fps, so there is a significant fps boost.",
      "RT isnt working in gameplay or benchmark scenario. It just works in car showroom.",
      "lmao so thats why car showroom is so slow for me",
      "Yeah but it‚Äôs very good for the price imo. I‚Äôm hoping to score a 3080 or 3070 ti through Best Buy at msrp so I can sell what I‚Äôm using (6700xt reference card)"
    ]
  },
  {
    "brand": "amd",
    "generation": "6000",
    "tier": "mid",
    "matched_keywords": [
      "6750",
      "6750"
    ],
    "title": "Say hello to my little friend (upgraded from a RX 6750 XT Red Devil)",
    "selftext": "",
    "comments": [
      "Sapphire Nitro+ is unarguably the best looking card of this generation",
      "Fir every beautiful women in the world, there‚Äôs a man who is tired of how she looks.",
      "aRGB",
      "That is to connect the GPU to the motherboard to control the RGB colours if you wish, I just used Trixx though.",
      "You might be the beautiful woman in the analogy. Sorry lol",
      "What are those pins for? Right from the power connector",
      "I think it's my favourite but in person the hotspots on the LEDs are much more prominent than in pictures which is a bit of a let down. Wish it was a smoother diffusion.",
      "I knew somebody would mention that buy yeah its the photo slanted.",
      "the 2nd photo, is the GPU sagging or the photo was taken slanted",
      "I was a photography nerd at one point earlier in life, and in case you want the technical term for what you're seeing, this is an optical aberration known as \"barrel distortion\", caused by an imperfectly shaped lens which causes a bowing effect, usually in the center of the photo.\n\nIt is indeed wonky.",
      "Nice I have the same BUT do you use the anti-sag bracket included?, because it seems that you have quite the sag there!",
      "Controversial take but I think the Pure and the white tuf look better,\n\nAs a seasoned nitro+ owner this card has been mid for me honestly.",
      "I was thinking of getting the same card i.e. 7800 XT but I changed my mind and now I'm getting the 7900 GRE, in my case, I only have to pay a bit more for the upgrade.",
      "Was it even worth it? It's like going from 6750xt to 6800xt",
      "Yup, I simply love it and the looks played role in my selection.",
      "That's the third 8-pin connector, (i think) all Sapphire cards have 3 connectors so they can pull more power to get just a bit more of overclock. OP doesn't seem to really mind though",
      "Well I am able to max out all game settings now and still get more fps than than I was getting with the 6750 with some settings turned down. Plus you get the newer tech. For me I think it was worth it.",
      "no",
      "Hu?",
      "Oh OK, then enjoy I ended putting mine vertical with a cooler master GPU bracket/riser."
    ]
  },
  {
    "brand": "amd",
    "generation": "6000",
    "tier": "mid",
    "matched_keywords": [
      "6700xt"
    ],
    "title": "This GPU generation is gone",
    "selftext": "I think that substantially this generation of GPU is gone for us, and that when there will finally be stock and prices somehow near MRSP, we will already be close to the first leaks and the first engineering samples of navi3\n\n5700xt July 2019\n\n5600xt January 2020\n\n6800xt November 2020\n\n6700xt March 2021\n\nif the development time between one gen and another stays the same, it's not difficult to hypothesize navi3 more or less in 10 months from now, so end of this year or beginning of 2022\n\neven if in September / October there were finally stock of cards at \"normal\" prices, it would not make much sense to buy those cards with navi3 coming out so close\n\nwhat do you guys think?",
    "comments": [
      "I remember over the summer everyone advising not to buy a GPU since the new ones were right around the corner...\n\nFool me once.",
      "If only I could believe in September/October to have normal prices. I decided I'd just play mostly older games and backlog and put my GPU upgrade on hold indefinitely and invest in other hobbies instead. In my time high tier GPUs were 400-500‚Ç¨, not 600, not 1000 and certainly not 1500‚Ç¨ or more. That's just ridiculous.",
      "Usually it's 2 years between GPU cycles, and we're 6 months since release. We've got awhile yet. lol Late 2022 is when the next ones will theoretically, and that's assuming everything goes well. There will probably be a refresh like the 3080ti etc late this year.",
      "Same. Saw Pulse 5700xt's and 5600xt's on sale frequently from July through october, perfectly reasonable prices all day, and now those same cards are on ebay for $800+.",
      "I've been fooled. Now rocking a 3900X with a R9 280 lol",
      "fuck these scalpers and miners this is the worst i have seen it been pc gaming for 3 decades",
      "I HAD a 5700xt and returned it because it was too close to better cards coming soon.\n\nLuckily the 1060 lives on.",
      "i'm just waiting for the second-hand market after the crypto currency crash",
      "AMD have already stated they're on a 12-18 month cadence for both CPUs and GPUs. Expect the next gen to come by mid next year.",
      "The pandemic hasn't helped. There's chip shortages in all industries. \n\nBut the combination of scalpers, miners, and the shortage has made this absolutely insane. I'm just glad I'm content with my current GPU.",
      "From a gamer's point of view this makes perfect sense. There are hundreds of excellent games out there that each person has never really enjoyed, and no time to play them all. Also, even if you want to have fun with a modern game you don't have to force yourself to only play it on ultra settings 4k 120fps and so on.\n\nA lot of people waste their money paying inflated prices because they \"need to have the latest just because\".\n\nOthers use the GPU for research, rendering, or some other work. That's fine.\n\nBut strictly for gaming, yeah.. like you said, there's no sense in pushing it that far.\n\nI myself have an endless backlog of dozens of  games I consider \"must play\" stuff.",
      "This, I would not expect RDNA 3 gpus until mid/late next year.",
      "This might be the time it does not crash",
      "Ugh, you have to be kicking yourself. LOL",
      "Prices wont normalize by Q3. I don't know why people keep saying this. It doesn't make sense.  \n  \nThe west market will likely stabilize a lot quicker than the rest of the world but not by Q3. How many people are still waiting for GPU's? How many resellers are going to try and continue an artificial scarcity just to sell at inflated prices for a bit longer? This will get milked dry just as everything always does. It makes no sense to normalize prices unless inventory starts filling up. It wont happen by Q3. People are still waiting on GPU's they ordered back in November at launch and some of those are even getting cancelled because the GPU's they originally ordered are no longer in production. Remember how they said supply will be back to normal by end of March? It's far from normal. I've said it before and I'll say it again; don't expect things to go back to normal for a while. **If** it ever even is going to be normal again.  \n  \nThe MSRP has been getting worse for generations now. Mid-range GPU's going for $350-400 is unacceptable. Now that we're being *conditioned* to these ridiculous scalper prices, what's wrong with raising the MSRP for next gen another $100? People are already willing to pay scalper prices so clearly GPU's aren't generating enough profit. The days of affordable GPU's are gone. We will eventually get back down to MSRP but the MSRP will never be the same again. Remember this *if* or when the next 4060 starts at $375 or $399 MSRP.",
      "Stay strong buddy our time in the sun will come",
      "shits so bad alot of people are giving up on pc gaming",
      "Oh, oh yes indeed.\n\nBasically I bought the 5700xt for my \"old\" pc of 4 years, and then decided it was stupid to not just build a whole new one with all new gen parts. So I had a \"reason\" but man hindsight is murder.",
      "I believe Linus made a video in 2020 summer recommending to buy computer hardware right away, predicting massive shortages.",
      "Yea they really have no reason to push out rdna3 when 6800 xt and all are flying of the shelf's and is gonna keep flying"
    ]
  },
  {
    "brand": "amd",
    "generation": "6000",
    "tier": "mid",
    "matched_keywords": [
      "6750",
      "6750"
    ],
    "title": "AMD Radeon RX 7600 XT's China release date uncertain amid RX 6750 GRE series popularity - VideoCardz.com",
    "selftext": "",
    "comments": [
      "Wait a 16GB GPU at $300, why did this GPU not come out here ages ago?",
      "Needed to get rid of RDNA 2 inventory",
      "Illusion of choice. They wanted you to either spend $260 for the 7600 or cough up $450 for the 7700XT which they priced terribly in order to upsell you on the $500 7800XT with not much in between. \n\nAll while clearing inventory of last gen 6700XT in the $300 range. \n\nNow that inventory is drying up BOOM release a product to fill the gap and give it 16gb of VRAM for those who you couldn‚Äôt successfully upsell the 7800XT to.",
      "Texture settings usually don't cost much performance as long as you have enough VRAM. So this will let you run ultra textures for a long while even if you have to turn down other settings.",
      "if it comes with 40CU, its more like a 6700 XT with 16GB",
      "Golden Rabbit Edition. Supposed to be China exclusive, but I can find all the gre cards in my home country (Southeast Europe)",
      "lol as if radeon marketing division was that competent.  or they were the top choice in gpus.",
      "Not quite. 7600 trounces 6600xt across the board. 6650XT is SLIGHTLY slower then the 7600, but they trade blows.",
      "This is what I don't get, I feel like this 16GB will be used as a crutch to sell it at like $370, because you know, ain't nothing out there with 16GB of memory below $450. Memory is cheap, but that doesn't translate to better prices for us, that 16GB can justify at least a $50 up charge in the eyes of corporates, i don't want it if it means $50 more than what an 8GB card would've been, it's a 1080p GPU, would be nice if there was an option between both.",
      "4060 Ti 16GB enters the chat. $500 launch MSRP for 128 bit LMAO\n\nDamn, some people actually bought that. They got hosed so badly.",
      "It's almost definitely a 7600 with twice the VRAM and like 10-15% better performance",
      "They sell all their allocation just fine. Most of it goes to CPUs, consoles, and handhelds so they don't have that many left-over for GPUs. \n\nThey can't be any more of a choice than they already are since it would take years or decades to order more, receive more, and produce more.",
      "I'm looking to buy a RX 6700 XT next week, should I wait for this instead?",
      "But is it fast enough to make use of 16GB?",
      "Its kinda amazing. when it comes to toyotas and japanese automobiles they took all the market by storm. But AMD's \"Toyota\" lineup AM4 and RDNA2 didnt dent the marketshare of other brands. and now AM5 and RDNA3 is fighting for the same picky buyer %20 that already upgraded leaving stock behind. I guess cars are more expensive entitites to push people into value products while Chips are just more like guccis?",
      "Exactly.  I picked up a used 7600 and has been working really well as an experiment.  going to pick the XT Up and keep it as my primary machine.",
      "The 7700xt is already a rx6800 so..",
      "Agree. Electricity cost is much cheaper in mainland China compared to a lot of states in Us",
      "If you see a 6700 XT for $300, get that. This will most likely be slower than a 6700 XT and it'll probably cost at least 299.",
      "Did you forget about the ARC A770? 16 GB variant has been on sale for quite some time now. Can find them easily for under $300."
    ]
  },
  {
    "brand": "amd",
    "generation": "6000",
    "tier": "mid",
    "matched_keywords": [
      "6700xt"
    ],
    "title": "RX 6700XT + RYZEN 5 5600X | 25 Games Tested at 1080P, 1440P and 4K",
    "selftext": "",
    "comments": [
      "I shouldn't see much difference at 1440p if I use a 11400F instead right?",
      "Depends on the game still. In something like cyberpunk where crowds seem to hit the cpu hard you would.",
      "I am glad I managed to secure a 6900 XT while my 6700 XT was being shipped to me. Upgrading from 1080p @60fps to 1440p  @144hz is insane.\n\nYour previous video on the ultrawide 6800 XT + 5600x helped me a lot to justify the purchase of the 6900 XT.\n\nI just don't get why AMD recommends the 6700 XT for 1440p gaming. Sure for 60fps it is solid but anything above depends on the game and what settings you are comfortable to compromise for more fps.\n\nOverall excellent video.",
      "It depends heavily on the game, in most games it'll be fine but some games are more CPU heavy. 11400f definitely has better value than 5600x imo",
      "If the gpu is at 97-98% the difference will be minimal if any, this ofc if the power limit is removed",
      "Meanwhile there‚Äôs those random channels that only shows bar graph and it just looks skeptical",
      "I have a Sapphire Nitro+ 6800XT and it is Awesome for 1440/144. 6800XT runs 1440/144 buttery smooth. Doesn't break a sweat.",
      "This comment should be renamed - user that doesn't know the basic and usually has unstable overclocks and then blames gpu drivers",
      "Hey, i mean, why would you use a lower resolution when this card can play most games at 1440P around 100 fps? I see no sense in there. Also, releasing the OC/UV tutorial in some minutes ;)",
      "Dude I intended to get a 6800 XT but it was impossible to get one for MSRP. I was lucky to grab the 6900 XT slightly above MSRP from a guy who accidentality ordered two. The 6900 XT was a bit overkill for my use case but I will take that over scalper prices",
      "Thanks, i get it. That's why you have timestamps. Live stats are always better for this, charts are for the gpu and cpu comparisons :D",
      "For the price it‚Äôs at now a days, yeah",
      "I run a  5800X with the 6700 XT. It's brilliant.",
      "Thanks for the words",
      "Thank you",
      "I agree. I really wanted the Sapphire Nitro+ 6900XT to pair with my 5900X but I have zero regrets or qualms with my 6800XT",
      "Seems like you overclocked your brain also",
      "You got to appreciate all the effort put into this 1 hr bench video !",
      "Here https://youtu.be/h5C5jNedZqM",
      "Thanks!"
    ]
  },
  {
    "brand": "amd",
    "generation": "6000",
    "tier": "mid",
    "matched_keywords": [
      "6750xt"
    ],
    "title": "New VGA 6750XT w/ 5600X",
    "selftext": "CPU - 5600X\nVGA - Xfx merc 6750XT\nRam - Vengence 3600Mhz C16 16 (8*2)\nSSD - Crucial P5 1TB m.2\nMB - Tuf B550 \nHDD - 4TB (2 x2TB)\nPSU - corsair RM 750 \nüòÖ",
    "comments": [
      "I really like the design of the XFX shroud. I got a 6800xt because of it. Enjoy it!",
      "Nice build you don't see many XFX cards with the white merc logo its black on my 6950 XT.",
      "Its called GPU as a short term or video/graphics card to be more specific, not VGA, VGA is an old port used to display GPU output to monitor.\n\nAnyhow, congratz as its a solid card, enjoy :)",
      "The 7900xtx only has XFX lights :(",
      "Yeah this made me wonder if OP might be a bit on the senior side as VGA hasn't been used in some time now.",
      "Yeah I have no idea why they got rid of the extra text, it made the GPU look really unique. No other GPU does it.",
      "And that ugly silver backplate instead of black",
      "back in days we called them as VGA cards , thats why xD . thanks",
      "I like that backplate!",
      "I have a white build and it looks great in it. But I get it that most builds are black. They should give the choice between silver and black.",
      "I got a Red devil 6750xt, but man does that XFX one look good.",
      "Whats the performance difference between a 6600xt and 6750xt?\n\nReally nice looking build.",
      "My buddy got this exact model and it's too much for a 6700 XT but oh boy it never gets warm. Enjoy man.",
      "Same card as in my friends build i did for him. Such a sweet card",
      "I put this same GPU in my son‚Äôs computer, nice peppy little card",
      "Very well proportioned build, I like it !! üòÅ",
      "![gif](emote|free_emotes_pack|heart_eyes)",
      "VGA stands for Video Graphics Adapter, not the port, which is a 15 pin D-Sub, so OP is technically correct. Greetings from another senior user!\n\nCGA - Colour Graphics Adapter\nEGA - Enhanced Graphics Adapter\nVGA - Video Graphics Adapter \n\nThere were other more obscure ones too.",
      "Roughly 30%.\nBut on top of raw performance you get extra 4GB of VRAM, wider bus and more L3 cache. The jump is nice, but I think 6800 makes more sense, it's ~54% faster.",
      "thanks :D"
    ]
  },
  {
    "brand": "amd",
    "generation": "6000",
    "tier": "mid",
    "matched_keywords": [
      "6750",
      "6750"
    ],
    "title": "RX 7700 XT vs. RX 6750 XT for game development and 3d work",
    "selftext": "Hey all.\n\nI'm planning to upgrade from my current laptop (i5-2430M, Radeon HD 6470M, 8gb DDR3-1333) to something faster. Way faster.\n\nI'm torn between these two cards (RX 7700 XT and RX 6750 XT). I have heard something about the RX 7000 series being better for productivity than the RX 6000 series, I don't know if this is true.\n\nThe price difference between these two cards is 63 euro.\n\nI'm planning to use it for Unreal Engine, Unity, Godot and Blender. I don't know much about these programs since I have never used them before.\n\nDoes anyone know how much more the RX 7700 XT is better than the RX 6750 XT for game development and 3d work?",
    "comments": [
      "Between those two I'd say the 7700 XT is the better choice, but you can't go wrong with either. AMD cards will do fine in all of those but Nvidia is just superior in blender thanks to CUDA.  I've done unity dev work on a 6800 XT and it was perfectly fine. \n\nIn all honesty, except for blender your CPU matters more than your GPU with these tasks- Unity will use all the threads you can throw at it when compiling and if choosing the 6750 XT over the 7700XT gives you the budget to go for an 8-core chip instead of a 6-core chip, do it.\n\nThat being said i agree with the other commenter, a used RTX 3080 10GB is the best value in that price range right now. Those that work are well within the valley of the bathtub curve and you'll probably get at least 5 years out of a used one. (Just maybe avoid the zotac trinity model of the 3080 those are cheaper for a reason)",
      "Excuse my ignorance but aren‚Äôt nvidia cards better at these tasks?",
      "used 3080",
      "I think you will be better with Nvidea hardware as they might be better at handling productivity...",
      "All this info is very helpful, thank you!\n\nBoth options feature a Ryzen 7 7700.",
      "Probably, yes. Sadly, the best nVIDIA card that fits in my budget (430 euro) is the RTX 3060 12gb.\n\nIsn't the RX 7700 XT better than the RX 7700 XT for all my use cases (except Blender ofcourse)?",
      "They are said to be, yes.",
      "I don't really know about buying used. It's quite risky.",
      "Might be, yes.\n\nAlthough the best nVIDIA card that fits in my budget (430 euro) is the RTX 3060 12gb, what costs 290 euro here.",
      "Well productivity wise nvidia seems like your best bet. Although I don‚Äôt do any of these tasks and only game, so I went with AMD. But for productivity go for nvidia. Where are you from? 430 for a 3060 seems a bit steep imo.",
      "Less than you'd think. the biggest risk is the lack of warranty",
      "Bro Actually sometimes 7900xtx performs similar to 4060ti in Productivity so it will be better to research if AMD support those applications. It's all on your applications.",
      "I'm from the Netherlands btw.\n\nI mean't my max. Budget for a gpu is 430. The 3060 12gb costs 289 at a minimum here.",
      "I'm afraid when the buyer protection of the platform is over, That then for some (random reason) the gpu dies, and I've then lost a lot of money.",
      "Yeah, I'm researching. But it's quite difficult to find a benchmark or anything for Unreal, Unity and Godot.\n\nAtleast I found out that the RX 7700 XT is quite close to the RTX 3060 on blender.\n\nNVIDIA GeForce RTX 3060\tMedian score:2147.17\tNumber of benchmarks:411 AMD Radeon RX 7700 XT\tMedian score:2128.77\tNumber of benchmarks:59\n\nSource: [opendata.blender.org](https://opendata.blender.org/)",
      "Thats an idea. Yes, you may need the VRAM. You may want more modern features though. Just a thought.",
      "That doesn't really happen with GPUs a ton UNLESS they've been reflowed. If they've lasted 2 years, they'll probably last another 5 if cared for properly.",
      "I have had a used 3080 for 2 years with no issues. I always buy used cards. No risk and way more performance per dollar.",
      "If possible try the things physically at a Centre near you. Whichever satisfies you buy it... I think this suggestion is sounds good but I don't know if the seller can let you check these things.... Gamers love AMD but Nvidea shifted focus to AI...."
    ]
  },
  {
    "brand": "amd",
    "generation": "6000",
    "tier": "mid",
    "matched_keywords": [
      "6700xt"
    ],
    "title": "RX 6700xt ASUS TUF BEST Undervolt. Using only 112W and 52C at 100%",
    "selftext": "Hey i was trying to undervolt my gpu because it has some coil whine, after an hour I found a good voltage and clock  speed that don t crush so I decided to play with them. As I loaded to my game (ARK) I Saw that a GPU that s supposed to use 200w is using only 112W while staying at 52-55C at 30%fan which is crazy.I just wanted to share my settings with you because I think this is really good result.\nEdit: Don t blame me if doesnt work on your GPU, maybe i just have some really good model.\n\nhttps://preview.redd.it/dyotg3qdaccb1.png?width=1920&format=png&auto=webp&s=71aa87ae28e981449aabdd5a8e3def1ddc89704e\n\nhttps://preview.redd.it/5xuwj0qdaccb1.png?width=1887&format=png&auto=webp&s=1153b8918a2d8e5eecaf35454b50dcc15b5c9b07",
    "comments": [
      "Stability trumps power and temps anyday. I highly doubt this is stable. You just haven't found it's weakness yet.\n\nEdit: ya it wasn't stable. Huge surprise.",
      "It's a very good result! Just keep in mind that you might run into some crashes down the line. Getting the undervolt stable requires some time and patience, for reference at 1100mv mine seems stable in heavy benchmarks but I do get some sporadic crashes so I upped it to 1140 for now. Still a very nice saving :)",
      "Only one crash, so far.",
      "Here's my spreadsheet of stable voltages and clocks across the whole range of my 6700xt sample. \n\nhttps://docs.google.com/spreadsheets/d/1sOVt4gNZQYdSHWGY24a6u3yRolVa5qb6ACAD1DJ1Ck8/edit?usp=sharing\n\nNote that they mostly all use 1130mV, which means a -70mV undervolt from the stock 1200mV of my card. \n\nTL;DR Stockish 187W at 2470MHz, all the way down to peak efficiency of 67W at 1345MHz. Sweetspot I'd say is 124W at 2110MHz. \n\nKeep in mind these are Unigine Superposition 4K tests, which I've found to have up to 30% higher power consumption per clockspeed than the majority of games.",
      "my 6700 runs at 90w (stock is 160w) since january and it never crashed even once, to be fair a lowered the clock a little but it didn't really degrade my performance much, it's maybe 5%",
      "Not all cards are born equal",
      "I got cucked by the silicon lottery it seems üò≠",
      "Bro I get crashes at 1165 with 2400-2500 core clocks and +100 memory clock.",
      "I m playing on that since posted, only 1 crash So i incresed voltage by 10",
      "Yeah the software reporting on this generation of AMD cards is not very accurate to the real power consumption. At a reported TGP of 185W reported in software, it's actually pulling ~230W from the PSU/Motherboard. \n\nhttps://www.igorslab.de/en/graphics-cards-and-their-consumption-read-out-rather-than-measured-why-this-is-easy-with-nvidia-and-nearly-impossible-with-amd/",
      "Run 3dmark stress test.",
      "Difference is that the 4060 is manufactured E-Waste or as Gamers Nexus put it: A waste of Sand.",
      "I literally have every option enabled, GPU usage at 99% CPU is 5 5600 so there isn t any bottleneck, what is your problem?",
      "Makes sense, I have the Sapphire Pulse 6700 XT",
      "Most self aware redditor.",
      "Try testing other games, ARK is too dynamic and has terrible cpu/gpu optimization.",
      "Xfx 6800xt merc at 4k undervolted to 1055mv uses a whole 130-180watts, very rarely hits 200w and is usually around 150-160w.\n\nUndervolted and overclocked, it gets better fps than the factory OC.",
      "Undervolted amd = next gen play",
      ">Stock 187W\n\nUnrelated but kind of related question as I am a brand new owner of a 6700XT & you seem to have *some* knowledge. What's the maximum Total Graphics Power it's supposed to pull in watts? I've seen websites advertise the total power draw as 230W but from what I can see in the AMD Adrenaline software & HWinfo64 in TGP field, it maxes out at 180-185W; is that normal?",
      "I love this. Did you fill up the spreadsheet manually, or programatically? I would like to do this on my 6800xt"
    ]
  },
  {
    "brand": "amd",
    "generation": "6000",
    "tier": "mid",
    "matched_keywords": [
      "6750",
      "6750"
    ],
    "title": "ASUS Radeon RX 6750 GRE \"Megalodon\" graphics card spotted",
    "selftext": "",
    "comments": [
      "Region limited products are so stupid.",
      "Even worse, there are 2 versions of it.\n\nThe 6750GRE 12GB is 40CU and fed by the full 192-bit bus. It boosts to 2581mhz.\n\nThe 10GB version is 36CU,  and only has a 160-bit bus. This one only boosts to 2450mhz.\n\nIn theory (CU x Mhz), the 12GB version is like 15% faster. This is some 3060 8GB type shit.",
      "The GRE (Golden Rabbit Edition) branding confuses me, 2023 was the year of the rabbit in China. It's been year of the Dragon in 2024.",
      "I just call it RX 6750 Gregory \n\n\n\n/s",
      "GDE.\n\nI love it!",
      "The naming is deceptive. It's got the same VRAM size and speed, same shader count, and same boost clock as the RX 6700 non-XT. It's an RX 6700.",
      ">The GRE (Golden Rabbit Edition) branding confuses me, 2023 was the year of the rabbit in China. It's been year of the Dragon in 2024.\n\nAMD never said GRE comes from Golden Rabbit Edition, that's why they continue using it, plus this name already has brand recognition.",
      "The GREG edition.",
      "We've had this chip since forever as the 6700 10GB",
      "naw it's just a rebadged 6700 (non xt)  \nnot THAT egregious",
      "Why are you spreading fake news? All GRE models are literally called ÈáëÂÖîÁâà in china and that literally translates 1:1 to golden rabbit edition.",
      ">Why are you spreading fake news? **All GRE models are literally called ÈáëÂÖîÁâà in china** and that literally translates 1:1 to golden rabbit edition.\n\nThat's not true. **There's no mention of  ÈáëÂÖîÁâà on any GRE products on chinese amd.com.**\n\n[https://www.amd.com/zh-cn/support/downloads/drivers.html/graphics/radeon-rx/radeon-rx-6000-series/amd-radeon-rx-6750-gre-12gb.html](https://www.amd.com/zh-cn/support/downloads/drivers.html/graphics/radeon-rx/radeon-rx-6000-series/amd-radeon-rx-6750-gre-12gb.html)\n\n[https://www.amd.com/zh-cn/support/downloads/drivers.html/graphics/radeon-rx/radeon-rx-6000-series/amd-radeon-rx-6750-gre-10gb.html](https://www.amd.com/zh-cn/support/downloads/drivers.html/graphics/radeon-rx/radeon-rx-6000-series/amd-radeon-rx-6750-gre-10gb.html)\n\n[https://www.amd.com/zh-cn/products/graphics/desktops/radeon/7000-series/amd-radeon-rx-7900-gre.html](https://www.amd.com/zh-cn/products/graphics/desktops/radeon/7000-series/amd-radeon-rx-7900-gre.html)\n\n[https://www.amd.com/zh-cn/products/graphics/desktops/radeon.html#tabs-32886884b5-item-ebdfea529f-tab](https://www.amd.com/zh-cn/products/graphics/desktops/radeon.html#tabs-32886884b5-item-ebdfea529f-tab)\n\n[https://www.amd.com/zh-tw/products/graphics/desktops/radeon.html#tabs-0a31ea901d-item-dd3584f26e-tab](https://www.amd.com/zh-tw/products/graphics/desktops/radeon.html#tabs-0a31ea901d-item-dd3584f26e-tab)\n\nHere are a few listings on [JD.com](http://JD.com), one of the largest etailer in China. Just GRE in the names, **no mention of ÈáëÂÖîÁâà anywhere.**\n\n[https://item.jd.com/100102125601.html](https://item.jd.com/100102125601.html)\n\n[https://item.jd.com/100100540622.html](https://item.jd.com/100100540622.html)\n\n[https://item.jd.com/100102125601.html](https://item.jd.com/100102125601.html)",
      "I'm now disputing what GRE means. I gave you a bunch of links where AMD said nothing about \"Golden Rabbit Edition\" or ÈáëÂÖîÁâà  being an AMD official name. It's simply GRE.\n\n**I'm still waiting for your proof where AMD said that GRE is Golden Rabbit Edition is the full, official naming.**\n\nUnless you provide an AMD marketing material or PR release, you're the one spreading fake news.",
      "AMD boardmakers are still releasing new GPUs 2 generations behind!  They are #1 in overproduction, if not anything else!",
      "Can we get those boxes outside of China too?",
      "I expected more from a Megalodon class card. üòÖ",
      "Exactly AMD is doing it more & more, where is the 7600x3d in rest of Europe?",
      "Your comment has been removed, likely because it contains trollish, antagonistic, rude or uncivil language, such as insults, racist or other derogatory remarks.\n\n*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/Amd) if you have any questions or concerns.*",
      "Ever heard of retcon? AMD realized its a bad move marketing wise to keep using GRE over the years despite it no longer being the rabbit year. Its just a bandaid fix to prevent people from realizing its original meaning through cencorship.\n\nGo to any independent chinese reviewer that did a gre review, all of them call it that.\n\nThe same naming concept actually happened before the GRE, in the form of the RX 590 GME, aka Golden Mouse Edition.\n\nAMD realized how damaging it is to brand recognition to keep changing names every year they need to release a defective product at a lower price point below the XT model so they kept GRE while removing the original meaning of GRE.\n\nIts common practise in the business world, a quick example being an esports organization called Gamers2 rebranding entirely to G2 forgoing its entire meaning because Gamers2 is such a dumb name."
    ]
  },
  {
    "brand": "amd",
    "generation": "6000",
    "tier": "mid",
    "matched_keywords": [
      "6750",
      "6750"
    ],
    "title": "RX 7600 XT 16gb vs RX 6750 XT 12Gb vs RTX 3060 12Gb vs RTX 4060 8 Gb",
    "selftext": "I don‚Äôt know shit about graphics cards, but I need to buy one. After doing some research on my own, these are the four options I came up with for something around 350‚Ç¨. But as I stated before, I don‚Äôt know shit, and there seems to be a lot of discourse about which is the better option, so I hope one of you who‚Äôs more knowledgeable can enlighten me.",
    "comments": [
      "6750xt is the fastest card in non ray tracing workloads, and has a good balance of vram to speed. 4060 is second fastest but suffers from 8gb vram, it will be OK at 1080p wouldnt go 1440p on it though. Some games can really suffer from the 8gb not all though. The 7600xt and 3060 12gb are about the same speed, the 3060 has the benefit of dlss. The 7600xt 16gb seems nice but it's not really fast enough to play games in a scenario where you would need it. \n\nTldr: I would get the 6750xt if you can still find it for a good price.",
      "If you video edit/ professional 3d work etc., 3060 12gb, otherwise if you're just gaming no rt it's the 6750xt",
      "Gaming? Go AMD. If you can swing a 7700XT it would be insanely good. 7600XT is right behind it, so that‚Äôs fine as well. Definitely not Nvidia in this price range.",
      "What resolution?\n\nThis changes things a little but if it were me I'd play @1440p and I'd pick the 6750XT if prices are okay still with low stock. \n\nOtherwise it would be the 7700XT id budget allows, if not a 7600XT",
      "In that forget Nvidia. The 760pxt will play 1080p very well and do ok in 1440p compared to the 6750xt, that does very well 1440p and has great p2p",
      "Picked up the 6750xt during the holidays. With a 7600x3d, it dominates at 1080 ultra on everything. Space Marine was the toughest title so far,  with average FPS in 70, with dips into mid 50's. Tried it at 4k with Space Marine, and managed an average 60 on low and medium settings with quality upscaling. Most other titles are 100+ fps ultra at 1080.\n\nNot telling you to trust my feedback alone, but I debated my options at length during the building process, just check my post history. The 6750 XT smokes the rest of your options if NVIDIA luxuries are not needed. I purchased at $320, and given the market at the time, it was evenly priced with the rest. I don't know how prices have fluctuated, but be aware that the 7700 XT has come down to $350, and if it's within your budget, you should pick that up instead, if the price difference isn't significant.",
      "It‚Äôs mostly for gaming but I‚Äôd also wanna do some video editing and do some hobby 3d work is the 6750xt still the best option?",
      "assuming you don't make money video editing them yeah sure",
      "Nah I don‚Äôt just for personal enjoyment and potentially social media preciate the help tho also the 3060 is like 40‚Ç¨ cheaper at 320 does that change anything",
      "nah it don't. 6750xt can be anywhere from 30% to 100% faster than the 3060",
      "Alright last question before I press order we‚Äôre both talking about the rx 6750 xt mech 2x 12gb (refurbished but don‚Äôt think thats an issue) cause there is also a 6750 trio",
      "generally a 3 fan should always cool better than a 2 fan card but you should only get the trio if it's the same price as the xt mech",
      "Nah the trio is almost twice as expensive unless I buy a second hand one really appreciate the help man"
    ]
  },
  {
    "brand": "amd",
    "generation": "6000",
    "tier": "mid",
    "matched_keywords": [
      "6650"
    ],
    "title": "went from a 1650 up to a rx 6650 xt",
    "selftext": "",
    "comments": [
      "Apes here don't know how to say CONGRATS ON NEW BUILD.\n\nCongrats bro xD It must be a massive boost. Also Welcome to team red üö©üòÅüö©",
      "I think you are supposed to use the non-split part of the split PCIe",
      "I currently have a GTX 1650 and a Ryzen 5 5600 (non-X). How noticeable is the improvement? I wanna update at some point.",
      "Thnx bro ye AMD is great (drivers work perfectly didnt have any issues)",
      "Your cpu cooler design puzzles me",
      "Oof its a helluva improvement but if you had to upgrade i suggest you get a rx 6700 xt when the prices drop i got mine for a reasonable price brand new so i got that warrantyüòä",
      "Doesn't really matter for a low power card like this as long as your psu isn't a bomb",
      "I think he meant the pcie power cable",
      "Like the part thats hanging now, the one that splits in to the one plugged",
      "No no, he's definitely on to something.",
      "What CPU do you have?",
      "2.5-3x the improvement going from 1650 to 6650 XT.",
      "Currently a ryzen 5 5600g i ripped out of a prebuilt but im getting a ryzen 5 5600 or an 5600x next week",
      "Why? It would not be such a stark improvement. Rather upgrade to something which will show a more meaningful improvement. Or I would rather spend that money on games.",
      "theres something else wrong with ur system linus tech tips did a whole video dedicated to amds \"driver issues\" and its usually something else with your pc thats causing instability and i can tell you i had minimal issues with amds drivers",
      "Perfectly smooth, all the time, on AMD.\n\nYou're confusing ini»õial game launch where the driver creates a cache in DX11 and earlier, that goes away in 5 min, with general stuttering.",
      "no, it is the other way aroud",
      "I'll be going from RX470 4gb to 7900XT 20gb\nSoon",
      "Notice any difference? ;-)",
      "Enjoy the serious jump. And possibility of RT here and there.\n\nAnd use FSR2 and mod in FSR2 wherever possible.\n\nAnd use driver RSR where neither FSR2 options are possible. 77% scale looks as good as native quite often."
    ]
  },
  {
    "brand": "amd",
    "generation": "6000",
    "tier": "mid",
    "matched_keywords": [
      "6650xt"
    ],
    "title": "PowerColor RX 6650XT Hellhound has 2689 MHz boost clock, features 17.5 Gbps memory - VideoCardz.com",
    "selftext": "",
    "comments": [
      "So with a 4% increase in frequency and a 10% increase in memory bandwidth, what kind of performance increase are we looking at? I have no idea if Navi 23 might benefit from the additional memory bandwidth.",
      "I'm pretty sure all of the lower end rdna 2 gpus had memory bandwidth problems, I mean the 6500xt is in its own league but the 6600 and 6600xt didn't have the most memory bandwidth, so I think this will help it get like 5-15% more performance which isn't a lot, especially considering that rdna3 is going to be launching soon with twice the performance as rdna2",
      "Jesus Christ, why everyone's so toxic? I sometimes forget that you can't comment in some subredits.",
      "I wish, but I think AMD is going to set the MSRP at $379, the original MSRP of the 6600 XT.\n\nPrices have gone down a lot and I don't expect them to use these refreshes to increase prices, but at the same time I don't see them lowering the MSRP yet (cause then the remaining stock of the original models would have to get huge pricecuts.)",
      "For $299?",
      "When you are comparing to card in the same architecture, yeah they actually do. While clock speeds certainly aren't everything and they certainly are usable for comparisons within a lineup, especially when comparing to a card with the same CU count.",
      "Man, it's depressing how much people forget that's exactly how things used to work.\n\nWe're *supposed* to get improvements in performance per dollar as the years go by.",
      "Must be Sapphire fans.",
      "RDNA3 is launching soon, but Navi33 is launching much later, or so are the rumors. These cards will still have a lifetime of almost a year I would assume.",
      "If you really believe AMD actively worked to make RDNA2 \"bad for mining\" then you're delusional.",
      "Other way around. Navi33 is first, Navi31 and 32 later",
      "RX 6500 XT has strange issues even running in PCIe 4.0 mode. An example of this was that in HUB's review the RX 570 4GB outperformed it in Rainbow Six Siege with the HD textures enabled.\n\nPerformance issues caused by textures are typically the result of not having enough VRAM and/or not enough memory bandwidth since as long as you can keep the textures in memory they should be essentially \"free\".",
      "I am just trying to figure out if this is a worthy upgrade from my 1080... alas its not. \nWould like to go for a 3060ti, if I could find one for a decent price. But alas eh no",
      "Why would they drop 80 dollars off the price while improving it?",
      "The 6500 XT had problems when used with PCIe 3.0 (6600 series less so): [https://www.techpowerup.com/review/amd-radeon-rx-6500-xt-pci-express-scaling/29.html](https://www.techpowerup.com/review/amd-radeon-rx-6500-xt-pci-express-scaling/29.html)\n\nBut I don't think memory bandwidth was the problem.",
      "You can't directly compare clock speeds between different architectures.",
      "I get that reference. Good times...",
      "Yeah,I made a mistake there,though the performance tier will probably be much different,and prices probably as well. Otherwise these midrange refreshes won't make sense at all... Guess we'll have to wait and see.",
      "lol, what a nonsense. RDNA2 is terrible for miners in general. RDNA1 is like like twice as fast in mining at the same gaming performance. That's because RDNA2 mostly scales in core frequency which does not scale mining performance at all, more CUs is what would scale mining in the first place and increase memory bandwidth will still be held back by low CU count in mining. I mean RX 5700 XT has around 80% higher hashrate than RX 6600 XT, while latter one has mostly even small lead in gaming performance.. So basically bad mining cards will be slightly less bad at it - that's it.",
      "CashGrab50XT^^TM"
    ]
  },
  {
    "brand": "amd",
    "generation": "6000",
    "tier": "mid",
    "matched_keywords": [
      "6750",
      "6750"
    ],
    "title": "Sapphire launches Radeon RX 6750 GRE 12GB Black Diamond edition - VideoCardz.com",
    "selftext": "",
    "comments": [
      "Golden rabbit edition Black diamong edition",
      "black diamond edition wowweeee",
      "What year is it again?",
      "Year of the Rabbit, it's in the name",
      "370$ lol",
      "The Golden Rabit Edition Black Diamond Editio. 6750XT what a name",
      "Lacy Black Thong Edition",
      "Well the lunar new year isn't here yet so technically it is still year of rabbit",
      "PC gaming is doomed",
      "350-range is for 4060.so a special edition 6750 is good for special edition collectors. if they wanted to be a good value they wouldn't bother with special cards inomo",
      "id say new pc games are, but there are a million older awesome games that are way better on new hardware",
      "Where can you buy this.",
      "It‚Äôs been doomed for a number of years now.",
      "I still can't find the Aurora version.",
      "So what would you replace \"is\" with?",
      "So what would you replace \"is\" with?",
      "Remember when the HD 7000 series got rebadged as the R9 290, the R9 390? They're not new to this, they're true to this üò≠üò≠",
      "You're thinking of the 280 and the 280X. The 290 and the 390 were Hawaii and Grenada, respectively. Both of those were new evolutionary steps of graphics core next architecture.  The 280 and the 280X were refreshes of the 7970 and the 7950, because they were just too competitive against what Nvidia had put out for the mid-range.",
      "Wat?",
      "Was doomed years ago."
    ]
  },
  {
    "brand": "amd",
    "generation": "6000",
    "tier": "mid",
    "matched_keywords": [
      "6700xt"
    ],
    "title": "6700XT - I want to confirm high idle consumption does not happen only on dual monitor setups (One monitor, 1080p, 144hz - Freesync disabled vs. enabled)",
    "selftext": "",
    "comments": [
      "First of all using Adrenaline and Afterburner together is a no no no, it can mess up things really bad. Delete Afterburner fast!",
      "I thought the high idle power consumption was an RDNA3 thing, not an RDNA2 thing?",
      "You gotta turn off fast boot. Or at least that's what fixed it for me.",
      "My 6800XT downclocks to \\~50-200Mhz VRAM and idles at 7 watts with triple screens (1x 1440P 144Hz and 2x 1080P 60Hz). So saying the cards without HBM memory can't downclock is clearly false.\n\nIt really seems to depend on the combination of monitors you use, and possibly even if you use Displayport or HDMI, idk. With so many different brands of monitors with different specs it's basically luck of the draw.\n\nThis applies to both AMD and Nvidia. RDNA3 does seem to have extra issues with absurd idle power use but RDNA2 does not, at least nothing worse than Nvidia.",
      "Why I'm saying configurations. It's easy to point fingers, but in the end NV has a similar issue, so even them with their giant reach can't handle all configurations.\n\nI'll just say, that with NV you are less likely to see the issue at least to the same severity, but there is enough evidence to say they aren't immune from it.",
      "I noticed the same thing with my 6800. Free sync was turned off and my vram clock speed was not clocking down so I tried turning on free sync and it fixed the issue.",
      "You have to disable fast boot in bios to solve the performance settings resetting issue.",
      "Yeah, sadly with the growth of higher resolution monitors with higher fresh rates, things had to change. I believe it would affect almost any generation of device, I've read users with Polaris10 having the issues.\n\nYou have to think of it in just a normal concept of \"more power.\" A device out putting 165hz versus one doing 60hz is naturally going to use more power. The level will vary on the hardware in the configuration why it can strike just about anyone if they have hardware that wasn't accounted for.\n\nIt's a nice big can of worms.",
      "Uh no.. FreeSync will clock the same as your framerate, anywhere between 48-144Hz. It only clicks to 60Hz if you're getting 60FPS in which case you're not gonna notice anyway. \n\nYou should always enable it. It's literally called Adaptive Sync, so you do NOT need smooth 144FPS at all. \n\nIt's V-sync that has certain negative effects.",
      "Funny, I get high idle usage on a single 1440p 144hz display if I turn freesync ON. With freesync off the usage is normal.",
      "It's a monitor configuration thing from things I've read.\n\nI've read some users buying a new monitor hit them with the clocks.\n\nIn the end, use some of the solutions and hope you get satisfying results.",
      "Yeah, I'm just saying, I never heard of the high idle usage in RDNA2 before, only started hearing about it with RDNA3.",
      "it's actually since GCN 1.0..",
      "If you're running at 60FPS, you still see 60 new images per second. That your monitor refreshes more often than that doesn't change anything. If anything it can introduce screen tearing. But it doesn't make it smoother.\n\nAlso any half decent, relatively cheap GPU will get you the high framerates you need anyway. It's extremely easy to get 100+ FPS nowadays. A $500 6800XT will serve you well. If that's out of your budget you can try the used market, or the 6700XT, also a GPU that handles 1440P high FPS gaming well. The 6700XT can be found for $200 used.\n\n**You seem to have an old system. What monitor do you have?**",
      "Im seeing people with this isue that i never saw on mine, im using 2 displayes same model and resolution, both on DP.\n\nA note: dont use msi afterburner, it will case some conflits with adrenaline",
      "No issue here 6950 XT on 144hz Benq I get a feeling this is monitor specific and I also use MSI afterburner for OSD and no It does not cause issues. Also OP maybe you should try the latest drivers 23.7.2.",
      "this is amd bug (if you have a monitor non 60hz (75/144 etc))\n\nmemory clock always max\n\n\\--\n\nfix:\n\n[https://www.youtube.com/watch?v=xhWfShsy\\_Bk](https://www.youtube.com/watch?v=xhWfShsy_Bk)\n\nor\n\n[https://www.reddit.com/r/Amd/comments/ex685k/if\\_you\\_have\\_the\\_full\\_memory\\_clock\\_bug\\_heres\\_the/](https://www.reddit.com/r/Amd/comments/ex685k/if_you_have_the_full_memory_clock_bug_heres_the/)\n\nor use 60hz",
      "I only use afterburner for monitoring",
      "Why would you ever turn FreeSync off though.\n\nI have a triple screen setup, 1440P 144Hz and 2x 1080P 60Hz. The two 1080P monitors do not support Freesync, yet my 6800XT idles at 7 watts powering these 3 screens. So idk if it's truly related to FreeSync. I seem to have won the jackpot at 50-200Mhz VRAM clock at 7 watts.\n\nIt seems to be total luck of the draw regarding your monitor combinations, for both Nvidia and AMD. RDNA3 does have extra issues but RDNA2 is the same. Nvidia cards can also experience higher idle power consumption depending on the monitors.",
      "Are you saying that memory clock max is a bug?\n\nAlso those fixes aren't universal. In the OP's case it would be enabling freesync. That's when it idles. I had the opposite experience for example, inhzd to disable freesync on all monitor osd's to make it idle"
    ]
  },
  {
    "brand": "amd",
    "generation": "6000",
    "tier": "mid",
    "matched_keywords": [
      "6750",
      "6750"
    ],
    "title": "Refurbished Radeon 6750 xt mech 2x 12 gb v1 (359‚Ç¨) vs new gigabyte GeForce 3060 gaming oc 12 gb 2.0 (319‚Ç¨)",
    "selftext": "I wanna use it mostly for gaming and possibly video editing but I‚Äôm really struggling with making a choice cause everyone is saying the 6750 but when I look at the 6750 people are saying the mech 2x is the worst possible model",
    "comments": [
      "I would rather have the 6750.",
      "get it anyways.",
      "Worst possible model but you are getting  40% more performance for 10% more of the price",
      "AMD, I have that exact card it‚Äôs good. Cons of amd is that it has worse rt performance. Other than that I don‚Äôt really use upscalers so idc about dlss but maybe u might",
      "Which country, 7700xt might be similar pricing",
      "The 6750xt is superior to the 3060.",
      "you dont need a crazy cooler for a 6750xt even the lowest end models perform fine. id take that 6750xt for the significantly more powerful raster (closer to a 3070ti than the 3060) you may get better results with video editing but if gaming is your priority a few extra mins editing isnt worth losing 40% performance in games imo.",
      "Get the 3060 for DLSS4.",
      "It‚Äôs MSI‚Äôs lower end sure, but I had a 5700xt mech that still runs like a champ and has had constant abuse since its release. After 4 years of service I repaded and repasted then it went to my a new home.  I‚Äôd argue that anything Asus is inferior. I‚Äôve RMA with ASUS 4x now.",
      "It's a brand new premium model. DLSS performance mode IS faster than 6750 native. I had both card, returned it and got a 5070ti.",
      "The 6750xt is 40% faster, a 3060 on performance mode upscaling isn‚Äôt as fast.\n\nThe 6750xt performs like a 2080ti, 3070 or a 4060ti. \n\nThe 3060 performs like a 1080ti, 2070,  or 5700xt."
    ]
  },
  {
    "brand": "amd",
    "generation": "6000",
    "tier": "mid",
    "matched_keywords": [
      "6750",
      "6750"
    ],
    "title": "Out with the old and in with the new! [XFX QICK RX 6750 XT ‚Üí SAPPHIRE PULSE RX 9070]",
    "selftext": "",
    "comments": [
      "The GPU got smaller!",
      "Yet quieter and cooler!\n\nVery efficient card.",
      "I can't tell if you're being serious or not üòÇ it's a massive upgrade. \n\nIt's like 80% faster on average and doesn't even compare in RT and FSR 4.",
      "It was from Overclockers UK. The Nitro+ model looks great, it's a beast.\n\n9070 is a best in general! Managed to get it on launch day for ¬£539.",
      "I just ordered my NITRO+ today! The waiting paid off üí™üèº",
      "Oooh! Newegg? I‚Äôd love to get my hands on a Nitro+ ü§§",
      "i do have an question, is all the 9070 non xt come with 3 fans configuration ? i though at least the pulse from sapphire came in two fans....\nMy case is limited to 280mm max...",
      "It does, that's the Sapphire Pulse you're seeing in the third picture, the 3 fan card below it is my old XFX 6750 XT.\n\nThe Sapphire Pulse 9070 280mm long, it's a great card...quiet, cool and efficient. Great for 1440p/4K.",
      "Sweet!\n\nBeen loving this thing, it's made me jump back into gaming again. Wait till you see FSR 4, it's incredible. \n\nAlso idk if you've heard or seen it, but there is a mod called OptiScaler which allows you to inject FSR 4 into games that only support FSR 2/3. \n\nI was playing with it in AW2, check out the difference.\n\n[https://youtu.be/070vbz\\_Eu\\_A](https://youtu.be/070vbz_Eu_A)"
    ]
  },
  {
    "brand": "amd",
    "generation": "6000",
    "tier": "mid",
    "matched_keywords": [
      "6750",
      "6750"
    ],
    "title": "Help to choose budget GPU RTX 3070 Palit/Gamerock, RX 6750 XT, RTX 4060",
    "selftext": "Hello, please to make a choice with budget GPU.  \nSo far from google i got that 4060 only good in power efficiency, but loses in raw FPS. But i was wandering if 4060 performance is smother in newer games and there is going to be less problems in future.\n\nMby there is some GPU that i should look into it. Going to take they from local \"ebay\".\n\nRight now im on Ryzen 5600, RX 580 PCI 3.0x16. Im going to upgrade motherboard in future, but right now its not much performance lose compare to PCI 4.0. And im sticking with 1080p monitor in a near future. ",
    "comments": [
      "6750 xt because the vram then 3070. I say this as a 3070 user I wish I went for a 3080 because of the vram. 4060 is just shitty like 15% worse than a 3070.",
      "Thank you"
    ]
  },
  {
    "brand": "amd",
    "generation": "6000",
    "tier": "mid",
    "matched_keywords": [
      "rx6750"
    ],
    "title": "What GPU to upgrade from RX6750 XT Dual",
    "selftext": "Hey, so i currently have the asus RX6750 XT Dual and I am thinking about upgrading. I am mainly playing CS2 and Overwatch 2 and I would like to also livestream these games. I currently own a 240hz monitor but want to upgrade soon to 360 hz or maybe higher. My Processor is a AMD 7800X3d.\n\nLet me know you recommendations please, I would buy a used one, since I don¬¥t have a unlimited budget",
    "comments": [
      "The RX 6750XT is too close in performance to the RTX 3070 and RTX 3080, because they are within the 20% range above what your RTX 6750XT can do, so, your only choices would be on AMD's side this would be the RX 9070XT only and with Nvidia the RTX 4070ti Super and RTX 4080 are your only options. There is no Intel ARC video cards that can beat the RX 6750XT 12 GB card.\n\nI don't think you have any option really if you want to save money other than to just wait a couple more years and either get used cards mentioned or look to the next generation cards in about two years from both AMD and Nvidia. I don't think Intel has anything that can beat an RTX 3070 yet.\n\nPlease note - If you decide that the RX 7800XT 16 GB is good enough, then on the Woot website the Sapphire RX 7800XT is $599, and on the Newegg website there are more than half a dozen brands that sell the card from 540 to 7730 US dollars.",
      "7800 xt decent jump.. but at right price",
      "thanks for your reply  \ni really hope intel brings out some higher performing cards...  \nI guess ill wait for the upcoming amd cards this year and see how they perform in real scenarios"
    ]
  },
  {
    "brand": "amd",
    "generation": "6000",
    "tier": "mid",
    "matched_keywords": [
      "6650"
    ],
    "title": "Looking to upgrade from my RX 6650 XT",
    "selftext": "As the title say.  I have an AMD Ryzen 5 5500 as a CPU.\n\nWhat can I get that will allow me to see a nice jump in performance? My budget is arround 500‚Ç¨. Big max at 600.",
    "comments": [
      "Tbh i would use that money to upgrade both ur gpu and cpu. Get a 5600x or a 5600x3d depending on ur budget and maybe the new rtx 5060 ti if y can find it for msrp ( sell ur old components too ) u can probably go higher cuz idk how the prices r looking where u live and ur psu could be an issue too. I‚Äôd rather upgrade everything equally than dump everything in the gpu and have it bottlenecked",
      "Okay, thank you for your input. I will look into it. If I have to change both I might aswell change the whole computer haha",
      "Find at MSRP. ROFL. U mean the MSRP that predates tariffs?",
      "If u see it that way sure, maybe not the answer u were expecting but this is how i see it, u could just get a 5060 ti but im just saying"
    ]
  },
  {
    "brand": "amd",
    "generation": "6000",
    "tier": "mid",
    "matched_keywords": [
      "rx6700",
      "rx6700"
    ],
    "title": "The RX6700 is a 1080p/1440p beast and probably the best VFM right now.",
    "selftext": "Hey there. I‚Äôm just making the following post to share my appreciation and to say that I‚Äôm so impressed with the RX 6700. \n\nI‚Äôve been a NVIDIA boy since forever, I only owned a RX580 for a secondary PC but I sold that too. \n\nMy main rig has a RTX3070 Ti. My second rig now uses a RX6700. \n\nI never felt so exciting for purchasing a GPU as I feel about RX6700. I‚Äôve only bought for 350‚Ç¨ plus the 2 games from the AMD promotion which I sold minimising the exposure to 300‚Ç¨. \n\nThe card is amazing, it‚Äôs perfect for 1080p and can rock 1440p as well as I tested them on both monitors.\n\nThe consumption power is nuts! 120W and a temp of just 54oC under stress test with just the default fan curve. VRAM set at 2100 fast timings, min freq at 2500 max at 2600 , rock stable at 1100mV (I‚Äôm just now doing the appropriate tests to lower the Mac), I mean the card is just killing it.\n\nWell done AMD,\nYou‚Äôve earned a huge fan!",
    "comments": [
      "The 6700XT is even more impressive. Especially considering anyone who owned a 5700XT prior and sold it during the crypto boom practically got a free upgrade.... it sips power runs quietly and runs 3440x1440 no worries",
      "Yup, did this. Bought a 5700xt for ‚Ç¨300,- just before the price went mad. A year later I sold it for ‚Ç¨600 and bought a 6700xt for the same money.",
      "I have a 3080 and a 6750 XT (preeetty much a 6700 XT but you have the privilege of paying more) and can vouch for a similar observation. \n\nI lent away my 3080 rig for work purposes and kept the 6750 XT at home. It produces enough FPS for 1440p-gaming in my experience.",
      "On 1440p in Warzone which isn‚Äôt the best game to benchmark (I know) paired an Intel i9 9900K I was at about 130-140FPS average out of the box but using low to medium settings. In PUBG I was running 210+ FPS. I did a 3D Mark test as well but I‚Äôd need to search to find the link.\n\nI never felt so enthusiastic about a GPU purchase. I even convinced my friends to go for a RX6600XT as they want to play in 1080p. And it was hard to do as they were green fan Bois . üòõ",
      "Shit I managed to get a 6700XT for MSRP on launch day and sold my RX 580 for a high enough price that I basically broke even. Those were some crazy times.",
      "Thanks for the post. I am going to grab one for the new year. It looks amazing vfm. It rocks 1400p hard? Glad to hear the temp and power are low. I like low power / temp. It feels like good engineering.",
      "yep the 6700xt and RX6800 are peak units in terms of power/performance ratio, it's legit absurd and rarely seen.",
      "Im still hoping the 7700XT will be equally impressive just with a bit more juice. A 6700XT without the crypto boom selling of a 5700XT isn't a meaningful upgrade for the price for me.",
      "The Callisto Protocol and Dead Island 2. It was Sapphire Pulse. I‚Äôm in Europe too (Greece).",
      "Did you have to do anything special to get fast timing to work? I just get BSODs when i try",
      "In AMD favour games it does better obviously. In Warzone 2 I noticed for reasons unknown that it outperforms the 3070 Ti.",
      "Its slightly better than 6650 XT  \\[like 5 -10% ?\\] and 2 more gb of VRAM, think its a bargain for that price with 2 games for sure. Which games tho ?\n\nAlso what brand ? I have seen some Powercolor Fighter and its the worst model and stuff like MSI Mech also meh, but i guess for that price and not so high watt usage then temps should be fine \\[can always undervolt as well\\] . For that price in Europe you can buy rtx 3050, im really mad at team green in the last couple of years for those prices, dont need DLSS and RT either.",
      "I just got a notification that here in Europe the 6700XT brand new dropped to ‚Ç¨300!\n\nThe used market will go down to ‚Ç¨150-200 tops.\n\nIt's most likely the best value GPU around right now. I paid ‚Ç¨750 for mine lol.. But it's a 1080P monster and still a good medium-high setting GPU for 1440P.\n\nThe 6700XT at this price point is unbeatable, delivering 3070 performance, and if you're willing to buy used (which is perfectly fine if you pick it up in person and get a demo etc) then it is sick value. Used cards often aren't even that old.",
      "Ah, neighbour then - Im from Bulgaria, Sapphire Pulse is way better in my opinion compared to the ones i mentioned - budget models of Msi Mech and Powercolor Fighter.\n\nThose 2 games are not the best \\[Calisto Protocol was hyped \\] but still seems like great value Sapphire Pulse plus 2 games for 350 euro, not sure i can find so amazing deal in my country, may be 350 euro without games and not Sapphire pulse.\n\nRyzen 5600 \\[X\\] and 6600/6600 XT /6650 XT / 6700 seems like great deal lately for mid range PC 1080p/1440p money and performance wise, cheers.\n\nEyeing an upgrade myself soon enough ryzen 2600/rx 570 4gb and would be willing to upgrade to 5600 non X cuz better price here like under 150 euro and one of the mentioned above cards depending on price, Sapphire is my favorite brand for AMD Radeon for sure tho.",
      "I paired with a R5 5600X replacing my 2600 so I‚Äôm overally satisfied with the upgrade on a secondary PC.",
      "Yes its a great value, i was tempted to buy it and call it a day but in the end i ordered the rx 6700xt nitro+ (the non oc model) for 485 ‚Ç¨ in my country.\nI personally thought that if i have to upgrade my gpu (i have right now the rx 580 nitro+) i will buy a nitro+ (i am very pleased my 580 nitro+)again if the price isnt outlandish.\nIn my country the sapphire 6700 cost 390( the pulse edition) so i thought that for 100 more i will buy more performance more vram more features (top end model) and better temperatures .. and it was inside my budget (500‚Ç¨)\nAnd also it would be better combination with my rest of the system r7 5700x 32 gb 3200 cl14 ddr4 , 1440p 180hz monitor.",
      "For 300 bucks ? Gonna grab them in my local european retailer , oh wait, it's 500 euros.. nevermind",
      "No I simply followed a YT video who tuned the 6700 non XT. Set the memory at 2112 and Fast Timing enabled. Though Jayz2cent claimed that in his tests it made no difference at all. (Having it enabled and disabled).",
      "Bought mine last week (6750XT same chip as 6700XT) as christmas present since i had years to upgrade (last GPU upgrade being my r9 290), im pretty satisfied so far, the card is very competitive if you like high refresh rates displays but it can do better if you don't mind RT, i found 4K being plausible with my Freesync monitor.\n\nHere some things i noticed:\n\n1200mv as stock voltage is crazy, this Navi 22 chip can be very efficient, totally waste of power + heat.\n\nOverclocking (uh...) was a very complicated thing at first coming from old gen GPUs had no prior experience how boost + undervolting works so some research had to be done.\n\nMy model is the MSI Gaming X Trio, the cooler is probably overkill but coming from sapphires Vapor-X design i didn't want some generic two fan cooler.\n\nDunno if AMD gave all good Navi 22 chips to 6750XT, i can actually overclock the card to 2950Mhz with 1085mv but the memory is unstable so im running rn 2750min Freq. 2850max same voltage as above but with maxed out memory and fast timings.\n\nAlso, it might sound cringe but i like how this GPU has the same CUs/Cores configuration as my dead R9 290, it's like my old GPU still lives on xD",
      "How does it compare to the RTX 3070 Ti in your main rig?"
    ]
  },
  {
    "brand": "amd",
    "generation": "6000",
    "tier": "mid",
    "matched_keywords": [
      "6650"
    ],
    "title": "Your experiences with the RX 6650 XT",
    "selftext": "Hello, \n\nI currently have a MSI RX 580 8GB Armor, and I experience a lot of driver crashes (timeouts), especially while booting up games. \n\nI thought of getting a new card, as the RX 580 also isn't up2date any more. \n\nI am kinda fed up the AMD graphic drivers, so I thought of switching to NVIDIA. I thought of an RTX 3060. (My CPU is i5-10400F)\n\nBut now I saw the RX 6650 XT, which even seem to perform a little better than the 3060 and it is cheaper in my country. \n\nBut - Do you guys have any issues driver timeouts related (Using the latest drivers, no overclock, no underclock, no undervolt)? This would be important for me to know.",
    "comments": [
      "The 580 is a rock solid (driver) platform now.\n\nIf you are getting crashes you have actual problems. Driver timeouts can be anything from dying cards to weakening power supply transient spikes, or even bad PCI lanes on mobo.\n\nI would start by checking for GPU sag, maybe repaste the card, swap PCIe slots, and then swapping or borrowing a different PSU.",
      "GPU drivers crashing can be borderline anything, having my ram running with xmp on was crashing my GPU drivers üòÇ",
      "> swapped to an nvidia card, poof, problem‚Äôs gone. \n\nReplacing an old, broken card with a working one is usually a solution to it being broken.",
      "I had a Sapphire RX 6650 XT Nitro+ for about a month, but the fans on it died and I had to return it to the store.\n\nIn return, they sent me an MSI RX 6650 XT Gaming X.\n\nAside from the minor setback of the fans on my Sapphire card, in terms of software, both cards performed well. I used the 22.11.1 and 22.11.2 drivers and had no crash, timeout or anything like that.\n\nSingle monitor, Windows 10.",
      "In which country it's allowed to marry GPU?",
      "Lol @ RTX Remix on a 3060ti. I just bought an NVidia card & listing RTX remix as a plus at the 3060ti level is beyond silly. Dlss advantage is very marginal, *slightly* wider support for now, quality basically the same. At this price point, I'd go for whichever card offered more raster performance for the price. Driver issues are very difficult to quantify either way. The best you can do is look for widely reported issues in games or software that you use a lot; ie that matter to you.",
      ">  nvidia drivers will handle it way better \n\nAs in, they just produce very random errors/corruption instead of actually catching the issue and crashing.\n\nThat is likely better for casual gamers, but *horrible* for professionals.\n\nAs always, stress test and error test your RAM!",
      "Zero issues with the games I play on the RX 580. Could it be a cable problem? Even the ones that come with the monitor can give you trouble (don't know if driver timeouts in particular.)",
      "Murica, baby.",
      "If I were you I'd pay the Nvidia tax... while my switchover to AMD has been pretty trouble free there were issues with the drivers that I had to troubleshoot (drivers > 22.5.1 unstable, display timeouts in Chromium browsers with video playback).\n\nConsidering how long AMD seems to be taking to release stable driver iterations I'd have stayed on Nvidia.\n\nI will say that on 22.5.1 it seems to be rock stable so take that for what its worth.",
      "It matches a 6700XT while being $70 more expensive. At a price of about $410, in the US, that means that it trades blows with a card while being about 18% more expensive.",
      "I recently upgraded my wife from a GTX 1060 3 GB to a 6650XT. As far as I know, she hasn't had any issues.",
      "You just proved it wasn‚Äôt the drivers by switching hardware lol.",
      "Hmm. How beefy is your power supply? Any fluctuations in voltage on the rails when the card is loading textures? (HWMonitor can watch this for you)",
      "I recently upgraded from an RX 580 to an XFX 6650 XT. It‚Äôs been very stable for me. If you‚Äôre thinking about anything raytracing related, forget about it with this card. Even the Unreal 2 demo is flaky with frame rates. I didn‚Äôt care about that, I just wanted to take advantage of my ultrawide 1440 monitor. And for non-RT it does a very good job at that.\n\nWhile newer games will drive temperatures higher than the RX 580, older games tend to run cooler in my experience. Plenty of ventilation in your case is still a good idea. \n\nBe sure to enable SAM on your motherboard, it really makes a difference in performance with the 6650 XT. Especially with preventing stutters and drops. \n\nFSR is pretty neat too, it definitely ups your frame rates for more demanding games. Just understand that thick vegetation and stuff like that can really break the upscaler, so if the graphics start looking chunky, that‚Äôs the first thing to adjust. \n\nHope that helps!",
      "Why would he buy the nvidia card instead of the amd one? The amd one is cheaper, yet surpasses the rtx 3060 ti by a bit.",
      ">Even the choice of cable can cripple a GPU nowadays. (Looking at you DisplayPort Pin20)\n\nOr just power cable splitters..",
      "> I currently have a MSI RX 580 8GB Armor, and I experience a lot of driver crashes (timeouts), especially while booting up games. \n\nThat almost certainly means the card is unstable, due to damage to itself, or other components in your PC failing/being unstable.\n\nDriver timeout just means the driver stopped responding, not that it actually caused that to happen by itself. The card crashing because it, for example, hit a bad voltage dip while the VRMs shift gears during a game launch, can also cause that if it falls short of completely crashing the system.\n\nHave you attempted to underclock the core and especially VRAM? Also, what PSU are you using? Any problems not caused by the GPU itself being bad will continue to haunt a newer GPU, often worse due to the architectures being more sensitive to electrical antics.",
      "Yeah. It has honestly gotten very difficult to troubleshoot nowadays, and it doesn‚Äôt help that seemingly every card is pushed to some voltage or performance limit out of box nowadays. Even the choice of cable can cripple a GPU nowadays. (Looking at you DisplayPort Pin20)",
      "Frankly, the first time you wiped with ddu should have told you it‚Äôs not the problem (weekly wipes would be irrelevant). \n\nBut I sympathize, because it‚Äôs getting nigh impossible in windows to troubleshoot GPU issues without advanced knowledge (finding break points in voltage, memory timings etc). \n\nFor lots of people they never find why a particular card just ram like crap in their rig (and not someone else‚Äôs)."
    ]
  },
  {
    "brand": "amd",
    "generation": "6000",
    "tier": "mid",
    "matched_keywords": [
      "6650xt"
    ],
    "title": "I7 9700F and RX 6650XT?",
    "selftext": "I7 9700F and RX 6650XT combo? \nAre they still enough?\nBottleneck at 1080P gaming?\nThis Upgrade will be last upgrade of my old setup.",
    "comments": [
      "The 6650 XT is pretty capable at 1080p, on par with the 7600. Not sure about the CPU.",
      "Yeah this should be okay for most games. Obviously both components are aging, the 8GB frame buffer and the 14nm++++++++++++++++++++++\n\nEdit: I salute any budget banger pc like this. So reasonable!"
    ]
  },
  {
    "brand": "amd",
    "generation": "6000",
    "tier": "mid",
    "matched_keywords": [
      "6650"
    ],
    "title": "Should i get a 6650 xt or a 4060?",
    "selftext": "I'm a newbie to graphics cards :)",
    "comments": [
      "Why not a 6700XT?",
      ">4060 is outdated\n\nWhere the hell do you live? In 2050? Lol people still going strong with a 1080ti these days.",
      "Check your monitor first, then go from there. Black Friday in 6 weeks. Cyber Monday so huge deals",
      "That doesn't make it outdated. There's GPUs from many years ago that still work fine for a lot games. If you can get a good deal on a 4060 then it's probably worth it depending on what you want to do on your PC. Like, I have a 3060, everyone says it's not worth it but it still runs games pretty well at 1080p. Just because it's the low end version of the 40 series, does not mean it's outdated.",
      "4060 is outdated, pick 4070 at least, or simply 6700xt.",
      "outdated, what do you mean? you can still enjoy games using something \"outdated\" like an rx 5700xt",
      "stream, ia , 3d , rt    4060   \npure gaming 6650xt",
      "6700xt",
      "What's your budget?",
      "Look for used 2080ti/6700xt/6750xt/3080/6800xt\n\npreferably locally and tested working in front of you before purchase,  \nif bought through ebay or other test it thoroughly when you get it and Read the description carefully of any card being sold (like if its for parts only/not working) if any issues come up report them with photos and ebay customer service is very good generally.",
      "I have a 4060 and an Rx 6750 xt. They run basically neck and neck. 4060 over a 6650 all day everyday.",
      "That's not really a good comparison. 4060 wins that matchup all day every day.",
      "Same price? 4060, but there's also the 6750XT which is better than the 4060 and only costs like $10-20 more",
      "Never 4060",
      "neither.\n\nget a 3060 12 GB or a 6700 xt.\n\nyou want at least 12 GB vram as 8 GB vram is a major issue in lots of new games.\n\nif all you can afford is an 8 GB vram, then the rx 6600 should be the least shit option, but as you mentioned at least a 4060, the 3060 12 GB is clearly on the table.\n\nthere is also the rx 6800, which if you can get it for 360 us dollars new would be a great deal,\n\nbut if not the 3060 12 GB or 6700 xt would both be vastly better options than the 4060 8 GB insult at least.",
      "Save up that extra couple hundred and buy 4080 super or 7900xtx man, you want it to be future proof( play games years on like butter and without updating ur card)",
      "4060",
      "yeah sad reality, is why used 2080ti is such a hot item rn honestly.  that or like a 6750xt/6700xt\n\n8gb gpu's run into more issues more often now days and when buying a gpu I'd hope user can get at least 3-4 years out of it at best.  6-8gb gpu's will have to be careful with some games and tweak settings to avoid hitching especially as time goes on.",
      "12gb one is ok, but yeah its a bit underpowered for price.",
      "me using gt 1030 4gb rn:"
    ]
  },
  {
    "brand": "amd",
    "generation": "6000",
    "tier": "mid",
    "matched_keywords": [
      "6750xt"
    ],
    "title": "First time going AMD! Really looking forward to this RX 6750XT",
    "selftext": "Any tips on getting most out of it?",
    "comments": [
      "You know, people do complain about the prices of GPUs nowadays, which is fair enough, but whenever I see a comparison like this it always reminds me that modern cards in general tend to feel way more premium than they used to.\n\n&#x200B;\n\nCongrats on the upgrade! A few things you may want to investigate:\n\n&#x200B;\n\n* Does your system support Smart Access Memory (SAM)? It can produce a small gain in specific titles.\n* What resolution is your display? If it's at least 1440p you may be able to use FSR with little visual degradation (in Quality) to get a bit more juice out of your card (or run it more quietly if you're maxxed out in framerate). This goes double for 4k, where the technology really excels, IMO.\n* I've personally found the open source Linux drivers to be quite stable; not sure if there's an open source Windows equivalent.\n* Have fun!",
      "Each time I see a DirectCUII card it remembers me \"the good ol'days\" I dunnow why but this is so symbolic of an entire era ! This DirectCUII and the MSI TwinFrozr !",
      "Make sure SAM is on, if it's greyed out then you'll need to enable Resizable BAR in your BIOS.\n\nRadeon Software > Performance tab > Tuning > SmartAccess Memory\n\nAlso in this tuning tab you can undervolt your GPU and set a custom fan profile if you'd like. By undervolting you can cut power usage by a decent amount while keeping the same/better performance. This resets every driver update so make sure you export a profile after you're done tuning and reapply it after you update.",
      "Yup, that card quality shift definitely started gaining a lot of momentum with the Nvidia 10 series. \n\nEven backplates were very rare to find on any brand/AIB‚Äôs GPU models. By the time the 30 series/6000 series hit it was the norm for almost every model down the stack. \n\nAIB‚Äôs must have finally realized that people shop with their eyes a lot of the time.",
      "I got the 6750 for Christmas; it replaced my 5700. The 6750 has been outstanding for me... fast, stable, and cool. Great performance to price.\n\nHere are my Radeon settings:  \n\n\nhttps://preview.redd.it/izgji0okbf5b1.png?width=1963&format=png&auto=webp&s=8da76c21379282461e863e1d696391d1f381f8db",
      "> Any tips on getting most out of it? \n\nPlay around with Adrenalin's Performance tab. Enjoy undervolting and playing around checking what you can get from the card's specs/speed/power draw etc.\n\nI recommend trying Radeon Chill. I turned it on once not expecting too much, and it turned out to just seamlessly let me play while eating less power.\n\nAlso, Adrenalin offers customised settings per game. Depending on what you play, you may want to sometimes activate Chill, other times Boost, and so on. Enjoy!",
      "Out of those options, you should definitely be looking at the 6800xt for a reasonable upgrade over a 2080ti.  I upgraded from a GTX 1080 at the start of this year to a 6800xt and I've been thrilled with the performance.  It's over double the performance of my 1080, and more importantly, should perform well for the next few years.  As far as coil whine goes, it's luck of the draw.  All I can tell you is my own experience.\n\nI bought an XFX 6800xt Merc, and I'm running it on an 860w Platinum PSU.  My card had light coil whine, which got drowned out as soon as any fans started to spin up seriously.  Five months later, and all coil whine is either gone, or so slight that I can't hear it.\n\nI would highly value performance over some coil whine, but it obviously bothers some people more than others.  In \"most\" cases, if cards do have coil whine, it tends to eventually shake out and quiet down, assuming there isn't a power issue of some kind.  But, there is no definitive way to make sure you get a card without one.",
      "Seen so many people moving from Nvidia to AMD because of price/performance but in the end... Market share doesn't move a bit. It's tragic",
      "I remember the 8800 GTS very fondly.",
      "One more thing... be sure to turn off Windows' driver updates. For some reason, every once in a while, Windows will take it upon itself to replace the Radeon driver with its own driver, which prevents my games from loading. [Here's](https://pureinfotech.com/disable-automatic-driver-install-windows-11/) how to turn off Windows driver updates.",
      "I used to have a reference 6700xt and Sapphire Nitro 6800xt se. I absolutely loved the cards. Like the previous people before me stated. Manually go download the second latest driver. Use DDU to delete all other drivers on your system. Then install the second latest driver. No beta drivers. Watch for new drivers. Usually I check once a month. Once a new one comes out move up one driver. I think you'll enjoy your new card.\n\n If you do have any issue's. Don't hesitate to reach out to someone either here or AMDs reddit. Free help might not always be the best but there's people here with alot of experience and knowledge. That would be willing to help you resolve the issue\n\nWelcome to team Red.",
      "It‚Äôs not *terrible* advice considering that there was an incident in the past with a rare case of [radeon drivers bricking windows](https://www.neowin.net/amp/amd-confirms-updating-radeon-gpu-drivers-can-brick-your-windows-installation/).\n\nSo if you‚Äôre running completely fine then there‚Äôs no reason not to wait for an update.\n\nAnd FYI, I‚Äôd say the same thing about every single company especially nvidia. They have occasional issues as well.",
      "Watch AncientGameplays. He has videos on AMD settings optimizations, troubleshooting issues and patch rundowns.",
      "People dont believe when I tell them that I never had single problem with the XTX SWFT\n\n6700XT I got . no driver issues whatsoever , runs every game efficiently , stays cold, fans not too loud, no coil whine.. \n\nTell them that they are very good for what they offer !",
      "To some part depending on the Model its also for cooling and making the card more stable cause heat sinks get heavier.",
      "Welcome brother",
      "Stable undervolt for me on the Powercolor Red Devil counterpart is 1130 but obviously test different values out",
      "NGL seeing that 8800 made me all warm and fuzzy inside‚Ä¶\n\nThe 6750 is a great card, just whack SAM on and enjoy!",
      "Nice bro, my last Nvidia card was GTX760 from asus. Nice card, very quiet. After that I've only had AMD cards though, Nvidia is not worth it anymore.",
      "I just got an RX 6700 and it's already so efficient, I can't wait to see what it does when I undervolt it."
    ]
  },
  {
    "brand": "amd",
    "generation": "6000",
    "tier": "mid",
    "matched_keywords": [
      "6700xt"
    ],
    "title": "Cyberpunk 2077 | FidelityFX Super Resolution on Linux | RX 6700XT | FSR",
    "selftext": "",
    "comments": [
      "It really does look the same to me, I mean...there are probably differences but is very hard to perceive.\n\nThe improvement in FPS though, pretty sweet.",
      "CP2077 is really perfect for FSR - the game is never super sharp to begin with and there is a lot going on.\n\nWould be nice if they implemented FSR in an upcoming patch.",
      "YouTube videos not good to see differences without zooming. But I do appreciate it looks close to the same either way.",
      "Unfortunately, it does not work on Windows as of now, I mean specifically on Cyberpunk. OP did on Linux using some mod...but yes FSR works on a few other games\n\nhttps://www.amd.com/en/technologies/radeon-software-fidelityfx-super-resolution\n\nHere is a link to supported games *on* Windows with official support.\n\nHope it helps! :)",
      "It works on Linux as a form of fake fullscreen window. You know how a sub native resolution window can get stretched to fill your entire screen? Well, you can change a setting so the window is upscaled using FSR instead of the regular Bilinear Filtering, that's how it works.\n\nIt haven't been done yet, but it's possible to do the same on Windows. [This program](https://github.com/Blinue/Magpie) does that with a variety of high quality upscalers but it doesn't has FSR yet. The next version, however, will.",
      "Pretty acceptable quality if you're not zooming or pixel peeping.\n\nhttps://imgsli.com/NjI4Nzk/4/5",
      "I made the video, so I was zooming in and out closely, so I could tell the difference, because I know \"where\" to look. But my girlfriend for example could not tell which one is which, showing her the pictures side by side.",
      "The thing is, your eyes do not zoom in no, but when you actually look at the whole image from a normal viewing distance, all those small pixel peeped details together give a visual downgrade that is  noticeable.\n\nSure, for somebody that just wants to be able to scrape by, that is a sacrifice worth making, but it is not close to native or no difference. And that is at 4K, at lower resolutions it is really obvious. \n\nI was perfectly fine playing games using gpu scaling and a reshade sharpening filter on my shitty laptop, \n\nFSR is a tiny bit better then that, Nvidia's new \"Sharpening +\" or AMD's CAS will give similar results with other simple upscaling methods.\n\nHowever it is easier for people to just toggle an option in the game menu, but for anyone who has been doing upscaling + sharpening before I just don't see where the hype is coming from. \n\nI do however feel that AMD needs to provide some other upscaling solution using similar tech to Nvidia's DLSS or some form of temporal solution, their GPU's are similarly priced and don't provide a real answer to that, FSR is  not enough to compete.\n\nIt is a good thing to offer something to people that don't have any upscaling solution or don't know how to get a decent image using regular upscaling techniques. \n\nBut let it be an extra, not an alternative to a far superior tech.\n\nI am looking to buy a product that offers me as much as possible for similar prices and AMD has not convinced me with this, I don't care about the company that makes it, but I do want to buy a product and not feel like I am missing out on something.",
      "Does it work on Windows too? Would love to test this with my 6900XT.",
      "\"DLSS will never be mainstream as long as only RTX cards can use it\" Lets see, COD? DLSS, Warzone? DLSS, Fortnite? DLSS, Battlefield? DLSS, Cyberpunk & the Witcher 3 remaster? DLSS, DOOM? DLSS, Watch Dogs? DLSS, Minecraft? DLSS, Metro? DLSS, Mount & Blade? DLSS, Read Dead Redemption? DLSS, Tomb Raider? DLSS, Wolfenstein? DLSS, Rust? DLSS, Final Fantasy? DLSS\n\nAvailable in UE4 & Unity with no work. Id say its already mainstream? Assassin's Creed Valhalla is about the only triple-A game I can find at short notice that doesn't have it.\n\nPeople have been saying it wasn't in many games for a long time, but guess what, we only get a few big game releases a year! It's been in the majority of releases for some time now. In fact, its got to the point where its more likely to be in the game than not.\n\nOn the flip side, AMD FSR is literally just a lanczos upscale with sharpening, you're welcome to check that in the source. Which is why below 4k it performs very poorly. In fact if you compile the dev version of [Magpie](https://github.com/Blinue/Magpie) you can try it and upscale any game you like! Just set to windowed borderless and choose a lower resolution and it will upscale the image using FSR.\n\nThat said, its not exactly all that much better than existing upscaling. I played with it myself but for example in Fortnite it didn't really provide much of an increase in quality over the traditional upscaler.\n\nThreatened? No, wanting to comment when people have massive double standards? Yes.\n\nFSR has its uses, but comparing to DLSS is just not something its in a position to do.",
      "DLSS Almost indistinguishable in blind tests with minimal ghosting in edge cases- 'Complete garbage, looks terrible \\*downvote & harass\\*'\n\nFSR Significantly worse image quality, blurred but overall pleasing image - 'No pixel peeping boys! Wow so good! Just don't zoom in or analyse, most people can't tell the difference! A\\*'\n\nThe sub of double standards.",
      "About the same as DLSS performance mode going by the amount of blurring going on over the whole image, especially the sidewalk, but its very very noticeable. The end result is still usable though. That said, this sub has spent months trying to destroy DLSS even when results were far better than this, so to hold this to the same standards would mean its terrible.\n\nThat said, it does look comparable to DLSS performance mode, which is far faster.",
      "there's a very clear loss of detail without zooming or pixel peeping. I had to look closer, but I can definitely tell the difference.\n\nI made sure to not look at which was FSR/Native when I opened the link and I guessed the one that's native.\n\nLook at the mini map, there's lines missing in the FSR side, that's an easy example to compare.\n\nEdit: look towards the white light, and the black stuff has clear detail loss. You have to look at static sections of the scene. Since the comparison shot isn't the same image, you have to do that.",
      ">A little oversharpened to my eyes\n\nCheck again, the oversharpened is the native one. We got baited since the positions are switched compared to video, FSR is on the left while Native is on the right.",
      "Yeah it‚Äôs hard to spot differences in a 4k image with 1080p video on my phone‚Ä¶",
      "Better than the comparison image posted here by my reckoning! The base game has ghosting in it to quite a degree because it uses TAA, which is still there with FSR, FSR just runs on top of it.\n\nThat said, using the newer DLSS 2.2 dll file give better results. For the most part though, even gamers nexus hailed it as extremely impressive, and the LTT DLSS blind comparison video showed that most people can't tell the difference either.\n\nLegitimately the ultra quality pre-set looks similar to the DLSS performance pre-set in many cases, especially at 1440p where FSR does far worse.\n\nI'll just have to disagree with you, coming from someone who has a 3060Ti and a 6800XT, of which the 6800XT is sat in its box not being used.",
      "I meant with the open source driver (Radv). Last time I checked CP2077 froze after the menu with the pro driver.",
      "https://github.com/andrewcs0901/Magpie/releases/tag/v0.5.1",
      "Right you are, my bad. Just goes to show how close they are if it comes down to personal preference.",
      "Calm your tits my dude, I actually quite like FSR and am not looking to trash it. One of the images looks overly sharp to my eyes, just turns out it's not the one I expected.\n\nHaving said that, I've played Cyberpunk on a 4K TV from a distance, thought it looked great, and then played it much closer on a UWQHD display and thought it looked crap. The game natively has this amazing ability to look fuzzy in some places (NPC character models seems to suffer with this) whilst overly sharp in others (like ground textures, for some reason)."
    ]
  },
  {
    "brand": "amd",
    "generation": "6000",
    "tier": "mid",
    "matched_keywords": [
      "6700xt"
    ],
    "title": "Here's something you don't see every day: PyTorch running on top of ROCm on a 6800M (6700XT) laptop! Took a ton of minor config tweaks and a few patches but it actually functionally works. HUGE!",
    "selftext": "",
    "comments": [
      "Linux: the hobby of getting your platform to the starting line.",
      "Pytorch runs flawlessly on Nvidia cards. A single command to download and install, and you're done. The current situation for compute on AMD cards is all due to AMD, not Linux or pytorch.",
      "That's a lot of work to flex that you use Arch.   \n\n\nBut serously good job getting it working.",
      "I previously tried running Microsoft's DirectML version of tensorflow, but it was slow and only used Tensorflow 1.15.  I'd previously tried and failed to get pytorch to work with ROCm.  But today I thoroughly went through the steps and got it working.  Note that in the picture the speed varies a lot.  This is because it is still building up a good cache of optimized kernels.  Once that cache is built it should be very fast.  If anyone has questions, ask away!",
      "AMD always eventually gets their act together, but it's usually sadly a few years too late.  I'm just glad I'm able to get this working before my GPU is totally out of date!",
      "Now you only need to write a nice blog post or gist with details on how you made it work ;)",
      "It's totally AMD's fault actually.",
      "AMD has been dragging their feet with ROCm support for both RDNA and RDNA2.  It does not inspire confidence or development work when AMD's CUDA equivalent still does not run on two year old hardware, and is only barely starting to work for the current gen.  From what I've seen, PyTorch has actually been doing a rather good job of supporting both APIs.  The reason the patch was necessary is all the old ROCm cards had a warp size of 64, whereas these new ones are more like NVIDIA cards with 32.  Overall it's very new and untested.",
      "Yessir",
      "This is actually a case where Windows is behind. You want to do DNNs, you go to Linux (and NVIDIA).\n\nEdit:\n\nBy the way, that is not to say that Linux isn't still a shitty experience. We have a DGX Station A100 at work, and the NVIDIA people came around to install it and explain how to work with it. While at it they explained how to update the OS version and firmware, managed to bork it while upgrading it and spent a couple of hours restoring it.\n\nI personally never had a Linux experience that was fire and forget, except running live CDs or anything else prepackaged that doesn't need any installation or updates.\n\nStill, that doesn't invalidate what I said before. Some things just don't have a good Windows infrastructure. That DGX Station runs only Linux, nothing else.",
      "I was referring to the Linux ecosystem. The fact that many companies don‚Äôt put the effort in isn‚Äôt the Linux OS‚Äôs fault, but it‚Äôs part of the reality of embracing the ecosystem.",
      "ROCm recently added support for gfx1030 (6800XT).  I've seen reports of it working in Tensorflow, but not PyTorch.  My GPU always spouted a hipErrorNoBinaryForAllGPUs regardless, as it is a 6700XT/6800M/gfx1031.  What I had to do was manually edit the CMakeLists.txt file in each component of ROCm to only say \"gfx1030\" instead of all of the other ones, as well as replacing the name in the ifdef sections.  However, pytorch would still not work..  I found a pull request titled \"[ROCM] query warp size for host code, do not use C10_WARP_SIZE¬†#67294\" and decided to try it out.  Sure enough, it worked perfectly!",
      "Have you documented the tweaks and configs you had to set? If so please share with the community.",
      "Just install ubuntu if you don't want to tweak a few things. Or even mint, it's even easier.",
      "Well done. Pity it still takes an effort, but it's certainly better than not working at all. Hopefully AMD will get to the point where no work is needed.",
      "I feel like I'm the only person in the world who hasn't had problems with Nvidia drivers. On Ubuntu I just go into the Software Updater and tell it to use the proprietary Nvidia drivers and they just work.",
      ">Pytorch runs flawlessly on Nvidia cards. A single command to download and install, and you're done.\n\nNow if only drivers worked this easily for Nvidia as well.",
      "Personally I had a lot of problem with my nvidia drivers. I have to disable browser hardware acceleration, and APST on my nvme drive because Nvidia drivers doesn't work well with them.",
      "I don't really know how difficult this will be to do. Could you explain in more detail the directions you followed, what configs were tweaked and why, what patches were applied and why . Could you clarify which AMD gpus this is applicable to. Like is it only necessary to do this particular setup for RX6000 series GPUs but not for other AMD GPUs.",
      "Why is it so much trouble to get it working on AMD GPUs in the first place? Do the PyTorch developers just not support it that well?"
    ]
  },
  {
    "brand": "amd",
    "generation": "6000",
    "tier": "mid",
    "matched_keywords": [
      "6650"
    ],
    "title": "[Tom's Hardware] AMD RX 7600 Could Cost More Than the RX 6650 XT",
    "selftext": "",
    "comments": [
      "Can I politely ask all these rumours to shut up?\n\nIt's getting announced at Computex. That's in one week or so.\n\nIf they're right, AMD can shove it. If not, stop baiting and wait and see.",
      "Yeah, they're intolerable. If you're also into football (the European one), then every other year you get a confluence of PC hardware rumours and transfer rumours. Kills the internet dead.",
      "For sure, saying \"the new version is more expensive than the current market value of the old one\" is a given. That's literally how retail works.",
      "Rumorers never shut up. \"Hey did you guys know the 4070 TI is a rebadged 4080 12...\"\n\n\"YES, WE KNOW. YOU TOLD US 20 TIMES\"",
      "It's going to be interesting to see how the RT performance of the 7000 drops off below the 7900 cards. It's possible that they'll offer a meaningful improvement on the 6000 the whole way down the stack. Otherwise, it's hard to see why someone wouldn't just get a 6700XT",
      "A $300 price for the 7600 also bumps it up against the 6700 XT and one can be found on Newegg for $320 as I type.  How will its performance compare to the 6700 XT?  What happens if 6700 XT's drop further in price?",
      "> A pair of listings on PC-Canada has revealed the price of AMD's upcoming RX 7600 in Canada. One of the listings features a Sapphire Pulse RX 7600 for $451.99 CAD, and the other is $443.99 CAD for an MSI RX 7600 Mech 2x Classic. After converting to USD and factoring in any potential \"early adopter tax,\" we end up with approximate prices of around $299 USD. That's technically less than the launch price of AMD's RX 6600, and well below the RX 6650 XT's $399 MSRP, though these days the various RX 66xx-class GPUs tend to sell far below their launch prices.",
      "> And that \"companies are not your friends\"\n\nThat's because yeah, companies are not your friends.",
      "Swear to Christ people are angrier at AMD for not selling a GPU for the price of a McChicken than they are at Nvidia for raising prices.\n\nThis card is cheaper than its predecessor, last gen GPU's have been marked down to even cheaper than that within the past few weeks, this cards main competition is pathetic (4050 6GB of RAM), and people still find some reason to bitch and want the price to be lower.",
      "If only social media extended that same courtesy to Nvidia.\n\nOver the last few months we had some really cool rumors taken at face value, examples:\n\nWhen someone said that RTX 4070ti would launch at $1000 MSRP (increased from $900 after rebadging the 4080 12GB). Ended up being completely false.\n\nWhen someone said that 4070 was $750 ($50 below the $800 MSRP of 4070ti). Ended up being completely false.\n\nYou can still find thousands of angry comments in Reddit threads discussing these rumors.",
      "A real informative headline would have simply said \"RX 7600 expected to cost $299\". The article would have discussed the source of the price speculation and the reasoning, and compared it to MSRPs and current street prices.\n\nWhich is largely what the article did, it just framed it in \"this chip doesn't seem worth the price\", which is just another bunch of speculations thrown over the price ones.",
      "Thanks for sharing that. It had big \"The Onion\" energy, and it actually surprises me how keenly they skewered the tactic by showing an example of it right in the article.\n\nThat said, I don't understand people who hate click on things. If I see clickbait, I move along. And if it's in a feed I have control over, I permanently block the source the first time and make sure only to read from places that don't use clickbait titles.\n\nI honestly think that eventually, people catch on and that clickbait's a short term strategy that fails in the long run however.",
      "There has been a general meme trend that AMD is out to gouge consumers by raising their hardware costs, and I fully expect more articles to lean into that overly cynical mindspace\n\nOften when people on the r/amd reddit talk about it, that I have seen, it seems to come out~\n\n that they also expect AMD is currently, or would have, taken all of the anti-competitive actions against their competitors, like that Nvidia and Intel have done time and again.\n\nAnd that \"companies are not your friends\" to the extent that historical pro-consumer actions on AMDs part should be ignored, cause reasons\n\nAnd they get mashed together in various ways to claim that AMD is screwing us, or has been, or would have been if only they could have been\n\nReally, it is just confusing.",
      "Yes and no? If you bench 6950 XT vs 7900 XT in 1440p and 4K, the difference in raster between them is significantly smaller than the difference in RT. Like say if performance difference in raster is 20% in a completely GPU bound scenario, RT will be 40-60%.",
      "leaked out of his ass",
      "[Stop following lying sacks of @!#$ such as \"Moore's Law is Dead\" and stop giving them the time of day.](https://www.reddit.com/r/GamingLeaksAndRumours/comments/pke49l/new_xbox_series_s_model_with_new_6nm_amd_apu/hc30xsk/?context=3)",
      "Seeing that this GPU is essentially the same as a 6650XT, except with dual issue SIMD, thats pretty sad.",
      "Wow, so a newer and faster card is more expensive than the *current market value* of the last gen card?\n\nI'm shocked, utterly shocked. Wait until they find about clearance TV pricing...",
      "Well, in the pre-crypto days. As launch of new GPUs whose performance overlapped with the previous gen approached, the previous gen would drop in price. When the new gen came out the new generation would cost a touch more for the same performance. Typically, they would have lower power and new features to justify costing a bit more. So, a 7600 at $300 probably performs a little bit worse than a 6700XT at raster, and at least about the same ray tracing.\n\nIf that plays out, we should be dealing with a bunch of posts along the lines of \"should I buy a 6700XT for $x or a 7600 $y?\" And, there will be no right answer.",
      "That's twice the cost of this class of card, and it would likely require a larger PSU for many people considering this card and most of them probably don't even have 4k monitors.  \n\nThis card is for people building a whole computer for $650, not just graphics card."
    ]
  },
  {
    "brand": "amd",
    "generation": "6000",
    "tier": "mid",
    "matched_keywords": [
      "6750",
      "6750"
    ],
    "title": "Sapphire launches Radeon RX 6750 GRE 10GB Starry Sky graphics card - VideoCardz.com",
    "selftext": "",
    "comments": [
      "Cut down crappy cards for the Chinese market. \n\nWe won't see these, nor should we want these.",
      "> nor should we want these          \n\nAll depending on price/power usage/size",
      "I mean, it's the same thing as a RX 6700 10GB which has been available for a long time now.",
      "Because they know that it will sell better that way. If they make it seem \"new\" people will go and enquire about it. It's probably that simple. [This is not the first time AMD has done this sort of thing, I remember the RX 590 GME, which is just a rebranded RX 580, not even a clock bump over the 580 like the real 590 was because the 590 was the 580 moved to a smaller node. This is just a straight up rebrand like the 6750 GRE is.](https://videocardz.com/newz/amd-radeon-rx-590-gme-features-polaris-20-xtx)",
      "Radeon RX 6750 Golden Rabbit Edition Starry Sky Graphics Card? \n\nWho the fuck names this shit?",
      "100%, if the price is right it could be a good budget pick for some people, although I doubt the price will be right.",
      "I agree it's stupid to rename it.",
      "These could be great for like $250-$260",
      "It's jyst a 6700 with an \"upscaled\" name üëé.",
      "A 6800 GRE would be more interesting by far.",
      "Even if they decided to sell them outside of China, they'd be way too expensive for what they are.\n\n\"At the current exchange rate, that's approximately $330\"",
      "I kind of love the design of the grey one. It's always nice to see some experimentation that isn't the standard black/white affair.\n\nI hope they use this same design ID with the RX 8000 series. It'd look even cooler with some premium materials.",
      "GRE made more sense last year. This year is Dragon year.\n\nThis card makes no sense. 7700XT is not that fast so shouldnt have issues with sanctions. Sell 7700XT instead of outdated 6750.",
      "Boo, another refresh",
      "It‚Äôs for the Chinese market.",
      "Why chinese market gets those cut down versions? Why not just sell standard cards like in EU or US",
      "they are more cost sensitive and big enough of a market to warrant a version tuned to their needs.",
      "I want that if its only $180",
      "Well supposedly its more power efficient but nobody wanted to buy one off Amazon to prove it :(",
      "Hey OP ‚Äî Your post has been removed for not being in compliance with Rule 8. \n\nBe civil and follow Reddit's sitewide rules, this means no insults, personal attacks, slurs, brigading or any other rude or condescending behaviour towards other users.\n\nPlease read the [rules](https://www.reddit.com/r/Amd/about/rules/) or message the mods for any further clarification."
    ]
  },
  {
    "brand": "amd",
    "generation": "6000",
    "tier": "mid",
    "matched_keywords": [
      "6700xt"
    ],
    "title": "5800X / 6700XT PowerColor, in all its glory",
    "selftext": "",
    "comments": [
      "If your graphics card glows this kind of orange you really need to improve the cooling.\n\n(Yes, I know, just couldn't resist)",
      "The CPU cooler is a Dark Rock Pro 4 (BK022)\n\nThe memory is [G.SKILL Trident Z Neo Series 32GB DDR4 3600 14-15-15-35](https://www.newegg.com/g-skill-32gb-288-pin-ddr4-sdram/p/N82E16820374093?Item=N82E16820374093) (Got it on Black Friday for $239.99)\n\nThe PSU is a Seasonic PRIME 850W\n\nThe CPU I got lucky and picked it up for $299 at Microcenter, which triggered the rest of the build (of course)\n\nSome benchmarks here if anyone is interested: \n\nhttps://imgur.com/a/9GmwwNH\n\n[Geekbench 5 (Linux)](https://browser.geekbench.com/v5/cpu/11490863)\n\n[Geekbench 5 (Windows)](https://browser.geekbench.com/v5/cpu/11491585)",
      "Damn, your build is nearly a dead ringer for mine. 6700xt Red Devil, 5600g, 32GB Trident Z RGB 3600MT.\n\nMy Red Devil has no problem hitting 2800MHz all day long at 57c/81c hot spot, fantastic card. Not going to OC the memory because apparently there's no VRAM temp sensor?",
      "Nice, only missing the pc case üòÖ",
      "I got it at the Microcenter in Tustin, CA. Paid $899 for it, was orig $999 with $100 marked off. Picked it up about a week ago.\n\nI have a RX 480 also myself, and I picked up a 1440p, so I'm leaving the 1080p on the old machine, and using my new GPU with the 1440p. Really enjoying it. It's a nice change.",
      "Man I want that 6700 red devil.\n\nI just settled for a jigabyte 6600",
      "I definitely understand. I paid $899 at Microcenter for the card. Obviously a lot, but I mean the options are limited. At least I didn't reward a scalper. That I refuse. But I knew I wanted this particular card, given its looks and how well it cools. Got really great reviews.",
      "Both my 6700xts that ive owned (msi gaming x, gigabyte gaming oc) have vram temp sensors. (Hwinfo64) My msi 6700xt (the one I kept) is waterblocked right now and vram temp doesnt go above 52c. Heatsink had the vram temp junction at 78c with max oc. \n\nYou got a great 6700xt if it can hit 2800mhz, my waterblocked one can't sustain 2700mhz in game or its unstable",
      "Shit man I was JUST mc a few hours ago. It was 999.99 I want it, but not for a g note",
      "Hundred bucks is a hundred bucks",
      "You got 3 fans on Dark Rock Pro 4? Damn man. I'm using mine on a 5600X with a single fan on front.",
      "All the case anyone need. Nice build.",
      "Sweet build.\n\nDoes the X570S have dual bios? I'm guessing not based on the docs, but wanted to hear from a board owner.",
      "Hello dad. I have r5 3600 + devil 5700xt. I hope to be big and strong like you one day",
      "finally someone else posting a pre built test pic.\n\nFor alot of you out there, first timers and not first timers.\n\nDoing this helps finding problems easier and tests make sure shit works.\n\nnicely done OP",
      "No case gang",
      "Now that's a red hot machine.ü§ò",
      "Love that red afterglow!",
      "I have a 3060ti but i really want a 3070 or better\nI love the 6700xt but I‚Äôm not positive it is a big enough upgrade for me\nBut damn the red devils look sexy af",
      "I have the same exact card. Managed to get it for msrp! \n\nGreat card for 1440p gaming!"
    ]
  },
  {
    "brand": "amd",
    "generation": "6000",
    "tier": "mid",
    "matched_keywords": [
      "6700xt",
      "6750xt"
    ],
    "title": "For 6700xt and 6750xt owners, what model did you buy, why, and how has it been treating you?",
    "selftext": "I'm wondering what models people are satisfied with and why. I would appreciate it if some of you could share your experience with temps, noise, and any issues you've had.",
    "comments": [
      "I have what is probably the cheapest model or one of the cheapest ones in the XFX 6700XT Speedster SWFT309. \n\nIt does the job just fine. The default fan curve on it is maybe a bit too conservative letting the GPU junction temp go up to 95-100¬∞C while trying to stay quite and while thats still comfortably below the 110¬∞C limit raising the fan curve just 10% lowers the temperatures into the mid to low 80 or even high 70's.\n\nRealisticy i wouldn't recomend this model purely because there days models like the Sapphire Pulse, XFX Merc or Powercolor models hover around a comparable price. I pretty much just bought it because it was cheapest by quite a mile on Black Friday due to a deal.",
      "My mate got an msi 6750 xt and it's been very good for him, relatively cool and runs games just fine at 1440p",
      "Initially bought an Asus Rog Strix 6750XT but returned it due to insane coil whine. Picked up a Red Devil 6700XT the following week and although the whine is still there, it's nowhere near as bad as the Asus. Hoping a few weeks/months break-in will get rid of the whine completely.\n\nRunning a small undervolt/underclock and perfectly happy with it.",
      "6700xt, bought the cheapest one 2 months ago, powercolor fighter.1440p and games I play flies.Noise wise is fine as long one dont push it.3 fan models are recommended for those noise sensitive ones.\n\nHappy with it as it replaced my old trusty Vega56",
      "Sapphire Pulse RX 6700 XT running spiderman 70-75celcius average 90 fps can reach above 144 there more but i'll can't recall the stats",
      "Sapphire Nitro+ 6700xt. Runs Calisto Protocol at \\~90fps on 1080p ultra, 135-165 on high. Mostly 60fps(capped at 60) on a heavily modded skyrim. All the rest of my games run at 120-165. whatever i've got my monitor set to or higher if i'm not frame capping. 35-45C main, 40-65C hotspot. It stays cool even at a 2740 clock. Note i cap my frames to 60-165 depending on what I'm playing. No sense in making it work harder than necessary.",
      "xfx 6700XT merc  \n\n\nAmazingly, nice temps, cant hear the thing full fanload. No whine. ¬£300.. can't moan at all.",
      "I bought the red devil 6750xt and it‚Äôs great. Runs silent and crushes all my games that I was struggling with before.",
      "1080p",
      "For anyone getting crazy hotspot temps with the 6700's, I've got the cheapass Sapphire 10gb one and I flipped the whole PC upside down and now the hotspot temp never gets above 90. I think it's something to do with the vacuum chamber in the cooler not having enough water in it.",
      "I got the MSI RX 6700 XT MECH 2X OC 12G. I've had it for almost a year now and I can't say I've had any issues. I got it because it was the first time I saw this tier of GPU under $400 that I was able get at my local microcenter for $350. I figured that MSI would be a reputable brand and most variants perform within 1-2% of each other generally. Definitely an upgrade over my previous GTX 1070 and lets me utilize my 1440p monitor. I think the thing I like the most besides the performance increase of the upgrade is the Software. I had no problems with my 1070 but it felt like a chore every time i had to open up GeForce or control panel compared to opening up Adrenaline which feels more intuitive and user friendly. The price and performance of Intel Arc does interest me but I hear that some older games dont work well and the software still needs development.",
      "Is this at 1440p?",
      "Got the same card. Limited it around 1500 rpm which makes it quieter but you can still hear it. (Thing ships with 100% fanspeed for like 65 degrees? Wtf?)\nTemps tough are quite good.(even with tamed fans)\n\nSadly mine got coil whine but i almost always wear my headset while playing, so its not the end of the world.\n\nPlaying at 1080p 144hz and recently upgraded my rx 5700 non xt to  a 6700xt and my 3600 to 5700x.",
      "Cool beans.",
      "A lot of times corruption comes from memory errors. You could run it at stock settings and see if it still happens.",
      "Thanks. I have installed latest adrenalin driver and turned off GFXOFF using MPT. I haven't noticed any problems yet while using my pc with low gpu usage (its been around 3 hours now). Hopefully its fixed now.",
      "I have mine fot around a month now and im quite happy with it (still the coil whine is a bit annoying)",
      "3700x and 5700x its been fine so far",
      "Power Color Red devil 6700xt, performs very well, and had no problems at all..\n\nNoise is almost silent because i undervolted it..  1105mv with 2600 gpu and 2100 mem? i can't remember.. temps are around 60/65 when i play games.",
      "I just bought a sapphire pulse rx 6700 xt. Playing with D2R 1440p maxed settings about 90-110 fps and 65-70C gpu and 90-100C hot spot temps, depends on the area. Everything fine so far. Stock settings for the card. One more thing its very silent cant hear in closed case and zero coil whine. So its a very good card i think."
    ]
  },
  {
    "brand": "amd",
    "generation": "6000",
    "tier": "mid",
    "matched_keywords": [
      "6750xt"
    ],
    "title": "Xfx speedster qick 6750xt vs powercolor fighter 6750xt",
    "selftext": "Wanted some help deciding between these two cards. I mainly play city builders/strategy games (really looking forward to civ7). From what I can tell these cards are essentially identical. The only thing I notice is the warranty for xfx is 3 years vs 2 for powercolor. I have no prior experience with either manufacture. For reference in trying to spend around $350 on the card and pairing it with a 7600x, mobo undecided yet, 1080p for now but will eventually upgrade that. Thanks in advance! ",
    "comments": [
      "Prices have gone up the last couple months sadly. I picked up my 7700XT for $350 during the summer. The 6800XT was around there too. Currently though, the 6750XT is solid for that price. A used RTX 3070 would be a good choice as well, just keep in mind it's only 8gb. If you plan on going 1440p in the future, i would skip a 3070",
      "If your case can fit it, get the XFX. It's not even a comparison. Better support, better reputation, and better cooling. I have an XFX speedster 7700XT, and it is a REALLY good card. Under full load, the core never goes past 55c. Memory and hotspot sits closer to 70c. It can get loud under full load, but a 2 fan card would be even louder.",
      "ja i saw a response above said choosing a short card\n\na three-fans one might overlength",
      "Might as well get the Gigabyte Gaming OC 7700XT for $400. \n\nThe Qick 6750XT is $360. I'd pay the extra $40 for a significant performance jump.\n\nAs for the motherboard, considering you have the Fractal North and you don't wish to install a micro ATX board, go for the MSI B650 Gaming Plus Wifi for $170.\n\nHowever if we're talking most value for money, that would be the AsRock B650M PG Lightning Wifi (micro-Atx) for $120. It's good enough for a 9800x3d.\n\nPrices seem to be high across the board and many items are out of stock - so these are the decent options I could find.\n\nhttps://pcpartpicker.com/list/JDxq6D",
      "I just got the xfx one  been playing mainly CS2 and it stays nice and cool and works really well",
      "I believe it can. I have a fractal design north so without a front radiator it should be good to about 350mm. \n\nDo you have any other recommendations in that price range or are those my best options for what I'm trying to do?",
      "I actually wanted that board but the prices and availability are horrible right now. I was seriously contemplating the microcenter deal with the 7600x, gigabyte b650 auros, and 32 gb of g skill ram for like $450. I already have the case and a PSU.",
      "Any cheaper bundles?\n\nHow much is the 7600x3d bundle?",
      "Thanks for the info!",
      "Sorry I misspoke. They have 7700x (not 7600x) with either the gigabyte gaming x ax b650 ($400) or gigabyte auros elite ax ice b650 ($440). Both come with the same gskill ram. They don't officially list the 7600x3d bundle anymore since it's out of stock but i believe it was around $450\n\nCheaper they have the 7600x or 9600x with asus b650-a prime ax 2 for $300 and $330 respectively. Or you can upgrade and get it with asus b650m tuf gaming for $340 and $370.",
      "The asus prime is a mediocre motherboard, I'd recommend going for the 7600x + B650M Tuf Wifi bundle for $340. I'm hoping the RAM is 6000Mhz and not 5600Mhz.\n\n[https://pcpartpicker.com/list/qnKpHW](https://pcpartpicker.com/list/qnKpHW) \\- Similar equivalents are $400 if bought seperately.\n\nIt's not worth paying extra for the 9600x. Spend the $30 on a decent air cooler like the Peerless Assasin or the ID Cooling A620.\n\nThe Gigabyte Gaming X AX is one of the better boards out there and going for a more premium board is not worth it. If you want an ATX board, the 7700X bundle for $400 is pretty decent.\n\nThe $70-$100 price difference between the 7600x and 7700x bundles are significant enough to jump to a higher tier GPU. For example you can get a 7800XT for $480 instead of a 7700XT ($400)."
    ]
  },
  {
    "brand": "amd",
    "generation": "6000",
    "tier": "mid",
    "matched_keywords": [
      "6750",
      "6750"
    ],
    "title": "AMD's upcoming Radeon RX 6750 GRE reportedly just 'an overclocked RX 6700 10GB' - VideoCardz.com",
    "selftext": "",
    "comments": [
      "Called it. We knew cut-down Navi22 was mainly used for mining.\nDumping the leftover chips to the Chinese market makes the most sense.",
      "no gpus were sitting on the shelf in 2020 trust me",
      "Did anyone ever expect otherwise?",
      "I'm not sure what you expected. It's literally in the same \"6750\".",
      "What psu does he have, might be possible with a high quality psu but don't really think those exist at 450w, a 6700 is already cutting it close for a stable experience and a 6700xt uses 60w more",
      "Golden Rabbit Edition, in reference to the Chinese lunar year. In relation to the 6750 GRE and 7900 GRE, both utilize cut-down variants of their bigger siblings‚Äô GPU cores.",
      "It will be GREat company to the other GPUs sitting on shelves since 2020.",
      "That's true, but if Windows and / or Radeon Software has an error, there's a chance that everything including the power settings will be set to default, which could strain the power supply if the user doesn't remember to set that power limit again.",
      "I'd say go with a 6600 or a 6600 XT, power supplies degrade with time, and it's nice to have some extra headroom for safety reasons.",
      "Makes sense...dump em off in a value market in China for a small to moderate profit or sell them over the rest of the world for a slim profit or loss. This isnt relevant news for most of us so Im not understanding the unrelated comments here when this has nothing to do with most local markets.",
      "I would definitely go for the 6700 XT, then test it; it may doesn't need any undervolt either, but in the long run he should upgrade the PSU anyway (when he have the spare money).\n\nhttps://www.guru3d.com/articles-pages/amd-ryzen-5-5600-review,6.html\n\nhttps://www.guru3d.com/articles_pages/amd_radeon_rx_6700_xt_(reference)_review,5.html\n\nIt worth mentioning that some non-reference card could go a bit higher than that 240W max",
      "Re-brandeon moment",
      "I oced my rx 6700 to 2.8ghz with a great uv of 1075mv from 1200mv. Should I call it 6750gre instead. Lol",
      "5700X and powercolor rx 6800 in combination with bitfenix 450w no problem",
      "what sorcery is this.",
      "I was making fun of this weird gpu man.",
      "An RTX 4060 or an RX 6600 XT would be adequate for a PSU of this wattage, the 6700 (XT) would be maxing out his PSU that there wouldn‚Äôt be any sort of wiggle room.",
      "Just save yourselves the hassle and get the model that only requires 1x 8-pin by spec.  \n\nI guarantee you can still get more performance out of it beyond what Sapphire ships it at.",
      "Gotcha. Posts on previous \"GRE\" releases were acting as if they were a global release so I guess I'm having flashbacks of people not reading past the title.",
      "of course just like the 6750xt is a 6700xt with 18gbps memory and a tiny gpu core oc"
    ]
  },
  {
    "brand": "amd",
    "generation": "6000",
    "tier": "mid",
    "matched_keywords": [
      "6750",
      "6750"
    ],
    "title": "AMD to launch Radeon RX 6750 GRE graphics card in China, \"RTX 4060 price with RTX 4060 Ti performance\" - VideoCardz.com",
    "selftext": "",
    "comments": [
      "Isn't \"4060 price for 4060 Ti performance\" literally what the 6700 XT is for?",
      "That‚Äôs literally the definition of how the entire CPU/GPU market works, except worldwide and not just china",
      "XT sounds horny, GRE sounds cooler.",
      "so likely that 7700xt will be slightly faster than 4060ti and more expensive?",
      "Well I prefer Radeon all-in-wonder. That sounds the sexiest.",
      "This is literally how all cpus/gpus are made and sold",
      "Based on leaks - 7700xt will only have 12gb.",
      "lol",
      "More expensive than the 8gb card, but less than the 16gb card.",
      "Hardly unprecedented for AMD. Both the RX 580 2048SP and 896SP RX 560 come from this die harvesting.",
      "Thank you for that mental image, UnwashedArmpitLicker",
      "Yes",
      "Agreed. It makes me the most... \"curious\".\n\n\"What!? You do TVs, too!?\"",
      "Better for them to be on peoples hands then on a landfill.",
      "ok, i stand corrected, but its definitely not 8 gb.",
      "AMD loves Xs.",
      "I feel like these are just repurposed leftover mining chips",
      "But doesn't GRE stand for \"Greatly Reduced Expectations\"?",
      "You mean AMD owns twitt...X ?",
      "Nah. I think the purchase of my 6700XT after 3 years of Polaris use is breathtaking. It does everything maxed out at 1440p well over 144 FPS. What more do you want?"
    ]
  },
  {
    "brand": "amd",
    "generation": "6000",
    "tier": "mid",
    "matched_keywords": [
      "6700xt"
    ],
    "title": "PC with 7900XTX red devil pulls 666 watts from the wall.",
    "selftext": "Recently upgraded from a 6700XT to 7900XTX. \n\nMy powersupply is 750W so I'm cutting it very close, but it's a new Seasonic focus gold, so I'm sure it's reliable. I'm just not going to overclock the card, this was worst case scenario with a Ryzen 7900X and GPU both maxed out.",
    "comments": [
      "Now you know why it's called a Red Devil.",
      "Is this a peak or sustained wattage?\n\nIn any case, 666 from the wall at around 90% efficiency means the PSU is supplying about 600W, so you have a 20% buffer.",
      "Ah gotcha, I appreciate the info! The card does recommend a 900W PSU minimum, but I should be good. \n\nThis was at peak load, realistically when gaming I'm only pulling like 450-580W depending on the game. Idle and basic tasks it's 110-170W (this is total PC usage). \n\nI know modern GPUs also have power spikes, but I haven't crashed or had any issues yet.",
      "Wait till the wires turns hot red and start to melt everything.",
      "Maybe that's why it's called the red devil.",
      "The old Seasonic Focus line was really bad at dealing with transients, so you are either lucky or have a newer model (or maybe Powercolor kept the transients low with this model, I haven't seen any proper review.)\n\n>This was at peak load\n\nYou mean like running a CPU and a GPU stress test at the same time?",
      "Might be time for an exorcist",
      "Correct, this was everything at 100% load. Which while gaming the Ryzen 7900X barely does anything, it's all the 7900XTX",
      "OP was playing Diablo 4 at that moment.",
      "They recomend higher to avoid liability. They don't know what the rest of your system is, so it's better to overestimate.\n\nI would still look at undervolting any card, less draw with no draw backs.",
      "Then wrap them around a can of Chef boyaRDee.",
      "So basically your PC is a bit of a demon ;)",
      "That seems about right, 13900K+4090 users report 650w peaks. A good 750w PSU is fine for that. I love posts like this to prove the 1000w gang wrong.",
      "‚õß",
      "I have a 4090 and 5800X3D and I've gone never gone above 600. Running a 750 watt, and the 4090 is slightly overclocked. 750 watt gang",
      ">then it'd consume 812W of power at the wall to supply that.\n\nAnd it would be rated to do so. PSU ratings are the sum of the DC rails, not the draw from the wall. A 750W PSU can supply 750W of DC power combined, it's just a matter of how efficiently it does it.",
      "Plot twist he was also running Diablo 4",
      "Truly a red devil!",
      "r/AyyMD",
      "Where are you seeing that the red Devil XTX recommends a 900w PSU minimum? Everywhere lists it as a 750w min PSU"
    ]
  },
  {
    "brand": "amd",
    "generation": "6000",
    "tier": "mid",
    "matched_keywords": [
      "6750",
      "6750"
    ],
    "title": "AMD's last-gen Navi 22 GPU is still competitive against Nvidia's latest Ada Lovelace GPU ‚Äî RX 6750 GRE beats RTX 4060 in a new review",
    "selftext": "",
    "comments": [
      "6750 GRE 12 GB*, which is basically overclocked 6700 XT.\n\n6750 GRE 10 GB is the 6700 10 GB, which is closer to RX 6650 XT and slightly slower than 4060, but very close to it nontheless.",
      "Higher tier old product beats lower tier new product news at 11. What's tragic is the 4060 is really a 4050 but priced like what a 4060 ti should be priced at. That said $289 is a pretty good MSRP for this... too bad it's china only",
      "As far as I know, the RX 6750 GRE 10GB and RX 6750 GRE 12GB are a second set of refreshes of the RX 6700 and RX 6700 XT, and were originally China only and European OEM ( only available in pre-builts ) only but have since become available retail. I personally find the 6750 GRE 10GB naming to be pretty stupid because it is slower than the original 6700 XT despite having a higher tier name.",
      "It‚Äôs also competitive against 7600. Interesting way to frame the headline",
      "In other news, the 2080ti beats the 4060.\n\nMore shockers at 11",
      "The GRE cards are literally a rebadge of existing parts with no changes in specification.\n\nThe card refresh progression:\n\n* 6700 (10GB, 160-bit bus) --> rebadged into the 6750 GRE 10GB\n* 6700 XT (12GB, 192-bit bus) --> rebadged into to a 6750 GRE 12GB\n* The 6700 XT also got a previous refresh long before the GRE cards came out, called the 6750 XT. It's faster than the 6700 XT (and thus the 6750 GRE 12GB), due to higher clocks for the cores, memory, and cache.\n\nRDNA 2 (and RDNA3) is great value in many regions compared to the horse shit value RTX 40 series.",
      "Because there is little/no improvement over the 3060 and it has less VRAM",
      "The 4060 is shit so this isnt really unexpected.",
      "Breaking news",
      "I think it's compared to each other because the price is close. That's why the 7800 XT is compared to the 4070, even though it's \"higher\" tier. 4070 is still 50 to 100 USD more expensive.",
      "The cheapest 4060 right now is $290. For $310 you can get a 6700xt which is not only 20% faster but also has more vram.\n\nNvidia isn‚Äôt competitive in the mid range market at all right now. They are competitive in low end $250 price point, where the 3060 goes head to head with the 6650xt, and then the high end. At the $500 price point the 4070 beats the 7800xt in value, at $700 the 4070ti and the 7900xt being a tie, and at $1000 the 4080 beating the 7900xtx.\n\nAmd is killing it at the $200 price point where the 6600 has no competition, at the $300 price point with the 6700xt crushing the 4060, and at $400 the 6800 crushing the 4060ti.",
      "How is it shit",
      "The 10 GiB could've been named 6700 GRE",
      "You still didn't explain the difference lol.",
      "It‚Äôs what would be a 4050 in every other generation for $300. After the 3050 was a distance of a gpu at $250. It‚Äôs terrible, apart from using the gigabyte LP version for niche situations.",
      "I did though? They are refreshes of the RX 6700 and RX 6700 XT? Same as the first refresh of the RX 6700 XT, the RX 6750 XT. Same die, just with tweaked power limits and better binning to allow for increased clocks. Some refreshes might also include higher speed memory or even a die shrink as well, but I don't believe these do.",
      "amd should have just named it the 6750 XL like they used to do in the past. It would be less confusing.",
      "4060 is x50\n\n4060 ti is x60\n\n4070 is x60 ti\n\n4070 ti is x70\n\n4080 is x80\n\n4090 is xTitan\n\n6750 gre = ???",
      "I mean the power efficiency is the point",
      "Even in raytracing?"
    ]
  },
  {
    "brand": "amd",
    "generation": "6000",
    "tier": "mid",
    "matched_keywords": [
      "rx6700",
      "rx6700"
    ],
    "title": "Rx6700 vs RTX 3070",
    "selftext": "Hi. I'm upgrading my pc completely, and I'm in doubt about my new GPU. How good is it to use Ryzen 7 with an RX6700, and how good is it to use a Ryzen 7 5800x with an RTX 3070? Does the Smart Access Memory make a big difference?",
    "comments": [
      "To get the best performance your ryzen 7 would have to be  Ryzen 5000 cpu due to its ipc and either of these cards. The choice of card will probably depend on what your going to be using it for as they both have SAM/ Resizable BAR, albeit Sam does seem to perform slightly better. The 3070 is the slightly faster card but only has 8gb compare to 12gb plus it also has dlls and rtx.",
      "3070 is without a doubt the better card at the same price. Slightly better performance overall, much better raytracing, DLSS. Only reason some people are recommending 6700XT is because you're on the AMD subreddit.",
      "Whatever you can afford/is available. If closely priced, I'd take the 3070 for DLSS and RT if you care about that.",
      "6700XT cuz 30 series are VRAM choked",
      "The 3070 is better than the 6700XT at 4K tho.",
      "11GB VRAM is recommended for playing in 4k native max settings which is not really doable with either of the 3070 or 6700\n\nfor 1440p (the target of these cards) 8GB proved to be enough\n\nthat 16GB on AMD cards is mostly marketing for the 1440p cards and lower, it could still be useful if you use these GPU for modeling or video/image editing as you could really use these 16GB then",
      "If the prices are the same I'd go with rtx 3070. But in my experience the 3070s are harder to find and cost double it's rx equivalent.",
      "done. it's the 5800x",
      "ehhem where the hell is rx6800 non xt in your comparisons. 3070>6700xt 3080>6800 3080ti>6800xt 3090>6900xt is that what you meant?",
      "It's funny people are sticking to the 8 gigs vram not enough but don't mention the lackluster raytracing performance on the AMD card and a lack of a proper AI upscaler.",
      "The rx 6800 is close to 3070ti, the 3080 obliterates it",
      "FYI SAM works with Ryzen 3000 series and Intel CPUs at least from 10000 series onwards.",
      "Do you know how ram a works?\nIf a game uses 20gb vram with a 3090, that doesn‚Äôt mean that it won‚Äôt run with a gpu less then 20gb vram\nAlso msrp is $499 for the 3070\nQuestion: what‚Äôs the better gpu 470 8gb or 580 4gb?",
      "Not comparable to the rtx 30 series, but even on those cards it‚Äôs not worth it without DLSS, the best feature imo. Too bad most games don‚Äôt have it",
      "Dude, in this market, if you HAVE to buy a Card, take what you can get/afford...3070 is better, 6700xt is good enough. They are roughly on 2080ti level, so unless the pricing is the issue, either one will get you what you need to do. My 2080ti crapped out on me, and I'm looking to get either one of these myself, but I had a Vega56 as a backup so I'm waiting for saner prices...",
      "Hi.\n\nNo, it does not make a big difference. Between those two cards, the 3070 is the best card, and will do great üòä",
      "Radeon is only better if its cheaper 3070 > 6700Xt 3080>6800XT 3080ti > 6900XT",
      "As if VRAM is the only thing that matters or differentiates the cards‚Ä¶",
      "OP is asking about 6700XT - you are listing \"6800XT>3080/6900XT>3080TI\"...\n\n\n3070 is simply the better card overall, but  DLSS is more widespread and its performance in RT is way better, it also has nvenc and cuda for professional workloads.\n\n\nThe 8GB only hurts it at 4K in couple titles. Honestly it all depends on what the price is for either of them.",
      "Personally, I‚Äôve owned a 3060ti and 6700xt. The 6700xt is noticeably more powerful than the 3060ti but I think it‚Äôs still a small tick behind a 3070, but at the same time the 8gb on the 3070 will become a bit of a bottleneck soon enough. Also the AMD GPUs seem to be gaining performance through drivers faster than Nvidia so the 6700xt might eventually be equal to or better than the 3070."
    ]
  },
  {
    "brand": "amd",
    "generation": "6000",
    "tier": "mid",
    "matched_keywords": [
      "6700xt"
    ],
    "title": "This was my first building a PC. It has a 5900x and a 6700xt. I love it!!",
    "selftext": "",
    "comments": [
      "Enjoy it!",
      "Right on. I got a 3900X and an XFX 6700XT and couldn't be happier.",
      "Nice.",
      "Looks awesome.",
      "You got the Merc 319? Mine has been incredible! Like I seriously couldn‚Äôt ask more any more out of it as far as just quality. It‚Äôs so so nice.",
      "5900X is overkill for just gaming, but it's still a great 1440p system. I have a 5600X/6700XT and I love it.",
      "I can imagine the happiness you're feeling right now - nothing like getting a badass first system.\n\nEnjoy it !",
      "It really is. The temps are nice, the fans don't go full-blast and the performance is great.",
      "It's looks soo good! :D",
      "Good job",
      "Looks dope ! :D",
      "Thanks everyone! It was super fun to do ngl.",
      "Nice build but kind of lopsided imo",
      "Great job dude!",
      "I'm gonna get a prebuilt for now just for the games, and then build my own in the future, because building your own right now is way too expensive.",
      "That's awesome dude! Welcome to the PC world! :)",
      "Up until today I never cared for reference AMD cards.  This build changed that, and I commend you for that.",
      "What are those fans? \nEdit spelling",
      "(I haven't built in a while) the memory has lighting, where to buy this?",
      "Just got a 5800x, coming wed to replace my 3700x. Going with my 3080, definitely excited. Might get my first nvme drive too. But seeing your nxzt cooler is tempting! Nice neon look!"
    ]
  },
  {
    "brand": "amd",
    "generation": "6000",
    "tier": "mid",
    "matched_keywords": [
      "6700xt"
    ],
    "title": "Help for a gamer dad...6700xt, 6800 or 6800xt.",
    "selftext": "Currently have an i5 11400, 32gb ram and a 3060 gpu with a 600watt psu.  I'd prefer to keep total costs around 400.  Mainly play fortnite, halo infinite, COD... just got an Asus tuf vg27aq3a (1440P, 180hz) that I'd like to max out or just be able to play at 1440p and at least 120fps without issues.\n\nGiven this, which should I go with?  Look like prices are $359 for the 6700xt, $429 for the 6800, and $489 for the 6800xt... however I believe for the 6800xt I'd need to spend another $100 on a PSU upgrade no?\n\nSo $359, $429 and $589?  I'm not looking for bleeding edge tech as I have a series x and ps5, just looking to add a good 3rd option for our family where I don't have to fiddle with settings and can just set and forget at good resolution/fps.\n\nUpdate - After some good feedback I've decided to stay put for at least another 2 years with my 3060.  At first I thought it was my GPU causing the issues which started this whole thread.  Apparently the epic games launcher was set to stream the graphical assets in fortnite, which explained why the first game would stutter but subsequent games were smooth.  I went ahead and checked the box to download the 30gb's or so and boom...1440p, epic quality and runs at no less than 90fps.  \n\nSo yea, I'm just going to hold off for at least 2 years.  Thanks!",
    "comments": [
      "I would say 6800xt. 6700xt would be best value but would not be a substantial upgrade from 3060. Especially if you want 1440 p at 120fps.",
      "I have been researching similar and I am upgrading from a budget build. I am finding that the 6700xt is the best value for the dollar when on sale. However the 6800's have 16gb ram I think. Benchmarks I saw put the 6800xt about 20% faster than the 6700xt. So you can try to search for a price that justifies that 20% gain or not.",
      "Thanks!  Okay so I'm now between the 6800xt and the 7800xt. Both are the same price.... What should I go with?  And any reco on the PSU?",
      "No, no. Your at 1440 so i think your cpu will be fine for that resolution, not for 1080.\n\nHeres the deal, u want your jump from 3060 to next, to be substantial and u ideally want a gpu that can push 1440 to high refresh in future games too.\n\nThats why Id say 6800 as minimum but the 6800xt is a good deal more performance to last u longer, ive had both actually.  \n\nI would also not be trying so hard to keep a psu.  Ran my 6800xt for two yrs on 700w also.  Were it not for transient spikes, id try it on 600w maybe power limited. But bottom line, psu not that expensive.",
      "7800xt, its a better performing card.",
      "Agreed, 6800 or maybe 6800xt would be the best for longevity. However if you don't want to also spend more for a power supply. My 6700XT keeps me happy at 1440p. I don't expect that to last forever with newer games but I'm not exactly playing the latest titles either. \n\nTbh, you might find more stability with a higher wattage power supply anyway, even the 6700xt,  say 750 atleast. Depends on quality of current unit.",
      "6800xt!",
      "Upgrade to a 6700xt hardly seems worth it, especially at current prices. \n\nThe 7700xt at $421 and 6800 at $409 on Amazon don't seem too bad.\n\nThe 7800xt I'd say is a better deal than the 6800xt. 60w less power and a similar price. I think I've seen $480 or $490 recently.",
      "The 6800XT is, of course, the best option for your immediate and future wants and needs but yeah... I tested mine, 700W suggested, in gf's PC (5600X, 750W PSU and usually a 3070) It did ok but 600W isn't doing it, even with tweaks aso. Fwiw I used the 6800XT (in my PC) with a 5800X and a 1000W PSU that's also fine for a 7900XTX's appetite. If you take the 6800XT/new PSU route I'd suggest at least 850W to cover you for any later upgrades on a similar scale.\n\nAs for perf, my 6800XT was a 3440x1440 card 3 years ago but since then has been written down to 1440p for more recent AAA's approaching the kind of frame rates you're looking at with any real longevity (and short of cutting settings hard as you go on) For the other cards there's somewhat less compromise re the PSU (600W base for both) but more for the performance. All are fine cards at their respective levels though with the 6700XT's 12Gb being the lowest cap I'd use for 1440p and the 16Gb of the others offering some buffer.",
      "How much are you going to sell your 3060 for? Does that change anything? Because as of now I wouldn't upgrade the 3060 to any of these if I was just paying the prices you're saying for them and not getting any of it back.\n\nI see it like this, with that 3060 you should already be able to get 1440/120 in those games with tweaking settings/dlss and the only one you're going to be able to max out and still be at 1440/120 is cod with the 6800/xt which you should upgrade your psu for making it even harder to justify. There aren't really any cards capable of consistently comfortably maxing out games at 1440/120 aside from the 4090. Even the 4070 super which is another $100 more than the 6800xt at least in the US only runs at around 1440/90 using dlss in Fortnite at max settings.\n\nThat PC should already be a good match for the performance level of the PS5/xsx as it generally performs similarly but with the benefits of better rt and dlss.",
      "6750 will get you 95 fps In COD running max settings in 1440p. And you can find it for under 400$",
      "Man, if you could put a little bit more, 7800xt's are dropping. just picked up a hellhound",
      "7800xt. 1440 solid performance.",
      "Oh nice, thanks for the input!  Yea I mean $359 seems pretty good, considering I have a 600watt psu and it's max draw is 230 watts. With my i5 that puts it around 300-400.  Really didn't want to incur an additional cost for that.\n\nYea and like you, I'm coming from a semi-budget build, but also want a good price/value ratio.  Curious what graphics card did you upgrade from?",
      "Ohhh I didn't even consider bottlenecking..... Crap.  So then what about the 6700xt vs 6800 non xt?  Or still a bottleneck?",
      "650 watt  recommended min per AMD.",
      "Any bottle neck issues?",
      "So I just looked it up... Wow!  Yea same price.  So 7800xt seems like the winner.  Any PSU reco for that?",
      "Yeah that's a good point. So I wasnt looking to be fairly aggressive with the 3060 sell it for about 200.  Must used ones seem to be going for 250.  My rationale is I also want to future proof my rig as a have a 14 and 11-year-old, so trying to get something that would run 1440p at 120 for the next 4 to 5 years.  \n\nThat being said, yeah your point remains. I booted up Halo infinite and had no issues whatsoever.  I guess I was a little nervous because fortnite was stuttering which threw me off.  Then after some research I realized I guess it's prone to do that?  Anyway, with 200 back would you still recommend moving forward with the 7800 XT and PSU or no?",
      "And you'd reco that over my 3060?  Worth the upgrade?"
    ]
  },
  {
    "brand": "amd",
    "generation": "6000",
    "tier": "mid",
    "matched_keywords": [
      "rx6700",
      "rx6700"
    ],
    "title": "Possible Radeon RX6700 series graphic card Render Leaked by JayzTwoCents",
    "selftext": "",
    "comments": [
      "Still think the VII is the best looking card out of RTG",
      "Vega 64 Limited Edition reference blower LOOKS sleek as hell.\n\nIt just hurts my ears a little.",
      "A non insignificant number of the issues with the 5700xt was (probably) due to power delivery. Put more headers on it the card won't boot without and you have less issues of people not realising the adapter they bought from Amazon made of aluminum flakes coated in plastic that can't carry the current required aren't acceptable. There's a reason NVIDIA put a disclaimer that your warranty is void if you don't use the adapter included with the 3080.",
      "I'll wait for some Pulse design from Sapphire Tech.",
      "Dual 8 pin= power. Next month for full specs/price is to looooong AMD!",
      "I actually like it.",
      "Im still a big fan of the HD7990 https://images.anandtech.com/doci/6915/7990Car_678x452.jpg",
      "Blowers suck though. So I rather have performance over blower",
      "If Team Rocket sold gpus",
      "Looks horrible, but whatever, as long as it delivers. (and isnt trying to steal my pokemon...)\n\nIts not like the AIB cards look much better... when I look at what they created for the 30XX cards... ugly af.\n\nI really liked the \"flat\" and \"not special\" design of the Vega FE cards, and Radeon VII. But nowadays, its all about \"who can fit the most RGB and branding on the shroud\"... and then they all try to differentiate by coming up with \"unique\" RGB... which then messes up the entire aesthetics of the card.\n\nThat aside, I also dont need a \"Radeon\" or \"Geforce\" logo on the card, I know what i paid hundreds of dollars for.\n\nIts not like I am constantly looking into my case to figure out if my card suddenly changed the branding and is now a RTX 6900 or so, made by nvidia.",
      "Not really, in the renders it seems worse than it is assuming the Fortnite render is accurate. Buildzoid talked about that, fearing that they may have repeated the same mistake from the Radeon VII cooler with the giant Radeon logo blocking the airflow, but that's not the case with this card, the Radeon logo barely takes any space and shouldn't obstruct the airflow.",
      "Or the Nitro+ if it comes in that variant.",
      "Team Rocket",
      "My problem with most of the non-rectangle cards is the aesthetic is attempting to be too gamer-y. Any detail on the plastic housing makes it appear less cheap than it actually is.",
      "Your one 5700xt is the golden standard to which all 5700xt‚Äôs shall be compared. It is known. Amen.",
      "that seems like a LOT of plastic to keep heat trapped....",
      "It's ugly.  Like *really* ugly.  A big step back from AMDs minimalist design.",
      "I personally loved the 295x2... love that red fan! :-D  \n\n\nWould of loved a Radeon VII design with these fans.  \n\n\n[https://www.guru3d.com/index.php?ct=articles&action=file&id=9746&admin=0a8fcaad6b03da6a6895d1ada2e171002a287bc1](https://www.guru3d.com/index.php?ct=articles&action=file&id=9746&admin=0a8fcaad6b03da6a6895d1ada2e171002a287bc1)",
      "400W would definitely be three 8-pins. And no reason? Look how many people crashed their GPUs with single pig-tail connector on 225W Navi cards. Transient power draw is an issue.",
      "2x8pin means between 301W and 375W peak power consumption unless AMD is going over PCIe power standards (which they've done before)."
    ]
  },
  {
    "brand": "amd",
    "generation": "6000",
    "tier": "mid",
    "matched_keywords": [
      "6700xt"
    ],
    "title": "Maybe not the best 6700XT model, but I'm incredibly happy with it and it was $320",
    "selftext": "",
    "comments": [
      "I think anybody would be happy with it at that price.",
      "There's big devaluation currently happening in my country (Argentina). The dollar exchange price was up like 50% in a short amount of time and some retailers hadn't updated the prices. I had some Ethereum that I mined with my old 5700XT and it's essentially valued as dollars here so I said fuck it and got it.",
      "Where are you guys finding $320 6700XTs?",
      "There's hardly no difference in models . Enjoy your card",
      "Lucky break",
      "It's Argentina pricing, he is using the \"black market\" USD exchange rate. \nThe importers here get USD at cheaper prices, and even with all the tariffs and stuff the cards end up being cheaper with the black market exchange rate.\n\nTake into consideration that the median monthly Argentine income is around 350-400 USD (taking black market exchange rate), so someone needs to save for a few months to buy a graphics card. I would rather pay 500 USD a graphics card with a 1500-2000 USD monthly income If you ask me.",
      "This.\n\nHave an ASRock 6800XT in the house and it has been doing as well as can be expected from any 6800XT.\n\nEnjoy!",
      "No they not. Stop spreading bs. As long the block is lower then the rad its ok.",
      "Not the OP, but I bought a used Qick 319 6700xt on ebay for $320 last month. If you don't mind a used GPU, you might be able to find a similar deal as well.",
      "Yeah, I watched that video too. Steve mentioned that the tubes should always be higher than the pump and they are. There's literally no other way to orient it I'm my case and it's been running fine like this for 3+ years",
      "I tried but it's longer on the side with the tubes so sadly it doesn't align properly if I install it upsidedown. It also doesn't fit on the top so I have no option but to leave it as is. The hoses are a little bit higher than the pump so it should be fine though.",
      "Hey, if it works it works, what's important is that it is sufficient for your needs and doesnt overheat.",
      "Awesome card for that price. The 5600X/6700XT is a great combo",
      "HOW?!\n\nHere the cheapest RX 6600 cost like that!",
      "I got my RX 6600 Powercolor in 230USD (argentina)",
      "Yeah aio seems to have to short hoses anyway to put them at the bottom.",
      "I 'just' want a 6700 XT msrp or lower",
      "So cheap‚Ä¶ I can‚Äôt get that price in Malaysia ‚Ä¶zzzz",
      "You don't need to feel like your card is lesser than just because it's not a premium model regardless of the GPU you get but especially of a mid range one like a 6700xt, used or new. It's nothing to brag about to get a premium model of a mid range card. In fact, kind of the opposite; it's a bit foolish, unless you somehow got it for a cheap price.",
      "I mean personally i'm looking at selling a 6800XT around the $500s."
    ]
  },
  {
    "brand": "amd",
    "generation": "6000",
    "tier": "mid",
    "matched_keywords": [
      "6700xt"
    ],
    "title": "2022: Join team red 6700xt + 5600g",
    "selftext": "",
    "comments": [
      "Right?",
      "Nice!\n\nThe HDD is just for backup purposes, right?",
      ">D is just for backup purpose\n\nHahahaha yes and just extra cheap storage (got two m.2 NVMe SSDs in the motherboard)",
      "Coming from a 1070 ti and 2700x I absolutely love the increase in performance and lower power draw (both GPUs while gaming draw the same about 180w +- and the CPU is much lower on the 5600g 60w vs the 2700x 105w).",
      "Great question and one I meditated on for a number of weeks. After a ton of research I saw that the 5600g was around the gaming performance of a 3700x which is enough with my 6700xt. AND I want to repurpose the 5600g in another sff (non GPU, 3 litre case) build that's currently got a 2200g. I'll do so when my 5600g starts to bottleneck in games (if it does) I'll consider the 5800x3d or AM5 depending on the times. I've got a fairly large library and it doesn't bottleneck any of my games except for the new spiderman (with everything in highest and has been know to hog all CPUs hoping there's going to be a new patch to take less load on the CPU).",
      "Doesn't look like enough to affect performance. The back plate is a bit bent as well. Wonder if it was shipping damage.",
      "Compact!",
      "Why did you choose the 5600G? Wouldn't a 5600 non-X offer much better performance?",
      ">u radiator fin seems to be a bit curved at the end. Cute build overall, i like this si\n\nWow didn't even spot the back plate! Yes I got it for a steal on the second hand market now I know why lol. Check performance and cooling though all it perfect on that front.",
      "Your gpu radiator fin seems to be a bit curved at the end. Cute build overall, i like this simplicity.",
      "About every three years I upgrade my system, and realized this time, I could get away with upgrading only the CPU (after flashing MB bios), as everything else was still sufficient. Went from 2400G to 5600G. Wow, what an increase. Everything in Windows just flies. Going from Zen 1 to Zen 3 is a huge increase.",
      "Hmm why the G though and not a 5600/5700?\n\nEdit: Nevermind, read the comments.",
      "Haha \n\nBarracuda go boom!\n\nhttps://i.imgur.com/GU4O57V.jpg",
      "It's a Cooler Master NR200 \n\nInitially bought it as it seem like a budget all rounder and to fit my old atx psu (with 3d printed bracket) in now I'm just great-full I went for \"bigger\" mini itx case as gpu's have gotten really huge!",
      "All good if used. I would be a little annoyed if it was new.",
      "Enjoy the 6700xt such a beast",
      "Welcome and congratulations üéâ",
      "I can't imagine having something that's sensitive to magnetism, that is that close to an object that emits electromagnetic radiation.\n\nBut I'm sure there's been tests about that otherwise they wouldn't do it. Neat compact build!",
      "very nice build! i have the same cpu paired with 1080ti and its great.\n\nMake sure to run RAM at highest clock your cpu allows. you can pump 1.3v vSOC safely to Cezanne , it should let you run fclk at 2200+ . due to smaller cache than Vermeer , these chips benefit greatly from fast ram and fclk. also don't underestimate the performance impact of the below timings (up to 15% more fps in some games) :  tRC tRRDS tRRDL tRFC",
      "that pc looks so small if i try hard enough i could fit it in my pocket"
    ]
  },
  {
    "brand": "amd",
    "generation": "6000",
    "tier": "mid",
    "matched_keywords": [
      "6650",
      "6650xt"
    ],
    "title": "The RX 6700 (Non-XT) is currently 10‚Ç¨ more than an RX 6650 XT, worth it?",
    "selftext": "Sapphire Pulse RX 6650XT = 376‚Ç¨\n\nSapphire Radeon RX 6700 Gaming OC = 386‚Ç¨",
    "comments": [
      "2gb extra of vram and 4% more performance. For 10,sounds not bad to me.",
      "Yes of course it's worth it!\n\nRegarding the GPU part:\n\n32CUs(2048 Shader Cores) => 36CUs(2304 Shader Cores)\n\n2MB Level 2 Cache => 3MB Level 2 Cache\n\n32MB Level 3 Cache (renamed InfinityCache) => 80MB Level 3 Cache\n\n&#x200B;\n\nRegarding the VRAM part:\n\nVRAM bus width: 128bits => 160bits\n\nVRAM size: 8GB GDDR6 (17.5Gbps) = 10GB GDDR6 (16Gbps)\n\n(here the VRAM frequency drops in favor of the quantity, but this drop will have no impact on performance because it will be largely compensated (or even surpassed) thanks to the increase in InfinityCache and the VRAM bus widths)\n\nFinally, the PCIexpress bus goes from \"PCIe4.0 x8\" to \"PCIe4.0 x16\", and all this for an identical thermal release (TDP) of 175Watts, in stock settings of course.\n\nSo of course that for 10 Dollars the Radeon RX 6700 10GB is more interesting than the Radeon RX 6650 XT 8GB, it is slightly more efficient (5 to 10% depending on the game) but above all it is more \"future-proof\".",
      "They're the same. The 6650 XT is a 6600 XT that's pushed a little further on the performance/power curve while the 6700 is a cut down 6700 XT (larger die).\n\nIn general, a larger die gives greater performance/clock and performance/volt. So if you undervolted and clocked both cards, the 6700 would be much more efficient.",
      "It's technically a stupid question on their part as you're fully in control of the power limit. So simply setting a lower one would be better. Matching TDP they should perform better still.",
      "$10 for 2gb  more vram seems good to me!",
      "Bruh. Who cares? You‚Äôre getting a better chip and more VRAM. Get it",
      "The trick is to UV and limit the frames to the max your monitor is capable.  \nNo need for 300 frames when your monitor can just handle 144hz",
      "Honestly, currently the Radeon RX 6700 10GB is the GPU with the best Performance/Price ratio, and even more so if you plan to overclock the card a little(or even more).\n\nOtherwise, if you want to wait a little longer to decide, soon the graphics card that will have the best Performance/Price ratio will be the Radeon RX 6800 16GB because in my country (in France) it is starting to slowly (but surely) approach 500 ‚Ç¨, which will give it the best performance/price/future-proof ratio with its 16GB GDDR6 and its excellent 4K performance.",
      "Get the better chip and do -100mV in the driver and you are golden",
      "6700 uses same or less power than 6600, let alone 6650 XT",
      "So silicon needs a certain amount of voltage to hit a certain clock speed, but it varies with every unit. So they set a super high voltage to get the highest yields (working units divided by total units), but by definition it's excessive for most of the units.\n\n\"Undervolting\" is reducing this voltage while keeping the clocks the same. This can actually *increase* performance as the card has more thermal headroom and can thus hit those clocks more, as well as free up thermal headroom for the memory and reduce load on power delivery (further efficiency gains). By reducing heat you also reduce CPU temps so it may boost more aggressively.\n\nAdditionally, the clock targets tend to also be set quite high, and there are steep diminishing returns to having higher clock speeds. So you can also reduce those clock targets which allows you to reduce the voltage further. You may lose a little performance but less than you think.\n\nFor example, by reducing clocks and voltage I was able to cut power consumption by nearly 20% and only lost ~3% performance on a 5700 XT. [See this user](https://www.reddit.com/r/Amd/comments/dgkfyb/more_undervolting_results_on_a_reference_5700xt/)\n\nEdit: Another thing is that silicon quality *increases* over time, but to my knowledge the stock voltage settings are not changed or set per card. So the later you buy the card, the higher the chance your card is overvolted. At least with rdna1",
      "Can you make a 6700 perform like an XT with some driver shenanigans like you could with the 5700?",
      "I don't think so, less memory and memory bandwidth keeps it separate.",
      "175Watts TDP too, i have said same thermal release, that's what it meant.",
      "I know, but electricity in my country is very, very expensive, I'd like to save as much money in the long run (electricity wise) as possible",
      "20W difference from what I saw. You could look up both cards specs (which I did on Newegg)",
      "6700 > 6650\n\nUndervolts and overclocks really well and is better suited to 1440p resolution\n\nCheck out Ancient Gameplays youtube reviews on the very card.",
      "Because the 6700 is clocked lower.  The 6650XT is pushed outside of the efficiency window for the chips.\nThe 6650XT is juiced to the max to squeeze higher performance out of a smaller chip.\nThe 6700 is a bigger chip with more compute units, so it can do the same work at less power.  \n\nObviously you COULD push the 6700 to use more power, but you wouldn't want to.  Even AMD's site shows the 6700 @ 175w TBP vs the 6650XT @ 180 TBP.\n\nIt's the same logic as what we're seeing with the new CPUs coming out where you can get like 95% of the performance but can cut 25% of the power usage.  (Those are arbitrary numbers, but the logic still applies.  The higher you push piece of silicon, the more inefficient you get.)",
      "Yes",
      "take the 6700"
    ]
  },
  {
    "brand": "amd",
    "generation": "6000",
    "tier": "mid",
    "matched_keywords": [
      "6750xt"
    ],
    "title": "I upgraded my RTX 2060 to a 4060 today only to go online and fine out that apparently it sucks. Is it worth returning and getting an RX 6750xt instead?",
    "selftext": "",
    "comments": [
      "Not sure why you would decide to do your research *after* buying the product, but if you‚Äôre happy with the performance you‚Äôre getting just stick with it.",
      "The 6750XT is a card I would have suggested over the 4060 if you had asked before you purchased.\n\nThat said, you‚Äôve already got it now. And to its credit, the 4060 does have DLSS and frame gen. It‚Äôs not that it‚Äôs a terrible card, it‚Äôs just that its overpriced compared to its competitors which perform better with more VRAM.\n\nThe 6750XT is around 18-20% faster. Which means if you‚Äôre getting 60fps on your 4060, you‚Äôd be getting more like 72fps on a 6750XT (with better textures probably because of the higher VRAM). If that‚Äôs worth it to you, then sure swap em out ü§∑üèª‚Äç‚ôÇÔ∏è",
      "Brother you don't check framerates / frame times ? Install MSI afterburner and learn how to use it..",
      "Did your performance increase?  Are you happy with the performance you have?  If so why change it after you already purchased and installed it?",
      "Thanks man I'll ask my dad if we can try and return it tommorow. I feel really awful about the whole thing cause I adamant it was the best one for the price",
      "why does 4060 suck tho",
      "I don't think it'll fit onto the motherboard now that I'm looking at it :((((",
      "why did you keep it?",
      ":)))) yeah see.. use MSI afterburner bro it's worth it for watching CPU and GPU % usage and temps",
      "I tend to find out that small upgrades, like same tier of card but two generations younger don't paint such a beautiful picture in my computer as they do in reviews and tests and whatnot, and gains in-game can be smaller than in benchmarks. This may depend on what you're trying the card to do (e.g. churn out frames vs process ultra-HD textures in 4K, the latter of which is of course VRAM-intense). I feel that to some extent, in some ways, a 60 is a 60, a 70 is a 70, and a generation or two doesn't always cause a big uplift in the same old games (though it could in newer ones).\n\nRe: nVidia vs AMD, choose nVidia for DLSS and/or ray-tracing, choose AMD for rasterization performance and if you're okay with FSR instead of DLSS, and if you want more RAM for textures (but of course compare how much they have, it's just that AMD will normally tend to have more).",
      "Try turning on DLSS and frame Gen.",
      "A 4060 should be around 50% faster (at 1080p) than a vanilla 2060.",
      "I did some research before and didn't see any of the bad shit about the graphics card yet like IMMEDIATELY after installing it I get a video in my YouTube recommendations calling it Nvidias worst product",
      "It's still a powerful card compared to a 2060, when people say its bad it doesn't mean its going to explode in your face, its just not the greatest value to performance card out there, if you're happy with it then stick with it. If you're someone that cares about saving a buck and/or getting a bit more performance then look into better cards.",
      "No problem. But hey, just make sure it fits your case. The cheaper 6750XT and RX6800 are pretty long cards depending on which one you‚Äôre looking at. Just be careful not to accidentally swap for a card that won‚Äôt fit in your PC case.",
      "Cut twice and measure once!",
      "Idk. I think people are mad it has 8 gigabytes of vram. It's running pretty smooth for me so far",
      "Man i wish it was the same here, the 6750xt is a whole 100$ more expensive than the 4060 here",
      "will 6750 XT run quiet at 4k gaming (3840 x 2160) ?",
      "Okay so turns out the game I was playing auto changed all of the settings to ultra murder fucker raytracing 3000 and that's why the game was running like ass. Turned it off and it's running smooth as hell now"
    ]
  },
  {
    "brand": "amd",
    "generation": "6000",
    "tier": "mid",
    "matched_keywords": [
      "6750xt"
    ],
    "title": "Deciding Whether or not to get the RX 6750xt now for $349 ($379 Ship & Tax) or wait to some other deal comes out",
    "selftext": "",
    "comments": []
  },
  {
    "brand": "amd",
    "generation": "6000",
    "tier": "mid",
    "matched_keywords": [
      "6700xt"
    ],
    "title": "6400 to 6700XT comparison",
    "selftext": "My old rx6400 compared to my new 6700XT.",
    "comments": [
      "[a 6900XT reference Vs a Zotac 4090...](https://i.redd.it/9m5kgio8tc5b1.jpeg)",
      "Don't talk to me or my son ever again :p\n\nPs, congrats, enjoy!",
      "I need to see a 6400 next to a 4090 lol",
      "My old desktop PC was a SFF office computer with a LP 6400.  The kids used it for Minecraft and war thunder.  \n\nI decided to finish my desktop build so I could get Starfield.  Did a 7600/6700XT build.  I thought the 6400 was hilarious next to the 6700XT.  \n\nNow I'm going to sell my 3070ti Alienware laptop and buy a new monitor.",
      "I have no reason to buy a 6400 but it's just plain adorable lmao.",
      "also sand down the gpu die and get some closeups of the transistors, i wanna compare",
      "It's like those videos that compare starship sizes, or Kaiju sizes.",
      "Nice get! Last year I upgraded my CPU to R7 5700X and now I've gotten myself the 6750XT also because of Starfield!",
      "That is just ridiculous",
      "cool upgrade\n\n\nyour cpu cooler's fans are on backwards",
      "Thanks, I figured that out after these pics.  I have them both on the \"forward\" side of each stack now, with a front to back airflow direction.",
      "You vs the guy she says is just a friend",
      "There are very very few reasons.  Its probably the best priced low profile option that can actually fire up a modern game (at 1080 low or medium) at playable framerates.",
      "Shroud and fans are important. More powerful GPU's need larger cooling and fans to function.",
      "When i went from a 6800xt to a 7900xt lets Just say it was similair",
      "I wonder which one is faster.",
      "Amazing upgrade, enjoy the extra FPS!!üòÅ",
      "Unfortunate how all RX 7600's are the size of the 6700XT while the RTX 4060 has not only plenty mini-ITX sized options (meaning <180mm), but also a LP variant on the way... :/\n\nSo RX 6400 sized RTX 4060 or RX 6700XT sized RX 7600?\n\nIf I want to replace a certain 160 mm AMD flagship from 2015...\\* you can get about the same performance and the same VRAM capacity from AMD in form of the 6500XT (8!!! years later) OR get something from NVIDIA if you actually want an upgrade (RTX 4060/Ti).\n\n\\*R9 Nano (596mm¬≤ 28nm) ![gif](emote|free_emotes_pack|heart_eyes)",
      "I have the exact same gpu. One of the few dual slot 6700XT in existence.",
      "I have that same Sapphire 6400 on one of my SFF's. Great little low power bugger."
    ]
  },
  {
    "brand": "amd",
    "generation": "6000",
    "tier": "mid",
    "matched_keywords": [
      "6700xt"
    ],
    "title": "Rx 6700xt very low power draw??",
    "selftext": "Hi ,\n\nI just upgraded from Vega 64 to Rx 6700xt .\n\nI have got Shappire pulse model , I have quickly tried ac vallhala at 3440x1440 and I get gpu clock 2500Mhz , memory 2100Mhz about 75fps and a power draw of 130W \n\nIs that normal? Seems very low to me my vega used to draw 280W in games ...",
    "comments": [
      "To be fair, Vega was very power hungry beside using hbm",
      "6000 series cards are actually very efficient",
      "Don‚Äôt use hw monitor, it is not updated.  Use hwinfo64.",
      "I wouldn't trust power draw readings from Afterburner/Rivatuner, they've given inaccurate readings with AMD cards many times before. Use HWinfo instead. I'd like to know if you get the same power draw on HWinfo as well, if that's the case then there is something weird going on in my opinion..\n\nEdit: 75 fps at that resolution is crazy good by the way, my 5900X + 3080 struggles to stay at 60 fps @ 2560x1440",
      "Thanks it might be normal I am just so used to see 300W power draw that I was very surprised was expecting about 180-200W not 130 xD",
      "That's true I had to buy a new 850W PSU as it was crashing with my previous 650W all the time",
      "cup you use? Is the card at 100% utilisation?",
      "75fps is pretty good for ultrawide 1440p for 6700xt, so it's not like the card can push out significantly more and is in a need of power",
      "I have found it , Hwinfo shows that in ac vallhala at 1440p uw max settings is pulling 162W and Gpu PPT limit is 213.9W",
      "That's more reasonable. This made me open the game and check for myself and I'm only pulling  roughly 195W on an undervolted 3080 so ~162W is likely accurate.",
      "That is low.",
      "Is amd chill turned on in Adrenalin? My normal gaming load is pulling around 180w to 220w.",
      "If you don‚Äôt mind me asking,when, where, and for how much did you get an RX6700xt?!",
      "RDNA2 is very power efficient compared to Vega64.",
      "AC: Valhalla draws surprisingly little power, I have tested AMD and Nvidia cards and I have seen them drawing less than expected. On the other hand, The Division 2 draws an insane amount of power, pretty much more than any other game I recall testing.",
      "You'll never get accurate board power readings on an AMD GPU as it can't be done from the card itself, you need to monitor the external power rails.\n\nAMD only monitors power usage on the die itself, they don't monitor board power.",
      "Thanks I'll check it now and let you know .",
      "Or just use the AMD FPS overlay which gives the power draw as well",
      "Cpu is at : 36-40% Ryzen 3600\nGPU is at 99%",
      "Guess only undervolting could have saved you"
    ]
  },
  {
    "brand": "amd",
    "generation": "6000",
    "tier": "mid",
    "matched_keywords": [
      "6750xt"
    ],
    "title": "7600xt vs 6750xt",
    "selftext": "A year ago I would've blindly picked up the 6750xt due to the raw performance for 1440p (considering the values), but today I don't know. \n\nI'm unsure, I think dropping 15% performance for 4gb of VRAM is actually tempting, seeing as a few games I'd like to try can suck up to 16gb.\n\nAny thoughts? Thanks!",
    "comments": [
      "im taking the 6750xt then. i thought you had the 6750xt and were gonna downgrade to the 7600xt lol.",
      "thats a downgrade in terms of performance. smallest uptick id take in your situation would either be the 7800xt or minimum the 7700xt. wouldnt lose performance for slightly more vram.",
      "My OG 6700xt is still going strong 3yrs later 1440p 144/165hz gaming",
      "you didn't mention prices.\n\nfor example depending on the prices the rx 6800 could be the far better deal at 360 us dollars nw instead.\n\nit has 16 GB vram and it outperforms both.\n\nat 1440p the rx 6800 is 40% faster than the 7600 xt, while generally being better price/performance compared to the 7600 xt.\n\nand the rx 6800 is also 24% faster than the 6700 xt. don't have data on the 6750xt for comparison exactly.\n\nbut the rx 6800 would be a big step up and better value/us dollars.\n\nso while again not knowing the prices for your region for those 3 cards, the rx 6800  may be the best option and it is quite close in absolute price to those other cards generally.\n\nif i were a friend of mine, i'd tell you to either get the rx 6800 if you want a new card for the holidays, or wait for q1 2025 to get an rdna4 card.\n\nand as rdna4 might just be great value at 500 euros/us dollars, but maybe 360 us dollars range is still shit, the rx 6800 at 360 us dollars might still be the best option.",
      "Budget won't allow me for a 7700xt. I only have enough for a 6750xt or 7600xt, 1440p and it has to last at least 3 years",
      "Oh no, I'm discussing 16 X 12gb VRAM for the performances. Are you sure 12gb will be enough for 3 years?",
      "no one knows. im regardless gonna take the significantly faster card even if that means lowering settings to fit the vram allotment of the card i choose. i play at 1440p high refresh and with my 6900xt i can basically pin my monitor at 165fps with any game that i play. id also look for some used options ive seen 6800xt sell right around the price of a 6750xt. yeah no warranty but for 1440p being on a tight budget seriously limits your options considering its more difficult to run than 1080p for a gpu.",
      "Brazil used prices are as bad as new ones, it ain't worth. Guess it's gonna have to be the 6750xt",
      "No feedback but they are widespread for $350 shipped new now.",
      "would have been nice to know you luved outside the us because i just found this https://www.ebay.com/itm/387605579168?mkcid=16&mkevt=1&mkrid=711-127632-2357-0&ssspo=vbocw198ruc&sssrc=4429486&ssuid=&var=&widget_ver=artemis&media=COPY brand new 6800 for 320 which is cheaper than ive seen 6750xts going for. look for a 6800 in your area you might get a huge performance boost for not much more money."
    ]
  },
  {
    "brand": "amd",
    "generation": "6000",
    "tier": "mid",
    "matched_keywords": [
      "6750",
      "6750"
    ],
    "title": "2080 super vs ry 6750",
    "selftext": "Currently i am running the 2080sp but its really struggling to run stalker 2 so im thinking its time for a upgrade, i dont care for raytracing tbh so im thinking of going for a rx 6750 or should i wait for something else, Any guidance is appreciated.",
    "comments": []
  },
  {
    "brand": "amd",
    "generation": "6000",
    "tier": "mid",
    "matched_keywords": [
      "6650"
    ],
    "title": "AMD Forces a Price Increase: Radeon RX 6650 XT Review",
    "selftext": "",
    "comments": [
      "\\> But why?\n\nFor the price increase duh",
      "Absolute shockers how basically with [worst marketshare](https://g3f4h2w2.rocketcdn.me/wp-content/uploads/2021/12/GPU-Add-in-Board-Market-Share-2002-to-Q3-2021-1024x358.png) ever, instead of looking for ways to gain some marketshare back - they drown themselves even further with, as predicted, lazy msrp bump for final RDNA2 cashgrab",
      "Yes, and rumor has it that the 7xxx series is supposed to be at least $50 dollars more than these MSRP. Simple answer is, don't buy them. I realize that may not be an option for some people but the only way to get the point across that we won't be gouged to death for corporate profits is to not buy the cards.",
      "Sure, but at this stage, AMD is losing marketshare at a rather alarming rate. Intel hasn't even entered the space yet either, AMD should be fighting tooth and nail to keep as much marketshare as they can before Intel enters, because you can bet your bottom dollar, Intel's strategy will be to target the mainstream market which is where AMD is currently succeeding. \n\nIntel will simply outprice AMD and NVIDIA to gain marketshare and then what will AMD have to show for it, AMD's fanbase primarily buys based on value in dGPU, so once Intel provides better value why choose AMD? AMD can't beat NVIDIA in sales in the high end halo market due to NVIDIA's mindshare and they also can't beat them in the midrange sector where NVIDIA will simply out-ship and out-market them. Adding Intel into the mix only puts AMD in a tough position, so they better believe they're gonna have a problem when Intel starts putting out cards at cost price or at a loss just to get marketshare.\n\nThe only saving grace for AMD is that they will be able to match NVIDIA for performance or slightly beat them or slightly lose to them in a particular segment, but that matters very little because AMD's had that advantage for years and still cards like the GTX 1060 out-shipped the RX 480/580 and RX 470/570 combined. AMD for whatever reason can't penetrate the market towards gamers, despite their business being slightly profitable in terms of margins. I think it really has to do with their marketing, it's cringe, Radeon Rebellion is a good example of just cringe marketing. Then you have situations like Vega where they hyped it up only for it to release later than the GTX 1080 by a year and match it in performance. I'm happy those days are a bit behind AMD but they also don't seem to not market very effectively. NVIDIA's name is plastered everywhere in net cafes, at eSports events, they will send parts to streamers to promote stuff, they will even work with Intel on overclocking records etc. AMD does none of that because they're too stubborn or too stupid to. AMD's marketing \"hype\" is to put RDNA2 in Fortnite, which isn't their target market for starters and especially when Fortnite was losing popularity too... It's not even comparable the two types of marketing, NVIDIA is simply better in that area, even if NVIDIA imo is disingenuous, they simply will put their name out there more effectively.",
      "Would have made it even more sense to launch it at the 6600XT price then if they are discontinuing it.",
      "This thing gets basically the same performance as a 5700XT and costs the exact same amount, the only advantage it has over the 5700XT is some lackluster RT. Modern GPU prices are a joke...",
      "Fanboys will twist anything to argue \"it's good for us!!!\"",
      "In my country and i also checked in Germany the price difference was around 60‚Ç¨ so maybe it depends a bit on market.",
      "this looks utterly atrocious",
      "The whole point of a refresh is to offer better performances at the same price",
      "Be aware that we've been told by multiple sources that the initial wave of 6650 XT stock has been subsidized by AMD in quite a few regions, so I'd wait a little bit before making any conclusions regarding pricing.\n\nThat said if they are going to continue to keep selling the 6650 XT at the same prices the 6600 XT's were available when why make the price hike official? Not a good look for AMD if that's the case. Ideally at this point you'd want the MSRP to be $20 lower, not higher :D",
      "If you check Newegg there actually isn't a price increase. There's 3 models in stock for 400 right now, which is the same price AIB's were selling the 6600 XT for and also the MSRP of the 6650 XT\n\nWhat I think happened is AMD is stealing the scalper margin from AIB's with this card. The price AMD (and Nvidia) charges AIB's for GPU dies is based on MSRP. However, the 66X0 cards do not have a reference model, so AIB's decide the actual selling price. AIB's were basically buying dies from AMD with the 380 MSRP in mind and then scalping them to 400.\n\nWe saw this before with the 2060. Nvidia reduced the MSRP to 300, but after quickly selling off their remaining FE's, they never restocked them. That means AIB's were free to set the actual selling price so the *actual* cost of a 2060 was 320-340. But AIB's got the dies from Nvidia with the 300 dollar MSRP in mind.\n\nAMD (and Nvidia) likely set the contracts up this way because in a normal market, the selling price for the card would be around their MSRP. Both companies do not have the scale of AIB's to produce PCB's and the other needed components, so they're reliant on them, especially for the cheaper models. Which is why that compromise was historically left in. But obviously AIB's took that little loophole and *ran* with it over the past two years.\n\nSo AMD just set the MSRP at what the actual selling price would be to be more honest and get more from AIB's. So this is actually a net positive for gamers oddly enough because they're now getting a *faster* card for the same price as before.\n\nThe issue is the reviews didn't know that this would happen since they can't see the future so they all come off as negative. Even though this card is actually a net positive for gamers. But imo the price jousting is pretty interesting from a business perspective.",
      "Their mindset has always been the same...the only difference is that now they can get away with more due to the high demand.\n\nThat doesn't change the fact that this is a trash refresh that add nothing to the current generation so people have all the right to be pissed off.",
      "It looks like the 6600 XT is getting discontinued but the 6700 XT and 6900 XT will still be around. Good news is that multiple models of the 6650 XT are in stock for MSRP (399) at Newegg so it's actually overall an improvment.\n\nThis card looks like AMD stealing the scalper margin from AIB's without changing the street price for people.",
      "Market share doesn't matter if your margins are still massive. Losing sales/market share isn't always a bad move if you can charge more % wise.",
      "This wouldn't be the product to gain marketshare back though, and certainly not at this stage, perhaps 4/5 months out from the next generaton. \n\nAlso desktop GPUs is one of AMDs lowest priority product categories.",
      "Expected really.\n\nEurope is basically the MSRP in euro (1:1 vs $) + 19-27% tax.",
      "There's been RX 6600 XT at 380 with launch batch. So what's your point? Making conclusion on launch batch?",
      "> Why cannibalise profits and future sales while the demand and price are sky high?\n\nDemand and prices are dropping pretty fast. Stuff's all going back to normal, so really, the whole bubble is about to burst. Plus, Crypto is in shambles.",
      "39% makes up a considerable chunk of their revenue though, and is by the far the fastest growing segment. \n\nFrom your own link:\n\n>between Q1 2020 and Q1 2021, which was a 92% increase. Further analysis reveals that revenue from the Computing and Graphics segment has grown at a rate of 46%, while that from the Enterprise, Embedded and Semi-Custom segment has grown at a rate of 286% during this period.\n\nThe margins on enterprise will be that much higher than mainstream as well."
    ]
  },
  {
    "brand": "amd",
    "generation": "6000",
    "tier": "high",
    "matched_keywords": [
      "rx6800",
      "6800"
    ],
    "title": "Why is no1 talking about this: AMD is setting a new Performance/Watt standard with the RX6800",
    "selftext": "AMD is setting a new Performance/Watt standard with the RX6800(XT). 95% of the performance of the 3080 at 66% of the power consumption!\n\n&#x200B;\n\n[https://tpucdn.com/review/amd-radeon-rx-6800-xt/images/performance-per-watt\\_2560-1440.png](https://tpucdn.com/review/amd-radeon-rx-6800-xt/images/performance-per-watt_2560-1440.png)",
    "comments": [
      "Because we're busy talking about how we couldn't even have a chance at getting one.",
      "Because that's a terribly cherrypicked reading and clearly not representative of reality. I quickly looked at three other publications (Gamersnexus, computerbase, and PCGH) and all three conclude around 280-290W for the 6800XT and 320-322W for the 3080 (both within spec as quoted by the manufacturers), which are both a far cry from the numbers presented by TPU.\n\nRegardless of that, you fail to understand the reason of why AMD was called out in past years for their power consumption; It wasn't because they were drawing X amount of watts past some arbitrary threshold, it was because they were drawing FAR more power than the competition with much less performance to show for. Right now, AMD cards are undoubtedly more efficient, but the gap is so small that they could almost be considered on the same tier of power consumption/cooling requirements for the performance that they bring. \n\nIf you're going to be power hungry, you better be bringing performance to the table to justify it, which is what both companies did.",
      "Because that's like discussing supercars fuel consumption. Noone cares.",
      "As an ITX case user - I care. The performance per watt is really impressive. ITX builds are quite niche, but AMD definitely have an edge there because of it now.",
      "I dont want to be cooking during summer!",
      "Don't live in a hot climate I see. Thats one of the most important things to consider when living in a hot place. Yes I can use AC but the less heat I generate in my room, the better.",
      "I never got those \"arguments\". Were not comparing microarchitectures or nodes, we're comparing GPUs, how they perform and what power they draw. The rest does not matter, really.",
      "Exactly, Can't get an Nvidia, can't get an AMD, heck can't even buy the 4K monitor that I'm after. Gaming is going to be pretty shitty this year and 2021. Maybe even 2022. I guess I will be waiting for the next Generation of cards.",
      "Sure, but you can undervolt the 6800XT, too. \n\nComputerbase say you can knock 10W off and actually *improve* performance by ~4-5% overall. I'm sure if you give up those improvements you can knock even more wattage off of the top.",
      "After seeing the power of rtx 3000 series people just slide off the power usage.",
      "> uses GDDR6X\n\nThat's part of its architecture design. NV used it because they needed more memory bandwidth.\n\nAMD went with on-die cache to avoid using expensive & power hungry 6X.",
      "Because TPU's power consumption numbers are nowhere near close to other reviewers numbers.",
      "As a stockholder, I care because that's all the enterprise market cares about lol",
      "TBH, I'm wondering if I'm just going to permanently hang 1+ generation back. Buying computer parts has become a circle of hell, these past few years.  A 3900X paired with a 570 can actually give me utility, today. My 1080Ti is waterblocked, and can hang awhile longer...",
      "I'd save this type of rage (and yes, that is what it sounds like i'm sorry.) for after seeing how the stock is with non-reference cards. I personally wouldn't mind if the reference was sacrificed for non-reference stock to a degree.\n\n I mean we will still see \"no stock\" day 1 of non-references no matter if they have acceptable stock or unacceptable stock because the demand is just insane atm but we can probably still judge them by how many ppl can get their hands on one / reseller volume on ebay etc.\n\nAll that said, it really weirds me out how much feeling people invest on launch-day product availability i have to say. I don't mean this as to be an apologist, just i've never been in that boat and i cannot get used to seeing it happening still.",
      "AMD building automatical boost into their chips is actually a perfect example of how efficiency means more headroom. If their chips used 20W/core to sustain 4GHz instead of 10W, they wouldn't be able to boost as high and the feature would be far less impactful.\n\nAlso, efficiency definitely means more thermal headroom for a given level of performance, which means exotic solutions are not needed. Look at some of the partner 3090 boards. Like, holy fuck they are just comically large.",
      "It's only 20-30W less than a 3080, not going to make a big difference. Seeing power figures from GN or HUB, it's not more efficient than Amp√®re. TPU is the outlier.\n\nhttps://www.techspot.com/review/2144-amd-radeon-6800-xt/",
      "Because you‚Äôre ignoring literally every review that does not support TPU",
      "I don't consider this an efficiency win. Ampere is on a considerably worse node, has a bigger die, uses GDDR6X (80-90w) and still manages to perform similarly.\n\nImagine if this was apples to apples with Nvidia on a comparable node and it would be the same story as usual which is exactly what's going to happen when they make the move.\n\nEven now the core only power draw of a 3080 is in the 200w range with most of the rest of it's power budget going to VRAM. This is just my opinion but I don't see parity with Nvidia in rasterization as the incredible achievement it's being made out to be here. AMD had a huge opportunity while Nvidia sandbagged in favor or profit using what is essentially a 10nm node and still came up short. They will take a beating next go around.",
      "To be honest, while I dont care about power draw that much, its still nice not having a sauna in your room."
    ]
  },
  {
    "brand": "amd",
    "generation": "6000",
    "tier": "high",
    "matched_keywords": [
      "6800xt",
      "rx6800",
      "6800"
    ],
    "title": "Anyone got experience with a Rx 6800/ xt with only a 550W PSU ?",
    "selftext": "\nManaged to get a RX6800 and thinking of using it with my ryzen 5 3600\n\nOnly problem is I have a 550W PSU. It‚Äôs an Corsair RM550 and it hasn‚Äôt even been in use for half a year\n\nWould also be interested in the performance with a 6800xt (maybe undervolted)",
    "comments": [
      "What's the power supply recommendation from AMD or the board partner? Follow that.\n\n\n\nAMD's website says 650W for 6800 and 750W for 6800XT.",
      "Don‚Äôt ever cheap on power supply. You may run it , probably gets black screen (an indication of insufficient power) but you‚Äôll also be putting all of the components inside your PC at risk overtime due to early degradation from maxing out your PSU. A blown out PSU can easily destroy your whole PC.",
      "Stick it in the computer. If it reboots at max. load, then the PSU isn't enough. It might also run fine for a while (months/years) until the PSU degrades and then it will start rebooting or causing other problems.\n\nThe best scenario is to follow the min. psu recommendations set by the manufacturer.",
      "I tried using a reference 5700 on a 500w psu and it‚Äôd occasionally reboot itself. I got a 650psu to prevent potential damage. If you have a 6800, id go no less than a bronze 650w. I‚Äôve since upgraded to a RM750 gold but used a power spec 650 on it just fine (with my reference 6800)",
      "1) Wattage isn't the end-all be-all of a PSU. It's much more than that. Efficiency, transient response, ripple. These are all just as important as wattage.\n2) Suggesting a wattage based on only the GPU is meaningless. A suggestion that does not at the very least also take the CPU into consideration is to be discarded. \nYou can run a 5950X and a 6900XT on a cheap 800 watt PSU and it can go out in fireworks, and you can pair it with a high quality 600 watt PSU and never have any problem.",
      "Any source for the \"degradation from running at max power\" ? Seems strange that the manufacturer would advertise unsafe power ranges for the product.\n\nLower efficiency at max power why not? But degradation?",
      "Shit 700W PSU can be a lot worse then good 500W PSU. It gets complicated. And the efficiency rating is not always a reliable indicator for PSU quality, but there's some correlation.",
      "u/str33tsofjust1c3 said what I came to say.\n\n\\*edit\\* I see now the RM550 only has one 8-pin EPS CPU connector on the PSU end, and one 8-pin PCIe connector on the PSU end, which means you'd be using a daisy-chain cable (one PSU hookup, two PCIe hookups on one cable).\n\nI would not run the RX 6800 XT on a single, daisy-chain PSU cable.\n\nThe RX 6800 would \\*probably\\* be fine...\n\nPSU Quality is SO much more than that pretty number on the side of the unit.  The Corsair RM series is a solid, basic, gold-rated PSU.  For an RX 6800, you shouldn't have an issue at all.  For an RX 6800 XT, so long as you didn't go ham with the power limit, and especially if you locked clocks to say, 2500MHz, and undervolted, I don't forsee you having issues.\n\nSpeaking in general, a few good \\*rough\\* feeler gauges of PSU quality are:\n\n\\- Price of the unit, compared to...\n\n\\- The max wattage rating, the max single-rail 12V amperage rating\n\n\\- The length of the warranty.\n\n\\- And the efficiency rating (though this is MUCH less important than the previous two items)\n\nRe: Warranty.  The warranty length is telling you the general quality of the electronics components used within a particular unit.\n\nMy rules of thumb are: A gold-rated PSU with a 5-year warranty is the \\**BARE*\\* minimum I would ever consider, and I would *only* buy it if there were NO other PSU's with a 7+ year warranty available.\n\n7-year warranties are the bog-standard for decent-quality Gold-rated PSU's.  A lot of gold-rated PSU's are coming with 10-year warranties now, with higher efficiency rated PSU's coming with 10-12year warranties.",
      "Because of transients tripping the OC protection.",
      "One thing about the psu, case, and fans, is that they can last you 8-10 years over multiple systems.  My cx500 is circa 2013 and it lives on with a 1700 gtx 1080 system I use as a backup.",
      "I'd say the same, don't go cheap on a psu. My last psu, Corsair HX520w, lasted me 12 years and still worked ok. I only upgraded it recently because of a new build. Also running a psu close to full load will kill it faster.",
      "Read manual I got a 6800xt and manual reccomend no less than 750w",
      "I have 5700 gaming x paired with a Pure Power 10 500w and never had a reboot (ryzen 3600)",
      "I‚Äôve seen my 6800xt hit 330w, that cpu will hit 120w = 450w and change... it‚Äôs damn close, too close I‚Äôd say. I have a 700w I‚Äôm not worried when recommended is 750w.. but 550w you say? Gulp.",
      "i'm talking about from the socket full system powerdraw",
      "with platnium efficency at 240V it's around 95%+ efficency so 532W for the components still extremly close to 550W",
      "I don't know enough, but it happened with the Vega cards and some Seasonic high-end models a few years back.\n\nWith more recent GPUs and their dynamic/opportunistic boost, it seems the problem is the fast load changes more than the mere wattage.",
      "Well OP if your reading this 6800 mostlikely fine 6800XT prob fine but if you start getting Black screen crashes Swap the PSU.\n\nthere everybody should be happy now",
      "That's marginal at best. Very marginal.\n\n[https://www.whatpsu.com/psu/cpu/AMD-Ryzen-3600/gpu/AMD-Radeon-RX-6800-XT](https://www.whatpsu.com/psu/cpu/AMD-Ryzen-3600/gpu/AMD-Radeon-RX-6800-XT)\n\nI honestly think minimum 600W as recommended by [whatpsu.com](https://whatpsu.com) is marginal. The PSU is most happy when it can deliver about 40-50 % of max rated, and a practical max is about 60 % of rated. Pushing it to max rated over time not only produces an ungodly amount of heat, but it also shortens the life of the PSU significantly, and potentially worse if you're really unlucky...",
      "Would not realy try that i got my 6800xt hooked up to a 850W platnium PSU and with wattmeter from the socket i'v had spikes up to like 560W and i'm on 240V so it's more efficent to compared to if you are in the states on 120V and your rocking a gold PSU"
    ]
  },
  {
    "brand": "amd",
    "generation": "6000",
    "tier": "high",
    "matched_keywords": [
      "rx6800"
    ],
    "title": "Radeon RX6800 is overpriced IMO",
    "selftext": "I think the pricing of RX6800 is not right it's $80 more expensive than RTX3070 which is $499, yet RX6800 barely beats RTX2080Ti, also RX6800 lacks DLSS which is a huge deal moving forward. I think RX6800 should cost around $449 otherwise it‚Äôs DOA.",
    "comments": [
      "it's 18% faster on average.",
      "only with the smart access memory feature and you need ZEN3 for that. They didnt show \"stock\" 6800 performance.",
      "I disagree, 3070 is DOA because 8GB is not enough anymore at all. Games already taxing 8GB for awhile now. Probably why Nvidia is rushing a ti version with more VRAM.",
      "I do think the 16GB of VRAM makes it a bit of a better deal, but I'd also have preferred if it was a bit cheaper and the 3070 as well for that matter.",
      "It beats it by 15-20% and has double the VRAM. Some of you guys will never be satisfied i swear. Its a very good value product.\n\nI guess AMD should just start undervalluing their products and sell them for bargain prices to make some of you people will be satisfied.\n\nAnd lmao at the DOA comment. The hyperbole is strong.",
      "It beats 3070 in AMD select titles, we need to wait for real reviews before saying anything, but I still see NVIDIA advantage since it has DLSS which boosts FPS by almost 40%",
      "I think after benchmarks we're going to be left with the 6800XT as the only card worthwhile in this lineup.\n\nSame for NV and their 3080. The flagships from both companies look absolutely worth their costs but the halo cards are just looking like poor value and I'm iffy on the 3070/6800\n\nThe 3090 is ridiculous, the 6900XT looks like a 3080 + Zen3 helping it reach 3090 speeds. The 6800 doubles RAM of the confusingly low 8gb 3070 but the 6800 doesn't have DLSS.",
      "Do you really think the 3070 real market price will be 499?",
      "The 3070 basically matches the the 2080Ti. The 6800 beats them both, and has double the VRAM. That's how I see it",
      "I think it is unfair to say that 8gb is not enough anymore when in all the third party reviews the 3070 managed to match the 2080Ti even at 4K. It may not be enough for 4K in future, but at 1440p I am sure it will suffice for future games.",
      "Same can be said with AMD.",
      "Lol this. FE prices are a lie.",
      ">\"Remember, the 3070 handily beat the 2080ti also.\"\n\nLmao it does not. Where did you get that from. The 3070 and 2080ti are basicly matched in performance down to a 1-2% difference.",
      "I don't think you understand how GPU works. Just because your 5700xt is maxed at 1440p doesn't mean 8gb is not enough. If 8gb will bottleneck a 5700xt then how does a 3070 even match a 2080Ti the first place. Your 5700xt is being maxed out before it can even utilize 8gb of vram.",
      "Cyberpunk 2077 will have DLSS support",
      "KEK \n\nAccording to gamersnexus the rage mode accounted for just 1%-2% improvement. The 6800xt already matches 3080 native without rage mode or sam, look at the benches without those features enabled\n\n>Anythign above that was pushed by the ZEN3 smart access memory feature + RAGE mode\n\nwhat makes ya say that increasing cu count by 8 adds nothing to it? We have rumors of aib cards clocking to 2.3 or 2.4ghz gameclock. The 80cu card already beats the 3080 just by having higher cu count because it runs at similar clocks to the 6800xt which matched rtx 3080, it just has additional few % from sam and rage mode that brought it closer to 3090 for marketing bench purposes.\n\nThe claim that amd ain't gonna beat 3080's already wrong because 6900xt without rage mode and sam definitely beats rtx 3080 in pure raster. You were also wrong about amd showing their best card in the zen3 teaser.\n\nHey i can man up to being wrong about zen3 gaming performance (yea i overestimated zen3), seems you can't do the same when you're wrong",
      "I know what you meant the first time; your vram is maxed out at 1440p. What I am saying is that just because you see you 100% vram usage does not mean that it bottleneck factor. If that's the case then a significantly more powerful gpu like the 3070 with 8gb of vram would not perform the same as a 2080Ti at 4K. \n\nI am willing to bet that a 3080 with 8gb of vram will perform almost identically to a 3080 with 10gb of vram within a 5% margin.",
      "You didn't mention 6800xt? You said amd showed their best and they ain't gonna beat 3080\n\nSo you're just gonna ignore the 6800xt matching 3080 at native and assume that increasing the cu count by 8 and maintaining the same clocks ain't gonna put the 6900xt ahead of the 3080?\n\nThat's denial man, hilarious how ya were going ham on others calling them delusional and in denial but are exactly that rn",
      "Why ain't the math checking out? +11% cu on 6900xt with same clocks, +7% performance across titles (not perfect scaling) and +3%-4% to match 3090. 3090's on average 10% ahead of 3080. \"Sam\" ain't gonna add 10% performance on average, it's on the low side between 3%-6% with outlier at 13%\n\nAin't gonna matter if it's 10% ahead of the 3080, even if it's just 5% ahead without sam and rage mode it's already ahead",
      "Didn't the 6800 use the smart thing too? So technically its less FPS then the chart if you don't have a new cpu?"
    ]
  },
  {
    "brand": "amd",
    "generation": "6000",
    "tier": "high",
    "matched_keywords": [
      "6800xt",
      "6800"
    ],
    "title": "4060ti or 6800xt ? Which one should I buy, in your opinion.",
    "selftext": "I am stuck between getting a 4060ti (16gb) or a 6800 AMD gpu   \n\n\nI have always had a Nvidia GPU so don't know much about AMD   \n\n\nIs the XT version like TI / SUPER ?   \n\n\nIf you were in my position which one would you get ?  \nThanks, and sorry for my lack of knowledge.   \n\n\n&#x200B;",
    "comments": [
      "if you're gonna be using it for mostly gaming and don't need any software using CUDA cores, get 6800xt, it's not even close. Both rx6800 and rx6800xt are gonna beat every version of 4060 and 4060ti in gaming.",
      "If you will do any blender or 3d modeling work on or if you want to use Ray tracing, nvidia is the best at that. So 4060 ti is the way to go. Though if you just want better fps go for 6800xt",
      "If you will do any blender or 3d modeling work or if you want to use Ray tracing, nvidia is the best at that. So 4060 ti is the way to go. Though if you just want better fps go for 6800xt",
      "6800xt easily i would say that is if you can find one. I was in the same predicament a week or 2 ago. My 2080ti started artifacting in March and  i wanted something that could replace it for another 2ish years untill i build a new pc. Everything i saw pointed towards the 6800xt but in the UK i just couldnt find it at all and im not really a used/refurbished kinda buyer so got a 7800xt on early black friday deal for pretty much the same price as a 4060ti 16gb. Just make sure you do the DDU steps correctly and the switch over to AMD should be fine- its not ideal imo as fresh install of windows is better but it does the job",
      "Thanks"
    ]
  },
  {
    "brand": "amd",
    "generation": "6000",
    "tier": "high",
    "matched_keywords": [
      "rx6800",
      "6800"
    ],
    "title": "RX6800 vs RTX3080",
    "selftext": "I managed to snag a 6800 on launch, and have the opportunity to trade it for a 3080 at no extra cost to me. I am wondering what everyone‚Äôs thoughts are on this? \n\nI game in 2K at 144hz. Plan on playing the new cyberpunk game. \n\nWhat are the pros and cons?",
    "comments": [
      "If it‚Äôs a 6800 non-XT then you definitely should trade it in",
      "I'd trade a XT for a 3080",
      "Literal no contest the 3080 is same level as the XT this is a no brainer for upgrading basically.",
      "You'd be foolish not to take that trade.",
      "Do it, even it if were xt model. 3080 is just more mainstream atm. With dlss2.0 and rtx if you would want to use.",
      "Yes it‚Äôs a reference design 6800 non XT",
      "False narrative that keeps poping up. Without RT games, without DLSS :\n\n[https://www.3dcenter.org/artikel/launch-analyse-amd-radeon-rx-6800-6800-xt/launch-analyse-amd-radeon-rx-6800-6800-xt-seite-2](https://www.3dcenter.org/artikel/launch-analyse-amd-radeon-rx-6800-6800-xt/launch-analyse-amd-radeon-rx-6800-6800-xt-seite-2)\n\nWith 6800XT normalized (100%)\n\n1080p : 3/13 sites 3080<100%,  103.5% avg.\n\n1440p : 2/17 sites 3080 < 100% ,  103.7% avg.\n\n4k  :  0/17 sites 3080 <100%, 107.4% avg.\n\nRT 1440p :   127,6% for 3080.\n\nA few patterns emerge also, the less tests, like \\~9 games, mostly a similar list to AMD's, show the 3080 under, or other with some gimped DDR4 speeds (2933) which seems to bottleneck the 3080 somehow at low resolutions.",
      "Trade it. It's pretty much a no-brainer.",
      "Don‚Äôt you bring the truth here!",
      "If it‚Äôs a 6800 non XT I would say do it. The 3080 will still trade blows with rasterization but come out on top  60% of the time. However the 3080s RayTracing is far better.",
      "Sounds like a pretty good deal. Go for it.",
      "Sounds like a deal too good to be true",
      "It also loses out in 4k and DLSS makes the gap even larger",
      "Um, who the fuck's just *giving* you a 3080 for a 6800?\n\nIs there anything else to this?",
      "Someone offered me the price of a 3080 for my 6800 and I am able to place an order through a local shop for a 3080.",
      "It could be on backorder for a few months, so I'd confirm when stock will arrive at your store first.",
      "It's objectively faster. Not sure what you're smoking but nvidia use standard dxr api for directx game. The only proprietary stuff nvidia used was vulkan rt extension because untill recently vulkan didn't support ray tracing at all.",
      "You do know AMD has been in console forever.  By your logic this should have happened 5 years ago",
      "Nope! Just dropped off my card and heading to the store tomorrow to order a 3080",
      "The xt beats the 3080 in most games that are not ray-traced though. Can be a bit of a toss-up"
    ]
  },
  {
    "brand": "amd",
    "generation": "6000",
    "tier": "high",
    "matched_keywords": [
      "6800"
    ],
    "title": "Need suggestions: is a 650W PSU enough for the RX 6800??",
    "selftext": "Hello, as title says, will a 650W PSU be enough for a Gigabyte RX 6800 Gaming OC? Or should I go for something slightly less power hungry like the RX 6700 XT?\n\nThe PSU is Seasonic Focus SGX-650. Full [specs](https://seasonic.com/focus-sgx#specification) here.",
    "comments": [
      "Yeah amd recommends a 650 for the 6800 and they pad it generously bc they dont know if you have a 65w cpu or a 200w threadripper.\n\nYou aren't pairing it with a 200w threadripper are you?",
      "You're totally set then, enjoy it!",
      "Yes, it's fine",
      "Ahah no, I'm running a quiet 3700X, two M2 and couple of fans. That's all.",
      "They pad the power rating because peak power draw is much higher then continuous power draw.  A 6900XT might consume 314w full load but it'll spike up to around 600w for 20ms periods.  It's gotten to the point where the upcoming new ATX PSU standard requires new PSUs to be able to handle 2 times their stated wattage for short periods of time (when in reality they should improve the DC to DC converting on graphics cards to prevent these spikes).  I'm really not a fan of these because if these spikes increase on next gen GPUs (which is likely given the increased power draw rumors) it means that more people will have to buy new PSUs.  For how expensive modern GPUs are, they should be able to afford the couple of cents in hardware to tame these spikes and I expect it'll cause people headaches.",
      "same i run my 6800XT on Strix 650W",
      "AMD recommend a 750w but power supply being enough would also depend on CPU pull and all other components in system and if you are going to overclock..\n\nIf you have a 700w power draw for total system you want to be in the 70% efficiency range. Of the PSU so you would need a 1000w to leave room for minor upgrades and overclocking \n\n\nYou want power cables for each plug on GPU no pigtails a cable for each plug to reduce possibly of not enough power through a single cable.  \n\n\nLack of power can cause system crash. It can also cause black screens and other system issues never cheap out of power supply get a good one it's worth it when you are powering $1000 dollars of hardware. And a cheap power supply can die and take hardware with it.",
      "I run 3700x and 6800 on a 600 Plat no issues whatsoever",
      "I have the same PSU with a 3600X and an RX 480, so a total TDP of 215W, even at full load the PSU is under 50% load and the fan doesn't start. The 3700X and RX 6800 are at 315W so your PSU will also stayt quiet most of teh times",
      "I have a seasonic focus 650w running with a 9700k and a 6800.\n\nBeen running since 2019 like a charm.",
      "I ran my 6800 on a very good quality 530W beQuiet! Pure Power PSU with a 5900X, so it can be done.",
      "Thanks for your feedback.",
      "Thanks!",
      "this is the only card that measured power spike 20ms.\n\n[https://www.techpowerup.com/review/asus-radeon-rx-6800-strix-oc/35.html](https://www.techpowerup.com/review/asus-radeon-rx-6800-strix-oc/35.html)\n\n[https://www.techpowerup.com/review/powercolor-radeon-rx-6800-red-dragon/](https://www.techpowerup.com/review/powercolor-radeon-rx-6800-red-dragon/)\n\nreference : 318w , Asus : 334w , Power color: 338w\n\npower spike can be related to black screen so forget about sustained power consumption\n\njust grab 750w. I wish there was an additional spec that AIB could tell us what are their value about power spike.\n\nYour PSU datesheet doesn't say Single rail or Multiple-rail but i think it's single rail then I see no problem.\n\njust read more comments :\n\n[https://www.reddit.com/r/Amd/comments/l99p1w/amd\\_6900xt\\_power\\_spike\\_is\\_real/](https://www.reddit.com/r/Amd/comments/l99p1w/amd_6900xt_power_spike_is_real/)",
      "I am getting a 6800 with 650W and it should be completely fine.",
      "There are GPU calculators where you can plug your PC specs in and it will tell you the suggested GPU to use. EVGA has one on their website.",
      "When companies make up these PSU requirements they play it safe and expect your PSU to already have 10 years of wear with 4 mechanical drives and 2 optical drives installed. I've never had problems running a video card that recommended 50 or 100w more than my PSU, if you're only running 1 or 2 ssd's and your cpu only has a 65-95w tdp then go for it!\n\nThe only thing you shouldn't do is put a high end card in a low end pre-built workstation with only 250 or 350w. Also never use molex to pcie adapters, always make sure your PSU has proper separate pcie cables for every connector on your video card, never daisy chain them!",
      "If you can afford it atm, I would counsel going with something like a Corsair 850W PSU--not because your current build needs it, because it doesn't, as many have correctly stated.  Your 650 should do fine.  But  in 1-3 years when you get ready to upgrade to a much more serious system, if you do, you will more than likely already be set with a PSU that could last as long as a decade, maybe.  I've got a Corsair, HX-850, fully modular, and I've had it for a long time and during all kinds of hardware upgrades it has performed well without so much as a squeak.  Right now it's pushing an Aorus x570 Master with a 3900X, 5 hard drives and two NVMe drives, totaling \\~10TBs, a DVD writer, 32GB (4x8GB) of system ram running at 3733MHz, and an AMD 50th Anniversary ED 5700XT, with the GPU and boot NVMe runn in PCIe4 mode, and some other stuff which I cannot recall atm...;)  I game at 4k, with two Noctua CPU fans--push-pull--and three Noctua case fans.  And I've never had so much as a squeak out of the PSU in complaint...;)\n\nThat's all I wanted to say about that...;)  Have fun!",
      "It's fine for me 5600x, B550m TUF Plus RX6800 EVGA G2 650W Gold",
      "Even 550 is enough, I run that with a 3900x and RX6800."
    ]
  },
  {
    "brand": "amd",
    "generation": "6000",
    "tier": "high",
    "matched_keywords": [
      "rx6800"
    ],
    "title": "RX6800 XT Merc319 Core + Ryzen 7 3700x + 32GB 3600mhz <3",
    "selftext": "",
    "comments": [
      "excellent performance, the only downside is a little coil, but other than that it's excellent, very good temperatures. low fan noise",
      "Niceee",
      "How the 6800xt performs ?"
    ]
  },
  {
    "brand": "amd",
    "generation": "6000",
    "tier": "high",
    "matched_keywords": [
      "6800xt",
      "rx6800",
      "6800"
    ],
    "title": "RX6800 Morpheus 2 Mod",
    "selftext": "I did the absolut mad thing of taking my reference 6800 apart and mounting a Morpheus 2. I realized the great OC potential but did want the card to stay quiet. So I took it apart shelved the front and backplate (if you drill four holes you can keep both on like with vega) and mounted the better cooler.I had not drill at hand so I did go for custom VRM cooling:\n\nhttps://preview.redd.it/l0ryi8ucc1661.jpg?width=4000&format=pjpg&auto=webp&s=78acf5d41549c9fe5c49fde417be867b0deb10fb\n\nhttps://preview.redd.it/ydqrczcec1661.jpg?width=4000&format=pjpg&auto=webp&s=d57821f1746c4f06c4f66c12de847b1fb9f689aa\n\n[ thermal glue and paste combo](https://preview.redd.it/6hx0ncsfc1661.jpg?width=4000&format=pjpg&auto=webp&s=dfb474d42e2f65d100c5ba28c1b571bf52686405)\n\n[ One small cooler to the left of the die is still missing in this picture](https://preview.redd.it/s8kwonmjc1661.jpg?width=4000&format=pjpg&auto=webp&s=fac95c043667788b3741576ca42fa696406054e6)\n\n[ The cooler barely covers the whole chip](https://preview.redd.it/53eh8m8mc1661.jpg?width=4000&format=pjpg&auto=webp&s=356bb8b875b4b3f18d106dfcf950c1c3e0b12beb)\n\n[ Mounting it with enough \\(but not to  much\\) pressure was a little tricky, I later used the Morpheus bracket  below the Vega one to get more pressure. \\(The 6800 bracket has smaller  holes that would need drilling to fit morpheus screws\\)](https://preview.redd.it/b3gnx1qqc1661.jpg?width=4000&format=pjpg&auto=webp&s=3510098a0d6a42ab17bc636694b15511957aaf4f)\n\nhttps://preview.redd.it/x7b5essuc1661.jpg?width=4000&format=pjpg&auto=webp&s=6c3bba754386a27d34b84c89a2a34c3beb56498c\n\nHotspot temp in idle is 5¬∞C above core and while benching within about 15¬∞C. Idle 35/40¬∞C, gaming max 60/75¬∞C.  All \"noise\" is gone and temps are much better, so I call it a success. I did not yet beat my TimeSpy scores but those where pretty crazy anyway (16 837 GPU Score). I get almost reference XT performance with OC. Non demanding titles dont even activate the fans. (e.g. csgo capped at 600fps stays below 55¬∞C with passive cooling)\n\n[ In SOTTR at WQHD it is matching 6800XT performance with 2444Mhz Core  2150Mhz Mem. Holding 2390 - 2400Mhz. I am using reference 6800XT power  limits with 1150mV Vcore. ](https://preview.redd.it/otmc0updd1661.png?width=2560&format=png&auto=webp&s=d4e3c2c8bb10d9cc398f4ad4d5d3a97a49361856)\n\n[ Ultra with RT about 15Fps more than what I saw in stock benchmarks, also XT territory](https://preview.redd.it/exrmej7ed1661.png?width=2560&format=png&auto=webp&s=8cc9bf23a64d266e468f571f602e468c491e3b20)\n\n[ sottr temps](https://i.redd.it/9zl9kw4hd1661.gif)\n\nWas it worth it?Yes it is cooler and quiter. Performance did not change signifcantly, maybe a few mhz more for my stable oc. Max Benchmark clock did not change even whith 10+¬∞C better temps.\n\nSo if you have a morpheus lying around go for it. Otherwise the reference cooler is good enough even for top 100 scores. There is always risk of damaging something. Imagine being me after switching the cooler, trying to boot and get \"AGP Error\" beeps with my old vega (swapped the cooler) and the new 6800. Turned out my mobo just wanted twenty minutes of no power no battery time before it worked again (swapped again).",
    "comments": [
      "Thanks for sharing! Never seen anyone doing the Morpheus mod on a RX 6800 before. Great results tbh üòä",
      "Nice to see that it works! I had a Morpheus II on my 1080 Ti. It was a Inno3D X3 ultra edition, but the cooler was bad. Always had temps at 80c and the card would throttle. With the Morpheus II and two ML120 fans my temps dropped to 52c and clocks were stable at 2050Mhz, while staying silent.\n\nFor the Radeon 6800 series I think the Morpheus 8057 is a better option than the II. The heatsink dimensions on the 8057 are 40x38mm vs 40x32mm on the II. You'll have better coverage on the core with the 8057.",
      "I put one on a Vega 56 and shit was hilarious. 1600Mhz rock steady levels of hilarious.",
      "Hey, what is your total card height(incl fans)? i want to know if this would fit in my NR200",
      "I've been wanting to pick up a Morpheus to cool my 7970 while I wait for a 6700 to exist & be in stock. \n\nDoes the 8057 come with newer mounting brackets? Think I'll have trouble mounting it to such an old card in the interim?",
      "Yeah, your temps are looking pretty good though. The 5000-series had massive issues with GDDR6 temps, even with much bigger heatsinks than yours and heatsinks+active cooling on the back of the card I can barely get temps below 90¬∞C. Seems that the new chip casings have better thermal conductivity",
      "Can you link your 3DMark Timespy result? My 6800 only gets 15,512 with the max frequency set at 2450MHz. Can't complete Timespy with any higher frequency. Curious what your frequency is to get >16k.",
      "What are your VRam temps (if the card gives a readout of those)?\n\nGDDR6 is a bitch to cool, chances are you are cooking them",
      "Hi,\n\nI've bought used Raijintek Morhpeus Core for Radeon VII, but soon bought Silverstone FT02, so was not sure if it will work rotated.\nBut I wonder if this \"Morpheus II core\" would work on 6800XT, or if I need special version for this GPU?\nHave you tested it in 90deg rotated position? (I use Silverstone FT02 case)",
      "Will the morheus 8057 fit the sapphire 6900xt?",
      "This is great! I have a Morpheus II Core lying around and a new 6700 XT.  \n\n\n[u/Falk\\_csgo](https://www.reddit.com/user/Falk_csgo/) If you want more performance from the 6800 ref, you can use the MorePowerTool (MPT) to raise power limits. You mention above using a Vega AND Morpheus mounting bracket, did you use a bracket from another card, or only what was included with the Morpheus?",
      "With 25mm fans about 77mm, backplate not attached, so better take 8cm",
      "Sure, place 73 gpu score: [https://www.3dmark.com/spy/16369088](https://www.3dmark.com/spy/16369088) Freq I set the card to was actually 2544Mhz but it does not reach much more than 2500.Also cooling is important, I opened the windows and cranked my case + gpu fans to server mode. The rest is silicon lottery I guess.\n\nOh and this was only bench stable, my everyday oc ends below 2450Mhz. Above 2500Mhz I had crashes in timespy every few runs, but still stable enough to go for it.",
      "How do I read my VRam temps?\n\nhwinfo64 Memory Junction?\n\nThis is after 15min of stresstesting with MSI Kombustor - FurMark Donut:\n\n[https://imgur.com/a/lJsOgWp](https://imgur.com/a/lJsOgWp)",
      "Hi, I used a Raijintek Morpheus II Core Black. And the XT reference design is the same pcb except the actual die, so it should work.\n\nI did not test 90¬∞. But if you want to do 90¬∞ with normal motherboard mounting (no vertical gpu mount) the heavy weight probably has to be supported somehow or you risk your pcie slot. Oh wait :D you mean vertical gpu mount not cooler 90¬∞ on the gpu xD I am getting tired!\n\nBe aware that you might need extra washers for optimum mounting pressure. Have a drill ready so you can use the original front and backplate to keep the card rigid.\n\nAnd if you do this dont forget to post results :)",
      "Im not sure, what is the difference between the 8057 and 2?\n\nAlso the upgrade from 6900 stock cooler to a morpheus does not have as much potential as for a 6800 since the stock cooler is bigger.",
      "I was just looking at the mounting points of the 5700 XT and 6700 XT on techpowerup and they \\*appear\\* to be the same. \n\n  \nDM me if you want to buy a Morpheus II Core, NIB. I purchased it for my Nitro+ V64 and never needed it.",
      "thanks!",
      "Thanks!",
      "Thanks for reply. So I'm happy I haven't sold Morpheus.\nCould you point me what I need to drill? (I've got drill)\n\nAbout 90deg mount, not only GPU, but whole botherboard. Look for Silverstone FT02, RV01 or RV02. Its superior cases, but problematic with so many coolers."
    ]
  },
  {
    "brand": "amd",
    "generation": "6000",
    "tier": "high",
    "matched_keywords": [
      "rx6800",
      "6800"
    ],
    "title": "RX6800 and RX6800XT in stock in UK",
    "selftext": "[https://www.overclockers.co.uk/search/index/sSearch/rx+6800/sPerPage/12/sPage/1](https://www.overclockers.co.uk/search/index/sSearch/rx+6800/sPerPage/12/sPage/1)\n\nMany available as of 19:22",
    "comments": [
      "Actual Fact: That wasn't erroneous, it was to purposely give the forum users\\\\regular customers a chance!\n\n&#x200B;\n\nit's quite good actually, very clever. \n\n3d printer - more like 3d virtual printer",
      "OCUK so its no surprise the rip off merchants",
      "Fun fact about why they're not selling that fast:\n\nthey are erroneously categorized under 3D Printers:  https://imgur.com/LqLVija",
      "Wow ridiculous pricing",
      "Approaching ¬£1K for a 6800XT (yes I know it's a Limited Edition version) and hovering around ¬£800-900...  \n...no thanks. I'll wait for the next gen of GPU releases at this rate.",
      "Got  a Sapphire Reference RX 6800 this after noon about 3pm ¬£599. Over the moon. \n\nThere is still 6800 available. its a good one too ¬£700 unfortunately  [‚ñ∑ Sapphire Radeon RX 6800 Pulse 16GB GDDR6 PCI-‚Ä¶ | OcUK (overclockers.co.uk)](https://www.overclockers.co.uk/sapphire-radeon-rx-6800-pulse-16gb-gddr6-pci-express-graphics-card-gx-39d-sp.html)",
      "3D printers? more like money printers selling them for a grand a pop when they should be 700ish for partner cards.",
      "According to that page, they have at least 60+ of various 6800/6800XT AIB models in stock.  Impressive.  Wonder how fast they'll go?",
      "They've got the 6800s priced so close to the 6800XTs there's no reason to buy a 6800 until the XTs are out of stock.",
      "And not a one in the US AMD store.",
      "They haven‚Äôt got shit on CCL and AWD tbf",
      "Radeon RX 6800 XT NITRO+  ¬£900 = $1234.82\n\nI would rather buy from ebay scalpers then these scumbags.",
      "Sapphire 6800XT Nitro+ for 900GBP/1200USD is hilariously preposterous and I guess I'm going to stay on 5700XT until it dies and then find a hobby where it doesn't feel like I'm stuffing banknotes into a shredder.\n\nI've pretty much impulse bought fun things for more (coincidentally, a 3d printer for instance) but I refuse to spend this much on something that brings this little on principle.",
      "What are the msrp on these cards? As I know overclockers heighten the prices but not sure how much they have done so for these",
      "Think im just gonna stick to my 480 with those prices üòÖüò≠",
      "God, ¬£700 for the lower end flagship card.\n\nI remember paying ¬£90 for an HD 3850.",
      "Limited Edition really doesn‚Äôt mean much this time.",
      "I got this same card from overclockers today, are you impressed with it??",
      "Apparently they've been up since about 3pm according to the forums (I saw it there before seeing this thread). That's 7 hours at this point.\n\nWon't last long once the wider internet figures it out though.",
      "The 6800XT Nitro+ would be around ¬£720-¬£750 if there was no shortage. The OCUK price is ¬£859.99 right now so an extra ¬£110. If you have an old gpu to sell then it balances out since you would probably get an inflated price for it on ebay."
    ]
  },
  {
    "brand": "amd",
    "generation": "6000",
    "tier": "high",
    "matched_keywords": [
      "6800xt",
      "rx6800",
      "6800"
    ],
    "title": "1440p : RX6800 or RX6800xt",
    "selftext": "It is difficult to make a decision.   I run games at 1440p and I don't think I am going to get a 4K monitor soon.\n\nRX 6800 are sporadically pop up here and there but the price difference between the 2 is not much.  I am wondering if I should go for 6800 now since I would not be a person that would benefit much from the 6800xt.  Am I wrong ?",
    "comments": [
      "6800, costs less. Since both are not ready for ray tracing, chances are in 2 years you will want to upgrade again to buy a gpu with good RT. If you're not worried about that, at msrp, I'd get the XT, the difference in price isn't high (the performance jump isn't high either, but if you can afford both, 70 is good to have the better card)",
      "Personally I would just get the 6800XT considering the small 10% difference in MSRP price. But finding something at MSRP is very hard so I would just get what you can at this point.",
      "For what it's worth, even if you buy a Ray Tracing card in 2021 you'll still probably need to upgrade it in two years.  If folks think a 3080 is going to have great Ray Tracing performance in 2022, even though it didn't in 2020, they're gonna have a bad time.",
      "The XT is ~15% faster and costs ~10% more.\n\nSo it's actually better price/performance ratio than the 6800 which is unusual.\n\nBoth are good though, if you can get them at MSRP its not going to make a world of difference.",
      "Surprised there are no \"but it has DLSS so it's ok\" answer to your comment yet.",
      "the 6800 vanilla would probably be more than enough in most cases.... it's last i checked, still the best bang for the buck. Obviously the 6800xt will have a definite edge over it... but that's entirely up to you.",
      "6800 non xt",
      "Get the RX 6800XT",
      "6800XT due to the fairly small price premium over the 6800",
      "As mentioned. How things are going we may be looking at throwing the 69XT to bin in a year or two if all new AAA games come out with RT stuff like CB2077 as RDNA2 is currently quite week with RT. If nothing major happens in the software department it is more than likely that RDNA3 will be way more powerful with RT, like double or triple, and at this point the RDNA2 cards are quite literally struggling.\n\nSo bearing this in mind we need to look at the price vs performance vs longevity formula. And if all RDNA2 cards will be scrap when next gen hits, in a year or two, then getting the cheapest option is the wisest decision, unless you are sleeping on piles of money, then of course get the best there is everytime.",
      "The idea of rdna2 being garbage in a gen is laughable. It's the same tech the consoles have, it's gonna be optimized toward for many years to come.",
      "Only game I have that the 6800 struggles to play a bit at high/ultra 1440p is Cyberpunk 2077, but even then it gets in the area of 70-80 FPS, everything else I play the 6800 stomps on at 1440p.\n\nThat said, if I'd had the option I would rather have the 6800 XT.",
      "The RX 6800 might be fine. I have the 6800xt and for the most part can play games 4K 60 max settings. I think 1440p has half the pixel count of 4K, so it'll be a lot easier on the card to get playable frame rates. I'l probably go for the 6800xt because you'll probably want to upgrade after 2 more generations unless next year's cards are 30-50% better.",
      "I went with the first one I could buy msrp (msi 6800 from best buy). I am extremely happy with it. 1440p 144hz paired with 2600x until my 5600x arrives. Upgrading from a heavily overclocked/uv pulse vega 56. Really a great Reference design vs. the 5700 or vega lineup.",
      "I got the non xt because I just felt like it was all I would need now and later on when something else shiny pops up.",
      "I guess im a bit late for this but i figured i would post anyway.\n\nInitially i had aimed for the 6800XT or 3080 since i planned to get a 1440P monitor.\n\nBut when i found a Reference 6800 for a good price i could not pass it up so i ended up going with that.\n\nAnd i had no reason to worry regarding to 1440P performance.\n\nIt has no issue running current games in 1440P\n\n(I get 70-80 in Cyberpunk 2077 at ultra settings and it feels / looks perfectly smooth and the same with my flight sims etc)\n\nSo i would say in regards to todays games the 6800 is prefectly capable for 1440P.\n\nNow if i would have had an option for a 6800XT for 70 usd more i probably would have taken it.\n\nBut the 6800 is prefectly fine for 1440P and i have no issues or complaints with it so far.\n\nEverything runs prefectly smooth.\n\n(And the reference card runs extremely cool and quiet as well with temps of 58-62C att full load with the fans at 30-35%)\n\nSo to summarize my opinion. \n\nIf you want the 6800XT (and can get it) then sure go for it.\n\n (Since it is more powerful and the MSRP price difference isnt huge)\n\nBut the 6800 seems to be perfect for 1440P (as of now atleast)\n\nso if you do not want to wait for a 6800XT i dont think that a 6800 will disappoint you.",
      "I suggest wait for FSR, and then make final verdict about RT",
      "Where I live I saw price difference of around 20% to 23% going from a 6800 to 6800 XT, depends on the models of course, the \"big\" retailer with multiple stores (sometimes more than one per city) even have some in stock at some stores, and in stock at the warehouse for online orders, meanwhile the specialized retailers that have a single / several stores stores across the country (they deal mostly on the web store) have them at higher prices and limits them to a whole PC purchase, funny. Personally I \"want\" an 6800XT but REALLY cant justify upgrading the 5700XT, its not twice as fast at 1440p and ray-tracing performance are 2070-2080 levels, so logical thing would be to wait a gen.. but hey, who does that \"logical\" thing.",
      "Did your comment Age fine ? Or were you wrong cuz we‚Äôre in 2022 now",
      "DLSS is fantastic, game changing technology, and I'm a huge fan of it!  But at the same time, if Ray Tracing is going to grow more complex with time (and I imagine it will) then DLSS will have to make similar advances in performance to compensate for the extra processing.  \n  \nNow to be fair DLSS could improve more quickly than Ray Tracing does, and if that's the case then yeah, 2020's RT cards are going to hold out a bit longer.... but when one has to depend on *two* technologies at once to get a playable framerate, that creates potential negative conflicts and consequences.  \n  \nAs of right this moment I'm not convinced that Ray Tracing is more than a gimmick.  In five or ten years it could be the industry standard, but today, in 2021, I just don't think the tech is ready for primetime.  A lot of these games don't present a significant visual improvement over rasterization, but *all* of them have a 20% performance hit.  (I've been reassured repeatedly that my opinion on Ray Tracing is wrong, though, so take what I said with a grain of salt.)  \n  \nDLSS is cool, Ray Tracing will be cool, but if somebody is getting a top of the line RTX GPU in 2021 and expecting it to perform really well in Ray Traced games in 2023, I just think they're going to be disappointed is all.  God bless early adopters, I guess."
    ]
  },
  {
    "brand": "amd",
    "generation": "6000",
    "tier": "high",
    "matched_keywords": [
      "6800xt",
      "rx6800",
      "6800"
    ],
    "title": "Waterblocks for Smaller Reference Radeon RX 6800 PCB - Pulse 6800 - Fighter 6800 - Are any actually being created???",
    "selftext": "I noticed Bykski had designed an A-RX6800-X waterblock on AliExpress, based around a smaller reference RX 6800 PCB, however when I ordered one I was sent the larger A-RX6900XT-X waterblock, which was for the larger stock reference boards (I was later told that the A-RX6800-X was only an illustration).\n\nFrom my research online, the smaller reference Radeon RX 6800 PCB seems to be the basis for the Sapphire Pulse 6800 & Powercolor Fighter 6800. I'm wondering in these crazy times of graphics cards, if anyone is actually doing waterblocks for these 6800 cards, that can occasionally be purchased, as opposed to the standard reference that have basically never existed in any reasonable numbers (at least here in Australia).\n\nThese cards are faster than the geforce 2080ti and 3070 cards, and can sometimes compete with the 3080, and yet the slower, older 5700xt pulse seem to have plenty of waterblocks available.\n\nI was originally hoping to buy a reference 6800xt, (which would have made the waterblock search easy), but could only find a Pulse 6800 for around the same price. Now 6700XT cards are even more expensive locally than both of their much faster stock siblings, were originally sold for.\n\nIf anyone has found a waterblock for the Sapphire Pulse 6800, would you please let me know?\n\nhttps://preview.redd.it/2846jq14f8q61.jpg?width=706&format=pjpg&auto=webp&s=6f1e32664fc6fd91ba3c587a8a010c2b4c106247",
    "comments": [
      "I‚Äôm pretty sure Bykski does actually sell a separate block with the A-RX6800-X name, and that it‚Äôs not just an illustration of the A-RX6900XT-X block. If you look closely at the photos, they are actually different blocks, so I reckon your seller sent you the wrong product and then tried to claim that it‚Äôs all the same thing.\n\nEDIT: Bykski also lists a block by the name of A-SP6800-X for Sapphire 6800 cards, so that one might fit the Pulse if it has a different PCB from reference cards.",
      "I'm still waiting for someone with some inside knowledge.  The pulse 6800 is quite a beast of a card (2500mhz+) and quite energy efficient.  I would love to be able to add it into my custom loop which has plenty of headroom available...",
      "I think I just found the waterblock. The Bykski A-DL6800-X has just been released. It should fit the Sapphire Pulse 6800, Powercolor Fighter 6800, and the Dataland X-serial 6800 model, which all look like they share the same PCB layout.\n\n[BYKSKI A-DL6800-X](https://imgur.com/a/dprkdma)",
      "http://imgur.com/gallery/7VRkjif",
      "I can't find any pcb pictures or diagrams of the 6800xt pulse. The pulse 6800 is based on a smaller amd reference board design, also used by powercolor fighter & dataland x series. \n\nThe only thing I can find from techpowerup is the pulse 6800xt has a slightly longer heatsink than the 6800xt nitro. U might need to disassemble it to check if it uses the amd reference or nitro, which should have waterblocks, or another model out there. Make sure you check the vrm clearances for compatibility. The ek site also has some compatibility photos & diagrams which may be useful. \n\nGood luck.",
      "The A-SP6800-X waterblock is for the Nitro 6800. I was told from a Bykski AliExpress store the A-RX6800-X was not actually physically available, it was only listed in online pictures. They provided the A-RX6900XT-X block which will fit all the the standard stock AMD reference parts.\n\nThe Pulse 6800 and Fighter 6800 closely resemble the smaller 6800 AMD reference design that is shown in the diagrams of the A-RX6800-X waterblock\n\n[Smaller Reference RX 6800 PCB - Pulse & Fighter](https://imgur.com/a/e8p8bOT)",
      "Did you ever find out if they work ?",
      "Did you ever find any new information? I have a pulse that I desperately want a waterblock for.",
      "It should arrive any day now. I saw someone show it installed on what looked to be a powercolor fighter 6800 card. So fingers crossed the pulse fits as well",
      "Unfortunately, still waiting.  The ali express seller said they would let me know if a compatible block ever became available.  It's a shame amd only produced the 6800 on the larger 6800/6900xt reference design boards and not the smaller reference design pcb sapphire and powercolor utilised. \nIt seems crazy that most of the much slower mid range 5700 series have waterblocks,  but many of the high end 6800 series have nothing available yet...",
      "I think I just found the waterblock. The Bykski A-DL6800-X has just been released. It should fit the Sapphire Pulse 6800, Powercolor Fighter 6800, and the Dataland X-serial 6800 model, which all look like they share the same PCB layout.\n\n[BYKSKI A-DL6800-X](https://imgur.com/a/dprkdma)",
      "Thank you so much. I‚Äôll probably get it when i get back from vacation. If you get it let me know if it works for you.",
      "I have ordered one from AliExpress. Its on its way & should arrive in the next week or two. Ill post up how things go. The initial A-RX6800-X waterblock design didnt account for the bottom capacitor nearest the pci-e notch that this one seems to overcome with a larger cut out, which I guess its why it was never made.",
      "It fits nicely. U might need to use the included thermal pads along with the grey thermal clay already on the board to properly connect the PCB to the VRM and memory, on the main block and the back plate to ensure you achieve the best results. I went the full hog by also  using conductonaut liquid metal on the core and surrounded it with nail polish to protect the components around it",
      "Thanks for testing and the info.",
      "How have temps been holding up? Any issues?",
      ">A-RX6800-X waterblock\n\nDid you ever get yours for the pulse?"
    ]
  },
  {
    "brand": "amd",
    "generation": "6000",
    "tier": "high",
    "matched_keywords": [
      "6800xt",
      "rx6800",
      "6800"
    ],
    "title": "EK-Classic Water Block for the Radeon RX 6800, RX 6800XT, and RX 6900 Graphics Cards!",
    "selftext": "EK release custom Cards blocks..\n\n[https://videocardz.com/press-release/ek-announces-classic-waterblock-for-amd-radeon-rx-6900-and-rx-6800-graphics-cards](https://videocardz.com/press-release/ek-announces-classic-waterblock-for-amd-radeon-rx-6900-and-rx-6800-graphics-cards)\n\n&#x200B;\n\n**Current Compatibility List for EK-Classic GPU Water Block RX 6800/6900 D-RGB**\n\n* AMD Radeon RX 6800\n* AMD Radeon RX 6800 XT\n* AMD Radeon RX 6900 XT\n* ASRock Radeon RX 6800 16GB\n* ASRock Radeon RX 6900 XT 16GB\n* ASUS Radeon RX 6800 XT 16GB\n* ASUS Radeon RX 6800, RX6800-16G, 16GB GDDR6 (90YV0FY0-U0NA00)\n* ASUS Radeon RX 6900 XT 16GB (RX6900XT-16G)\n* BIOSTAR Radeon RX 6900 XT 16GB\n* Gigabyte Radeon RX 6800 16GB (GV-R68-16GC-B)\n* Gigabyte Radeon RX 6800 XT 16GB (GV-R68XT-16GC-B)\n* Gigabyte Radeon RX 6900 XT 16G (GV-R69XT-16GC-B)\n* MSI Radeon RX 6800 16GB\n* MSI Radeon RX 6800 XT 16GB\n* MSI Radeon RX 6900 XT 16GB\n* PowerColor AMD Radeon RX 6800 16GB GDDR6 (AXRX 6800 16GBD6-M2DHC)\n* PowerColor AMD Radeon RX 6800 XT 16GB GDDR6 (AXRX 6800XT 16GBD6-M2DHC)\n* PowerColor AMD Radeon RX 6900 XT 16GB GDDR6 (AXRX 6900XT 16GBD6-M2DHC)\n* Sapphire Radeon RX 6800 16GB\n* Sapphire Radeon RX 6900 XT 16GB (21308-01-20G)\n* Sapphire RX 6800 XT 16GB\n* XFX AMD Radeon RX 6900 XT (RX-69TMATFD8)\n\nsource: videocardz\n\n&#x200B;",
    "comments": [
      "Oh, finally!\n\nI hate the vector series design with that space wasting RGB piece at the very end.",
      "agree.. i fixed it with milk glass foil on LED chips also on acrylic part. i hate to see transistors.. no its smoth light..\\^\\^",
      "at least there will be plenty in stock",
      "Is the EK AIO for the reference cards worth it? \n\nMy Chinese cheap ass case is having hard time expelling the heat from my 69XT and on top of that it doesn't really like to undervolt but I feel like there could be some performance to unlock with lower temps, it goes nicely 2600-2700 at the beginning of any tests but starts to throttle quite fast when the junction hits 95C..",
      "I hope this time with 100% QA and no scratches..",
      "gpu block + plate costs $190 shipped, and only they have it in stock. they stick it where the sun don't shine. alphacool block+plate costs $143 shipped from PPCs.",
      "Instead of spending $400 on the gpu loop, why not spend the money getting a better case?",
      "I have no idea what milk glass foil on LED chips means, but it sounds delicious haha",
      "Good question. Partly why I'm here. My vega with a blower was fine and I have a feeling that the case is kind of fine without the 69XT dumping 350W of heath into it.\n\nBut if I get a better case, will the junction temp go down by 10C or so? Or am I still looking at the 95C junction, maybe not at 30seconds but maybe at 3 minutes?",
      "haaha.. xD .. it means i don¬¥t like to see the capacitors. So i put some frosted glassfilm on the acrylic part on the end of the 6900er.. and with EK GPU Block on the right end is the led implented. it give nice frosted effect.. luv it..",
      "gonna buy one of these and then finally get the card in 6 months!"
    ]
  },
  {
    "brand": "amd",
    "generation": "6000",
    "tier": "high",
    "matched_keywords": [
      "6800"
    ],
    "title": "I‚Äôm tore between the 6800 XT vs 3080",
    "selftext": "I‚Äôm gonna be getting prebuilt so actually getting one won‚Äôt be of any issue, the thing is that i have no idea which one i‚Äôm gonna go with; i know for sure that i will get for a Zen 3 CPU so i‚Äôm really considering going for for the 6800 XT because of the compatibility between both (and not to mention the extra 6gb‚Äôs of memory), however i‚Äôve never owned an Radeon gpu and from what i‚Äôve heard their drivers are not as good as Nvidia‚Äôs. What should i go for?",
    "comments": [
      "Wait 18th, see benchmarks and then decide.",
      "If you‚Äôre going with zen 3 then get the 6800xt. The driver issues were from last gen and were mostly fixed. Supposedly it was due to a hardware issue, but with rdna2 it should be fixed",
      "Get whichever are in stock you can sell the other for retail if you don't like it anyway",
      "Wait for benchmarks and make an educated decision. :-)",
      "30 mins? That‚Äôs optimistic.",
      "Wait for whatever's in stock but I hope amd made loads of cards that wont go out of stock in less than 30 mins",
      "Wait for benchmarks",
      "I see, thx for the advice.",
      "I'll be glad if it stayed for 3 mins",
      "Zen 3 and RX6800 XT perfect match :)",
      "Feel like if you don't have zen 3 then you missing out",
      "6800xt supposedly has increased performance when paired with a zen 3 cpu on a pcie gen 4 lane. If you have a b550/x570 MOBO from which the GPU can take advantage of the pcie 4.0 slot, then its probably better to get the 6800xt. Again, wait for benchmarks though just to be sure."
    ]
  },
  {
    "brand": "amd",
    "generation": "6000",
    "tier": "high",
    "matched_keywords": [
      "rx6800",
      "6800"
    ],
    "title": "NVIDIA RTX 3070 or Radeon RX 6800/XT",
    "selftext": "So I'm looking into buying one of the newer graphics cards, but of course I'm unsure of which one. I've been trying to get Nvidia's 3070 since it released until I learned of Radeon's new RT 6800 and 6800 XT. \n\nI know that the RTX 3070 is the cheaper option, but the RX6800 is reportedly faster in most aspects. (This will actually be my first GPU so I don't know much about the terms).\n\nSince the latter is coming out tomorrow I'd like to know: \nShould I attempt to buy Radeon's or hope I can nab Nvidia's during another sporadic restock?",
    "comments": [
      "The RX6800 is also about $100 more... ü§®\n\nAs mentioned there is zero true benchmarks of the RX6800 or RX6800XT.\n\nWhat your basing your comment off is the AMD presentation and or a random leak on the internet claiming their benchmark results to be legit.",
      "There are no benchmarks of amd cards except for the claims of amd.",
      "from my experience it wasn't really playable, I think the game tries to get the missing VRAM from your \"other\", much much much slower ram, and this translates in a ton of spikes.",
      "What resolution are you interested in? Are you interested in ray tracing? If so, from what I've seen, the 3070 actually beats the 6800 XT despite being $150 cheaper in terms of 4K ray tracing. However, if you just care about raw rasterized performance, AMD has more VRAM and is quite good at non-ray tracing fps. The 6800XT is on par with the 3080 in non-4K ray tracing fps, despite having a $50 lower MSRP while also having more VRAM.\n\nI think the 3070 has plenty of VRAM for 1440p, but if you intend to keep it for a long time, then I think it would not be great for 4K. I think the 3080's 10gb is plenty for 4K, but AMD's 6800 and 6800XT have 16gb, which is clearly more. \n\nFinally, not all of these cards are in the same price bracket. However, oversimplified, roughly:\n\n4K, ray-tracing: 3080 \n4K, no ray-tracing: 6800 XT\n1440p, ray-tracing: 3070, 3080 (if you can afford it)\n1440p, no ray-tracing: 6800 XT (if you can afford it), 6800 (budget alternative), 3070 (Not the highest performance, but still a reasonably strong contender given its price)\n\nRather unfortunately, both NVDIA and AMD are having supply issues right now, so purchasing any of these at MSRP is going to be difficult.",
      "idk what led you to believe any or this... the benchmarks show that the 6800xt is either equal or better than the 3080, which itself is significantly better than the 3070. And I have personally tweaked down settings because I was using too much VRAM (8.9Go on mh:world) in 1440p, which means players who play in 4k use much more themselves.",
      "Thanks for the advice! I actually managed to snag a 3070 amidst the chaos of the 6800 launch. Great timing too since my laptop fan broke soon after",
      "Benchmarks already exist. The RTX 3070 is trash compared to both 6800 cards. Again, it also has half the VRAM as well. Only an obsessed fan would buy a 3070 at this point.",
      "how does this showcase, when the game wants more vram than the card got?\n\nDid you get stutter, bad fps, objects noticeably popping into existence?",
      "thx for the info, was honestly wondering how the missing vram showes ingame.",
      "The RTX 3070 is a shitty buy. The AMD 6800 cards are both way faster. They also have 16 gigs vram, where the 3070 only has 8 gigs.",
      "Uh don't trust what a company tells you. Wait for actual reviews before saying which is faster",
      "3070 obviously, its cheaper and perform the same as 6800 , don't let anyone trick you with an extra VRAM story, it's near impossible to reach  8 GB of VRAM . however if u can pay extra go for 6800 Xt  its cheaper than 3080,"
    ]
  },
  {
    "brand": "amd",
    "generation": "6000",
    "tier": "high",
    "matched_keywords": [
      "6800xt",
      "rx6800",
      "6800"
    ],
    "title": "650W PSU. RX6800 or undervolted RX6800 XT ?",
    "selftext": "I'm already preparing for the time when the prices will drop to somewhat acceptable (not in a hurry anyway haha), but I have a problem :\n\nI thought about getting a 6800XT, for which AMD recommends a 750W PSU.\n\nI only have 650w (bequiet straight power 11 platinum) - that's what they recommend for the 6800.\n\nSo here are my options : \n\n\\- Get a 6800XT anyway, and run it as it is : what do I risk ?  \n\\- Get a 6800XT and undervolt it so it suits the PSU : would it still be better than 6800 ?  \n\\- Get a 6800 : the most secure choice as I understand it.\n\nWhat do you think ?",
    "comments": [
      "Get whatever video card you can get. It's that hard to purchase a GPU.\n\nIf the card performs better than an RX 6700XT, then you can underclock the GPU using MSI Afterburner. Please note that, if the wattage requirement of the video card exceeds 90% of your PSU which is 585 watts, you should reduce the power usage of the card to get under the 585 mark, so, that the durability of your power supply is not reduced in the future.\n\nIf you benchmark the video card, the Nvidia RTX 3080 and above and the AMD RX 6800 and above can hit 500 watts during the tests. I'm not sure if you want to risk it, because that will be the moment your computer system might crash. Almost all power supplies are able to exceed their stated maximum power totals, but they can only do it for a short time."
    ]
  },
  {
    "brand": "amd",
    "generation": "6000",
    "tier": "high",
    "matched_keywords": [
      "6800xt",
      "rx6800",
      "6800"
    ],
    "title": "Help request for AMD 6800/6800XT owners - benchmark against RTX 3080",
    "selftext": "Hello, AMD users!  I am the creator of the performant, open-source and cross-platform Fast Fourier Transform library for Vulkan - VkFFT ([https://github.com/DTolm/VkFFT](https://github.com/DTolm/VkFFT)). I have recently made a post about comparing RTX 3080/ Radeon VII in VkFFT benchmark: [https://www.reddit.com/r/Amd/comments/jwrkj9/rtx\\_3080\\_and\\_radeon\\_vii\\_benchmark\\_results\\_in/](https://www.reddit.com/r/Amd/comments/jwrkj9/rtx_3080_and_radeon_vii_benchmark_results_in/). I wanted to ask if some of you have access to the fresh AMD GPUs to help me do the benchmark of them (the GitHub repository has Windows executables). Older version of VkFFT used in Phoronix benchmark ([https://www.phoronix.com/scan.php?page=article&item=amd-rx6800-linux&num=8](https://www.phoronix.com/scan.php?page=article&item=amd-rx6800-linux&num=8)) has some big performance gains on smaller systems due to Infinity Cache. New benchmark should give more information on how Infinity Cache works and scales and I would like to make a post about it afterwards. You can contact me on reddit or through E-mail (at the bottom of GitHub page).\n\nThanks!",
    "comments": []
  },
  {
    "brand": "amd",
    "generation": "6000",
    "tier": "high",
    "matched_keywords": [
      "6800xt",
      "6800"
    ],
    "title": "What GPU to get",
    "selftext": "Hello people,\n\nSo I need help deciding what GPU to get\n\nGPUS:\n\nRX 6800 XFX NEW = 444.50eur\n\nRX 6800XT PHANTOM NEW = 500eur, USED same GPU selling for 400eur\n\nRX 6800XT Lenovo Legion USED = 370eur\n\nRX 6800 Nitro + USED = 370eur\n\nRX 7700XT Acer Nitro NEW = 444eur\n\nThose are the GPU's I am looking into. Can't decide which one to get. I never bought USED gpus so I am kinda scared about that don't know is it worth buying used GPU's.\n\nI currently have Gigabyte RTX 3060 12gb, and for CPU ryzen 5 5600. When I buy a new GPU, i won't be buying a new CPU for the next 6-9 months (when I get new, I will go with ryzen 5 7600x).\n\nAlso for now I have 1080p monitor but after buying new GPU il buy next month new 1440p monitor.\n\nAlso I have Thermaltake Smart BM2 750W PSU.\n\nSo if someone has some free time please help me decide what GPU to get because I am kinda lost. (also never had AMD GPU)\n\nThanks for your time beautiful people.",
    "comments": [
      "Hey man so I got ex 7800xt and paired with my ryzen 5 5600 its actually really good. I am having crazzy fps on 1080p except in new call of duty and warzone. For some reason my gpu is not at 100% while running extreme settings with native resolution. But overall i am happy with it got it today so will test mode tomorrow but for now i am really happy with the purchase.",
      "Given your current setup and plans, here‚Äôs my top choices for performance and value:\n\n1. **RX 6800 XT (Used) f** (Lenovo Legion or Nitro+)\n   *  The RX 6800 XT is a great 1440p GPU, and at 370 EUR, these used options are strong value buys. Both models should give you a substantial performance boost over your RTX 3060, especially in 1440p gaming.\n   *  Used GPUs are a bit riskier, but if these come with a warranty or are from a reputable seller, they can be excellent deals. Just check for clear seller policies on returns or issues.\n2. **RX 7700 XT (New)** \n   *  The RX 7700 XT is newer and generally has better support for modern features like AV1 encoding and lower power consumption. It performs close to the 6800 XT in 1440p and provides a safer, new option without the risk associated with used hardware.\n   *  Performance-wise, the 7700 XT is generally close to the RX 6800 XT but is a bit more expensive than the used 6800 XT options. However, as it‚Äôs new, it comes with full warranty support.\n3. **RX 6800 XFX (New)** \n   *  This new option offers a balance of performance and price, without the risk of buying used. It‚Äôs a bit below the 6800 XT in raw power but still excellent for 1440p.\n   *  For a similar price, you might get more future-proofing with the RX 7700 XT, though the 6800 XFX is still solid.\n\nThe 7700 XT, being newer, has the advantage of possibly longer driver support. However, for raw 1440p performance, both the RX 6800 XT options will perform similarly.\n\nIf you‚Äôre cautious about used GPUs, the new RX 7700 XT or the new RX 6800 might be safer choices. But if you‚Äôre comfortable with the used route, the 370 EUR RX 6800 XT options are an incredible value for performance.\n\nIf you‚Äôre comfortable with used, go with either the RX 6800 XT Lenovo Legion or Nitro+ at 370 EUR for the best price-to-performance. If you‚Äôd rather stick with new hardware, the RX 7700 XT at 444 EUR is a strong choice that will handle 1440p gaming and comes with warranty support.\n\nEither of these will be great at 1440p, especially when paired with your planned Ryzen 5 7600X upgrade.\n\nWell I feel like I have just typed more than I should but I hope you find this helpful. I have tried as much as possible to dig deep into all aspects just to provide a more played out opinion.",
      "They are all the same, more or less. I had the RX6800 16GB for 3 years and the 6800XT for two weeks. Would prefer the RX6800 16GB again and overclock it to 6800XT performance level. The 128MB IF$ is just insainly good for 1440p, although the compute power is on a medium level of ~17 Tflops fp32 for the RX6800. The RX6800 has the best compute/cache ratio of all RDNA2/3 GPUs. 60CU over 128MB, it's 2.13 MB IF$ per CU, the RX6800 swims in bandwidth and is always Compute limited. The IPC per CU is here in greatest form. \nThats the reason why I would go for the RX 6800 for 400‚Ç¨ by now.",
      "Have fun man I am happy for you.",
      "Wow thanks man for your great answer. Il prob go with 6800 xt used, or I am considering also rx 7800xt to buy on amazon in Germany since I have friends there that can get it for me and bring me to Croatia. 7800xt is 460 euros on amazon and for 100 more euros I can get new GPU from new Gen.",
      "Yea I get that thanks for the info. I am now thinking about getting 7800xt since i can brand new for 460‚Ç¨.",
      "Welcome, I am happy I got to lay it out for you.",
      "Yeah, brand new with guarantee is always better.",
      "One more question do you think it would be worth it pay 100‚Ç¨ more brand new from store 7800xt over used 6800xt that is selling for 370‚Ç¨?",
      "Yeah it is worth it. You have to look at it with from an angle of longevity new will always be better than used regardless of specs but of course there is a matter of preference. Personally I would always go for a new if I can.",
      "Yea thats what I thought. Il prob go with new 7800xt its good price new gen and its brand new not used. Thanks man for help",
      "You also happen to be very lucky with these prices from the part of the world I am from the prices would range somewhere between 600-790",
      "Welcome. You'll bring reviews of how it performs from your end."
    ]
  },
  {
    "brand": "amd",
    "generation": "6000",
    "tier": "high",
    "matched_keywords": [
      "6800xt"
    ],
    "title": "new card, futureproof for the next years",
    "selftext": "I built a new system in December 2020. As there was already a problem in getting videocards a bought a 2nd hand 980ti. \n\nNow 2 years later the supply is better, prices are dropping for both used and new cards so it is time to look for an upgrade, especially because I replaced my 51\" HD television for a 4k 55\" (I game on my pc sitting on 180cm distance from the screen) and the 4k resolution¬† is pushing the 980 to its limits. \n\nInteresting options now are the RTX 3070 8gb for ‚Ç¨400¬† used, or 6800XT 16GB for ‚Ç¨475 used in the Netherlands. The 3080 is a lot more expensive. \n\nWhich card is a better choice at the moment, which is a more futureproof choice for the next 4 years?\nMy hesitation of the 3070 is especially the 8gb ram, a relatively small amount for 4k resolution. \n\nAlso, will the prices drop more in the next months/year (new and used)? \n\nThe games I play are mostly 3-5 years old. So in 2026 I play most likely the games released in 2022. \n\nCurrent system: \n\nMainboard: Gigabyte Z490M Gaming X (Z490, socket 1200)\nCPU: Intel Core i5-10400F 2,9GHz (4,3GHz) 6core\nRAM: 2x 8GB PNY XLR8 DDR4 3600MHz\nPSU: MSI MPG A650GF gold rating\nSSD: Crucial 1TB M.2\nGraphics card: Asus Strix GTX 980 TI 6GB",
    "comments": [
      "I would choose rx6800 because of the vram",
      "It's also about 25% faster so an easy win for the 6800XT",
      "The 3070 is a 1440p card,  if you want 4k go 6800xt or (preferably) higher",
      "Also don‚Äôt forget when going to amd from Nvidia I would run the program ddu to completely remove the nvidia drivers.",
      "For future proofing, I would avoid the Rtx 3070 because it‚Äôs vram is only 8GB. I would definitely choose the 6800xt because the 16GB will help in the future.",
      "All right, 6800 XT or higher it is. Hopefully the prices will drop more :)",
      "As a 7900 XT will be eur1200 (MSRP in USD times 1,3), I expect a 7800XT to be around eur1000\n\nThat said, I think eur700 for a 6900XT is a good price, with availability right away instead of waiting another year and the hassle to get one.\n\n(Hopefully I can get one for 700 , as the prices a increasing and dropping each day)",
      "6800 „Äã 3070.",
      "There‚Äôs no real future proofing with gpus, but if you want to at least have a good experience without spending crazy amounts of money, it‚Äôs better to stay at a mid range and upgrade more often than going with a higher end and trying to use it for a long time:\n\nIll use nvidia as an example.\n\nit‚Äôs better to upgrade to a x60/x70 every 1/2 gens, selling the old card while it still has some value so in the end, after the cost of the first card, it feels more like a subscription where you‚Äôre only paying the difference between the new card and sale price of the old card every year / couple of years.\n\nNot only you keep a good and constant performance that keeps up with games over the years, you do so without actually spending a crazy amount of money, you also keep up with newer technology.\n\nAlso don‚Äôt forget the power cost, people ignore that but at the end of the year, can bit quite a big amount depending on how expensive is electricity there‚Ä¶ x60-x70 are the most efficient in power terms, deliver the most frames per watt so keep your power bill in mind.\n\nI mean, a 980ti, while still being slightly more powerful in raw terms than a 3050, it doesn‚Äôt have tech like DLSS, meaning it consumes like 2-3x the power while actually performing worse than the 3050 once you enable DLSS. I bet a rtx6070 in a couple gens will be much more desirable than even a 4090 is by then, and with the cost of the 4090 (and the high power bill), you can literally pay the x70 upgrade/sell cycle for many years, way longer than the 4090 realistic lifetime. So even a 4090, unless you need that performance now, wouldn‚Äôt be a good future proof GPU, even if it performed well these years, just because of the power consumption.",
      "If you can stretch a 6950 are not crazy to buy compared to a Nvidia line up. The only 2 down sides to amd is their rt is better and drivers can be more stable",
      "That is also a factor that I am considering, but the difference is not that big with our electricity prices.\n\nIn the recent past  is usually bought 2nd hand mid range or high end for ‚Ç¨ 200 each 3 years. But with 4k that is not a good option. So I need to increase the budget\n\nIn the ATi 8500 and 9800Pro era  I bought those two cards brand-new. But then, a high end card was costing ‚Ç¨300 new instead of the 1000+ now.\n\nNew prices now are 649 for a 6800 XT, 699 for a 6900 XT and 1049 for a 6950 XT. Still the 6800 XT and 6900 XT are above my normal budget.",
      "Actual new Prices at the moment \n\n‚Ç¨649 for 6800 XT\n‚Ç¨699 for 6900 XT\n‚Ç¨1049 for 6950XT\n\nSo the the price gap to a 6950 XT is big",
      "Yeh, cards are too expensive nowadays, I haven‚Äôt upgraded my old ryzen 1600 and 980ti (i have one too) because of principle, im not going to pay scalper prices, and shops are still selling them at that, rather not play at all even thou the 980ti can still handle games well enough for 1080p (cyberpunk at high settings and fsr in 1080p still runs at 60 fps)\n\nBut I only got the 980ti because i needed the performance back then since i had a oculus rift, but before that i used to upgrade the x70 every gen from the gtx275 to gtx770 and it costed always under the 100‚Ç¨ per gen to do so after selling the old and it kept me playing the latest games at quality settings and the standard resolution of the time and i always had the latest drivers and technologies (shadow play, hairworks, etc).\n\nI skipped the 1070 because made sense downgrading from a 980ti, i waited for the rtx2070 but we know the story there‚Ä¶ the gtx1000s where probably the last time we had reasonable prices.",
      "https://www.newegg.com/msi-rx-6950-xt-gaming-x-trio-16g/p/N82E16814137733\n\nWe can get a 6950xt for 779 USD I don't know if new egg shios international",
      "6950xt pricing is very temporary, IMO. Once the 7900's are available, this will also fall.",
      "The Asus 6900 XT is now 32% below MSRP here at the moment.\n\nI bought the used asus 980ti in December 2020 for EUR 210  one year later, they where asking EUR 400 for a used 980ti... now it is EUR. So a bit more normal, so the prices a dropping and stabilising.\n\n\nBut still deciding if I am willing to pay 700 euros for a brand-new Asus 6900 XT (or 650 for a 6800 XT)",
      "You never, ever ship a gpu to europe, not only they will still kill your deal with vat, you have extra fees for importing and you can also say bye bye to rma if something goes wrong unless you want to pay a lot in shipping.\n\nGpus are stupid expensive here in europe (I haven‚Äôt seen a rtx4090 for under 2000‚Ç¨ with the avg price being like 2200-2400‚Ç¨) i bet a 4080 here will cost as much as 4090 in the us, which is annoying as the majority of europeans still have much less purchasing power/expendable income (these high gpu prices are clearly being condoned and promoted by american buyers)",
      "Divide the avg fps by the price, at this point 50‚Ç¨ wont make much of a difference if you‚Äôre paying over 700‚Ç¨, but tbh, id check benchmarks, calculate the avg cost per frame of all current gpus and pick the cheapest gpu of the bunch (it will be probably still be one of the mid to mid high tier ones) and that would be my choice and new tier for the upgrade and sell cycle, just add just a bit of offset if you want technologies like ray tracing or not",
      "Yeah vat is a pia, I wish everyone would just use Australia's vat amount.",
      "Indeed 50 euros for 10% more fps, so could be interesting for the rest value or more lifespan on the long run\n\nFact is, that it is more fps and vram per euro in comparing to the nvidia cards, the 3080 is 900 euro here, 3070 ti 750 euro"
    ]
  },
  {
    "brand": "amd",
    "generation": "6000",
    "tier": "high",
    "matched_keywords": [
      "6800xt"
    ],
    "title": "AMD Queue 05/19/22",
    "selftext": "Got on the AMD queue today and was in almost immediately.  They've added the 6900xt back, but no 6800xt still.  My guess is they're only selling the 6750xt, 6900xt, and 6950xt moving forward.  Sucks for me, because I've been hoping to pick up a 6800xt.  Looks like I'll have to go third party once the prices get a little closer to MSRP for the reference card.",
    "comments": [
      "After months of getting high wait times and leaving empty handed, I finally got to the store instantly, just to leave empty handed again because the 6800xt aren't for sale anymore, I guess that everyone wanted one? It seems that not even the bot/scalpers bothered this week.",
      "Same issue with Nvidia.\n\nAMD knows they can get more money by selling those GPU dies as 6950s, than as 6800's, and the yield is so good they just don't get enough defective cards to create 6800s.\n\nWith Nvidia, they were even greedier, they created the rtx 3080ti, so they could sell the defective 3090 dies at 70% markup compared to 3080s, so a MSRP rtx 3080 is now almost impossible to get.",
      "AMD HQ: \"Yes, we beat the scalpers!\" /s",
      "No sign of the 6900xt in the canadian store, but I got one  6750xt quite easy and both the 6750xt and the 6950xt are still available at 13:40 EST.",
      "Yep.  Exact same story here, and that's my guess to your points.  We know miners are starting to offload due to profitability issues, so it looks like the bots are probably on hold until RDNA3 hits later this year.",
      "store still 100% in stock lol",
      "Makes me laugh at the scalpers trying to sell reference 6750s for $750 on ebay.",
      "Where are you located? If in the bay area, I have a used midnight black 6800xt I need to sell.",
      "Yeah, all 3 cards are available on the US site still.  I think the days of needing to queue are gone (unless they actually bring the 6800xt reference back).",
      "Beaten scalpers: yes, we're beaten /s",
      "Yeah, I'm not comfortable one-offing a shipment like that too.  Appreciate it, though.",
      "[https://www.newegg.com/xfx-radeon-rx-6800-xt-rx-68xtaqfd9/p/N82E16814150867](https://www.newegg.com/xfx-radeon-rx-6800-xt-rx-68xtaqfd9/p/N82E16814150867)\n\n$769 plus one month of game and the game bundle added to the offer; That's as close as I would expect you to get to the \"MSRP\" of the 6800XT, especially since the AIB 6800XT was never offered in 2020 at anywhere below $790-800 (even at launch)",
      "East coast.",
      "Hey I live in East Bay! Check your dm‚Äôs",
      "I actually saw that earlier (it'd be $779, though).  The only thing I hesitated in is that I need to water cool it, and I had a hard time pinning down any water blocks that were made specifically for this version of the card (plenty of Merc varieties out there, though).  I'll have to keep watching it.",
      "Damn, I'm west coast. Didn't want to leave getting the product to you up to shippers who can steal/break it.",
      "I'm on the East Coast.  I sent a PM.  Not sure if you'd be interested.",
      "don't see anything",
      "[https://www.amazon.com/XFX-Speedster-MERC319-Graphics-RX-68XTALFD9/dp/B08TJ2BHCQ/](https://www.amazon.com/XFX-Speedster-MERC319-Graphics-RX-68XTALFD9/dp/B08TJ2BHCQ/)\n\nMERC319 for $799 and does have waterblocks available for it. (At least from bykski)",
      "Okay, check now"
    ]
  },
  {
    "brand": "amd",
    "generation": "6000",
    "tier": "high",
    "matched_keywords": [
      "6800"
    ],
    "title": "AMD Radeon RX 6800 allegedly 1.5x faster than GeForce RTX 3090 in cryptocurrency mining",
    "selftext": "",
    "comments": [
      "Bots+Scalpers+Miners+Pandemic. The four horsemen of the GPU apocalypse.",
      "How do I delete someone elses post?",
      "Please don't..",
      "Well first you'll need to crack their password, so I'd recommend getting a really powerful graphics card capable of calculating a lot of hashes quickly.",
      "I actually heard it deletes your cryptocurrency. Best not to risk it.",
      "Reviewers get all the stock*",
      "(**Here we go again**)x2",
      "Everyone just repeat : fake news, fake news, fake news.... Fck",
      "And by that we mean one single GPU that has to be passed around.",
      "And here I thought the Nvidia launch was bad... turns out it was just a warmup",
      "Probably start with some small talk. \n\nGet to know them a bit. Find out what is their birthday, any pets/children, favorite sports teams and colors.\n\nToss that all into John the Ripper.",
      "Now we're REALLY never going to get it.",
      "Ah shit, here we go again.",
      "Another 3 years with RX 580 it seems.",
      "**Please read this before buying up all the gaming cards thinking you'll get rich from bitcoin mining:**\n\nGTX 3090: 106 m Hashes/second at 300 watts. price =$1500\n\nRX 6800 XT : 150-200 mhashes/second. price = $650\n\nAnt Miner (low end ASIC bitcoin mining card):   1,000  mhashes second. 63 Watts. Price $38\n\nSo the BTC miner is about 100 times better value than the Graphics cards, and has lower running cost. SAVE THE GRAPHICS CARDS FOR GRAPHICS PEOPLE!\n\n\\----------------\n\n\"How is that possible?\"\n\nbecause ASIC hardware doesn't  waste silicone space on circuits that do graphics. They can focus 100% of the silicon on dedicated circuits that only perform the Bitcoin Hashing algorithm. It's not uncommon for ASIC to get 2 orders of magnitude improvements over generalized hardware.  \n\n\nEdit: Misspelled a word",
      "And it's gone",
      "Fuck you crypto miners!! If prices start to rise at launch, I'm not going to upgrade my system. Tired of this crap...",
      "But this is guaranteed sales of their parts. And that's what they want.",
      "No please... not again",
      "That's the actual truth about review samples. They have to send them around to other reviewers since early supply is always an issue."
    ]
  },
  {
    "brand": "amd",
    "generation": "6000",
    "tier": "high",
    "matched_keywords": [
      "6800"
    ],
    "title": "One of the big offical AMD sellers, in the netherlands selling the 6800 xt for more than 1200 dollar at this point it isn't even funny anymore",
    "selftext": "",
    "comments": [
      "And here I was thinking the 850‚Ç¨ Alternate Germany are asking were ridiculous.",
      "Fun fact: it Was ridiculous",
      "Yes, but sadly this pricing decision has nothing to do with AMD. Anti-trust laws prohibit AMD from dictating a minimum or maximum price to resellers - this is entirely Alternate's doing. \n\nWhat Alternate is doing is shitty though and shows that yesterday's assertion that no dutch retailer had cards was not true. They just did not want to sell those cards at MSRP...",
      "Yeah we should rename Alternate to Scalpernate",
      "And they have the gall to charge 5‚Ç¨ for shipping too...",
      "To sell it for 1800‚Ç¨ on eBay",
      "This i'm so suprised nobody mentioned this but AMD does it as well, we are buying cards that cost 600 euro+ why the ever living F are they charging shipping??",
      "We could also register the domain scalpernate.de/com/net/nl/etc. and \"adjust\" google search results for \"alternate\", which is a common word in english language to be suggested and redirected to scalpernate.\n\nI seriously wonder why we dont have laws against scalping on that scale in the EU. Ofc you have a variance, but how can it be over 1.5x of the MSRP not even 1 day after launch? It can't.",
      "Its a joke, Spain's price was 670‚Ç¨ for the 6800xt from the major retailer, a very reasonable price.",
      "Alternate is just the shittiest company I know. Pls don't buy there.\n\nThey did the same with the oculus rift S.",
      "Because that would add ‚Ç¨5 to the MSRP.",
      "You know what's even more ridiculous? That OP didn't mention that that listing doesn't even have an order button. Let alone stock. You can't buy it. It's obviously a placeholder.\n\nOf course his story is a better narrative for kudo's, so...\n\nEdit// As of 16:17 European Time (30 minutes prior to this edit), the situation changed and Alternate has put 5 pieces of stock on their site for this particular card. They also sold.",
      "Yeah i know that but its still a very shitty thing to do",
      "Seriously.. what amount of time has to pass so that people can clearly call NVIDIA/AMD out on the actual price of their product? Are people going to use the \"free market\" excuse until the next gen arrives? Why are PS5/XSX and many other products being sold at their advertised value, but GPUs somehow get a free pass?",
      "Just Alternate overcharging like they always do - even when supply is much better (though not to this extent).",
      "same thing happening with nvidia.. The prices are way beyond what nvidia said the prices would be.. so annoying. At this rate by the time most people get a card at a normal price its gonna be 1.5 to a 1 year before the next gen lol",
      "Knowing the very basic principle of economy doesn't make this any less frustrating. You are not the only one who has seen wikipedia articles.",
      "Supply and demand. Which obviously works out fine for Alternate.",
      "Lol for 100 units\n\nIt was a decent price, but the stock was a joke. It's a perfect marketing strategy. Look at all of *ass trying to grab one.",
      "Are you sure? German alternate price of 850 (1000$) was not a placeholder"
    ]
  },
  {
    "brand": "amd",
    "generation": "6000",
    "tier": "high",
    "matched_keywords": [
      "6800"
    ],
    "title": "It's been awhile since I've had an AMD GPU. Just replaced my GTX 1080 with an RX 6800 XT and I couldn't be happier with this absolute UNIT!",
    "selftext": "",
    "comments": [
      "This is definitely 1st world problem. I'm gonna hold on to 1080ti until it dies ngl. There are so many excellent old games so I don't need to play the latest games",
      "Following the trend, your next GPU will be roughly 5 slots thick and 18 inches long.",
      "You are talking to man who is running R7 260X 1Gb",
      "So for those interested, the cards from left to right are:\n\n1. Unknown, cause I was 7 when we got it lol\n2. Zotac GT 440\n3. Asus GTX 660 (I had 2 in sli)\n4. Gigabyte GTX 1080 Xtreme\n5. Asus TUF RX 6800 XT\n\nIf any of you Reddit wizards knows what that first card on the left is, let me know. It's a Radeon something. I feel like it's 4000?",
      "Usually I win these ‚Äòmy GPU is old‚Äô fights with a HD6950 but I think you win this time.  I tip my highly inefficient old hat to you.",
      "That Asus card is what they use as a model for the house in escape from tarkov",
      "I have experience with that kind of dimensions, so no stress about that.",
      "I've got a GTX 1070 and feeling it but with no stock and overcharging everywhere it's difficult to know what to do.",
      "Yesterday I picked up this beast\nhttps://imgur.com/a/t0QN8G9",
      "Look at dem anime tittes",
      "I think that was your CPU...",
      "Pretty sure the one on the left is a Radeon HD 4350, I have one of those cards too.",
      "Old games for 1080ti? \n\nGames have stagnated since it came, it will work just as well as a new card next 5 years. It was to good when it came out.\n\nI figure 5 more years before i replace it. My 6600k cpu also stays, new CPUs have marginally better single thread performance and that's what I need.",
      "New cpus are significantly better than your 6600K. \n\nI dont wanna tell you that your cpu is bad. If you like it thats great. \n\nBut since the launch of ryzen in 2017 it is low end. And almost every newer game will give you stutter and a worse framerate. And your 1080ti will get bottlenecked in many games even in 4k for some. \n\nThat 4 cores are enough for gaming was true maybe 4 years ago. \n\nDont spread false stuff just because you are fine with your performance.",
      "Lol i use an hd 6870 with a dedicated power supply xD",
      "Lol surprisingly no. I got it from memory express (Canada). It was definitely still overpriced compared to MSRP though",
      "I just upgraded from a 2080 Max Q to a 3600X/  6800 and I‚Äôm sold on AMD. 1080‚Äôs are pretty great still if you‚Äôre a 1080p gamer tho, it‚Äôs just not enough for 1440p IMO.",
      "Omfg is that a tank on the right",
      "It's not. But similar. In Tarkov it is a 750 Ti",
      "Yeah I'm not sure the guy above you realises how far CPUs have come recently in terms of raw performance.\n\nUntil fairly recently I thought my 6700k was still fairly high end, until I looked at benchmark scores. Don't get me wrong, it's a fantastic CPU, and certainly still plays modern games with no problems, but the newer generations are just way, way, way better in almost every way."
    ]
  },
  {
    "brand": "amd",
    "generation": "6000",
    "tier": "high",
    "matched_keywords": [
      "6800xt"
    ],
    "title": "Unpopular opinion here but 6800XT should be $100 cheaper compared to 3080.",
    "selftext": "\n\nAMD is not fighting on features, they are not fighting on performance, they don't have user base with brand loyalty, they don't have more inventory and they don't have better drivers.\n\nYes it was a good leap compared to 5000 but that is also because they didn't compete at higher end.\n\nWhy would you tell anyone to buy 6800XT over 3080?\n\nComparable performance at 1080p and 1440p is good but for $50 more you get playable ray tracing and better overall package.\n\nMore VRAM is a good point but why would it matter when it is not getting utilized right now and probably won't for quite some time.",
    "comments": [
      "The demand is greater than supply so far, so they could sell them even higher.",
      "Popular Opinion: Both should be made $100 cheaper.",
      "It‚Äôs hard to raise prices later, but it‚Äôs easy to lower them. If in doubt start high and slowly lower the price, moving down the demand curve, until you get the quantity sold that you want.",
      "Unpopular opinion here, but AMD could have launched the 6800XT at $800, and they'd still sell everything they can ship until the new year.",
      "It's about \\~$300 cheaper in my country compared to 3080 ($1200 vs $1500).\n\nBoth, however, are MIA.",
      "> Less scalpers\n\ndohohoho.",
      "I am surprised that the price isn't higher.",
      "You can't easily raise MSRP, but you can lower it. Expect a price drop if they actually manage to meet demand in a few months.",
      "It already is $100 cheaper or more depending on the region. I wish people would pay more attention to real pricing and less attention to MSRP fantasy pricing.\n\nI paid 680‚Ç¨ for a RX 6800XT from AMD directly. 3080 FE isn't possible to buy in Europe anymore and the cheapest AIB models where I live are 800‚Ç¨.",
      "Someone knows their firm-level economics!",
      "3090 enters the chat.",
      "...and why would either AMD or NVIDIA charge $100 less when their products are sold as soon as they hit the shelves as-is?",
      "they said *should*. thats unrelated to the actual market value",
      "It's gonna be $100 high for non-reference models. So yeah...",
      "Would make sense to sell on higher price actually. Less scalpers, less price hiking by dubious stores and after all better margins. Lower the price only when you can meet the demand.",
      "That's not unpopular. That just being real and doing business.\n\nThere is a business demand, and there is a void from nvidia. AMD listing at a higher price is the highly touted capitalism working just as expected. Too many out there don't understand business and have been brought up in the US culture of discount, discount, discount. \n\nNow, on to chapter 2. The first hands of cards are dealt, competition is real (finally). Will green or red make any pricing reactions in Q1 will be the first thing to watch, and whether refresh in Q3/Q4 will be hasten is also be interesting to keep an eye on.",
      "Same for Romania lol. They are inflated, but literally 6800xt is the same price as 3070s.",
      "wishful thinking, opinion, frustration. I dont know, everybody got their own reason",
      "I think this statement is 3 days early. We need to see what the AIB cards come in at for the 6800XT. Realistically even if you can get a 3080 you are paying at least $750 if not more as the AIBs are mostly just making their top end cards the Strixes and FTW3's of the world. Are they $699 or higher. Keep in mind the AIB cards will likely beat the 3080 flat out a well.\n\nAMD has also said that at least through the end of the year, so you have a situation where the reference design is $100 cheaper and the AIB boards are $50-100 less for better overall performance in all non RT titles.",
      "WTF do you mean they're not fighting on performance?"
    ]
  },
  {
    "brand": "amd",
    "generation": "6000",
    "tier": "high",
    "matched_keywords": [
      "6800"
    ],
    "title": "Get your brand new rx 6700 xt for the price of an rx 6800!",
    "selftext": "",
    "comments": [
      "More like at the price of a 6900 XT, screw buying a GPU these guys suck.",
      "Yeah there's a reason why the dutch sites have stock and its the euro sign followed by 4 digits.\n\nI've been waiting for a replacement for my old gpu for overa year now because of no stock anywhere but I'm not blowing 1k for this",
      "It's totally insane. I've paid 1280‚Ç¨ at the beginning of this year for my 6900XT, because I had a bad feeling about the prices. Seems, my feeling was right.",
      "It's legit crazy. I don't know why we even have an MSRP anymore.",
      "An rx 6800 at bloated price that is",
      "I don't know if anything will ever be MSRP again. Even after crypto boom ceases - these guys know that gamers are willing to pay 2-3x MSRP for cards so why wouldn't they just make them that price forever?",
      "Volume and competition, I suppose. The number of people willing to pay this much are relatively small: for every entheusiast who is buying cards somehow, there are the literally five people who asked me to make a cost effective build that I have flatly told \"not until prices come down\". I'm not upgrading any time soon, and I'm directing people to buy consoles when they ask me how to game right now, something I've never done before in my life.\n\nCompetition, theoretically, will help push prices down - Intel GPUs have to put themselves into some niche in the market, and amd and nvidia will want to respond, so once the market HAS supply then it might act rationally again.",
      "[This comment has been removed by author. This is a direct reponse to reddit's continuous encouragement of toxicity. Not to mention the anti-consumer API change. This comment is and will forever be GDPR protected.]",
      "I'm in China, got a 6900XT reference for 1100‚Ç¨ (MSRP is around 1030‚Ç¨ here) from a reseller because they weren't selling so well, everyone was trying to get the lower models from AMD and nVidia around MSRP at the time. These days the 6900XT goes around 1500‚Ç¨ at least, lower models above 1000‚Ç¨, so glad i pulled the trigger even though i planned to get the 6800xt originally.",
      "I ordered a prebuilt the other day for $1700 just so I can get the 6800 out of it and sell the rest to make up the difference. That entire system is cheaper than one 6800 on eBay.",
      "Right I was looking how much my pc build is worth today. And my 5700xt was selling for $1700 on amazon.  It's crazy",
      "It's a bullshit. I'm really tired of this shit. I just wanted a SINGLE 6800 XT at a fkn normal price as they promised. Just one card to play my fkn games as it's supposed to be.",
      "1500‚Ç¨ lol, try 2000‚Ç¨.",
      "FFS. ~$1620 AT START for cheapest 6700xt here. Jesus christ. I'm done!",
      "Bruh, intel is gonna take full adevantage of the price level. Only hope is a crypto crash.",
      "Yeah I paid $950 for a 6800 XT with an msrp of around $800 in December and slightly regretted it until this somehow managed to get so much worse this year. Definitely glad I did it now.",
      "So how‚Äôs the hash rate efficiency? Asking the important question here /s",
      "Fuck that geez, I'm pissed off about AMD  still not fullfiing  5900x orders  from nov 5th  (uk), while still releasing more products they can not fullfill but man I feel so grateful  I was able to get  zotac trinity  rtx 3080 order on launch right near the bottom of the queue  till Oct then was able  swap to a Palit gaming Pro as that queue had been fulfilled at the time  for an extra ¬£30 in Oct which shipped 2 days later  just gets shitter for gamers",
      "Haha dit is azerty maar alternate kan er ook wat van. 899 voor de goedkoopste wat geen pre order is. \nSorry maar 2x adviesprijs gaat mij t petje boven. \n\nMijn 1060 werkt nog goed genoeg",
      "You got lucky then. I've tried this in the UK and even selling the parts I'd still end up paying nearly ¬£900 for a 6800.\n\nThat would be a preorder 6800 as well!"
    ]
  },
  {
    "brand": "amd",
    "generation": "6000",
    "tier": "high",
    "matched_keywords": [
      "6800xt"
    ],
    "title": "i5-2500k / R9 390 into 5600x / 6800xt - i'm finally here",
    "selftext": "",
    "comments": [
      "After few years of waiting for an upgrade i've managed to get here. I was casually gaming at 1080p and it was managable but decided it's nice to check 1440p / 144Hz as i was astonished with high refresh rate when seen it in action @ my friends house. That's why i discarded 4k60 from the list.\n\nGrabbed 5600x as there were plenty of them available here in Poland and lucked out with 6800xt with an order @ 15:16 local time at second biggest retailer. Didn't expect i would make it and received info from retailer, that it will be shipped in a month which got me sad. I wanted to cancel and wait for AIB drop next week, but then got a message next day that it's ready to be shipped.\n\nOriginally i wanted to buy 3080 FE but restrained myself until i will see what AMD will release with RDNA2. After reveal the choice was simple but still if i wouldn't get 6800XT, 3080 was my backup plan. I don't care about the brand, just about the performance.\n\nThis system is perfect now, 5600x with PBO boosts up to 4850Mhz if required. It's still a fresh lineup of CPUs so i think next AGESA / BIOS releases will allow for better OC.\n\n6800XT is just a monster for my needs. Some people reported coil whine but mine doesn't have any. Idles @ 50 degrees Celsius and goes up to 80 when gaming.\n\nFull system specs:\n\nR5 5600x  \nASUS TUF X570-Plus  \n16GB 3600 CL16 IRDM Pro GoodRAM kit (Hynix CJR) - still need to play a bit with it  \n6800XT Ref by PowerColor  \n750W Gold PSU  \n\nTo everybody waiting to snag the card / CPU: it's worth it.",
      "CPU in MediaExpert, GPU in x-kom since in morele it was already sold out.",
      "Where in Poland did you buy it ?",
      "Great buy! Congratulations on the new build. \n\nI myself am surviving with an i7 2600 (non-K) and RX 570 4GB (2nd hand to replace a failed RX 480 8GB). \n\nAm currently indecisive whether to pick 5600X or 5800X paired with RX 6800 or 6800XT.",
      "It‚Äôs going to be the same CPU upgrade for me. The 2500k was an absolute beast for its day and I‚Äôm hoping the 5600x will have a similar longevity.",
      "Haha, Sandy Bridge is really immortal, i've waited so many years but always had the feeling that it ain't worth it yet. \n\nFor the CPU choice i had the same and as i purely game (without streaming), went with 5600x as i really doubt those 2 extra cores will make a difference. Still at 1440p i will be more GPU limited than CPU.\n\nAnyway, both of them are great choice. 5800x runs a bit hotter form what i see (65W vs 105W TDP) but if you've got a proper cooling, won't be a problem.\n\nI have a friend who bought 5800X and is really happy about it.",
      "Immortal Sandy bridge crew unite - before we quickly disband and jump ship to Zen 3. \n\nso looking forward to replacing my old 3820. It has served me well but I'm way overloading it atm. My 5900X is getting ever closer to being sent - have it confirmed for the 30th. \n\nPersonally I think the balance of a 6800XT and 5600X for just a gaming rig is pretty much perfect.",
      "Congrats man, what a sweet build! Did a similar upgrade 2 years ago from a 2500k, 60hz 1080p, and gtx 580s to a 9900k, 1080ti, 120hz 1440p UW. What a crazy upgrade, enjoy it!",
      "Already gave it to my younger brother. He likes to play old games so will perfectly fit him :)",
      "So are you going to sell that old sandybridge pc ? Or are you looking to use at as a secondary/streaming pc?",
      "There are so many of us upgrading from a i5-2500k this generation. Every top comment on the YouTube videos (LTT, J2C etc) all have people saying the same thing!",
      "That's a great gaming PC you have there. It should serve you well for years to come.\n\n&#x200B;\n\nAfter getting my stimulus check I decided to finally build a new PC that would replace my PC from 2012 (outside the GPU). It was the PC below:\n\nCPU - i7-3770K @ 4.5 GHz \nRAM - 16GB forgot speed\nGPU - GTX 680 until a 980 ti the day it was released\nPSU - 650 watt\n\nAfter doing my research I learned that the new CPUs and GPUs were right around the corner. Luckily AMD was going to support the current AM4 socket for at least one more CPUs series. So I bought the following to hold me over until the new CPUs and GPUs launched.\n\nCPU - 3800X @ 4.5GHz all cores & IF at 1800 w/NH-D15 stable in games, not in stress testing\nRAM - DDR4 3600\nMB - Gigabyte X570 Aorus Ultra \nGPU - EVGA 2080 Super XC Ultra\nPSU - Corsair 850 watt\nStorage - 1x256Gb (OS) 1x1TB Samsung 970 Evo Plus (games) 6TB of HHDs (2TB & 4TB)\n\nMy plan was to wait until the new GPUs and CPUs dropped and buy the best for VR games. Yesterday I was finally able to buy a 3090 FE (not paying %300+ for the EVGA FTW3 3090) from Best Buy and I will be buying a 5900X as soon as I'm lucky enough to be able to click the \"purchase\" button on a website.\n\nAfter I get my 5900X I will use that computer for at least 5 years and upgrade again. The only thing that would cause me to upgrade before 5 years is if a part comes out that gives me 200% better performance than what I will have now or a game I must play isn't enjoyable because of my current hardware.\n\nI plan on buying a PCI-E 4.0 M.2 drive in the future but for now if I need more storage I will just pickup a large mechanical drive or a large 2.5\" SSD for gaming stuff.\n\nI might buy better RAM since it seems that the memory timings for RAM effect the CPU performance more than the previous Ryzen chips.\n\nSince I play VR mostly I think this rig will allow me to have fun for years to come.\n\nFinal PC Form:\n\nCPU - 5900X with a NH-D15 (OC not known yet since I don't own it yet)\nRAM - DDR4 3600 for now and IF at 1800 (1:1)\nMB - Gigabyte X570 Aorua Ultra\nGPU - 3090 FE\nPSU - Corsair RMX 850\nStorage - 1x256Gb (OS) 1x1TB Samsung 970 Evo Plus (games)",
      "I have the feeling that it will be usable for quite some time :)",
      "Very good choice hope  he will have a good time!",
      "Also part of the immortal Sandy Bridge crew! I5-2500k here, this week I got a 1080 for ¬£200 to replace my GTX 670, and looking to get the 5600x with a new mobo and RAM! I feel Sandy Bridge's time has come!",
      "‚ÄúWelcome, time-spanning soul. Welcome... to your destiny.‚Äù",
      "Damn, i felt like 2500k was getting too slow in 2016 and then i upgraded to ryzen 1600x near end of 2017.\n\nI actually didnt expect that big of upgrade in gaming performance due to single thread performance being really about same when both are overclocked, but it was actually big improvement. Having done that i think that sandy bridge owners think improvement is less than you actually get by upgrading.",
      "It's like moving from HDD to SSD in terms of responsivness of the system and overall experience. Its just faster in everything what i do, even causual activities like web browsing seems to be more umm, fluent?\n\nFrom the gaming perspective, there's nothing even to compare now. Zen 3 demolishes my SB very much.",
      "Haha i fully agree. I think the time has come to really abandon old platform and get going with new shiny stuff.\n\nI restrained myself for so many years because Sandy Bridge was still delivering what i needed but i told myself it's time to go and do not look back.\n\nIt was a perfect decision :)",
      "That's a huge jump. I think one zen3 core would almost outrun that whole 2500k. Congrats."
    ]
  },
  {
    "brand": "amd",
    "generation": "6000",
    "tier": "high",
    "matched_keywords": [
      "6800xt",
      "rx6800"
    ],
    "title": "Reference 6000 series Or AIBs?",
    "selftext": "I wanna purchase RX6800 but if I go for AIB cards price will be closer to 6800XT reference card...if I get reference will it be good ? I know aib card usually performs better.",
    "comments": [
      "With the XT version only beeing 70 $ more expensive than non XT, its going to be really awkward when aibs want 100-200$ more for their cards. Considering the smaller nvidia cards are 200 $ apart and even they get mixed up with 3070 surpassing 3080 in price, which is pretty stupid.\n\nIf the same happens as with nvidia now, you are gonna see these 2 models completely mixed all over the place and a crappy aib 6800 will have no reason to exist beside the reference 6800 xt for even cheaper. A triple fan, 2.5 slot card cant be that bad , can it ? ;)",
      "Reference Vega was a single fan blower wasn't it?\n\nSo everyone knew it was gonna have shitty temps. Especially considering it's a 300w card.\n\n6000 series all have triple fan designs so there is no chance in hell that it will even perform anywhere NEAR as bad.",
      "Do you know when is the review of 6000 both aib and reference ?",
      ">With Nvidia, everything almost always provides adequate cooling and it is really a matter of what is better but nothing is flawed to the point of being unusable or sounding like a fighter jet taking off under load.\n\nYou never bought a lower - medium-end AIB Nvidia model or ?... like ... Zotac 970 DUAL fan fucking thing is a jet engine on 80C and tons more like this...\n\n&#x200B;\n\nEvery aib on both sides makes shitty and better models.",
      ">Do we know if/when AIB cards are going to be released?\n\nGN asked amd and AIBS\n\nAMD said they hope they have enough stock , at least for a few hours after release something along that.\n\n&#x200B;\n\nand AIBS told GN different time lines some 1 week after release some weeks after release.",
      "wait for benchmarks and reviews",
      "I'm waiting for custom boards personally, I want to see if there are higher binned models.",
      "AIB",
      "Reference should be okay, but right now the main challenge is making sure there is enough supply. If an AIB card is in stock and it's in your price range, you might as well get that.",
      "Serious question.  Do we know if/when AIB cards are going to be released?",
      ">apart and even they get mixed up with 3070 surpassing 3080 in price, which is pretty stupid.\n\nLiterarily every single  aib 3070 on the german market is at least 50 more expensive than a 3080 FE... so stupid...",
      "At launch most likely",
      "That'd be because it has a metal shroud and part of the vent is blocked... which is basically fixed on the 6000 series. Also the 6000 series has ducted fans... which are quieter at high speeds.",
      "The Radeon 7 was a triple fan open cooler also tho, but was slammed for being too noisy by the press.\n\nIt would be great if we can finally get a good reference cooler by Radeon, so they can shed the \"hot & loud\" meme.",
      "On the AMD side definitely wait for reviews and performance to be evaluated. AMD has historically made some really poor reference cards (ahem Vega 64) that didn‚Äôt have adequate cooling designs and required massive fan speeds. \n\nAIBs on the AMD side have historically been awful as well at times, with Asus on the 5700xt for example totally forgetting to cool the VRMs on one of their models.\n\nWith Nvidia, everything almost always provides adequate cooling and it is really a matter of what is better but nothing is flawed to the point of being unusable or sounding like a fighter jet taking off under load. On the AMD side you have to be more careful in your decision making.\n\nHopefully, this isn‚Äôt an issue with the RX 6000 series like it has been in the past but there have been so many issues in the past I‚Äôd definitely remain wary until the reviews prove otherwise.",
      "We don't know",
      "Look at Price performance from the date we have right now 6800 is the worst deal ever it's 70 bucks less than 6800xt for like 15%-20% less Performance  \n\nAMD is trying to Milk the Market hard right now to be honest if you look at the Market it makes sense for them at least Short term to do so, which sucks from customer perspective  your choice though \n\n(not even mentioning 6900xt which is only for people who don't care about money period)"
    ]
  },
  {
    "brand": "amd",
    "generation": "6000",
    "tier": "high",
    "matched_keywords": [
      "6800xt"
    ],
    "title": "6800XT launch was as bad as RTX3080 launch.. change my mind..",
    "selftext": "AMDs chance to get all mad Nvidia people... fail.",
    "comments": [
      "This launch actually seemed worse",
      "Newegg- sold out in 8 seconds.\n\nBnh - screen came up saying its in demand, doesnt let you search.\n\nAmazon - nothing ever came up if you search for it. You need the specific link to see it, but then it says unavailable\n\nBestbuy - coming soon thats it",
      "Bots bought every graphics card with \"6800\" in the title.\n\nAll the old 6800GT's sold instantly.",
      "Can't see him having a job long if he's going to act that stupid. Lots of angry customers and you post something like that LOL",
      "Newegg was sold out before the page even refreshed. Literally less than half a second.",
      "AMD Frank Azor(marketing) on twitter:    \n*Just successfully ordered an @amd @Radeon RX 6800 for myself on http://amd.com. Required some refreshing to get the order through but it worked.*    \nhttps://twitter.com/azorfrank/status/1329068706538811392?s=21\n\nIt just works!",
      "Worse",
      "Yeah, when I was searching, the 6800GT's came up for \\~$138 so I saw that every time the page refreshed.\n\nThen they went out of stock precisely at 6AM PST, the same happened with a ton of other things (CPU's) but the funny thing was 15-20 minutes after, they started coming back in stock again (except for the GFX Cards) as if someone realized the mistake and was cancelling orders.",
      "So far, it was worse. No Best Buy, Amazon or BH Photo sales. Pretty pathetic.",
      "The launch is worse as they made zero bot prevention knowing full well it would be needed. I managed to get to order confirmation page before the website crashed, never once asked for any verification I was human. Just popped up add to cart, then pay with paypal, 2 button pushes before it crashed.",
      "Yep. 2070 died a month or so before the 30 launch after two RMAs (thanks, MSI!), gone through three successive utterly shit launches. Look forward to the fourth utterly amateur hour performance on the 8th when the 6900 launches. \n\nNvidia installed the bar in the fucking basement and after two months of talking shit, AMD still managed to trip over it.",
      "wait really? lool",
      "Does he have any awareness at all?  He acting like a fucking troll",
      "6800xt.....for a media center. Talk about overkill",
      "Made it through checkout on AMD.com and then it just closed the page, didn‚Äôt charge my card, and I got nothing lol.\n\nNever saw the cards go available on Amazon or Newegg. Apparently they were up on Newegg but they must have gone so fast I missed them between refreshes.\n\nOverall 0/10, would not F5 on launch again.",
      "hahah worse. i have yet to find ANYTHING relating to 6000 series in any online shop ^^",
      "I need to make some BS product and, when AMD/NV next announce their lineup, sell it with the same number in the title. Then cash in on all the bots.\n\n\"All sales final.\" (well, I can try at least)",
      "Covid really messed up the tech hobby. Lowered production because of closed factories and increased demand because mod more people at home. Then you have to deal with scalpers, retailers and companies trying to exploit the situation. The demand should decrease once the vaccines are out and more people abandon the PCs and consoles to go out. However, I really feel bad for people who really need an upgrade or wanted to make a full build this year. Stay strong friends.",
      "I felt the same way.",
      "''sEe ? iT wAsNt A pApEr lAuNcH!!! I gOt oNe !!!11''"
    ]
  },
  {
    "brand": "amd",
    "generation": "6000",
    "tier": "high",
    "matched_keywords": [
      "rx6800"
    ],
    "title": "¬£800 for a RX6800 :(",
    "selftext": "",
    "comments": [
      "The is a 3070 in stock in the Netherlands and they are asking ‚Ç¨999 for it. I didn't get an EVGA 3080 FTW3 for ‚Ç¨880 3 months ago because I found it too expensive compared to Asus Strix (little did I know my non OC would never be in stock), I got the 3060ti Tuf OC for ‚Ç¨530 just before Christmas. Little bit more than the $399 MSRP for the FE, but compared to the 2021 prices... it was a good price",
      "Yeah I'm just leaving this gen to it I think, I don't like the idea of years with 10gb vram, or crap price performance ratio with no raytracing/dlss. Kinda resenting everyone paying so far over the top because it's showing them how much they can charge.",
      "I feel you, had the chance to buy a then overpriced 3080 a few months ago, thinking I'll get a better price by waiting and it then never happened and prices shot up FAR more.\n\nI got lucky now though by using a Twitter/Discord channel that alerts on stocks and I bagged myself a 3080 ASUS STRIX OC (UK) at a good price from Amazon, it should arrive this week or early next week... can't wait!\n\nI'm just hoping the delivery happens and it doesn't get delayed, destroyed or whatever in transit.\n\n**Edit**: added link as people are asking me in PM from where I got the notification.\n\n**Edit 2**: the price was about 800 pounds including import taxes/fees/etc, far cheaper than retailers that sell them at 900 now (which you can't also find).",
      "That's actually the MRSP for that GPU right now. In my country they cost up to 1000 USD :(",
      "Acording to Google, MSRP should be around ¬£600 in the UK. This is a 33.3% rise.",
      "I say that as someone that already has 11... The new console gen has started so it's reasonable to expect the texture size and quality to go up and not be limited by xbone and PS4 capabilities. I generally prefer 4k 60 so it really will matter when they start to push capabilities within a couple of years probably",
      "Here there is an RX 580 for 500$",
      "Well I think I'm gonna buy a console if prices don't go down, eh",
      "This is a custom AIB model a high end one at that. At worst it should be 100 USD more than reference MSRP not 150-200 USD",
      "Lol you say that like 10gb vram isn't a lot...",
      "just as a reference for the UK, I got the AMD reference 6800 from amd direct for ¬£530, so assume that's the msrp for the UK.\n\nAs a side note the reference is fine, typically 70 - 80 degrees for the temps (85 for the hot spot), but can easily be lowered by adjusting the fan curve, if you can find the reference go with that the AIB cards aren't worth the premium",
      "The market decides the price.  \nIf it is overpriced, don't buy it until it returns to a reasonable price.",
      "I'll be buying and RTX3000 if this is how its going to look. If the 6800 XT is ¬£1k there is no way im getting one.",
      "'Member when a mid-high end GPU was like $300-400(US)?\n\nI 'member",
      "Nearly 900 euros incl taxes and all, which I think is pretty good all things considered as it's 800 pounds in the UK.",
      "Not if people keep buying this shit.",
      "Technically yes, but short supply and high demand usually pushes things the other way.\n\nPersonally I think I'll skip another generation of GPU my GTX1070 will have to do I flat out refuse to pay anything approaching ¬£1000 for a GPU.\n\nThe short supply is also a demonstration of what happens when you put all your manufacturing eggs in a single basket. Seems someone skipped school the day that lesson was being taught.",
      "I paid ¬£420 for my gigabyte gaming oc pro 3060ti from currys",
      "The new consoles have shared system memory. They've got a lot because it does 2 jobs. \nYou'll not saturate 10gb vram very easily. \nPc gaming has has high resolution textures for years and years. They aren't a new thing. He'll go load half life 2 at 4k and see how good a 16 year old game and it's textures look!",
      "That's insane. I bought my RX 580 2 years ago for around $200 USD used!"
    ]
  },
  {
    "brand": "amd",
    "generation": "6000",
    "tier": "high",
    "matched_keywords": [
      "6800"
    ],
    "title": "[HUB] 16GB vs. 8GB VRAM: Radeon RX 6800 vs. GeForce RTX 3070, 2023 Revisit",
    "selftext": "",
    "comments": [
      "tl;dr \"definitive proof that 8GB of VRAM is no longer sufficient for high end gaming\"",
      "That is now. We're in the middle of a VRAM boom and it's only gonna get worse. 8GB will be for 1080P low settings soon. 12GB is considered entry level now by game devs, with 16GB being normal and playing on ultra will require even more. We will likely see this change in the next 1, max 2 years.\n\nThis is why AMD put 20-24GB VRAM on RDNA3. It's also why 4070Ti/4080 owners are getting ripped off even harder than they realize. \n\nFor years game devs gimped their own games to fit into 8GB VRAM, but now that PS4 support died they have collectively decided..  nope. Textures alone will be 12GB or more.",
      "1080P with high details is hardly \"highend\"....",
      "4070Ti vs 7900XT will be a similar scenario in 2 years. Except then we're not talking $500 cards but $800 cards.\n\nNvidia really messed up here. Even if it's intentional to make people upgrade much sooner than the normal 4-5 year upgrade cycle, the backlash will hurt.",
      "and yet this would be a -40 vote comment in 2022 let alone 2020.",
      "Reminder that both the RX 6900XT and 6950Xt cost the SAME price as the 3070 Ti.",
      "Daniel Owen just did a review on 3070 ti vs 6950xt as they are priced the same (in fact the 6950xt is cheaper on average) and showed how, for the money, the 6950xt destroys the 3070ti, even beating it in many games with RT enabled.\n\nHe is also a very pleasant youtuber.",
      "NVIDIA Can do whatever they want because most gamers want their cards over any brand. Sadly.",
      "exactly, had a chuckle when the nvidia GPU still stutters with DLSS On.....",
      "It‚Äôs great that AMD is forcing the VRAM competition even if they couldn‚Äôt compete on the top-end. At least NVIDIA is being forced to lower their price or increase VRAM on the mid to low end.",
      "If you google it you'll find reddit threads from 1-2 years ago laughing about this topic and saying 8GB is fine and AMD is dumb for putting so much VRAM on their cards, that it's just a \"trick\" to sell their GPUs because they suck.\n\nThat's what Nvidia gamers were thinking. And keep in mind the ones on Reddit tend to represent the more knowledgeable portion of gamers..",
      "To be fair, DLSS doesnt do that much for VRAM usage.\n\nDigital Foundry on this topic:\n\n[https://youtu.be/hkBTOUOqUCU?t=4278](https://youtu.be/hkBTOUOqUCU?t=4278)",
      "üéµVRAM killed the ray tracing starüéµ",
      "not sure where it was said, but nvidia hopes to replace gamers with ai customers...atleast a plan b",
      "This (vram) was a rising issue, 8gb don't cut it it's just people slow to catch up and pull their heads out of Nvidia's ass.\n\nAlso the 6800 nonxt seems like the golden goose of last generation of GPUs, enough horsepower to match or beat the RTX 3070Ti, 16GB vram, decent ray tracing and almost same or lower price than RTX 3070.",
      "I was debating between a 4070Ti or 7900XT, but this has definitely swayed me to the AMD GPU with its 20GB VRAM. I feel even 12GB is cutting it a bit fine these days.",
      "Hogwarts already using nearly 15GB of VRAM (12GB from game, 2.5GB for other stuff) at 1440p ultra with RT enabled. Those 12GB cards are toast in the future.",
      "The fact that some games run normally on 8GB GPUs, but look like shit, even tho settings are set to \"high\" and \"ultra\" is really problematic. In the past you at least got low FPS and would scale down settings as a result, here you don't even get consistant settings, it is all over the place. I guess game developers prefer angry posts about poor image quality over angry posts about poor performance.",
      "That's actually their goal, they want to be an AI company in the not so distant future.\n\nIntel's total worth: $135 billion\n\nAMD's total worth: $148 billion\n\nNvidia's total worth: an eye watering $662 billion. More than double the worth of AMD and Intel combined. Despite having a lower annual revenue than both.\n\nAnd this has very little to do with their consumer gaming cards. They could stop production of all Geforce GPUs, focus entirely on their professional cards and still make bank. Especially with the razor thin margins on RTX4000 cards. Smart people have invested in Nvidia because of AI. \n\nAlthough, if you had invested in AMD in Q3-4 2022, you would have doubled your money by now too..  crazy swings, almost like crypto.",
      "And yet only 20% of steam users (from the latest survey) had more than 8GB of VRAM.  Either the devs are out of touch or they just want to cater to the high end."
    ]
  },
  {
    "brand": "amd",
    "generation": "6000",
    "tier": "high",
    "matched_keywords": [
      "6800xt"
    ],
    "title": "5600X + 6800XT first time with AMD proc",
    "selftext": "",
    "comments": [
      "Move your GPU to the top slot for better performance",
      "Please the gpu to the top.",
      "Already moved GPU to first slot. I will add benchs soon\n\n[New photo first slot](https://i.ibb.co/tp8XzMk/IMG-20201129-122817.jpg)\n\n\\-**Borderland 3 test BADASS QUALITY: 2560x1440p**\n\n*TOP PCIE SLOT*: 112FPS ***(+43%)***\n\n*BOTTOM PCIE SLOT*: 78FPS\n\nI am doing further analysis because this is toooo much difference...\n\n\\-**Unigine Superposition 1080 extreme:**\n\n*TOP PCIE SLOT*: 10263 vs  ***(+3,8%)***\n\n*Bottom PCIE:* 9885\n\n\\-**3dmark Timespy**\n\n*TOP PCIE SLOT:* [https://www.3dmark.com/3dm/53861960](https://www.3dmark.com/3dm/53861960) 14851 points ***(+8,5%)***\n\n*BOTTOM PCIE SLOT:*  [https://www.3dmark.com/3dm/53855003](https://www.3dmark.com/3dm/53855003) 13685 points\n\nIn this case GPU temp was even better on top PCIE slot (72¬∫ vs 74¬∫ avg)",
      "Yes, but one is directly connected to the CPU while the other one is going through the chipset. The performance difference is very small, but its not optimal.",
      "Lower slot is only 4 or 8x (depending on motherboard), while the upper one is 16x / 8x (16x if the one you're using now is unpopulated).\n\nAMD CPU has only 24 PCIe lanes, on X570 4 are for chipset (sata and so), 4 are for NVMe (the upper one, the lower goes thru the chipset) and the remaining 16 are switchable: 16 on top or 8 + 8.\n\nOn B550 first slot get the whole 16 lanes and the remaining ones gets their connectivity from the chipset.\n\nInterestingly X570 drive PCIe 4.0 chipset latched PCIe connectors, while B550 only gives you PCIe 3.0 ones. Not that much of a difference, but this partly explains why X570 requires active cooling.\n\nThat's why.",
      "Edit (already moved it) \n\n[Moved to the top](https://i.ibb.co/10gdHYG/photo-2020-11-29-19-55-53.jpg)",
      "Yep and that's why you always put the gpu as priority in the pcie hierarchy",
      "Last time I had an Amd gpu it was a 6850 so technically I am downgrading\n\n[Ryzen 5600x without vent installed](https://i.ibb.co/fnTVncX/IMG-20201127-212702.jpg)",
      "Why do the people who have no idea, argue with people who do.....?",
      "Try running [Superposition](https://benchmark.unigine.com/superposition) and/or [Furmark](https://geeks3d.com/furmark/). They're both free benchmarking utilities. Some games have in-game benchmarks, such as the Tomb Raider games. If you have 3Dmark ([currently $4.49 on Steam sale until 2nd Dec](https://store.steampowered.com/app/223850/3DMark/)), then you could use its Time Spy benchmark.",
      "ALL",
      "Borderlands difference was huge. I am thinking of doing a retest on bottom pcie to find out if initial test was wrong somehow",
      "Not arguing, but why? Want to see if I am missing something. See OP's reply to the other comment.",
      "This is a bit easier to understand.\n\nX570\n\n[https://www.gamersnexus.net/images/media/2019/news/amd/x570-chipset-block-diagram.jpg](https://www.gamersnexus.net/images/media/2019/news/amd/x570-chipset-block-diagram.jpg)\n\n&#x200B;\n\nB550\n\n[https://www.gamersnexus.net/images/media/2020/amd-chipsets-b550/amd-b550-chipset-block-diagram.png](https://www.gamersnexus.net/images/media/2020/amd-chipsets-b550/amd-b550-chipset-block-diagram.png)",
      "Except if you look at the specifications list:  \n\n\n>**AMD Ryzen‚Ñ¢ 5000 Series/ 3000 Series Desktop Processors**  \n1 x PCIe 4.0 x16 (x16 mode)  \n**AMD RyzenTM** **4000 G-Series / 2000 Series Processors**  \n1 x PCIe 3.0 x16 (x16 mode)  \n**AMD RyzenTM** **3000 G-Series / 2000 G-Series Processors**  \n1 x PCIe 3.0/2.0 x16 (x8 mode)  \n**AMD X570 chipset**  \n1 x PCIe 4.0 x16 (max at x4 mode)  \n2 x PCIe 4.0 x1 \n\nThat second \"x16 slot\" is limited to x4 lanes despite using a physical x16 slot. There will be performance loss by using that second slot, although it'd most likely be in single digit percentages.",
      "Its ok to move the card to 1st pci slot,  you were afriad the heatsink is too close to the gpu? If they are not touching its should be no problem.",
      "They are usually the same people who pay ass tons of money on top of what a product should cost for RGB all over their components/peripherals",
      "Thanks for posting the results! Can‚Äôt believe it makes that much of a difference.",
      "I want to test differences between both configs",
      "Bought it here in Spain... just at release... it was hell crazy because they werent listed so doing F5 all the time till somehow they got insta-listed then delisted but I was already at the article page so I was lucky to get one (669‚Ç¨)"
    ]
  },
  {
    "brand": "amd",
    "generation": "6000",
    "tier": "high",
    "matched_keywords": [
      "6800"
    ],
    "title": "AMD's Radeon RX 6800 and the RTX 3060 are Faster than RTX 3070 in Doom Eternal w/ Ray-Tracing Enabled",
    "selftext": "",
    "comments": [
      "So it runs out of memory?",
      "Sort of. Doesn't crash or anything. Minimal stutters but the average is affected by quite a bit.",
      "\"Really 4gb of vram!\"\n\n>3.5gb fast vram\n\n>0.5gb s l o w vram",
      "Why i have feeling the rtx 3070 is the new gtx 970",
      "DOOM and DOOM Eternal are very sensitive to VRAM when the graphics are all the way up.\n\nDoes no one recall NVIDIA using 4K settings that made the 3080 choke a bit due to VRAM usage and made the 3090 look MUCH better by comparison?",
      "That's not the point. The point is that the 3070 has a 4K capable GPU but not enought VRAM for said resolution",
      "Generally tech press tests in highest available settings for maximum GPU bound test. That's pretty much industry standard.",
      "https://i.gifer.com/9U4v.gif",
      "There was fuckery with vram\nIt was advertised as 4gb but it actually was 3.5 + 0.5 (3.5 being of good, fast, memory giving you effectively 0.5gb less)\nIt causes stuttering and performance problems",
      "I agree that 8GB isn't enough today for a new high end card, but this ain't why. It's a setting that forces the GPU to cache extra unused textures in memory - reducing it doesn't affect image quality at all.",
      "Remember when they told us VRAM won't be a problem and we're overreacting?",
      "The VRAM in nvidia's cards is too damn low",
      ">Does no one recall NVIDIA using 4K settings that made the 3080 choke a bit due to VRAM usage and made the 3090 look MUCH better by comparison?\n\nI believe the comparison was between the 2080 and the 3080 and the scenarios in question would make the former run into issues with its smaller frame buffer. It's one of the few games that had the touted \"up to 2x performance uplift\", in part because of that.",
      "Yes that‚Äôs why people were doing 4K benchmarks with MSAA cranked up back in the day.  \n\nIt‚Äôs not always as simply as just cranking everything up.  Benchmarks back in the day used to run low/med/high quality presets for comparison which seems to have been replaced strictly by resolution tests.",
      "8gb is busted.... How long till it's 10gb?",
      "Yeh but also imagine paying all that money for a really small bowl",
      "No, that _is_ the point. The textual pool option in Eternal simply allocates additional VRAM, and has nothing to do with the quality of the textures. This is a non-issue *for this title.*\n\n8GB is small for a premium card, yes, but this case is an anomaly.",
      ">DOOM and DOOM Eternal are very sensitive to VRAM when the graphics are all the way up.\n\nYep. Doom was the game DF used to do the misleading \"3080 is two times faster than 2080\" video  (crippled perf by not fitting in 2080's VRAM)",
      "I'm sure they did know better, but \"Texture Pool Overflow Affects Performance in Doom Eternal\" doesn't net nearly the same number of clicks.",
      "Remember when this sub shat on Digital Foundry for testing Doom Eternal with Ampere gpus using this setting to purposefully make the 2080 perform worse (and thus make the 3080 look better)?\n\nNow people are using the exact same thing they criticized to shit on the 3070. Disingenuity at its best."
    ]
  },
  {
    "brand": "amd",
    "generation": "6000",
    "tier": "high",
    "matched_keywords": [
      "6800"
    ],
    "title": "[Optimum Tech] Test Fitting the RX 6800 XT in ITX Cases",
    "selftext": "",
    "comments": [
      "The only fucking Youtuber I can actually stand more than 5 minutes of. No 20 minute unboxing videos like some people. No useless outtakes and gags, no screaming and acting a fool, no baseless claims, no beating around the bush and stalling, no filler. Just incredible and actually valuable information with a calm, cool and collected demeanor, and the best editing in the game to go along with it. Sorry Phil, but it's not even close. He is honestly the only one I truly trust as well, and he has been a godsend to the SFFPC community. If it sounds like I am a cuck, it's because I am.\n\nEdit: Even the fucking screenshot shown above for the video is perfect. No cheesy Photoshop, and no eye roll worthy click bait title. He just tells you exactly what the video is about in about 7 words. Love this man and his plain black shirts.",
      "omg this looks beautiful",
      "*cough* Jayz2cents *cough*",
      "Do the cards ship with googly eyes?\n\n[https://imgur.com/a/tv9bx5a](https://imgur.com/a/tv9bx5a)",
      "Optimum Tech always create relevant video. All other YouTubers just create unboxing video for the sake of having a video.",
      ">no screaming and acting a fool\n\nI wonder who you are referring to here lol.",
      "I dont know what it is but I cant stand that channel, and I like LTT.",
      "He's whiney and entitled, whereas LTT is mostly just \"disappointed\" if something isn't nice. I've tried to watch Jayz, but he's just so annoying to me. I watch LTT occasionally, but I prefer a more technical presentation. I mostly watch Gamer's Nexus and Level1Techs, but even they seem to have a bunch of filler.\n\nWhy can't I just get a 5-10 min video or short article that summarizes the important details. I don't care for staring at FPS graphs, I just want to see a general overview at each resolution. Leave the graphs and whatnot for a blog post, video should be concise and high interest, with links in the description for more details.",
      "ooooooWHAT is up guys, we're BACK with ANOTHER video card review, this time it's the RADEON! 69 (nice) HUNDRED XT! \n\nBeforewegetintothevideothoughguys, PLEASE smashthelikebuttonandsubscribe. It really us helps grow the channel, and don't forget to hit the notification bell so you don't miss ANY of the GAMER CONTENT we put out EVERY SINGLE DAY.\n\n\\*to person behind the camera\\* Haha, did we get everything?\n\nPerson behind the camera: \\*some bullshit haha we're relatable\\*\n\nHaha, WOO! Let's get into it!",
      "Lol, so many people here and on /r/hardware are too young to realize that good print media exists.\n\nGamersNexus was a print website for several years before Steve started a Youtube channel. Same with HardwareUnboxed Steve. He wrote for TechSpot for over a decade (and still does) before he even started doing Youtube. Almost all of their content is available in written form for anyone who wants to spend 5 minutes looking for it rather than mindlessly clicking on videos.\n\nThis doesn't even include the dozens of websites that exist and publish content with no Youtube analog. If you're complaining that you don't like these videos and prefer to read news/reviews/benchmarks, then you're just lying to yourself. The written content exists and is not hard to find. You're either just too lazy or don't actually prefer reading.",
      "You mean you don't want to listen to Gamers Nexus stretch 3 minutes of news into a 32 minute video?!",
      "Linus is very entertaining though.",
      "Well good thing I just ordered the Nr200p, I knew the 6800xt wasn't gonna fit in my ghost s1",
      "anyone gave a verdict on the silverstone sg13?",
      "And these days his staff is often more watchable than him. You got Anthony and Colin who are just great, Alex and Jake who are madmen with their projects, and even Riley (NCIX Keys) and James have truly come on their own. If there's one thing I won't give Linus shit for, it's how he treats his employees.",
      "Gamers nexus DO have articles too. So you can pick whatever.",
      "RX5700 reference barely fits in it. I doubt RX6800XT will.",
      "HU benchmarking 4 recently released games is not bad, that said exact dimensions are also welcome.",
      "I'm watching this thinking how nice it is that it would fit in my NCase M1.\n\nThen I remembered that I have a better chance of winning that iPhone draw on the apple sub that getting one.",
      "Second image reminds me of [this](https://i.imgur.com/82PYlbs.jpg)."
    ]
  },
  {
    "brand": "amd",
    "generation": "6000",
    "tier": "high",
    "matched_keywords": [
      "6800xt"
    ],
    "title": "6800XT from Dell Alienware, impressive cooler surprisingly. Green PCB is not so nice.",
    "selftext": "",
    "comments": [
      "\"Any PCB colour you want as long as it's green\" - that used to be the norm like 20 years ago.\n\nOf course it would've been nicer if the PCB is black or red (or even grey), but as long as the card is okay, you don't have much to complain.",
      "I wasn't aware dell used oem GPUs in their desktop builds. Makes sense, though.",
      "If there's the choice between the PCB being green or costing a little more, green is the obvious choice",
      "Getting even older, brown was common.",
      "Sometimes they came in like a yellowish color. You could either get green or a yellowish green color.",
      "If there‚Äôs a choice between green and even getting one at all, green is the obvious choice.",
      "dell, alienware, same thing, proprietary is their thing",
      "Yeah, Dell does do that. Anything they make has the green PCB board, which, it's not a big deal, but I prefer the newer black ones",
      "Green PCB looks cool though",
      "This! Maybe I'm old, but I never understood why green became a \"low tier/budget\" thing. Remember those blue Intel MB PCBs? I liked those the most.\n\nBut then, I don't like RGB, so it's probably being 30s me.",
      "It kinda looks like a cost-down Radeon VII. Interesting!",
      "I mean if I was given the choice between no graphics card or green PCB graphics card I'm taking the green PCB. Even if it was $10 cheaper to buy new I'd take a green PCB.",
      "What is wrong with green PCB? It has some impact on performance? Or you can see it from kilometre away?",
      "The UD mobos from Gigabyte have brown PCB and I think it looks pretty. It reminds me of wood.",
      "I think the Radeon VII cooler still the best looking GPU cooler.",
      "TFW you buy a $650 graphics card for $650",
      "Dell are notorious for using awful coolers. Their proprietary stuff is complete garbage\n\nAlienware is literally the worst brand that exists in terms of quality",
      "I'd love to see cool red PCB, like on my old Radeon 9550 and Radeon x1600",
      "Red PCBs on ATI Radeon cards back in the day was nice too.",
      "Every once in a while you‚Äôd see blue, but I think that was only motherboards idk ¬Ø\\_(„ÉÑ)_/¬Ø\n\nEdit: YES I GET IT YALL HAVE SEEN BLUE GRAPHICS CARD BOARDS BEFORE."
    ]
  },
  {
    "brand": "amd",
    "generation": "6000",
    "tier": "high",
    "matched_keywords": [
      "6800"
    ],
    "title": "AMD Radeon RX 6900 XT, RX 6800 XT and RX 6800 reference desings are being discontinued - VideoCardz.com",
    "selftext": "",
    "comments": [
      "Not surprising. Every AMD reference card disappeared when the AIB partner cards were ready.\n\n\nThe only downsides to this are the fact that the reference cards are thus far the most compact variants of the RX 6800/6900 series cards (they're shorter than all AIB partner cards and the RX 6800 non-XT refrence card is the only two slot card in the RX 6800/6900 series) and the fact that these cards were the safest bet if someone wanted to water cool theirs.",
      "Don‚Äôt blame yourself, sonny boy. You missed out on the reference card F5 bonanza. But I got some great news for ya! We have partner cards with your name on them, starting at just $899 + tax! Now, I know it‚Äôs not the same deal we talked about before, but don‚Äôt worry. Your computer deserves this card and so do you. Who cares about a couple hundred bucks here and there. So just enter your CC info today and you can have your card in time for Easter!",
      "Also makes it a nightmare for watercooling blocks. Means manufacturers like EK have to either not produce a waterblock or produce many different designs for all the different AIBs.",
      "So mrsp is literally a lie. Is there even any msrp 6800XT, if not this card literally isn't even a 650 dollar at all.",
      "So we are then stuck with overpriced AIB cards? Screw this... I was happy for GPUs to finally go down in prices and would have gladly payed 650‚Ç¨, but the AIB price markups are insane...",
      "So, AMD finally makes a competent reference design and they decide to discontinue it less than 2 months after their paper launch?\n\nlmao this is hilarious, I honestly didn't think AMD would manage to mess up their launch any worse than Nvidia did with their, but holy shit this is amazing.\n\n\nSo, what's the official MSRP of these cards now?",
      "so only 20 of each were ever made before discontinued. what is this, streetwear?",
      "Damn straight there mr salesman, i just dropped 1.5k new zealand dollars for a rx 6800 xt red devil card, pleasure doin' business with ya",
      "Are you fucking kidding me??? There was never even a chance to get one!\n\n>end of life\n\n?!?!!!",
      "Nvidia is still making FE months after launch while AMD‚Äôs reference production was basically dropped after 1 week lmao",
      "Oh it's not need. Air coolers are very good these days. Watercooling is purely enthusiast. But it is still a big market.",
      "They're not overpriced, the reference models were underpriced so that AMD could put a graph up to make the pricing look more competitive than it is.\n\nIt's an absolute disgrace, and I can't help but feel they'll do the same thing with the 6600xt and 6500xt, which are the cards I was actually looking forward to.",
      "so mr scott herkelman literally lied about saying the ref design will still be manufacturate until early 2021. it's not like i prefer the ref design or performance over aib models but aren't they suppose to exist to at least available at msrp ? aib models pricing is even worse than nvidia situation rn",
      "AMD is seriously becoming anti-consumer. I had high hopes and support for them through their dark times and now that they're even competitive with intel & Nvidia I thought only good times were to roll. NOPE! It's chuck \"fucking\" testa.",
      "Another downside is they are the only reasonably priced models.",
      "And 15 of them were sent to reviewers",
      "I wonder why you actually need a full GPU water block (except hard overclocking with powermod).\n\nI use CPU AIO on 1080 TI with a bracket. Sure it doesn't cover VRM or VRAM, but it has a 90mm fan that blows directly against main VRM. The I/O side VRM is a concern though, but all reviewers shown it's colder than with high-end air coolers.",
      "MSRP is also being discontinued with them",
      "Prices were a lie then and all reviews need to be redone without the fake US$649 price.",
      "According to what AMD told Hardware unboxed. Can we really take their word for it though?"
    ]
  },
  {
    "brand": "amd",
    "generation": "6000",
    "tier": "high",
    "matched_keywords": [
      "6800"
    ],
    "title": "RX 6800 XT Midnight Black is a beast and a beauty",
    "selftext": "",
    "comments": [
      "Don't know if you know about this but you can actually change the colour of the Radeon logo on the 6800 XT and 6900 XT.",
      "Thanks for sharing this! Engineer on my team did a great job on it‚Ä¶ but it seems often overlooked.",
      "You just go to the AMD driver page, select GPU, select OS, then there should be a tool called \"AMD Radeon RX 6000 RGB Tool\".\n\nThe build looks great BTW. I also have a 6800XT Midnight coming in. Can't wait!",
      "I looked slightly into it but stopped, how do I do that?",
      "Thanks for letting me know! Enjoy your new card!",
      "That's a big ass cpu cooler. [Noice](https://youtu.be/UBX8MWYel3s)",
      "Beautiful rig dude! glad to see a special edition midnight black card getting into capable hands!",
      "Honestly, the midnight black version should have been the stock color of the card. I have a 6900xt and I love the card dont get me wrong but the 3xxx reference cards have a very classy look to them while these cards just dont.",
      "Yup, very much overlooked. Only found out because I noticed the logo diffuser is clear on the 6800 XT and 6900 XT. A quick google search and found out you could change the colour. Maybe should advertise it somewhere on the box?",
      "I doubt even AMD employees or executives know that for certain. Demand is unpredictable.",
      "An engineer who‚Äôs team mate worked on building the software (or firmware interface) for changing RGB lighting on a graphics card probably wouldn‚Äôt have any exposure to the logistics side of the company, sadly",
      "When I game or benchmark I see it around 65-69 range. I would say it cools just about the same as the 360mm rad but it is way more quiet in my experience. The Corsair H150i I had on balanced settings would make a ton of noise when i'm gaming",
      "Are those Lian Li chain fans? If yes, how do you feel about them?\n\nP. S. Looks really awesome BTW, the Radeon red logo really stands out with all the other white highlights.",
      "Yes they are. I recently just switched over from the Corsair QL120s. I like these a lot. Way more than the QLs. The whole ‚Äúunifan‚Äù design where you can chain them is game changing when it comes to cable managing. The back of my case looks more neat. They are easy to set up (6 wires in total for all the fans) and the diffused lightning look is great. The QLs I feel like has too many LEDs and can be too bright, along with having to cable manage 16+ wires and invest in the corsair ecosystem",
      "If the 6900 XT had this variant then it'll be slightly more desirable. I had a 3070 Founders Edition and it was hard to let go",
      "MSI's version to do the same is 200MB+.",
      "I had a 3080 before getting the 6900xt. The 3xxx series is just so well built and classy looking. These aren't bad by any stretch but man  the silver and red trim just is so meh",
      "That cooler looks like itll cool a car engine",
      "LOL I went from a 360mm rad to this, wanted to try something new. It's HUGE",
      "An engineer can do a great job on a features function, it takes a UX designer to make sure it‚Äôs presence is clear and appropriate."
    ]
  },
  {
    "brand": "amd",
    "generation": "6000",
    "tier": "high",
    "matched_keywords": [
      "rx6800"
    ],
    "title": "Upgraded: rx580 to rx6800. Holy mother. Eye watering fast.",
    "selftext": "",
    "comments": [
      "I changed from Vega 56 to 6800XT recently and yes, the difference for me (gaming @ 1440p) is massive.",
      "Congratulations. I did the same basically rx580 to 6900xt.",
      "It's one of those moments where you don't understand how you could have lived without it till now.",
      "Wait until I get from Intel HD graphics to 7900xtü§¶‚Äç‚ôÄÔ∏è",
      "It is true but don't get me wrong, the Vega has served me well for almost 5 years but I found myself reducing the graphical fidelity lower and lower to keep the FPS around my 60Hz monitor's range.\n\nWith some luck and the new GPUs prices coming down I've managed to get the Nitro+ SE on sale brand new for ¬£649 (twice as much as I paid for Vega all these years ago). \n\nThis coupled with new CPU (5800X3D) and new monitor (165Hz) I can enjoy my system for another few years easily playing 100+ FPS in most demanding games (or reducing it with AMD Chill to a comfortable range whilst using much less power).\n\nThe 6800XT is a brilliant GPU.",
      "You really should stop daisy-chaining pci-e power. Not only is it a fire hazard, it can lead to some crashing issues due to transient power spikes that gpus produce.",
      "Thanks, to you as well.",
      "Congrats for living into the 202X graphics age. I remember in 2019, I was buying \"mining rig\" used Rx580s for like $95 off of eBay and Mercari.  Low and behold, the card would become the pandemic favorite and the resell market prices were over $300.",
      "I still love my Sapphire RX 580. Been one of the best GPUs I have had in years. I need to repaste her, been about a year.",
      "Congratulations in advance :D",
      "just waiting for the new amd gpus to drop so i can upgrade from rx470 to 6650xt at an even cheaper price",
      "i went R9-290, to temporary RX480, to RX6800XT, and yeah, big jump for real. the only reason i even did the 480, was i got a deal on a good used card, and the driver support had ended on everything before the 400 series, and i couldn't play Forza Horizon 5 due to driver issues.",
      "Because they are not out yet. If you always follow the \"next\" release, you never buy",
      "Can't wait to ditch my GTX 1080 for a sweet new RDNA 3 card",
      "I am running a RX580 right now and want to upgrade to this as well. Thanks for the post!",
      "Crappy products exist because there are people who‚Äôd still buy them. The very existence of wish.com is a testament to that.",
      "Why do they make such cables then? Always bothers me",
      "He was mentioning transient spikes, that said the 6800 is less of a worry than say a 6800xt -6950xt if overclocked.\n\nI can cause system shutdowns on my 6800xt if I OC too much using MPT due to transients even though the power usage shown in something like hwinfo is what is expected.\n\nStock with a decent power supply you should be fine though",
      "Yeah, the performance is awesome, and also undervolting potential, at least if you're lucky. I went from a reference Vega 56 that I bought for 160‚Ç¨ right before the GPU craze, to selling it for 420‚Ç¨ during it and buying a new reference 6800 for 900‚Ç¨.\n\nThe difference in performance but also noise was incredible. Then I managed to sell my 1.5yrs old reference 6800 for 515‚Ç¨ and bought a 3 months old MSI Gaming X Trios for 420‚Ç¨.\n\nI run this thing at 2300-2400MHz with an insane 880mV, it's so quiet, even compared to the reference model, which I actually liked more design-wise. Really happy about the decision, though. These GPU's are crazy price to performance wise, especially in my market, where Nvidia is still overpriced. Wouldn't want to support them anyway, though.",
      "Same went from Sapphire Pulse RX 580 to Sapphire Nitro+ RX 6800 and It's unreal. Can't wait to uv/oc this."
    ]
  },
  {
    "brand": "amd",
    "generation": "6000",
    "tier": "high",
    "matched_keywords": [
      "6800"
    ],
    "title": "Stealthy mATX build w/ RX 6800",
    "selftext": "",
    "comments": [
      "OMG look how close it is to the GPU lol",
      "yeah it's a really tight fit lol, the backplate is so thick on the 6800 too, idk how I'll remove it if I ever have to",
      "[PCPartPicker List](https://pcpartpicker.com/b/jMx6Mp)\n\nManaged to snag a RX 6800 off amd.com at MSRP! this is basically my end-game build for the next few years :)",
      "Ive done that with my build too, but one day my screwdriver is going to slip off the clip and nick the Mobo and I am going to cry hysterically hahahaha",
      "Man that's a HUGE cooler for a 3600.",
      "personally i bought a solid cooler back when i had a 1600 because i knew that i‚Äôd upgrade soon and it‚Äôd last me years. now i have a 10900k and the arctic freezer 34 holds up excellently. \n\nabsolutely no shame in the big cooler on a 3600",
      "I bought this board back in 2018",
      "Ryzen 5 3600 clocked at 4.25GHz",
      "Why a B350? Unless I am mistaken, there are B450 matx boards around 70 to 80 dollars. I'm just curious.",
      "It will be fine.",
      "There is a big difference between clean and FUCKING CLEAN",
      "What CPU are you using?",
      "Honestly saying PCIe 4.0 doesn't make any noticeable difference. It is more of an improvement to a NVMe SSD (A PCIe 4.0 one obviously).",
      "I still remember the old AMD socket retention clips (CPUs) for the cheap heat sinks. You had to get a screw driver in them and push down to get the retention clip on the socket. One false slip and a screw driver comes down full force onto the motherboard.\n\nDid I mention the CPU beneath the heat sinks also had exposed tiles at the time? So all the while you had to make sure the pressure wasn‚Äôt too unequally distributed.\n\nI‚Äôm so glad things have moved on from those days.",
      "I did that once, and the motherboard died. Fortunately, the retailer was kind enough to give me a replacement.",
      "Oh OK makes sense. Nice build!",
      "yep! it's virtually inaudible though. at 1000 RPM, I never go over 65c, even in prime95",
      "I agree the arctic freezer is a beast of a cooler at it's price point. I bought it originally to replace the H80i V2 (my ryzen 5 1600 4.0  was thermal throttling). Hilarious that a cooler about half the price of H80 did a far better job cooling my OC cpu. \n\nI recently upgraded to a 10700k and it's doing a superb job cooling my cpu at stock settings, hell the fan barely ramps up playing games.",
      "I so hated those clips",
      "It's a really good cooler if you plan on going zen 3 later."
    ]
  },
  {
    "brand": "amd",
    "generation": "6000",
    "tier": "high",
    "matched_keywords": [
      "6800"
    ],
    "title": "Completed my Build! 6800 XT",
    "selftext": "",
    "comments": [
      "Big Ass tower coolers have a style of their own. They're like like the big muscular bodyguards next to a VIP. Silent, but imposing.",
      "Dope!! I got my 6800.... little jealous you got that extra slot... but that Radeon in red is beautiful to look at. Enjoy!",
      "He's forcefeeding air which might be necessary due to the amount of space underneath",
      "I see a bottome intake fan just for the gpu, i upvote",
      "What's the reasoning behind the Extra fan crammed under the GPU?",
      "^^Be  ^^Quiet",
      "Love that",
      "More like the engine block on a powerful V8 engine.",
      "Learned it from the years with my Node 202 case. It was very tough getting this fan in (spot wasn‚Äôt intended for fans), but it made a huge difference",
      "Thank you!",
      "DAMN SON WHERED YA FIND THIS",
      "Yeah I can see that. But, would it be of any use since the air is just going to be recirculated i.e. no source to fresh air? I'm actually asking because if this actually works I'm tempted to try this",
      "Launch day, snail monitor discord, Newegg, Apple Pay",
      "dark rock pro 4 is awesome. almost silent with my 3700x. cant hear it i open my window even a little bit in a big city on a zero traffic street",
      "If he has another fan in the bottom front or below the psu shroud, it should definitely work, since air pressure below the GPU/shroud will be higher than ontop of it. This would force the air to go directly towards the GPU",
      "Can the Radeon logo be turned off?",
      "Cooler Master V8.  \nOr the actual V shaped Scythe kama cross. \nAnd honorable mention; scythe ninja that looks like the cylinder on a 1 cylinder air-cooled motorcycle.",
      "You can fit so much more RGB on an aio though right?",
      "One question \n\n**how**",
      "Mostly an anesthetic reasons I would say. \n\nThere is also clearance (tower cooler are big AF).\n\nAlso some misinformation. People think watercooling is better. Custom loop is better than any AIO/Air Cooler but AIO aren't really better than Air Cooler."
    ]
  },
  {
    "brand": "amd",
    "generation": "6000",
    "tier": "high",
    "matched_keywords": [
      "6800"
    ],
    "title": "Radeon RX 6800 vs. GeForce RTX 3070, 40 Game Benchmark: 1080p, 1440p & 4K",
    "selftext": "",
    "comments": [
      "TL;DW- The RX 6800 is 11% faster in 1440p and 10% in 4K\n\nThe reason why those numbers are quite low from what some of us are expecting is because the Radeon card have issues in some of the games such as Warhammer Vermintide 2 and Kingdom Come: Deliverance and is neck to neck in some others such as Hitman 2 and Star Wars Jedi Fallen Order.\n\nPersonally this card should've been the same price as the 3070 if AMD is serious about undercutting Nvidia but it seems just like with Zen 3 they're being overconfident about their products which might or might not be the top dogs in the long run with ~~Comet~~ Rocket Lake coming soon and new titles will be able to leverage Nvidia's software and feature more 2021 and beyond. I'm hoping for price cuts across all their product ranges to remain competitive.",
      "Agreed. 6800 for $500 and the XT for ~$600 after the shortages would be extremely competitive against NVidia",
      "The $650 pricetag is fine for the XT version but you don't ever see them at those prices. Even in my country the 6800 XT has the exact same price as the 3080 which isn't supposed to be.",
      "The main issue here is the 6800 is closer to price to the 6800xt than it is to the 3070.",
      "# Timestamps:\n\n* [01:16](https://www.youtube.com/watch?v=5mXQ1NxEQ1E&t=76s) - Test setup \n* [02:41](https://www.youtube.com/watch?v=5mXQ1NxEQ1E&t=161s) - Battlefield V \n* [04:02](https://www.youtube.com/watch?v=5mXQ1NxEQ1E&t=242s) - Hitman 2 \n* [04:36](https://www.youtube.com/watch?v=5mXQ1NxEQ1E&t=276s) - Borderlands 3 \n* [05:01](https://www.youtube.com/watch?v=5mXQ1NxEQ1E&t=301s) - Fortnite \n* [05:28](https://www.youtube.com/watch?v=5mXQ1NxEQ1E&t=328s) - Apex Legends \n* [05:51](https://www.youtube.com/watch?v=5mXQ1NxEQ1E&t=351s) - PlayerUnknown‚Äôs Battlegrounds \n* [06:12](https://www.youtube.com/watch?v=5mXQ1NxEQ1E&t=372s) - Cyberpunk 2077 \n* [06:38](https://www.youtube.com/watch?v=5mXQ1NxEQ1E&t=398s) - Call of Duty Modern Warfare \n* [07:06](https://www.youtube.com/watch?v=5mXQ1NxEQ1E&t=426s) - The Witcher 3 \n* [07:35](https://www.youtube.com/watch?v=5mXQ1NxEQ1E&t=455s) - Control \n* [07:58](https://www.youtube.com/watch?v=5mXQ1NxEQ1E&t=478s) - Red Dead Redemption 2 \n* [08:30](https://www.youtube.com/watch?v=5mXQ1NxEQ1E&t=510s) - The Outer Worlds \n* [08:50](https://www.youtube.com/watch?v=5mXQ1NxEQ1E&t=530s) - Warhammer Vermintide 2 \n* [09:49](https://www.youtube.com/watch?v=5mXQ1NxEQ1E&t=589s) - World of Tanks \n* [10:07](https://www.youtube.com/watch?v=5mXQ1NxEQ1E&t=607s) - Kingdom Come Deliverance \n* [10:56](https://www.youtube.com/watch?v=5mXQ1NxEQ1E&t=656s) - 1440p \n* [11:42](https://www.youtube.com/watch?v=5mXQ1NxEQ1E&t=702s) - 4K \n* [12:06](https://www.youtube.com/watch?v=5mXQ1NxEQ1E&t=726s) - Final Thoughts",
      "Note, it's only 14% faster if you take those games out.\n\nI agree with you that AMD are being excessively greedy with pricing for the Radeon GPUs here. I can understand it with Ryzen, they've established themselves in that market, they are providing industry leading performance, they should charge a premium.\n\nBut with Radeon? Charging a 15-20% premium over the competition, with a worse software stack and worse features all around, for a 10-14% performance uplift is unacceptable. They need to aggressively take the market from Nvidia the same way they did from Intel with Ryzen back in 2018. RDNA2 is in many ways comparable to Zen+ and Zen+ was, and even still is, insanely good value for the performance you get out of it.",
      "I really really wish u/HardwareUnboxed would be more careful when arguing against the 8GB VRAM of the RTX 3070. They said:\n\n>and we've already got a number of examples where the RTX 3070 is hamstrung by its 8GB VRAM buffer: Doom Eternal using the ultra nightmare preset is one example, Cyberpunk 2077 with ray tracing enabled is another and there would be more to come surely (shortly?)\n\nWhy is the RT performance in Cyberpunk 2077 mentioned here? With RT enabled the RX 6800 would be almost unplayable. So how come this is mentioned as a shortcoming of the RTX 3070 versus the RX 6800?",
      "For me (UK here), I got the rx 6800 for ¬£10 less than an AIB 3070 I also had, so the 6800 was a complete win for me, region pricing for these seems to vary wildly",
      "tbh, anyone who doesnt need the high end cards for some specific reason, will be very happy with either of those cards for msrp. \nComparing with msrp you get 10% more performance for 10% higher costs. So you should choose between the amd brand or far superior rtx performance. (And special cases of cuda and so on)",
      "Performance doesn‚Äôt matter if neither exists anywhere",
      "Exactly, in Portugal there is only one model for 6800 and 6800XT that is listed at the msrp\nAll the other models are 70+‚Ç¨... It's actually kinda annoying\nCause i wanted a 6800/6800XT but the ones available are all way over msrp",
      "It's common knowledge that the 6800 beats the 3070 but if only you could buy a 6800 for MSRP that would be a great buy.\n\nEven 100 euro more than MSRP i'd be fine with, but what i'm seeing is at least a 250-300 euro extra if I want to own a 6800.\n\nI went for a 3070 that was 100 euro over MSRP.",
      "It's 16% though",
      "Yeah... where i live both 6800XT and 3080 go for 1200‚Ç¨+.  \n6800 non XT for 1000‚Ç¨+  \n\n\nAt least i got the 5900x at msrp.",
      "You mean Rocket Lake? I won't hold my breath on a back-port from Ice Lake to 14nm. Even Ice Lake notebooks weren't that much of a competitive challenge for AMD.",
      "Yes because they're testing on stock basis. DLSS, SAM and overclocking results aren't tested",
      "No? For $50 more you get equivalent rasterization, way better raytracing, and better features in the 3080. $600 would be a very compelling pricepoint and if the 6800XT were $600 I probably would have gotten it. Instead, I felt like the 3070 was the better pick for me (especially because I was able to find one).",
      "Where I am, the 6800 is $150usd more expensive than the 3070 cards and it's only $30usd away from the RTX3080.\n\nSo I don't know, maybe the 6800 vs 3070 makese sense in HUB land but where I am the 6800's competitor is actually the RTX3080. 3070 vs 6800 doesn't make sense for me personally because the 6800 is 10% faster but 30% more expensive",
      "Neither card is future proof and the VRAM won't change that.",
      "But keep in mind that top 5 (with 30% lead) games are just as misrepresentative and are also the exeption and not the rule. Im mean in ac vallhala the 5700xt matches the 2080ti ... Like wtf"
    ]
  },
  {
    "brand": "amd",
    "generation": "6000",
    "tier": "high",
    "matched_keywords": [
      "6800xt"
    ],
    "title": "My all blinged-out AMD rig. (5600x, 6800XT, Turtle)",
    "selftext": "",
    "comments": [
      "Damn golden rig",
      "What are the clock speeds of the turtle?",
      "You might be shell-shocked, but it's a fat zero for all of them. Too bad everything else is bottlenecking turtle's performance.",
      "Black and gold never dissapoints, looks dope!",
      "Dog?",
      "[I love goooooold](https://youtu.be/HnzH15hwt48)",
      "This is nice. I like lighting when it‚Äôs a single colour in the system.",
      "It's Adam Jensen's personal rig.",
      "Just reseat the turtle and Afterburner'd the heck of it",
      "Yeah that's what I went for from the beginning. Thank you!",
      "Ahhh, Dog",
      "Your faja must be proud",
      "I really like this. Well done.",
      "Really clean and aesthetically pleasing build, nice work!",
      "Thank you. :) This is the RGB strip I used twice:\nhttps://www.amazon.com/GIM-Compatible-Magnetic-Addressable-Gigabyte/dp/B0899P2SBD (GIM KB-14 RGB PC Light Strip)",
      "Praise the dog!",
      "It's kind of sad that gold is falling out of favor for rose gold in tech products.",
      "Thanks! One of my main goals obviously.",
      "Thanks! For Corsair iCUE? To be honest, I'm just using a profile I found here:\nhttps://lewisgerschwitz.com/corsair.html\nIt's the Pumpkin profile from the Halloween collection. Maybe go from there and make adjustments if needed.\n\nFor Gigabyte RGB Fusion, I'm using the standard yellow color on all devices. (GPU, Mainboard, Strips)\n\nThe image makes my rig probably look more golden than it actually is. Have been struggling with this as well, but it's still my favorite RGB setup!",
      ":D Maybe a step up in terms of GPU, CPU or Mainboard, but I can't complain. The \"bang for buck\" above 6800XT or 5600x doesn't improve at all, and I'll be able to do all I need and want to for years to come."
    ]
  },
  {
    "brand": "amd",
    "generation": "6000",
    "tier": "high",
    "matched_keywords": [
      "6800xt"
    ],
    "title": "Replaced a 10 year old pc recently! 5800x3d 6800XT",
    "selftext": "",
    "comments": [
      "I adore XFX's GPU shrouds",
      "Replaced a 10 year old pc recently! 5800x3d 6800XT\n\nhttps://i.imgur.com/FZm5rJs.jpg\n\nParts list here! https://pcpartpicker.com/b/4jNPxr\n\nReplaced this guy: https://pcpartpicker.com/list/YC9423\n\nWent the lazy way with undervolting the cpu and just gave it -10 per core. May creep it up. I am currently getting about 63c average in game. 62c average on the 6800xt. Only minimally tweaked the fan curve using msi afterburner. Not a pc person but am now becoming one!\n\nPosted this earlier this week but got taken down for breaking the weekend rules!",
      "don't mind these lame commenters, that is a very sweet build and you will be able to run everything up to 4k if you really want to.",
      "Sick setup bro. It will carry you for many more years to come.\n\n\nI just snatched myself a 6700 a month ago. Best ever GPU I've ever had !",
      "it's recommended that you run two seperate pcie cables from your powersupply to your graphics card rather than using one cable and its daisy chain. Each cable is rated for 150w and your graphics card can pull 300w. Nice all black build though",
      "They probably like having more than 10% profit margin.",
      "And here I am thinking of switching my 6800xt for a 7900xtx haha fucking consumerism",
      "No dumb RGB, simple, clean - this thing's superb",
      "I believe its generally recommended because you don't 100% for sure know what's on the other end in the psu. Some are meant to put out that much power and support their daisy chains in that manner, while your mileage may vary with others.\n\nThe cables themselves should be able to handle it if designed to spec. I have a Corsair SF 750 and it was confirmed by Corsair that it was intended to be used as such. There are various places that test out the limit of spikes as well. The SF 750 delivers around 950 watts of oversurge before shutting down. Its probably best to confirm with your manufacturer though.\n\nI've been using a 6900xt daisy-chained for awhile with no issues, though it is just the reference model with no overclock.\n\nHere's a link that helped me better understand the EE side of it.\n\n[https://linustechtips.com/topic/1431258-how-much-power-an-8-pin-to-2x-62-pin-connector-can-output/](https://linustechtips.com/topic/1431258-how-much-power-an-8-pin-to-2x-62-pin-connector-can-output/)",
      "Looks really clean. I upgrade recently from a 4790k and a 1070  to a 5800x and 6800. Enjoy.",
      "I ran a 8320 + 970 combo for a while too. Upgraded to a 3600 cpu a couple years ago but I‚Äôm still rocking that 970",
      "Yea they look so damn gooood, wish they did nvidia too.",
      "No matter what there‚Äôs always something out there better than what you already have. And someone will always wish that they had what you have. Stay Humble gamers.",
      "I have a feeling you don't understand computers very well.",
      "What in the hell is wrong with you?",
      "I just upgraded a 770 to a 3080 and I'll be upgrading my 4790k to a 7950X3D soon, can't wait!",
      "Absolutely.  Newest games even can hit at least 60 fps easily with that card.  I have the 5900x.  Was a free upgrade from my 5800x that a coworker bent the pins on.",
      "Sorry to hear that",
      "Tell me you are spoiled asf without telling me",
      "There is more to that recommendation than is perceived by most.\nIf they are smaller than 14 gauge cables then it is recommended to run individual cables. It actually has nothing to do with the amount of power running through the cables but the resistance of the wire itself. Wire degrades throughput by resistance to amperage requiring more voltage to move the amperage. This is why quality power supplies output 12.3v-12.5v on the 12v power wires. 14 gauge can handle about 28 amps before going below the 3% voltage drop required for critical or sensitive components.\n\nExample at under 2 feet for 14 gauge wire \n12v*25 amps is 300w total\nVoltage drop of 0.31 or 2.59%\nSo only 11.69V*25 amps or 292watts is actually making it to the end of the wire (graphics card). Shorter distance or bigger wire is the only way to lessen the problem.\n\n12v*28 amps is 336w total\nVoltage drop is .35v or 2.9%\nSo 11.65v*28 amps or 326w is actually making it to the end of the wire (graphics card).\n\nTo fully understand the issue look at a marine wire chart for amperage by gauge for critical components and a voltage drop calculator.\n\nhttps://www.bluesea.com/resources/1437\n\nhttps://www.inchcalculator.com/voltage-drop-calculator/"
    ]
  },
  {
    "brand": "amd",
    "generation": "6000",
    "tier": "high",
    "matched_keywords": [
      "6800"
    ],
    "title": "AMD Radeon RX 6800 drops to $469, while RTX 4070 is still in stock - VideoCardz.com",
    "selftext": "",
    "comments": [
      "$399 sounds right for both cards.",
      "Kinda wanna sell my card and get a used RX 6800 / 6800XT to be honest. The only Nvidia exclusive feature I use is DLSS, which will be missed, but i'm sick of having the worry about VRAM since I play at 1440p.",
      "The prices are in free fall. I predict the prices will fall further. Mindfactory still has lot of 4070 in stock at MSRP or close. That's extraordinary for a new GPU launch. \n\nWe are in recession lads. The new status quo has arrived.",
      "Dips where? Still $600-650 in Europe :(",
      "in europe still > 600$/‚Ç¨",
      "Same. My next card will be AMD. Killing Gamestream was the final move to push me over.",
      "4070Ti should have been 4060Ti at 399.\n\n4070 should have been 4060 at $350\n\nthe true 4070 should be the current 4080, at 499\n\n4080 Super 20gb at 599\n\n4080 Ti 20gb at 799 \n\n4090 at 999\n\n4090Ti/Titan at 1599",
      ">4070Ti should have been 4060Ti at 399\n\nBy that logic, the 7900 XT should be $399 as well, since AMD has clearly pegged its value to that of the 4070 Ti.\n\n1. The \"4080 12GB\" was originally MSRP $899 before being \"unlaunched\"\n2. The 7900 XT gets announced and later released for $899 despite that price making no sense next to the $999 7900 XTX.\n3. A month later the rebranded 4070 Ti releases for $799\n4. AMD (eventually) drops the 7900 XT to $799",
      "Prices are not in free fall. That would be lovely, but it‚Äôs not the case. The new cards have been holding steady at msrp, with the occasional modest sale. \n\nSome good deals to be had on last gen AMD cards for sure, but free fall is a bit hyperbolic.",
      "They named their 7800 the 7900XT to try and overcharge for it so, yeah.",
      "Soon the price difference will be so big I‚Äôll just fly out and come home with a few GPUs.",
      "I‚Äôd bite at 297 instantly, even though I don‚Äôt feel the need to upgrade my tried and true 5700xt",
      "Oh, my bad. That one card can be had for like $80 under msrp now. \n\nTOTAL FREE FALL. \n\nGrab one at the bottom of a dumpster near you, spring ‚Äò24.",
      "If the best AMD can do with their high end hardware is compete with cards that should be the xx60 ti and xx70, then they would also have to price them accordingly. Lucky for AMD that Nvidia decided to make a giant price increase.\n\nI'm not saying they're in on it together, but it does seem awfully convenient for both parties.",
      "The reference RX6800 has a msrp of 579. I know that an aftermarket version is slightly more expensive, but still it's been 2.5 years now for a mediocre +/- 110 drop. I don't consider this as a free fall. I was expecting between 350-400 by now.",
      "Funnily enough, the GTX 770 10 years ago was a rebranded GTX 680, which was likewise accused of being put too high in the product stack.",
      "> I'm not saying they're in on it together, but it does seem awfully convenient for both parties\n\nThose must be the \"corrective forces of the free market\" that I've heard so much about.",
      "Would it be weird to wait for the 7800xt just so I can have a 7800x3d/7800xt build?",
      "GameStream sucked anyway. I bought a 20 ft active HDMI cable and will never look back.",
      "I bought it a week ago for like 100 more ü•≤"
    ]
  },
  {
    "brand": "amd",
    "generation": "6000",
    "tier": "high",
    "matched_keywords": [
      "6800xt"
    ],
    "title": "Bought this factory refurbished 6800XT for $405",
    "selftext": "",
    "comments": [
      "where? also congrats",
      "Congrats. I got a 6900xt for $570 and here I thought I got the best deal haha",
      "From lttstore.com?",
      "Local distributor. Me and my friend bought one each.",
      "I had that option for $600 but chose the 6800XT since gaming will be limited to 1080p/1440p plus the $200 savings.",
      "Lol ...",
      "Bro i got a 6600xt for 435e a week ago, damn you americans",
      "What‚Äôs the currency so I can convert it to cheeseburgers per block",
      "Sick, have fun with it",
      "Did it came with LTT Water Bottle?",
      "Definitely a better choice, Extra $200 isn't worth it for 6900xt. What was the problem with the card tho?",
      "No clue. The local distributor was just selling a bunch of them. Said it was sent back to the factory and repaired. Came in a sealed box. Looks brand new. They gave me 3 months warranty but honestly GPUs don't die easily (if you use the right PSU/cables) so if it passes the 3 months mark without a hiccup then I'm not stressed about it long term. Plus I doubt I'll lose much value if I plan to sell it next year outside the warranty period.",
      "Thats what I say all the time for fuck sake, thats what I envy about americans, fucking garage sales, godwill stuff and shit like that. Freaking 10$ gpus that work",
      "Can you let me know about the local distributer?",
      "These [guys](https://www.pcgarage.me)",
      "Noted üôÇ",
      "Yeah,  linus sex tips",
      "580-> 5700 -> 6800xt, never had a driver issue.",
      "Check your drivers, OS, and the rest of your system before blaming AMD. Same goes for NVIDIA.",
      "I had driver issues with the 5700 XT that was resolved soon after launch. Never had any issues with my new 6700 XT other than it failing (but that was probably ASUS's fault, got it RMAed).\n\nI had numerous driver issues with my 3060 Ti and with a 3070. I don't swear off NVIDIA cards though."
    ]
  },
  {
    "brand": "amd",
    "generation": "6000",
    "tier": "high",
    "matched_keywords": [
      "6800"
    ],
    "title": "6800 XT Midnight Black is awesome! First AMD build. waited years for this!",
    "selftext": "",
    "comments": [
      "very nice setup! i always wanted that hsf...",
      "Seeing that cooler instantly made me angry. I broke 2 MBs because of this stupid thing.",
      "Thanks man! I got lucky and got it at MSRP from AMD's official website.",
      "Sorry to hear that bro. What happened? I love this cooler",
      "Sick Build bro, and congrats on getting a GPU",
      "Wait, is the Midnight Black Triple 8 Pin? Or is it Dual 8 Pin, but your RGB is just sticking out?",
      "It's double but i used a triple 8 pin strimer and removed one part of it and moved the 2 remaining cables to the centre.",
      "Thanks a lot bro! had to spend many weeks trying my luck on the AMD drops. But it was worth it in the end. cant complain when I have this beast for 650 Euros",
      "I like the simplicity in color choice, but it also looks bad ass!!!",
      "Taking off the fans were far harder than they have any right to be, making me get rougher with handling the while system than normal, breaking them.\n\n  \n\n\nGoing with the Scythe Ninja 5. You don't have to take off the middle fan to access the screws to take them off, and the clips that hold onto the heatsink actually have little parts sticking out that makes it far easier to remove the fans should you need to. The DRP4 doesn't have the clips stick out which means I need a flathead or knife to take it off.",
      "sorry but i have to disagree with you on that. I actually went with an air cooler so that i don't have to tinker with it anymore and it has almost no point of failure in the future beside the fans and they can be replaced easily. big ones like this and the Noctua competitor run extremely quiet. i sent mine to max 60% fan speed and I get amazing temps.",
      "https://gathering.tweakers.net/forum/list_messages/2027306/0\n\nThat's a link to a Dutch page that has a lot of advice on the Thursday drops. You can translate the page with Google.\n\nAlso join a discord alert server.\n\nMy tips are:\n\nLogin to PayPal on a separate tab and set auto refresh add on so that you won't get logged out.\n\nUse the script that you should find on that page. It basically makes the add to cart button appear. Without the script there is almost no chance. Drops are usually at 5:33 central European time. I started using the script every minute starting at 5:30.  However AMD fuck with us every once in a while and drop earlier around 4 or later around 6.  But most of the time it's at 5:33",
      "Noice!  About to put the exact same card in my system but it will not be quite so pretty.  Also on big air with a Cryorig R1 Ultimate with 3x 140mm fans.",
      "Nice! Enjoy the card man! It's a beast. Running everything 1440p at ultra",
      "What was your process for getting one on their site? I‚Äôve been trying for a bit now to no avail",
      "Glad you like it! It's very calming and not too much at all in my opinion.",
      "ah yes true, it was tricky taking off the middle fan especially with smaller cases. I hate to use the included screwdriver to reach far enough. no way I could have reached with my hands. and my hands are actually small.",
      "While I agree that it's a bit tricky to get the middle fan out, i still love the cooler. I changed CPUs on my brother's build with the same cooler and it was no problem using the screw driver. It can be made easier but i don't mind spending an extra 15 minutes if i can have a nice looking quiet cooler.",
      "Absolutely beautiful",
      "Thanks bro! I love Lian Li and AMD!"
    ]
  },
  {
    "brand": "amd",
    "generation": "6000",
    "tier": "high",
    "matched_keywords": [
      "6800xt"
    ],
    "title": "Upgrade day! Vega 64 to 6800xt",
    "selftext": "",
    "comments": [
      "congrats that's gonna be a huge boost",
      "Yeah it is! The Vega served me well until I switched to a super-ultrawide monitor (3480x1200, so roughly 2.5k). Now this thing is crushing it.",
      "> Strangest part of the upgrade is that it made my RAM oc unstable. Still working through how that could happen since I didn't touch settings for it.\n\nYou lifted your GPU bottleneck, so now your CPU is more likely to present one. CPU and RAM are more dependent on each other.",
      "Out with the venerable MSI Vega 64 air boost, in with the Sapphire Pulse 6800xt. Going through settings and benchmarks now. Surprised how big a jump SAM made. \n\nStrangest part of the upgrade is that it made my RAM oc unstable. Still working through how that could happen since I didn't touch settings for it.",
      "Exactly what happened to me, running Radeon VII then upgraded to 3480x1200 and watched my GPU cry. Luckily for me, the funds from selling the VII more than paid for my MSRP 6900xt replacement.",
      "Still on Vega 64 üí™",
      "Lttstore.com",
      "The VII is also god tier at mining. That and it being rare is why it maintains value. BIG HBM2 quad stack energy",
      "yup still holding a good value and kinda rare too",
      "I can hear that blower styled Vega 64 even though it‚Äôs unplugged.",
      "I had a PCIe 4 ssd already (wd black), and it didn't cause issues. Guessing EMI from the new gpu is most likely.",
      "Pcie 3 vs 4?  EMI from the new gpu?",
      "Same.\n\nNot even considering it until RDNA3.",
      "Had a Steel Series one about the same size before this and it was great, I just didn't like the solid black cause it showed dirt. This is the first printed one I've had that didn't fade in a month.\n\nMock em if you want, but it's a good desk matt",
      "That must feel amazing",
      "Well enjoy the new toy.  I do love my powercolor red devil 6800 xt for messing around tweaking and overclocking.",
      "Good thing I sold my vega 64 a couple of months ago for slightly below its retail price. But what to upgrade next. The RX580 does her job kinda ok running ffixv on 3440x1440.",
      "Not considering anything until graphic cards will be in a normal price.",
      "Are the Vega cards holding price as well as the VII? I went from a 56 flashed to 64 to a 6800xt that I got lucky with in the amd queue a couple weeks ago. \n\nI have the components to make a server/spare/2nd pc out of the left overs, but would it make more sense to sell the vega56 now, sit on the 2nd computer idea and get a cheap MSRP card in 6 months?",
      "Red Dragon K556"
    ]
  },
  {
    "brand": "amd",
    "generation": "6000",
    "tier": "high",
    "matched_keywords": [
      "6800xt"
    ],
    "title": "Wait, 57fps with SFR at 4k with 6800XT ?",
    "selftext": "",
    "comments": [
      "I wouldn't be worried, pc port is apparently true 4k while ps4/ps5 version where upscaled using checkboarded\n\npc is also getting unlocked fps and other graphical improvements. you're basically getting the version of gow that devs wanted everyone to enjoy.",
      "Wait until you see the 1% lows",
      "To be fair that's still 1662p + the small frame rate hit FSR costs. I'd imagine this would mean like 70fps if you played at native 1440p with no FSR. Still not great, but who knows what kind of useless things they incorporated into \"Ultra\" settings.",
      "exactly, people overestimate average framerate while ignoring 1% lows. 57fps average, so 1% lows are in 40ies range and that's with FSR? Unless there's something super taxing at ultra - that's pretty shitty result",
      "Yep, never play ultra, always go high and some stuff medium to gain FPS with no quality loss",
      "Finally a game with proper Ultra settings. It has been years since we last had one with Ultra Settings intended for future hardware.\n\nUltra presets are dumb for gaming, use high.",
      "Cyberpunk awkwardly sitting in the corner intended for the RTX 10090",
      "You‚Äôre not wrong. The [visual] difference between ultra and high is usually pretty minimal in most games.",
      "What is this peasantry? If I can't play at ultra, I uninstall the game.",
      "Played it on ps4 and will play on pc. O.O you not special",
      "Interesting: God of War was tested on the old driver 21.5.2 with Windows 10 October 2020 version. I hope that in the release version with new drivers, performance will be much higher, otherwise you can already panic about optimizing the game.",
      "in few weeks yes lol",
      "Not to mention ultra presets typically crank AA to the max, which generally isn't necessary at 4k.",
      "Obligatory \"we are not the same\" meme here",
      "gow is on pc now?",
      "I leave the room.",
      "Isn‚Äôt cyberpunk more cpu heavy as well so if you don‚Äôt have a really beefy cpu to match to let‚Äôs say a 3090 your kinda f‚Äôed",
      "> while ps4/ps5 version where upscaled using checkboarded\n\nPS4 is also like 8x weaker lol",
      "Ultra 144fps or I leave the room.",
      "Either the game is extremely badly optimized or they are using ultra settings that have a high performance cost."
    ]
  },
  {
    "brand": "amd",
    "generation": "6000",
    "tier": "high",
    "matched_keywords": [
      "6800xt"
    ],
    "title": "Kopite: \"Mining performance of the 6800XT is a bit higher than the 5700XT, but much lower than RTX 3080.\"",
    "selftext": "",
    "comments": [
      "Terrible, now don't buy them, the 3080 is better please buy it.",
      "Wow. No one should buy these. Terrible",
      "Clearly a mark of weak and faulty gpu, AMD should be ashamed of themselves. Everybody should really avoid buying this generation gpu and should just stick to earlier generation.",
      "Yeah, totally not worth it. Everyone line up and wait for the RTX3000s, they are so much better and I'd recommend them to anyone who wants to buy a graphics card right now !",
      "Unfortunately for us N21 stock will probably seem super low precisely *because* nobody can buy 3080s and want something just as fast.",
      "N21 is terrible, don't look at it at launch (wait 3 months), go seek the 3080. Great value!",
      "Pile of garbage. Can't wait to not have one of these in my PC.",
      "Good.  Please keep it that way.  Don't want to have to deal with scalpers and their distant relatives too.",
      "First time AMD fans are glad Nvidia is faster xD",
      "Petition to open micro center in every major city",
      "I recommended my grandfather a 3080. Great value! Definitely better than the Rx 6000 series.",
      "Why get garbage when you can get great value! Get the 30 series ;)",
      "I walked into a microcenter on Zen 3 launch day at 2pm and bought a 3080 EVGa FTW for an employee with his credit card. They had manyy in stock. It was quite odd.",
      "THE MORE YOU BUY THE MORE YOU SAVE",
      "And in the rest of the world",
      "I assume everyone is just fucking around and cause there's no stock they want to joke and tell people to buy Nvidia cards so there's less competition for the new rdna2 cards.",
      "\"The Toyota Urban Cruiser...\"",
      "Radeon VII is still best mining card from AMD. Undervolted and memory OC and its even better.",
      "Go for the 3090, its even better.",
      "Or Nvidia"
    ]
  },
  {
    "brand": "amd",
    "generation": "6000",
    "tier": "high",
    "matched_keywords": [
      "6800"
    ],
    "title": "My Entry to team Red 5800X3D + 6800 XT",
    "selftext": "",
    "comments": [
      "Impressive cable management.",
      "System components 9/10\n\nStyle and Ergonomics 0/10",
      "Nice specs it's gonna run great but that is a horribly messy build.",
      "Sarcasm taken thanks for the chuckle though xd",
      "Built my son a 5800x/6800xt rig for Christmas and it's a ripper. Congrats on the new system!",
      "\"It just works!\"",
      "Ergonomics? Are you regularly using your cases as footstools?",
      "Dont listen to these guys, if it works, it works!",
      "That is completely pointless, if the case still does it job (holding shit in place), no need to change it except for aesthetic purposes.",
      "Cable managemen‚Äôt",
      "I've seen worse. We've all seen worse, he may be going by the term life's too short for cable management.",
      "As god intended",
      "There is no PSU shroud so the cables are out in the open and you run the CPU fan cables out of the top of the cooler instead of hiding them underneath by flipping the fans. A bit more cable management and it would look pretty nice",
      "You are an awesome dad!",
      "Those are load bearing cables holding the cooler in place",
      "Why should he if the old one works fine?\n\n You should upgrade because of a need, not because something is simply old yet still good.",
      "Case is 7 years old never had a shroud",
      "I mean its still a great case being a bequiet silentbase 600",
      "Correct",
      "Cosmetic shit doesn‚Äôt affect performance. \n\nDoesn‚Äôt matter how it looks with the side on the case and tucked under a desk anyway."
    ]
  },
  {
    "brand": "amd",
    "generation": "6000",
    "tier": "high",
    "matched_keywords": [
      "6800"
    ],
    "title": "Is it just me or the Radeon 6800 XT is a combination of the front and back end of the 197O Dodge Charger?",
    "selftext": "",
    "comments": [
      "Is it just me, or did the original poster put an \"O\" rather than a zero in \"1970\"?",
      "I'm glad your mind is at peace now.",
      "AMD: Dodge Charger   \nNvidia: Doge Neon   \n   \n^(This post brought to you by the /r/AyyMD/ gang.)",
      "yes",
      "Oh man i was in the same boat. Thank you",
      "Given how HD5870 was inspired by Batmobile, I don't think it's absurd to think their latest GPU design was also inspired by a car.",
      "With the way the market is right now, ive seen them go for in my area up to 2000",
      "RX 68O0 XT",
      "Glad I'm not the only one. It also reminds me of the og Battlestar Galactica cylons.",
      "How much is this video card",
      "[Like this?](https://i.imgur.com/IDOF7Km.jpg)",
      "Indeed. Nice catch",
      "197 O",
      "Please put two different power cables in that baby! Love the card I have the same one!",
      "Throws me for a L0OP",
      "Good one. I laughed out loud.",
      "It is not me, it is just you. we can't go on this way with suspicious minds.",
      "I'd this the top of the line card now",
      "Fun fact, the guy that designed K.I.T.T.'s scrolling sensor in Knight Rider based the design on the og Battlestar Galactica's Cylon Centurion helmet. \n\nCoincidentally, both series were created by famed show writer Glen A. Larson.",
      "I don't know how you thought of a 1970 Dodge Charger (except for the grill I guess) when it clearly looks much closer to, say, [a 2019 Dodge Charger](http://sf.co.ua/id30577)"
    ]
  },
  {
    "brand": "amd",
    "generation": "6000",
    "tier": "high",
    "matched_keywords": [
      "6800xt"
    ],
    "title": "My first build: 5900X + 6800XT, all black yet all red",
    "selftext": "",
    "comments": [
      "Jesus, that GPU almost doesn‚Äôt fit!",
      "That‚Äôs what she said.",
      "That cooler looks a bit small for an 5900x.",
      "If thats the Noctua NH-U12S I have the same one on my 5900x and it runs good... then again I can't ever get above 30% load because my 1660S is a bottleneck ü•≤",
      "Very nice .. How are your temps?",
      "Whilst I agree it‚Äôs far from ideal. No need to shit on the guy on his first build. Instead you could have suggested a better case and a better cooling solution.",
      "CPU tops out around 73¬∞C or so, GPU around the same, while gaming at 4K in games like MSFS 2020 and RDR2. So well within the chips‚Äô recommended temps.",
      "In cases bigger isn't necessary better.",
      "hard disagree. Perfect fit is a lot more attractive than taking up excessive space on your desk or floor, without accomplishing anything. This build could be 1/3 of the size, actually.",
      "You named your dick GPU?",
      "Slight angle on the GPU hurts my ocd",
      "Ummm......",
      "Hi case brother! [https://imgur.com/mHvNKwR](https://imgur.com/mHvNKwR) \n\n5800x, with a DH15S squeezed in. Good taste you have on the Chromax. \n\n(apologies to the subreddit for the GPU).",
      "You didn't?",
      "I‚Äôve got the same case with a 1080ti and a 5950x temps and noise are fine. Fractal is pretty good wish case design specifically around isolating noise",
      "It is, and it works perfectly fine. CPU temps rarely get above 73 or so degrees Celsius, so no worries really.",
      "Yeah, so most people's typical use case isn't running Prime 95 and Furmark simultaneously for 12 hours, so it doesn't really matter.",
      "No RGB 1337 stuff, take my upvote!",
      "Just what I thought. Such a beast deserves a bigger, better case.",
      "Nah, I named mine CPU cause it cums in smaller package and fast."
    ]
  },
  {
    "brand": "amd",
    "generation": "6000",
    "tier": "high",
    "matched_keywords": [
      "rx6800"
    ],
    "title": "Officially joined team red today. PowerColor RX6800 16GB.",
    "selftext": "",
    "comments": [
      "Is buying RX 6800 over RX 6700XT worth it?\n\nIn my country, Sapphire pulse RX 6700XT is $422 and Sapphire pulse RX 6800 is $664. Is the $240 premium worth it for RX 6800 ?\n\nEdit: 1440p gaming.",
      "Fuck Jensen",
      "Jensen is unhappy seeing you go red :)",
      "Fuck Jensen",
      "Upgraded from an EVGA GeForce 1070ti. Smooth installation using DDU with no problems.",
      "Depends if the used market price is good enough, I got my rx 6800 for 400 bucks. It came with all the original packaging with even some hardware still unopened. I still ran tests recommended by tech YouTubers to make sure the card is in good health.",
      "Fuck Jensen",
      "That's a really big difference so I'd say no. In US the difference is little so people jump to 6800 even 6800xt as it sometimes discounts really low to 550",
      "Might wanna change that 550W PSU to a bigger one",
      "Fuck Jensen",
      "big card = big pp\n\nalso AMD = big pp\n\nOP must have massive anaconda pp",
      "All my homies hate Jensen",
      "wowww that's a big card",
      "I bought a ASRock Phantom Gaming 16GB OC 6800XT Card a few months back. I have loved using the Adrenalin Software. When combined with a 5800X CPU, I have become full on AMD. No regrets here.",
      "Fuck Jensen",
      "Upgrade that PSU my brother",
      "6800xt is closer to 6900xt than 6800 to 6800xt so that's not where to cheap out but I won't judge op.",
      "What Tests are you referring to ?",
      "Seconded",
      "Amen"
    ]
  },
  {
    "brand": "amd",
    "generation": "6000",
    "tier": "high",
    "matched_keywords": [
      "6800xt"
    ],
    "title": "5900x / 6800XT OC tuf edition. With a little Boba Fett Theme that I finished this month !",
    "selftext": "",
    "comments": [
      "This is the way.",
      "Looks good! The case choice is a shame though, that airflow is gonna be tough",
      "Where the hell are you people getting your 6800s?",
      "tuf*",
      "5900x / 6800xt oc tuf / asus x570 tuf plus mobo  / 32gb TridentZ 3200mhz / Corsair RM 850x psu / 1Tb Crucial P1 NVMe / 1Tb WD NVme / Noctua DH15s / top fans are 140mm, rear and front are 120s. Case is ‚Äúwell, was black‚ÄùLian Li  205. Couple rgb strips in there as well.",
      "No offense but I don't think you understand how airflow works",
      "Boba festus sounds like a rotting milk tea drink",
      "TBF, The Mandalorian helmet they cut in tho the front will probably help...",
      "Legend mate what giveaway",
      "Thanks for being nuanced.\n\nThere's something about PC builders that makes them want to have a YES or NO about every part.\n\nIt's the worst or it's the best.\n\nThere is such a thing as \"good enough\", if he likes the looks, the CPU isn't at like 90C and the noise is fine, who cares?\n\nTbh, I'll take a creative \"imperfect\" setup over the same 3 cases post with 0 creativity between them.",
      "That a really good idea ! Didn‚Äôt even think to add those. üëç",
      "Where is the green?\n\nThis is more mandalorian\n\nVery nice",
      "This is the way",
      "https://imgur.com/a/6cDrwK6\n\nHeres a pic. Before that I treid the Lian Li PC-O11 Dynamic XL case, was not impressed with that case as it came damaged (returned it) and the build quality was meh. I was much more impressed by the Fractal Meshify 2 case, found the build quality was much better (IMO).\n\nEdit: Also, gotta say, NOCTUA has been absolutly the best company I have ever had the pleasure contacting. I contacted them about my CPU cooler, as it came with a defective screw and I also requested an AM4 mounting kit from them. They sent all the spare parts for free. Just provided supporting documents.",
      "Bad bot",
      "Just wanted to drop a note saying that someone downvoted every comment, so I upvoted every comment.\n\nCome on people. Be nice.",
      "Stock discords like stockdrops.",
      "I did it with a frosted glass spray and stencils. Lot of places that have spray paint will probably have it. Not hard to do, and you can add layers depending on how transparent you want it to be.",
      "I have this case. Airflow is great, actually.",
      "Looks like orange and black to me lol"
    ]
  },
  {
    "brand": "amd",
    "generation": "6000",
    "tier": "high",
    "matched_keywords": [
      "6800"
    ],
    "title": "Fresh AMD RX 6800 XT reference cards 'expected to be available in the first quarter of 2021'",
    "selftext": "",
    "comments": [
      "\"Rumor\"\n\n\"Expected to be available\"\n\n\"RX 6800 XT priced at $649\"\n\n\"Hot single girls in your area\"\n\n&#x200B;\n\nPressing \\[X\\] for doubt right now",
      "Well there are hot single girls for sure in my area, just not interested in me, so that's the more believable out of those",
      "All the hot singles in my area are busy gaming on their new RX6800s :(",
      "Let me make a prediction. They'll make them available at the same day and time the 6700XT drops, instead of doing a staggered approach, making the website turn to shit yet again.\n\nThey did this when they released the 6900XT and put the 6800XT back on sale at the same time.",
      "...but will it be organic?",
      "I bet Frank Azor's cousin will click buy now and get one ;)",
      "Right now my Vega 64s are making 5 bucks a day, so good luck on supply. This will be the worst gpu shortage ever.",
      "Hot Single GPUs",
      "I am already thinking about buying its successor instead, since I don't believe the prices will get any better in the next 6 month.",
      "I doubt you will see the successor anytime soon. As they don't even have the production capacity to meet the demand for its existing product line.",
      "With 0 added growth hormones and artificial preservatives!",
      "And they're only costing $4.99 in electricity!",
      "> So next gen will be far easier to get.\n\nwell, ignoring that apple and others will also be doing their best to get that supply, some already are(apple is already on 5nm)",
      "I still cant get over the end of SLI support... as a kid i aspired to have a triple gpu watercooled build... those 980 builds were out of this world",
      "Yeah more cards for scalpers to sell woho",
      "I think the \"Hot single girls in your area\" is the most probable out of those.",
      "Frank Azor will buy a second one to spite us.",
      "1st Quarter: January 1st through March 31st. Well, were already in February and still none available.",
      "Yep it was a fucking headache. I spent almost 2 hours solid F5'ing and it was all pointless because not a single 6800XT actually sold from the main store page I don't think, pretty sure the whole stock got sold via a secondary store page someone found because they still had stock for a few hours after launch but soon as that link got shared around they were gone in no time. Thankfully some kind soul shared it in this subreddit lol. They should just let people enter in a raffle for them really. Yes some scalpers still get them but its as fair as you can reasonably do, better than letting your website die for half a day and let everyone waste their day.",
      "We went from \"I bought it easily on our store site!\" to \"Rumors indicate that at some point in the future there maybe the potential to possibly see a reference 6800xt in stock one second before it sells out.\""
    ]
  },
  {
    "brand": "amd",
    "generation": "6000",
    "tier": "high",
    "matched_keywords": [
      "6800xt"
    ],
    "title": "Update: A very kind member of the medical community helped me get the final piece(6800xt) of the build I am gifting to my brother.",
    "selftext": "",
    "comments": [
      "Hey its me your brother",
      "Wow what a coincidence I am also his brother!",
      "Bro you can change the Radeon logo to a different color: https://www.reddit.com/r/Amd/comments/kg9vni/you_can_finally_change_led_color_on_the_reference/ggdlfj3/?utm_source=share&utm_medium=ios_app&utm_name=iossmf&context=3",
      "What a beautiful build man, gz!",
      "i also choose this guys brother",
      "The build looks amazing. Are you looking for another brother by any chance?",
      "I had no idea thank you!",
      "Thanks! Waiting for my brother to come home and reveal it to him for the first time.",
      "My long lost brother! We finally meet. Just a heads up father should be back any second with the milk. Prolly a long line or traffic it's been a few years since he left.",
      "Not at the moment lol",
      "Woah.   I had to leave a comment on this when I normally don‚Äôt.\n\n\nStunning.   \n\n\nI don‚Äôt think any other word I can think of at the moment, sums up how I feel about this build. \n\nHats off m8",
      "Well executed!\n\nI just don't understand the popularity of this case. Having moved the front intake fans to the backside of the case, next to the mainboard, makes no sense. You want 3 fans there for aesthetics, but in order to have proper airflow they must be installed as intake. So you see the ugly backside of the fans. And in addition to that your airflow now is restricted, because the air must turn 90¬∞.\n\nPeople who chose to go fully visuals use the fans as exhaust and pull dust through every gap of the case.\n\nThis case makes no sense...",
      "Beware, it's AyyMD heresy to change from red.",
      "Wait so who‚Äôs the father?",
      "Are those bottom slot fans in exhaust config? Seems like you'd want them intaking directly into the GPU.",
      "Dad where's the milk?",
      "What keyboard is that?",
      "Looks like the Drop Alt Mechanical Keyboard.\n\n[https://drop.com/buy/drop-alt-mechanical-keyboard](https://drop.com/buy/drop-alt-mechanical-keyboard)",
      "Let me know how he reacts hahah",
      "Ok I‚Äôm gonna sound dumb, where‚Äôs the power supply?"
    ]
  },
  {
    "brand": "amd",
    "generation": "6000",
    "tier": "high",
    "matched_keywords": [
      "6800"
    ],
    "title": "Early RX 9070 XT benchmark compared to 6800 XT and it's almost 4x faster",
    "selftext": "",
    "comments": [
      "This sounds like the similarly misleading junk that some rags were touting in their RTX 5070 \"preview\" articles yesterday.\n\nWhat the cited tweet actually says:\n\n>263% faster than 6800xt in wukong benchmark cinematic RT + frame gen fsr50%\n\n1. It's in a single RT benchmark with frame generation, the same marketing BS that Nvidia did to say the 5070 was bringing 4090 performance.\n\n2. It's comparing a leaked benchmark from one unknown source to the tweeter's own benchmark.\n\n3. Even past that trash, the article is rounding up an extra 10% in performance to call it \"almost 4x.\"\n\nSo, we've got two different data sources that aren't using identical setups being pumped up by frame gen, then getting a second pumping from the article author's rounding crap.",
      "stupid post",
      "‚Äúin wukong benchmark cinematic RT + frame gen fsr50%‚Äú",
      "crazy we get these posts when AMD already released performance numbers. The 9070XT is around 65-70% faster than the 6800XT ü§¶‚Äç‚ôÇÔ∏è\n\n4x faster.. that is about as dumb as nvidia claiming the 5070 is faster than the 4090 üòÇ",
      "Framegen just invalidates the result lol",
      "AMD doesn't have multiframegen tho, which was the biggest reason 5070 fps was exaggerated to be 4x the actual",
      "At this point, I don't care for rumors. Reviews are live tomorrow, and a lot of the reviews I've seen so far for the 5070 have said we should keep an eye out so I'm interested in RT. I know raster will be good.",
      "If framegen gets that high, base fps is what 120?",
      "9070xt uses basically same boosts than 6800xt, but they are comparing ray tracing performance, on which 6800xt is pretty much unusable so it's relatively easy to quadruple the fps",
      "No, it's an Apple-like comparison",
      "....\n\nPretty misleading title as they picked a game that's RT heavy and run it against 6800xt.",
      "What a load of BS!\n\nIf the 9070XT is 4x faster than the 6800XT that means it will be the fastest GPU in the world, surpassing the 5090 by a significant margin \n\nWhen you want to lie, at least make it doable",
      "The GN video today made the 5070 MF claim look way worse. Its not even close.",
      "Why? What's stopping 6800 XT from using exactly the same framegen?\n\n\nLol indeed. Someone clearly doesn't know anything about critical thinking.\n\n```\nRX 6800 XT under the same settings\n```",
      "I need to know what the rt numbers look like tho.",
      "Hell yeah, shame OP, shame!",
      "\"The[¬†leaked benchmarks](https://x.com/GawroskiT/status/1896838352844026103)¬†seem to come from the Chinese forum Chiphell but were posted on X by tech enthusiast Tomasz Gawro≈Ñski, who showed the RX 9070 XT reportedly being 263% faster, delivering 69 FPS compared to just 19 FPS on the RX 6800 XT under the same settings. **The test was conducted at 4K resolution with** ***cinematic ray tracing*****, frame generation, and FSR set to 50%, making it a demanding scenario that favors the**¬†[**improved ray tracing of RX 9000 series GPUs**](https://www.pcguide.com/news/significant-gen-over-gen-gains-in-rt-titles-amd-claim-2x-rt-performance-in-9000-series-gpu-lineup/)**.\"**\n\nIt's with RT on. It's just expected.\n\nhttps://i.redd.it/50b4biez1qme1.gif",
      "Exactly, and unlike Nvidia, AMD never claimed this",
      "based on steve's review from GN on the 5070, everyone should wait a day before making a decision and he kept referencing how the 7900XT was beating the 5070 in too many situations even some with RT but who knows what that was about.",
      "Yeah, my criticism isn't with AMD, it's the author of the article."
    ]
  },
  {
    "brand": "amd",
    "generation": "6000",
    "tier": "high",
    "matched_keywords": [
      "6800"
    ],
    "title": "Broken AMD 6800/6900 GPUs after driver update? Video in the description (not mine)",
    "selftext": "",
    "comments": [
      "Just in case you haven't heard of KrisFix and are questioning his expertise or motives:\n\nHe has been repairing a lot of GPUs on a very high level for a number of years so he knows what he is talking about. Just look at the videos on his channel, they speak for themself\n\nExample: \n\nHere he is reballing a 3090 chip + ram because the card was drenched in liquid metal: https://www.youtube.com/watch?v=6nQCj5N9fV8 (skip to the last third of the video to see the soldering)\n\nHe is not some random small hobby Youtuber trying to create drama for views. \n\nIf he says \"I see a pattern here\" then people should certainly pay attention to what he is saying",
      "XFX 6900xt on 22.11.2 and nothing weird on going for me.\n\n(Knock on wood. Fingers crossed. Toes crossed.)\n\n&#x200B;\n\nedited",
      "This is crazy. My RX 6900xt recently died. About a day after I installed the newest driver.",
      "`if (warranty > 24) {`\n\n  `execute = \"overvolt.exe\"`  \n  `greeting = \"Check our brand new 7000 series GPUs\";`  \n`}`",
      "Count mine in. I had to replace my 6900 xt a month ago. I upgraded to the newest drivers at the time.i also used the auto undervolt feature in adrenaline software. then, I  played Black Mesa with every setting on ultra at 144hz 4k for an hour. I shut the PC down. The GPU never came back on the next day.\n\nEdit - my GPU is a reference 6900 xt model. GPU died after I updated to 22.11.2 recommended whql. Never mined with it. Just benchmarking/gaming/productivity",
      "People replying should include which aib card they are using \n\nCould help isolate the issue",
      "Unfortunately it's going to be very hard to verify this, as I don't think there are many repair shops doing GPU board repairs, that also have a social media presence. \n\nAIBs would know due to warranty claims, but it's not in their best interest to tell journalists about abnormally high defective GPUs.",
      "Same Here for me. Excact Same Symptom.\n\nPowercolor Red Devil Ultimate 6900XT",
      "JFC can we as consumers ever catch a freaking break???",
      "My Gaming X Trio is working fine too. This shit is making me nervous tho lol",
      "I suppose it's good that i'm still on ye olde circa may 2022 drivers because black screen crashes are the bane of my existence and I refuse to modify windows settings to compensate.",
      "Yeah Kris Fix is a professional. Love his channel.",
      "Out with the old. In with the new",
      "No issues with my card (reference)\n\nLast driver 22.11.2 WHQL",
      "*nervously walks behind you...\n\nThis is like a horror film, but first person.",
      "I like your funny words magic man",
      "Technically you only have 1 year of hassle free warranty in germany where you can return the product for rma. The second year becomes a little more complicated because now you as the customer have to prove to the seller that the damage/fault was already there at the time of buying the product.\n\nSo if a component was maybe already faulty but did not immediately result in a failure for example.\n\nNormally you would expect them to be accomadating and still just give you a replacement unit but they could also refuse it and demand that you prove them that this fault was already there at the time you bought the product at. Which would obviously be quite difficult as a consumer to do so.\n\nMaybe that's why they just send it to a repair shop.\n\nEdit: Of course this is just the minimum warranty requiered by law but individual companies can extend this if they so choose to.",
      "Mit dem Angriff Medions wird alles in ordnung kommen!",
      "My god. If this is true, this is absolutely disastrous for AMD.  \n\nThe GPU world has been an absolute dumpster fire as of late. Both AMD and Nvidia dropping the ball again and again.  \n\nThat said, a botched driver update that bricks a bunch of previous gen cards absolutely takes the cake.",
      "Some games specifically ask to update drivers. I was happily using the may release and WZ2 will not run unless I update the driver."
    ]
  },
  {
    "brand": "amd",
    "generation": "6000",
    "tier": "high",
    "matched_keywords": [
      "6800"
    ],
    "title": "In Love! 980 to 6800 Xt.",
    "selftext": "",
    "comments": [
      "You should use two separate 8 pin cables from the PSU.",
      "Ty, i will look at it tomorrow :)",
      "It's a 300w card. You should use two separate PSU cables.",
      "Generally it's recommended to use separate cables to power the card, if it has more than one connectors. Especially if it's a 300W VGA.\n\nEven most PSU makers [agree](https://knowledge.seasonic.com/article/8-installation-remark-for-high-power-consumption-graphics-cards) with this, which is why the purpose of these daisy chained cables is questionable -  you need a 2nd cable anyway for the most optimal power delivery and stability, so they just make things more complicated and they look ugly... \n\nIf the card has 2x6 pin connectors it should be okay, but most modern cards (released in the past 5+ years) won't use that layout since 1x8 pin can offer the same with just one connector.",
      "I have seen people Complain about bad performance Or worse then they expected from their cards because of this.",
      "Someone had stuttering issues yesterday and got mad at me for recommending this for a 5700xt.\n\nIt even says to run separate PSU cables in the manual.",
      "Since it's above 250W max draw right?",
      "Liking how industrial this card looks, looks the business.",
      "I was considering using the be quiet cooler.how does it perform?i assume you have a ryzen cpu",
      "Is that the DRP4? Why does it look different\n\nedit: That's the Dark Rock Pro 3. I don't see anything wrong with it",
      "~~While you are at it, install your CPU cooler in the correct orientation/way.~~ The middle fan of the Dark Rock Pro 4 is the most effective in cooling and doing loads of work. It needs to be properly orientated however. The first and second fan should both be in the same direction, taking fresh air from the front of the PC and exhausting towards the back. Make sure to double check the orientation of your fans is correct and they are flipped the correct way. There are small arrows on the side of the fan which show the direction of flow of air.\n\nEdit: Thanks for the corrections. Was sleepy and didn't notice the differences with the Dark Rock Pro 4. I have the DRP4 and it would be installed incorrectly if it was the same cooler. Something was registering off with my brain because the fins seemed to be orientated the correct way, but I wasn't sure.",
      "Big boy!",
      "Word of asterisk.  EPS-12v 8 pin for the CPU carries a 300W stamp from PCI-SIG, and uses 4, 12V conductors.\n\nThe 8-pin, PCIe addin power connectors uses three conductors for 12V, is rated at 150W by PCI-SIG (margin). Termination pins, cable length and gauge, PSU capabilities and in-PSU distribution header config/layout for modular are such a grab-bag it's safest to always run two cables per spec -- and really not that inconvenient.\n\nOld AT power connectors are a favorite example of getting things wrong even at the highest levels where things won't fail safe. Add in vendors sometimes add a Y-adapter for their particular card, but these adapters often find themselves in the cable collection to be reused under the wrong conditions.\n\nI've seen people soften and deform small areas of plexiglass side windows where a single, 8-pin wiring was pressed against it while plugged in to a Y adapter with high power cards.\n\nRunning 300W in a cable can heat up the PSU end and/or GPU end as the resistive joule-heating will conduct through the copper if it's out of spec enough for the setup.",
      "Industrial can sort of mean it looks sleek/modern, but also looks tough and rugged.",
      "Very nice cool down a lot. As long as you have the space for it.",
      "Like it belongs in a factory / manufacturing",
      "This isn't technically true if the cables are above spec, and on good PSU's they will be. Basically, the cable itself can feed enough current, without voltage sag, to feed two connectors. You don't really need a large increase in cross-section of the core to double the amps the cable can feed. And in most PSU's there arent multiple rails, it's one large rail feeding all the 12v cables.",
      "very quiet and keeps my 3700x below 65 degrees at around 1000rpm",
      "While it may run, it may shut down because transient spikes can exceed the rating of the single cable bundle. So if it has two connectors use two cables. Three connectors can use two cables with one pigtail if needed.",
      "Been running my 1080ti even overclocked with just one cable and I‚Äôve had zero issues."
    ]
  },
  {
    "brand": "amd",
    "generation": "6000",
    "tier": "high",
    "matched_keywords": [
      "6800"
    ],
    "title": "I gained almost 1000 points on Timespy rolling back my drivers. (rx 6800)",
    "selftext": "",
    "comments": [
      "I found this as well, but not with the score, only the stability of the card.  When I first purchased my 6800XT back in February, those drivers at the time (21.2.1?) were significantly more stable than the latest ones.  On the latest ones, I got screen flickering, black screens and random game crashes, whereas re-installing the older ones resulted in none of those.\n\nMoral of the story : never update to the latest drivers unless you absolutely have to i.e support for a particular game you want to play that requires them.",
      "I have had the exact same issues. Bought the card in February, performed amazingly well, I was really impressed. Updated to the 21.3.1 drivers from late March and have had nothing but problems described by yourself. \n\nShame, as the ray tracing support for dirt 5 and cyberpunk came with these drivers.",
      "You probably just had a bad install, here's a comparison with my 6800 on the same driver version:\n\n[https://www.3dmark.com/compare/spy/19543014/spy/19522581](https://www.3dmark.com/compare/spy/19543014/spy/19522581)\n\nEdit: Driver had a hickup, so here's another comparison after reboot:\n\n[https://www.3dmark.com/compare/spy/19522581/spy/19543355](https://www.3dmark.com/compare/spy/19522581/spy/19543355)",
      "\"bad install\" for as basic thing as a driver is something evil.",
      "21.3.1 and 21.3.2 are a mess, i dont know how they got throug QA at all",
      "yet it is a thing more common than anything else, this 'bad install' is not only related to drivers you've got firmware/bios flashing as well there your possibilities can brick the device or an unstable one, reflash the same bios and it works perfectly the second time around just like with drivers.\n\n21.3.1 works perfectly fine for me that being said Intel,NVidia or AMD or any other vendor for that matter bad driver installs is as old as it can get, it goes back as far as I can remember which would be Windows 3.1\n\nand I am curious how you define a driver as something 'basic' technically it is vastly more intricate compared to application level software like games or office.",
      "welcome to AMD drivers, where bugs are proclaimed as intended behavior (my 5700XT was locked at max memory speed, but there was a workaround for that \"intended\" behavior)",
      "21.3.1 sapphire 5700xt reporting in.\n\nthis driver was for us. hella stable for me. 2600+5700xt",
      "These scores are meaningless as they are combined scores. Show us the GPU scores please.\n\n&#x200B;\n\nI can not talk about stock performance, but I reached my personal best with the latest whql driver. (21.3.1)",
      "GPUs are fine, it's just that software isn't AMDs forte.\n\nIts not just drivers too, Intel has better AI and ML suite for a couple of years now, without even having a HPC card released. Don't even talk about infinitely delayed DLSS alternatives and other features.\n\nIts like one day they open sourced their drivers on linux and said to hell with a dev team, we only need 5 anyway.",
      "\"I'll keep it ok those drivers until I can't anymore\": You should not need to do this with a high end gpu",
      "Drivers is the number 1 reason i switched to Nvidia after experiencing the for a year 5700 XT since launch",
      "Ditto. 3700x and 5700xt, running much smoother with the update.",
      "It was very likely a bad driver install, as your GPU wasn't boosting properly. I downclocked my 6800 to the average frequency of your GPU and got approximately the same result:\n\n[https://www.3dmark.com/compare/spy/19522581/spy/19549521](https://www.3dmark.com/compare/spy/19522581/spy/19549521)",
      "Same here. No issues on my end (5900X, 5700 XT).",
      "Well Nvidia fucked up support for VR headsets for 4 months, so team green is not always better...",
      "Why such a degradation in performance with the latest drivers?\n\nThey're also extremely unstable. Radeon Adrenline 2020 refuses to open some times.\n\nI'm new to AMD gpus, is this the norm? having to dig around for good drivers for my card? (I'm now using the 21.2.3 drivers)",
      "6900XT on 21.3.2 here, not noticing any issues. I did DDU prior to installing the new drivers though.",
      "Vega 64 locks core voltage to 1.2V (max) for all frequencies after resume from sleep if voltage floor was modified in Wattman for 2 years now.\n\n\"Works as intended\" was answer, despite workaround with another sleep on default voltages fixing it existing.",
      "RadeonPro Drivers 21q1.1 is the best for RX Vega at moment, adrenalin 21.3.1 anda 21.3.2 is bad for RX Vega's and Polaris too."
    ]
  },
  {
    "brand": "amd",
    "generation": "6000",
    "tier": "high",
    "matched_keywords": [
      "6800"
    ],
    "title": "[Guru3D] Availability of the Radeon RX 6800 (XT) & 6900 XT Is Still Extremely Poor",
    "selftext": "",
    "comments": [
      "6800 2930 ordered 117 delivered\n\n6800xt 2513 ordered 42 delivered\n\n6900xt 354 ordered 0 delivered\n\nfor the 159 delivered: \"we did not expect so much demand\"",
      "ordered=from manufacturer\n\nnot by customers",
      "Saw the 6900xt on ebuyer today had it in my basket almost purchased it but then did a double take on myself like \"do I ACTUALLY need this? nope\" so gonna wait till stock normalizes I was only going to pull the trigger because of low stock like \"if I don't get one when will I?\" just gonna wait 6 month and see whats on sale then. Not going to be triggered to buy somthing because of low stock which I almost was.",
      "Are these numbers accurate? That just blows my mind. I‚Äôm one of the 2513 ordered and now I just feel like I‚Äôm never gonna receive it",
      "Honestly I feel that if it wasn't for the high level of demand for high end GPUs people wouldn't be as willing to buy an RX 6900 XT or RTX 3090. In a \"normal\" GPU market it simply doesn't make any sense to buy these cards unless you are using them for work.",
      "I was told by Canada computers that my 6800 XT will just never come in, so I can either wait for an AIB that they have no expected delivery date, or go to the back of the line for a 3080. Definitely a month of waiting well spent /s",
      "they said 2 months for availability, we are on month 1 + 5days and counting\n\nI said that it was a lie but.. who knows, I hope I'm wrong",
      "The 6800xt red devil variant from powercolor retails for 1197 USD. What is worse, I don't think this will go down any time soon",
      "Yeah thats the problem im having right now, I don't really need a 6800xt / 6900xt but currently running a rx 580 8GB and the games I play run fine so I don't \"NEED\" one of these new cards but I would certainly notice the difference.\n\nPersonally I wish there was more of a mid tier GPU available, right now 5700xt is about the price I want to pay, but fuck buying something like a 5700xt or anything not \"this generation\" for the IPC uplift.\n\nHoping next year AMD puts out some replacement for the 5700xt or Nvida up the amount of VRAM in their cards because I was even looking at the 3060ti etc but its like I am not going from 8GB VRAM to 8GB ...",
      "AMD confirmed that more reference cards will be made for all models. But given that at most AMD is only getting at most 60 GPUs per wafer and Nvidia is getting at most 50 GPUs per wafer for both companies largest dies, don't expect supply to normalize any time soon. Keep in mind that that's only 140,000 TSMC 7nm wafers processed every month in total. And AMD has between 44,000 and 70,000 of those (we know that no customer is over 50% and some customers have dropped without disclosing who the allocation went to). Nvidia is using Samsung 8nm and we aren't sure how many wafers they're buying or even how many wafers per month Samsung is making on 8nm versus their 7nm process. But total supply to Nvidia is likely between 100-300% of what AMD is using at TSMC for GPUs based on what numbers look like in wholesale channels.\n\nMy guess is that Nvidia probably has around 10k-15K wafers/mo for all of its Ampere products including the A100 which is currently out of stock with earliest possible delivery via air being listed as 3 weeks. And AMD is likely only dedicating 2-3K wafers/mo to their high-end GPUs with the vast majority of their TSMC 7nm wafer allotment being slotted for console APUs, processors, and low- and mid-range GPUs that are launching next year. Furthermore, AMD also is starting to fulfill CDNA which is a 120 CU  computer focused GPGPU solution for data centers which features better FP16, FP32, and FP64 performance compared to Nvidia's A100 and has already been ordered in bulk, along with the not yet publicly released new Epyc processors for the first two exascale supercomputers.\n\nOh, and to top this all off, we've had shortages of the following so far this year:\n\n* Screws\n\n* Shipping containers from China\n\n* Shipping containers to China\n\n* Air freight capacity due to decreased intercontinental flights and now vaccine deployment\n\nAnd all of that is affecting the ability to move produced products from Asia to the rest of the world. Not to mention the fact that shipping is taking longer due to COVID-19 mitigations that slow down the loading and unloading of ships, planes, trains, and trucks.",
      "AMD told Hardware Unboxed that in up to 8 weeks MSRP cards from AIB partners would be available so we will have to wait until mid-January to see if that ends up being true or not.",
      "No. The mining craze was way worse. I know it first hand because I bought my RX 580 back then and I remember that I had to wait for months to get it.\n\n\nIt eventually got to a point where the only card that was readily available was the GT 1030 (even the RX 550s were selling out immediately). At least currently I can still buy an RX 5000-series card or an RTX 20-series card if I needed to.",
      ">AMD confirmed that more reference cards will be made for all models\n\nAMD's word means nothing at this point.\n\nThey have said-\n\n- There would be more stock than nVidia launch - **false**, *nVidia had more cards - both sold out quickly but nVidia had 2-3x the cards available on launch day.*\n\n- There would be 5-7x the stock for AIB cards - **false**, *there were even less cards for the AIB models than reference.* \n\n- There would be a general availability and a return to MSRP within 4-8 weeks (still in progress, but considering we're hitting christmas, new year then chinese new year - we can do this one early, there won't be stock before march) - false",
      "My canada computers hasn‚Äôt told me this, but they have no idea when I‚Äôll get my card either",
      "I saw my first social media post about someone actually getting a 6800XT yesterday. It was a reference design from XFX. Compared to nvidia, I see maybe 5-10 posts every day of people getting 3080's and 3070's. \n\nI know this is far from a quantitative analysis, but this is a factor I've been using to judge availability for years and it has always worked for me.",
      "The fact they decided to keep the reference going means they might think this won't happen now.",
      "Nah its not that one dimensional, they do proper market research and much more to find out the demand but they also are restricted by foundry capacity.",
      "Weren't 580s and 1060s going for $500? That was super rough. A $200 msrp card going for $500 and what's worse is that eventually retailers started charging that much. It's even funnier that despite all that and despite 4-5 years, the msrp of the rx 580 hasn't changed (still around $180?)",
      "I got a 6900xt this morning at microcenter. Had to be there at 5:30am outside though to be one of the first 10 in the store",
      "It‚Äôs so much worse than the 30 series. I‚Äôll grant them that they were released later but I‚Äôve seen basically no restocks of these cards."
    ]
  },
  {
    "brand": "amd",
    "generation": "6000",
    "tier": "high",
    "matched_keywords": [
      "6800"
    ],
    "title": "Leaked Radeon RX 7800 16GB TimeSpy Score Shows 17% Improvement Over Last Generation's RX 6800",
    "selftext": "",
    "comments": [
      "The 6800 feels like the forgotten GPU in the 6000 series lineup. Everyone talks about the 6750XT, 6800XT and 6950XT but never the 6800.",
      "I think you forgot the long lost 6700 10GB",
      "So weaker than my 6800xt",
      "I have the 6700. It really is the forgotten child of amd. Runs great at 1440p and has 10gb too. It basically the 7600 but with a bit more power and more vram",
      "This whole gen has been incredibly mediocre for AMD. Between the bad efficiency (especially compared to RTX 40), underwhelming uplifts in raster and RT, and major driver issues with power draw and VR I don't know how anyone could go for an RDNA3 card until they're heavily discounted.",
      "It's rarely worth upgrading just one generation anyway, unless you consciously bought the bottom of the stack of one generation with the specific intent of buying the top of the next.\n\nRX6800 is a fine 16GB card and will last you a while yet.",
      "Yeap, that's the reason they'll market it as \"7800\" not \"7800 XT\"  \nPeople would riot otherwise",
      "$549 is way too much for this when there is a 4070 which is regularly cheaper with bundles. Given how atrocious upscaling and drivers have been this series, this should be considerably cheaper for it to be viable‚Ä¶ but hey, literally every new gpu from any manufacturer is shit value.",
      "Think I'll just hold onto my RX 6800 for a while longer. I really don't see a huge reason to upgrade this generation from either Nvidia or AMD at this point.",
      "Fellow 6700 user. Got it 260 brand new and it‚Äôs great! Can even do 4k on older titles with a little settings tweaking or fsr",
      "The 6700 is what the 7600 should've been. A 10 GB 1080p high performer that can dabble and dance in 1440p pretty decently\n\nEdit: accidentally typed 4k instead of 1440p initially",
      "That's because for a while the 6800 was going for 480$ with the XT at just 30$ more",
      "The worst part? It's hardly more efficient and just not worth the extra cost when compared to cheaper Navi21 options.",
      "You'd hope so. If it's anywhere near $600 then it would make 0 sense to get one over a 6950xt",
      "They did that with the 7600, and people still rioted.",
      "Cheapest 4080 I see right now is $1140. Cheapest XTX is $960 looking on Amazon and Newegg. So for $180 more I get a significantly more efficient card with better RT, DLSS3, and CUDA. Wouldn't be a hard decision for me to go for the 4080 if I was deciding between the two.\n\nAMD is delusional with their pricing this gen or maybe they just don't care and know they won't sell much at their current prices and are ok with it as long as the profit margins are high.\n\nNvidia is also delusional with their pricing this gen but at least they have a good line of cards and people justify paying more for the better features.",
      "The 6800 XT is a pretty big step up and isn‚Äôt that much more. It‚Äôs not as good of a value proposition as the others.",
      "Yes, while consuming ~30-40W less power.",
      "the really ugly one is going to be 7700, where you're using almost as much N6 wafer area as a 7600 and then adding 200mm2 of N5P.  The MCM area overhead is atrocious.\n\nSo basically take a 7600 and then add three Zen4 chiplets worth of area, to slide performance upwards from 4060 to 4060 Ti performance.  Which it should edge past pretty easily ofc (4060 ti + 5-10%?) but it's gonna be a godawful deal for AMD.  Like I guess if it's 10% faster than 4060 Ti 8GB they do $429?  What an absolute waste of silicon from their perspective.  \n\nThere literally is not a number where that product is worthwhile - even at $499 it would be a waste of silicon for AMD compared to Zen chiplets.  And 7800 really needed to be sold for at least $600.  But the product performance just can't justify that.  This is Vega 2.0 where AMD is getting pinched by how poorly their silicon is performing relative to the established performance levels of the competition, and even AMD can't pretend it's an awesome deal at MSRP, but neither can they afford to go any lower on pricing.\n\nThat was when we saw the bundle deals (\"buy a GPU for $100 more than MSRP and get a coupon for $100 off a specific monitor nobody wants absolutely free, coupon expires in 30 days!\") and other crap kick in to shift ASPs upwards.  And even still, standalone MSRP was so low that partners couldn't actually make a profit on the cards they were ordering from AMD (\"made by AMD\" reference cards).  Everyone got real mad about that with NVIDIA a year ago, I think everyone forgot that was an AMD thing with Vega too lmao.\n\nI think the numbers have to be $499 for 7800 and $399 for 7700, *maybe* they will try for $529/$429 to squeeze a couple more bucks but at $450/$550 they are DOA.  DLSS alone is worth 10% to me.",
      "AMD didn't charge $400 for a 8GB card, which is what they taunted Nvidia for."
    ]
  },
  {
    "brand": "amd",
    "generation": "6000",
    "tier": "high",
    "matched_keywords": [
      "6800"
    ],
    "title": "AMD Radeon RX 7800 XT GPU Review & Benchmarks vs. RX 6800 XT, RTX 4070, & More",
    "selftext": "",
    "comments": [
      "Happy with my recent 6950xt purchase",
      "My decision to buy the 6800XT last year is looking better and better.  This is no doubt the best price/performance AMD has released this generation, but the lack of generational uplift is disappointing.",
      "Guess I‚Äôll be sticking to my RX 5700 XT or finding a 6000 series replacement.",
      "People calling it Trash are mostly correct. Its not a great card for its price. \n\nWhen compared to its Nivida equivalent? Its ALOT better. Can't wait to see nvidia sell 4 for every 1 AMD sells",
      "So mostly the same performance to last gen but costs slightly less and consumes less power",
      "It seems like it should have been the 7700xt, with the 7900xt being a 7800xt, and 7900xtx being a 7900xt.",
      "Just bought a 6950XT as well, working wonders in Starfield",
      "I'm guessing most people expected a better generational uplift over the 6800XT.",
      "I know the price is okay in the USA, but here in Australia, it's not that great. \n\nA 7800 XT the cheapest I can find as of writing is $879 AUD, that's converted to USD with tax included ~$561 USD which is about right once you add 10% GST/VAT and maybe some extra fees for being shipped to a penal colony. \n\nThe cheapest 4070 is like $889 AUD. So yeah the 4GB of VRAM extra is nice, but the RT performance, DLSS and other features like NVIDIA Broadcast and just general driver stability or rendering performance keep the RTX 4070 lingering around as an option. The $100 pricing gap between the 7800 XT and the 4070 in the USA is basically not really a thing here.\n\nThe 7800 XT desperately needs a price drop here in Australia to be a relevant purchase. A good $80 AUD price drop puts the 7800 XT into a spot of consideration. But then I remember that a used 6800 XT goes for around $650 AUD, so unless you really use RT or want AV1 can't see a reason to buy a 7800 XT.\n\nAnother AMD graphics card release, another dead on arrival product here in Australia.",
      "and improved RT performance, and AI Accelerators, and AV1 encoding.",
      "Spoiler: he wasn't that happy.",
      "Forgot about the 4060 Ti already? It didn't even have cheaper MSRP",
      "I had been looking at buying a 6800xt but now with the 7800xt out, I might just do that. Sure, they're comparable in performance, but the 7800xt seems to win in the power consumption category. Maybe I'm in the minority here but that actually matters to me.",
      "Hubs video too. No significant change in performance. Thanks amd for blessing us with this massive W today. Same performance as last gens card something I have not seen on either nvidia or amds side in so long but hey. It's just $15 more expensive than last gens card so that's good ? Maybe...? I'm so fucking upset how did we get to this? Maybe by the time we get a 9800xt it might be a slight improvement who knows",
      "Nvidia is our best friend. We dont talk about issues, because they dont have any and never make mistakes.\nAlways the best choice for gamers!",
      "I just bought one after looking at the reviews. Also an important point is that 6800xt performance uplift via drivers is likely not going to happen anymore but 7800xt is likely going to get quite a few driver updates that improve performance. \n\nPlus I have seen reviews from 3 different sources running sometimes the same games and where Steve was getting better performance on the 6800xt the other two were getting equal or better performance on 7800xt. \n\nImportant thing to note, Steve was running the stock version of 7800xt vs sapphire nitro+ version of 6800xt. Jayztwocents was running the same version of two cards(red devil powercolor) and 7800xt was showing better results vs 6800xt. \n\nAnd I was hoping for exactly this, similar performance for less power draw and same price or cheaper. And it is in UK same price or cheaper.",
      "AMD has no shame anymore.",
      "In theory, yes. But honestly modern cards tend to really struggle with OC's compared to older cards. The way they boost is just pretty aggressive out of the box. I think very few people get meaningful OC's on any 5000/6000/7000 series cards.",
      ">it's $499 and runs as fast as a 4070\n\nSure, that's one way to look at it.  The other way is that it runs like a 6800XT for the price of a 6800XT.  Not saying that's bad (at least compared to the competition), just not very exciting.  People want generational uplift and this has essentially none.  If you have a mid-range or better card from last generation, there is nothing for you here.",
      "Stick with the 6950xt"
    ]
  },
  {
    "brand": "amd",
    "generation": "6000",
    "tier": "high",
    "matched_keywords": [
      "6800xt",
      "6800"
    ],
    "title": "Bullsh1t_Buster on Twitter: Navi21 (6800XT/6800) mining performance is not very good.",
    "selftext": "",
    "comments": [
      "Whatever brings doubt to miners, I'm all for it.",
      "First guy says it‚Äôs great at mining, second guy says it sucks at mining? \n\nWhy should we believe either one? Who the heck are these people? Can somebody explain?",
      "Yes pls.\n\nReally hope 6800XT stock isn't as garbage as the 3080.\n\nReally want to build a PC in Jan/Feb next year and really hope there are GPUs available.",
      "I do t know who to believe. But i know who i want to believe.",
      "Fair warning: it will be. For the last several GPU releases, regardless of Nvidia/AMD, the high/mid-tier GPUs consistently sold out during their initial launch runs. It's kind of expected and you should plan around it.\n\nDoes it suck? Definitely. It's just part of that early adopter tax you pay for the newest hardware.",
      "In theory it should be worse as RDNA is gaming tech vs the compute strength of CDNA. AFAIK, mining relies on compute performance more than graphics/rasterization performance.",
      "God I fucking hope this is true.",
      "yea it absolutely sucks balls, don't buy it. Hell, go out of your way to avoid them. Don't even load up the websites. They're terrible. So bad. \n\n\n\n    Maybe I'll actually be able to get one now",
      "Yes.",
      "Ah 2020, where a card being shit at mining is a cause for hope.",
      "I don't know who bullsh1t\\_buster is, but I trust [kopite7kimi](https://twitter.com/kopite7kimi/status/1325831282434035712). If this is credible to him, that's good enough for me.",
      "eth mining is bandwidth dependent RDNA should be perfectly fine at this but eth is going pos so it's still fine",
      "fragile handle mindless worthless north squalid sip fear rinse onerous\n\n *This post was mass deleted and anonymized with [Redact](https://redact.dev)*",
      "To be clear, I hope it's garbage at mining because I want to actually be able to *buy* said Ferrari, haha",
      "Is the PCMR thing really taking off nowadays or is the production just low?",
      "The whole fucking thing just wastes resources for no good reason.",
      "Meh, with that memory bus it probably isn't much faster than a 5700xt mining ethereum.",
      "I hope so. Fuck the scalpers, bots, and miners.",
      "Hope this is true. I hate everything mining. The whole thing is just distributed criminal money laundering and I want mining to have not a single fucking cent of influence on pricing and not a single board of impact on availability",
      "It won't the whole point of ETH is to circumvent caching."
    ]
  },
  {
    "brand": "amd",
    "generation": "6000",
    "tier": "high",
    "matched_keywords": [
      "6800xt"
    ],
    "title": "6800xt midnight black",
    "selftext": "",
    "comments": [
      "On 1440p gaming with a manual fan curve I'm barely tickling 60-65c under full load",
      "Someone correct me if I‚Äôm wrong but dooesnt the cooling of amd reference 6000 series suffer when on its side?",
      "Hurts. Been trying to beat the system since the black edition popped up first....",
      "It suffers in lengthwise vertical orientations (I/O on top). This orientation is fine. If we can trust some of the posts comparing temps and orientation, it might actually be the best orientation option. Either way, as long as the long edge is parallel to the ground there isn't a severe performance impact.",
      "Other than AMD.com occasional restock, is there anywhere else I can get this sexy beast on MSRP? Thank you.",
      "I was lucky and landed it first round of release",
      "its front mounted hoses on bottom which is how they recommended to mount it if you cant top mount",
      "Low and slow, ow to make a great chilli",
      "I just did my first ever AMD build with a 5600x + 6800 XT. I‚Äôve always had Intel+Nvidia. This thing rips! The midnight black is slick. Red Devil for me.",
      "Msrp? No",
      "So long reddit, thanks for all the fish.",
      "I got mine in the normal way. If I could put it vertically like this I would tho. I baught the SAPPHIRE NITRO RX6800XT special edition which has RGB fans. Didn‚Äôt realize I wouldn‚Äôt even see them though unless it was vertical. Still looks like a beautiful card tho because the sapphire cards are already just very visually appealing with the mirror rgb sapphire logo and silver top. But I still run at good temps. About 75c under full load running demanding games. So I don‚Äôt think it makes much of a difference as long as you have good cooling within you‚Äôre pc. I got a micro atx case. Corsair crystal 280x. My card is one of the bigger 6800xt cards so it literally just fit the case with about a half inch between the card and front fans. I got a AIO rad and 4 other fans. 2 fans on the bottom(intake), 2 on the front(intake) and the aio rad on top (exhaust). Runs pretty cool for a smaller case with some beastly hardware. Rx6800xt and 5950x",
      "Teach me your secrets. I have been trying for a 6800xt for 7 weeks now.",
      "What case is this?",
      "Front mount bottom hoses and tank well above pump height",
      "I had and early invite and had it in my cart but couldn't submit because it wanted Canadian province info entered for my address as well as a state. I was on the US site and had a US address selected too.",
      "Has NZXT's software improved?  I've avoided them for years because their software left much to be desired.",
      "Convert my reference 6900 to water..Temps never crest 50c. At 2700mhz. If I set Modern Warfare to 1080p render resolution I can push 400 fps. Who knew you could get CSGO fps in a modern game.\n\nPic for reference.\nhttp://imgur.com/gallery/NbXCFb5",
      "Oh my bad I thought the rad was on the bottom of the case.  You're right.",
      "me too i just got an AMD build, always been intel nvidia but by god this thing is a true thread ripper."
    ]
  },
  {
    "brand": "amd",
    "generation": "6000",
    "tier": "high",
    "matched_keywords": [
      "6800"
    ],
    "title": "Introducing, Sleipnir, my first ever team red build! 5800X and 6800 Nitro+",
    "selftext": "",
    "comments": [
      "That GPU sag is scary; have you considered getting something to prop it up?",
      "Yeah, I have to move it to it's permanent home, I'm thinking of rigging a sag bracket to the SSD tray",
      "Lian li anti sag bracket order it from microcenter.",
      "GET A GPU BRACE ASAP!",
      "I nabbed mine from Newegg Business, it was available, I wanted it, and I bought it. Couldn't have done it without Falcodrin's AMD stream though.",
      "Looks like bequiet pure base 500.",
      "Yep! BeQuiet! Pure Base 500DX",
      "What case is this?",
      "YES! FALCODRIN! He's an absolute legend. I ended up finding FairGame, a bot used to fight back against scalpers on that stream and I was able to snag a 5600X",
      "My  RTX 3070 came with a support bracket, but I don't need it.\n\nthankfully not a problem for my a Silverstone FT02 case, with the vertical case orientation. Heat vents upwards.\nThe weight is supported by the PCI slot screw\n\nMore cases need to do this!",
      "So you have to buy a new one from them",
      "It sags a bit but the angle of the shot also makes it look worse than it is, probably.",
      "Cheap solution: suspend it with wire from top of the case. Fishing wire is transparent.",
      "How are your temps with your CPU and that cooler?",
      "GPU sag is unlikely to cause any functional issues. PCBs are designed to flex",
      "I just looked it up, ugh I hate how python always breaks its own backwards compatibility... (Needs 3.8, 3.9 breaks the program.) I honestly wonder why python continues to be popular when shit like this keeps happening, release after release, year after year.",
      "Because for those of us that write Python it‚Äôs a non issue to have multiple versions installed. You just use a virtual environment and create it with the needed Python binary, easy peasy.",
      "Unless you are completely blocking all airflow it won't affect temperatures. Cable management is purely for visual and maintenance purposes.",
      "I don't understand why GPU manufacturers can't include something that prevents the damn thing from destroying itself.",
      "Cinebench pushed it to 82C in MC, 63C in SC with just PBO and no other tuning. Clocked between 4.4 to 4.6ghz"
    ]
  },
  {
    "brand": "amd",
    "generation": "6000",
    "tier": "high",
    "matched_keywords": [
      "6800"
    ],
    "title": "AMD Radeon RX 6800 XT Performance Has Increased by Up to 9% Since Launch: Faster than the RTX 3080 at 1080p and 1440p",
    "selftext": "",
    "comments": [
      "Well this is good news just still waiting for a real price to pick one up.",
      "I'm not sure this data is comparing performance in the same games, or it's simply a case that more or different games are now being used for testing. It's probably worth noting that we tested with 18 games back in 2020, and our margins haven't changed: [https://twitter.com/HardwareUnboxed/status/1408975767535460355](https://twitter.com/HardwareUnboxed/status/1408975767535460355)  \n\n\nI noted that a lot of these review outlets were testing with less than a dozen games, so if they've since updated the games list this will change the margins a lot.",
      "First review of TPU :\n\n[https://www.techpowerup.com/review/amd-radeon-rx-6800-xt/35.html](https://www.techpowerup.com/review/amd-radeon-rx-6800-xt/35.html)\n\n6800XT is slower than 3080 by 6%\n\nLatest benchmark of  TPU (Geforce RTX 3070 Ti ) :\n\n[https://www.techpowerup.com/review/gigabyte-geforce-rtx-3070-ti-gaming-oc/28.html](https://www.techpowerup.com/review/gigabyte-geforce-rtx-3070-ti-gaming-oc/28.html)\n\n6800XT is faster than than 3080 by 1.81%\n\nsummary : since First review to now , 6800XT is improved by 7.81% more.\n\n&#x200B;\n\nedit: wrong math , It's 8.3%",
      "Until then the next ones are out probably",
      "That's 100% fine. My 5700xt is fine until I can get a 6800xt for msrp.",
      "It was faster below 4K at launch.  The only reviews which showed otherwise had far too few games to get a proper average, and/or skewed heavily towards nVidia-tuned titles.",
      "You love to see it. Apparently the latest patch was a big one, with a few percentage point gains from reading some comments.",
      "You may want to think about trading for a 6700xt. Apparently you can just trade 1:1 since it current value leans towards mining profit and not gaming performance. After prices (hopefully) drop the 6700xt resale should be a little higher than the 5700xt as it leans towards gaming again.",
      "Not quite. It started at 94% of the 3080 and ended at 101.81%, which is an 8.3% increase. Think of the 7.81% you got as a proportion of the original 94% :)",
      "Great, so when can I buy one for MSRP?",
      "Yeah that's my point, the games list is different. Anno 1800 has been dropped for example and Assassin's Creed Odyssey has been replaced by Valhalla which is a big win for AMD and they've added Cyberpunk 2077. They've dropped Project Cars 3 which was a really bad title for AMD.\n\nThen other changes include the addition of Watch Dogs Legion, the upgrade to Hitman 3 from 2, and the removal of Star Wars Jedi in favour of Squadrons. So a good number of changes there that completely invalidates the comparison.",
      "How much are we talking here?",
      "Faulty reporting.  It hasnt \"increased\".   They tested different games, a bunch of them AMD partenered ones - Dirt 5, Valhalla, Resident Evil Village which place the AMD cards ahead. And many outlets dont retest older cards that might benefit from driver and patch uplifts.  So the newer released cards get benchmarked with newer drivers and patched games while results for 3080 and 3090 are showed from last year.",
      "Maybe its worth doing another fine wine investigation",
      "True, but it also depends on what titles you're comparing. As well as what graphics settings you're using.\n\nMSAA in use? AMD's probably winning due to the incredible pixel fillrate of 128 ROPs combined with 128MB of cache.\n\nSuper-heavy volumetric effects? Nvidia's probably going to win due to the big FLOPS advantage.\n\nAs for FineWine, it's probably going to be less of a thing with RDNA and RDNA2. The strength of RDNA2 is that the chips seems to be very well balanced and utilized, which wasn't the case at all for GCN. Even at GCN's launch, AMD needed more execution units to match Nvidia. Going back 9 years, AMD's gone from 2048 ALUs with the 7970, to 5120 ALUs with the 6900 XT.\n\nAmpere on the other hand, is a lot less balanced than previous Nvidia generations. It even exhibits similarities with GCN where higher gaming resolutions perform noticeably better when compared against previous generations. Going back 9 years, Nvidia's gone from 1536 ALUs with the 680, to 10496 with the 3090.",
      "20-25% so it is like jumping up 1.5 tiers to something between a 2080 super and 2080 ti and your card sits a little below a 2070 super. If you look at ebay sold listings prices, you can potentially get another $100 cash during the trade too.\n\n\nYour current card is a solid 1440p card at high settings so even if you sit on it and not trade up, you at least won't be struggling for playable framerates and settings (unlike my gtx 980 that is struggling at 1080p medium settings on a 1440p144hz monitor).\n\n\nI feel you about the prices. A $1200 rtx 2080 ti equivalent should be $500 right now. Gaming is a hobby and paying 2-4x more than a console for a single part is one thing but paying up to 3x the MSRP of a card is insane even if I can drop $3k on a 3090 without any financial strain.",
      "Biggest con is, they are even harder to get than the RTX3080,  I've only ever seen 6700XT or 6900XT for sale irl mostly 6900XT",
      "Nvidia is years ahead in adoption, ML, hardware encoding, and software (CUDA).\n\n While RDNA 3 might be great for gamers, AMD has a long way to go with rocm and broader use case support before Nvidia will truly be threatened. \n\nRDNA3 will rock I am sure, but let's not get lazy!",
      "Thank you, I do love cake.",
      "I'm curious how raytracing performance is, that's a big thing for me"
    ]
  },
  {
    "brand": "amd",
    "generation": "6000",
    "tier": "high",
    "matched_keywords": [
      "6800xt"
    ],
    "title": "My 6800XT purchase from November was cancelled yesterday",
    "selftext": "I bought a reference 6800XT at MSRP from a UK store, and at the time was told I was in a preorder queue dispite the store saying there were no preorders. I was then told a couple days ago that Sapphire has discontinued making reference cards so I will never get my preorder fulfilled. To the store's credit they did offer me a discount on one specific card but I'm building in a Meshify C so most AIB cards are too long so I refused and was refunded.\nNow I'm just like everyone else 5 months into this mess waiting for a 6800XT to exist at remotely reasonable prices.\nGood luck to you all.",
    "comments": [
      "Would have been easier to get a different case and go with the card they offered IMO.",
      "Should have just taken the discount on the other card, and traded it for a reference model or something in your local area for the price difference.",
      "I have an sffpc and you can be damn sure that if I got the chance to get a full lenght 3000 series at msrp I would've changed cases to one that allows a longer gpu.\n\nGot a good enough deal on a 2 fan 3060ti so I didn't have to do that",
      "Man, you wouldn‚Äôt be profiting if you just bought it and traded for something else at MSRP. At this point, just getting any card in your hands should be the goal. Then go over to r/hardwareswap and get yourself the card you want...",
      "I have absolutely no clue why he thought it was a good idea to refuse the different model knowing just how shitty the market it is right now over a case; It's going to cost him MUCH more to get any other card than it would have to just get the card now plus a Meshify 2 to replace his Meshify C.\n\nI can't even blame the retailer in this case, since they gave OP a very reasonable option and he decided to be obtuse for the sake of being obtuse.",
      "The worst part is that the sapphire models aren‚Äôt too long for the Meshify C as long as you put the hypothetical AIO at the top instead of the front, so he gave up the card for no real reason...",
      "some people just dont think no point in doing it for them.",
      "That's not a vote of confidence from your retailer.\nDid they just have a 90 day cron that cleans out old orders to keep the books tidy fiscal period to fiscal period?",
      "That feeling when you reject a rx 6000 card because it doesn't fit in your case:",
      "massive facepalm on OP's part",
      "I'm sure like most people they get locked into an idea or upset about the current issue they close off their mind to any other possible changes they could make to improve the situation because it wasnt their fought and blame was on the store.\n\nNowadays consumers gotta learn to take responsibility because stores are handcuffed by things mostly out of their control.",
      "Well, perhaps the OP didn‚Äôt want the hassle for trading the card ? Idk, also most the of the deals are made in the US, op is from the UK, if something goes sideways it‚Äôll be a mess",
      "Pretty sure most online retailers have a policy that any purchase that isn't shipped within 90 days is voided. Hell, even scale model figurine websites have this policy.",
      "came to the comment section to see OP getting roasted and i gotta say, i‚Äôm not disappointed",
      "According to Fractal's own site, the Meshify C can hold a 315mm long card with a full size front fan installed. If you were to install a slim front fan, you could get that up to 325mm long. Did you check the length of the AIB? There are only a few 6800 XTs that would qualify as too long for that case.",
      "Sorry to say but if they offered you a card at a discount, should've changed cases",
      "If they're out of stock then the prices are imaginary anyway.",
      "It's like rejecting a pallet of money because it doesn't fit in your wallet. OP is obtuse.",
      "The Mesh C is massive...I don't even understand...I fit an AIB 3080 into a 12L case with 240 AIO\n\nThis is some pepega stuff here my dude.",
      "Id say its a significantly larger hassle to not have the gpu, and have to wait for the prices to go down and get one then, rather than making a post on a reddit."
    ]
  },
  {
    "brand": "amd",
    "generation": "6000",
    "tier": "high",
    "matched_keywords": [
      "6800"
    ],
    "title": "Powercolor Red Devil RX 6800 Series",
    "selftext": "",
    "comments": [
      "ENOUGH WITH THE TEASERS",
      "They think it's much more of a big deal than it really is. 90% of us just want any 6800xt chip and will stick it in a case which itself hides the look.",
      "40 and I want my shit to glow like a unicorn on molly.",
      "wow it got fans! next  level",
      "Just show it, ffs.",
      "Yeah it *can* definitely be an age thing. I'm 33 so I have my case literally behind my desk where you cannot see nor hear it. However, I've been building rigs since I was 13 and I've never wanted RGB. For many years my computer was my only way of watching movies in my bedroom and who wants laser lights lighting up the room during a movie or when trying to sleep?\n\nJust need the shit to work and not fail, and not be super loud.",
      "49 here.  These kids don't know the beige world we came from.",
      "So sapphire and XFX have been teased, now Powercolor. I take it Gigabyte is tomorrow, Asrock on Sunday, MSI on Monday and ASUS on Tuesday?",
      "It is composed of..... Only Fans ;)",
      "32 here, I try to buy parts that don't RGB",
      "Can we just get a product page with a release date? This is annoying and pointless.",
      "Cringe!",
      "51 and I have a case with RGB on full display in my living room. White and red at the moment, but I can switch it to whatever color and whatever effect I want. All of this anti-RGB sentiment is getting ridiculous. There is nothing wrong with it. Blast unicorn vomit to your heart's content or switch it all off. It's up to your own personal preference.",
      "Well, at least Sapphire has the cards up on a product page with specs, so they are past the tease phase. Gigabyte, ASRock, MSI and Asus have already done their teasing.\n\nXFX and Powercolor are the last ones out of those where they've only shown snippets of the cards. The other ones at least they've shown the whole thing.",
      "Petition to ban these fucking things from the sub. They have absolutely no purpose! I feel like I'm taking crazy pills.",
      "No they do not. Beige cases with beige mice and keyboards and beige CRT monitors.",
      "All I want is an AIB card that will fit in my NCASE (as long as it's not an iffy brand). So far my last hope seems to be Powercolor, if not that I guess I try to get a reference card.",
      "AMDRewards codes are getting wild.",
      "If this bothers you to this extent, then yes, you are taking crazy pills lol.",
      "A bland looking GPU would be a nice change of pace for me over the ultra gamer aesthetic many seem to be going for."
    ]
  },
  {
    "brand": "amd",
    "generation": "6000",
    "tier": "high",
    "matched_keywords": [
      "6800"
    ],
    "title": "AMD Radeon RX 6800 XT up to 12% Faster than the NVIDIA RTX 3080 in Unreal Engine 5 Demo w/ Lumen Based S/W Ray Tracing",
    "selftext": "",
    "comments": [
      "Why not just post the Digital Foundry video. You can gain a ton more info out of there than from this article that is poorly written and not even accurate in some stuff.\n\nFSR is not even used in the demo.",
      "Because OP is the writer. I have pointed out some of his mistakes in the past as well.",
      "\"...at the 1080p Epic setting with FSR upscaling to 4K.\"\n\nWhile that's nice I suppose, I was really looking to see that claim be at native resolution. I mean, hasn't the 6800 xt already been shown to outperform the 3080 at 1080p? Plus I would certainly hope the 6800 xt makes use of fsr better than Nvidia would considering its an AMD developed upscaling solution. All in all a bit disappointed in the article.\n\nEdit- The article is misleading. As pointed out, FSR wasn't used.",
      "If it has to run fast on consoles, it's going to be well optimised for AMD hardware.",
      "Taken straight from the article: https://www.hardwaretimes.com/wp-content/uploads/2021/06/image-20-1024x540.png\n\nIt's TSR, Epic's engine upscaling, not FSR.",
      "People have been saying this for a decade already and yet we still get games that run faster on Nvidia hardware.",
      "Nvidia puts in a lot of work to help devs optimise for Nvidia hardware, to be fair. So that‚Äôs not surprising to me",
      "https://youtu.be/C99VwDGyLg0",
      "Dear lord, what a clickbait headline this is.\n\nAlso, 75 fps at native 1080p is pretty depressing stuff. Between that and the \"this only works on stationary objects\" thing, let's not all jump on the software raytracing just yet.",
      "Not sure why you are downvotes, this was literally done and shown with hidden tesselation for example.",
      "And slower on amd",
      "And u didn't post the link either? üòÇ",
      "The article is just blog spam, Digital Foundry video is source.  They never mention FSR because its not using it.  Its TSR.. but its just like improved TAAU... which is fine.. like DLSS is an improved TAAU.  But nothing to do with FSR.",
      "Do you have a link?",
      "And not using dedicated RT hardware...\n\nThis is like a one legged man challenging a two legged man to a race and then tying the other guy's legs together.\n\nIn the real world AMD isn't even close at RT performance.",
      "Why is he being downvoted? Someone else confirmed that it was TSR below",
      "You're missing the point because you didn't read the article. The article suggests this demo uses FSR which is false.",
      "I mean, they literally tested it in the demo and yeah, the 10900k was getting a higher fps.",
      "GHz =/= single-core performance. I guess the word 'speed' is throwing people off here?",
      "It IS Unreal Engine 5's Temporal Super Resolution. The video this article took the information from deliberately points it out multiple times.\n\nBut this is Hardware Times we are talking about. Quality journalism isn't something you should expect from them."
    ]
  },
  {
    "brand": "amd",
    "generation": "6000",
    "tier": "high",
    "matched_keywords": [
      "6800"
    ],
    "title": "Zen 4 build. R9 7900X + RX 6800 XT",
    "selftext": "",
    "comments": [
      "Fans cost more than most people‚Äôs builds",
      "Dude bought a 7900x+x670, good value isnt a concern to him",
      "seems like >$550 in fan cost if you include tax lol",
      "And they aren't even that good!",
      "Are the fans next to the mobo tray reverse flow (airflow away from motor mount side)?",
      "I'm surprised your case doesn't hover off the ground with all of those fans lol. Nice build!",
      "Very nice! Looks like we both jumped on the 7900x bandwagon. I decided to air cool mine which I haven't done since 2008 so that's been fun.",
      "Yep... Marketing sells lmao",
      "People who don't care about rgb save so much money. You can usually pick up the 5 pack of Arctics 120mm fans for like 40 or $50 Canadian and they're such a good value. Good air flow and very quiet.",
      "The fans next to the motherboard are in a push pull configuration to cool the GPU AIO rad so they take air from the front fans that are intake and exhaust it to the side of the case. Bottom and front fans are intake. Rest of the fans are exhaust. There are 15 Lian li SL Infinity fans total in this case connected to 2 SL controllers. And 3 noctua fans on the top CPU AIO rad that is also in a push pull config. 18 fans total in the case.",
      "Hello there. The PSU is a ROG Thor Platinum 1200W.",
      "Lol powered by the gods themselves build looks great man someday i hope to get one that nice",
      "What power supply you have in this beast?",
      "I don't think its necessarily bad, I'm looking to get the same (but waiting first to see if B650 will bring any atx 2-dimm boards first - there were tachyon rumors but we shall see).\n\nOtherwise 7900x fits my needs exactly and the board well, that's the only chipset currently available.\n\nBut out of curiosity what did you mean by good value? What it seemed to me when I was laying all this out - the 5000 ryzen chip upgrade would've been maybe $300-400 less (ram cost is negligible since it seemed like good binned ddr4 for ryzen costs similarly to hynix m-die <ddr5>, this may not be optimal value per cost but I enjoy the OC), however the cpu performance uplift seemed worth it for tasks - this of course varies per person but just goes to show that it is maybe harder to judge \"good value\".\n\nedit: but also yes excessive shiny fans are expensive but it does look nice :)))",
      "Looks like you ready for 2025 CPU & GPU Cards",
      "I am sure you will. Post it here then so we can also appreciate it. üëç",
      "Might be a couple months away on that but im hoping these prices drop some more",
      "so i  dont understand the logic of the side exhaust, wont that pull alot of the fresh air from the front directly back out?",
      "Lian li dynamic XL I believe.",
      "How does the air cooler perform? I also ordered a 7900x and would like to use a air cooler. I was thinking either the nh d15  or dark rock pro 4 on a fractal design torrent with stock coolers since I can't really find other 180mm fans"
    ]
  },
  {
    "brand": "amd",
    "generation": "6000",
    "tier": "high",
    "matched_keywords": [
      "6800xt"
    ],
    "title": "3070 order delayed/ cancelled, 6800XT here I come!",
    "selftext": "So I guess Best Buy couldn't even get the 3070 stock in that they were promised. My order that actually went through was just marked as delayed and if they don't fill it by the 20th they will be cancelling it. I was already feeling like AMD might make me regret my decision as I want to play some games on my 4k/120 TV. I hope AMD can have the stock to make fools out of Nvidia, because I want a 6800XT!",
    "comments": [
      "If AMD can beat Nvidia on supply, just think of how much market share Nvidia will lose simply due to not being able to meet demand. I'm in the same boat, to be honest. Will go either way depending on what I can get fastest.\n\nAlthough the shared memory feature of Ryzen & Radeon paired together makes me lean more towards AMD now...",
      "Samsung 10/8nm is low yielding. through and through a paper launch to get some attention off of amd. yield problems for this node has been known since 2017... (8nm is a 2018 refresh of the 10nm node, also low yielding).\n\ntsmc 7nm+ actually has yields to back up demand. and is newer with higher quality.\n\nedit edit: amd group stepped up, I was -1 karma for pointing this out.\n\nit's not hard to find info on the Samsung 10nm yield problems... one commenter said \"back up your claims\", how hard is performing a Google search yourself?\n\nhttps://www.electronicsweekly.com/news/business/samsung-tsmc-hit-poor-10nm-yields-2016-12/\n\nhttps://www.xda-developers.com/report-unsatisfactory-yield-rates-for-10nm-finfet-process-pushing-back-smartphone-schedules/\n\nhttps://www.slashgear.com/low-10nm-processor-yields-could-delay-high-end-smartphone-06477200/\n\nhttps://www.extremetech.com/gaming/315898-nvidia-rtx-3080-and-3090-shortages-likely-to-persist-into-2021\n\nhttps://www.guru3d.com/news-story/nvidia-allegedly-moving-ampere-to-7-nm-tsmc-in-2021.html\n\nhttps://fuse.wikichip.org/news/1443/vlsi-2018-samsungs-8nm-8lpp-a-10nm-extension/2/\n\nhttps://www.techradar.com/news/you-might-have-trouble-getting-an-nvidia-rtx-3080-or-3090-until-2021\n\nhttp://www.worldpronews.com/39224/1178/290/26f31dce9cf105e05c66d2b4fed68cab7f86a2a4",
      "Yeah I think the shared memory is a super cool feature, but I don't think it's something that will get me to ditch my 3700x for awhile",
      "Only works with 5000 series chips and a 500 series MOBO",
      "I'm far more optimistic that TSMC can pump out the chips but they're also massively booked by others as well so it makes me wonder what kind of sustained production they'll be able to achieve over time after their initial front-loaded stock gets depleted in 6 seconds by bots.",
      "Wish you luck because they will sold out soon after launch.  You're more likely to see the 3070 back in stock before the new 6000 series (obviously released first)",
      "I was rooting for Samsung to do well with Nvidia tbh. I think in the next 5 years, TSMC could have a monopoly on the industry with Apple, AMD, and Nvidia. Some competition could be good for everyone.",
      "3070 had much bigger supply, but i assume it also had much bigger demand.",
      "It doesn‚Äôt work with the 3700x?",
      "TSMC 7nm yields are kinda godly tbh. TSMC is doing something very right",
      "I think you're under representing the demand for Ampere. Nvidia is the go-to graphics card manufacturer regardless of if AMD is making up ground.",
      "With all the hype around modern GPUs and their improvement over last gen, the real winner is anyone who gets a next gen AMD or Nvidia card in their system this year.",
      "Even if AMD beats Nvidia on supply, the demand will be even higher, so it won't matter.\n\nI'm 100%  sure that Big Navi demand, especially for 6800XT will be higher than Ampere, and AMD can't do any magic that'll have any supply for that.",
      "The amd supply isn't going to be much better according to rumors",
      "What if the 6800XT is sold out too and you can‚Äôt get it? Are you just gonna not get a gpu?",
      "Please keep your 3080 orders!!!  I want to have a better chance of landing a 6800XT on launch.",
      "Meaning I'll be able to do this with my 3700x and B550 MOBO?",
      "I have a bad feeling, it will be the same for the 6800 series. Not because of TSMC yields, but because of PS5, the new XBox and Ryzen 5000. All releasing at the same time.\n\nI'm in the same boat, preordered a 3080, will try to (pre)order a 6800XT on lanch day and whatever arrives first will be kept. Both cards will be great.\n\nRyzen 5000 release on thursday might be a good indication about possible supply issues on AMDs side, even though CPUs are a bit different i believe.",
      "I'm wondering if Nvidia's supply bottle neck on the 3080 is Samsung making the GPU or micron making the gddr6x.  If we see 3070 (which uses normal gddr6) availability normalize faster than the 3080 it would make me suspect the gddr6x is what's holding back the 3080.",
      "i would say samsung. there have been a lot and long rumors about problems with samsung 8nm. dont forget 3070 isnt the same die as 3080 and 3090. 3070 is smaller and easier to make. \n\nsoon after 3080 launch there was a picture either from chip manufacturing lab or card manufacturing lab, of a 3080 cards or chips in testing. failure rate because of cooling was over 30% i think. that means at least 30% of tested chips didnt qualify as 3080 because they need too much power and cant be cooled properly if chips are running at advertised 3080 frequencies.\n\non other hand, the gddr6x maker had basically 0 rumors about problems with its manufacturing, and as other pointed out in older topics, they were making quite many very high speed ram chips, that would indicate their manufacturing process is in good shape. i know, its not quite the same because gddr6x isnt a industry standard but something memory company and nvidia made together for nvidia, and it doesnt automatically make gddr6x production yield quality as the ram chips they are making. \n\nbut from all the rumors floating around, i would say samsung is the issue, kinda. because there is also a rumor than nvidia is buying limited amount of big chips until samsung improves yields. i am not sure how this works and why nvidia would have to pay for defected chips and not just good ones, but thats the rumor.\n\nanother bad sign for samsung as culprit is that Ampere architecture, similar as Turing, has one of the worst performance jumps in generation in nvidias history. and it is with a node jump, from Turing at TSMC 12nm to Ampere at samsung 8nm. since Ampere launch, many are saying that samsung 8nm is not a a big jump for silicon from TSMC 12nm. \n\nfor full truth we will probably have to wait a few months though"
    ]
  },
  {
    "brand": "amd",
    "generation": "6000",
    "tier": "high",
    "matched_keywords": [
      "6800"
    ],
    "title": "RX 6800 positive experience makes AMD GPU's hate hard to understand",
    "selftext": "I have owned an RX 6800 (PowerColor Fighter) since December 2022 and I just want to say that it probably is the best card I have ever owned, firstly thanks to its performance (relative to its contemporary competition), secondly for not having issues with it contrary to general opinion about AMD GPU's and thirdly for its value for money (425 EUR, second hand, 2 years of warranty left). \n\nI use it on an AM4 platform with a 5800x3d for 1440p gaming and I have never noticed anything majorly fishy during all these months. In recent times I have owned an RX 3070 (positive feelings as well) and an RX 6600 XT, which gave me some headaches because of ReBar Z390 compatibility issues, I'll admit, but I managed to get the best of it in the end. \n\nPositives for you with this card or rather a negative experience?\n\n\\*Since 2002 I have owned 8 GPU's (4 Nvidia and 4 ATI/AMD), so non-partisan consumer here. \n\n&#x200B;\n\n&#x200B;",
    "comments": [
      "Went from a r9 390 to a 1080ti to sapphire pulse rx 6800, all great cards honestly.\n\n\nNever had a problem with either brands.",
      "What hate ? Doesn't most of Reddit recommend the rx6700 and rx6800xt as the gpu to get ?\n\nPeople go for nvidia because it's either all they ever know or they really need ray tracing, upscalers and CUDA. Personally I can't stand upscalers(only game at 4k native) and the games I play either don't have ray tracing or it's an half assed attempt of it's implementation that changes very little, so radeon was the only logical option.",
      "This is a bit of a ramble that doesn‚Äôt really have much to do with the RX 6800 and more to do with AMD cards overall, but I guess this all comes down to that user‚Äôs personal experience. For the most part I‚Äôve only owned ATI and AMD GPUs, integrated and discrete. I‚Äôve had the odd Intel iGPU (and a couple of Arc cards) and the odd Nvidia GPU, but by and large, I have a love/hate relationship with AMD given my varying experiences of their cards. \n\nLargely, you can boil down a lot of peoples‚Äô frustrations to drivers, power consumption and/or performance in a given scenario. Bad drivers are something I experienced first-hand on my R9 Fury X, which didn‚Äôt work on the Adrenalin 2020 drivers until the August 2020 drivers - and it took the final legacy driver patch in June 2022 to make official post-2019 drivers usable on it. I know drivers have burned a few people that I‚Äôve talked to (predominately those with cards that AMD has neglected on Windows, like the discrete Fiji and Vega cards), but at the end of the day, your mileage may vary. \n\nAnd that‚Äôs what it boils down to: what does your setup and use case play nicer with? I had an RTX 3060 and while it was a performance uplift from my Fury X, I felt massively disappointed by it and decided to go back to AMD to get a 7900 XT. Outside of instability from my card‚Äôs high boost clock that I‚Äôve had to fiddle with (2850MHz), I‚Äôve been massively satisfied by it - and I don‚Äôt think I could‚Äôve said the same about an RTX 4070 Ti for myself. This could very well go vice versa, too - I have a 4K monitor, which really leans into what the 7900 XT does best, but if I was gunning for HFR 1440p gaming, I could‚Äôve lived with the 4070 Ti easily.",
      "A lot of people still dont buy AMD because the hate of the years ago are still somewhat in their brain.",
      "I went from R7 370 to 1660 Super to 6800xt.\n\nNo problems here either.",
      "I've had many cards from both companies. My experience was similar on both sided with pros/cons and minor issues at times.\n\nI love AMD for it's superior gpu software and interface (for my needs), but I like Nvidia for DLSS and better ray tracing (I don't use it much, but it's nice to know it's there when I do).\n\nI'll buy whatever feels like the best deal at the time, but I have a bit of a soft spot for AMD due to them making adaptive sync affordable.",
      "I ran Nvidia since 2008 till this year, it's the only GPU and software for that GPU that I really knew. It was a leap of faith that my RX 6750XT wouldn't mess up for fail me on what can honestly be a varied selection of games I play. Maybe there would be crashes or driver errors or whatever and maybe it was worth the $50 more to just get a 4060Ti and play it safe. \n\nIt has been the most boring fucking transition ever. I set it up and forgot about it as it just runs flawlessly if not better than my Nvidia card as I didn't have to scrub through emails to remember my login for geforce experience this time.",
      "The only thing I know that I'm missing is better RT. Some games it be nice to have a better playable RT experience. With my 6900XT, I generally just leave it off. Even with FSR2, the fluctuations are too extreme even when it seems playable. 80/90fps one second down to 35/45fps the next second. \n\nThe only upside is RT ATM overall seems meh. Not very noticable to me in SpiderMan or Fortnite and Hogwarts is so rough around the edges it isn't worth having on. \n\nGames I want to have RT, like Stray or DRG, don't sadly. \n\nThough it seems like RT on RDNA3 is greatly improved. \n\nOtherwise I'm happy with my pick. Maybe if I go Nvidia I'll notice more of what I am missing. I had upgraded from a GeForce 1660S. But at the end of the day I am still mostly focus on the most raster performance I can get for my money. When I got my 6900XT it was during the crypto boom so comparable Nvidia was like 600-800 dollars more at the time.",
      "I swore I would never buy a ATi/AMD card ever again after several bad experiences in the past. But the Covid shit show forced me into buying a RX 6800 XT. And it's been a great overall experience. No driver issues, great performance and the software experience with adrenaline is much better than what team green is offering. And considering how Nvidia is pricing their stuff now I think I will be sticking with AMD for the foreseeable future.",
      "Reddit loves AMD cards tho. So do all my YT suggestions i get.\n\nBuilt a new PC recently, 6800XT was the most suggested card everywhere in the price range i was looking.\n\nI decided to go with the 4070 in the end, but i really like that we have options to chose from. \n\nPower consumption plus more expensive PSU are not always counted in the comparisions tho. That was the deciding factor for me.",
      "Not as if nvidia were not just as hated (if not more) at different times.  \n\n\nI guess for a lot of people it might be the attitude around when they go their first machine.  \n\n\nMaybe I go more AMD since ATI was my third \"3d\" card, voodoo 1 add on being the first, but then again I have been nvidia a lot too. Hey my current laptop is (not that it gets used as much!).",
      "A lot of them hating on it have probably never tried DLSS themselves tbh",
      ">are we dealing with an irrational consumer\n\nNo. Most consumers like DLSS, Reflex etc and it is usually worth the extra $50-$100 over the AMD alternative. Most people also buy prebuilts, which almost never feature AMD cards.",
      "The problems people have with AMD are the fact they aren‚Äôt much cheaper than the Nvidia alternative and are lacking features. DLSS is sorely missed on AMD and they don‚Äôt even have an answer for framegen so going forward they are going to have some competition problems.\n\nThey aren‚Äôt bad cards, but there are some frustrating things. Issues with DXVK on older games, people having issues with VRR, Dolby Atmos issues, etc.",
      "The reddit cloud loves and hates on them. The reality is Nvidia has the mind share so the world outside of reddit really doesn't care. They buy Nvidia, it works, they move on. Without something to generate a lot of buzz, AMD feeds their niche in the GPU department and tries to claw back any ground they lost over the last decade. Last I read steam surveys had them at 8% market share and combined with other sources a high estimate of 12% is possible. \n\nI personally love the reddit AMD crowd. They're over zealous sometimes but hopefully Intels next GPU round does better and we get more people realizing there are alternatives. Nvidia sitting pretty at 90% market share and legions of investors isn't good for anyone in the consumer segment. We need all the viable options we can get.",
      "Nvidia is really driving the GPU industry with a huge investment in R&D, that's why. CUDA, Optix, RT cores, Tensor cores, DLSS, DLSS-FG for example.\n\nAMD is always responding, ROCm, HIP-RT, RT cores, WMMA instruction, FSR 1/2, FSR3, so while their raw raster performance is certainly up to snuff they're typically at least a generation behind on all the other bits.\n\nMost *gamers* don't care that much beyond raw raster performance so that's why AMD is such a good option in that space.",
      "Same, I've had an RX 480 and now an RX 6950...   Nothing but good experiences outside of Windows Update causing driver issues with Adrenaline Software...   But that's because Microsoft removed the option to disable automatic driver updates in the Windows Updater...\n\nDriver stability and issues are slightly better than my experience with Nvidia over the same period.",
      "sis kid had a 6800 soon 3 years, he is happy and me with a 6700xt runs stuff perfectly.\n\nvery few writes on social medias usually so ignore them works",
      "Funny enough you can not even use RT in any lower end Nvidia GPU because u run out of vram and they end up losing to AMD in many RT scenarios.\n\nYeah the freesync was amazing for AMD to open that up.\n\nAMD has done a scummy thing on Freesync is that they make freesync over HDMI (not the vesa standard in 2.0 and above) an AMD only thing and refuse to open it up.",
      "Why should anybody care if DLSS is a ‚Äòstandard‚Äô or if it‚Äôs open source?"
    ]
  },
  {
    "brand": "amd",
    "generation": "6000",
    "tier": "high",
    "matched_keywords": [
      "6800xt"
    ],
    "title": "Minor update here. GTX 970 to a RX 6800XT Red Devil",
    "selftext": "",
    "comments": [
      "Awesome! I too had a GTX 970 (MSI), though a Sapphire RX 6900XT popped up for me! How are you liking the switch from Nvidia to AMD? It's been nothing but improvements across the board for me, but I still need to get around to streaming, video editing and Blender.",
      "I got the card this Wednesday. On Friday I went on a business trip so I wasn‚Äôt able to do some testing yet. The AMD software is far more complete than Nvidia‚Äôs and this beast is so powerful that some games I play, the fans don‚Äôt need to turn on even at high frame rates.",
      "When I got my first Nvidia card last year (3060), I was pretty surprised how much worse GeForce experience was compared to the Radeon/Adrenalin app. I just assumed Nvidia‚Äôs default software would be way better but it‚Äôs actually pretty underwhelming haha.",
      "I have the same card except its a 6700xt. With those phanteks neon rbg strips it looks really sexy! üòÄ",
      "That‚Äôs an even bigger jump than I made. I went from a FuryX to a 6800XT. Enjoy!",
      "look up \"rnnoise\" there are many forks for many different applications for it. it's free and open source.\n( one fork for example is for use with general windows equalizer apo https://github.com/werman/noise-suppression-for-voice )\n\nif you want a \"commercial\" solution then \"krisp\" would be the way to go. they do ai based cancellation and there is also a free version, i am not sure about the limitation tho. -> https://krisp.ai",
      "I went from nvidia to amd with a 6700xt and the AMD software feels way better, the only thing I miss is the Nvidia rtx voice, that shit completely blocked out my loud ass keyboard and random background noise. Is there an AMD alternative to that software? I'd pay for it if I had to",
      "As an nvidia GPU user I don‚Äôt even use the GeForce experience app lol. I just use the standalone drivers.",
      "> I know everything don't bother\n\nlmfao",
      ">How are you liking the switch from Nvidia to AMD? It's been nothing but improvements across the board for me\n\nI have no allegiance to any manufacturer, but it's important to note that any improvement you're seeing should 100% be **because you've upgraded to a far newer and more powerful graphics card**, and nothing at all to do with changing from Nvidia to AMD.\n\nI've not decided what my next graphics card will be yet, but I've never had an AMD graphics card, and I still occasionally see bad stuff about their drivers, which puts me off a bit tbh.\n\nI'm happy with the move I made from and Intel 2600K to an AMD 5900X, but there are still some issues which I feel AMD haven't properly addressed yet (hopefully it's a matter of \"when\" and not \"if\"!)",
      "Smaller node means much smaller heat density, concentration in a single very small spot vs high spread area",
      "I'm moving from 2080 to 6800  (XFX Merc) - your jump must feel huge\n\n1440?",
      "FWIW, ReLive is my one major complaint with AMD's software. Shadowplay is *so* much better by comparison.",
      "Same card I have here (in 6900 XT flavor). Boyo you are about to FLY! Enjoy man!! Cheers",
      "I wasn‚Äôt able to test yet. My plans is to hook it to my 4K OLED tv :D",
      "Now you'll know what having more than 3.5gbs of vram is like.",
      "It does! Sadly my strips got some weird color strains in white and blue colors after 3 months of use. But the red looks totally amazing.",
      "IIRC those can be rmad, id give it a try. They have a high failure rate, or at least they had.",
      "same. went from gtx 1070 to rx 5700 xt and now back to rtx 3070 ti. it‚Äôs not even a matter of opinion it‚Äôs just a fact that shadowplay is so much better. plus nvidia has a better encoder",
      "Massively more power efficient, double the VRAM. Supports open standards like FSR, SAM. \nBetter driver tools for overclocking. \n\nNVENC is the single item that‚Äôs a true trade off, and it‚Äôs relevant to basically 1% of users."
    ]
  },
  {
    "brand": "amd",
    "generation": "6000",
    "tier": "high",
    "matched_keywords": [
      "6800"
    ],
    "title": "Sapphire RX 6800 XT Nitro tease",
    "selftext": "",
    "comments": [
      "Looks really good so far. Pls no weird color accents.",
      "I mean, nothing's stopping you from turning off RGB on RGB components, meanwhile, you can't turn on RGB on shit that doesn't have it in the first place. \n\nOptions are always better, that's what PC gaming is all about.",
      "Came to say the same thing, please leave it stealthy/normal looking.",
      "Sapphire Nitro cards are always the best on when it comes to Radeons. I'm hyped.",
      "Fuck RGB, let Monochrome rule supreme.",
      "Yes. I pay thousands and thousands of dollars, it has a glass side panel and I want my things to look aesthetically pleasing. I'm quite frankly astounded that you could even ask that question 'genuinely', like it's some big mystery that people want their things to look nice?",
      "these \"teases\" are so tiring, it's just a fucking GPU",
      "Not even, it's 3 fans and some plastic. Or a rendering of them.",
      "That‚Äôs a very interesting fan blade design, I‚Äôll say that much!",
      "Dis looks gorgeous",
      "It looks like 2.5 slots from the image.",
      "So, one huge fan on one end, and two same sized fans on the rest of the cooler.\n\nI wonder how big this cooler is going to be vs the reference design.",
      "I personally miss the crazy Vapor-X models...",
      "The only \"tease\" will be the 3.5 seconds these GPUs will be in stock before getting scooped up by bots.",
      "Might as well ask why people care how their clothes look, or why anyone cares about art, music, or poetry.\n\nI don't understand how anyone can be genuinely puzzled as to why anyone wants anything to be as pleasant as possible.\n\nIt's not a problem to not care what your hardware looks like, but it's also not a mystery why anyone would.",
      "I'm with you on that.  I've got a closed case and I never see my card, but I don't mind a bit if there's RGB on it for folks who like that stuff.\n\nThough it does make me wonder a bit what a fully utilitarian card might look like.  Just all function dictating form, no nod to aesthetics at all.  I think I might like to have a card like that.",
      "VaporX and Toxic. They‚Äôre gonna happen",
      "I‚Äôm waiting for the 32GB heavily overclocked toxic 6900xt.",
      "Hope the rx 5700 xt gets a price drop when this bad boy comes out.",
      "Please be a 2-slotter. üôè\n\nITX needs some love."
    ]
  },
  {
    "brand": "amd",
    "generation": "6000",
    "tier": "high",
    "matched_keywords": [
      "6800"
    ],
    "title": "First GPU Upgrade in Five Years: GTX 1080 to RX 6800 XT",
    "selftext": "",
    "comments": [
      "Next you should go after a 5800x3d...that will be a huge upgrade for your gpu and cpu on one platform. Like a generational jump. Pretty crazy",
      "That's the plan, eventually.  My computer budget is used up for a few months, though I think it was money well spent.  I got the 6800 XT for $570 new from Amazon back in December (though it took a month to arrive), and before that, I upgraded my old 2560x1080 75hz Ultrawide to the HP X34 3440x1440 165hz Ultrawide for $400.\n\nHopefully there will still be some good deals on the 5800x3d a few months from now, rather than stock shortages and price jumps from people buying them up...",
      "Almighty frame rate unlock! As others have said, bang in a 5800X3D and you're set for another 5 years. Very neat setup you've got as well.",
      "Specs:\n\nCPU: Ryzen 7 3700x\n\nCPU Cooler: Fractal Celsius+ S28 Dynamic X2 280mm AIO\n\nGPU: XFX 6800 XT MERC Core @ 2550/2150 1035mv\n\nMotherboard: Asrock x570 Taichi\n\nMemory: GSkill Ripjaws 32GB DDR4 @ 3600\n\nPSU: Fractal Ion+ 860W Platinum\n\nCase: Phanteks P600s\n\n[Timespy Graphics Score 21136](https://www.3dmark.com/spy/34892327)",
      "I recently seen 5800x3d for 274 at a microcenter ([link](https://www.reddit.com/r/buildapcsales/comments/10mejzp/cpu_amd_ryzen_7_5800x3d_27499_29999_25_new/)) but I think the extra discount is for new customers. Still seems like a great deal. I'm hoping it goes near 250. That could be a striking point for me.\n\nI also recently got a 6800xt (the red devil one) and wasnt sure yet if I want to get the 5800x3d now or wait since it could be the best for the current platform I am on.",
      "I'm no fortune teller but I think the 5800x3d won't get much lower. It's basically endgame for am4 so people with am4 boards will continue to buy it and AMD will move on to produce am5 stuff.",
      "BTW I love this phanteks case and congrats on the upgrade",
      "Your PC specs are almost identical to mine (I still have a 1080). How is the 6800XT? I'be been thinking about buying this GPU for some months.",
      "Overall it's been great.  For general gaming, it's over double the performance I had with my 1080.  I got a 3440x1440 ultrawide monitor last year, and the 1080 was still putting up a valiant effort thanks to the release of FSR, but now I can crank settings to max or near-max in most recent titles at native resolution and get 60+ fps.  It even does pretty well with light raytracing.\n\nDriver-side, things have been a little spottier.  When I first installed the card, I installed the (still) newest 22.11.2 drivers, and got video playback issues in Firefox and some driver resets.  I happen to be on Windows 11, and in its \"infinite wisdom,\" automatically installed a recent beta driver shortly after I installed 22.11.2.  Normally I would be annoyed, ...except the beta driver is running beautifully.  Youtube playback on Firefox is fine ...up to 1440p 60.  4k playback is choppy, but doesn't black screen or do anything wonky.  And 4k HDR youtube plays fine through Edge and Chrome, so, meh.\n\nI'm rambling.  TLDR: some driver kinks that might pop up, but when things work smoothly, performance is amazing.",
      "Thanks!  This Phanteks case was the first really modern case I've owned.  I bought it when I switched platforms to Ryzen back in 2020 and it made managing cables a breeze.  And yes, sometime this year, hopefully sooner than later, I'll be looking to get a 5800x3d.  That should keep me set for the next several years, as you and others have said.",
      "That‚Äôs crazy‚Ä¶ here in the middle of Europe the cheapest 6800XT sits at 700‚Ç¨ (incl. VAT). For 970‚Ç¨ you‚Äòd get a 7900XT‚Ä¶\n\nYou can basically decide between spending a lot and overpaying for the newest gen or spending less but still overpaying for an older gen.\n\nLast week a friend asked for advice for upgrading from an GTX 1080 with a budget of 700‚Ç¨ and the only thing I could tell him was ‚Äûraise your budget or stay put for the time being‚Äú.",
      "Ha, I did a very similar upgrade...had a 2600x and 1080ti, bought a 3440x1440 ultrawide and couldn't drive it properly so thought...time for an upgrade. Bought a 5600x and then 6800xt (Red Devil) and am so impressed with the improvement. 6800xt is a beast.",
      "I also have a 3700x but for someone who also values some workloads, would the 5800x3d hurt me there? I been using my 3700x at 4.4 ghz stable for almost 4 yrs but was thinking to upgrade to 5700x. However, I heard it's not much difference if I did upgrade to 5700x. \n\nWhile thinking about the 5800x3d, I understand that it's better for gaming. I just worry about the workload on editing and basic things.",
      "How's 6800xt handling 2k ultrawide? How often do you hit 100fps+, or is it just hovering around 60? I was considering this GPU as i have the same specs for the screen, but i was worried a bit about future proofing.",
      "Pretty sure you would see a pretty massive improvement in any single or multithreaded workload over a 3 series. Clock speed isn‚Äôt everything, the architecture, cache etc are all going to contribute to performance. Not to mention if you plan on keeping this system for years why not just slot in the best processor you can get for the motherboard you already have, it could let you get another 5 years out of the system you already have. If you see one at the right price I say go for it.",
      "You could make a new account, Aliexpress style, but you know, depends on how much you care about contributing to the profit margins of Micro Center. \n\n&#x200B;\n\nI like Micro Center and wish to contribute to its continued success so I personally wouldn't do it, but individuals must make his own decision.",
      "6800xt user here, by 2k ultrawide did you mean 3440 by 1440? If so thats what i use, and for example in Modern Warfare both in the multiplayer and Warzone it sits above 100 fps comfortably at Ultra settings with 110 fov. \n\nI do use FSR cause i have a 144hz monitor so i want to get closer to that number, but i think even without that i think the framerate would still be good.\n\nIf you want to i could run a benchmark for you if i have the game!\n\nEdit: FSR is at Quality i believe",
      "Thanks!  Aside from a few small hiccups, I've been blown away by the 6800XT's gaming performance.  It's over twice as powerful as my 1080 was, and going by what limited ultrawide benchmarks I could find, I'm in 6900XT territory with a decent undervolt and overclock.\n\nAnd yes, I love this case as well.  Upgraded to it when I upgraded to Ryzen back in 2020.  The netting and dust guards have been invaluable as my computer sits in a room that loves to gather dust, and the cable management features are great.",
      "Yep, I've been really impressed with the performance increase.  I was looking at both the Red Devil and the XFX Merc as upgrade options, but the XFX card had the best deal going when I snagged it on Amazon.  Funnily enough, the last four AMD cards I've owned have all been from XFX, and they all worked great for me.  I think I've managed a pretty solid overclock on my 6800xt as well.  It's currently sitting at 2500-2600 core, 1035mv and averages 2560 in most games.  Memory is at 2150 (2140 actual) and fast timings, and power is maxed at 295W.  I've tried More Power Tool and upping the power limit, but I think my card is maxed.  Throwing more watts at it ups the heat but not performance.  How's the Red Devil been treating you?",
      "I‚Äôm on a 1080 but at 4K. If I was 1440p the 6800xt would have been perfect and I see them around 520-550 bucks. Decided to step up to an XTX which will be here in March. Can‚Äôt go wrong with the 6800XT if you‚Äôre in less than 4k, and even at 4K it‚Äôs still double or more than the 1080."
    ]
  },
  {
    "brand": "amd",
    "generation": "6000",
    "tier": "high",
    "matched_keywords": [
      "6800"
    ],
    "title": "6800 XT with 6900 XT/3090 Performance. Higher clocks do not always mean higher scores!",
    "selftext": "",
    "comments": [
      "TUF Asus Gaming Radeon Rx 6800 XT AMD Wattman Settings\n\n* GPU Clock Speed: 2350-2450 MHz\n* GPU Voltage: 1100 mV\n* Memory Timing: Fast\n* Memory Frequency: 2150 MHz\n* Power Limit: 15%\n* Smart Access Memory: Enabled",
      "Try 2120 on the memory. The VRAM automatically loosens timings above 2124 MHz, so you want to stay below that.",
      "6800XT is low key in the shadow of the 3080/3090 tbh. But it's a silent beast! Nice!",
      "vanish worthless wise frightening wide grandfather file point jellyfish spectacular -- mass edited with redact.dev",
      "Man I love my 6800xt but missing out on ray tracing and dlss kills me sometimes",
      "Is the same true with the 6900XT as well, do you know? Or is this just the standard enforced product segmentation in effect again?",
      "Nice, I'll see if I get a boost that way. I also haven't tried lowering the voltage even further, so I think I can get even more performance that way. I'll give this a shot when I get home from work and let you guys know how it goes! Let's see how far we can take this card!",
      "Mine clocked itself aroud 2730 mhz or so sometime.\nAll i did was undervolt... there was some artifacts, limites it to 2675 mhz and never had artifacts after this. Also saw some 327 watts consuption LOL. Now i limited it to 180 fps, consumes about 225 watts average whatever i do lol.",
      "only really in terms of ray tracing and 4k.\n\n&#x200B;\n\nif you're not on those trains, then its blow for blow pretty much and the 6800Xt is slightly ahead.  if you're into ray tracing and 4k, then its an obvious loss.\n\n&#x200B;\n\nnot sure why the 3090 is mentioned, it's not a competing card.",
      "At least it can run raytracing even if it's not amazing at it. If some super crazy RT game comes out there's the option to tweak settings until it's satisfactory. The 5700XT was the true dead end card since it offered great performance per dollar but lacked any future proofing.",
      "Plenty of people would love to get their hands on a true dead end card given the insane inflated bubble we are in.",
      "Yeah I noticed something funny with my gaming PC when I was tuning it for nicehash. Anything over 2120 on the memory was causing it to lose performance which I thought was weird. Your explanation would explain why",
      "Just picked on up a few weeks ago. They're a beast of a card. Ulgraded from a 980ti.",
      "All of us don't care about unrealistic benchmark scores either.",
      "dlss sucks in a lot of games man. 3090 here and i find dlss in cyberpunk unbearable, blurry mess even on quality. Ray tracing also feels like a single graphical setting, you turn it on and have to look for it. Most scenes in cp2077 are identical, but shiny glass is reflective. I painstakingly went back and forth in various areas turning RT on and off‚Ä¶long story short, youre missing very little. Check YT comparisons if you dont believe me\n\n\nIts not world shattering stuff. I firmly believe marketing has planted a seed in peoples heads its world shattering, and it really isnt yet. Amazing what adverts can do tbh, especially for cp2077",
      "The trick is to find settings where the card does not permanently hit the power target limit of 293W. My card's sweet spot is 2560 MHz @ 1030 mV and mentioned memory settings. The power consumption in Time Spy is  around 285W, the card constantly boosts to 2500 and my graphics score is well above 21,000 while my hot spot temp is below 95c (reference card). Since you have an AIB card and a Zen3 CPU, you should get even better results.",
      "It is. I have my 6900xt same settings",
      "3090 is also double the price.",
      "Okay but from the perspective of a gamer it won't be a big deal for quite a bit. Until most people have a decently powerful ray tracing GPU, developers will still have to create a decent rasterization based lighting system and tack on ray tracing effects afterwards.\n\nRay tracing will be revolutionary when everyone has it and developers can stop spending tons of time and resources creating point lights and faking real world lighting that can be simulated, and instead put that time to improving other aspects of the game.",
      "I would say its above 3080 and below 3090 (dlss not counting), source: i got both and tested them."
    ]
  },
  {
    "brand": "amd",
    "generation": "6000",
    "tier": "high",
    "matched_keywords": [
      "6800xt"
    ],
    "title": "Got my hands on a brand new 6800xt for an amazing price today.",
    "selftext": "",
    "comments": [
      "I traded my rx 580 and $450",
      "You leave us without the price?! What kind of monster are you!",
      "very nice indeed.",
      "Congrats! Got myself a 6900xt about 3 weeks ago. Love it. Make u tweak the setting via the AMD adrenaline software, undervolt it between 1110 to 1150 and turn the power consumption up to 15%. Theirs plenty of YouTube videos on it if u need help. Enjoy ur new card!",
      "Performance and cooling. These Radeon cards have a high TDP but for what ever reason doesn't fully hit the power limit yet the stock voltage really heats up the card and can cause it to thermal throttle. So it's basically a balancing act between the 2. This is a very weak explanation,  videos on YouTube explain it much better. \n\nOh and tweak the fan curve too, the overall card Temps aren't bad but as u see on the software the junction temp on the card can get over 100, so tweak the undervolt and fan curve accordingly.",
      "> Make u tweak the setting via the AMD adrenaline software, undervolt it between 1110 to 1150 and turn the power consumption up to 15%.\n\nWhy for?",
      "Note that this is a problem mostly on reference cards and low-end cards. Once you get to the XTXH cards and the super nicely binned cards (Asrock Taichi), the coolers are so over-engineered that it won't thermal throttle even if you push the card to an extreme (unless the card is in like some sort of NZXT hot box case).",
      "Great deal. I just paid $850 for a Gaming X Trio model. It's a hell of a card. I love mine. Enjoy it",
      "850?\n\nOmg we're getting fxxxd over here in Europe!",
      "Ooo nice deal!",
      "What am amazing price",
      "Thank you thank you it was a Facebook market place find believe it or not!",
      "Had mine for a yr and a half. Rx 6800xt are Great cards",
      "I actually traded my 5700XT Red devil for 6800XT and paid 100‚Ç¨ with the trade. It's running super smooth, even after almost 6 months :)",
      "Sorry, I traded my rx 580 and $450 for it",
      "It's one of the best designed boxes ever, a delight to open.",
      "Just got mine 2 weeks ago. I upgraded from a 6700XT and I'm still surprised by the performance increase. Over 20k in Time Spy and it crushes in 1440p. Love it. The 6000 series cards have been great",
      "Outstanding! Congratulations!\n\nGlad to see enthusiasts able to get hardware.",
      "> It's running super smooth, even after almost 6 months \n\nIs that surprising? What were you expecting it to do after 6 months?",
      "Ah ok thanks"
    ]
  },
  {
    "brand": "amd",
    "generation": "6000",
    "tier": "high",
    "matched_keywords": [
      "6800xt"
    ],
    "title": "anyone else think that the 6800xt looks like a boombox?",
    "selftext": "",
    "comments": [
      "Batteries not included...",
      "ObnoxiousLittleCunt",
      "Yeah, I do think it does. Does it matter though? I'm happy they ditched the blower-style coolers.\nAnd also: who doesn't like a good boombox? :D",
      "Requires 8 D batteries and lasts 1 hour",
      "No, unfortunately the 6000 series doesn't include a Ryzen CPU, you still have to buy that separate. Would be a great bundle deal though!",
      "as long as they deliver great performance idc honestly. just found it funny",
      "It reminds me of a transformers toy from the 80s or 90s",
      "Those were the days, now it'd have a built-in non-user-replaceable battery under 5 layers of plastic, epoxied to some structural piece to prevent you replacing the battery at all costs.",
      "So, now we will update the BIOS using mini audio cassettes now ?\n\n&#x200B;\n\n/jk",
      "Yeah.\n\nSome have interpreted them to mean AMD bad, and some have interpreted them to mean AMD good.\n\nI'll wait for actual reviews before making any kind of judgement.",
      "lol Boombox and Soundwave",
      "Amd did that with zen1 back in the day, it was good for people to have a selection of compatible mobos and cpu to pair with gpu inside.\n\nAaaaahhh the good times.",
      "Yeah, it's somewhere between beating the 3090 handily and barely beating the 2070S. It's simultaneously going to be a pair launch and have plenty of supply. It's also going to have somewhere between 6GB DDR6 and 16GB HBM2. It's shr√∂dinger's GPU launch.\n\nSeriously though, the only thing we know for certain is XBox Series X performance from Digital Foundry, which is 52 CUs, and people have been extrapolating from that despite not even knowing the settings it's running at other than resolution.\n\nWait for benchmarks and reviews.",
      "You have to live it !!!",
      "What?",
      "I‚Äôm not keeping up with the news very well, are there any leaks about performance yet?",
      "The  3,840 stream processors make the streamers get dumb\n\nThe base clock's bumping but I need the FPS higher",
      "Actually no, this is only the 6800 not the 6900 XT",
      "I think this looks rad",
      "Well now that you show us this..."
    ]
  },
  {
    "brand": "amd",
    "generation": "6000",
    "tier": "high",
    "matched_keywords": [
      "6800"
    ],
    "title": "Finally retired my 1070 with this used, AWESOME, RX 6800 XT!!!",
    "selftext": "",
    "comments": [
      "Hi guys. I don't have any friends that are into PC stuff, so I came to share with you. This is my ship of Theseus. It started around 2008, and I've been upgrading it since then. (all cpu and gpu were bought as previous gen, sometimes 2 or 3 years after release. all new, except the current gpu)\n\nIt started with a intel core 2 duo and a nvidia fx 5000 series, can't remember the models\n\nchange platform to a amd phenom 2, with a radeon hd 5770\n\nupgraded to a radeon hd 6870\n\nthen change platform to intel i7 3770k\n\nupgraded to a nvidia gtx 680\n\nupgraded to a nvidia gtx 1070\n\nchange platform to amd Ryzen 7 3700X\n\nupgraded to a 5800x3d\n\nand lastly, to this monster of a rx 6800 xt (used), 16 gb lets go!!\n\nrest of the system:\n\ngigabyte x570 aorus ultra\n\ngskill Trident Z ddr4 2x8gb 3200 cl18\n\nssd Corsair Mp510 256gb (os)\n\nssd Kingston a2000 1tb (games and temp)\n\nhdd WD Black 6tb (media)\n\npsu seasonic X-850 gold\n\ncpu cooler Id-cooling Auraflow X 240\n\nCorsair Airflow 4000d\n\n6 noctua NF-F12 industrialPPC 3000 pwm LOL\n\nmonitor LG 27gl650f 144hz (1080p, now wishing for a 1440p)\n\nkeyboard logitech g710+\n\nmouse logitech g502\n\nheadphones sennheiser hd 518\n\nSo now i'm all amd. I have to say, since I bought the gtx 680, I saw nvidia as a better choice, and this idea stayed with me in the following years, even when amd released good gpus.\n\nI have kept my gtx 1070 since 2017. I didn't need to upgrade to 16 or 2000 series from nvidia, when 3000 series came out, prices were impossible, even more here where I live. I had hopes for 4000 series, but they really screwed up , and meanwhile, I completely ignored amds offerings. I regret that, i could have purchased a new 6800 xd, 1 or 2 years ago..\n\nanyway, im super happy with my 6800 xt, performance is insane, coming from a 1070, and even more considering i have a 1080p monitor, maybe i'll look for a 1440p upgrade.\n\ncheers!",
      "Most people who spend more for nvidia gpu‚Äôs literally think amd gpu‚Äôs give you herpes or don‚Äôt run games.  Seriously, nvidia marketing has convinced people to spend more money for the same performance.  Crazy.",
      "nvidia has some nice features, and i think RT its gonna be a big thing in the coming years in most games, but i made the decision of having more raster performance, and if rt runs, ok, if it doesn't, also ok..",
      "RT wont be relevant until consoles themselves can do demanding RT. Consoles are the baseline.",
      "I love my 6800xt too. I use it for 1440p gaming, but also flight and racing sims in VR on a Reverb G2.",
      "Awesome! \n\nThat's quite a story of upgrades. Do you still use the original case?\n\nI'm on a 1070 and I decided to survive until RTX 5000/RX 8000. My backlog of older games is gigantic, anyway, lol.\n\nBut it's great that you made the jump already! Enjoy your increased framerate, the RX 6800 XT is strong enough for your future 1440p screen, too!",
      "i think rt is the way on, but ill be excited when it becomes mainstream, and not a privilege",
      "Nvidias cards are more expensive for their features. AMD cards are good for native, raster performance. But FSR is not great, and they handle ray tracing poorly.",
      "i omitted some upgrades details, like cases, ram, storage.. i had 3 different cases, currently in the Corsair Airflow 4000d\n\ni like any art stile game, but im a sucker for icandy haha",
      "Funny how RT is a nothingburger but only until AMD is at parity in your mind?  \n\nI think AMD \"parity\" on that would be fantastic for the games industry but it's also wishful thinking that would require the competition not continuing to make sizable improvements of their own.",
      "Shader compilation just goes away once it's completed. It resets after every driver reinstall or shader cache reset. Usually it goes away after 5-15 minutes of just playing the game.",
      "I just went from the 1070ti to the 6800 XT myself. Seems like a popular upgrade path. But I did the 5800X instead of the X3D.",
      "Rt is relevant if you feel like its relevant. Rt, especially path tracing, can make a huge difference. Metro Exodus EE is a very good example.",
      "...if you dont use an upscaler or rt.",
      "Good choice!",
      "My 6800xt may outlast my old 9700 pro max. I love this card for 1440p and 4K in some cases.  I went from 3600x to 5600x and now 5800x3d and uogrsded my vega 56 to a 6800xt and I'm blown away.  It runs even better since I tweaked it in the drivers.",
      "Retired my 5700xt to a 6800, what a fucking beast of a card. Undervolted I'm pulling the same as a 5700xt, but it is so much stronger.",
      "I went from 1070 to 6800xt also yooo. I upgraded to an x3d processor also on am4.",
      "I upgraded from a 1070 to a 6700xt and can't really say I've been super impressed. Destiny 2 stutters like crazy for me on the 6700xt where I have no issues on the 1070.",
      "lets go!!!"
    ]
  },
  {
    "brand": "amd",
    "generation": "6000",
    "tier": "high",
    "matched_keywords": [
      "6800"
    ],
    "title": "Launch day AMD.com 6800 XT order \"lost\" at FedEx - You should check your tracking number(s)",
    "selftext": "Were you able to successfully place an order on the AMD site for a 6800 / XT on launch day? If so you may want to check your tracking number to see if it's actually showing signs of activity.\n\n&#x200B;\n\nIf you are like me, it has been \"stuck\" in **OSSEO, MN** since the day the order was placed. I called FedEx ( 1 (800) 463-3339 ) this morning inquiring on why that is. In turn they had that specific FedEx location call me back only to tell me the package was not in their database and it is now officially **lost**. They then instructed me to call AMD and have them file a claim.\n\n&#x200B;\n\nI then called AMD ( 877-284-1566 ) and after a few minutes on hold, was told that this was not their first call regarding lost 6800's. The person I spoke to said that plenty of others were complaining about it on social media sites (Reddit named specifically) and that they are aware of this problem. At this time it would appear they will contact you back in 2-3 business days. Most likely to issue you a refund since they have no stock with which to compensate you at this time.\n\n&#x200B;\n\n&#x200B;\n\n&#x200B;\n\n\\[edit\\]\n\nIt is now 11/30/20, 12 days since my order was placed. After 10 days of being in OSSEO, MN, the package arrived this afternoon. At this point I'm not upset but rather relieved that the worry is over and have been happily playing Death Stranding (fitting huh?) all evening.\n\nI'd like to thank those who have stepped forward with their stories. To anyone who has yet to get their card; no need to panic. I'm sure you will get yours soon enough. :-)",
    "comments": [
      "I'm sorry to hear it. Sadly delivery drivers with sticky fingers appears to be becoming more common.",
      "I got lucky with my 5950x amd direct order since I received it. Boy was I scared though after hearing about how bad Digital rivers is and reading google reviews about how the Osseo,MN FedEx warehouse is the Bermuda Triangle of packages. I wish you good luck and hopefully they happen to find and scan them in so you can get it.",
      "It didn't even make it to a driver from what I can tell :-(. It seems they \"misplaced\" pallets of 6800s, hence why I made this post to help others that may be wondering why they won't be receiving their cards. \n\nA quick cursory look at FedEx's Reddit and Twitter pages reveals that they are also catching similar heat with regards to stolen PS5s. I sure would hate to be them right about now.",
      ">Osseo,MN\n\nHOLY FRICK! You weren't kidding!  \n\n\n[https://www.reddit.com/r/FedEx/comments/jcz3z9/whats\\_up\\_with\\_the\\_osseo\\_mn\\_warehouse/](https://www.reddit.com/r/FedEx/comments/jcz3z9/whats_up_with_the_osseo_mn_warehouse/)  \n\n\nCalling them the Bermuda Triangle of packages is spot on. It does make me wonder if AMD / Digital River knew about this beforehand. If I were them I would have saved myself the headache and chose another shipper. Then again hindsight is 20/20...\n\n&#x200B;\n\nWhere are you when I need you... Bridges / Fragile Express? :-/",
      "A lot of people keep trying to blame delivery drivers. Seems to me that it is far more likely that it is anyone involved in the process who can't be easily tracked.\n\nObviously there is a small number of delivery drivers who are actually that stupid.",
      "Yeah, I dont think FedEx drivers would risk their job for a meaningless piece of computer hardware. Some of these delivery drivers make in excess of $70,000 annually, and I am sure they will rather keep their job than be fired for some random crap. People on this sub pretty much parrot what people on the playstation sub said. Lo and behold their package was just delayed a couple of days. Calm your tits folks",
      "Thanks to SoapyCristian, I was able to find a similar situation involving that [God Awful depot and NVIDIA cards](https://www.reddit.com/r/nvidia/comments/ixw4bq/3080_fes_stuck_in_osseo_minnesota/).\n\nIt would seem that this place doesn't do outbound scans and that they automagically appear at the destination days / weeks later. If you are on this boat with me; keep faith alive. Should anything new develop, I will update. The person I spoke to did say they didn't have it in their database after all and was declared lost.",
      "FedEx in Pacoima stole my PS5 preorder from Target form Sept 27th",
      "70 grand + a few more grand here and there...idk. I dont doubt it occurs, but the scale isn't mainstream.",
      "You would think that. But I have seen it before. Several years ago, I bought a custom order Lenovo W520. Got from China over to the western seaboard, and shipped all the way to my local depot. Where it was last scanned on the truck for delivery. Then \"it fell off\".\n\nUh huh.",
      "The driver's software tracks every movement they make, I think this would have to happen before last mile delivery",
      "I had some parts not get updated at the Osseo facility for about 3 days only to be delivered to be without notice to me in Seattle. I'm not sure what's going on with the employees in that warehouse.",
      "I watched as I was pulling up to my house a Amazon driver take a pic of my package pick it up and leave lol Amazon refunded me",
      ">It‚Äôs not just risking their job, it‚Äôs committing a federal crime.\n\nDepends.  FedEx isn't the Postal Service and isn't covered by the rather strict federal laws that protect mail.  Crimes involving FedEx aren't under the jurisdiction of federal law enforcement like the Postal Inspection Service.  \n\nFedEx is the carrier that as a merchant I've had the most packages disappear while passing through their warehouses.  From experience USPS is the best about not having packages stolen during transit or at least being able to actually retrieve them if lost... while UPS comes in a close second.  I suspect UPS is almost as good as USPS because their employees actually give a fk about their jobs due to like USPS having a living wage and benefits due to a strong labor union.  FedEx and Ontrac are the worst with employees that for good reason don't give a fk.\n\n\n^(edit:)\n\n^(Ofc... for a hefty fee FedEx has a high security option where they will guarantee packages aren't lost or stolen during transit.)",
      "The more I read into it, the more cases crop up like yours from that location. Most of them as recent as October but some of them go back a year. It makes me wonder how come no one has gone down there and straightened them out.",
      "After retailers mark stuff up because they can, you can't even guarantee you will get it anyway. If it isn't retail employees cancelling your orders and selling your stuff to others, or warehouse workers disappearing entire pallets of goodies, it's drivers getting wise and running off with packages.\n\nWhat a garbage year for building a PC.",
      "are they just shipping these things with the packaging visible?   how do people know what they are?  if they labeling is visible that its a gpu, thats just dumb.",
      "Yup, my 3080 FE was in Osseo MN for a solid week. It literally updated a few minutes before it was out for delivery. Good luck.",
      "Drivers are not stealing.  The products are scanned and loaded into each vehicle.  If it gets on the truck, UPS knows it and the driver is liable if things \"disappear\"",
      "Lmao, I ordered two 5700XT's from Amazon, both just had the shipping label on the actual box."
    ]
  },
  {
    "brand": "amd",
    "generation": "6000",
    "tier": "high",
    "matched_keywords": [
      "6800"
    ],
    "title": "XTIA Xproto-N Build - 5800X3D with RX 6800",
    "selftext": "",
    "comments": [
      "Technically, your house is now a PC case, and you're living in your PC. And that's cool.",
      "Dude, I also rock the same chassis - word of advice, the standard upright position fucks with the operation of the vapour chamber cooling on your GPU. You can also place it on its side with the GPU in an upright position and it should drop around 10-30C off.",
      "Really enjoyed this build. I ordered the custom length cables from XTIA (White) as well as the USB3.0 Audio front bracket. Cable management is surprisingly easy with this case. XTIA made slots for cables exactly where you need them. Cables are all running through a completely open 3/4\" gap in the center. Odd thing about this case is that it's crazy quiet even at arms length. GPU junction temperature hovers around 77C with fans running around 1400RPM (very quiet). CPU temp during gaming hover around 75C with fan at 50% (very quiet).",
      "You should tell your kids in the future (unless u already have them) this was your phone in 2022",
      "30C that's pretty intense. I'm not noticing any GPU thermal issues. Seems to be on par or better than when it was in my NR200 but if I do I'll definitely try your advice.",
      "Yes, vapor chambers are usually pretty insensitive to gravity. https://www.1-act.com/resources/heat-pipe-fundamentals/different-types-of-heat-pipes/vapor-chambers/",
      "Depends on the design of the cooler.\n\nI have an older HP laptop that will run just fine upside down for about 10 minutes until the heatpipes dry out at the evaporator end, and then the CPU temp rapidly climbs to over 100¬∞C before it shuts down to protect itself.\n\nFlipping it back over brings the CPU temp down massively in just a few moments.\n\n(I had used it upside down because it was connected to a TV + wireless keyboard and mouse, and was on the carpet. The vents are on the bottom, so upside down seemed like a good idea...)",
      "Lol",
      "How are your cpu temps with that cooler? Looks cool mate",
      ">GPU junction temperature hovers around 77C with fans running around 1400RPM (very quiet). CPU temp during gaming hover around 75C with fan at 50% (very quiet).\n\nAlso, thank you. Never built with a case like this before it was a lot of fun.",
      "My RX 6800 XT would overheat in that direction in Xproto. How's yours doing? Turned out it's vapor chamber didn't work well in that orientation - over half of the radiator stayed cool to touch. Temps were  MUCH better when I put my Xproto to the side.",
      "Or warm depending on overclocks right?",
      "capable simplistic upbeat elderly water foolish sand escape cows automatic -- mass edited with https://redact.dev/",
      "only me or do they look like massive phones straight out the 90s",
      "Set it to Wumbo.",
      "Have you done any undervolting on the GPU or used curve optimizer to undervolt the CPU? Great build and good temps, just wondering if you tried bringing the temps down further with either of the above.",
      "Just for you:\nhttps://i.imgur.com/GHuV3OU.jpg",
      "Didn't realise the rx6800 came with metal razor blade fins. Careful OP",
      "Get an air blower and it takes 5 mins.",
      "Thanks, now I have to clean my monitor of coffee"
    ]
  },
  {
    "brand": "amd",
    "generation": "6000",
    "tier": "high",
    "matched_keywords": [
      "6800"
    ],
    "title": "[HUB] Best High-End GPU of 2020, GeForce RTX 3080 10G vs. Radeon RX 6800 XT: 2023 Revisit",
    "selftext": "",
    "comments": [
      "The 6800xt is over 200‚Ç¨ cheaper than the 3080 in Germany. Prise wise the 6950xt is about the same as the 3080. How do these two compare?",
      "Nvidia 30 series has always been faster at higher resolutions relative to AMD 6000 series, probably because the two architectures simply behave differently. The vram mostly doesn't play a role because apparently 10gb is still enough, but in the 3070 vs 6800 video you can clearly see how much the 3070 struggles. The issue is certainly overblown, some people think the 3070 is now useless when in reality it's just a matter of adjusting a few settings and it can still play very well, but the real problem is Nvidia putting only 8gb of vram on a GPU of that performance class. In the long run it's going to severely impact the longevity of the card.",
      "See the interesting thing is that at 4k (where vram matters most) the margin widens in favor of the 3080. Also interesting to note is HU reported that in hogwars legacy the 3080 ran out of vram but the 6800xt didn't provide a playable experience either. Maybe, just maybe, the vram issue is a bit overblown? For the most part, the lack of vram is not what's holding these gpus back",
      "6950XT is basically a 3090 level of performance. That's a no-brainer, Radeon wins.\n\nAnd the 6800XT is an even better deal.",
      "I was expecting to see this sub complain about HUB using so many RT titles, therefore swaying the % differences in favor of the 3080. Glad to see that‚Äôs not the case, at least not yet. In reality, anyone who bought a 3080, like myself, was interested in RT, so it definitely matters between these 2 GPUs, but I have to admit I was hoping to buy a 6800xt until a 3080 kinda fell into my lap during the height of the pandemic for close to MSRP.",
      "The \"vram\" issue is only about the fact that in 2023 you should not buy cards with low vram and expect not to encounter issues in 2024 in various ports or AAA titles coming out.         \nCards will work, you will be still able to play simply low vram have huge chance to impact quality of graphics you can use. \n\n\"Developers should optimize their games\" ... yes they should, but they will not do it as this require time and time means cost so something investors don't like.          \nLets be honest new titles will become more vram hungry and everything below 16GB at this point will need to be replaced somewhere in 2024.    \n\nFact that we get \"new\" cards in 2023 that have less than 16GB ram and cost >300$ is pretty much planned way to force users to buy new cards \"soon\".\n\nUnless like me you play in stellaris ... and stuff like Serf City.",
      "> Maybe, just maybe, the vram issue is a bit overblown?\n\nI think it's mostly misinterpreted. \n\nIf you have a 3070 8GB or especially 3080 10GB you should happily keep using it until either performance or outright VRAM limitations keep you from playing games at acceptable settings. You'll likely be able to use that card even at 1440p with minimal sacrifices for a while to come and enjoy a smooth gaming experience overall even in recent and near future titles.\n\nWhat the 3070 vs 6800 video did highlight was that we are approaching a threshold where VRAM capacity in the order of 8 (or 10 for that matter) GB is becoming a reasonable limitation in performance especially in the near future, bottlenecking otherwise excellent performance. Nvidia is still releasing 12GB GPUs at a $600 price point and even at $800 with the 4070ti (cheapest pc part picker prices). When buying new at that price point, it's not a bad concern to have if (like me) you like to milk a GPU until the end.\n\nI've had VRAM run out well before performance did in the past with a 780ti, it's a waste.\n\nThe 3070 and 3080 are still great cards, but the VRAM limitation should be a consideration to those buying new, especially since 16GB AMD cards are so comparatively cheap.",
      "same in Croatia, that's why i bought 6800xt and will sell 3070 while i can get some decent money for it.",
      "I'm just here for the comments :)",
      "I picked the 6800XT over the 3080 and they were at the same price. No way Im buying a 10GB GPU in 2023.",
      "Peformance class\nPrice class",
      "As a 6800XT owner there is nothing wrong with using RT on. It‚Äôs a very relevant tech now compared to launch, and in basically any game that has RT except for Cyberpunk I turn RT on. I still get playable frame rates so I figure why not use it (Dead Space, Callisto Protocol, Doom Eternal, Control, all ran well enough with RT) but the fact is I‚Äôd be getting much better performance with a 3080 at those settings.",
      "I upgraded from an RX 480 to an RTX 3080 back in 2020 and was able to get my card for around MSRP.\n\n\nFor me it came down to \"bad RT performance and no DLSS forever\" vs \"potential VRAM issues between now and 2024\". I rolled the dice and went for the new tech over the VRAM and so far it's been fine. I think TLOU's horrible PC port is the only game where you can't reasonably tune around the memory usage (not that there are many games where it's even an issue). Is it a sign of things to come? Really too early to say. Cyberpunk with full on pathtracing uses less VRAM than TLOU and Hogwarts.",
      "Strix 970 to xfx 6800xt merc this past black friday weekend $549 new.\n\nSkipped 10 series, 20 was a joke, 30 unavailable until 2 years later above msrp, 40 an even worse joke than 20.\n\nSeems to be a lot of posts and comments like mine recently. To be honest I can't say Ive ever seen so many people posting \"Ive always had Nvidia but theyve overvalued their cards\" or something similar lately.\n\nBeen loving the card, and can't stress enough to anyone on the fence that the 6800xt and 6950xt are totally worth looking at with current pricing. The only reason I didn't go with the 6950xt was I would also need a new psu and I just didn't want to do it as of yet.\n\nAlso, nvidia could learn from Adrenaline, control panel has looked and functioned the same since windows 98, needs updated.",
      "Yeah this makes sense. If we start approaching the point where vram is the main limitation, then ofc nvidia is messing by not increasing the vram of their chips. \n\nBut more specific to this video, so far the 3080 has aged better than the 6800xt, in direct contradiction to what a lot of people said back when both chips released",
      "6800xt is way better than 3070",
      "I still believe at the time the 3080 was and is a better card for near the same price. People on here overblow the Vram issue by a mile. More Vram for a 1440p card is not worth the crappy encoder (RIP Quest Users), no DLSS, dogshit UE4 VR performance and no Ai broadcasting at all. The 6800XT is still an amazing card and with it being $200 cheaper in some places it is the better card today but when both were around $700 idk why anyone would give up all those features so that one random Vram heavy game might work better tbh. The 3080s also have a much higher resell value compared to the 6800XT. People are selling 3080 used for $500+ rn.",
      "> . People on here overblow the Vram issue by a mile. \n\nDozens of RT games: RT is still years away.\n\nCouple of games with VRAM issues: 12GB is literally unusable. I don't care it's better at RT, VR, upscaling, or productivity.\n\n-This sub.",
      "It's been around 2.5 years since the 3080 and the 6800xt released, and at that time there were a lot of people making this exact same point (\"buy 6800xt because it will age better than the 3080.\") Yet the 3080 is still doing fine",
      "Same.\n\nGot my 6800xt at launch.\n\nChillin"
    ]
  },
  {
    "brand": "amd",
    "generation": "6000",
    "tier": "high",
    "matched_keywords": [
      "6800xt"
    ],
    "title": "First all AMD build since 2009- 5600X/6800XT/B550 Tomahawk",
    "selftext": "",
    "comments": [
      "You shouldn't use that daisy-chained GPU power cable. Run two independent cables.",
      "welcome to team red bro. sick rig.",
      "Have always had Nvidia cards (usually paired with Intel chips)\n\nTNT2>MX420>5200Ultra>6600GT>HD5770>GTX670>life gap>1660 Super>6800XT\n\nGoing from the 1660 Super to the 6800XT is like a quantum leap in not just speed, but driver capability. OC'ing straight from the drivers? Integer scaling is rad, and 16GB of VRAM means VR is actually playable.",
      "Agreed",
      "Just ordered a 6800xt myself. Was gonna go 3080 from EVGA. But hearing that news I can't buy a 3080 from EVGA, and I wouldn't have bought from any other company. \n\n6800xt seems to be better than the 3080 anyways, and it'll be my second amd GPU. Previous was rx580. \n\nAlso upgrade from my 5 2600 to a 5800x3d! Can't justify upgrading ram and a Mobo just for the 7000 series quite yet.",
      "Don‚Äôt mix brands though!  Learned that the hard way (specifically Corsair cable with a EVGA psu",
      "Wait, what? I have the RM850x and it came with two PCIe cables. You just need to connect both to the PSU, and only use the main cable, let the pigtails hang off. By the way I had almost the same build, 5600x and reference 6800, before upgrading to a 5950x and MSI gaming x 6800 (CPU upgrade cost me 180‚Ç¨ and GPU upgrade netted me 100‚Ç¨ hahah).",
      "I was thinking about that since the shrinkwrap looks terrible. But two 8-pin PCI-E connectors is about $60 from Corsair...",
      "Short answer is that each cable is certified to run 150 watts, as each 8-pin is rated at 150 watts. If you plug one cable into both you‚Äôre effectively running potentially 300 watts over a cable certified at 150 watts. Most manufacturers will account for it but it‚Äôs better to be safe than have a melted psu cable.",
      "Welcome to the club my guy. The 6800XT is a badass card very good choice",
      "congrats man, currently building almost identical build but with a b450 instead of the b550, I was very hesitant to get the 5700X instead to pair with such a powerful card, but actually went with the 5600X instead.",
      "Indeed, welcome to the family.",
      "Yes, there is a technical reason. I don‚Äôt know the specifics of the technicals, but I do know that using two separate cables will provide more consistent clean power to the GPU.\n\nUsing that setup, take for example the +5v pin, two wires for +5v are being merged into one +5v pin on the PSU side (unless this cable also splits on the PSU side; but I‚Äôve not seen that). \n\nWhile technically this does work and can work without problems, but if you decide to push the power limits and overclock, you could start to run to into some issues pretty quickly.",
      "Yeah, I have an AORUS 5700 XT which...Gigabyte pretty much floored the clocks on to max out of the factory, so that would be a good explanation for why my GPU at times seems to just...click off. Time to add that second cable tonight!",
      "unfortunately, my EVGA 850 also only came with pigtails. but I still used 2 individual cords and wrapped them together.",
      "Beautiful.",
      "Welcome back to the good side.",
      "The difference between 5600X and 5700X in gaming is basically non-existent anyway, so yeah",
      "Just these shrink wrapped pigtails",
      "For gaming, more often than not the 5800x 3D performs better - for non-gaming tasks, the 5900X blows it out of the water.\n\nI'm waiting for prices to drop on the 5800x 3D and upgrading my gaming rig's 5600x just for this reason - maximize my AM4 lifespan"
    ]
  },
  {
    "brand": "amd",
    "generation": "6000",
    "tier": "high",
    "matched_keywords": [
      "6800xt"
    ],
    "title": "AMD Radeon RX 7800 XT alleged scores \"19K\" points in TimeSpy matching RX 6800XT - VideoCardz.com",
    "selftext": "",
    "comments": [
      "New gen is equal to last gen? Some fancy joke?",
      "Inflation hit their naming scheme this time, I guess",
      "Wasn't this obvious?\n\n7800xt vs 6800xt\n\n60 CUs vs 72 CUs\n\n2.4ghz vs 2.2 ghz\n\nSo 83% of the cores boosted by 10% more clocks and add in a little IPCs.\n\nThen you get 7800xt = 6800xt",
      "Not like this is three years later with the same performance ü§¶‚Äç‚ôÇÔ∏èü§∑‚Äç‚ôÇÔ∏è",
      "Can't wait for 2030 when we won't be deciding between 9700, 9800 and 9900, but between 9990xtx, 9990xxxtx and 9999xxxx",
      "The names mean nothing it's all about the price.\n\n7900XT is the replacement to the 6800XT.",
      "how dare you use math to predict things that are based on basic math!\n\n*obligatory /s*",
      "So 6950xt that i bought yesterday was a good deal :)",
      "Why is an expectation of IPC from a new architecture \"out of nowhere\"?",
      "This generation sucks. This is not a generational uplift, this is a product replacement.",
      "It‚Äôs really just the same price they were clearing out the last generation for. While it‚Äôs better than last Gen launch price it‚Äôs not as good as if they had launched in say March. It‚Äôs also a disappointing generational uplift.",
      "Don't be silly. Elon successfully trademarks the letter X in 2028 forcing GPU manufactures to replace them with exclamation points.",
      "Gonna be curious to see how reviewers treat this if it really only matches the 6800XT. 4060Ti got universally shit on and it at least beats out 3060Ti at 1080p and 1440p for the most part.\n\nAs everyone has said this really should've been a 7700XT at $450.",
      "No reason, this is just a replacement as 6800 XT stock is drying out. For newcomers, it's more power efficient and has the latest tech, better RT performance, and has AI cores.\n\nEdit: also AV1 hardware encoder/decoder - thanks hj17 for pointing it out.",
      "Whats the price uplift and performance uplift of such replacement respectively?",
      "Around %33 performance uplift for 38% price increase at launch.",
      "AV1 encoding, longer-lasting driver support, slightly lower power usage, and I guess that tech they announced at gamescom that's exclusive to 7000 series cards (Anti-Lag+? Or driver-level frame generation? Maybe both, I can't remember)\n\nNot really a compelling reason to upgrade if you already have a 6800XT in my opinion, it's probably more for the people who haven't upgraded their card in more than 3 years. I probably would have gone for a 7800XT if I hadn't just bought a new 6800 a month ago.",
      "Not great. I thought it would be closer to the 6900XT.",
      "Cause we already had Navi31 reviews including deep dives and micro-benchmarks so the performance of Navi32 is absolutely trivially easy to preduct.",
      "It's the naming that's changed. The 7800 XT is matching (and likely exceeding by a little) the 6800 XT with 12 fewer compute units, 64MB less Infinity Cache, 768 fewer shading units, 48 fewer TMU's and 32 fewer ROP's at 37 less watts, for $100 less. It's really what the 7700 XT should have been.\n\nPeople saying RDNA3 has no architectural uplift whatsoever are paying attention to names and nothing else."
    ]
  },
  {
    "brand": "amd",
    "generation": "6000",
    "tier": "high",
    "matched_keywords": [
      "6800"
    ],
    "title": "Stealthy-er mATX Build w/ RX 6800 XT MB",
    "selftext": "",
    "comments": [
      "You didn't like the case so you figured you might aswell upgrade the GPU, CPU, and CPU cooler? PC building in a nutshell.",
      "A couple months back, I posted [this pic of my build.](https://redd.it/l8o8tl)\n\nAlthough it was nice, I wasn't a fan of the case (I hid it from that image as you can tell), and since then the 6800 XT MB had released. So I wanted to change those two things... but I ended up changing a few other things as well, resulting in my build right now :)\n\nPCPartPicker List: https://pcpartpicker.com/list/BwWqZZ\n\ncable management pics, for those who enjoy that sort of thing: https://imgur.com/a/accqgfH",
      ">\"Man, these headphones are trash, I need to get a new DAC.\"  \n>  \n>\"It just doesn't make sense to have a custom mechanical keyboard a Microsoft Mouse.\"  \n>  \n>\"Having *one* sleeved cable looks weird, maybe it's time to upgrade my PSU.\"  \n  \nEtc.",
      "mATX such an under rated form factor. Did you do anything to prevent GPU sag?",
      "because you can't put an ATX board in an mATX case\n\nwhy an mATX case? because I prefer the size",
      "https://www.reddit.com/r/Amd/comments/l8o8tl/stealthy\\_matx\\_build\\_w\\_rx\\_6800/gldjmdr/?utm\\_source=reddit&utm\\_medium=web2x&context=3\n\n>Managed to snag a RX 6800 off amd.com at MSRP! this is basically my end-game build for the next few years :)\n\nThat post of yours aged well haha",
      "Beautiful system but shame you can‚Äôt show off the motherboard üòÖ",
      "[here's a better look at the inside, yeah it is pretty hard to see the Mobo lol](https://i.imgur.com/8y3PCsN.jpg)",
      "Tried that case with a 5950X + 3080 too.   \nLooks clean, very small build, but holy shit with a NH-D15SE and max. fans used it really gets superhot. Had to change the case again.",
      "I actually have a mechanical keyboard and a microsoft intellimouse 1.0A, nearing 2 decades old, older than me. can't exactly afford a heavy enough mouse for me",
      "Nope, from what I can tell the GPU isn't sagging",
      "Personally I love MITX cases. I had a TU150 build last year but had to go full ATX because I like high end parts and it was just too small for the cooling I needed.",
      "Basically, yes lmao",
      "Which case did you move to?",
      "Yeah, I wrote that while knowing that my old, optical wireless Microsoft Mouse was superb in its simplicity.  It wasn't fancy or featureful, but it did the job, it was the Honda Civic of computer mice.  (I actually drive a Civic IRL, so I'm allowed to say that.)  \n  \nMicrosoft keyboards are reasonably user friendly, too.  They're not mechanical, but for most consumers that doesn't matter, and they always worked well for me.  \n  \nStill, any excuse to buy a new mouse, right?  \n  \n>can't exactly afford a heavy enough mouse for me  \n  \nDo heavy mice cost that much more?",
      "Very sleek. What did you use to paint the GPU shroud or did you just cover the red lines with something?\n\nNVM: It's the midnight black version (forgot those existed)",
      "Now we‚Äôre talking! Very clean and no rgb unicorn puke üëçüèª Have my upvote sir!",
      "I think temps are just slightly better on the D15, not sure why that is. They should be very similar, but the D15 is just slightly better from what I tested. Also, I prefer how the D15 looks",
      "ü§£",
      "Be Quiet Pure Base 500DX. It was near the top of the stack for thermals and I like how it looks. Lian Li Lancool Mesh II was another choice I considered wrongly with excellent thermals."
    ]
  },
  {
    "brand": "amd",
    "generation": "6000",
    "tier": "high",
    "matched_keywords": [
      "6800xt"
    ],
    "title": "Sapphire 6800XT Nitro product page is up!",
    "selftext": "",
    "comments": [
      "There appears to be a second page:\nhttps://www.sapphiretech.com/en/consumer/nitro-radeon-rx-6800-xt-se-16g-gddr6\n\nImplying there is a special edition (SE) with RGB on the fans.\n\nEDIT: SE also has a USB-C port instead of a 3rd display port",
      "So no one here is going to talk about the 850w minimum recommended power supply?\nEdit: I misread it doesn't say recommended at all. It says minimum.\n\n*Does not support all features including but not limited to Hardware Raytracing\n\nSystem Requirement\n\nMinimum 750 Watt Power Supply",
      "Damn, why they have to make type-c premium",
      "I think some VR headsets",
      "Nope.. we simply do not give a shit anymore",
      "850W covers their bases in case you buy a $30 piece of shit PSU that can only output 400W safely.\n\nAlthough, because of how switch-mode power supplies work, you will get better efficiency if you spec your PSU to roughly double your system's power consumption. Peak efficiency typically occurs at 50-70% of rated maximum.",
      "My God, it's beautiful. I really want the one from sapphire, I like supporting them as a company. I might not be as big of a fan as you but I appreciate what they do. Thanks for the link and thanks for all of your videos. Your content is packed with great information and it is very digestible unlike some other technical videos.",
      "AMD AIB models markup are usually tighter compared to Nvidia's. Sapphire Powercolor, and XFX all made top-end 5700XTs within $50 of the $399 MSRP.  I *expect* the AIB cards to be within $100 of MSRP for the 6800 series.\n\nEven Gigabyte's 5700XT price was good.\n\nIt's the AIBs like MSI and especially ASUS that like to price their stuff wildly.",
      "there are also a number of monitors that support it as an input method as well since USB-c display output is very popular on laptops",
      "what type of display uses usb-c?  I‚Äôve only seen it on phones and some newer peripherals.",
      "I saw that and thought, ‚Äúit doesn‚Äôt require that‚Äù",
      "perfect yes, this way my girlfriend will have no suspicion!",
      "They can run fine off a 650W",
      "*Four years ago I bought a AX1200i, everyone called me a madman...*",
      "Yes the man himself, the legend, the ghost, the greatest Sapphire fanboi there exists",
      "VirtualLink is effectively dead after Turing; None of the HMD manufacturers supported it, so it never took off. I imagine that this USB-C is simply capable of driving a Displayport signal and maybe data transfer, but no powering devices.",
      "Nitro is the highest, also since you are new, usually Sapphire and their Nitro series are the best cards you can get.",
      "Recommended power supplies are pretty inaccurate.   They just throw a big number up there so that when someone tries to run it on a 500W and it performs poorly or, not all, they can say \"Well, we told you it would need at least an 850W.  \n  \nRealistically, 650-750W is more than enough, unless your'e running that toasty 300W 10900K",
      "I've a 750W Gold, hopefully It Will be good",
      "wattage requirements doh\n\nfor sure the reference 6800 non-xt will need only 650w"
    ]
  },
  {
    "brand": "amd",
    "generation": "6000",
    "tier": "high",
    "matched_keywords": [
      "6800"
    ],
    "title": "Simulated Radeon RX 7800 XT GPU ends up 4% to 13% faster than RX 6800 XT - VideoCardz.com",
    "selftext": "",
    "comments": [
      "Yeah... both nvidia and amd seem to have a hard time beating the 6000 amd's series deals for low/med/high-end, unless you want to get the top of both current generations the rest looks like a waste of time. Even if this is still a rumor I doubt it'll end up any different. Probably gonna end up getting an rx 6950 xt like any sane person.",
      "If it doesn't have some crazy power efficiency, it's better for them not to even release it.",
      "Not even a good simulation lol. This is based on the assumption the Navi 31 70cu card will be 7800XT, when the leaked rumours indicate 7800XT will be 60CU N32 card.\n\nDoesn't make sense to equate the GPU to 7800XT. It's not like 7800X3D simulated graphs where we got near accurate simulations.",
      "Its not just about the value. If your sucessor (with almost same CU count of 70 vs 72) is only a single digits faster than the previous gen, \n\nThen you fucked up. Its the same with the 7600 vs 6600xt (both 32CUs). Its just sad at this point. Almost as sad as NVs milking of consumers this gen.",
      "Power consumption difference will likely be pretty large. The 6950 XT also went up in price recently.",
      "Has anything from this gen of AMD so far had impressive efficiency? It seems like they really walked away from efficiency this round.",
      "4 to 13%, like the 7600 was going to be 11% better than the 6650 xt? :(",
      "Same deal here for 3+ months and actually it went down by 20EUR, once you do some UV you'll have a much more efficient card and lose 5% perf. in the worst case. Unless the 7800 xt isn't 50/100 cheaper than the rx 6950 xt there is no reason to wait for anyone that has been eyeing the rx 6950 xt.",
      "RDNA 3 is a disappointment.\nHopefully, discounted 7900 XT down to $699 would fix this generation.",
      "I worry more about the price than the performance for cards these days. The problem is not the performance, they could call it a 7800 XT and it could be the same speed as the 6800 XT, but if it's $399 or $349 then it's a decent product. But if it's $599 or something, then it's DOA. There's no bad product, just bad pricing. Yes, even the horrible \"4060 Ti\" wouldn't of been canned it they named it appropriately, say the RTX 4050 Ti and sold it at $199 or $249.",
      "tldr; if you're waiting for 7700/7800, don't. just buy a 6800 XT or 6900 XT",
      "6950 XT is the goal, haha. If that's it but maybe 20 to 40% better on power, then we're good. There isn't much room between the 7900 XT to the 69\\*\\* series for a 7800 XT.",
      "It's just more proof that the \"7900\" products should have been named \"7800\". If anything, it is strange that AMD decided to play the \"one-up in naming\" game with the 4080 / 7900XTX and will probably do the same with 4070 / 7800, but *didn't* do the same with the 4060 / 7600.",
      "The 60CU N32 performance means it cannot be more expensive than a 4070, which means it'll be branded as a 7800 non-XT.\n\nSimilar scenario to the 7600.\n\nThe 7800 XT will either be this GPU or will not exist at all.",
      "Yuss :3  \nAlso the same hype predictions for 7900XTX and 7900 XT before they were even out.",
      "That argument has always been bizarre to me. \n\n\"Hey, if you wait a year or two, they'll sort the drivers out to the point that they should have released with!\" lol\n\nNvidia also does driver improvements over time, but tend to get most of the performance right out of the gate.\n\nSaying it's like \"fine wine\" is a weird take on unoptimized drivers that take years to fix.",
      "They're still efficient, but they're tuned in the other direction at stock. I took 35 watts off the top of stock 7950X settings and get higher Cinebench R23 scores, lower thermals, and better gaming performance. I'm running -24 all-core PBO and haven't even tested higher undervolts on the cheapest X670E board available.",
      "I'm gonna be pissed if it's just another 6950 XT.",
      "I was about to suggest power consumption might be a factor... but it's only about 10 watts of power difference... and for those 10 watts you get another 2 gigabytes of VRAM and 4% more overall performance... and you can undervolt...\n\nI'm actually curious as to why people are buying the 7600 when the 6700 has an identical price...",
      "6900XT in the US is hard to find, AMD replaced it with the 6950XT. I have a Red Devil 6900XT with minor coil whine but other than that I‚Äôm very happy with it."
    ]
  },
  {
    "brand": "amd",
    "generation": "6000",
    "tier": "high",
    "matched_keywords": [
      "6800xt"
    ],
    "title": "5600X / 6800XT Nitro+SE",
    "selftext": "",
    "comments": [
      "The table being smaller than the PC is giving me hella anxiety, but she's a beaut",
      "ahah don‚Äôt worry it‚Äôs just for pictures \npc is safe on my desk now",
      "I'm not a lights in my pc kinda guy, I prefer a nice looking discrete case.\n\nBut this looks pretty badass dude",
      "behind the motherboard, case is a lian li o11 mini",
      "7 fans at 800 rpm and for aio both at 900rpm and i can‚Äôt hear them honestly\ncase is very quiet and temps are good while gaming",
      "Where's the psu?",
      "i trade him against a 3080 FE so 730‚Ç¨",
      "I disagree. More fans at low RPM works better than less fans at high RPM. I've got a 7 fan system that was originally 5 fans (just one at the front, now three) and it's quieter because of it. I'm running bequiet! Silent Wings 3 and they're great.",
      "Critical question, how much did you pay for that 6800xt?\n\nThe build is beautiful.",
      "I have 13 noctuas in my machine running at 30 to 40% I can't hear a thing.",
      "I got my 6800 non xt for $989 at Microcenter. Not much coverage on it from reviewers but I love this thing. It demolishes 21:9 1440p.",
      "depends on your aio, trust me i try but i can‚Äôt dot it properly",
      "aio is alpenf√∂hn 280mm white, amd plate is included",
      "i know but i can‚Äôt because gpu is too big",
      "haha.  It's a Lian-Li 011 Dynamic case....the PSU goes behind the motherboard.  The case is a bit wide as a result.",
      "This should'nt be a problem as long as the highest point of the radiator is located higher than the pump.",
      "Where did you get the amd AIO?",
      "thank you !",
      "The tempered glass is off the case, so the interior is exposed.",
      "Why would it make a difference to the lifespan of the cooler? Whether it goes up or down first, it still has to come back down (or up), and those neutralize each other."
    ]
  },
  {
    "brand": "amd",
    "generation": "6000",
    "tier": "high",
    "matched_keywords": [
      "6800"
    ],
    "title": "High-end AMD RDNA 2 supply is dwindling ‚Äî RX 6950 XT, RX 6900 XT, RX 6800 XT virtually out of stock",
    "selftext": "",
    "comments": [
      "that tracks, our microcenter still has a bit, it was 25+ since last year, now its at 17, guess they ain't restocking no more. I'm hoping they will drop price to move inventory a good sidegrade from 6800xt assuming it goes down a hundred more\n\nhttps://i.imgur.com/rWgZNu1.png",
      "Tons of them left in Norway. The only one virtually gone with just a couple of overpriced units in stock is 6800 and 6800XT.\n\nEven the 6700XT is easy to get cheap, I'm really ashamed of how many green cultists there are in this country",
      "Yet the ancient RX580 is still plentiful.  What's your thoughts on that?",
      "brand new or second hand? cause all I see for Polaris are ex-mining card.",
      "elastic rob alleged plate longing snails lush zephyr cough tart\n\n *This post was mass deleted and anonymized with [Redact](https://redact.dev/home)*",
      "Cheapest RX 6800 XT cost 6600 NOK, you can get 7800 XT for 6700 NOK or a 4070 for 7000 NOK.\n\nI bought my 6800 XT used for 4000 NOK over a year ago ü§£",
      "Anecdotes be anecdotin': I've got a 6700 XT, *not* a high-end card at all, really, but goddamn does this thing **scream** at 1440p.  \n  \nRDNA2 is a really great value proposition, and we're kind of getting to the point in computer hardware that people don't need as much future-proofing as they once thought.  It's like what we're seeing with cellphones; new and improved hardware is coming out all the time, but for many of us the *old* hardware still does everything we need it to do and more.  \n  \n>\"My gaming computer has a CPU bottleneck.\"  \n>  \n>*\"But your game is running at 350fps!\"*  \n>  \n>\"Nevertheless.\"  \n  \nThis may not be good for AMD, or less than ideal, anyway, but at the same time I'm kind of pleased as an onlooker to see that consumer habits may be changing a little bit.  Not everybody needs a Hummer, y'know?  *Some* people can get the most out of buying a Hummer, but not most.",
      "6950 XT was available for a long time as a fantastic value 1440p gaming card. Now the 7900GRE is available at the same performance tier at a lower price and is less power hungry.",
      "Exactly, usually I don't keep a high-end card, generally I resell it shortly after the arrival of its replacement, an RX 7900XTX Sapphire NITRO+ model, really an excellent card very well cooled (despite its increased TGP from 350 to 430 Watts in stock setting), but for now I'm going to keep my \"old\" RX 6900XT from MSI Gaming \"Z\" Trio model, with \"Navi21XTXH\" chip instead of \"Navi21XTX\" (running at a stock voltage of 1.2v instead of 1.175v), rather than managing to sell it used for just over 400‚Ç¨/400usd",
      "afterthought escape square shy quiet door cake familiar depend outgoing\n\n *This post was mass deleted and anonymized with [Redact](https://redact.dev/home)*",
      "Brand new - Best Buy here are STILL selling XFX 580's.\n\nFunny thing you say about it being an ex-mining card.  Before COVID ruined everything, I bought a Sapphire Nitro+ RX 580 for $100 USD from r\\/hardwareswap that was an ex-mining card.\n\nThing is, the person was very transparent about how it was used.  Was in one of those mass-mining setups with an open bench.  24/7 AC-cooled room.  Underclocked at the beginning.\n\nI still have it to this day and I probably run it harder in a worse environment than he does (kinda dusty room, humid, gets warm during the day, etc) and it still runs like a champ.",
      "Yeah the 7900XT and XTX launched at too high a price and the 6950XT suddenly became much better value proposition.",
      "You might be on to something there.  I bought one a year or so ago as \"new\" on Amazon, and it turns out it had been (poorly) repasted at some point and was running hot.",
      "Sardo-what now? XD",
      "I bought my 6700 XT during the drought.  \n  \nI will not be answering any followup questions.",
      "what's wrong with sardines? :(",
      "[About that...](https://www.amd.com/en/products/graphics/amd-radeon-rx-7700-xt)",
      ">I'm really ashamed of how many green cultists there are in this country\n\nMore for yourself.",
      "Yeah it screams at 1440p in most games, but playing Horizon Forbidden West on my 6700XT makes it *cry* instead lol.",
      "100%.  I got a RX 6800 (non-XT) and loving it for 1440p.  Made the switch from Nvidia to AMD GPU for the first time in almost a decade and it has been great so far.  Bummed that I didn't wait a little longer now that models are as low as $380 but other than that no regrets."
    ]
  },
  {
    "brand": "amd",
    "generation": "6000",
    "tier": "high",
    "matched_keywords": [
      "6800"
    ],
    "title": "[Digital Foundry] AMD Radeon 6800 XT/6800 vs Nvidia GeForce RTX 3080/3070 Review - Which Should You Buy?",
    "selftext": "",
    "comments": [
      "The answer:\n\nNeither until prices and availability become sane.",
      "It‚Äôs not a question of which one should you buy but which one can you buy?",
      "It's really interesting that Rich holds the unpopular opinion that 16GB isn't worth it for these cards. Around 17:00 he says that AMD could have gone in for the kill by cutting VRAM down to 8GB and taking a big price advantage.",
      ">unless you want to keep your card for 4-5+ years\n\nShockingly, not everyone does yearly upgrades for the heck of it",
      "This isn't particularly an unpopular opinion, neither of the next gen consoles can get more than 10GB of VRAM and with features like DirectStorage coming to the PC which will allow you to stream textures directly to the GPU memory from a PCIe storage device the VRAM isn't going to be a big limitation even for textures which are absolutely insane and well above the point of diminishing returns. \n\nThe next gen engines are essentially built around asset streaming where both textures and geometry is streamed from fast PCIe storage directly to the GPU.\n\nI really don't know why AMD went for 16GB of GDDR6, could be just a numbers game, could be that their DCC color compression is still worse (still no DCC on ROPs for example) and it also looks like they will not be supporting inline compression for DirectStorage so they might need to compensate for that.\n\nAnd before people say remember Fury that's not the same case, the issue with the Fury was more complicated.\n\nThe Fury came out when consoles could already allocated more than its total VRAM (at least on the PS4 which allowed VRAM allocation of upto 6GB) and if a game say had to use 1GB extra than what the Fury could support you would be at a deficit of 25% that's a lot to swap in an out, and much harder to optimize for than 12.5-10% of a 8/10GB VRAM GPU today.\n\nThe APIs at the time of the Fury X were also much worse in terms of direct memory management, with DX12 and Vulkan you can do much better fine grain allocation and control combined with essentially zero copy access to system memory and to any memory mapped IO address space and you get a very different situation than 5 years ago.",
      ">  the unpopular opinion that 16GB isn't worth it for these cards.\n\nProblem is 16GB of VRAM might not even matter with these cards. They live/die on whether the infinity cache is being effectively used. If something is too large that there are a ton of cache misses the thing starts falling on its face. There exists the potential that nothing will be able to actually leverage that 16GB without slamming into the infinity cache limits like a truck into a concrete wall.",
      "Game coverage is a more important part of their channel. And curently there are 3 new consoles out there with plently of games to test and compare. Basicly the most important time for a channel like they are.\n\nIm sure they will release some Zen 3 video's as they get around to them.",
      "The recommended GPU for 1440p at *ultra* settings without RT is a 2060.\n\nI'm not sure what framerate they're targeting there, but why does everyone seem to think that the game is the next Crysis?",
      "why would people NOT care about DLSS? Its free performance and huge difference",
      "Same, I am on a waiting list for the 3080 and 6800 XT. Right after the launch of the 3000-series I thought I would get the 6800 XT because its probably easier to get but now it looks like the opposite. If I cannot get a GPU before December 10th I will see if I can run CP2077 at 1440p on my GTX 1080. Spending ‚Ç¨800+ on a GPU seems pointless if it works somewhat decent on my current GPU.",
      "I think the 3080 is the better choice if you can get it. DLSS and better RT performance is worth it in the long run.",
      "How about we ask this question again sometime in March when there might be a hope of there being stock to purchase?",
      "Can't believe they would mention a new feature RDNA2 supports.  Insane.",
      "A game using more than 8 GBs of VRAM =/= a game actually *needing* more than 8 GBs of VRAM. Lots of engines will do the smart thing and pack whatever VRAM is there full because then its there for faster access, it doesn't mean those engines won't give good performance with identical settings on less VRAM. \n\nCould also be the reason for occasional stutters in Horizon Zero Dawn - game needs to load something, on systems with large amounts of VRAM available it can grab it faster. \n\nDoom Eternal runs absolutely fine maxed out at 1440p on 8 gig cards.",
      "Ill follow 3 bots and atleast in europe... 3080 and 3070 drop atleast 6x more often than amd cards...\n\nsadly around 60% of those cards at ridiculous prices",
      "also constant harassments by console fanboys takes toll on your work.\n\nJohn Linneman had to lock twitter account to get away from that",
      "Even assuming that happens... what makes you think Nvidia won't have significant advantage with ML upscaling performance like they do with RT? You can't ignore that Nvidia has dedicated hardware for those tasks.",
      "The trend for VRAM usage is going to follow console game development. The reason most games are using 4-6Gb of VRAM currently is because that is the limit available in the last generation consoles. If that trend continues, we will start to see 8-10Gb of VRAM usage at 4k instead of the 4-6Gb we see now. I would expect any games developed specifically for the PS5 or XSX to have high VRAM requirements for their max settings. Also, keep in mind PC versions often get an ultra texture pack.",
      "This guy gets it",
      "The people here rationalizing buying an AMD card this generation are absolutely ridiculous"
    ]
  },
  {
    "brand": "amd",
    "generation": "6000",
    "tier": "high",
    "matched_keywords": [
      "6800"
    ],
    "title": "just got a used RX 6800 XT Sapphire Nitro for $260 USD in good condition",
    "selftext": "upgraded from a rx 6600, this card is a beast!\nundervolted at 950mv, it only use 215w of power.\nthe only complaint that i have is this card got some coil whine but that's okay, is it normal for high powered cards like this to have coil whine?",
    "comments": [
      "It's fine the coil wine won't affect anything other than give you a headache I suggest turning fans up so you just can't hear it",
      "Pretty sure 6000 series is known for bad coil whine. Mine also has it",
      "Set an FPS limit and the whining stops. As much as the monitor Hz. Although if your monitor is 144Hz or above it probably won't go away. The point is that the less FPS the card has to work at the quieter the whine will be or disappear.",
      "I can hear mine wail. It reminds me of my old Mac that I could hear as it was ‚Äúthinking‚Äù while in use.",
      "Mine is as silent as an owl diving for its meal. Red devil 6700xt.",
      "Iirc coil whine from the GPU can be caused by a mix of the GPU, PSU, and/or \"dirty power\".",
      "Ayyee I have this card!! Mine is whisper silent too!!",
      "Awesome price, gg üëè",
      "Wow, what is this cpu cooling? Looks super cool",
      "Oh man, what a similar issue!! \n\nThe new 6800XT wouldn't boot. I went further trying to figure out my issue with a backup card, a 5600XT I had. Would run for a bit and suddenly shut off. Week into using I deducted it was either mobo/PCIE or PSU.\n\nWas both 8 pins that were melted and just noticed 2 days ago that my power supply has burns.\n\nI have zero coil whine after getting a BeQuiet 1200 watt.",
      "Good score dude, coil whine is fairly common though. In my experience (XFX 6800xt swft) the sound level decreases with an undervolt and the pitch shifts with the set clockspeed.\n\nAs for fixing it, people say that different power supplies can help. Unfortunately that wasn't the case for mine",
      "You can use superglue on the chokes to stop/minimize coil whine.",
      "Sounds like a good deal to me.",
      "My 6700XT has pretty bad coil whine but I \"fixed\" it by underclocking/undervolting slightly.",
      "My 6600XT Gaming X doesn't have no noticeable coil whine.",
      "Luckily I hit the silicon lotto and my 6800 is silent",
      "Pretty sure it's just 2 rgb fans on a either side of a mounted air cooler",
      "Kinda silly nobody fixes this stuff at the factory",
      "What a coincidence! My issue was also the psu. First card I got worked perfectly, until my pc randomly shut off and refused to turn on in any way until swapping the gpu out. Second one wasn't stable at stock clocks for even a second, and the third worked fine except for very specific scenarios in very specific games where it would cause a system restart. Deduced it was likely the psu having poor transient spike response, it was a pretty cheap corsair 750 watt from 2017. Got a much better A tier 1000 watt psu and have never crashed since. Coil whine got better after swapping psu, but not by a whole lot",
      "Great find! I have the power color 6800xt‚Ä¶ I don‚Äôt know what this coil whine fear is, I‚Äôve never heard it on mine. People seem to make a big deal about it"
    ]
  },
  {
    "brand": "amd",
    "generation": "6000",
    "tier": "high",
    "matched_keywords": [
      "6800xt"
    ],
    "title": "5800x3d with a 6800xt. Upgrade from a 2700x and 2070s, very big difference",
    "selftext": "",
    "comments": [
      "[https://www.reddit.com/r/Amd/comments/zzt6ze/my\\_entry\\_to\\_team\\_red\\_5800x3d\\_6800\\_xt/](https://www.reddit.com/r/Amd/comments/zzt6ze/my_entry_to_team_red_5800x3d_6800_xt/)\n\nIts fun to consider that whilst these two PC's look completely different, they're identical in performance. :D",
      "His probably costs a fortune less so props to him for knowing how to save üòÖ",
      "Ayyy I also have that lego set!",
      "Aww, such a wholesome response üòä",
      "These ‚Äúfluflu things‚Äù to make the setup more pleasant is super expensive not everyone can expend the time or money doing these things, just that PCI cable from this post is almost 100$, not even counting the NXZT things, for me, we have some brands that do the same costing half‚Ä¶ it‚Äôs not critique, this build is beautiful and congratulations, but I wish these things could be more ‚Äúaccessible‚Äù so everyone could have a good looking case. There is something special when you look to your setup that yourself build and it is good looking",
      "The theme is god damm good",
      "The build is fantastic but the photography is even better! Love it!",
      "It's not about the cost for me. I legitimately want a computer case that has no glowy bits and doesn't stand out. I want it to just be an unassuming box of some neutral color.\n\nAcoustics become my biggest concern after that. Get me some silent noctua fans and some water cooling to minimize the background noise.\n\nNothing wrong with wanting a pretty case to look at. When I was younger I would have loved something like OP made. Certainly way better looking than anything i've built. \n\nNow just give me a NR200 and no RGB on the internals and i'm happy. lol",
      "Lian li o11 dynamic mini",
      "Came here for this too just got it for Christmas mom wanted me to build with my little siblings but have something ‚Äúcool‚Äù to display still",
      "It‚Äôs a great case, surprising amount of cable management space especially if you don‚Äôt have a 2.5 or 3.5in drive. Really easy to build in too",
      "Now imagine he went 5800X3D",
      "[should have posted this earlier‚Ä¶](https://pcpartpicker.com/user/Romanoodles_/saved/#view=6nLRVn)",
      "Nice looking build dude. Is it possible to get the name of the case?",
      "Just helped my buddy go from a 1800x to a 5600x on the same X370 board. Crazy how much of a performance upgrade that was. From ~2fps in highly modded XCOM 2 to ~15fps. And the only change was the cpu.",
      "Welcome to Team Red ü¶æ GPU wise anyway :) \nWana sell that 2700x?",
      "Lian li sl120 fans and the table is the ikea karlby",
      "Yeah I do anyway because of the aio block, but I just didn‚Äôt have the money at the time to purchase two extra fans for the aio to make them all match, although I will be getting the matching fans soon",
      "Is that the one where the petals are little pink frogs? It wqs posted on /r/mildlyinteresting a few days ago",
      "thank you. much appreciated."
    ]
  },
  {
    "brand": "amd",
    "generation": "6000",
    "tier": "high",
    "matched_keywords": [
      "6800"
    ],
    "title": "[HUB] Radeon RX 6800 XT vs. GeForce RTX 4060 Ti 16G, 40+ Game Benchmark @ 1080p, 1440p & 4K",
    "selftext": "",
    "comments": [
      "These comparisons will always be interesting, but at  the same time pissing in the wind \n\nThe 6800xt is undoubtedly the better GPU, but the 4060ti will be more popular and outsell it regardless",
      "tl:dr; RX 6800 XT is:\n\n* 19% faster on average @ 1080p\n* 26% faster on average @ 1440p\n* 32% faster on average @ 4k",
      "Which is a damn shame. The 4060 series cards this generation are absolute dog shit, but people are already buying them in droves based on the latest steam hardware survey",
      "We couldn't convince people to buy 570s over 1050tis back in the day when they would win in 100% of everything. No but.. raytracing dlss 3d modeling ai something something the 1050ti literally had 0 advantages and it way outsold the 570. Kinda hopeless hoping people buy more amd cards today when it didn't happen back then. I just want some real competition which ultimately benefits the customer but if amd sells faster cards and Nvidia sells just as many cards as before we won't be getting that",
      "Prebuilts.\n\nOnce you realize like 90% of PC gamers are buying prebuilts, you will see why the 3050 outsold the 6700/6650 etc whatever.\n\nThe 4060/ti is going to be a huge prebuilt card, it‚Äôs likely going to outsell all of RDNA2 and 3 combined lol.",
      "In Germany the cheapest 4060ti 16GB is 550‚Ç¨, while the cheapest 6800 XT is 530‚Ç¨. DLSS3/frame gen and powerdraw alone should never be enough to warrant paying MORE for 20% less performance...",
      "RX 6800 16gb would be a better comparison, its faster, cheaper and more similar in efficiency.",
      "Now that would be shocking, given it's an *incredible* 128bit interface, compared to the 256bit interface of the 6800XT (and 3060 TI).\n\nIt truly is the worst card released in years.",
      "Well, still not regretting getting my 6800XT a year ago and for less than they currently sell for even.",
      "They use different nodes so die sizes aren't comparable. When you look at transistor counts (22.9 billion on 4060 Ti and 26.8 billion on the 6800 XT) you see that the 6800 XT has about 17% more transistors and is about that much faster at 1080p and even faster than that at higher resolutions. So technically speaking, in this situation, at higher resolutions AMD has better performance per transistor than NVIDIA, mostly due to the small 128 bit bus of the 4060 Ti. Also of course the 4060 Ti is the more efficient product because it uses the better node.",
      "Then don't watch it? It's really just that simple.",
      "Fwiw, that's with RT included. For those who care, It's 23%, 30%, 37% without.  \n  \nWhat I found interesting is the 6800xt actually wins somewhat comfortably in most of the RT tests, but cyberpunk is notably where it loses badly. Not sure of the reasons (maybe it just does more ray tracing?) But now I'm realizing how often this game is used as a demonstration of the huge RT advantage Nvidia has, and - based on this data - it's actually an outlier. (Ie. AMD RT is obviously weak, but cyberpunk seems to exaggerate it)",
      "Literally no advantage?  How about power use?\n\nNormally that's not such a big deal, except the 1050 Ti can be entirely powered off the PCIe slot, whereas that's not possible for the 570.  That's a big difference for OEM builds where there's a premium just for a PSU that has a PCIe plug on it.",
      "I don't know, I do think it differs per region. In my area, the 4060TI 16GB is a cool 100 euro more than the 6800. That's not really a good comparison, as they are in a different price class.",
      "This is exactly why the 1050Ti did so well. It was the go to office PC upgrade card because it runs with no external power. \n\nI bought a 1060 6GB over a 480 8GB because the 1060 was marginally faster, used less power but also happened to be same price in stores! ~¬£230. \n\nIf you‚Äôre not winning the metrics you‚Äôve got to win on price or you‚Äôre just not going to sell in to a dominant market. It‚Äôs pretty frustrating. \n\nIf the 480 8GB had have been 199 in store it would have been a no brainer.\n\nMan I wish 60 tier cards still cost those prices üòû",
      "Ada is impressive technologically. A damn shame they are just selling 30% over what they should.",
      "No problem, I hope he enjoys it.  \nHis milking helped me to buy RX6800 non-XT over 3070 and now I'm really happy that I went with his suggestions to buy 16GB card.",
      "I think the point is you can get the 4060ti and 6800xt for about the same price.",
      "They showed a power consumption graph...",
      "Because they are similar in price maybe?"
    ]
  },
  {
    "brand": "amd",
    "generation": "6000",
    "tier": "high",
    "matched_keywords": [
      "6800"
    ],
    "title": "Why is my RX 6800 pushing 330w?",
    "selftext": "",
    "comments": [
      "This is the game that killed those bad 3090s, right?",
      "Hi, a while ago [I made a comment on this here](https://www.reddit.com/r/Amd/comments/psjgfv/radeon_software_adrenalin_2192_release_notes/hdv9t4y/)\n\nit seems that Radeon Software and other applications like GPU-Z are reporting incorrect GPU power consumption figures on 21.9.2.\n\nThis cannot be observed on the 21.8.2 WHQL driver. I validated this with some benchmark runs (gaming and synthetic) and a socket wattmeter to measure any difference in total system power consumption (for which there was none between the two aformentioned drivers).\n\nI wouldn't worry - this isn't a case of new world bricking your GPUs like from a few months ago with those EVGA 3090s.\n\nHopefully this reporting bug can be fixed",
      "Did you increase the power limits?",
      "Its a stock card, fan curve has been changed to be more aggressive.",
      "No, every card has firmware/driver limits and New World shouldn't be held responsible for EVGAs failure.\n\nhttps://www.pcworld.com/article/3632091/evga-explains-how-amazons-mmo-bricked-24-geforce-rtx-3090s.html\n\nIt's bad form to have uncapped fps menus, but the cards dying was due to a defect, and triggered by a near firmware limit power draw. It's up to the manufacturer or AIB partner to ensure their limits and quality standards.",
      "The game did a thing that probably wasn't good (uncapped FPS menus).\n\nHowever, that shouldn't be capable of killing a GPU. Uncapped FPS Menus should be harmless, just a waste of electricity. Maybe make your PC kinda loud as all the fans ramp up to cool the GPU.\n\nIt was EVGA's fault that the cards _died_ due to it; because their firmware was incorrect. It's up to NVidia/EVGA to make sure that the firmware contains the proper power limits to prevent the card from self-destructing.\n\nThe game just happened to be the first time that conditions aligned correctly for the incorrect values in the firmware to actually cause _immediate_ hardware damage. It's entirely possible (if not likely) that under normal usage, those cards would have suffered an early death due to the incorrect firmware limits.",
      "Check HWinfo64.",
      "New World",
      "24 total EVGA cards died‚Ä¶And EVGA has fully admitted it was a manufacturing flaw.\n\nThat story is about the most overblown overreaction ever concerning pc flaws.",
      "Reference design or partner card?",
      "This. IIRC they even 'fixed' it by capping the menu items that were supposedly going uncapped.\n\nIt's kind of like the entire game engine is being developed as they make the game. lol",
      "This is post 21.9.1 driver \nThe cards are in fact pulling a lot more power than before \nMy 6800xt spikes to 370 during benchmarks after 21.9.1",
      "To summarize, yes this was the game lol",
      "Just use Radeon chill. Have mine set with lower bound of 119fps and upper limit of 164fps. This keeps it near the refresh rate without dropping so low that I'd notice it in games.",
      "No, the card should be able to go right up to the manufacturer firmware limits without dying. New World can't and didn't bypass these limits.",
      "Limit your fps.",
      "I generally observed a persistent offset but there were also reporting spikes. None of this was true to the power usage from the wall in any case.\n\nYour GPU won't be using more power under load on 21.9.2",
      "Games don't control hardware, they just contain instructions on how to render frames.",
      "This is untrue:\n\nhttps://www.reddit.com/r/Amd/comments/psjgfv/radeon_software_adrenalin_2192_release_notes/hdv9t4y/",
      "It *was* qualified as \"those **bad** 3090s.\""
    ]
  },
  {
    "brand": "amd",
    "generation": "6000",
    "tier": "high",
    "matched_keywords": [
      "6800xt"
    ],
    "title": "5600x and xfx merc 319 6800xt",
    "selftext": "",
    "comments": [
      "Merc gang represent",
      "Man that xfx card looks so good! I got a red devil 6800xt cause that's all micro center had. Great looking build!!",
      "There's one here ‚òùüèº",
      "I've been drooling over the MERC 319 since it was released. How do you like it?",
      "Hey, I love my 6900 red devil!!",
      "Still playing with toys aren't we?",
      "Its great except in RT like all the amds",
      "Yeah it's a cool build but idk why people put toys in their cases",
      "If you can get one, do it, but as a proud owner of the 3060 Ti, real time raytracing just isn‚Äôt quite ready yet for my personal usage: high frame rates at 4K is amazing (DLSS for my card gets me there easily), but I dip below 60 FPS with most RT on. \n\nNext generation will see AMD and Nvidia‚Äôs RT solutions hit the mainstream I think",
      "Oh don't get me wrong, I love the red devil card, it overclocks like a beast!",
      "I've had nothing but amd, but I'm kinda considering looking for a 3080 with the way RT helps with lighting it'll help me see better. I've got horrible vision so I can use all the help I can get",
      "I've always been an amd guy and this is the first time I went nvidia, I got a 3070, RT for me isn't the best feature of the RTX series, DLSS is, and it's fantastic, it will increase the longevity of the cards",
      "07",
      "I've got the same card and I absolutely love it, it's tank. Never seen a card fly up to 2550 and stay cool on air generally at about 280w. Amazing upgrade.",
      "great build!",
      "I'm a cool dad",
      "Dude, it stays cold... It's ridiculous!",
      "It's a nice card, surprisingly no sag either. It's very well built!",
      "I found someone locally wanting to trade my gigabyte 3070 for an xfx 6800xt‚Ä¶ till I found out the 6800xt is 340mm long, way over my cases 320mm max",
      "Why? I think it looks fine. The ones that I think are dumb are the ones that don't go with the color theme of the case. So many just put random shit in their case."
    ]
  },
  {
    "brand": "amd",
    "generation": "6000",
    "tier": "high",
    "matched_keywords": [
      "6800"
    ],
    "title": "The 6800 / 6800 XT is set to launch at 6 am PT on 11/18 per NewEgg customer service.",
    "selftext": "",
    "comments": [
      "The real helpful portion will be if newegg sends out emails with links to the product again. Because last time those pages weren't showing up from searches.",
      "Here‚Äôs your email two hours after the stock is out, sir",
      "And they'll be sold out before anyone has enough time to watch a single review video.",
      "Good luck. I'm hoping that i can snag a 6800xt since i couldn't get my hands on the 5950x last time",
      "If AMD follows CPU review times which im sure they will. Then the GPU's and the reviews will lauch at the same time. Which is fucking stupid.",
      "And the motherfuckers will be on eBay by 6:01 for double the price.",
      "and here Amazon sent me two accidentally lol",
      "Just remember to look at Newegg's return policies and see if you're ok with being stuck with a launch day GPU's problems backed by that return policy",
      "I wish they'd copy NVIDIA and release the review embargo a day or two beforehand",
      "I'm going to upvote this for visibility as this question is being asked every 10mins at the moment.",
      "There was a big ad on the front page with direct links. That's your best bet if they make another ad.",
      "Fortunately their holiday return policy extends until the end of January.\n\nIf you file an RMA with them and they don't have any replacements in stock, they will offer you a refund.  They've done that twice for me before anyway.",
      "For the Ryzen 9 launch, I was seeing a patient at 8:55am EST and about to wrap things up when he decided to tell me his life story when I only wanted to know if he had any drug allergies. Missed my window to order it.",
      "Set to Out of Stock for 6am PT.",
      "PT = Pacific time? As in PST?",
      "That‚Äôs why I wouldn‚Äôt order cards from Newegg. Good chances you stuck with a heavy whine card",
      "They usually don't let you return GPU's for refunds.  If you want to return for replacement, they have a very narrow definition of what's considered a defect.  For example, they don't consider deafening coil whine to be a defect.",
      "Amazon had solid stock on all but 5950x for at least 5 minutes.  But you should absolutely stick around to see if units pop back into stock",
      "that's where you messed up. I was there the first 20 seconds too and I refused to believe they were sold out that fast. I refreshed the page for 15 minutes straight and that's when I got a \"see all buying options\" button. There was not even an \"add to cart\" button\n\nI sped through that checkout so fast.\n\nIt looks like those pages were just being DDOSed and the products were glitching in and out of stock, at least on Amazon\n\nWould explain why Amazon sent me two since that was probably a glitch thanks to DDOSing the page lol",
      "Like a rocket ship straight into the reseller's baskets."
    ]
  },
  {
    "brand": "amd",
    "generation": "6000",
    "tier": "high",
    "matched_keywords": [
      "6800"
    ],
    "title": "[GN] AMD Radeon RX 6800 XT GPU Review: Gaming, Thermals, Noise, & Smart Access Memory Benchmarks",
    "selftext": "",
    "comments": [
      "TL;DR:\n\nStrong rasterization performance, trades punches with the 3080FE, SAM enabled does something, not in all games, RAGE Mode is useless. Raytracing performance is bad, pretty bad, and no DLSS alternative kills it if you want to play Raytracing enabled games at high resolution and graphic detail.\n\nGN says the stock cooler is mediocre, ~~but they do noise normalized testing~~ testing done with auto settings, LTT shows that it performs on par with Nvidia custom solution, but they didn't disclose noise levels or fan speeds.",
      "Ray Tracing performance is surprisingly bad. \n\nConsidering it's a big selling point for the consoles, I expect pretty much all AAA games to have some sort of ray tracing from now on. \n\nTo me, this makes the 6800XT not competitive at 10% lower price than the 3080.",
      "Nothing about this is shocking though. We knew the RT performance was pretty bad compared to Nvidia. It's their first generation, same as how Turing RT performance was terrible.  AMD is working on their own DLSS. And 4k difference comes down to memory bandwidth. I'm actually happy for the AMD crowd. It's about time there's a direct competitor to Nvidia. I'm a 4k player and have a 3080 but damn if this isn't exciting because it pushes Nvidia AND Amd to push the envelope. 1440p non RT performance is absolutely mind-blowing",
      "AMD is good for 4k too, just a little behind nvidia, only falls short on Ray Tracing and DLSS for gaming.",
      "TUF 3080 destroys the FE thermals at the same price",
      "So Rage Mode is pretty much useless then? Seems like OCing the card provides much better performance numbers.   \n\n\nI wonder if thats a software issue?",
      "Most of the AIB cards do not have worse cooling though, and they generally have parity with the FE in the non-OC editions. Many of the AIB cards (Gigabyte Eagle, Asus TUF, EVGA FTW3) have noticably better cooling than the FE as you can see in GamersNexus' tests.",
      "Those who are patient are now rewarded. The better value play here is the 3080 given these benchmarks given that it's only $50 more. People will buy whatever they can get their hands on, and if you're happy, great. But I think Nvidia's got my money for this round.",
      "The testing in the review was actually with auto settings, as we said, we didn't change the fan speed for those tests. That will be in our follow-up testing.",
      "This doesn't look like an \"Nvidia killer\" to be honest",
      "It only works with the game RAGE.  Every time you drop below 60fps you get a tweet from John Carmack calling you a filthy environmentalist.",
      "Man Nvidia was so smart with these founders edition cards.\n\nThere are hardly any of them. They sell them at barely a profit. AIBs cannot match the cooling performance of those for anywhere near MSRP.\n\nAnd yet every comparison ever is to the founders edition performance at MSRP price. When 99% of people owning 30X0 cards will have to pay more for partner cards of equivalent or worse cooling. Just to get parity with founders edition you have to pay $50 more for the best value AIB cards due to overclocks.\n\nThe channel, Moore‚Äôs Law is Dead was dead on about this. The FE price and thermal performance is locked in for reviews but most people will have to pay slightly more for either shittier cooling or a lot more for a card with parity. \n\nFor those lucky few getting MSRP FE 3080, it‚Äôs a great deal.",
      "As expected, similar performance between 3080 and 6800XT, except when it comes to Ray tracing (and DLSS of course).\n\nIf you care about those 2 things (I do!) Nvidia is the only option sadly. (I say sadly because we can all agree that more competition is better)",
      "what a dissapointment\n\nEDIT: performance is okay, but they butchered the prices.",
      "Rage mode is just a max power consumption slider. What were you expecting it to do?",
      "**RAGE MODE** makes the fans louder so you can hear the card **RAGE**, how's that not worth it?",
      "NVENC OP",
      "Yah he talks about DLSS and Ray tracing in a few games and as expected, Nvidia destroys AMD for real time Ray tracing (even without DLSS), and if you account for DLSS, it's not even a competition... So let's hope AMD brings something similar to DLSS soon!",
      "I'd say 'viable' for 4k, bearing in mind that it's impossible to expect more than \\~80 fps in any case for \\*generic new release\\* unless it has DLSS.",
      "And streaming."
    ]
  },
  {
    "brand": "amd",
    "generation": "6000",
    "tier": "high",
    "matched_keywords": [
      "6800"
    ],
    "title": "PowerColor RX 6800 Red Dragon Review, Power, Thermals, Overclocking & Gaming",
    "selftext": "",
    "comments": [
      "I‚Äôve honestly stopped watching and reading reviews since there is basically zero stock. Perhaps in 6 months I‚Äôll watch some reviews, when the products are maybe in stock and price / performance can be considered. Right now the only relevant part of the review is where they sit in the stack.",
      "Remember when AMD made fun of NV and said they'd have more stock then they had less?\n\nFun times.",
      "For 500‚Ç¨, fantastic. For >1000‚Ç¨, not so much",
      ">AMD is an amateur company\n\nDumbest hot take I've seen on this sub since I created this account.",
      "\"*Hardware unavailable*\"",
      "AMD also said they'd help create an environment for AIBs to sell at MSRP. It's very difficult to take anything AMD says seriously anymore.",
      "There‚Äôs stock, it‚Äôs just 2-3x the price",
      "\"*pOoR vOlTa*\"",
      "it won't ever be 500, we both know that :D it won't ever be 600 either :(",
      "I‚Äòm sorry, but this is one of the worst takes I‚Äòve ever read, period. You lost me at  ‚Äûamateur company‚Äú.\n\nI hate to break it to you, but Intel/nVidia aren‚Äôt perfect either, far from it.",
      "Maybe there is stock in your area... but there isn't in most.\n\nIn Canada AMD 6000 line is 10x harder to find then RTX 3000 cards.",
      "00:00‚Äã - Welcome back to Hardware Unboxed  \n01:32‚Äã - A look over the graphics card  \n03:24‚Äã- Graphics card teardown  \n05:02‚Äã - Stock Stats  \n05:47‚Äã - Overclocked Stats  \n06:29‚Äã - Shadow of the Tomb Raider  \n07:22‚Äã - Power Consumption  \n08:02‚Äã - GPU Edge temps  \n08:18‚Äã - GPU Hotspot temps  \n08:31‚Äã - VRM temps  \n08:48‚Äã - GDDR6 memory temps  \n09:12‚Äã - Normalized GPU Edge temps  \n09:41‚Äã - Normalized GPU Hotspot temps  \n10:02‚Äã - Normalized VRM temps  \n10:17‚Äã - Normalized GDDR6 memory temps  \n10:30‚Äã - Final Thoughts",
      "How do they take themselves seriously?",
      "Yeah. HUB copies and pastes the timeline titles and sometimes forgets to edit some stuff.",
      "What are you expecting?",
      "I have 99 problems but a driver ain't one.",
      "Should add finding the card and paying for it to the review process",
      "Not sure if /whoosh on my part or what, but where the banner would usually read \"Hardware Unboxed\", it says that instead. I chuckled.",
      "tbh you shouldn't take anything ANY company says seriously\n\nall companies exist to make money, we are walking wallets to them",
      "For the same reason we watch natural history programmes about giant pandas or blue whales I guess."
    ]
  },
  {
    "brand": "amd",
    "generation": "6000",
    "tier": "high",
    "matched_keywords": [
      "6800xt"
    ],
    "title": "Went from Vega 56 to 6800XT for a net of $350. The deals are real right now.",
    "selftext": "",
    "comments": [
      "Blown away by the performance of the 6800XT. I game at 1080p 144hz and this card handles ultra settings in everything effortlessly.",
      "Haha nice deal. Here where i live the cheapest is only 650-700‚Ç¨ üòù and the 6950xt is 900‚Ç¨",
      "got mine the 28th from Asus.com. 529.99 for a new 6800xt tuf",
      "If you ever want to, this card will destroy 1440p ultrawide like nothing and the visual upgrade is well worth it.",
      "I wouldn‚Äôt say destroy, especially depending on your settings and the game you‚Äôre playing. It‚Äôs definitely an awesome card though.",
      "Bruh 6950 for a 1080p display... feelsbadman. Get yourself a nice 1440p ultra wide lol",
      "This. I mean, destroy rocket league or fortnite? Sure. But not current and upcoming AAA games",
      "Nice one man!\n\nLooks beautiful.\n\nI upgraded my 580 8gb sapphire nitro+ to a 6800xt reference model, got it at launch for ¬£659.\n\nI know the net is 350...but how much was the actual 6800xt out of curiosity.",
      "Huge upgrade- congrats",
      "I got a 6800xt for Christmas, had the 2060 before. It‚Äôs a great upgrade. It destroys 1440 p also. Congrats man I see no need for anything higher when this card is a beast",
      "That's a screaming deal!",
      "7900xtx is around 1600 ‚Ç¨ here un Austria. That's 60% above MSRP.",
      "This looks like the french prices after spending 3 months looking for a deal on the 6800xt.\n\nBtw, be careful as there are some scammers on Amazon that proposes flash deals on 6800xt and 6950xt on Amazon France. Once you place your order, they cancel it and send you an email saying something along the lines: this promotion is only available for direct transfers. Here is our Spanish IBAN, please send the money and you will get your card.\n\nThey hacked the accounts of legit Amazon seller and do this kind of shit. So be aware :)",
      "I installed a red devil 6950 today, also upgraded from a vega 56 and playing at 1080 lol. It draws less wattage than the Vega did in the one game I play.",
      "1080p for a 3080 equivalent is wild, but glad your enjoying it. Might wanna invest in a 1440p 144hz monitor soon tho.",
      "It's impressive how much more efficient RDNA2 is compared to Vega.",
      "Thanks!",
      "Yeah that's my plan",
      "Yep, mine was like new. Wouldn‚Äôt have known it was used if it weren‚Äôt for the open box. Great deal for $475!!",
      "I had a 5700xt and sold it during the mining craze. I inositol bought a 3070 ti but couldnt reason spending so much so i sold it for the same price  basically. I ended up buying a 3060 which is similar to the 5700xt. I told myself i would upgrade when RDNA3/Rtx 4000s come out but the prices has been disappointing. So i sold my 3060 and bought a used 3080. Went from a 5700xt to a 3080 for a net price of $250."
    ]
  },
  {
    "brand": "amd",
    "generation": "6000",
    "tier": "high",
    "matched_keywords": [
      "6800"
    ],
    "title": "Excellent news: Radeon RX 6800 XT is a horrible mining card",
    "selftext": "https://www.youtube.com/watch?v=HoMRPUAywkk\n\nEthereum:\n\nRadeon RX 6800 XT: 59 MH/s\n\nGeForce RTX 3080: 86 MH/s",
    "comments": [
      "Bro...why you have to go and say that..",
      "Yeah, because nobody has written an algorithm yet to exploit the 128MB 2TB/s cache",
      "Are miners still using consumer GPUs? I thought they have moved on to ASICs?",
      "Oh no, a miner won't be interested in my second hand card! That's awful.",
      "For Bitcoin yes. Other coins use different algorithms some of which are not good ASIC candidates.",
      "There are fewer things worse for the world than miners. Globally, they use as much electricity as a small sized first-world country and that electricity is being used to solve pointless equations.\n\nCrypto is a plague.",
      "Mining is DESIGNED not to work well with caches. It's one of the ways they make designing asic's difficult.",
      "No...\n\nMiners run 24/7, ‚ÄúGamers‚Äù go to sleep lol.\n\nAlso I get your point we waste electricity simply for entertainment.",
      "There is too much random reads on a huge dataset going on to make use of cache. This is by design.",
      "What about gamers? \n\nThey play a pointless game that has negligible positive effects on the world, if positive at all\n\nI am a gamer\n\nI get miners use a lot more power, but surely all gamers use more than them right?",
      "There are people that have mining farms that fill up a warehouse. Pretty sure it's a bit of a problem in China.  Or it was at one point at least.\n\nOptimized mining rigs can be efficient.  When I had a 6 gtx 1070 miner, its total power consumption was similar to my overclocked 4790k/980ti rig.  It was around 200Mh/s.",
      "it was sort of obvious that they'd write an algo to take advantage of that bigass cache",
      "Yep. But I mean, it's all a matter of time. Mining is a zero sum game, and if the margins get competitive enough, people will start R&D on ASICs.",
      "Many Coin dev dislike asics as they centralised the network and go against the ideal view of cryptocurrency. They change the algo to be asic resistant like monero did.",
      "Mining is bad. Crypto is not. They are not the same.",
      "GPU mining is actually quite profitable right now with ETHASH / Ethereum.  Even with this RX 6800, my calculations are that you can get back the cost of the card in 13-14 months depending on the electricity costs (65MH/s @ 250W is my guess on this card).   Which isn't bad.  What people don't know is that these algorithms are always improved upon, and when new cards come out, they are not optimized at all.  Plus,  hashrates+efficiency can improve when modded bioses are out for them (AMD cards only) and proper OC/undervolt tuning. \n\nIt's way too early to tell.",
      "When the hell is Etherium moving away from proof of work to proof of stake?\n\nWasnt that supposed to happen within a year or so?",
      "You don't buy tech for a resale purpose buddy",
      "Nah, that is literally not true.",
      "This is a dumpster fire of a comparison. At least gaming has provided value to the community. Bitshit hasnt."
    ]
  },
  {
    "brand": "amd",
    "generation": "6000",
    "tier": "high",
    "matched_keywords": [
      "6800xt"
    ],
    "title": "Finally finished this buildü§© 5950x, 6800xt.",
    "selftext": "",
    "comments": [
      "Is your camera covered in Vaseline?",
      "Nice! I'm thinking of buying a 6800xt for my 5900x. Still waiting for a good deal on it.",
      "Never understood the logic of making your camera utter shit in the interest of it not breaking.\nWhy have a good camera in the first place?",
      "Lmfao no I have a lens protector on that makes videos look a little foggy in dark rooms",
      "I've got a rotated monitor. Devs love them as lines of code tend not to be very long, but you'll have a lot of them, so it's the optimum use of screen space.\n\nIn fact, I use it kind of as a measuring stick; if I have to scroll to see a whole line, that's a sign that I should think about what I'm writing and if it should be broken out a little bit more",
      "Got mine for msrp from a seller on marketplace that bought the wrong color. I was like ‚Äúdamn man must be nice to get one gpu let alone 2 bc you got the wrong color‚Äù",
      "I get you. I am a developer but I use 4k screens instead as everything fits on the screen. With c++ lots of lines are long but I have considered trying to rotate one of my 4k screens.",
      "Can you drop the primary monitor‚Äôs wallpaper?",
      "Thermal take p3 core",
      "You can get a 6900xt and 6750xt and 6950xt on the actual Amd website for msrp almost every day",
      "Nice, how does that rotated monitor thing work out? I've seen tons of people with setups like that but I never understood it. Do you use that monitor only for chat programs or something? How do windows work if you drag them onto there since the aspect ratio is opposite.\nDo you have to shrink web pages to make them fit properly? I use a triple 4k setup and my monitors support auto rotate, but I've never done it (and my cables would have to be lengthened) so I'm just wondering.",
      "I‚Äôm getting the 5950x soon what are your temps like?",
      "It's an animated version of this: https://www.pixiv.net/en/artworks/82269588",
      "They don‚Äôt auto rotate you have to go to the display settings and change it to portrait mode and yes I mainly use it for discord or when I run virtual machines I have Linux on one monitor windows on another, but yeah it‚Äôs just drag and drop",
      "The monitor in the center (the ultrawide) can you post the wallpaper you have on?",
      "My lense protector doesn't do this. OP probably has oil/finger prints on lense protector.",
      "Nice build! Which case is that?",
      "Samesiesss. All packed into a micro atx case too\n\nhttps://imgur.com/gallery/42J1QMq\n\nhttps://imgur.com/gallery/vYzxzLp",
      "Replying to check back later, want it myself too!",
      "In this case with a 240mm aio, I average around 60 when gaming. If I‚Äôm running cinnebench it gets up to about 70"
    ]
  },
  {
    "brand": "amd",
    "generation": "6000",
    "tier": "top",
    "matched_keywords": [
      "6900xt",
      "6900"
    ],
    "title": "RX 6900 XT Launch went exactly as expected.",
    "selftext": "Not a single card.\n\n&#x200B;\n\nWhy do I even get my hopes up?\n\n&#x200B;\n\nCorrection: 1 was available, one of the watching discords found 1 whole card.\n\n&#x200B;\n\nCorrection 2: I spent 3 hrs trying to check out.....but ultimately failed. I had a 6900XT in my cart, I got to the \"Confirm payment\" page 100+ times.\n\n&#x200B;\n\nEdit:  Well this was originally intended to be a snarky post, but apparently it merited a gazillion reddit karma, I wonder if /u/AMDOfficial will come out of hiding to trade some of that internet karma for a graphics card, because they could sure use it right nowü§£üòÇü§£üòÇ\n\nAlso you jackwagons got my karma to 66.6k, /u/Tul-PowerColor does that net someone in the comment section a Red Devil Card? üòÇü§£\n\nIf I wasn't laughing, I'd be crying.",
    "comments": [
      "Can we skip the Redditor stages of grief routine, and go straight to acceptance?",
      "3080/90. Sold out immediately, Reddit bitched.\n3070. Sold out immediately, Reddit bitched.\n56/58/5900s. Sold out immediately, Reddit bitched\n67/6800. Sold out immediately, Reddit bitched.\nXbox. Sold out immediately, Reddit bitched but way less because they all want PS5s.\nPS. Sold out immediately, Reddit bitched.\n\nWhy change the amazing habit for the 6900XT?\n\nAt this point anyone genuinely surprised or angry should be wondering why they expected anything to be in stock.",
      "You don't even have to look at this launch cycle. 2080/ti. Sold out immediately, Reddit bitched. AMD 3900s. Sold out immediately, Reddit bitched. RX480. Sold out immediately, Reddit bitched. 1080/ti. Sold out immediately, Reddit bitched. \n\nReddit has the memory of a goldfish.",
      "don't see it even listed on Newegg yet\n\nEDIT: My bad. Newegg just didn't put the banner up like they literally always do. Cool, missed again",
      "Goldfish actually have decent memories. Check Mythbusters video on Jamie feeding them",
      "Checked Frank Azor's twitter page just in case he \"successfully\" ordered one. It seems he's been quiet for a while now, and his last tweet was on November 18 when he mentioned how he was able to successfully order a 6800.",
      "I CAME HERE TO BE ANGRY ALONG SIDE EVERYONE.\n\nMAD.",
      "Imagine that poor thing .. floating there .. all the sudden the vibrations around it are a deafening BOOOOOOM.. followed ..every day .. by the lifegivers blessing of food rain",
      "I work at micro center in byo department. First 2 people got in line not yesterday, but the day before yesterday at 4:30pm. I thought it was a joke at first but... they got a card. What can I say.",
      "That prick owes everyone a tenner.",
      "for real... micro center says they have 5 in stock at my local store but there is not why they will be there in the half hour it takes to get there. haven't seen any listings even online retailers.",
      "Ours learned that a tap on the glass means food",
      "Gotta get to Microcenter several hours before open for a chance to get a card on launch day. If you're not already there, you can bet there are at least 20+ people in line",
      "It's the journey, not the destination.  :)",
      "I'd imagine the eternal brrrrrr of the pump made them dead inside long before the tapping did",
      "What's weird is that it doesn't even show as an option on AMD's site, there's no 6900 XT listing.",
      "That‚Äôs because AMD put him in a timeout for successfully making a large group of customers quite irate at the company",
      "I mean when you have an AMD guy promising it wont be a paper launch... then surprise surprise it is one... I think that will piss off people more because they didn't temper expectation they flamed them",
      "holy crap. i got one. 9:13am EST. it was a newegg combo deal with a motherboard. i was like oh well crap. all sold out, for shits, i typed in 6900xt combo in the search and boom. it popped up. i even had to type my credit card info in twice bc i was rushing. lol.\n\nill just have to return the motherboard.",
      "LOUD NOISES"
    ]
  },
  {
    "brand": "amd",
    "generation": "6000",
    "tier": "top",
    "matched_keywords": [
      "6900"
    ],
    "title": "somehow i managed to buy a rx 6900 xt on release day through the amd store. it showed up today! i didint think they existed until i had it in my hand.",
    "selftext": "",
    "comments": [
      "That's some fancy packaging!\n\nI love how they look like team rocket cards, too! lol.",
      "Super jealous of that packaging. I got the Powercolor 6900 XT, and that just came in a plain cardboard box with a red sleeve on the outside. As barebones as it gets.",
      "Full on gpu porn",
      "It's made of canvas? I've heard there are shortages...",
      "this porb the fanciest packaging ive seen on gpu",
      "lttstore.com",
      "They'll swap it for nylon and hope no one notices, the thieves.",
      "best strip tease ever",
      "I got a reference XFX 6800, same thing. Plain box with a foam insert to hold the card. Nothing else.",
      "I expected him to drop it or get trolled with a brick lol.",
      "Its CGI",
      "Yeah having unboxed the founders rtx cards this gen and amd, amd has a much nicer style and overall unboxing experience",
      "Same story, but a tier down. Showed up 1.5 hours early to Microcenter on 6800XT launch. Line was wrapped around the building with reports they were getting very low stock. No dice. Tried to get one online f5'ing Newegg, BestBuy, and AMD. I never even saw a single listing appear in stock. No dice. Showed up 3.5 hours early this Tuesday. (when MC restocks) No AMD anything on that morning's truck. Still no dice. Walked out with an EVGA 3080 XC3 Ultra.\n\nI know I'm lucky to have any card, let alone one of the few good models that will fit a mITX case, but it still hurts my soul a bit.",
      "clean that room, christ. it‚Äôs so dirty in there",
      "Dramatic unbox rofl",
      "My 1080 fried in early October, I have been on integrated graphics for that long...",
      "I love PowerColors box because it‚Äôs so simple and doesn‚Äôt stand out too much",
      "Since I'm buying the expensive (aka, high end) cards, it means I care about graphics quality, which means I definitely care about RT.",
      "I like simple boxes too, mostly because it's less trash to sort. Also more environmentally friendly. I still want it very clear what the product is though, OEM packaging is too far\n\n\n\nEdit: though",
      "why the mess on the floor my guy"
    ]
  },
  {
    "brand": "amd",
    "generation": "6000",
    "tier": "top",
    "matched_keywords": [
      "6900"
    ],
    "title": "Finally got a 6900 XT!",
    "selftext": "",
    "comments": [
      "Always wanted to ask: Does the Mac Pro support the 6900XT and can it take full advantage of the card?\n\nEDIT- Oh, and how does it compare to the Vega II Duo Card?",
      "We installed a dozen these at work. I've never been a huge Mac fan, but these desktops are absolutely gorgeous inside. Very few surface mount components on the board, and oh so many pcie slots. Then they topped it off with matte black and no cable mess. If I had a bunch of disposable money, I would have no problem throwing Windows on one of these.\n\n[Inside picture from when I unboxed a new one.](https://i.imgur.com/UvWaDyG.jpg)",
      "The Metal benchmark from [GeekBench](https://browser.geekbench.com/metal-benchmarks) seems to show RDNA 2 being significantly faster than Vega.\n\nOne thing I am interested in though is ray tracing acceleration with Metal. I wonder if Apple utilizes the ray accelerators in RDNA 2 or is it still only available on the A13 and up?",
      "@johnnyphotog I actually like the Lego‚Äôs to hold it up",
      "There is rx 6000 series support since big sur 11.4\nBut some cards are not supported (I think rx 6700)",
      "Dell, Sony and so many other non-Apple laptop vendors got burned with with that generation of mGPUs, so nVidia deserves this blame.",
      "Because not everyone uses a graphics card for gaming.",
      "Depends entirely on workload. RDNA2 is better at rendering tasks, Vega has higher raw bandwidth but in some workloads RDNA2 can make up for it with infinity cache, Vega has better FP64, RDNA2 probably has more refined lower precision types and AI acceleration but that's not my area. The Vega 2 duo is also two Radeon VII dies crammed onto one board so that is heavily in its favor for compute workloads.",
      "Nvidia cost Apple a whole lot of money with MacBook GPU deaths, they‚Äôre not going to get into bed again anytime soon.",
      "I still can't unsee the back of a Dodge ~~Challenger~~  Charger on those cards. Well, in this post the car has flipped over, but that also happens.",
      "Nice! Is that a rack mount version?",
      ">redundant\nYou mean 'obsolete' ?",
      "I do video photography and graphic design on the Mac Side - dual boot into Windows 10 to separate NVMe - Shadow of the tomb raider is like Butter.",
      "Nope, that was entirely on Nvidia. The 8000m generation had high failure rates no matter which laptop vendor. It was a design fault purely with the GPU.",
      "I was thinking a smooth top to finish it off.",
      "Could use a half-height brick.",
      "Some people think stuff beside games don‚Äôt exist, never heard of video editing, photography, 3D modeling which also need a lot of processing power",
      "He needed a couple of Legos to support it, so not well apparently.",
      "Yep they're lovely machines, just a shame the CPUs have been made a bit redundant so quickly.",
      "‚Ä¶ so yea somebody actually does game on Mac"
    ]
  },
  {
    "brand": "amd",
    "generation": "6000",
    "tier": "top",
    "matched_keywords": [
      "6900"
    ],
    "title": "7900 XTX sometimes has worse performance than 6900 XT in VR gaming in benchmarks",
    "selftext": "",
    "comments": [
      "Probably drivers, same with the 180w power draw at idle. Feels like AMD just rushed the launch.",
      "Amd drivers: Everytime you think you're out, they pull you right back in.",
      "Clearly. Classic cash grab before the holidays. Though, I still bought one.",
      "I‚Äôm gonna bet that it‚Äôs a driver issue which can be fixed. Sucks they don‚Äôt have a solid driver run that Nvidia tends to have on launch day",
      "The issue goes wayyyy back, example from 2002:\n\nhttps://arstechnica.com/civis/threads/my-final-word-on-ati-and-driver-issues.796575/\n\nAnother from 2000 https://www.anandtech.com/show/536:\n\n>While the MAXX performed much more competitively than the Rage 128 at its release, and while the MAXX did come out in a reasonable time frame, **the solution was plagued by the usual ATI driver problems**\n\nAs they say, driver problems were the \"usual\" even in the year 2000, lol.",
      "Shareholders do",
      "Or they didnt want to be called liars for not launching in 2022.",
      "Why is it when I bring up AMD driver issues, everyone loses their minds... but I see AMD driver issues brought up here, and no one bats an eye?\n\nHere's let's try it RQ:\n\n**AMD GPU Driver's are the companies #1 hindrance on Windows PC's.**",
      "At least one of them is definitely incorrect - the OpenVR Benchmark for the 6900XT appears to be another run of the VRMark Blue Room Score... that, or somehow the 1% lows for the 6900XT are higher than the 4090... and man, 6000+ avg fps :D",
      "PC gamers: *have you tried updating the drivers?*\n\nAMD owners: *too scared.*",
      "with elite it's almost certainly drivers. the *6000* series has been broken for months due to driver issues. 7000 series for sure is also impacted.",
      "What's the rush? Can't you just wait 5 years for Fine Wine‚Ñ¢ magic?",
      "From 2001 - Radeon 8500:\n\n\"All of the specs pointed at a higher performing product, but in the end  \n we are limited by what has been ATI's Achilles' heel: drivers.\"\n\nhttps://www.anandtech.com/show/836/16",
      "The 6800/XT had similar VR issues two years ago at launch.  It took awhile for AMD to sort them out.",
      "> AMD just rushed the launch\n\nHave they ever released a truly finished product? The fine wine technology is mostly AMD releasing unfinished products and completing them... over years",
      "This feels like a vega moment - card is power hungry, is underperforming, AMD's bet on new cache technology isn't showing true potential. Then there are drivers... \n\n\n100% rushed a product that isn't ready.",
      "Vega 64 was destroyed by a GTX 1080 Ti for not much more money.\n\nAny 3x 8 pin power AIB 7900 XTX OC'd beats a 4080 OC'd AIB and the 4090 is a thousand dollars more than a 7900 XTX, at least in Europe.\n\nThe drivers definitely need improving but it's hardly a failure like Vega was, as it's competitive in performance which Vega 64 certainly wasn't.",
      "Value in companies is a tad more complex, stock price is also based on a companies 'perception'\n\nA late launch is an indication to the stock market that AMD is not ontop of their R&D and delivery of goods, which can affect their stock price.",
      "What an excellent marketing gimmick when you think about it. \"Ah yes, but by the time your GPU is becoming obsolete... these babies will run smoooooth AF\"",
      "If it's drivers yet again then all I can say is AMD needs to seriously look at the driver team and get some new talent in. It's obvious they got some old timers leading the teams who are not that good."
    ]
  },
  {
    "brand": "amd",
    "generation": "6000",
    "tier": "top",
    "matched_keywords": [
      "6900"
    ],
    "title": "Traded my RTX 3070 for a 6900 XT. Time Spy up 31%.",
    "selftext": "",
    "comments": [
      "Guy wanted my RTX 3070 + $80 USD for his reference 6900 xt. Looks like it was quite the deal!",
      "Said he did a bunch of emulation and wanted the broadcasting features. He got the reference AMD 6900 xt straight from AMD, so it actually goes for around the same price as the 3070 on the market.",
      "Damn that's an insane deal. Why did he trade a 6900XT for a 3070? I can't see any advantages of doing that at all.",
      "I've seen people offering reference 6900XT for 3080's or 3090's (or I guess 3080ti's now) because they needed the Nvidia ecosystem, but a 3070 is still insane. I don't know of anywhere where a 3070 would cost anywhere near as much as a 6900XT.",
      "Deals like these actually shows how much of a big deal features like the Nvidia Broadcast, DLSS and NVENC are. I still don't get why AMD is not trying to provide us any alternative to such features. Granted, that FSR is kind of an alternative to DLSS, but it still needs more work and proving to do, till it's accepted by the market, and the general populace.\n\nOn the other hand, AMD still has no answer for NVENC. Or Nvidia Broadcast which can be made to run on the GPU itself. Or even RTX voice.",
      "They're actually pretty easy to get off AMDs Canadian drops for $1228 CAD. Basically drop the exact same time every single week and are up for 20-30 minutes. Meanwhile if you check facebook marketplace you'll see the lowest priced RTX 3070s going for $1450 and near impossible to get since best buy canada stopped selling cards online and do in person only.",
      "> I still don't get why AMD is not trying to provide us any alternative to such features.\n\nIt's very simple: they can't at this point in time.",
      "I got my 10900 for $450 CAD brand new, the 5900x goes for $780 CAD. They perform within 5% of each other in games, def not worth it for me.",
      "now you need to trade your 10900 to a 5900 or 5950",
      "That's the beauty of cherry picking results, you can make it tell whatever story you want.",
      "This. People need to take a look at nvidia revenue vs amd and then remember the latter company also makes cpus‚Ä¶It‚Äôs actually unbelievable they compete at all. I fully expected the 6800xt to be no match for the 3080.",
      "ITT: people who think gaming is the only possible workload for a gpu",
      "Link the whole video, not one pic of DLSS testing. SMH...",
      "That is such a BS screenshot. You might as well show 6900xt with performance FSR and 3070 without and get another BS result.",
      "Nvidia just has so many more resources than Radeon does.",
      "Ah yes, the PCIe 4.0 that gives 0,7fps for your GPU is a game changer indeed.",
      "If you do things outside of gaming then CUDA and Optix can be huge upgrades",
      "Bro first off, I didn't ask about your setup. Second, I really don't care about min maxing useless benchmark numbers and spending hundreds and hundreds of dollars for no reason.\n\nIf you like to throw money down the drain then go for it, but for me there's no difference between the two in gaming. Period.",
      "https://static.techspot.com/articles-info/2160/bench/1440p_ACV.png",
      "I agree with you, it was just more a joke than actually an advice. Because you posted it on AMD subreddit lol"
    ]
  },
  {
    "brand": "amd",
    "generation": "6000",
    "tier": "top",
    "matched_keywords": [
      "6900xt"
    ],
    "title": "After almost 5 years of service, goodbye 1060 and welcome 6900XT!",
    "selftext": "",
    "comments": [
      "Wait people (and not just bots) can actually win the AMD drop? Whole family has been trying for a year no luck! Congrats, nice to see a win for a real person!",
      "6900xts are pretty wildly available now for msrp or near msrp.  Newegg and microcenter have them.  They are third party cards. So a little more expensive than msrp but not bad at all for an aib.",
      "Thank you all, last Radeon gpu I had was a 9550 SE back in 2004! I've had the 6900 for only a couple of days but it really is a beast",
      "You will never see amd msrp again.  Unless you get a reference card.  Microcenter isn‚Äôt inflating the price, aib are.",
      "The packaging for the 6900XT from AMD is almost as nice as the card.",
      "Yep, managed to get it at msrp on the weekly amd drop (I'm in the EU). I tried for a while though but never got lucky and I've always had \"more than an hour\" in the estimated waiting time. But two weeks ago the queueing system put me in the top of the line ü§üü§ü",
      "How much are these cards? Were you able to get it msrp?",
      "Every Thursday, at around 16:00, the AMD store start a gpu selling event (each drop has a different number of cards available, sometimes not so many, other times, like last week, drops are more consistent)\nYou will be placed in a queue, with the position on said queue assigned randomly. If you are lucky enough to be on the \"front positions\" of this virtual queue, you will be able to enter the online shop and buy one gpu.",
      "That's gonna be a huge jump. I went from a 970 to a 3070 ti and the jump in performance was enormous. Games that used to struggle to get 60 fps at 1080p medium settings are now running at 1440p 144+ fps at high settings (plus ray tracing in some games) \nI mean a game like doom eternal struggled a lot with my 970 at 1080p medium and now with dlss I can run the game at max settings, 1440p with ray tracing and get 144+ fps.",
      "Yeah you will...because the vast majority of PC gamers will not pay $1500 for a mid range GPU. I know I sure as hell won't.  If the prices don't come back down to some semblance of normalcy after the chip shortage is over. You're going to see the death of PC gaming. I love gaming on my PC. But there's no way I could ever justify a $1500 or $2000 video card when I can get an XBox Series S for $300.",
      "Am I the only one who thinks the RX 6000 reference cards look orgasmically good?",
      "That's a solid upgrade. You just went from hardly being able to play VR to playing on high settings. \n\nStrongly recommend a VR headset for your next buy if you don't have one. Congrats!",
      "Went from an RX580 8GB Sapphire Nitro+ to a 6800XT reference model.\n\nStill have my rx580...could've sold it for 150-200% the cost I paid for it..but I dunno.. sentimental value.",
      "What's your in game mhz?",
      "I'm in the EU, as well. What is this weekly AMD drop you talk about?",
      "Yep they get regular shipments.  Multiple a week.  The only issue is AIB companies have jacked their prices up so high it‚Äôs insane.  Between the component shortages and tariffs, they really ran with the price increases.  But this affects Nvidia too.",
      "From what I understand they are mostly abandoning the idea of MSRP in the GPU business right now. They've completely surrendered to scalpers and others driving prices up and decided to join them instead. This is partly due to everyone competing for space at TSMC instead of manufacturing their own stuff.",
      "God a 1060, how antiquated, send it to me and I'll 'dispose' it responsibly (cries on 750 Ti).",
      "This right here. MC has reference PowerColor 6900XT, 6800XT, and 6700XT in bulk pack boxes even. The 6900XT is 1399, 6800XT is 1099, and the 6700XT is 799. Better than their non reference where a 6800XT is 1349. However however still a good 300-400 over what AMD direct reference cards are. Tides are changing though. They keep getting more and more cards in quantity and model across the board and they are sitting on the shelves. So either people are giving up and holding out for new model drops, miner demand is easing, overall supply chain logistics are calming down or combination of those. So they certainly aren‚Äôt unattanium anymore. However pricing hasn‚Äôt yet really shifted accordingly.",
      "Got a merc319 6800xt the day XFX released them for MSRP.  Card beats the hell out of the 2080ti it replaced."
    ]
  },
  {
    "brand": "amd",
    "generation": "6000",
    "tier": "top",
    "matched_keywords": [
      "6950"
    ],
    "title": "Is my brain working right? Is this what we're thinking in terms of performance for 7900 XTX? Assuming it is 1.5x-1.7x over a 6950 XT.",
    "selftext": "",
    "comments": [
      "No. This is right. This is what AMD claimed.\n\nWe can't tell how true the numbers are until we get to benchmark it ourselves, though. But it looks great.",
      "Use the Techspot / Hub chart instead. TPU tested with a 5800X which did cause some slight CPU bottlenecking at 4K with the 4090.\n\nTechspot had the 4090 scoring 144fps in the 4k 13 game average and the 6900XT scoring 77 fps. The 54% perf/watt claim was for a 7900XTX at 300W (sneaky bastards) so that gets us to 119fps @ 300W. The extra bit of wattage will allow higher clocks but I expect that causes the perf/watt to drop off (otherwise AMD would have just compared stock vs stock like in prior launches) so lets say that extra 18% power only increases performance by 10% (might be generous but I don't know). That gets us to 130 fps in Techspot charts. Their 6950XT scored 85 fps in those charts and 1.54x that is 131fps so it is close IMO.\n\nGiven that that would make the 4090 about 10% faster than the 7900XTX in raster.\n\nThe 4080 16GB in the NV slides was about 20% ahead (using fantastic eyeball maths!) of the 3090Ti. That card scored 91fps in the techspot chart so that puts the 4080 16GB at around 110 fps.\n\nSo stack will probably look as follows for raster\n\n* 4090        144 fps ($1,600)\n* 7900XTX  131 fps ($999)\n* 7900XT    115 fps ($899)\n* 4080 16   110 fps ($1,200)\n* 4080 12   90 fps ($900) - or whatever it renamed to\n\nFor RT it might be more like (I did raster * 0.65 for NV and raster * 0.5 for AMD here)\n\n* 4090       94 fps ($1,600) 66 fps with new scaling\n* 4080 16   72 fps ($1,200) 51 fps with new scaling\n* 7900XTX  65 fps ($999) 41 fps with new scaling\n* 4080 12   59 fps ($899) 41 fps with new scaling\n* 7900XT    55 fps ($899) 37 fps with new scaling\n\nSo if you want RT performance then 4080 16 is not terrible, about 10% or so more performance for 20% more money. If you want raster then 7900XTX or XT are both good. If you want both you spend the $$ and go for a 4090.\n\nEDIT. I went through and checked the RT scaling at 4K in the games techspot tested. 4090 came out at 0.46x and 6950XT came out at 0.31x. Assuming the 4080 and 7900XTX are similar to those numbers I have updated the numbers to reflect that. It pans out that perf/$ is looking to be about the same for RT performance between NV and AMD but AMD will hold the advantage in raster which might offset the features NV have for some people, time will tell.",
      "Remember they did not compare it with the 4090 on purpose very different form last time when they showed 3090 on the charts. The 70% improvement is likely very rare and in a select few games. Expect the averages around 40-60%.",
      "I think AMD has been pretty accurate in their performance claims these recent years. They also don‚Äôt shy away from showing negative results",
      "90% performance at ~85% power and ~$600 cheaper is still quite good tho.",
      "All the marketing bullshit aside its probably 1.5x. Still impressive fps/$.",
      "But the benches they showed were still accurate.\n\nJust like i  this they didnt show a 4090. But based on their claims we know it is right around a 4090 in perfor.ance (assuming it is accurate which is tbd)",
      "7700/7800 seem promising",
      "^By far the most reasonable comment on here, imo.",
      "Yeah, it's better to update the chart for those games they showed.\n\n* Cyberpunk the 6950 XT doesn't do too well [https://tpucdn.com/review/nvidia-geforce-rtx-4090-founders-edition/images/cyberpunk-2077-3840-2160.png](https://tpucdn.com/review/nvidia-geforce-rtx-4090-founders-edition/images/cyberpunk-2077-3840-2160.png)\n   * With 1.7x like they reported, we're looking more like 66.7 vs 71.2 for the 4090\n* Watchdog Legions [https://tpucdn.com/review/nvidia-geforce-rtx-4090-founders-edition/images/watch-dogs-legion-3840-2160.png](https://tpucdn.com/review/nvidia-geforce-rtx-4090-founders-edition/images/watch-dogs-legion-3840-2160.png)\n   * With 1.5x like they reported, we're looking more like 95.85 vs 105.2 for the 4090",
      "Its not right. This benchmark is using a 5800x which bottlenecks the 4090 even at 4k. The other issue is that AMD only showed 6 games and said 'Up to 1.5x and 1.7x the 6950' this is the best case scenario, not the average one.\n\nIf the 7900 XTX was faster than a 4090 or even a bit slower AMD would've given us detailed performance benchmarks, but they completely avoided it, just like they avoided comparing Zen 4 to the 5800x3D.",
      "‚Ç¨uro prices \n\n2400‚Ç¨ for a 4090\n\nGuestimate prices for AMD 1200‚Ç¨ for the xtx and 1100‚Ç¨ for the xt",
      "fucking insane value compared to the overpriced 4090",
      "It wasn't 8k, it was like 7600x 2100, so 8k cut in half is what they showed.",
      "Slow down buddy lol. You've got 14-30 days to reconsider your purchase. I'm aware this is a pro-AMD subreddit, but there's no sense in making split decisions without knowing how these cards compare. With that said, you could use the money saved to invest in a full AMD build that'll surely out-pace a 4090 FE üëç",
      "I hope the 7900XTX humiliates the 4080. On paper the 7900XTX should destroy the 4080 with ease. 12 billion more transistors, 20-30% more bandwidth, 4GB more memory.. Die size of the 4080 is just 380mm2. 7900XT is like 520mm2 with chiplets included.",
      "Yeah, I mean we're talking about a freaking $600 price difference. That's a whole ass 6900xt (current) price difference.\n\n&#x200B;\n\nI wish people had more sense than money.",
      "I mean that's not them being inaccurate, they just didn't make that comparison cause they didn't like it.",
      "Don't forget these are \"up-to\" numbers from AMD - not average like all other benchmarks.  The real average numbers are going to be much less than what the maximum frames are.  Even more so depending on your CPU.",
      "If you care about ray tracing a lot you should keep the 4090 order, a 60% RT gain over the 6950 XT won‚Äôt place the 7900 XTX anywhere near the 4090.\n\nIf RT isn‚Äôt a big concern however, it looks like AMD will be much better value at the top end."
    ]
  },
  {
    "brand": "amd",
    "generation": "6000",
    "tier": "top",
    "matched_keywords": [
      "6950xt"
    ],
    "title": "6950XT at $599 on Newegg!",
    "selftext": "",
    "comments": [
      "This is a great deal tbh, totally a card that's worth that.",
      "Do you let the 6600 watch?",
      "Bro I just got a 6900XT for the same price. Buy it!",
      "There goes any reason to buy a 4070 now.  Way to go AMD!\nGreat deal for this card.  Especially with how powerful it is.",
      "Just got this card for $649, replacing my RX 6600, and it _fucks_",
      "good card buy it if you have few gen old card or something",
      "oc the ram and u have a 6950xt",
      ">Could you elaborate?\n\nThe major difference between the 6900 and the 6950 is memory speed. So they're saying if you could overclock the 6900xt's memory to 6950xt speed, then you have a 6950xt. \n\nExcept the 6950xt can also be overclocked, and will go beyond what a 6900xt can do, so it's kind of a silly point.",
      "Didn't wanna make it feel inadequate. It served its purpose back when you couldn't get ahold of cards.",
      "At this price might as well get a new psu if you lack the connectors. It's gonna be worth the upgrade",
      "Keep holding lads, don't give into the temptation!",
      "I'm eying it was an upgrade for my rx480. Just wondering, if my PSU only has 2 8 pin connectors, could I still use it? Like is it safe to leave one out? 2x8pin should give 500 watts, I think",
      "As long as you can buy them for the same price, really no need to get a 4070. I‚Äôm team green because of the features I want, but a 6950XT ar $600 is worth upgrading a PSU as well over the 4070‚Ä¶",
      "what about em?",
      "\"I don't want to play with you anymore\"",
      "Yeah, the \"just oc to get X\" was never a good point for me, it isn't worth the power they're wasting imo comparing to stock",
      "Just use a saw to trim off the excess on a full ATX PSU.",
      "It honestly was a bit emotional. I had decided to build the first computer I'd built in probably 25 years. My ass didn't even know m.2 SSDs were a thing or that new Intel CPUs didn't have actual pins, and it was the only card I could get ahold of. She did her job valiantly.",
      "That's the ugliest GPU I've ever seen",
      "12GB VRAM is all I have to say‚Ä¶ I have a 3070 and it‚Äôs still chugging new games 60+ fps on high at 1440p, but obviously the low amount of VRAM will hurt these cards in the long run. \n\nBy the time I upgrade (about 6-8 months from now), the 4070 will be around $450-500 used here and I still won‚Äôt find a 6950XT at all, only new, so I‚Äôll most probably still buy a 4070, but this shit is getting on my nerves too. I‚Äôm not going to buy a 4080 for like $1200 for adequate amount of VRAM to futureproof my gaming experience."
    ]
  },
  {
    "brand": "amd",
    "generation": "6000",
    "tier": "top",
    "matched_keywords": [
      "6900"
    ],
    "title": "RX 6900 XT render, I have few more, but can post only one :c",
    "selftext": "",
    "comments": [
      "Having to wait until the 28th is torture.",
      "I'm currently looking for tips on how to get into a coma for a short time.",
      "Don't fall into a coma right now, wait until after Lisa Su finished flexing on Thursday.",
      "GPU's are getting bigger and bigger instead of smaller and smaller üò©",
      "I mean you don't really just \"invent' a new way to disperse heat, not easily anyhow.  Water cooling is a thing, but you just introduce more points of failure into your system. Air works very reliably, and about the only thing that can go wrong is a fan stops spinning (which is easy to diagnose). Even then it's only posing a danger to the GPU really, rather than liquid cooling leaking in your system or something like that.\n\nAnd above all else, it's cheap and easy to manufacture. GPU's are already very expensive, not a whole lot of people will pay some massive premium for some revolutionary cooling solution that lowers their temps by 10C, and shrinks their card a few inches.\n\n&#x200B;\n\nEdit: Dumb typing mistakes and grammar",
      "this reminds me of 2017. Waiting for Vega...\n\ni do hope this will be a decent competitor",
      "Gotta keep ‚Äòem cool!",
      "You're damn right.",
      "[https://media.discordapp.net/attachments/469501377153073153/763104691252887562/rx6900xt\\_top.webp](https://media.discordapp.net/attachments/469501377153073153/763104691252887562/rx6900xt_top.webp)   [https://media.discordapp.net/attachments/469501377153073153/763104752929079348/rx59769.webp](https://media.discordapp.net/attachments/469501377153073153/763104752929079348/rx59769.webp)  \nTwo more here!",
      "Vega turned out great... For us who bought a V56 for less than the price of 5600XT, got Samsung HBM and flashed a Vega 64 firmware, then undervolted it and overclocked the memory. But seriously though launch time Vega was quite a disappointment. Way out of my price range for starters.",
      "Why haven't they invented better cooling technology as of yet? I mean we're in 2020 and we're still relying on air cooling fans to cool GPU's. There's gotta be a revolutionary idea thats better than the current setup",
      "Boy, do I have the product for you!    \n[https://www.youtube.com/watch?v=Dbr7B1OVa0g](https://www.youtube.com/watch?v=Dbr7B1OVa0g)",
      "Just a hint- instead of posting to imgur or discord, you can post to your own account, and then link it.",
      "That looks üî•. Kudos.",
      "The thing with engineering is that there's no need to change something if it:\na) works as intended\nb) is cost efficient\nc) is sufficient for what it needs to do\nThere will be no need to change the cooling method as long as it's the most convenient in all of those categories.",
      "+1 on launch Vega 56 with $100 discount day 1, flashed and all that. Most weren't that lucky though, waiting for partners cards, mining craze, no real use to HBCC and missing features. A mixed bag or even a disappointment for most but a gem for some of us, using Linux even more so.",
      "I'm looking forward for Devil version from PowerColor \\*-\\*",
      "Sapphire Nitro+ for me. Pretty keen to see what drops.",
      "Liquid cooling is still air cooling to be precise. The liquid is only used to move the heat.   \n\n\nThere will never be anything else. Heat is energy you just need to move and dissipate it. There is nothing else you can do.",
      "Damn that is sexy."
    ]
  },
  {
    "brand": "amd",
    "generation": "6000",
    "tier": "top",
    "matched_keywords": [
      "6900"
    ],
    "title": "The biggest Swiss retailer to receive 35 Radeon RX 6900 XT graphics cards for launch",
    "selftext": "",
    "comments": [
      "Well, who will win?\n\nWill it be:\n\n    timidandshy\n    bot1\n    bot31\n    bot3_8\n    bot98\n    bot69\n    bot11111\n    bot666\n    ...\n\nOr any of the other 6731532 contestants?",
      "wow, remember how we were all expletive on nvidia and amd was bragging about how their stock would be better?",
      "Swear to god, feels like a bunch of edgy teenagers are incharge of radeon's marketing department.",
      "They will only send the cards to physical adresses and they will be signature only. They won't do pickup for the cards as you can buy multiple ones this way with fake accounts.",
      "I don't think you can ever prevent someone from reselling something they legitimately bought. The difference in this situation, is that you will have to jump through a lot of hoops AND get lucky to get your hands on several cards.",
      "The correct answer is sassy middle aged men are in charge of marketing.",
      "I wasn't even born 35 years ago.",
      "The best part is that they decided to make a lottery who can buy a card.",
      "I believe they do this for luxury clothing, bags and shoes too. Feels like the raffle system would do well for GPUs as well. At least real people will have an equal chance as bots lol\n\n&#x200B;\n\nEDIT: Thanks for the inputs, learned a lot from your comments. TIL a lot.",
      "Honestly, that's more than I expected for a country with <9.000.000 citizens.  \nBut if we extrapolate that, it means Germany is going to receive less than 350 units. :(",
      "What's stopping someone from using neighbours or still intending to resell at least one unit?",
      "Well, better odds than F5'ing and dealing with bots taking all the cards.",
      "You are extrapolating wrong. This is not the only retailer but the biggest. \n\nI agree though that it is not much, but more than expected.",
      "The Alienware kind.",
      "Is that strange? For example, my yearly income (after taxes) is ~1700 USD. The world is a bigger and more diverse place than most Americans think.",
      "Can't wait for Frank to show up and say it's not a paper launch because he entered the raffle and got the 35th card.\n\nWhat a joke of a launch.",
      "this is kind of a hilarious, 'enter a raffle for a chance to give us money'",
      "r/usernamechecksout",
      "It's pretty strange on a forum discussing pricey tech.  After food, shelter, clothing and transportation, not a whole lot of that 1700 left to go to tech.",
      "Finally a reasonable people."
    ]
  },
  {
    "brand": "amd",
    "generation": "6000",
    "tier": "top",
    "matched_keywords": [
      "6900"
    ],
    "title": "AMD Radeon RX 6900 XT, RX 6800 XT and RX 6800 reference desings are being discontinued - VideoCardz.com",
    "selftext": "",
    "comments": [
      "Not surprising. Every AMD reference card disappeared when the AIB partner cards were ready.\n\n\nThe only downsides to this are the fact that the reference cards are thus far the most compact variants of the RX 6800/6900 series cards (they're shorter than all AIB partner cards and the RX 6800 non-XT refrence card is the only two slot card in the RX 6800/6900 series) and the fact that these cards were the safest bet if someone wanted to water cool theirs.",
      "Don‚Äôt blame yourself, sonny boy. You missed out on the reference card F5 bonanza. But I got some great news for ya! We have partner cards with your name on them, starting at just $899 + tax! Now, I know it‚Äôs not the same deal we talked about before, but don‚Äôt worry. Your computer deserves this card and so do you. Who cares about a couple hundred bucks here and there. So just enter your CC info today and you can have your card in time for Easter!",
      "Also makes it a nightmare for watercooling blocks. Means manufacturers like EK have to either not produce a waterblock or produce many different designs for all the different AIBs.",
      "So mrsp is literally a lie. Is there even any msrp 6800XT, if not this card literally isn't even a 650 dollar at all.",
      "So we are then stuck with overpriced AIB cards? Screw this... I was happy for GPUs to finally go down in prices and would have gladly payed 650‚Ç¨, but the AIB price markups are insane...",
      "So, AMD finally makes a competent reference design and they decide to discontinue it less than 2 months after their paper launch?\n\nlmao this is hilarious, I honestly didn't think AMD would manage to mess up their launch any worse than Nvidia did with their, but holy shit this is amazing.\n\n\nSo, what's the official MSRP of these cards now?",
      "so only 20 of each were ever made before discontinued. what is this, streetwear?",
      "Damn straight there mr salesman, i just dropped 1.5k new zealand dollars for a rx 6800 xt red devil card, pleasure doin' business with ya",
      "Are you fucking kidding me??? There was never even a chance to get one!\n\n>end of life\n\n?!?!!!",
      "Nvidia is still making FE months after launch while AMD‚Äôs reference production was basically dropped after 1 week lmao",
      "Oh it's not need. Air coolers are very good these days. Watercooling is purely enthusiast. But it is still a big market.",
      "They're not overpriced, the reference models were underpriced so that AMD could put a graph up to make the pricing look more competitive than it is.\n\nIt's an absolute disgrace, and I can't help but feel they'll do the same thing with the 6600xt and 6500xt, which are the cards I was actually looking forward to.",
      "so mr scott herkelman literally lied about saying the ref design will still be manufacturate until early 2021. it's not like i prefer the ref design or performance over aib models but aren't they suppose to exist to at least available at msrp ? aib models pricing is even worse than nvidia situation rn",
      "AMD is seriously becoming anti-consumer. I had high hopes and support for them through their dark times and now that they're even competitive with intel & Nvidia I thought only good times were to roll. NOPE! It's chuck \"fucking\" testa.",
      "Another downside is they are the only reasonably priced models.",
      "I wonder why you actually need a full GPU water block (except hard overclocking with powermod).\n\nI use CPU AIO on 1080 TI with a bracket. Sure it doesn't cover VRM or VRAM, but it has a 90mm fan that blows directly against main VRM. The I/O side VRM is a concern though, but all reviewers shown it's colder than with high-end air coolers.",
      "And 15 of them were sent to reviewers",
      "MSRP is also being discontinued with them",
      "Prices were a lie then and all reviews need to be redone without the fake US$649 price.",
      "According to what AMD told Hardware unboxed. Can we really take their word for it though?"
    ]
  },
  {
    "brand": "amd",
    "generation": "6000",
    "tier": "top",
    "matched_keywords": [
      "6900"
    ],
    "title": "Upgraded from a GTX 1080 Ti to an RX 6900 XT. I can now say that I have an entirely Team Red PC. As I'm primarily a Linux user, this makes me super happy.",
    "selftext": "",
    "comments": [
      "‚ÄúOh sick PC. What games you play?‚Äù ‚ÄúWell, do you have a minute to talk about Linux?‚Äù Smooth selling point.",
      "I do play games :).\n\nI dual boot Windows 10 for games. Nvidia has been a rough ride on Linux for a number of years. Their drivers are solid, don't get me wrong, but they like to go against standards, so if Linux software starts trending a new direction, it takes quite a few years for the Nvidia drivers to get support. The AMD and Intel drivers support the bleeding edge of everything.",
      "\"F*** you, nvidia!\" - Linus Torvalds",
      "I wish I could make the switch to Linux.  My primary problem is that (and I've spent a lot of time looking) is that I can't get an equivalent keyboard layout to US International (which I've been using for yeas for easy access to spanish characters).  I tried switching to a few different layouts in Linux but just couldn't get used to them.  \n\n\nReally want someone to copy the US International Microsoft keyboard layout for Linux.  \n\n\nNice computer man.",
      "Dude you can rearrange Buttons however you want I. Linux with a pretty basic script. I put STRG on Capslock for my GF since she had Problems using STRG in DotA2  because of her short fingers.\n\nBy the way fellow Linuxuser who also got his hands on a 6900XT and is super happy!",
      "Basically a complete redesign of how the Linux graphic stack works has been done over the last 6 years or so. The Intel and AMD drivers have been modified to demonstrate the new process. Nvidia drivers work around the whole thing and break most things that depend on it.\n\nPreviously, pretty much anything related to more than text mode was handled through the X server (the GUI, essentially). 3D APIs, drivers, screen management, etc. were all added as plugins to X for the most part. A massive amount of work has been done to untie these from X and make them stand on their own.\n\nThis allows things like graphics outside of the display server, using 3D acceleration on a headless server, passing references to graphics buffers between processes without copying them to the CPU, etc.\n\nIf you've ever heard of Wayland, it uses all of these separated components to provide a modernized display server.\n\nThe Nvidia drivers pretend this all doesn't exist and doesn't support any of it. When Nvidia was asked to support the features that literally every GPU support by Linux except for Nvidia does, they said they didn't like how it was done and supporting it was too much work for them. Then they proposed their own method of doing it and tried to strong arm everyone into using it, a method completely incompatible with everything else.\n\nHence why there's a bit of distaste for them in the Linux community.",
      "In particular, Wayland. Wayland is mostly broken on nvidia, but it's wonderful on AMD and Intel devices.",
      "ctrl in German",
      "oh yeah, AMD is absolutely the way to go. They contribute a ton to linux, and are one of the main reasons you can actually game in linux. Check out the Proton DB for a list, but for the most part 75% of all steam games are playable under linux, sometimes with better performance than in windows!",
      "dafuq is strg?",
      "Sounds like Nvidia",
      "Wayland supports variable refresh just fine, certain compositors don't.\n\nThe desktop world is moving forward with Wayland, and Nvidia is holding things back.",
      "They support it because all those systems running their $10,000 Tesla GPUs run Linux.\n\nBut most of those are crunching numbers with CUDA and not being used for 3D acceleration, so desktop Linux is pretty much an afterthought for them.",
      "More like \"Fuck you, Linux!\" - Nvidia.",
      "I made the same upgrade about two weeks ago. It's been fantastic. And after living on nvidia drivers in Linux for the past few years, I'm glad to see the back of them.",
      "Care to elaborate on those trends you speak of?",
      "Stadia uses a Vega-based AMD GPU which is broadly comparable to the Vega 56.",
      "Man that tubing looks dope af",
      "I know the feeling, as an artist I can never quite leave windows behind thanks to adobe. But I've lost so much data thanks to microsoft's increasingly buggy updates.\n\nThese days, distros like ubuntu and opensuse are really user friendly and easy to install. Your set up is also perfect for doing gpu passthrough where you reserve an entire graphics card for VM use.\n\nIncidentally, I frequent a Linux support discord server, so if you need help installing or maintaining linux, I know a lot of people who can help out.",
      "really?? i'm Brazilian and use US int. as my keyboard layout  \n\n\ni 've used deepin, Debian, pop\\_os, Manjaro and Arch, and could set the layout in every DE\n\njust sometimes i would have problems with the cedilla if my locale was en\\_US (if it was pt\\_BR it would set the cedilla normally) but a line on a config file would solve it"
    ]
  },
  {
    "brand": "amd",
    "generation": "6000",
    "tier": "top",
    "matched_keywords": [
      "6900"
    ],
    "title": "Since I can't buy one I made a vector drawing of the AMD 6900 XT instead",
    "selftext": "",
    "comments": [
      "damn it, you got me! nice rickroll in the QR code! :p",
      "Was hoping someone would try it! :D",
      "3D print it. Boom, you've got a brand new 6900 XT.",
      "Someone give this man a 6900XT!\n\nGoodjob on the Design OP! *Clap Clap",
      "You wouldn't download a card, would you?",
      "Made using illustrator and the amazing high res PCB shots from Techpowerup [here](https://www.techpowerup.com/review/amd-radeon-rx-6900-xt/5.html).",
      "Legend!",
      "One of the best way to include/hide rickroll.\n\nYou clearly deserve an award !",
      "fyi the traces going to from the PCIe connector aren't just 1 trace but 2 close together in a [differential pair](https://en.wikipedia.org/wiki/Differential_signaling)\n\nsome of the vias also don't look quite right, particularly the ones that don't go to a plane\n\notherwise it looks really nice, well done!",
      "Fuck you, I would If I could!",
      "Thanks for your feedback, great to get some from someone knowledgeable on the subject! I originally spotted the differential pairs in a few places but thought the double line was a bit much and wanted to keep it simple. Evidently that idea went out of the window as the drawing grew arms and legs so I guess there's no reason to have them left out. I don't know enough about the workings of the PCB with the vias to get everything quite right (and my patience was at its limit), but I put the extra traces back in for you [here](https://i.imgur.com/i4lQrEl.png).",
      "Thank you! It took a long time, I'm not quite sure how many hours. Probably about 15-20, but not all of it was that serious. Just some videos on and doodle away. It was never meant to get so detailed but I went a bit too far! I was able to use illustrators symbol feature thankfully to cut down on unique elements and just copy paste a lot of the parts.",
      "Nooo wayyy lmaooo",
      "I didn't know reddit supports vector images.",
      "Haha, I thought the same thing (in T'Challa's voice)",
      "Thanks for the feedback! Sorry, but I don't want to put the raw .svg up publicly as it took a lot of work and people can be a bit annoying stealing stuff. I am more than happy to make anyone a high res render with different backgrounds that they can edit.",
      "Very nicely done!\n\nHow long did this take?",
      "Oh ffs I didn't believe it and it got me",
      "Only $2,999.99 for the printable file.\n\nPaypal or Venmo only",
      "How's [this?](https://i.imgur.com/7wcziIX.png)"
    ]
  },
  {
    "brand": "amd",
    "generation": "6000",
    "tier": "top",
    "matched_keywords": [
      "6900xt"
    ],
    "title": "My 8yo r9 290x is retiring today, replaced by 6900xt Aorus master. Goodbye old friend !",
    "selftext": "",
    "comments": [
      "R9 290x has done its job proudly",
      "It's been reliable for 10 years (unlike my GFs)",
      "It'll always be in my heart. And proudly displayed on my shelf !",
      "290x was a beast. Enjoy the upgrade",
      "And here I am still rocking my PC I built literally 10 years ago, almost to the day. FX-8350 / HD 7950.\n\n... I need an upgrade.",
      "This is an upgrade",
      "Now it can relax haha. I might let my RX 580 do the same soon.",
      "Also not true at all, my GFs have all been outstanding girls, I'm pretty sure I've always been luckier to have them than them to have me, I just liked the punchline haha",
      "I like to make it worth it haha",
      "290x can still game today.  On par with an rx480. About 1.5x a 1050ti.\n\nYou got amazing value buying that 290x.  \n\nThe 6900x is bonkers fast.  Huge leap.",
      "Damn my man rocking it old-school lmao",
      "+1 for that Vapor-X R9 290x ‚Äî beautiful and an absolute shredder of a card! o7",
      "I'm honestly amazed this hardware survived and stayed usable for as long as it did. Your 290x is only one generation newer than my card!",
      "What cpu you paring it with",
      "Lol",
      "I'm a bit on the fence, really. The 580 is still a good card for me, and the fact that the 6700 xt I've been eyeing is out of stock has been giving me some time to ponder it haha.",
      "It's actually not the vapor X, I modded it with some blue Warhammer paint haha",
      "Even if it was true, I'd understand it pretty well. Girls are VERY complicated.",
      "280 non-x, IIRC.",
      "Ye quantum physics level sht haha"
    ]
  },
  {
    "brand": "amd",
    "generation": "6000",
    "tier": "top",
    "matched_keywords": [
      "6900xt"
    ],
    "title": "6900XT blew up",
    "selftext": "Big Bang and long hiss while playing Forza. PC still running, immediately jumped up flipped the PSU Switch and ripped out the Power Cord. Had to leave the room and open a window bcs of the horrible smell, later took PC apart, GPU smelled burnt.\n\nAMD Support couldn't help me. Using an insufficient Power Supply (650W) caused the damage. so no Warranty. Minimum Recommendation is 850W.. So i took of the Backplate and made some Pictures for you. SOL?\n\n(Specs: EVGA 650P2, 6900XT Stock no OC, no tuning, 5800X3D Stock, ASUS Dark Hero, G.Skill 16GB D.O.C.P 3200, 512GB Samsung SSD, 3x Noctua 120mm Fan) ...PC is running fine now with a GeForce 7300 SE\n\nhttps://preview.redd.it/fbdu6htus7oc1.jpg?width=2605&format=pjpg&auto=webp&s=2d1a1890b21c73eb135ca61d305172aeccc68229\n\nhttps://preview.redd.it/qedmbgtus7oc1.jpg?width=2979&format=pjpg&auto=webp&s=20a30c490580c6f5eb69748b9e3aaa140f3c8574\n\nhttps://preview.redd.it/pcjrrhtus7oc1.jpg?width=3547&format=pjpg&auto=webp&s=d139633edf2fc6872b99a7417d06f8bb256f7209",
    "comments": [
      ">Using an insufficient Power Supply (650W) caused the damage\n\nsays fuckin who? and furthermore, how the hell would that even work? \n\nthis is such a ubisoft support type of statement.",
      "650 vs 850 watt supply didn't cause this.\n\nCall back, tell them 850 watt was used. That's such a BS excuse of them to use to deny a claim.",
      "I might not be a professional in computer hardware, but I do have some experience building pcs, and even I know insufficient PSUs wouldn't cause shit to explode. The biggest problem it'd cause would be insufficient power (duh), causing the computer to suddenly turn off. You might also have problems like the leds being very dim, or fans running slower and or out of synch with each other.  \n\n\nI actually used to have a 600w PSU that was insufficient for my build and the most problems it'd cause is a few startup problems and dimmer leds. Once I upgraded to a 750w PSU all these problems disappeared. Never once did anything on my computer short out or explode because of the PSU.",
      "The biggest problem, besides instability, would be the PSU itself having an electrical or thermal issue as a result of handling an overspec load. Regardless, I still would expect the GPU itself to blow up, so we're all still in the same boat.",
      "Try contacting EVGA support. As the other reply said, PSU with insufficient power shouldn‚Äôt fry your GPU and the PSU manufacturer is responsible if it‚Äôs PSU problem.",
      "Indeed. As a computer engineer, I'm scratching my head at that one.\n\n\"My PSU's 12v rail couldn't provide enough amperage, which blew up the graphics card (???)\"\n\nThat is most definitely *not* what happened.",
      "All kinds of wild things can happen when a psu fails. Running psus to failure is a genuinely dangerous, bad idea.\n\nI actually had the same initial reaction as this thread, that the psu didn‚Äôt cause some random gpu failure, but when you point out that the gpu failed at the same time‚Ä¶ they‚Äôre actually right that this is a warranty issue for the psu vendor, they can‚Äôt make a gpu not blow up when you put 120v AC down a 12v DC cable‚Ä¶\n\n(and I‚Äôm guessing that the psu is probably old and out of warranty of course‚Ä¶ too much load on an old/crappy psu and when it goes bang it takes something else with it is a tale as old as time. It used to be *much* more common in the era when you got some junky ‚Äù500w‚Äù thing with your case.)",
      "Contact him, he may help you\n\n[https://www.youtube.com/@northwestrepair](https://www.youtube.com/@northwestrepair)",
      "If the GPU was \"starved\" of  the proper power, I would be surprised if the PSU didn't scramble and shut down.  I can't see a PSU continuing to run if it couldn't supply the needed power to the board, CPU, drives and GPU.  The CPU/GPU should run 550 watts, tops.  Not sure what else is drawing power, but a physical HDD runs about 5-10 watts/each drive.  Not sure about memory.\n\nI think AMD or EVGA is at fault for this one.",
      "It was prolly trying to pull more juice than what the PSU can handle, this happened to me back in 2013 running dual 5870‚Äôs in CF with a 3770K overclocked to the moon, all of this running on a CX550 until it blew up..",
      "Get your cousin Jim Bob to call and do a warranty claim. But instead say you have a 850 PSU.",
      "This man knows his stuff. See what he says but don‚Äôt expect miracles",
      "Hello, someone with engineering experience here -\n\nIt's not bullshit. The failure mode is pretty simple:\n\nPower = Voltage * Current.\n\nPower supplies provide a fixed voltage (12v). Card draws whatever current it needs to meet power demand.\n\nCard demand goes up. Card tries to draw more power than psu can handle. Psu begins to sag, voltage drops below 12v.\n\nCard has the same power demand, but is now being fed lower voltage. Power = Voltage * Current, if power is same and voltage goes down, current has to go up.\n\nCard draws more current to try to meet power demand. Psu sags more, voltage goes down, card getting less power per unit of current and thus increases current draw to make up.\n\nVicious cycle.\n\nUsually a psu's over-current protection will trip out and your rig will be safe.\n\n1. Not all psu's have good OCP.\n2. What happens if power demand is riight below trip point? Psu keeps running, but card is being undervolted and continues to draw higher than normal current.\n\nSo the card keeps running. But then, current through some component causes it to heat up too much. Component begins to fail, usually by becoming a short. Draws looots more current now and milliseconds later pops.\n\nEt viola, dead computer smell.",
      "I'm sorry for your experience. But that is definitely not what happened here. \n\nYour PSU and cabling might've overheated because of the high current that it couldn't handle, and that heat might've transferred to your GPU and done it in as well.\n\nWhat happened with OP though was the opposite. If anything it sounds like a short or overvoltage on the GPU itself, maybe it blew a capacitor as a result. You wouldn't see the type of failure OP saw from an overheat of the PSU due to a current level above its rating.",
      "wtf... whoever came up with the idea that a lower wattage psu caused your 6900 XT to explode should lose their job, that makes zero fucking sense, also amd officially recommends 750w and even then 650w is more than enough",
      "TL:DR: Most likely the GPU would work after you use soldering iron to remove the burnt component and cleaned with PCB cleaner. If they refused to pay for a warranty, i think it is worth a short in repairing this GPU.\n\nFrom the picture, it seems like a ceramic capacitor has exploded. My guess would be that the ceramic capacitor itself has some QC issue and it starts to degrade faster than normal and a leakage current started to flow through them. When the leakage current is high enough, it would burn. Since the package size is small (either a 0805 or 0603) ,even when it is \"burning\" there is still a relative small amount of current flowing through and i won't be worrying that the extra current would damage the large power plane inside the PCB. \n\n(I don't have the power ratings for ceramic capacitors, but usually resistors in that package could only handle 250mW before the burn, which is just a small fraction of power compared to 300W+ that the GPU would suck in)\n\nSince you said the GPU is still running when the component is burning. I think all the power rails would be working.\n\nIf you have a multimeter, you could use connectivity check function to check if there is a short circuit between the black capacitor with the lable C604 across it (should be the main power rail to GPU) and between the small across the brown capacitor C630 that is right beside the burnt component. If the power rail is not short to GND. I think it is very likely that the GPU could boot up again after the burnt component is removed with soldering iron and is properly cleaned. That ceramic capacitor should be used for filtering the 12V voltage right before the input of the buck converter.  Usually there are a surplus of them soldered on the board and missing a couple of them should be fine as long as the power rails are not short circuit to each other and the GPU + VRAM are still in working condition.\n\nAnother tip when asking for warranty is always play dumb. Always say that you used the recommended part and you have never touch any setting of the GPU and it just blow up on its own. The more specific info you provide, the more likely they would find a bullshit reason to refuse the warranty claim",
      "It‚Äôs an easy way out, if op didn‚Äôt say what was their psu, it would fine, any company will use anything in their favour  to deny warranty, happened to me with my car",
      "It took out one of the 5870‚Äôs as well, forgot to add that it also melted one of the power cables. Nothing major but the case was smoking for a good 10min. I posted this over in the AMD forums about a decade ago. If I find the post I‚Äôll link so you can see the damage.",
      "Switch mode power supply, MOSFETs could have failed to open for a brief period of time causing more than 12v to be fed into the gpu...\n\nThough I would have expected EVGA to have overcurrent protection to prevent this from happening.",
      "I agree with your general sentiment here, but from my reading of OP's post, the PSU hasn't failed. Moreover, his PSU looks pretty decent (650W 80+ Platinum). He said he swapped in a low-end GPU for the time being and the PC is working again. \n\nConsequently, I'd pull the blame away from the PSU and put it towards the build quality of the GPU. OP was running the GPU stock as well, so its electrical load under gaming (in combination with the efficient 5800X3D) should've been manageable by their high-quality PSU. \n\nWhat you said does make sense though, so I'm not discounting that. I just don't think that's the case here."
    ]
  },
  {
    "brand": "amd",
    "generation": "6000",
    "tier": "top",
    "matched_keywords": [
      "6900"
    ],
    "title": "My black beauty. 5900x + XFX 6900 XT merc",
    "selftext": "",
    "comments": [
      "Your GPU looks to be sagging.",
      "Love a pure amd build.",
      "Of course there may be a small comeback. But remember that 5000 series was a \"reply\" to their previous gen. Intel releases mid year and then amd does their next year and destroy it again. Mind you from leaks we are seeing small gains only by Intel. 5-8% single.core and way behind in multi. Plus Intel is maxing out at 8 core as well.",
      "XFX really makes the best looking coolers imo",
      "Actually Intel seems to be ahead in SC only because of clocks. It's still behind in IPC and that shows in multi where clocks get limited by their ridiculous TDP.\n\nAnd don't get me wrong, Rocket Lake doesn't look like a bad arch, but they are way past the 14nm++++++ sweet spot",
      "NH-D15s is good too.",
      "32GB Crucial Ballistix 3200 CL16",
      "I want to go full amd so badly (3700x -> 5900x, 2070s -> 6800xt). But somewhere deep inside I‚Äôm being told that intel might make a comeback soon",
      "Especially the merc looks so nice. And oh boy is it a huge and heavy card",
      "Nice, I like the no RGB approach.",
      "I'm running full amd and it's killer so far. 3600 and a 6800xt.",
      "I have mounted the front fan a slightly higher on the cooler. You can see it in the picture if you know it. The front fan is mounted higher than the middle one. \nBut I am not sure if you could move it even more to fit the tridentz. Technical it should be possible, if you have a big enough case so that the fan is not in the way of the side panel. I have the Meshify 2 and raised the fan just slightly above the ram and I think between the fan and the side panel is very little space left. \n\nBut you could also use the D15S which comes with only the middle fan. It's as far as I know just a little bit worse than with two fans.",
      "What RAM are you running under the D15?",
      "Where is the ram?",
      "FIX DAT SAGG.. looks good tho",
      "It is hiding under the chonky Noctua cooler.",
      "Nice, I'm a big fan of plain cases with no rgb.",
      "So on Amazon it says that the D15, ‚ÄúIn dual-fan mode, the NH-D15 should be used with standard-height RAM (up to 32mm).‚Äù\n\nBut on the crucial website it says that the Ballistix is ‚ÄúCrucial's Ballistix memory modules are really space-friendly. The heat spreader doesn't add a lot of height to the memory module. Checking in with a height of 39.17mm (1.54 inches), we expect the Ballistix memory modules to fit under large CPU air coolers without hiccups.‚Äù\n\nHow did you accommodate that 7mm difference? I know it‚Äôs a tiny difference, but just curious. I have the G.Skill TridentZ and its 44mm tall and that‚Äôs the reason I haven‚Äôt bought a D15 yet. Buying just the D15 is fine, but buying the D15 and replacement RAM ain‚Äôt pocket friendly.\n\nEdit: meant to clarify that I have the G.SKILL TridentZ RGB",
      "nice build i also got fractal case but a smaller one, got 5950x and gtx970 haha did preorder sapphire 6900xt but ofc no deliverydate, 32gb 3600 ripjaw. also prefer non rgb stuff. hope the GPU will fit max gpu length is 310cm with fans which the sapphire custom card should have. [https://i.imgur.com/8nnMzW0.jpg](https://i.imgur.com/8nnMzW0.jpg)",
      "Maybe a custom bra can fix that?"
    ]
  },
  {
    "brand": "amd",
    "generation": "6000",
    "tier": "top",
    "matched_keywords": [
      "6900xt"
    ],
    "title": "5900x and 6900xt",
    "selftext": "",
    "comments": [
      "The Monsta push-pull on the bottom looks massive.\n\nHow are your fan speeds/noise and gpu temps? And what fans do you use?",
      "If I ever get divorced this will be my mid life crisis.",
      "Not OP, but the fans are Corsair ML120 PRO LED White",
      "Shows just how much of an air cooled card is there for the air cooling.",
      "Honestly, they're not very good. Corsair's ML fans consistently perform worst or among the worst in any fan comparison between them andd other fans like Noctua A, Arctic P, Noiseblocker etc.\n\nCorsair's fan blade design just simply is quite poor, they have to spin much faster to produce decent airflow, which makes them noisy. I have a bunch of those ML120 fans gathering dust in a box because they were way too noisy while producing the same amount of airflow as my Noctua P and Silverstone fans.",
      "This lian li case has the psu behind the motherboard tray iirc",
      "Is that a massive radiator on the bottom!? If so, where is your psu?",
      "watercooled",
      "There's like $300 worth of fans alone in that case.\n\nThose are decent fans though.",
      "This is the way.",
      "Unless you have a water cooling loop don't \n\nThey're thick for a reason",
      "Corsairs are some of the worst rated fans in both performance and noise, yet they're the most expensive.\n\nLook up some YouTube reviews.... I have no idea why they're so popular",
      "Yeah but the RGB in that colour helps the cooling. It's been proven lol /s",
      "I feel like HR Giger would approve",
      "This is sick but I don't agree with the fan choice... I tried the Corsair ML120 Pro and thought they were unbearably noisy... unless you are just running them at low RPM.",
      "Literally got divorced recently spent 10k on a pc that is so stupidly overkill, can confirm it was a great idea.",
      "I wish more people knew about **Open RGB**, it controls pretty much all your RGB in one neat program, no need for multiple programs that may conflict or not even work properly in many cases",
      "Convection is not really a thing that helps in that scenario, because the fans push so much air through your pc case that the air get swapped every few seconds, so convection does not even has the time or the height to work",
      "Gamers Nexus did a video on this. Convection doesn't help.",
      "He probably keep those fans under 1000 rpms under load, with that much radiator volume."
    ]
  },
  {
    "brand": "amd",
    "generation": "6000",
    "tier": "top",
    "matched_keywords": [
      "6900xt"
    ],
    "title": "First build! 6900xt Red Devil and Ryzen 7 5800x",
    "selftext": "",
    "comments": [
      "Mobo: B550 Tomahawk\nRam: 4x8 32GB Trident Z Royal Silver 3200Mhz Cl14\nCPU: Ryzen 7 5800x\nAIO: Nzxt x73 \nGPU: 6900xt Red Devil\nStorage: 1tb Samsung 970 evo plus/2tb hdd\nPsu: 850w Seasonic and Cablemod meshpro replacements\nCase: Meshify 2, replaced all fans with Nzxt Aer 2",
      "This shit's dope. \n\nCould you post the full specs?",
      "Ahaha yeah been getting that a lot, this beast runs cool enough though.",
      "[This](https://www.reddit.com/r/buildapc/comments/cicmc1/tutorialpc_stat_screen_and_how_to_make_them/?utm_source=share&utm_medium=ios_app&utm_name=iossmf) post should explain everything",
      "I have almost the same specs as you. Started to have some serious issues while overclocking, eventually computer started shutting down. Replaced the power supply with a 1000w platinum and it's running great again. I started with a Corsair 850 gold\n\nOn a related side note I'm super jealous that you have three power rails. The XFX Merc card only has two for some unfathomable reason. Built to overclock but doesn't have enough power delivery... Smh",
      "Looks like all your budget went to the pc...",
      "Samsung Odyssey G7",
      "Why everybody's first build is stronger and looks better than my 56th build? And I'm 32...  \n\n\nJust a joke, but really...",
      "This isn't RGB, it's the glowing red of overheated heatsinks /s",
      "Can you see enough light from the front fans inside the case?",
      "I had a build like that. FX-8320 at 5.0GHz. While running OCCT small data set,  it was pulling 500 Watts at the wall (around 400 at the CPU after PSU and VRM losses). Even a 360mm AIO could barely keep up. Add in 2x 290s and I had to leave the door open while gaming.",
      "Where else should it go? ü§™",
      "as long as you choose seasonic everything will be fine!",
      "Wow i never thought that monitor had black levels that bad, well cool setup then",
      "Thats so dope. Whats the little display setup?",
      "The monitor",
      "Damn - now you got me kinda worried with my 750w and 6800xt + 5800x!",
      ">Damn - now you got me kinda worried with my 750w and 6800xt + 5800x!\n\nyou'll be fine. I have the same setup, with a 850W but I run a helluva HDD, and it's overkill anyway.",
      "Thanks! The monitor's absolutely amazing I'm actually thinking of getting another one for a dual monitor setup!",
      "I have overclocked 6900xt merc black + 3900x with Seasonic 750w Gold, been running like this since february no problems. I think they add extra W to recommended because there are people that use cheap, low quality PSU."
    ]
  },
  {
    "brand": "amd",
    "generation": "6000",
    "tier": "top",
    "matched_keywords": [
      "6950",
      "6900"
    ],
    "title": "RX 6950 XT vs RX 6900 XT - as per AMD's site",
    "selftext": "",
    "comments": [
      "So this is basically like an \"overclock\" of the original ones? (Asking for a friend since he is deciding between the rx 6750 xt and rtx 3070ti, around 150‚Ç¨ difference in price)",
      "**FPS averaged:** 139.75 vs 134.125\n\n4.19% faster for $100 more while using 20% more power... AMD stole Nvidia's playbook.",
      "That black fan shroud though",
      "At MSRP there is not a lot of reason to look at the 6750xt vs the 6700xt.  If you can get the 6700xt for ~70‚Ç¨ less than the 6750xt I would be more inclined to go that route as opposed to the 6750xt (MSRP prices compared).  Now, if the 6700XT is around the same price as the 6750XT that changes things.  Performance difference is minimal (2-5% from what I have seen).\n\nAs far as either vs the 3070Ti, that is a personal value proposition.  The 3070Ti has much better performance in many games and doesn't really ever lose to the 6700/6750XT.  It also has better ray tracing and includes DLSS.  Is that worth the price difference?  Very personal question.  I recently went back and forth on the same thing, and decided to go ahead and get a 6700 XT from AMD Direct.  But that price difference was more like $200-300, which to me was not worth it.  \n\nCan your friend wait a few more months?  Prices are sure to go down more over time and new cards are coming.",
      "> This. Should have done a refresh like 2080->2080S than this garbage\n\nI hope marketing students use AMD and Nvidia as case studies, because this is a perfect illustration of how mindshare warps the reception of a product.\n\nThe RTX 2080 --> 2080 Super was a significant price increase. You got 10% more performance for 20% more money. The 2080 Ti should've been $700, the 2080 should've been $500, and the 2070 should've been $400. Instead, you people lapped up those GPUs like they were caviar. The 2080 Ti broke sales records for a $1200 GPU.\n\n* The 3090 Ti is 33% more money for 7% more performance than the 3090.\n* The 6950 XT is 10% more money for 7% more performance than the 6900 XT.\n\nThe same geniuses who gave the 3090 Ti 8/10 for \"being the fastest\" are now criticising the 6950 XT, despite it being the fastest at 1080p and (marginally) 1440p, and despite it being **significantly** better value per frame than the 3090 Ti. You get 3090 Ti performance for almost half the price, but this is apparently not enough.\n\nThe 3090 Ti ($2000) and 6950 XT ($1100) are neck-and-neck, yet Nvidia get praised while AMD get slated. That's the power of mindshare. It's every corporation's dream to charge double what the competition charge for the same performance, while getting praised.",
      "Wow 5 fps more. Let me just run to spend my money asap",
      "My hope is that these are binned slightly better. But in reality they are probably just a clock and power adjustment with a memory module upgrade.",
      "At least theyre honest",
      "Strange, I saw Gamer‚Äôs Nexus showing about a 10% improvement.  Granted I have no intention of buying one but probably within margin of error",
      "To be fair both cards are AMD",
      "Looks like an nvidia move, cringe",
      "the only difference",
      "In-stock right now still. If it sells out it wont be for long. The 6900 XT, their previous halo/flagship has been sitting on shelves for months at its MSRP. People dont see the value in these. The 3090 has workstation value, and the 6800 xt and 3080 has gaming value. The price per frame are too high for these for gamers",
      "der8auer tested exactly that in his review. Despite AMD locking the 6900XT VRAM to max. 2150mhz he managed to beat the 6950XT at stock.",
      "As if we needed further confirmation:  \n**Corporations are not your friends.**",
      "Welcome to the non-sense of a broken market, I've been watching 3070s teeters around 3070ti pricing, same with 3060 to 3060ti. No real reason, other than market abuse, especially if the 3070/3060 aren't LHRs.\n\nAlso would say the 3070ti is definitely worth only 50 or so more, as long as that's all you're paying extra.",
      ">The RTX 2080 --> 2080 Super was a significant price increase. You got 10% more performance for 20% more money.\n\nCan you explain this? The 2080 Super was actually $100 cheaper than the original 2080 FE so I don't know what you're referring to.\n\nIt seems like you're upset that people aren't praising AMD for raising prices for the same performance tier, but the same reviewers that are criticizing AMD the 6x50 series called out Nvidia for the 3090 Ti and called it a \"dumb\" and \"tone-deaf\" release. Yes, Nvidia does have more mindshare. It's not a new phenomenon. That's why it's stupid for AMD to release these at higher prices.",
      "Admittedly for the power I pulled reviewer numbers",
      "And these are AMD's cherry picked titles too.",
      "I'd trade a 6950 XT for a 6900 XT and 100 dollars easily lol. Negligible performance increase for \"just\" 100 dollars more."
    ]
  },
  {
    "brand": "amd",
    "generation": "6000",
    "tier": "top",
    "matched_keywords": [
      "6950"
    ],
    "title": "Family fight: AMD Radeon RX 7900 XT is up to 7% faster than RX 6950 XT but costs 28% more - VideoCardz.com",
    "selftext": "",
    "comments": [
      "Nice of AMD to literally say to not buy RX 7000 series. I thought those were some third party charts, but no, it's their own charts showcasing how shit value RX 7000 are. Weird marketing strat.",
      "That's why i am keeping my 6900xt for now",
      "You totally should. Upgrading every gen is never a good idea, unless you are moving from something like low-end to high-end. If you already have a last-gen high-end card, there is no point in upgrading to a high-end one this gen.",
      "It‚Äôs wild to me that people upgrade every year. I just built my first pc and I‚Äôm not touching it for at least 3 years",
      "Up to 7% is a lie. Takes a few second to find results that show far more than that.\n\nAnd costing 28% more well good luck finding that because i can't find a 6950xt that much cheaper than a 7900xt in my country.",
      "The only AMD marketing strat this gen had been buy AMD because AMD good Nvidia bad. And people listened because even thought a 7900xt doesn't anything for its price if you post that you bought one you get a slap in the back, if you buy a 4070ti all reditors go out of their dungeon to tell you how bad the 4070ti is.",
      "The problem is that (at least from what I can find) the 6950xt has been better priced. I missed out when 6800xt's were $550-650, so now a $700-750 6950xt is my best bet once I do have the money.",
      "Very few people do that tho. 3-5 years is typical.",
      "AMD says you're part of the ultra enthusiast if you buy the 7900 xt  \n[https://twitter.com/amdradeon/status/1618341553587494941/photo/1](https://twitter.com/amdradeon/status/1618341553587494941/photo/1)  \n\n\nSo you're actually paying premium to be part of their exclusive group.",
      "The strangeest part is that those are AMD's own benchmark. Showcasing worst gains than most third party reviewers.\n\nWell it's not strange because they picked up e-sport games where they are probably CPU limited, but that's a weird way to market your products.",
      "It's chip binning, nothing to do with the overheating issues.\n\nAll chip manufacturers do this. Intel doesn't actually produce loads of different CPUs. They make one product, the best performing get core i9 designation, next batch below are i7, then i5, then i3.  It's all about avoiding waste and minimizing production cost.",
      "The biggest con AMD & Nvidia has going is convincing consumers that the latest generation is worth what they're asking..",
      "The strategy of the 7900XT is to sell 7900XTX chips that have a manufacturing defect. That's the whole point of the chiplet technology.\n\nIt's like when AMD put out the 3300X: they just so happened to have a bunch of chiplets that had 4 good cores, so they slapped them onto a CPU and sold them until they ran out of stock. Or like the 4500, which is likely just a batch of leftover Zen 2 chiplets that had cache defects.\n\nThe 7900XT is both an attempt to recoup money on bad stock, as well as acting serving as the [\"decoy\"](https://www.businessinsider.com/how-medium-size-tricks-you-2014-5) to get you to either help AMD move more 7900XTX's (\"it's only $100-200 more!\") or clear old stock (\"the 6950XT is $200-300 less!\").",
      "https://cdn.videocardz.com/1/2023/01/RX7900-RX6000-FPS-PER-DOLLAR.png\n\nThat's just hilarious that AMD would use frame per USD like that. I mean I guess I respect the honesty?",
      ">Very few people do that tho. 3-5 years is typical.\n\ni did it every year simply because i could sell my old xx80 or similiar card and then buy the new xx80 for like 20-80‚Ç¨ on top \n\n&#x200B;\n\nbut yeah... a xx80 or similiar costs this gen from both companys WAY MORE.",
      "MSI 6800 XT occasionally comes around on NewEgg for around 540. Just got one two days ago.",
      "On here it seems like everyone has a 4090 but in reality they are the enthusiasts, and they're selling out everywhere because they barely make any. \n\nIt's good buzz and gets the \"Nvidia has the fastest cards\" mindset into the public discourse, even if it's not true for the price. It's the reason people buy a 3050 instead of the same price or cheaper 6600xt",
      "That 7% figure comes straight from AMD's own website, in case you didn't read the article. As does the 28% price gap.  \n\n\nIf you have results that show figures substantially better than 7%, I am sure AMD would be dying to see them.",
      "how is evaluating 90 class cards on 1080p fps/$ honest?   should have been 4k. Comparing 1080p is misleading, it's the same as using i9 and ryzen 9 cpus and run 4k performance, suddenly they are all the same.",
      "They are trying to sell all the RDNA2 stock I think."
    ]
  },
  {
    "brand": "amd",
    "generation": "6000",
    "tier": "top",
    "matched_keywords": [
      "6900xt"
    ],
    "title": "My rx 6900xt finally arrived for my 5800x build, very satisfied with it and ready for legit any game for a couple of years.",
    "selftext": "",
    "comments": [
      "Clean built man!",
      "MAN... I am still struggling to see if i should get this GPU or not. It is the same price as my RTX 3070 in the scalpers market. I can sell my RTX 3070 and get the 6900XT for the same price. Maybe ending up spending $100buks more being my worst case. But..... still on the fence.",
      "One one hand, the 3070 has DLSS and that will make a big difference in games that use it. \n\nOn the other hand, the 6900xt is on average 35%ish faster.\n\nHere is some random yt video on it\n\nhttps://www.youtube.com/watch?v=xejgJADgf4o",
      "Are u serious? Im an nvidia fan but there's no reason to pick a 3070 over the 6900xt.",
      "Love my 6900 XT. Course I don't care about RTX or ray tracing in general, yet (for ray tracing).",
      "might upgrade when they release the ryzen 9 6900x\njust to have the NICE pc",
      "Thanks !",
      "The 6900xt is a fantastic card with great raster performance, no need to hype it up with objectively false claims about rt performance. It is not comparable to the 3080 or even the 3070.\n\nMake it clear what op will gain and lose, rt is definitely a loss for now.",
      "Consoles will put a limit on how demanding games will be. It‚Äòs all about them.",
      "I had the identical build, but I just upgraded to a 5900x. It's a really awesome build for 1440 gaming",
      "if rtx is not your most important concern, i'd say go for it\nstill good in rtx tho, sometimes beats rtx 3080 and most of the time the 3070",
      "The 35% more FPS will make DLSS irrelevant \n\nPlus, FSR is a thing",
      "Seconded. Sucks that false information gets upvoted \"because AMD good\". RDNA2 is a win, no doubt. But AMD is clearly behind the competition in terms of feature sets and ray tracing. I personally don't care about RT yet, but some people do. I have high hopes for FSR though.\n\nAlso, complete sidenote.... I'm more excited about the Lumens tech in UE5 than any current RT methods from AMD or NV.",
      "That video is literally bullshit lol",
      "The thumbnail literally shows red dead redemption with RTX on. Rtx for Red dead was announced a few weeks ago, while this video was uploaded 7 months ago in December of last year. Some other games in this video also didn‚Äôt have ray tracing when this video was uploaded. Such as doom eternal which it shows in the beginning of the video (again this video was uploaded LAST YEAR, doom eternal didn‚Äôt get raytracing until recently) So all those parts are just fake. Not to mention the uploader intentionally hid the like/dislike bar and literally all the top comments on the video is calling out all the fake benchmarks. Honestly no idea why that video is getting upvoted.",
      "The value of the 3070 right now is = to the 6900xt solely because or their mining performance being equal (but the 3070 is more efficient at it, so hence also valued more by miners). Imo when mining does die down, the card that will see its value decrease is the 3070 not the 6900xt",
      "got the card brand new on facebook marketplace for 50 canadian dollar over msrp",
      "That Fidelity Super Resolution could work for you. Its apparently super easy to implement so it should be in many games pipelines right now",
      "Half those games don't support ray tracing, yet he is claiming they do.\n\nAlso compare the results with other people and you will see they do not line up.",
      "Well there is, their feature set. As a current 3080 owner, yes I'd rather the 6900xt, but it won't perform as well with RT or use DLSS."
    ]
  },
  {
    "brand": "amd",
    "generation": "6000",
    "tier": "top",
    "matched_keywords": [
      "6950"
    ],
    "title": "Switched my RTX 3070 for a 6950 xt! With my 5900x processor, I'm full team red now",
    "selftext": "",
    "comments": [
      "NGL I've been tempted to make that same jump. But I am gonna hold out for the 7900xtx.",
      "Remember to enable AMD SAM in the drivers!!",
      "Thats a heck of a build my guy! What are your temps like with that cooler, been eyeing it for my 5900x as well",
      "Thanks for letting me know! I just enabled it in BIOS!",
      "I've been playing apex legends for about two hours now. My cpu is at 56.4 degrees Celsius with the die at 50.7",
      "That was my plan originally, but with the reference 7900 xtx at 1000 USD plus tax and everyone likely fighting over getting one on release, I thought it'd be better to just get the upgrade available now. For 770 USD, I thought it was a great deal on the 6950 xt. I did want to use it for gaming on ultra settings at 1440p now, since the 3070 just doesn't have the VRAM to perform at that resolution with those settings.",
      "I live in Peru in South America. I got the 3070 at msrp on release from the US for 550 dollars and I was able to sell it here in Per√∫ used for 400. I got the 6950 from Amazon for like 770 on black friday and a family member brought it for me here. So all in all, I've been really lucky with prices",
      "Same my man",
      "Dang that's some solid temps! Definitely will consider that cooler!",
      "Before/after benchmarks?",
      "Well, I play at 1440p. Before, with the 3070, I'd get between 110-130 fps on apex legends with everything on the highest settings and 110 fov. With thr 6950, it holds at 170 and dips to 169 periodically. 170 is my monitors refresh rate.\n\nThe main reason I was getting annoyed with the 3070 is because of the ram. With igb ram, I couldn't put games like resident evil village or steelrising in max settings.",
      "I'm hoping these cards drop in price with the 7900 series drop.",
      "Compatibility Support Module (CSM) it's kid glove mode, to ensure oddball hardware posts and at least sorta works.  When it's enabled many motherboard functions are substandard in their speed, bandwidth and overall performance.  It's a quick way to lose all your gains by leaving it on (or turning it on by accident)",
      "Congrats!\n\n\nJust want to say, there is no team \"red\" or \"blue\" or \"green\". These are not sports teams, or some charitable organizations. There's team consumer and team publicly traded for profit companies, when it comes to products. Consumers goal should always be to get the best value for the money. Companies goal is to get the best profit possible. Sometimes these 2 opposing factors align, sometimes especially nowdays not. Consumers should not be blinded by colors, marketing, fanboyism etc... cause if they do, they will get shafted.",
      "How much were you able to sell your 3070?",
      "If you're in Europe, it probably won't be happening\nAtleast not much. The 1000$ card is going to be around 1250‚Ç¨ here in the EU\n\nThe 1200$ 4080 is straight up 1550‚Ç¨ here\n\nOfc basically noone buys this shit\n\nThe 4090 is also straight 2K‚Ç¨",
      "The thing is that in my country, PC parts are super marked up. And, if I import it from the US, I have to pay 25% import taxes plus risk it getting damaged while it's shipped. So, I chose the 6950 xt in this case because it was a sure thing and it lined up with a relative being able to bring it to me.",
      "Ooh i understand, yes because of the resolution, same happens to me with rdr2 at max setting, plus i play on a Ultra wide screen 3440x1440 wich gives me even lower fps, I‚Äôm honestly waiting for the 79 series",
      "SAM is ReBar",
      "That Banshee though.\n\nBadass build!"
    ]
  },
  {
    "brand": "amd",
    "generation": "6000",
    "tier": "top",
    "matched_keywords": [
      "6900xt"
    ],
    "title": "Resolved Coil Whine on 6900XT by Switching From EVGA to Corsair PSU",
    "selftext": "",
    "comments": [
      "Some people in this thread seem to have misinterpreted your post as changing the PSU solved the GPU's coil whine. Edit: Your title is bad.\n\n**The coil whine was in the EVGA PSUs**.",
      "Wow that is serious coil whine, I have a 6900 xt that has slight whine on higher FPS but not quite as extensive as that.",
      "This is probably result of using this particular card type with this particular PSU. The strongest coil whine will appear if card draws power at a pattern that happens to be a resonance frequency of the PSU coils. Probably both EVGA models were equipped with the exact same coil, resulting in whine.",
      "Update 1/19/21:\n\nEVGA contacted me regarding whether or not they could help with RMA. They said that since the 750W G2 Supernova Gold was purchased as an \"EVGA Certified\" product EVGA reduced the warranty from 10 years to 1 year which means that even though the product was like new directly from EVGA, the warranty expired a couple years ago. They count the day it became \"EVGA Certified\" as the first day of warranty and not the first day the consumer purchased the product.\n\nBackstory:\n\nI upgraded my GTX 1060 6GB to a RX 6900XT. For first time ever in rig I heard awful coil whine that could be heard in the room next door. I'm an RN and used my stethoscope from work to assess PC before I blamed the GPU entirely. Turned out almost all of the noise was originating from my EVGA Supernova 750W G2 Gold PSU.\n\nMy first thought was maybe the PSU was always bad but I never realized it because my 1060 never put that much load on it for me to notice. I went to Best Buy and bought a new EVGA 700W Bronze PSU to test and the noise was almost identical.\n\nI decided to try one more PSU but from whatever other brand Best Buy had. I exchanged the EVGA for a Corsair RM750W Gold and the PSU buzzing went away entirely. There's still a tiny bit from the GPU only, but it's enjoyable once again to play games/music at night in quiet room while the kids are sleeping.\n\nI hope this might help someone exploring the same problem.",
      "Most brands have high and low quality units. \nIn general, if you are seeing a particular wattage for much less than others (wow, saving ten bucks!) you are often going to end up with much less clean power. \n\nOne of the most consistent PSU brands is definitely Seasonic though.",
      "Do you think it has anything to do with the brand? Or is it possible I was extremely unlucky with two EVGA units?",
      "Seasonic as a brand is still top-notch, agreed. They also make a lot of OEM units for other brands. I think some (usually more expensive) Corsair PSUs are actually made by Seasonic as well.",
      "FPS limiter, it does wonders.\n\nYes, under load, coil whine sucks, not much you can do about it.\n\nBut have you ever heard a 970 doing 8000fps on main menus? Awful.",
      "This needs to be higher because this is actually the answer. A lot of people want to return their card when it has coil whine but they are looking at the wrong component.",
      "This response makes sense. I had two different GPU's on the same PSU with no issues. It wasn't until I installed the 6900XT.",
      "My 2011 vintage Corsair HX750i started screaming at the slightest provocation (even SSD load) before I replaced it with a Seasonic TX-750.  \n\n&#x200B;\n\nMy reference RX 6800 XT had slight bit of whine that got better after the first few days, but dear lord, if you put an EK waterblock on your card, and you opt to also put a backplate on, don't tighten down the central 4 screws, else the backplate becomes an emitter for coil whine that projects it across the house.",
      "Yeah the backstory made it more clear. I have coil whine on my 6800XT, my PSU is fine. It's an SF750 so it better be, since it's a 80+ Platinum :D",
      "Yes. I picked up an RM850i Corsair PSU, and it was refurbished, right from Corsair‚Äôs factory in Texas. You get the OEM box, instead of Corsair‚Äôs fancy box and it has a tiny Seasonic logo on it.\nPerfectly quiet PSU, btw.",
      "I have the XFX 6800XT 319 Merc. It uses the same PCB and power delivery system from a 6900XT. \n\nUnfortunately, it doesn't fit in my computer case so I am waiting for a new case to arrive. As a result, it's on my open test bench, about 6\" to the left of my keyboard. Fortunately, it's the very first GPU I've owned where I cannot hear the coil whine. My 2080ti FE, 1080ti FTW3, and GTX690 all screamed and whined like banshees and we're audible from inside their respective chassis.\n\nI've used Seasonic, SilverStone, EVGA, AND Corsair PSUs and it's never made a lick of difference in GPU noise. There was probably something else that changed in the power equation (i.e. surge protector or power cable).",
      "\"bequiet\" ironic",
      "ho jesus that actually happened to me! GTX970 going like 8000fps on the game Symphony on steam. This was my first time hearing such noise i thought my pc was gonna blow up!",
      "In my experience, it's just a tossup if a paired combo whines or not. For example:\n\nPSU1 and GPU1 has coil whine.\n\nPSU2 and GPU2 has no coin whine.\n\nPSU1 and GPU2 has no coil whine\n\nPSU2 and GPU1 has no coil whine.\n\n\nCoil whine doesn't mean the card sucks, or the PSU sucks, it just means that together they are causing those caps to resonate at an annoying frequency.",
      "> This is probably result of using this particular card type with this particular PSU.\n\nWe recently got back an EVGA 750BQ power supply from a client complaining about coil whine in the PSU. I tested it with a GTX 560 (my work computer) running the Heaven benchmark. Tons of coil whine and very noticeable, especially when it transitions between scenes. It was very similar sounding to the 700BR in this video.",
      ">But have you ever heard a 970 doing 8000fps on main menus? Awful.\n\nI have. And mine have been completely silent all the time I've had it. However, a friend recently borrowed it, and he called me to complain about the coil whine.\n\nSo I'm pretty sure it's the specific configuration, most like the PSU, that's the real culprit here.",
      "FPS limiter at for example, 300, has absolutely no downsides.\n\nAs long as it's slightly above the refresh rate, you're fine.\n\nI'm running a 70hz display and have a global FPS limiter at 100, and everything works well with no inputlag whatsoever. No tearing issues, either."
    ]
  },
  {
    "brand": "amd",
    "generation": "6000",
    "tier": "top",
    "matched_keywords": [
      "6950xt"
    ],
    "title": "Built my son his first PC last weekend. R7 7700X & 6950XT",
    "selftext": "The computer pic was pre cable management, but was just ready to show him his new PC nothing beat seeing how happy he was. Link to the parts used (via pcpartspicker). https://pcpartpicker.com/user/ITZJOSH33/saved/BR4YXL",
    "comments": [
      "I‚Äôm a 40 year old looking to be adopted. Do you need another son?",
      "Did he catch you browsing adult pages? He must have some kind of leverage lol",
      "That would be awkward as I‚Äôm not 40 yet myself üòê",
      "Lol you‚Äôd have to think so, but nah he‚Äôs been wanting his own after he seen me build mine.\n\nhttps://preview.redd.it/3a1gtbqfun2b1.jpeg?width=3024&format=pjpg&auto=webp&s=80b9a6eb6d84b4022b7d9d10482df1e39f62d490",
      "So let him adopt you lol",
      "Thermalright AM5 secure frame\n\nThey cost ~$10",
      "They do nothing other than look cool but I hear they keep excess thermal paste from getting messy.",
      "Some games if he wants to, we don‚Äôt always have the same taste in games. However I do enjoy gaming with him.",
      "What is that red thing around the CPU? Can it be bought? Thank you.",
      "I think it's more relevant for Socket 1700 (Intel) where the more rectangular shape is apparently causing CPUs to bend/damaging the socket due to the way pressure is applied from the coolers. Using one of these evens it out.",
      "You let me know what you need to make it work. If it helps I have a young face.",
      "Lucky man.",
      "Why do we need it for?",
      "Here‚Äôs the CPU temp screen\n\nhttps://preview.redd.it/pdj9lbx2xq2b1.jpeg?width=4032&format=pjpg&auto=webp&s=1fa033a2cc25d5cde6c38c5e1d42de19ff0fffd9",
      "They don‚Äôt. The IHS is thicker than Niki Minaj.",
      "Lucky son.",
      "Less damaging the socket and more the bending prevents the cooling solution making good flat contact with the CPU which affects performance.",
      "I‚Äôd have to see your list of qualifications. Also your list of hobbies/passions/ and sports teams.",
      "You might want to change the pcpart picker name list. I mean it's not particularly sensitive, but people can be weird. Great build, I wish I had a PC like that lol.",
      "Do you play with him ?"
    ]
  },
  {
    "brand": "amd",
    "generation": "6000",
    "tier": "top",
    "matched_keywords": [
      "6950xt"
    ],
    "title": "Ryzen 9 5900XT & 6950XT Sapphire",
    "selftext": "",
    "comments": [
      "Jesus is that a 4-slot card? Great big chungus.",
      "Have you seen the 4.5 slot 3070 lol",
      "‚ÄúZAMN!‚Äù MY DREAM BUILD\nBut HOLY SHIT BRO WHY IS THE CARD THICCC",
      "Asus x Noctua 3070, 3080\n\nhttps://i.imgur.com/ayEIhyH.jpg\n\nhttps://i.imgur.com/ihnNYr6.jpg",
      "3 slot but you get a gpu support bracket it‚Äôs a heavy boy makes it look like 4 üòÇ",
      "WHAT",
      "Jesus Christ",
      "It‚Äôs a THICCC boy I watched a tear down on it apparently it‚Äôs so thiccc to help with the cooling because it‚Äôs get toasty",
      ">Sapphire really overengineered that card\n\nThats basically a brand feature at this point.",
      "Love this look. Simple and futuristic at the same time. What case is that, please?",
      "5900XT , how? :P",
      "Excuse my language but what the fuck",
      "It‚Äôs the Corsair 5000d airflow",
      "Could you please add a few more fans?",
      "For that overkill the GPU better not be more than 50 degrees under 100% load lol",
      "I'm pretty sure it's a sag bracket under it but technically still occupying 4 slots",
      "Sapphire really overengineered that card, haha.",
      "that cooler on anything less than a 3080 is just silly lol",
      "Only going to get thicker  with new generations, specially with Nvidia. 4k series is going to output over 400 watts stock, so the cooler needed to keep that cool will be massive.\n\nWent from sli needing 5+ slots between 2 cards to one card taking all that up itself, lol.",
      "Deffo worth it I had a 6800xt and I sold and bought this beast"
    ]
  },
  {
    "brand": "amd",
    "generation": "6000",
    "tier": "top",
    "matched_keywords": [
      "6900"
    ],
    "title": "Broken AMD 6800/6900 GPUs after driver update? Video in the description (not mine)",
    "selftext": "",
    "comments": [
      "Just in case you haven't heard of KrisFix and are questioning his expertise or motives:\n\nHe has been repairing a lot of GPUs on a very high level for a number of years so he knows what he is talking about. Just look at the videos on his channel, they speak for themself\n\nExample: \n\nHere he is reballing a 3090 chip + ram because the card was drenched in liquid metal: https://www.youtube.com/watch?v=6nQCj5N9fV8 (skip to the last third of the video to see the soldering)\n\nHe is not some random small hobby Youtuber trying to create drama for views. \n\nIf he says \"I see a pattern here\" then people should certainly pay attention to what he is saying",
      "XFX 6900xt on 22.11.2 and nothing weird on going for me.\n\n(Knock on wood. Fingers crossed. Toes crossed.)\n\n&#x200B;\n\nedited",
      "This is crazy. My RX 6900xt recently died. About a day after I installed the newest driver.",
      "`if (warranty > 24) {`\n\n  `execute = \"overvolt.exe\"`  \n  `greeting = \"Check our brand new 7000 series GPUs\";`  \n`}`",
      "Count mine in. I had to replace my 6900 xt a month ago. I upgraded to the newest drivers at the time.i also used the auto undervolt feature in adrenaline software. then, I  played Black Mesa with every setting on ultra at 144hz 4k for an hour. I shut the PC down. The GPU never came back on the next day.\n\nEdit - my GPU is a reference 6900 xt model. GPU died after I updated to 22.11.2 recommended whql. Never mined with it. Just benchmarking/gaming/productivity",
      "People replying should include which aib card they are using \n\nCould help isolate the issue",
      "Unfortunately it's going to be very hard to verify this, as I don't think there are many repair shops doing GPU board repairs, that also have a social media presence. \n\nAIBs would know due to warranty claims, but it's not in their best interest to tell journalists about abnormally high defective GPUs.",
      "JFC can we as consumers ever catch a freaking break???",
      "Same Here for me. Excact Same Symptom.\n\nPowercolor Red Devil Ultimate 6900XT",
      "Yeah Kris Fix is a professional. Love his channel.",
      "I suppose it's good that i'm still on ye olde circa may 2022 drivers because black screen crashes are the bane of my existence and I refuse to modify windows settings to compensate.",
      "My Gaming X Trio is working fine too. This shit is making me nervous tho lol",
      "No issues with my card (reference)\n\nLast driver 22.11.2 WHQL",
      "I like your funny words magic man",
      "*nervously walks behind you...\n\nThis is like a horror film, but first person.",
      "Out with the old. In with the new",
      "Technically you only have 1 year of hassle free warranty in germany where you can return the product for rma. The second year becomes a little more complicated because now you as the customer have to prove to the seller that the damage/fault was already there at the time of buying the product.\n\nSo if a component was maybe already faulty but did not immediately result in a failure for example.\n\nNormally you would expect them to be accomadating and still just give you a replacement unit but they could also refuse it and demand that you prove them that this fault was already there at the time you bought the product at. Which would obviously be quite difficult as a consumer to do so.\n\nMaybe that's why they just send it to a repair shop.\n\nEdit: Of course this is just the minimum warranty requiered by law but individual companies can extend this if they so choose to.",
      "Mit dem Angriff Medions wird alles in ordnung kommen!",
      "So you think exposing corporate failures constitutes a hit piece? The 7900 XTX was a clear manufacturing default, not a hit piece It's an issue they needed to be called out on because they were trying to hide it and disavow any liability until they were called out.\n\nThis issue has nothing to do with that but it's an issue nonetheless, so I guess if you think raising awareness for legitimate problems is a hit piece then yeah not surprised Germans are the ones leading the charge, as a nation they have a culture of calling a spade a spade.",
      "My god. If this is true, this is absolutely disastrous for AMD.  \n\nThe GPU world has been an absolute dumpster fire as of late. Both AMD and Nvidia dropping the ball again and again.  \n\nThat said, a botched driver update that bricks a bunch of previous gen cards absolutely takes the cake."
    ]
  },
  {
    "brand": "amd",
    "generation": "6000",
    "tier": "top",
    "matched_keywords": [
      "6900xt"
    ],
    "title": "5950X x 6900XT LC ; First real build.",
    "selftext": "",
    "comments": [
      "Yeah your fan situation is honestly pretty bad. If you optimise it a little you‚Äôll see way better temps",
      "Nice build and congrats. Interesting choice on your fan orientation. How are your temps?",
      ">since warm air rises.\n\nConvection has **zero** effect against this many fans. Cold air is entering the back through the open pcie slots hes not starving the gpu of air at all, the dust you mentioned is evidence of that. he'll just have to clean his computer every other month.\n\nNegative pressure is totally viable and often has a positive effect on radiant thermals inside the case.\n\nEdit: Well then. Thanks anonymous, I'll spend them wisely.",
      "Newegg: how many fans do you want?\nOP is 21savage:alot",
      "LMAO this is a very interesting fan's configuration indeed.",
      "76 c under high load generally around 40-50 c",
      "A fan of fans should always have the fans fanning the right way",
      "just noticed the 4 dominator plat dimms lmao. what speed?",
      "Very very interesting lol turn those bottom fans around. You have too much negative pressure with all fans blowing out.",
      "I‚Äôm a big fan of fans for no reason",
      "Lets be honest, you did it like this because of the how the RBGs look on the fans. You can buy the corsair ones that look the same on the back and the front if it really matters to you. I think they're the QL series.",
      "And you still have 8 other fans blowing out, resulting in a lot of negative pressure. If you turn the bottom around, the pressure would be more even and allow much more air through your case. I have the same case and have done just about every fan combination.",
      "Unusual fan arrangement. Bottom fans pushing air out??",
      "It‚Äôs a backplate and the glass wouldn‚Äôt fit back on the case unless I did some hoopty shit lmao you right",
      "3600",
      "at 4.8 ghz?",
      "I clean my computer constantly but not because it‚Äôs dusty just because I don‚Äôt want dust to build up, and none of the fans not directly connected to components have been effecting my system at all negatively",
      "I almost never clean my computers, because I have 6 of them and its a hassle. maybe like 4 times a year at most because I keep a clean home and don't have pets or smoke indoors.\n\nPeople a weird about PC perfection and I think its stupid.\n\nAn oil refinery doesn't pay electricians millions to cable manage for looks, they do it to ensure reparability, safety and efficiency. The people who cry about \"messy AIO tubes\" are the same people who run unshielded data parallel to their 12vpower lines. Its dick measuring idiocy.",
      "I actually just keep a bunch of ice cubes inside my rig so it‚Äôs not an issue",
      "Awesome build! I have the 6800 XT variant of that same gpu with a 5900X it's great. Mounted mine vertically last week."
    ]
  },
  {
    "brand": "amd",
    "generation": "6000",
    "tier": "top",
    "matched_keywords": [
      "6900xt"
    ],
    "title": "Here is my AMD build and battlestation - 5950X/6900XT",
    "selftext": "",
    "comments": [
      "It looks so clean and elegant. Nice station !",
      "I didnt built this in days or weeks, it took like months/years (im old and slow) and now I feel its 95% completed. Next update is probably 7900X3D/AM5",
      "Upvote for proper sound system, everyone skips that part for some reason üòû",
      "Cause headphones for the most part",
      "Never mind, I am young and slow. Took me a year to finish my build while new things on the tech market arrived hahaha ü§£",
      "I get that a lot of people use headphones. It is a relatively inexpensive way of getting a good sound. I have some Sennheiser HD380 headphones but hardly ever use them. For me, there‚Äôs something about the sound of a good speaker you just can‚Äôt beat when listening to music.",
      "When do you get the good headphones ? Heh",
      "Actually yes. It helps to keep positive pressure inside the case. It helps!",
      "Yes this is Ergotron LX",
      "Klipsch R-14PM",
      "I get that, but personally, I'll listen to my speaker setup on my tv instead of my desktop. My computer is just better to use with headphones with my use case",
      "Is that an Ergotron monitor mount? I‚Äôm considering one for Neo G9.",
      "With a build so powerful already I would recommend waiting a while on the upgrade. At least a few months while we make sure all of the kinks are ironed out with the new platform and we can see what motherboards work well, and likely DDR5 prices will keep dropping.   \n\nIf it was me I'd skip a generation (or 2).",
      "Nice build! I build my WC system too in Fractal case (Meshifi 2XL). You can see it in my profile :)\nWhat is model of 6900XT? I have Tuf version and it have bad coil whine. Do you notice coil whine of your GPU?",
      "Mmmm, fractal design. Delicious.",
      "I like Klipsch sound a lot",
      "So clean!\n\nDoes the foam help much with dust?",
      "That's what I thought when I saw this. Whole lot of horsepower to confine to one monitor lol.",
      "Depends on how nice the speakers are! Can‚Äôt tell the model but great speakers can provide just as good of a listening experience. Plus sometimes headphones just aren‚Äôt as comfortable üòÇ",
      "Yeah they make them powered and not. I have both. Love them."
    ]
  },
  {
    "brand": "amd",
    "generation": "6000",
    "tier": "top",
    "matched_keywords": [
      "6950xt"
    ],
    "title": "After 9 Years of service i wish my R9 380 a good retirement , and welcome my 6950xt in hope for the next 9 Years of gaming",
    "selftext": "Ngl i would stick to R9 if they still were updating the drivers otherwise it kinda forced me to upgrade",
    "comments": [
      "Sapphire - very nice brand choice of the GPU!!\n\nI would rank them among the top 3 in the AMD GPU maker's list.",
      "Are you me? I'm not upgrading again until Ryzen 16-core CCD. I came from 3570K and expect similar upgrade cycle",
      "Because Sapphire is the best?",
      "I can't wait to do the same with my RX 480s. They've performed extremely well for a long time but it's almost time to decommission them.",
      "Do u know why sometimes sapphire gpu models are most expensive ones and other gpus are cheapest?",
      "It depends du modele, sapphire produces the pulse and the nitro. The nitro is the more expensive",
      "Real",
      "I meant that one time sapphire model is most expensive one and sometimes its the cheapest",
      "This is the way",
      "The lack of new AMD driver software thing really stops you from newer titles even tho these cards still have some juice in them",
      "Awkwardly looking at this post while still using a RX 480 8GB and an i7 2600K‚Ä¶ üëÄ\n(I don‚Äôt game on my PC, which is why I don‚Äôt see a point in upgrading)",
      "/salute\n\nMy brother is using my old XFX HD 7950, still running smoothly.",
      "It's mid-range. RX6800 signifies the start of the high end cards on AMD.",
      "Low end is not much difference. High end theres a big difference ;)",
      "Toxic, highest",
      "I'm not only using pc for games i also do hobby style blender or video editing and i dont fear the power draw since you can always undervolt",
      "Did your fans die even once in 9 years? I actually had to jump from r9 280x to 1080ti beacause of fans dying.",
      "Good choice. I‚Äôm more a 3-5 year/2-3 gen GPU upgrader. Hoping my 7900XTX will age as well as the 5700XT thicc iii, Fury, 7970, 4870x2, 2900XT, X800XL and Radeon 64MB ViVo did.",
      "Nope i it was working fine all along",
      "Forced obsolescence FTW üòû"
    ]
  },
  {
    "brand": "amd",
    "generation": "6000",
    "tier": "top",
    "matched_keywords": [
      "6900"
    ],
    "title": "AMD Officially Launches RX 6900 XT Liquid Edition with 330W TDP and 18Gbps Memory",
    "selftext": "[https://videocardz.com/newz/amd-launches-radeon-rx-6900-xt-liquid-edition-with-330w-tbp-and-18gbps-memory](https://videocardz.com/newz/amd-launches-radeon-rx-6900-xt-liquid-edition-with-330w-tbp-and-18gbps-memory)",
    "comments": [
      "The cooler is made of the high end Unobtainium + paper launch alloy, for never seen before level of performance!",
      "Just 10% higher TDP for 10% higher clocks? That's actually pretty good. Looks like it's not past its \"sweet spot\". Either that, or these chips are the golden samples and have better efficiency than the ones used in the regular 6900XT.",
      "Summary:\n\n\nClock differences vs ref:\n\n10% game clock, 7.5% boost, 11% memory.\n\n10% more power usage.\n\n2 slot design, expected June",
      "Launching Nevermber 32, 2021",
      "These chips are golden samples yes, XTXH instead of XT dies (just higher binned)",
      "Or a Radeon 6969 XXXTT",
      "Nice, can't wait to get my hands on one of these when I build my retro PC in 25 years from now",
      "For never well be seen level of performance",
      "I just want an entry-level GPU PLEASE",
      "They should have called the RX 6900XT the RX 6900.",
      "Samsung already produces 18gbps memory, it's probably more costly though",
      "I wonder how they got the memory that fast, that's almost up to the 3080ti/90 (19Gbps) think the OG is 16Gbps?",
      "It takes a while to build up a supply of golden chips to produce a binned product like this.",
      "*11,25% memory :P",
      "Their marketing department needs a refresh.",
      "It will be seen. Just not by Verified Actual Gamers (TM). \n\nThe 4 cards at launch will do a lot of heavy lifting sitting in some scalpers basement, listed on ebay for $6900",
      "Can't wait until December 64, 2021",
      "Almost definitely golden samples. But still pretty impressive though.",
      "RX 6969 XD",
      "RDNA2 getting wet"
    ]
  },
  {
    "brand": "amd",
    "generation": "6000",
    "tier": "top",
    "matched_keywords": [
      "6900xt"
    ],
    "title": "Finally upgraded to 6900xt from Vega 56!",
    "selftext": "",
    "comments": [
      "That‚Äôs like triple the performance, enjoy!",
      "That case is HUGE.",
      "Phanteks 719, designed to be able to hold a full ATX system and an ITX system at the same time.\n\nedit: also the Phanteks Enthoo Pro 2, same design more airflow.",
      "Makes sense for streaming (streaming pc in ITX, main PC in ATX).",
      "Thanks, man!",
      "Have seen 1 or 2 couples come by in /r/buildapcforme that wanted it as a way to save space on the desk by putting both their machines in one case, but yeah pretty niche function.",
      "If you haven‚Äôt already, you should sell your Vega 56. It‚Äôs a beastly mining card with its HBM2 memory, (50MH ETH, 200MH ERG), you should get at least $800 for that card.",
      "Red Devil and Merc were my top choices but couldn't find any Red Devil here. They're both nice looking cards",
      "I like my Red Devil a bit better.",
      "Eh, as a former V64 owner it was starting to show it's age. Definitely a decent card still absolutely, but I have no regrets upping the ante to a 6800",
      ">Phanteks 719\n\nhey thanks for saying the name of my next case, didn't even know it existed and Obsidian 1000D is almost triple the price lol. getting it soon haha thanks m8",
      "I got $300 CAD for my Vega 64 when I sold in October 2020. I was a fool. :)",
      "Damn now I want to replace mine too",
      "Vega 56 enjoyer here. Maybe OP is going to play at 4K resolution. In that case, Vega 56 is not enough these days to properly perform on highly demanding titles.\n\nI'm playing at 1080p and still holds on incredibly well, though. Only thinking I bought it brand new 2+ years ago for a little more than 250‚Ç¨... I really dodged a bullet there, I guess.",
      "How much did you get for your vega56? 7-800‚Ç¨?",
      "A bit over double. Still solid AF :)",
      "All black system, very nice",
      "Got $350 USD for my Vega 64 in December. Also a fool.",
      "No... Not once you've experienced 1440p 144hz",
      "I've sold mine last week for 700‚Ç¨. Then got a 6700 XT for 700‚Ç¨..."
    ]
  },
  {
    "brand": "amd",
    "generation": "6000",
    "tier": "top",
    "matched_keywords": [
      "6950xt"
    ],
    "title": "6950xt OC FORMULA + 5950x",
    "selftext": "",
    "comments": [
      "Wtf is that ram cooler",
      "80mm noctua, dropped temps by 15 at max load (super stable), 3800 cl14 gets hot over 1.5v",
      "Huge gains in timespy benchmarks, as well as cpu intensive games such as Warzone (30+ fps increase compared to a 3200 cl16 kit)",
      "Solid 120 seconds per frame",
      "Well that's some oc... But does it improve the performance significantly?",
      "Wow @ the ram fan.  They included a sag bar for that gpu for a reason",
      "dips to 190 seconds per frame occasionally",
      "Installing it now‚ò∫Ô∏è",
      "Nice, what frames you getting in wz?",
      "I personally love how the honey comb mesh on the gpu matches the honey comb on the motherboard io side.",
      "Ah yes, swap out a $5 dollar fan for an $80 dollar fan just for aesthetic reasons",
      "Had to drop the resolution to 720p for a stable 60fps, but atleast it's playable üëç",
      "Saw your review on Newegg haha",
      "‚Ä¶Buuuuuut will it run minesweeper?",
      "That looks amazing. Which BeQuiet AIO is that? I didn‚Äôt know they had one with RGB on the pump head.",
      "Welcome to the club buddy https://imgur.com/gallery/PqMrEKT",
      "When stressing testing without a fan they will go above 50 celsius which causes instability, it maxes at 35-36 now",
      "I should of mentioned I also have 3800mhz CL14 ram in my rig.    Not sure for downvote but thought to give my fps to you since I have an identical rig has OP. 6950xt is probably a tiny bit better than the 3090 or on par with it",
      "üò≥  \nSexy.\n\nWhere'd you get those GPU cables?",
      "Honestly I prefer how mine looks, and it performs better than that!"
    ]
  },
  {
    "brand": "amd",
    "generation": "6000",
    "tier": "top",
    "matched_keywords": [
      "6900"
    ],
    "title": "[Guru3D] Availability of the Radeon RX 6800 (XT) & 6900 XT Is Still Extremely Poor",
    "selftext": "",
    "comments": [
      "6800 2930 ordered 117 delivered\n\n6800xt 2513 ordered 42 delivered\n\n6900xt 354 ordered 0 delivered\n\nfor the 159 delivered: \"we did not expect so much demand\"",
      "ordered=from manufacturer\n\nnot by customers",
      "Saw the 6900xt on ebuyer today had it in my basket almost purchased it but then did a double take on myself like \"do I ACTUALLY need this? nope\" so gonna wait till stock normalizes I was only going to pull the trigger because of low stock like \"if I don't get one when will I?\" just gonna wait 6 month and see whats on sale then. Not going to be triggered to buy somthing because of low stock which I almost was.",
      "Are these numbers accurate? That just blows my mind. I‚Äôm one of the 2513 ordered and now I just feel like I‚Äôm never gonna receive it",
      "Honestly I feel that if it wasn't for the high level of demand for high end GPUs people wouldn't be as willing to buy an RX 6900 XT or RTX 3090. In a \"normal\" GPU market it simply doesn't make any sense to buy these cards unless you are using them for work.",
      "I was told by Canada computers that my 6800 XT will just never come in, so I can either wait for an AIB that they have no expected delivery date, or go to the back of the line for a 3080. Definitely a month of waiting well spent /s",
      "they said 2 months for availability, we are on month 1 + 5days and counting\n\nI said that it was a lie but.. who knows, I hope I'm wrong",
      "The 6800xt red devil variant from powercolor retails for 1197 USD. What is worse, I don't think this will go down any time soon",
      "Yeah thats the problem im having right now, I don't really need a 6800xt / 6900xt but currently running a rx 580 8GB and the games I play run fine so I don't \"NEED\" one of these new cards but I would certainly notice the difference.\n\nPersonally I wish there was more of a mid tier GPU available, right now 5700xt is about the price I want to pay, but fuck buying something like a 5700xt or anything not \"this generation\" for the IPC uplift.\n\nHoping next year AMD puts out some replacement for the 5700xt or Nvida up the amount of VRAM in their cards because I was even looking at the 3060ti etc but its like I am not going from 8GB VRAM to 8GB ...",
      "AMD confirmed that more reference cards will be made for all models. But given that at most AMD is only getting at most 60 GPUs per wafer and Nvidia is getting at most 50 GPUs per wafer for both companies largest dies, don't expect supply to normalize any time soon. Keep in mind that that's only 140,000 TSMC 7nm wafers processed every month in total. And AMD has between 44,000 and 70,000 of those (we know that no customer is over 50% and some customers have dropped without disclosing who the allocation went to). Nvidia is using Samsung 8nm and we aren't sure how many wafers they're buying or even how many wafers per month Samsung is making on 8nm versus their 7nm process. But total supply to Nvidia is likely between 100-300% of what AMD is using at TSMC for GPUs based on what numbers look like in wholesale channels.\n\nMy guess is that Nvidia probably has around 10k-15K wafers/mo for all of its Ampere products including the A100 which is currently out of stock with earliest possible delivery via air being listed as 3 weeks. And AMD is likely only dedicating 2-3K wafers/mo to their high-end GPUs with the vast majority of their TSMC 7nm wafer allotment being slotted for console APUs, processors, and low- and mid-range GPUs that are launching next year. Furthermore, AMD also is starting to fulfill CDNA which is a 120 CU  computer focused GPGPU solution for data centers which features better FP16, FP32, and FP64 performance compared to Nvidia's A100 and has already been ordered in bulk, along with the not yet publicly released new Epyc processors for the first two exascale supercomputers.\n\nOh, and to top this all off, we've had shortages of the following so far this year:\n\n* Screws\n\n* Shipping containers from China\n\n* Shipping containers to China\n\n* Air freight capacity due to decreased intercontinental flights and now vaccine deployment\n\nAnd all of that is affecting the ability to move produced products from Asia to the rest of the world. Not to mention the fact that shipping is taking longer due to COVID-19 mitigations that slow down the loading and unloading of ships, planes, trains, and trucks.",
      ">AMD confirmed that more reference cards will be made for all models\n\nAMD's word means nothing at this point.\n\nThey have said-\n\n- There would be more stock than nVidia launch - **false**, *nVidia had more cards - both sold out quickly but nVidia had 2-3x the cards available on launch day.*\n\n- There would be 5-7x the stock for AIB cards - **false**, *there were even less cards for the AIB models than reference.* \n\n- There would be a general availability and a return to MSRP within 4-8 weeks (still in progress, but considering we're hitting christmas, new year then chinese new year - we can do this one early, there won't be stock before march) - false",
      "No. The mining craze was way worse. I know it first hand because I bought my RX 580 back then and I remember that I had to wait for months to get it.\n\n\nIt eventually got to a point where the only card that was readily available was the GT 1030 (even the RX 550s were selling out immediately). At least currently I can still buy an RX 5000-series card or an RTX 20-series card if I needed to.",
      "AMD told Hardware Unboxed that in up to 8 weeks MSRP cards from AIB partners would be available so we will have to wait until mid-January to see if that ends up being true or not.",
      "My canada computers hasn‚Äôt told me this, but they have no idea when I‚Äôll get my card either",
      "I saw my first social media post about someone actually getting a 6800XT yesterday. It was a reference design from XFX. Compared to nvidia, I see maybe 5-10 posts every day of people getting 3080's and 3070's. \n\nI know this is far from a quantitative analysis, but this is a factor I've been using to judge availability for years and it has always worked for me.",
      "The fact they decided to keep the reference going means they might think this won't happen now.",
      "Nah its not that one dimensional, they do proper market research and much more to find out the demand but they also are restricted by foundry capacity.",
      "Weren't 580s and 1060s going for $500? That was super rough. A $200 msrp card going for $500 and what's worse is that eventually retailers started charging that much. It's even funnier that despite all that and despite 4-5 years, the msrp of the rx 580 hasn't changed (still around $180?)",
      "It‚Äôs so much worse than the 30 series. I‚Äôll grant them that they were released later but I‚Äôve seen basically no restocks of these cards.",
      "I got a 6900xt this morning at microcenter. Had to be there at 5:30am outside though to be one of the first 10 in the store"
    ]
  },
  {
    "brand": "amd",
    "generation": "6000",
    "tier": "top",
    "matched_keywords": [
      "6950xt"
    ],
    "title": "AMD Radeon RX 6950XT drops to $610 prior to GeForce RTX 4070 launch - VideoCardz.com",
    "selftext": "",
    "comments": [
      "It was actually $599 yesterday but it was a \"shell shocker.\"",
      "This is a good deal. I got the XFX 6950XT Merc Black about 2 months ago, and it's been great. I've been testing the shit out of it and comparing it to the new stuff. It's basically a 4070ti without the RT performance. It does light RT work like in RE4 really well. Runs way better in games than in benchmarks. You can overclock them high, too. These are the best of the best Navi 21 KXTX boards AMD is trying to get rid of",
      "RE Engine is properly optimized. The RT performance is actually pretty good on game engines that took the time to implement for AMD.",
      "Sigh. Nowhere close to in Europe.",
      "I got mine at $700. This is a good deal.",
      "I think most people from Europe, including me, tend to forget that the US Prices don't have the tax included... Cuz AFAIK in Europe the listed price includes tax.",
      "..what? I count 5 different countries in the EU that have one within 5% of the US's price when you account for tax, Germany has it for nearly an identical price.\n\n$610=554.75 euros, Germany's VAT: 19%,  554.75*1.19=660.1525.\n\nYou can buy a 6950XT in Germany for 659 euros.\n\nCountry|Cheapest 6950XT (Euros)|Country's VAT|US price converted|% Difference\n:-:|:-:|:-:|:-:|:-:\nBelgium|696.95|21%|671.2475|+3.8%\nFrance|684.00|20%|665.7|+2.7%\nGermany|659.00|19%|660.1525|-0.2%\nItaly|684.00|22%|676.795|+1%\nNetherlands|689.00|21%|671.2475|+2.6%",
      "It's a very large country, if you're in the western part life will be mostly normal where as in the eastern part you will find entire cities where not one building is still standing.",
      "700 usd weeks ago",
      "No. The 6800xt is the perfect 1440p card.",
      "Respect that you've got the restraint to wait for that last few percent off.",
      "6950XT way better and its not even close",
      "> and it speaks to how nice Capcom's shaders are even without RT\n\nOr how \"meh\" the RT implementation is.",
      "Waiting for a $750 type deal on a 7900XT and I'm jumping. Newegg has one for $779 and it's real tempting to go ahead.",
      "I picked one up last week for $650 lol I‚Äôm good with that price.",
      ">Im better buying it from the US, this is ridiculous, at least we have free healthcare.\n\nAs a US citizen, I think you get the better end of this trade-off.",
      "$900 in Ukraine, the cheapest I managed to find... Prices here are insane and always was",
      "Not sure why this is getting downvoted. AMD usually gets good RT performance in games with less robust RT implementations. Dirt had good RT performance but in that game RT is just shadows and you have to look with a magjifying glass to see it.",
      "Paid $680 for my 6900XT and I thought that was a bargain!",
      "at only rasterization.  The 6950xt also uses a lot more power.  This can be an issue if you are just upgrading a gpu. Its what made me choose a 7900xt over the 6950. I have a 650w sfx psu and was worried about the spikes that the 6950 has so instead of spending the money on a psu i used it to get a little more performance.  \n\nOf course at current prices, i could have saved like $50 even with a new psu."
    ]
  },
  {
    "brand": "amd",
    "generation": "6000",
    "tier": "top",
    "matched_keywords": [
      "6900"
    ],
    "title": "Finally able to get a 6900 xt to go with the 5600x now that prices are down. Build complete. Black and silver all the way.",
    "selftext": "",
    "comments": [
      "Upvote for XFX 6900xt",
      "Nice.  After my first GPU, which was a Voodoo 2, I've had an unbroken run of nvidia cards.  The last was a 1080ti scored at a bargain price when the 3000s were announced.  But now, knowing the truth about that company, I want AMD to be my next GPU.  Please AMD, it's your best chance in your history to carpe frikkin diem.",
      "Looks clean. Enjoy!",
      "One of us ! One of us !",
      "Hey there bought it off Amazon for 729+tax. Can be found for cheaper off places like Newegg or micro center though. Check r/buildapcsales for deals as well.\n\nEdit: fixed subreddit lol",
      "Nvidia RTX 4000 GPUs are a scam and RDNA3 will be faster anyway",
      "They‚Äôre charging $900 for a rebadged RTX 4070",
      "Team red all the way",
      "Absolute monster of a card",
      "Oh most definitely will",
      "I can't even imagine how much of an upgrade that is. Can the GT 710 even play games?",
      "What is there to know?",
      "Lowest I‚Äôve seen it is $699 so that‚Äôs still really good. Congrats!",
      "Wow... I assume that's supposed to be the cheapest (FE). AIB's models will be more expensive... No way.",
      "Yeah, it's the first card I have that makes my NZXT Phantom 630 look ATX-sized lol\nIt matches that in power though, I have yet to find a game I struggle to run in 1440p with everything maxed out.",
      "Scam in what way?",
      "It‚Äôs refillable ü§∑‚Äç‚ôÄÔ∏è. Just preferences I guess",
      "There were murmurs over the years about a cringey, misogynistic culture there.  For example the geforce experience (GFE) was apparently a play on the girl friend experience, referring to a type of prostitution.  But until youtube became a platform for properly independent journalism they were just murmurs.  It's become clear (to me at least) in the last 5 ish years that nvidia are smiling, arrogant bullies with a toxic culture towards their customers.  The EVGA situation seems consistent with that.",
      "Most definitely do not check from /r/buildup/",
      "Oh, so 5% tax or wholly exempt. It must be nice."
    ]
  },
  {
    "brand": "amd",
    "generation": "6000",
    "tier": "top",
    "matched_keywords": [
      "6900xt"
    ],
    "title": "I'm very satisfied with how my build ended up-- 5900X + 6900XT",
    "selftext": "",
    "comments": [
      "No RGB, just R",
      "Pretty sweet. Love the blacked out no RGB look. Happy gaming",
      "I‚Äôve sold all of my rgb after seeing this.",
      "Lol when I do have lights, I prefer them to be a solid color. So I am indeed a fan of this blacked out, solid color aesthetic.",
      "I always love seeing those chromax covers on the d15. You should consider sleeved cables to match the rest of the build!",
      "Solid color is the way to go imo",
      "tried kind of everything but a chop stick works best. definitely wouldnt recommend a screwdriver like my dumb ass thought",
      "*giggles* 69",
      "Brother!",
      "W\n\n\nJoin the gang of aesthetic simplicity and reduce your electricity bill",
      "Looking good! :)",
      "bequiet 500DX",
      "eh definitely not MSRP, although i dont even know what would be the correct pricing of the \"Ultimate\" edition Red Devil, i bought it since it was the only one in stock. i spent at the time around 1400 euros",
      "Solid color that is BARELY on. So dim that you think it's painted on.",
      "R",
      ":) ive been in team red all my life, my first build was a phenom II X4 paired with an HD 7870",
      "Ok thanks I'm looking to buy and everything is so overpriced. Great looking build!",
      "I simply added two 140mm fans, one in the front and one on top, as the case already comes equipped with three fans.\nI chose that case because it fits on my desk, i found later while working on it that it is very well engineered and everything would fit neatly. the RAM modules stand at 39mm i could lower the fan further but id be touching them and i wanted to avoid that",
      "Snug as a bug in a rug",
      "Eh depends on the lights. Some \"painted-on\" looks sometimes look way worse than others. Depends on the components.\n\nStill though, usually it's nice at 25 to 50% brightness (unless you have tinted glass, which would be best at 75 to 100%)."
    ]
  },
  {
    "brand": "amd",
    "generation": "6000",
    "tier": "top",
    "matched_keywords": [
      "6950xt"
    ],
    "title": "ryzen 9 5900x, sapphire 6950xt",
    "selftext": "",
    "comments": [
      "onlyfans",
      "if you added a windmill to the center of the case it could also be self sufficient",
      "You need more fans, until there is no air.",
      "Do I count 16 fans? There has got to be some diminishing returns on those fans, right?\n\nYou can't even see the RGB on the fans top of the rad",
      "At this point, I kinda wanna spam their subreddit with posts like this.",
      "19, if you count the gpu fans.",
      "Could you add a few more fans please?",
      "Needs more fans",
      "Looks great. That card has an amazing design thats different from the rest.",
      "I setup a push pull on my AIO rad. Maybe a 1-2 degree difference. So it‚Äôs negligible. \n\nSince temps weren‚Äôt any worse, I kept it cause I liked being able to see my fan LEDs on both sides. \n\nMy biggest temp difference came from moving the rad from the top to the front. \n\nRAM temps also dipped fairly significantly when I went front mount as well.",
      "This Pc might be running at 90 ¬∞C and still look like it‚Äôs cold AF",
      "Typically not much difference when doubling up fans from what I have seen.  At least on CPU.  I honestly have never seen a push/pull on a rad...",
      "Didn't that happen when they said they would ban porn from the platform?",
      "Where's the power supply?",
      "I'm not quite sure what the fans on the motherboard panel are supposed to do. What air they pushing to / pulling from. Are they put there just for the beauty of it? Are there ventilation holes behind the back panel?",
      "Looks good\n\nGot a question: looking at the topfans, Is it necessary to do Fan / cpu cooler / Fan or is it possible to do only Cpu cooler / fan?",
      "I'm not the biggest fan of lit cases, but this setup looks awesome! Something about the light gray/blue hues just works.",
      "If you look closely, you can see ventilation holes behind them. So technically they're pulling air into the case.",
      "Don‚Äôt judge and don‚Äôt be a gatekeeper.",
      "Gorgeous machine, wow"
    ]
  },
  {
    "brand": "amd",
    "generation": "6000",
    "tier": "top",
    "matched_keywords": [
      "6950xt"
    ],
    "title": "White full AMD build complete! 5800x3D + Nitro Pure+ 6950XT",
    "selftext": "",
    "comments": [
      "Idk how but you managed to make an ugly all white build. \n\nnot trying to be mean.",
      "That gpu is richonkilous",
      "I think it needs more fans.",
      "Probably just poor lighting in the picture",
      "At what point do you have a computer attached to your GPU instead?",
      "imo it's not the lighting but the different shades of white & the lack of a 2nd tone. The CPU cooler being the most obvious of them all when it comes to the shade, but otherwise it just looks boring.\n\nI'm pretty sure darker lighting in the room and non-white LEDs should pretty much obfuscate it though since it's going to reflect a lot of it, but just lighting in the room wouldn't fix it I don't think",
      "What cpu Fan is that?",
      "Deepcool ak620 I believe",
      "Given that the motherboard and GPU have a bit of black the fans probably would look more uniform with black fins and white frame.\n\nI think this thing would look better overall in person than in photos anyway.\n\nIt's a very clean build though. Tight cable management and everything looks like a collection of organized little boxes.",
      "This combo rips through any game I throw at it! With PBO tuner 2 and a slight OC on the 6950XT it is running like a stable and cool. \n\nPC components: \n\nCPU: Ryzen 7 5800x3D \n\nGPU: Sapphire Nitro Pure+ 6950XT \n\nMB: MSI X570S Tomahawk \n\nRAM: TFORCE XTREEM 3600 CL14 \n\nCPU COOLER: DeepCool Ak620 white \n\nCase fans: 7X Corsair AF140 Elite \n\nCase: Lian Li Air Mini - White",
      "First things I thought of when seeing this. Is a dark filled freezer with a broken light or a rubber crazy room. It's has bad lighting in the picture",
      "@u.ruined.the.joke.stupid",
      "I have the same case and same fan layout. Good choice, too many people put two top exhausts and that causes the one on the front of the case to suck up all the cold air and eject it before the CPU can actually be cooled\n\nI recommend putting some sort of small wooden blocks underneath your case feet to get more vertical space for the bottom intake. After I did that, my temperatures dropped decently because the fans weren't choked anymore",
      "All that effort to make it all white and to be honest it doesn‚Äôt look very nice at all.",
      "Nice build! But just a heads up, does vertical PCI-E power connectors can be a [fire hazard!](https://linustechtips.com/uploads/monthly_2020_12/IMG_20201227_110316.thumb.jpg.2fc97993a181ba8935a73c0f81a16da4.jpg)\n\nMore photos here:\nhttps://linustechtips.com/topic/1287646-psa-dont-buy-aliexpress-pci-adapters/",
      "I agree",
      "Sick",
      "Or perhaps Only Fans?",
      "GPU comes with a support bracket, but doesn't look like op installed it.",
      "What"
    ]
  },
  {
    "brand": "amd",
    "generation": "6000",
    "tier": "top",
    "matched_keywords": [
      "6950xt"
    ],
    "title": "AMD Radeon RX 6950XT drops to 599 USD, now at same price as RTX 4070 - VideoCardz.com",
    "selftext": "",
    "comments": [
      "only in US probably",
      "In Spain you can buy an 6950 XT new for 649‚Ç¨ which is 596 freedom units. Not bad.",
      "South East Asia: Best I can do is $1200",
      ">Peoples want AMD to be competitive so that Nvidia drop price‚Ä¶ to buy Nvidia\n\nfacts, even on reddit you so so many people cry about nvidia's pricing while they have flair with an RTX 3000 or RTX 4000 card. Like bruh.",
      "But why? \n\n4070 will sell more than the near 2 years worth of the 6950XT on shelves. They know it. AMD‚Äôs RDNA 2 **entire** lineup is a blip on market share. Low sales on Nvidia is still more than AMD. 4070 Ti, 4080 and 4090 are appearing in the steam hardware survey while none of RDNA 3 are. Those low sale Ada cards are still (last time I checked) up to 70% of RDNA 2‚Äôs entire lineup.\n\nPeoples want AMD to be competitive so that Nvidia drop price‚Ä¶ to buy Nvidia. This is inherently why we have these prices. Don‚Äôt buy these cards if you want to send a message.",
      "Only problem it's 400w+ card. Compared to ~200w. That shit adds up depending where you live, excess heat can also be annoying to deal with.",
      "650‚Ç¨ includes sales tax of 21% = 537‚Ç¨ before tax = $596 before tax",
      "Shows you how much profit they make on these cards . At 599$ they still profit",
      "VAT is included in the price...",
      "Your turn Nvidia..",
      "‚Ç¨649 for the Black Merc at Mindfactory.\n\nThats exactly $599+VAT.",
      "Exactly. I want them to sell them at  -50% loss.",
      "We have to pay insane amounts of import tax",
      "Amd cpus being more efficient than intel = Woahh amazingggg. Nvidia GPUs being more efficient = no one cares about power consumption",
      "It's a little deceptive, and not that straightforward. The material costs are probably fair bit lower, but you also have to account for the upfront R&D costs. They likely amortize this cost over a  number of months post-release - which leads to higher launch MSRP.\n\nOnce the R&D costs are paid off, you can reduce the sell price as their total costs have dropped despite material costs remaining unchanged.",
      "Meanwhile in my EU country prices for rx 6950xt still start from $700 up to $800.",
      "The 6800xt already competes with the 4070. This wont just compare, it will beat the 4070",
      "True, I have never seen such things that have bad pricing like AMD products in SEA, an used R5 3600 is around 90$, with 90$ I can even buy new 5600 on taobao.",
      "Chollometro team, right? Waiting for mine to arrive!!",
      "For the majority of customers, at least gamers, the drivers and value adds are good enough on AMD GPUs.\n\nNvidia's big market share is mainly due to brand recognition. The fact that some developers basically only work with Nvidia GPUs (hello CD Project Red) contributes to that.\n\nFor the informed user, AMD cards are amazing value. But the majority of users don't frequent communities as Reddit. They just buy the brand they know."
    ]
  },
  {
    "brand": "amd",
    "generation": "6000",
    "tier": "top",
    "matched_keywords": [
      "6900xt"
    ],
    "title": "5900x, Sapphire Toxic 6900xt Extreme",
    "selftext": "",
    "comments": [
      "The incandescent bulb light color looks really neat",
      "Deus Ex vibes.",
      "OK, wow. First time seeing this AIO, and it is just beautiful. So is the GPU. \n\n10/10 build sir, well done!",
      "What fans are you using? I love the color you chose",
      "Lian Li AL120s",
      "Move aside RGB, we using BG now, black and gold",
      "In fact this is the first Toxic they made in years.  AMD finally has a gpu worthy of that brand.",
      "Thank you! Yeah this aio looks and performs excellently I'm surprised there aren't more reviews on it",
      "Could you provide me with the Hex for that color?",
      "It's the IN WIN BR36 360mm AIO with UMA Cooling Design https://www.amazon.com/dp/B096CBMD57/ref=cm_sw_r_apan_glt_fabc_9GBYEV0DKE25C788JRD9\n\nAnd the gpu has its own\n360 rad on the top",
      "Interesting question, found this page \n\n&#x200B;\n\n[http://planetpixelemporium.com/tutorialpages/light.html](http://planetpixelemporium.com/tutorialpages/light.html)",
      "Yes and it runs like a dream.",
      "God, the Toxic looks soooooooo amazing.",
      "Second this!",
      "Where did you hide the psu?",
      "What is that aio? Does it have dual 360 rads?",
      "OP reposted the pic, the previous post he said it was 255, 80, 0 in iCue",
      "Sapphire has been good with me when I had to RMA 2 times. First time, was quick and painless. I sent mine back and received one back. Second time, even quicker because I didn‚Äôt have to send my GPU back. They just sent me a new one. \nTurns out my GPU wasn‚Äôt the problem, so I had 2 good working 580s and I sold one to a friend.",
      "Makes sense. It looked like all four tubes were connected to the cpu pump/block. Nice aestethics in this build. I especially enjoy the coppery tint.",
      "No gfx card will ever be worth 2k"
    ]
  },
  {
    "brand": "amd",
    "generation": "6000",
    "tier": "top",
    "matched_keywords": [
      "6900xt"
    ],
    "title": "Yesterday one person bought 79 x 6700XT and 14 x 6900XT during the EU AMD drop (no joke, with proof).",
    "selftext": "",
    "comments": [
      "I think that's the Dutch browser extension\n\nIt shares the unique queue ID between the subscribers, I saw that in many forums in the web since (at least) 3 months from now so I think AMD/digital river is well aware of that\n\nThat's the new era of scalping: scalp BEFORE the purchase",
      "That was patched months ago nowadays it's way more complex, the guy has thousands of instances open and the more people solve captchas the more different queue IDs are made, his script also has a priority list where people who haven't had a chance as much get picked first.\n\nI'm glad for his script as months of trying manually didn't lead to anything mostly because cards were gone in 2 minutes as the bots shared the same no queue ID but it felt scummy and most of the people in the forums where they discuss this are the scum of the earth\n\nFor those unaware one guy didn't farm 70 cards, those are divided by the people using a dudes paid script which has about a thousand users by now",
      "He sells subscriptions which gives people a position on his waitlist. You need to have PayPal to do this. Yesterday 93 PayPals bought a GPU through this system in 10 seconds making it nearly impossible for others to buy. Earlier this bot was succesful, but not this succesful now it's probably has become the only option if you wan't to buy a GPU from AMD in the EU.\n\nI say \"PayPals\" because there's a lot of people who sign up for this service with multiple PayPal accounts.",
      "Whoever thinks the same thing won't happen when the new gen is out, is out of his mind lol.\n\nThis is the future of pc gaming. Get used to it.",
      ">This is the future of pc gaming. Get used to it.\n\nOnly if people keep paying way over msrp for the cards. If the scalpers can't sell their product, they will stop buying it. Problem solved.",
      "So what you're telling me is that this guy has a better queue (at least from a consumer perspective) than AMD does?",
      "A year ago i subscribed by EVGA for a 3080 at msrp. Still waiting, and shops have plenty evga in stock. The reality is that manufactures want to sell fast at the highest possible price‚Ä¶ thats a part of the problem too",
      "Wouldn't he need a different address for each card?",
      "Except this mentality is part of why prices are still where they are, and if people continue paying the prices that's where it'll stay\n\nThe victims aren't the people paying scalped/inflated pricing (They can afford it) and are only paying the price due to their own impatience\n\nThe victims are those who can't afford the inflated prices and are priced out of PC gaming entirely",
      "people here can't get cards because of other bots and this kind of things\n\nDR must find a way to avoid that\n\nmaybe an early email subscription with lottery will be better than thousand of millions of people and bots going to [amd.com](https://amd.com) only in those 3 minutes\n\nif things will not change we will never be able to buy upcoming gpu",
      "Yeah definitely.\n\nSounds like his queue is super convenient and hassle free. Plus I think it's brilliant that customers who weren't able to buy a card the week before get increasingly higher priority the next round.",
      "This was always going to happen\n\nPeople have been paying scalped prices for years now, that is why scalpers are still here, they're opportunists, and they've been given this opportunity (They don't do it just because, they want to make money)\n\nAnyone who has bought from a scalper cannot be angry about this, because you helped create this situation in your own small way, And tbh it's your fault if you payed an inflated price because you chose to do it out of impatience \n\nThe actual victims are those who can't afford the inflated prices and cant build a PC now because they've been priced out",
      "this is what happens when AMD picks the worst unreliable partner to run theirs shop ...  \nfrom perspective of customer who attempted to buy anything via AMD shop in past 12 + months  \ni would never ever buy AMD product again ... so bad the experience was and is ...",
      "EVGA still has their queue and people have been waiting since launch to see their name pop up still",
      "It‚Äôs trivial to register a bunch of emails so scalpers still win in that case.\n\nIt‚Äôs not an easy problem to solve and no idea you came up with in five minutes is going to work, otherwise it would have been solved by now. It‚Äôs not for lack of trying, it‚Äôs really hard to do without some kind of external reputational signal. For steam, that signal can be your spending history and wallet, AMD doesn‚Äôt have that sort of data for you.\n\n(The one thing AMD/NVIDIA have access to that could legitimately be useful is driver telemetry data tied to your account but nobody wants to talk about that.)\n\nBut seriously, things that are not actually good ways to ensure one-per-person:\n\n* emails\n* credit card numbers\n* shipping addresses\n* billing addresses\n* names\n* phone numbers\n* ip addresses\n\nTime and again every baby redditor thinks they‚Äôve solved the scalper problem by ‚Äújust limiting one per credit card‚Äù or ‚Äúone per billing address‚Äù and they don‚Äôt realize the sneaker market tried that like 15 years ago and scalpers trivially worked around it and found a solution. This is big business, the people who sell the tools make hundreds of grand per year enabling scalping, they have worked around ideas you haven‚Äôt even come up with yet.",
      "Its been 2 years and everything still out of stock,i don't blame people for paying way over MSRP at this point",
      "Friend of mine got his 3080 yesterday from EVGA email listing, almost 9 months after he signed up for it.",
      "Definitely? How did you come to this conclusion because it definitely is not. He just doesn't have to deal with what AMD is dealing with. It does not solve anything: It's first come first serve and thats being botted as well. Of course once you're subscribed to his services you have a very convenient experience but that is not what you need to compare to the AMD queue.\n\nHe only let's about 50 people buy a subscription once every while (allthough he has strongly oversold because of technical issues). Combine that with a high successrate and yes, customers will be satisfied.\n\nIf this wasn't exclusive it would be the same mess AMD is dealing with now. The only thing he is doing is moving the issue from the AMD queue-it queue to the people paying him for a subscripion, he actually started using some \"bot protection\" himself because people (scalpers) want a subscription.",
      "I've been on there since later 2020. The cards I signed up for are discontinued so I guess I'm not in any sort of real queue anymore.",
      "This stuff is no joke - my brother-in-law quit his IT job to specifically do this with a few guys. Besides a combination of bots, they also take advantages of mistakes in services like shippd, and of course most store pick up employees are push-overs. They basically travel around FL, GA, SC, and NC collecting cards and then dropping them right outside the port of jacksonville to some russians in a container truck. I think it's ridiculously messed up and there is a special place in hell for him... but kind of fascinating."
    ]
  },
  {
    "brand": "amd",
    "generation": "6000",
    "tier": "top",
    "matched_keywords": [
      "6900xt"
    ],
    "title": "Disabling Multi-Plane Overlay (MPO) fixed all desktop flickering/stuttering on my 6900XT",
    "selftext": "Been having flickering in varying amounts since driver version 22.2.2. The latest 22.10.3 improved the situation but it still came up from time to time (the Disney+ windows app was *especially* bad). Saw a mention of this being a fix elsewhere and tried it myself and suddenly.. everything is perfect.\n\nHere is how to disable it, courtesy of nvidia, where it *also* caused some flickering and stuttering issues: https://nvidia.custhelp.com/app/answers/detail/a_id/5157/~/after-updating-to-nvidia-game-ready-driver-461.09-or-newer%2C-some-desktop-apps\n\nThey provide a .reg file to make the change for you, but if you'd rather do it by hand the key is `HKEY_LOCAL_MACHINE\\SOFTWARE\\Microsoft\\Windows\\Dwm`, create DWORD `OverlayTestMode` with value `00000005`.\n\nDisabling this *may* break some of the Windows \"fullscreen optimization\" stuff, but frankly that's always been kind of a nightmare anyway.",
    "comments": [
      "Thanks mods for not deleting this and threating this as tech support, this should really be stickied honestly until AMD and Microsoft fix this, probably more a Microsoft issue seeing windows 11 22h2 updates just got paused, altho if had blackscreens that disabling MPO fixes on 21h2 as well so its much worse then being reported probably by Microsoft.",
      "For anyone with a 6900xt and a 240hz monitor that would randomly get gray screens - this fix appears to solve that as well. I usually would get a gray screen within 45 minutes, but haven't for about 4 days now.",
      "On 6900 XT. This solved the driver timeout crash when I use Chrome as well. Thank you.",
      "This has reduced my flickering by like 95%.",
      "It's not from nVidia, it's a fix we used on nVidia GPUs too for a while üòÇ crazy if only Microsoft / Intel /nVidia / AMD all corroborated more on the software side of things, we might get much more out of all our hardware. But why do that, when they can sell us more of course.",
      "Maybe it‚Äôs time to switch to Firefox instead?",
      "Almost as if MS should allow us to disable desktop compositing fully.",
      "Three days so far on 22.10.3 from 22.5.1 after disabling MPO, I've had no driver timeouts or black screens no matter how much I threw at it. This is the longest I've gone error-free on anything newer than 22.5.1, this thread needs to be stickered.\n\nHALLELUJAH!",
      "That's actually been the final nail in the coffin for me when it comes to going with Firefox. That MPO issue drove me nuts as I thought that it was just AMD drivers being AMD drivers.\n\nTurning off hardware acceleration is not a workable band-aid at that. I was pulling my hair out from audio cutout when I watch youtube after doing that. I can now safely conclude that the whole thing about AMD driver sucks isn't really an excuse anymore.",
      ">while others, again using the same GPU and drivers etc\n\nThat doesn't even come close to covering all the possible differences.\n\nSome people for example fixed black screen issues by turning off their RAM overclock.   Just because an app crashes for some, and not others, could be hardware, but it could also be all sorts of other software.  MSI Afterburner for example was known to cause crashes for some.  Windows has bugs and features that are only active for some in some situations (e.g. only with multi monitor with different refresh rates but only if all support 10 bit color).\n\nSo \"one friend with drivers ABC and card X has the issue but the other does not\" is nowhere close to proving that it is bad hardware.",
      "the fact that the nvidia article is over a year old while AMD hasn't even been able to discover this issue for 10 months is like... bruh",
      "Just a warning, this is NOT a fix for everyone. I tried the MPO edit and it gave me intermittent screen corruption across all 3 screens. Like someone was fiddling with my display port cables, but it was across all 3 screens at the same time for 1 to 2 frames, then would dissapear.\n\nI was never getting driver timeouts, just the black screen flickering and video issues in other windows in chrome, what fixed me was using the #angle workaround in chrome.\n\nSince then, for me, its been perfect on 22.9.1, no issues AT ALL. Like zero. I have 2 sets of virtual desktops, one for work and one for personal stuff and games, hell i even accidently had hurtworld open in the background and then ran minecraft, still nothing.",
      "i read that in some other forums the other day.\nwhat EXACTLY is multi-plane overlay used for anyway? does someone know? what is the USE CASE",
      "I'm not a graphics developer, so this could all be way off, but my understanding is that it allows the creation of arbitrary render targets (planes) which can be displayed in arbitrary arrangements by overlaying them in the final display render. The advantage is that these new \"planes\" can be treated as exclusive fullscreen by an application without actually using exclusive fullscreen display modes.",
      "I found some use cases described here: [https://www.reddit.com/r/nvidia/comments/qffxcz/mpo\\_multiplaneoverlays\\_are\\_amazing\\_you\\_can\\_play/](https://www.reddit.com/r/nvidia/comments/qffxcz/mpo_multiplaneoverlays_are_amazing_you_can_play/)\n\nIncluding opinions from \"MPOs are amazing\" to \"MPO is pure garbage\".",
      "Well good thing we're talking about an issue affecting all Chromium things that use hardware acceleration then.",
      "It's 100% M$ fault.\n\nI haven't run in to this on my 6800 XT is it unique to 6900 XT?",
      "As if it was this simple. From Nvidia of all places, couldn't write it. Thanks OP",
      "I can confirm this. 6900XT. Dual Samsung G7 + another 60Hz screen. Would get gray screens about every 20 minutes because I alt-tab a lot.\n\nTried this fix and to make things worse I enabled hardware acceleration in both firefox and chrome. Haven't had a single issue for 4 days now. ZERO gray screens!",
      "What about Zoom, Teams, Skype, vscode, Steam, Epic Games Launcher, GOG, Discord?"
    ]
  },
  {
    "brand": "amd",
    "generation": "6000",
    "tier": "top",
    "matched_keywords": [
      "6900xt"
    ],
    "title": "went a bit over board and now have the 6900xt paired with the 5950x.",
    "selftext": "",
    "comments": [
      "Overboard would be getting a vertical GPU mount.",
      "That's one way to suffocate a high end GPU.",
      "what's the rgb strip under the graphics card? built-in to the case or something else?",
      "If it could fit I would lol.",
      "Decent config for browsing the Internet.",
      "I had a vertical mount on my Strix LC 6800 XT but after upgrading from a B450/3700X to a B550/5900X I had to get rid of the vertical mount because it was pcie 3.0. They now have 4.0 extension cables and been meaning to get one. The Strix LC was made to be mounted vertically imo.",
      "Yea I think that's the move. Gonna return the 5950x for the 5800x to get $400 back.",
      "It would be a bracket so the fan won't be all up on the glass. But either way it's not happening.",
      "Great question! It's cooler master's rgb anti sag bracket.",
      "The 5950x was certainly an impulse buy. Still in the return window and debating if I should get the 5800x since my rig is primarily for gaming. I do on occasion edit large amounts of photos with lightroom and photoshop when I shoot weddings a few times a year. Maybe the 5900x is the sweet spot. That's why it's still kinda hard to get.",
      "Least powerful reddit PC",
      "Light room and photoshop don't really take advantage of the 5950X in the same way that video editing or music production would, so you might not even find a substantial difference between the 5800X and the 5950X in your workflow.",
      "Looks good man. I'm finding myself wanting to upgrade my 3700x to a 5900x but I think I'll wait for the XT refresh.",
      "Overboard would be going Threadripper pro on wrx80 or trx40. 16 cores is for peasants.",
      "Absolutley magnificent!",
      "It's no match for chrome though.",
      "thats a funny mesh front",
      "Thank you! It helps with airflow. Of course now they offer the 510 air version.",
      "It almost keeps up with roblox.",
      "I'm sure if I kept the glass front my rig would blow up! Lol! During my usual games both CPU and GPU are very low 70s average."
    ]
  },
  {
    "brand": "amd",
    "generation": "6000",
    "tier": "top",
    "matched_keywords": [
      "6900"
    ],
    "title": "All AMD ITX build, Ryzen 9 5900X + Radeon RX 6900 XT OC Formula",
    "selftext": "",
    "comments": [
      "This makes me want to build a mini. Good job üëç",
      "/r/sffpc \n\nHere is some more influence to get you to spend way to much money on a PC.",
      "Is that an eInk display? Looks like no backlight, but very clean.",
      "Correct! It‚Äôs a xiaomi e-ink thermometer",
      "Parts:\n\nCPU: AMD Ryzen 9 5900X\n\nCooler: Thermalright Peerless Assassin 120 White ARGB\n\nMobo: Gigabyte B550i v1.1\n\nMemory: Gskill DDR4 Samsung D-Die 16G DR.\n\nGPU: Asrock Radeon RX 6900 XT OC Formula\n\nCase: Sama IM 02 white tempered glass.\n\nPSU: Corsair SF750\n\nFan: 4x Thermalright ARGB White.\n\n&#x200B;\n\nWorks pretty well together",
      "I went on that sub a few times, ended up buying a meshlicious and built another PC.\n\nSlippery slope lol",
      "whats that inside clock part called and where can i get something like that",
      "is that ram stick slightly bent?",
      "It's good, I tested with power meter on desk, full blown overclock of this 6900 XT under 3dmark Time spy is 620w.\n\nBeware its AC outlet reading, so the actual psu DC load is about 90% of it, thus 550w max. SF750 is build with around 950w transient power burst thus no problem to handle occasional spike.\n\nGiven games usually less demanding than Time Spy, and I'm under volt it with just 450w tops.\n\nmanufacture just want your psu not the last straw to cause problem because you never knew if the people buying your card gonna use on a Gigabyte garbage tier smoking one or top tier 80+ Platinum one.",
      ">degrees freedom\n\nIt use mijia home app through bluetooth control, app can change F or C and read historical charts of temp. you can check this video I was watching before purchase: https://www.youtube.com/watch?v=1WoIXFl3pQk",
      "Kinda looks like you built a PC and had no money left for a monitor lol",
      "So it is possible to fit a 120mm CPU cooler in an ITX case.",
      "It‚Äôs a Xiaomi Mijia Thermometer E-ink display I bought from aliexpress",
      "It's actually not an NR200. It's a SAMA IM02 (at least in the US, it's sold under different brands in different regions). I just built my cousin a PC in it yesterday. Honestly think it is the best gateway to SFF PCs, though many would say it doesn't count since it is 21L.\n\nThe case is relatively cheap (I got it for $60 on Newegg) and supports mATX motherboards and ATX PSUs, so you don't have to pay the SFF tax and can reuse parts from your previous build.\n\nThe one grip I have with it is there is effectively zero space behind the motherboard tray.",
      "Stunning!",
      "I believe it's the impression given by the LED strip's shape of the ram sticks. Looking below the base seems to be in the clear.",
      "that is a super beautiful ITX set up. mine doesnt look nearly as nice xD",
      "It's perfect. The OC Formula is such a sick card, and looks like a perfect fit!",
      "Is the Sf750 enough to power the 6900xt and 5900x?\n\nI'm thinking of moving my 6900xt red devil ultimate to my SFF build but can't find a suitable PSU since powercolor suggests >900w lol.",
      "That's very very broad but for this particular case (nr200) yes some 120mm air coolers do fit like this one, but not all."
    ]
  },
  {
    "brand": "amd",
    "generation": "6000",
    "tier": "top",
    "matched_keywords": [
      "6900xt"
    ],
    "title": "5800x / 6900xt Liquid Cooled (AIO) Strix AMD Build *Red Glory*",
    "selftext": "",
    "comments": [
      "and they say money can't buy you happiness...",
      "Whoever said that must not have known anyone with an expensive hobby",
      "You ever see a sad person on a jet ski?  I rest my case...",
      "Ryzen 7 5800x, Strix B550-f Gaming Wifi, Strix 6900xt Liquid Cooled, Strix 360mm AIO CPU Cooler, Tforce 3600 CL18 (4x8GB), Cooler Master Cosmos C700P Black, Samsung 980 500 GB M.2 / Samsung 970 Evo 1TB M.2, ROG Thor 850w 80+ Platinum PS",
      "Looks hot",
      "that one guy from tiger king.",
      "I think they make nice hardware but I have no specific brand loyalty lol. My original Corsair CPU cooler was broken out of the box, RMA was going to take weeks and due to Covid I was unable to go to a store and get another one. The Strix one was available on Amazon. Originally wanted a 3080 but no luck there, this 6900xt fell into my lap through a friend and it was MSRP so I just grabbed it. The power supply which I originally purchased was a corsair 750w which had to be returned due to it not meeting the minimum requirements for the GPU. Kind of a shame the Thor power supply is hidden behind that shroud but oh well lol.",
      "You must really like Asus Rog products, but apart from that, looks real nice. That vertical gpu, especially with that specific model, just brings the build together nicely.",
      "*OUR* Glory",
      "Lol thanks. Kind of annoying the picture makes it look orange but it's a much darker red glow in person. And the tempered glass side is slightly tinted making it a bit darker.",
      "Thanks! The funny thing is this was not the original plan but due to unavailability of parts and a little luck this is what I was able to get. Took me 5 months to collect these parts without having to buy anything from scalpers.",
      "It was right around $5000 Canadian dollars. I'd have to ask my wife for the exact amount but she left. Lol jk but yeah I went over budget.",
      "$1699.99 in Canada",
      "Perhaps that's why I'm never happy with my PC.\n\n...or maybe it's just my monitor not being very friendly to my eyes",
      "I watched the Jayz video and gamers nexus about rad orientation and while i agree the hoses down setup is clearly the better option, as long as the rad is higher than your pump in a hose up situation it shouldn't be an issue. I was wondering how long it would take for someone to comment on that lol. Thanks!",
      "Lmfao, you're not wrong",
      "I bought an HDMI adapter to use my old VGA LCD monitor instead of the laptop screen. Best thing I've made so far, despite the lower resolution and color accuracy, the bigger size and overall clean look of my desk made the change worth it.",
      "Monitors are pretty inexpensive.  No sense in settling for mediocre when it is arguably the most important part of your rig.",
      "well I admire your dedication to not paying scalpers, and also patience",
      "That's a really nice looking rig, clearly thought out"
    ]
  },
  {
    "brand": "amd",
    "generation": "6000",
    "tier": "top",
    "matched_keywords": [
      "6900xt"
    ],
    "title": "5950X-Red Devil 6900XT under water",
    "selftext": "",
    "comments": [
      "I'm a simple man, i see a red team build, i hit upvote !",
      "*Darth Sidious Voice* Good! Good!",
      "Bro, you Red Devil you. This is a computer I dream about, enjoy it!",
      "My man, appreciate it!",
      "Very nice my dude! The whole thing is on point, but great move with the clear liquid and the subtlety of the red next to (under?) the mostly black cables is chef‚Äôs kiss for me. I did red/black alternating sections with my 6800xt midnight black / 4000D blacked out build and I often think about going for all black sleeves. Great!",
      "Let the coolant flow through you",
      "Thank you. And nice job on getting that Midnight 6800XT, probably the best looking GPU from AMD, ever. I know lots of people think red and black builds are played out, but just can't get away from going red. And funnily enough I've contemplated going with the red and black cables often.",
      "Your RGB has made you powerful.",
      "Thanks! And the liquid temp stays under 30C, so the air isn't hot or anything.",
      "Clean af bro, i hope it serves you long and well brother ‚ù§Ô∏è‚ú®",
      "Thanks, and I suppose I should have done that from the start.\n\nSpecs: 5950X@4.9GHz CCD1, 4.7GHz CCD2  \nRed Devil 6900XT@2650/2750MHz, 2150MHz w/Fast timings  \nROG Crosshair VIII Forumla  \n32GB Trident Z 3800MHz CL14  \nHX1000i PSU w/CableMod Pro Carbons  \nThermaltake View 51 case w/ML120 Pro  \nEK Quantum Magnitude Acetal AM4 block   \nAlphacool Eisblock Red Devil block  \nEK Kinetic D5 Pump/Res  \n360x40mm top and bottom rads  \n360x55mm side mounted rad",
      "I cant get my pc to look good with rgb. Any tips?",
      "Kind words my man, truly appreciate them. The plan is to keep rocking this one for a long while.",
      "I usually keep my hardware awhile. Still have a 3950X/1080Ti office build, and my daughters rocking my old hardware as well.   \n\n\nSpecs: 5950X@4.9GHz CCD1, 4.7GHz CCD2  \nRed Devil 6900XT@2650/2750MHz, 2150MHz w/Fast timings  \nROG Crosshair VIII Forumla  \n32GB Trident Z 3800MHz CL14  \nHX1000i PSU w/CableMod Pro Carbons  \nThermaltake View 51 case w/ML120 Pro  \nEK Quantum Magnitude Acetal AM4 block   \nAlphacool Eisblock Red Devil block  \nEK Kinetic D5 Pump/Res  \n360x40mm top and bottom rads  \n360x55mm side mounted rad",
      "Clean AF.",
      "Looks great !\n\n...but .. aren't you blowing hot air off of the bottom RAD back into your setup?\n\nPotentially causing issues if RAM and VRM's get too warm? ..and/or negating some of your overall cooling ..?",
      "*Darth Sidious Voice* A powerful PC it shall become! I dub thee, Darth Peecious! Lord Peecious... Rise!!!",
      "I am using an O11 Dynamic XL, and I started naively by having all three rads sending air out, that the case was completely air starved to the point where temperatures would climb to +22C over ambient water temps.  \n\n\nI reversed the side rad fans to blow air in (now my HDDs are actually running lower temps too), and installed 3x Noctua NF-A14s at the front, and everything is fine and dandy.   \n\n\nWhat are your CPU temps in games that use CPU a lot and get high frame rates? The worst offenders for me up to now were Dragon Age Inquisition and Far Cry 5, and I'm at around 79C for the best two cores and in the 40s -60s for the rest of the cores. The 3090 has a big die so it stays at the 48-50C range, and even the hot spot doesn't climb above 60-62C.\n\nWhen AMD moves to 5nm they need to think of something for the tiny really hot spots these CPUs get.",
      "No issues, loop idles in the mid 20s, CPU and GPU idle right around that. Gaming temps the CPU is usually in the 40s-50s and GPU in the mid 30s.",
      "Too poor to up vote this"
    ]
  },
  {
    "brand": "amd",
    "generation": "6000",
    "tier": "top",
    "matched_keywords": [
      "6900xt"
    ],
    "title": "Went to the red side. AMD 5950x and 6900xt",
    "selftext": "",
    "comments": [
      "You my sir are a mad lad. This is like the dream of every AMD fanboy gamer. \n\nAlso a very clean build, not my favorite color scheme but this build still looks amazing!!",
      "this is essentially an upgrade from my first PC build. started with a 3060ti and a 3700x\n\ncurrent specs:\n\nCase: Fractal Design Meshify 2\n\nCPU: AMD Ryzen 9 5950x\n\nGPU: Asrock 6900xt Formula OC\n\nMOBO: Asrock B550 Taichi\n\nRAM: Trident Royal Z 3600 CL16\n\nAIO: Phanteks Glacier One 240mm\n\nStorage:\n\n\\-Seagate Barracuda 2tb HDD\n\n\\-500gb Samsung Evo970 NVME\n\n\\-1TB Samsung Evo970 NVME\n\nSensor Display:\n\nGoverlay 3.5\" display\n\nFans:\n\nInwin Sirius Loop\n\nFractal 140mm case fans\n\nPhanteks 120mm MP fans for AIO\n\nRGB:\n\nPhanteks neon digital rgb strips\n\nPhanteks halos fan frames",
      "Looks Amazing!",
      "appreciate it! \n\nand I know its not for everyone.  Not completely happy with this fully, still trying to find something that I like for an everyday.",
      "What game or new monitor caused you to want to upgrade? Your old system handled everything already.",
      "I don't know. Just the hobby of it I guess.  I guess it's the same feeling as why mod your daily driver car to be faster. I didnt know what my end game was for my pc but I've Def got there.",
      "I upgraded from a 3700x to a 5950x *just because I could* (and I got it for msrp without even trying)\n\nI probably could‚Äôve gotten 10 years out of that 3700x with zero complaints‚Ä¶..",
      "some may say maybe too much...",
      "$2,000 for the cpu and gpu alone, unless OP somehow snagged the 6900xt for MSRP.",
      "thats the same exact boat I'm in and not even mad about it.",
      "inwin sirius loop",
      "You are welcome.\nBut if you are not fully happy with it, I take it happily  lol (joking ofc).\nMaybe the background on the display could have a more fitting design?",
      "Not red. More like neon purple mostly I looked at a lot of blurry neon like RBG.. This seems the most popular.",
      "yeah, I know been messing around with a few other stuff.  Its pretty much what I've settled on for right now. but still tinkering.",
      "How much does this system cost?",
      "What fans do you have? My favourite colour scheme is neon pink blue and purple so i just love it and these fans have really nice colour! Also that LED stripe at the bottom, looks very nice and very clean!",
      "thanks for the info about GOverlay. Never knew something like that existed. That will be a neat add-on to my build :)\n\nNice job on the build BTW",
      "goverlay.com",
      "Fractal meshify 2",
      "Well actually not, but at least it settles down to a certain point. I am wasting more time with configuring it than actually doing work on it lol"
    ]
  },
  {
    "brand": "amd",
    "generation": "6000",
    "tier": "top",
    "matched_keywords": [
      "6900"
    ],
    "title": "6800 XT with 6900 XT/3090 Performance. Higher clocks do not always mean higher scores!",
    "selftext": "",
    "comments": [
      "TUF Asus Gaming Radeon Rx 6800 XT AMD Wattman Settings\n\n* GPU Clock Speed: 2350-2450 MHz\n* GPU Voltage: 1100 mV\n* Memory Timing: Fast\n* Memory Frequency: 2150 MHz\n* Power Limit: 15%\n* Smart Access Memory: Enabled",
      "Try 2120 on the memory. The VRAM automatically loosens timings above 2124 MHz, so you want to stay below that.",
      "6800XT is low key in the shadow of the 3080/3090 tbh. But it's a silent beast! Nice!",
      "vanish worthless wise frightening wide grandfather file point jellyfish spectacular -- mass edited with redact.dev",
      "Man I love my 6800xt but missing out on ray tracing and dlss kills me sometimes",
      "Is the same true with the 6900XT as well, do you know? Or is this just the standard enforced product segmentation in effect again?",
      "Nice, I'll see if I get a boost that way. I also haven't tried lowering the voltage even further, so I think I can get even more performance that way. I'll give this a shot when I get home from work and let you guys know how it goes! Let's see how far we can take this card!",
      "Mine clocked itself aroud 2730 mhz or so sometime.\nAll i did was undervolt... there was some artifacts, limites it to 2675 mhz and never had artifacts after this. Also saw some 327 watts consuption LOL. Now i limited it to 180 fps, consumes about 225 watts average whatever i do lol.",
      "only really in terms of ray tracing and 4k.\n\n&#x200B;\n\nif you're not on those trains, then its blow for blow pretty much and the 6800Xt is slightly ahead.  if you're into ray tracing and 4k, then its an obvious loss.\n\n&#x200B;\n\nnot sure why the 3090 is mentioned, it's not a competing card.",
      "At least it can run raytracing even if it's not amazing at it. If some super crazy RT game comes out there's the option to tweak settings until it's satisfactory. The 5700XT was the true dead end card since it offered great performance per dollar but lacked any future proofing.",
      "Yeah I noticed something funny with my gaming PC when I was tuning it for nicehash. Anything over 2120 on the memory was causing it to lose performance which I thought was weird. Your explanation would explain why",
      "Plenty of people would love to get their hands on a true dead end card given the insane inflated bubble we are in.",
      "All of us don't care about unrealistic benchmark scores either.",
      "Just picked on up a few weeks ago. They're a beast of a card. Ulgraded from a 980ti.",
      "dlss sucks in a lot of games man. 3090 here and i find dlss in cyberpunk unbearable, blurry mess even on quality. Ray tracing also feels like a single graphical setting, you turn it on and have to look for it. Most scenes in cp2077 are identical, but shiny glass is reflective. I painstakingly went back and forth in various areas turning RT on and off‚Ä¶long story short, youre missing very little. Check YT comparisons if you dont believe me\n\n\nIts not world shattering stuff. I firmly believe marketing has planted a seed in peoples heads its world shattering, and it really isnt yet. Amazing what adverts can do tbh, especially for cp2077",
      "It is. I have my 6900xt same settings",
      "The trick is to find settings where the card does not permanently hit the power target limit of 293W. My card's sweet spot is 2560 MHz @ 1030 mV and mentioned memory settings. The power consumption in Time Spy is  around 285W, the card constantly boosts to 2500 and my graphics score is well above 21,000 while my hot spot temp is below 95c (reference card). Since you have an AIB card and a Zen3 CPU, you should get even better results.",
      ">1.1V\n\nThat's a (very slight) undervolt too right? It's nice when you can get so much extra performance without having to worry about heat or voltage whatsoever. I have my (reference) 6800xt running at 1025mV with a cap of 2400mHz, but it generally stays in the 2200-2300 range (for power budget reasons I think).",
      "3090 is also double the price.",
      "It's your Motherfuckin cake day!"
    ]
  },
  {
    "brand": "amd",
    "generation": "6000",
    "tier": "top",
    "matched_keywords": [
      "6950"
    ],
    "title": "My first AMD card, Power Color 6950 XT to replace my old 1080.",
    "selftext": "",
    "comments": [
      "6950 XT makes most sense right now, congrats!",
      "Great looking build and awesome GPU! Just a little advice I would not use pigtail pcie cables with that high end of a GPU that draws a butt load of power. You have a decent PSU but you need to use a dedicated cable for each 8 pin connection and if you dont have that many pcie connections coming from your PSU you need to get a higher rated one that does. At the least you can lose performance (been shown on Jayz2cents and BuildZoid's channels) and at the worst you can damage your GPU and PSU.",
      "At 635‚Ç¨ was the best deal possible right now.",
      "Indeed, had some watercooled ones locally for 599‚Ç¨, was really tempted but kept my 6800 XT.",
      "This. 6950xt owner here it pulls over 400W at times.\nGet rid of that daisy chain ASAP if you can.",
      "I wasn't able to use each individual 8 pin cable because i only have two of them, but i'm gonna order 3 cablemods.",
      "Welcome to the gang. It's a beast",
      "They can pull so much more than that if it‚Äôs a good power supply. Corsair only use 2 for their 600w cable.",
      "With OP's Seasonic PSU, I wouldn't worry at all - it's built for this!\n\nLarger diameter cables and a matching internal design [single rail(!), bigger caps to handle transients, higher rated mosfets, thicker cables] make sure that drawing 300W and more over that daisy-chained cable isn't a problem. \n\nThe \"weak points\" are the connectors and those are also what's rated for those 150W each.\n\nHowever, an 8pin EPS is built the same when it comes to the physical pin design, i.e. thickness of the metal and contact area (only difference: EPS uses 4 12V pins instead of 3), is rated for 336W and regularily pushed higher in servers. Accounting for having one 12V pin less, a PCIe 8pin is still good for at least 252W.\n\nParticularily in OP's case, these two cables with 3 connectors can definitely and comfortably provide enough power for the GPU, AND have some headroom left. In cheaper built and multi-rail PSUs, having more cables is needed, but not here.\n\nI have also verified this with my HX850i by pushing a Vega 56 to 360W ASIC and now with my 6800XT. Performance difference: zero. EMI is reduced by using more cables though.",
      "Awesome! I would refrain hitting your GPU with a heavy work load until you get rid of that pigtail. From what users like the other commenter have noted 400W power draw from there 6900/6950xt's. The max rating of an 8 pin pcie cable 150w/12.5a, so with only 2 cables the most you can safely pull is 300w so you really need that 3rd cable stat!",
      "5800X3D with 32GB RAM CL14",
      "I've already undervolted miny, 1.1v with 2500mhz min and 2600mhz max. Great perfomance and it peaks at 320w.",
      "Check out Ancient Gameplays on YouTube. He's got a great beginner OC guide for the 6950XT. Are you using it for 1440p or 4K?",
      "$599 right now at Micro Center in the US, for the AMD model",
      "Awesome. Tick on the memory timings to Fast Timings too ‚Ä¶ it really gave me a nice boost in performance in benchmarks.",
      "Does not included tax. With purchase of any CPU processor. \n\nThey've been running that promo all summer long but the previous markdown was $650 (from $699).\n\nAlso in-store only\\*\\*\\* which is the standard for most things at Micro Center.\n\n&#x200B;\n\nIf you've never been it's literally heaven, but hell for your wallet.",
      "What CPU are you using bossman?",
      "Same cooler if it's the Arctic Liquid Freeze II. Except I did push pull. Slick build.",
      "Nice. That‚Äôs what I did too. You are going to love that card. Mine really loves an undervolt‚Ä¶ I can get it down to 300-320 watts without any real loss in performance FYI. Enjoy it!!",
      "Time Spy Extreme Graphics Test 2 will give you the most realistic max stress test on RDNA2. \n\nIf you're pulling 320W then it's not max stress. My MPT unlocked Red Devil pulls 550W at 1.164v (and was happy doing so with a Corsair SF750 with the 2nd & 3rd 8 pins pig-tailed)."
    ]
  },
  {
    "brand": "amd",
    "generation": "6000",
    "tier": "top",
    "matched_keywords": [
      "6900"
    ],
    "title": "R9 5900X / XFX RX 6900 XT",
    "selftext": "",
    "comments": [
      "Oh shit, I‚Äôm sorry!  \n\\- Sorry for what? Our daddy told us not to be ashamed of our amd cpu and gpu, especially since they are such hot and need water cooling  \n\\- Yeah, I see that. Daddy gave you good advice!",
      "looks really nice, that XFX radeon card really looks good, wish I could get my hands on one. Is this your first watercooled build ? \n\nWhich way does the fluid flow out of the pump, is it going into that bottom rad first ?   \nOr is it hitting the right Monoblock inlet over the CPU first ?",
      "You clearly haven‚Äôt done a custom loop before . Been a part of and making custom loops on customers pc since 2007, and none of what you are saying is alarming and does little or nothing to the loop. If you want problems you do hard tubing .",
      "It gets hotter when I pull on it",
      "It would be if there was actually a problem. They've clearly never done a soft rubber water-cooling setup. Those ribs are longer than they need to be relative to their components, but they're not *long*. There's no risk here.",
      "No the dumbass you were commenting about",
      "That pump must be pretty powerful for 2 radiators in those positions",
      "Please do elaborate",
      "Is that cooling solution cum or monster energy zero ultra.",
      "Those sagging pipes are a very bad idea.\n\nSpeaking from experience...",
      "dangling your res over your gpu is more than i can handle",
      "You can get them at MSRP on Amazon (NE has them for that price as well):\n\n[XFX 6900xt at Amazon](https://www.amazon.com/XFX-Speedster-MERC319-Graphics-RX-69XTACBD9/dp/B08SVZNFWR/ref=sr_1_3?dchild=1&keywords=radeon+rx+6900+xt&qid=1635115253&qsid=132-8471457-8571065&s=electronics&sprefix=radeon+%2Celectronics%2C104&sr=1-3&sres=B08SVZNFWR%2CB09258PCFS%2CB08Q2R71CS%2CB096M7NPNP%2CB094DYSQQL%2CB08R81J62G%2CB093NBMV17%2CB093N3Q96N%2CB08R6M3JPS%2CB08W2GPR62%2CB08S6Z2HGW%2CB097FYBRXH%2CB083HZ3M1X%2CB09257F463%2CB08ZFYDH66%2CB097YWV6VP%2CB08QQFW9YS%2CB08Y934HZQ%2CB08TJ2BHCQ%2CB0966YJGLT&srpt=VIDEO_CARD)",
      "\"MSRP\" used to be $1400, which is what I got mine at..",
      "case ?",
      "Yes.",
      "He linked the Merc Black edition, which is like the XFX equivalent to EVGA's Kingpin line. They're extremely highly binned. If you managed to get the Merc Black for $1,400, though, then lucky you :D I paid about $1600 for my Merc Ultra (one step down in binning) back in January.",
      "Seriously wtf is this dude talking about and why has he been upvoted.",
      "I started with r/watercooling, spent a lot of time on EK, watching yt videos of cooling systems, checking out overclocking for their set ups (even though I've never been into OCing, shared setups). \n\nI also have an engineering degree and did very well in fluid mechanics, so the theory behind each part made sense and I can work out ideal rates for my loops, compare them to the measurements of my loop and empirically determined where I can improve it. \n\nI've stopped actually building WC loops because it's a lot of work and I'm lazy.",
      "Major gpu sag and three of the tubing runs are way way too long. Need to clean this up.",
      "[XFX Speedster Zero WB](https://www.newegg.com/xfx-radeon-rx-6900-xt-rx-69xtawbd9/p/N82E16814150863) \n\n1800$, take it or leave it."
    ]
  },
  {
    "brand": "amd",
    "generation": "6000",
    "tier": "top",
    "matched_keywords": [
      "6900xt"
    ],
    "title": "AMD Radeon RX 6900XT drops to $630 for Black Friday - VideoCardz.com",
    "selftext": "",
    "comments": [
      "**Still no way near as good as 6800 XT for 515$ on Newegg, though.**\n\nRemember - the initial MSRP of 6900 XT was horrible compared to the 6800 XT which was almost just as good for 350$ less, do not let that fool you.",
      "Yeah BF prices have mostly ignored GPU's in Europe this year outside of small discounts here and there.",
      "It would be a great 1440p card too my man",
      "meanwhile the 6800 XT here still costs almost 800‚Ç¨",
      "I was really expecting some killer GPU deals this Friday since the new gen is coming but...zilch, really.",
      "Got the 6800xt and am very satisfied of my purchase. As a 1080p gamer, I don‚Äôt need more.",
      "Not worth the performance per price. Better get a 6800 xt or just wait for rdna3.",
      "Yeah. I'm here like... What the fuck.",
      "I mean there's XFX 6900 for 750‚Ç¨ on Mindfactory.de, and that's about right when you account for import taxes + margins for the store.",
      "That just shows how much profit they're making on us.  I can't imagine they're selling these at a loss.",
      "Personally, I believe 1440p + High is much better than 1080p + Ultra/RT, but to each their own.",
      "There is no national sales tax. Every state, country, and city picks their own sales tax rate, combining to a range of 0%-10.5%.  Most people live in areas with a combined rate around 7-10%.",
      "6800XT at 1080p? What do you have like a 480 Hz monitor or something?",
      "Meanwhile 6800xt 1k+ in canada",
      "‚Ç¨750 is ‚Ç¨635+VAT (=$660+VAT). So only a minor difference in price.",
      "Not to play politics, but the relatively low sales tax that the US enjoys come with a whole host of trade offs.\n\nIt's up to you whether you feel like the trade is even. I personally do not. \n\nAnd this is coming from someone with two expensive hobbies (PC gaming and MTB'in) and only average income ($50k a year or so).",
      "These are AIB cards so most likely they are selling at a loss.  They have no choice since the price will go even lower once 7900 cards drop.",
      "I would wait. It's not far off. The 7000 series GPU launch will force the 6800XT lower. Finding that for under $450 would be awesome. 6900XT under $600 would be good for the price per performance if 6800XT doesn't drop below $450",
      "Dumb question, but how much tax is on that when you buy it in the US? Because you can get a 6900XT for 750,- ‚Ç¨ and that includes sales tax.\n\n(https://www.notebooksbilliger.de/asrock+radeon+rx+6900+xt+phantom+gaming+d+16g+oc+grafikkarte+699111)",
      "6900xt has regularly been going on sale for $799 in Canada. \n\nhttps://reddit.com/r/bapcsalescanada/comments/z3uiv3/gpu_asus_tuf_gaming_radeon_rx_6900_xt_top_edition/"
    ]
  },
  {
    "brand": "amd",
    "generation": "6000",
    "tier": "top",
    "matched_keywords": [
      "6950xt"
    ],
    "title": "Upgraded from a ryzen 7 2700 and a rx 590 to a 5800x3d and a rx 6950xt",
    "selftext": "PC case and psu were also changed cause that 6950xt is a big boi.Pretty satisfied with how it turned out (except for those pcu cables being the way they are).I'm loving that I can still keep alive my am4 motherboard with that 5800x3d.",
    "comments": [
      "What ya gonna do with all that power, all that power inside that tower? üé∂",
      "Ima git git git get you frames, get you frames inside yo games",
      "My bump, my massive framerate bump, so smooth, no tear no jump...",
      "My fans are spinnin'. Check it out.",
      "CO for the 5800x3d helps with temps. \n\nI have the ezdiy U bend power adaptors for my 6900xt,makes clean cable paths easier.\n\nI started with 3600x, nice work milking 2700 this long and keeping AM4, I can't see any reason to upgrade soon.",
      "That‚Äôs a beastly upgrade my dude! Enjoy",
      "Thank you very much ! I'm indeed enjoying every moment of it.",
      "Definitely a good combo, I rock the same but with the red devil gpu. How's the temps with that air cooler? Got a 240mm aio before and never had issues.",
      "You're ballin' now Big Dog.",
      "To be honest I wasn't aware about curve optimiser(I hope that is what you meant)  ,will definitely give it a look.\nAlso about the PSU cables at first I gave a look at the cablemod site but 60‚Ç¨ for a combined 2*8 pin cable was a bit too much for me ,the u bend connector on the other hand seems like a pretty good alternative.\nAnd yeah the 2700 has served me well not a single complaint about it as you said I will not be needing any upgrade soon.Thanks for the info man!",
      "If we are talking about the 5800x3d idle is about 35¬∞C and  max temps  while gaming is about 72¬∞C but generally it sits around 65-70¬∞C,I haven't tried a lot of games (mainly god of war and warzone 2)so I have still some testing to do .The only lets say \"annoying\" thing is that on not constant load(lets say I just opened some tabs on chrome ) the fans ramp pretty aggressively but I guess that is a fan curve issue and not so much a CPU.",
      "nice!\n\nfrom a 5800X3D and 6950XT  fellow owner",
      "Curve Optimiser. Many of us can use -30 on all cores with 5800x3d as the silicone was cherry picked for the 3d cache. poorer heat dissipation but the best chips.\n\nJust the U bend adaptors, I don't go in for showy hardware, but the adaptors are a cheap way to get good cable management.",
      "All of you deserve medals... or an award or some shit.",
      "I just got a 5800X3D after my 5800X died. Do yourself a favor and follow this guide: https://github.com/PrimeO7/How-to-undervolt-AMD-RYZEN-5800X3D-Guide-with-PBO2-Tuner/blob/main/README.md\n\nMy temps are down by almost 12c, my PC is stable, and I'm still hitting max boost.",
      "I'm on a 5600x and 2080 super. I'm also going to with a 58003d and probably a 7900xtx at some point.",
      "I‚Äôm doing small upgrade from a 3600 to a 5600x on a 3060 ti.",
      "THEE value upgrade at the moment. You really dont need more at the moment imo, and i rock 2k ultrawide. Enjoy the buttery-smooth frames my friend",
      "2700x gang checking in",
      "Congrats"
    ]
  },
  {
    "brand": "amd",
    "generation": "6000",
    "tier": "top",
    "matched_keywords": [
      "6900"
    ],
    "title": "This has to be my favorite AMD Radeon GPU. The RX 6900 XT Halo Infinite Edition! This is number 35 of 117 and I have a very awesome Halo Themed PC centered around this GPU!",
    "selftext": "",
    "comments": [
      "The only way to buy one is off of eBay. Since this card was only released as a giveaway item they were never offered for sale except for the ones that one it putting it on eBay :)",
      "Where does one buy these cards? honest question. Its awesome!",
      "I post stalked you just now and I see some of your other builds (eva etc)... do you have pics of your full Halo build?",
      "I have not done it yet actually :) still collecting all the parts to do it to be honest",
      "Thats a good deal for this limited edition, cheers!",
      "This one cost me $1200",
      "Well, if it makes u/PidgyPCs happy, then that is all that matters.",
      "great looking GPU, no fucking way I would've paid 2k",
      "Shiny",
      "Dang, how much did it run ya? If you don't mind telling.",
      "Thats what I said too! Salut",
      "‚ÄúBury my body, do not build any monument, keep my hands outside so that the world knows the person who won the world had nothing in his hands when dying‚Äú.  ‚Äì Last words of Alexander the Great.",
      "It does! I feel the $1200 was worth it :)",
      "neat! $1200 is still pricey, but as you say is an actual limited edition",
      "Exactly! Not sure if its the rarest GPU out there, but it says something with only 117 ever released LOL",
      "I didnt pay quite that much, I got this one for $1200 which is actually the most I would have spent for it. I find it worth it though to have 1 of few. If you look at my profile, I am not a stranger to Limited Edition products :)",
      "Ayy I‚Äôve got one as well. Love the card so much",
      "Right lol",
      "Be sure to share it with us when you do, Merry Christmas üéÑ",
      "It really is so cool!"
    ]
  },
  {
    "brand": "amd",
    "generation": "6000",
    "tier": "top",
    "matched_keywords": [
      "6900xt"
    ],
    "title": "6900xt thermal paste swap.",
    "selftext": "",
    "comments": [
      "Thermal Grizzly kryonaut extreme, dropped me 20¬∞c and got me back to number one on 3DMark.",
      "Such a beauty. The pink part is the best",
      "Yeah the original mount may have been bad but all I did was remove the cooler, replace the thermal paste and reassemble.",
      "20???",
      "Wow, that's crazy tbh ahah",
      "Yeah MSI fucked the mounting again this gen. No wonder its so high temps",
      "Yeah I know I was hitting thermal limits trying to get to number one on 3DMark so thought I'd strip it down. It's the MSI gaming z trio so has the unlocked core.",
      "I got a MSI 6900XT Gaming Z and considering what it cost the thought of taking it a part is pretty shocking so bravo from me.",
      "Swapped with chewed bubble gum?",
      "All proven bullshit by gamers nexus, there's such a thing as not enough, no such thing as too much as for manual spread on CPUs and GPUs it's the way all the top hall of fame overclockers do it so I'll stick with the record holders as what's good practice.",
      "Honestly it's really easy worth doing it you want to OC as I was hitting junction temp limit.",
      "I used Conductonaut a few years back on my ryzen CPU, 2 months after application it decided I had applied too much and leaked onto the motherboard and gtx 1080. \n\nI have learned my lesson and stick with non conductive now.",
      "Well, not a good QC job from MSI if the mounting was causing you thermal issues.",
      "It's pulling 340w benching.",
      "Manual spread is the best method.",
      "Kryonaut Extreme is pink\n\nNormal Kryonaut is not",
      "ü§£ no some of the best thermal paste there is.",
      "Once you've stripped down a GPU once, you won't think twice about doing it again, it's quite fun and satisfying making your card run better.",
      "So do people manually spread paste on GPUs? I know it was considered bad practice for CPUs in the past. \n\nFrom intel website,\"Incorrect manual application can cause air bubbles to form in the paste, which can negatively impact the thermal conductivity.\"\n\nAlso Intel,\"Too much reduces the efficacy of the paste, due to the metal surfaces being too far apart.\"",
      "Look at gamers nexus, Jayztwocents, kingpin for overclocking, Jayztwocents and gamers nexus have a lot of extreme overclocking videos with water and LN2."
    ]
  },
  {
    "brand": "amd",
    "generation": "6000",
    "tier": "top",
    "matched_keywords": [
      "6900xt"
    ],
    "title": "Finally got into the AMD Sale last week and picked up the 6900XT!!",
    "selftext": "",
    "comments": [
      "999 for 6900xt is a steal love this card. Wait‚Ä¶‚Ä¶.msrp is a steal? Yup it is",
      "Congrats! The box and packaging of the 6900xt is just as lovely as the card itself. Enjoy!",
      "Isn‚Äôt this the one that looks awfully suspicious when the fans are spinning?\n\nEdit: https://youtu.be/FzBzBruvkMY",
      "$1,000+shipping and handling\n\nNormally I wouldn't have considered this card as the 6800/XT are better values, but the state of the GPU market has those cards still costing more than I paid for this one",
      "I have been trying this for the better part of a year and still no luck for me, I am starting to think the queue is fake and these are just the bot posts.",
      "I checked out the bot posts and AMD did an exceptionally POOR job of stopping them. For weeks on end they'd boast about being able to open _hundreds_ of sessions and game the queue that way",
      "Oh yeah the packaging was amazing!",
      "It's not a bug, it's a feature.",
      "They finally started implementing anti-botting measures in January and it does help. Demand from mining is also way down currently. The 6800/6800xt sell out in the first couple minutes once the queue opens, you won't get one of those unless you instantly get in the queue, but the 6900xt was in stock for 10 minutes when I got mine from a 10 minute queue. There were 6700xt in stock 45 minutes after the queue opened last week so don't just nope out if you get a long queue time. Odds of getting a 6700xt are very good and will probably be even better next week given stock levels are similar.\n\nYou can open a few different browsers and queue up once in each one and it's \"in-private\" option. Don't refresh the page too quickly or you'll get softbanned when checking for the pre-queue to start. Scalping a 6700xt isn't worth it once you figure in your time and the small bit of profit you'll make after shipping/paypal fees. Newegg had some XFX 6700xt for $599/$629 last Friday and they were in stock for multiple hours.\n\nGood luck and keep at it.",
      "My arm after I saw this: üìà",
      "That‚Äôs a phenomenal deal on this market",
      "If you can get the 6800XT for a price near MSRP, I'd recommend it. The 6900XT is 11% faster, but like 30% more expensive.  So while I love my 6900XT, I'll be the first to say that it isn't worth the additional $300 odd dollars",
      "beasty boy! i just picked up an open box red devil ultimate for $1250 recently. they are great cards!",
      "Price?",
      "The AMD sale every Thursday morning",
      "Lol. I was looking at getting the 6800xt when prices fall a bit more.",
      "The only thing I'll give a 3080 TI over this card for is ray tracing, all the reviews say the 3080s do a lot. Much better job at ray tracing but for all the games in my library I only have like four that support it. So in my case no great loss",
      "If you don't want your keycap I'll buy it ;)",
      "from where did u get it",
      "Yeah it was my idea when buying the 6900XT.\n\nI wanted the 6800XT and it was more than enough, but no availability led me to the 6900."
    ]
  },
  {
    "brand": "amd",
    "generation": "6000",
    "tier": "top",
    "matched_keywords": [
      "6900"
    ],
    "title": "Just got these custom back plate for my 6900 black limited edition :D",
    "selftext": "",
    "comments": [
      "God damn that‚Äôs beautiful man",
      "https://www.v1tech.com/",
      "One word.... WHERE CAN I BUY ONE.",
      "By the ancestors, thank you.",
      "Thanks alot!",
      "You‚Äôre joking right. They‚Äôre not even testing the right components. Ofcourse it‚Äôll have no effect on GPU temps the backplate never cools the GPU directly. It cools the VRAM and VRM which they didn‚Äôt test. Its acrylic. Its not gonna be a heatsink.",
      "Holy shit are these ever cool. Why have these not become a thing. I think I'm gonna order one",
      "Man I have this same card. I didn't l know I could make it look even better",
      "Because withthe cards being higher and higher TDP putting an insulator on the backplate which is usually used to dissipate heat is not such a great idea.",
      "It's indeed a hard task, the card looks awesome out of the box",
      "Those ssd covers they offer are amaze thanks for sharing",
      "Wish I had discovered this before buying a vertical GPU bracket! This looks so much more legit!",
      "Not gonna lie, it's fuckin sweet",
      "V1 coming in clutch I see. I love the look of these 6000 series XFX cards. Nice build, friend. Merry Christmas as well.",
      "I didn't know that \"WHERE CAN I BUY ONE\" was only one word.",
      "To qoute Gordon: F off will ya?\n\n\nlol",
      "sexy",
      "Ok you win.",
      "Has to be the dopest looking computer I've ever seen",
      "Cool"
    ]
  },
  {
    "brand": "amd",
    "generation": "6000",
    "tier": "top",
    "matched_keywords": [
      "6900"
    ],
    "title": "No, it's not a console killer. CL530 w/ 5800X3D + 6900 XT",
    "selftext": "",
    "comments": [
      "Not a console killer- it‚Äôs even more",
      "Specs\n- CPU - Ryzen 7 5800X3D\n- CPU Cooler - ID-COOLING IS-60 EVO w/ NF-A12x25 & NF-A9x14\n- Motherboard - Gigabyte X570SI Aorus Pro\n- Memory - Corsair Vengeance LPX 32gb, 3200mhz CL16\n- Storage -\n - Crucial P5 Plus 2TB\n - Crucial MX500 2TB\n- GPU - Gigabyte 6900 XT Gaming OC\n- PSU - Corsair SF750\n\nThe 5800X3D throttles a little bit during all-core loads, but not too bad. It never throttles while gaming. Screenshot: https://imgur.com/NHBWLzG\nCinebench score: 14650\n\nGPU runs fine, topping out around 90c on the hotspot with an undervolt dropping its wattage from 300w to 240w\n\nPCPartPicker link for more details: https://pcpartpicker.com/b/T99NnQ",
      "Looks awesome, and I‚Äôm betting you look awesome too üòéüëâüëâ",
      "Undervolting is the best to do on all of the new hardware. Let it be GPUs, Ryzen 5000 or Intels 12000s.",
      "Your console vs the PC she tells you not to worry about.",
      "That things literally a beast in a briefcase lmao",
      "Yeah it‚Äôs a console serial slayer",
      "Yeah, I have the 5800X3D on a -30 CO as well. It helps a ton.",
      "Thanks dear",
      "Consoles don't actually do 4k most of the time, they use dynamic resolution and/or some sort of scaling. The framerate is often low too or at least not stable. Also, you can still do so much more with a pc.\n\nBut still, if you don't care about working on your pc, want something relatively cheap and very easy to use, a console is indeed the way to go.",
      "That's hot.... literally",
      "the worst part of PC gaming is how laughably big cases are. this definitely appeals to me. nice job OP",
      "never understood people calling pc's above 1000 dollars console killers, it's not very easy to just find a pc that can do ray tracing + 4k gaming(depends on game) at 500 dollars, let alone 300 dollars for 1080p no ray tracing 120fps(series s), Is it because of the size of the console or the general viability? it never made sense to me",
      "Its also way more expensive",
      "Yeah I‚Äôve got a regular 5800x & 5900x and curve optimizer helps a ton. My 5800x is an especially good sample in Cinebench it‚Äôll hit 16300 with curve optimizer or I can get about 16650 locking it at 4.8 all core but that hurts my gaming performance so I stick with curve optimizer.",
      "Have to take price into consideration, tbf. The 5800X3D alone costs 90% of a PS5.",
      "That is definitely a console killer the new consoles can still barely run anything above 60 frames.",
      "\\-30 ***all core***? No way that's stable.\n\nRun Core Cycler for a few hours, you'll find instability and low loads / idle.\n\n[https://www.overclock.net/threads/corecycler-tool-for-testing-curve-optimizer-settings.1777398/](https://www.overclock.net/threads/corecycler-tool-for-testing-curve-optimizer-settings.1777398/)\n\n[https://github.com/sp00n/corecycler](https://github.com/sp00n/corecycler)\n\n\nEdit: tagging u/exscape for relevant links ^",
      "Ran it for a few hours, 3 complete iterations: https://imgur.com/a/FzFpCbj\n\nNo errors, I might run it overnight for fun but I'm pretty sure its stable. Check the 5800X3D owner's thread at overclock.net and you'll see that -30 CO is not uncommon for this CPU.",
      "I have a 6900XT and 5800X in the same case and I believe the same cooler and I‚Äôve found the gpu stays quite cool but the 5800X throttles almost all the time. Waiting for the next Gen to come out to move on from the 5800X to something that runs a bit cooler"
    ]
  },
  {
    "brand": "amd",
    "generation": "6000",
    "tier": "top",
    "matched_keywords": [
      "6950",
      "6900"
    ],
    "title": "High-end AMD RDNA 2 supply is dwindling ‚Äî RX 6950 XT, RX 6900 XT, RX 6800 XT virtually out of stock",
    "selftext": "",
    "comments": [
      "Tons of them left in Norway. The only one virtually gone with just a couple of overpriced units in stock is 6800 and 6800XT.\n\nEven the 6700XT is easy to get cheap, I'm really ashamed of how many green cultists there are in this country",
      "that tracks, our microcenter still has a bit, it was 25+ since last year, now its at 17, guess they ain't restocking no more. I'm hoping they will drop price to move inventory a good sidegrade from 6800xt assuming it goes down a hundred more\n\nhttps://i.imgur.com/rWgZNu1.png",
      "Yet the ancient RX580 is still plentiful.  What's your thoughts on that?",
      "brand new or second hand? cause all I see for Polaris are ex-mining card.",
      "Cheapest RX 6800 XT cost 6600 NOK, you can get 7800 XT for 6700 NOK or a 4070 for 7000 NOK.\n\nI bought my 6800 XT used for 4000 NOK over a year ago ü§£",
      "elastic rob alleged plate longing snails lush zephyr cough tart\n\n *This post was mass deleted and anonymized with [Redact](https://redact.dev/home)*",
      "Anecdotes be anecdotin': I've got a 6700 XT, *not* a high-end card at all, really, but goddamn does this thing **scream** at 1440p.  \n  \nRDNA2 is a really great value proposition, and we're kind of getting to the point in computer hardware that people don't need as much future-proofing as they once thought.  It's like what we're seeing with cellphones; new and improved hardware is coming out all the time, but for many of us the *old* hardware still does everything we need it to do and more.  \n  \n>\"My gaming computer has a CPU bottleneck.\"  \n>  \n>*\"But your game is running at 350fps!\"*  \n>  \n>\"Nevertheless.\"  \n  \nThis may not be good for AMD, or less than ideal, anyway, but at the same time I'm kind of pleased as an onlooker to see that consumer habits may be changing a little bit.  Not everybody needs a Hummer, y'know?  *Some* people can get the most out of buying a Hummer, but not most.",
      "6950 XT was available for a long time as a fantastic value 1440p gaming card. Now the 7900GRE is available at the same performance tier at a lower price and is less power hungry.",
      "Exactly, usually I don't keep a high-end card, generally I resell it shortly after the arrival of its replacement, an RX 7900XTX Sapphire NITRO+ model, really an excellent card very well cooled (despite its increased TGP from 350 to 430 Watts in stock setting), but for now I'm going to keep my \"old\" RX 6900XT from MSI Gaming \"Z\" Trio model, with \"Navi21XTXH\" chip instead of \"Navi21XTX\" (running at a stock voltage of 1.2v instead of 1.175v), rather than managing to sell it used for just over 400‚Ç¨/400usd",
      "afterthought escape square shy quiet door cake familiar depend outgoing\n\n *This post was mass deleted and anonymized with [Redact](https://redact.dev/home)*",
      "Brand new - Best Buy here are STILL selling XFX 580's.\n\nFunny thing you say about it being an ex-mining card.  Before COVID ruined everything, I bought a Sapphire Nitro+ RX 580 for $100 USD from r\\/hardwareswap that was an ex-mining card.\n\nThing is, the person was very transparent about how it was used.  Was in one of those mass-mining setups with an open bench.  24/7 AC-cooled room.  Underclocked at the beginning.\n\nI still have it to this day and I probably run it harder in a worse environment than he does (kinda dusty room, humid, gets warm during the day, etc) and it still runs like a champ.",
      "Yeah the 7900XT and XTX launched at too high a price and the 6950XT suddenly became much better value proposition.",
      "Sardo-what now? XD",
      "You might be on to something there.  I bought one a year or so ago as \"new\" on Amazon, and it turns out it had been (poorly) repasted at some point and was running hot.",
      "Yeah it screams at 1440p in most games, but playing Horizon Forbidden West on my 6700XT makes it *cry* instead lol.",
      "Bought an rx6750xt recently for $330 to put in my AMD 7600 build. Gonna hold that mf until Doom can‚Äôt play on it anymore,",
      ">I'm really ashamed of how many green cultists there are in this country\n\nMore for yourself.",
      "100%.  I got a RX 6800 (non-XT) and loving it for 1440p.  Made the switch from Nvidia to AMD GPU for the first time in almost a decade and it has been great so far.  Bummed that I didn't wait a little longer now that models are as low as $380 but other than that no regrets.",
      "Different node.\n\nThere is a chance AMD had bought x wavers on the node (14nm Global Foundries), paid for it and didn't use them yet fully. There is a reason why the Zen3 compute die was on the same node family over at GF as well.",
      "[About that...](https://www.amd.com/en/products/graphics/amd-radeon-rx-7700-xt)"
    ]
  },
  {
    "brand": "amd",
    "generation": "6000",
    "tier": "top",
    "matched_keywords": [
      "6950xt"
    ],
    "title": "Build finally complete! Sapphire Nitro+ Pure 6950XT is a MONSTER gpu.",
    "selftext": "",
    "comments": [
      "Such a gigantic card. Looks lovely in there",
      "I got the sapphire nitro+ SE 6900XT and its a beast awesome looking card too,\n\nCan only run mine at 2650mhz so it really shows how well binned the 50 series is.",
      "Build Specs: \n\n-CPU: Intel 12900K \n\n-MB: MSI Z690I-Unify Mini ITX\n\n-RAM: DDR5 GSKILL 6000mhz cl36 Silver \n\n-GPU: Sapphire Nitro+ Pure 6950XT \n\n-CPU Cooler: DeepCool AK620 WH\n\n-PSU: Coolermaster SFX V850 White 850w\n\n-Case: O11D Mini white\n\nCase fans: Arctic P12 pwm pst - white/Arctic P14 pwm -pst",
      "Beautiful. May we share this on AMD social media?",
      "That is a cool 90 degree adapter you got there for your cables.",
      "Amazing build dude.",
      "\\*180¬∞ adapter.",
      "Ive got the same card and it's still a monster, it's at the point that the biggest bottleneck is trying to cool the damn thing in a 680x case",
      "Yes by all means!",
      "It performs almost on par with a Noctua nh-d15 but it's only $65.",
      "Oh shieet they released a white version of the CPU cooler?\n\nDamn might be getting that next then.\n\nHow is it noise level wise?",
      "Looks like the [DeepCool AK620 WH](https://www.deepcool.com/products/Cooling/cpuaircoolers/AK620-WH-High-Performance-CPU-Cooler/2022/15496.shtml).",
      "They were actually in stock.",
      "Looks crisp, good job üëçüèª what cpu cooler is that?",
      "How the Hell do some of you guys get these new cards so fast???",
      "OK... I don't usually say this, but OMFG that is a beautiful rig. Extremely well done, you should be proud. \n\nDo you have a build list of all your parts?",
      "Thanks!",
      "Yeah I had the nzxt h440i before my current case and temps were one to throttle temps,\n\nSo I bought the corsair icue 465rgb case and cooling is soooo much easier,\n\nMost games it stays under 85c games with raytracing it can get into the low 90s at times but ifs still 20c+ lower than my radeon 7 got to so much happier.",
      "achy bronto liphersoos arpregniator sarchosis inebriatolion\n\nOf course if you are aware, I forgive and to be onto it, I say, we eclkhath farsothey antoothrick.",
      "Your GPU is sagging a bit. It looks awesome having a beefcake like that but I would be concerned a tiny bit with the longevity of that PCIe lane."
    ]
  },
  {
    "brand": "amd",
    "generation": "6000",
    "tier": "top",
    "matched_keywords": [
      "6900xt"
    ],
    "title": "Painted the 6900xt reference card.",
    "selftext": "",
    "comments": [
      "Literally every version of the reference cooler that I have seen has looked dope, but this one takes the cake, absolutely gorgeous!  \n  \nI kinda' bet your GPU would even look good in a horizontal mount, since the white shroud would contrast with the black heatsink, so you've got a twofer there!  \n  \nVery cool mod OP, thank you for sharing it with us!",
      "Not bad for a painting. Almost looks real.",
      "Thank you sir.",
      "I'm an industrial painter but damn even I'm impressed by how well you were able to match the whites so well with a spray can too.",
      "The bottom right fan is not aligned with the others. You have to fix it",
      "Yeah, bought new off a kid for $1100 last week. I've painted my last two cards no issues.",
      "Some 14 year old kid on offerup had it brand new 1100. Came up",
      "Yeah too bad he got the color of the card wrong\n\n/s",
      "Beautiful build!",
      "Just be happy for the man god damn. How do you get around thinking so negatively?\n\nIt looks sick. Even cooler than my white 6700XT Hellhound.",
      "nice",
      "How did you paint it?",
      "Plasti dip",
      "Well I have a white 2060s I'm selling. Pretty sure it voids the warranty. Pretty easy depending on card disassemble, and take shroud off or in this case tape off everything your not painting.",
      "I was thinking of doing this to my 6700 xt reference and this makes me really want to do it. It looks so good",
      "This has to be the most prolific pc case ever designed.",
      "You Monster!!\n\n&#x200B;\n\n&#x200B;\n\n...sorry, I was talking to the card.",
      "So is the bottom left fan ^^",
      "Thanks bro.",
      "Can you change the color of the RADEON ? Mine is red and doesn‚Äôt seem to be changed"
    ]
  },
  {
    "brand": "amd",
    "generation": "6000",
    "tier": "top",
    "matched_keywords": [
      "6900xt"
    ],
    "title": "First ever PC build lemme know what y‚Äôall think. It‚Äôs got a 6900xt gpu, Ryzen 9 5900x cpu, 32 gb cl14 tridentZ neo ram, Samsung 980 pro 2 tb storage, rog strix 850w power supply, and a Phanteks 240m AIO. I also added a back case fan that didn‚Äôt come with the case.",
    "selftext": "",
    "comments": [
      "Great PC. Just don‚Äôt throw a dart through the case. ;)",
      "I'm assuming they're future proofing",
      "well someone didn't cheap out here.\n\ncables are a bit messy.\n\nyou don't want to daisy chain your gpu cables. try two separate ones.",
      "Thanks , I definitely won‚Äôt be using that dart board anymore until I move it üòÇ",
      "u/No-Tomorrow-9546 this is very important! Daisy chaining your gpu connectors can and probably will lead to a lot of issues, especially on a power-hungry gpu like the 6900xt. Pull another separate cable from your PSU to plug the other connector.",
      "Terrible term to use lol but yeah I agree. I always build a way over kill computer to last me a good 5-7 years. If not more. Just upgrade small things that break over time.",
      "Because modest builds don't get upvoted.",
      "Thank you. First thing that caught my attention was that dart board and your tempered glass panel. My anxiety is somewhat alleviated. üò±",
      "I just wanted to upgrade to 1440p now, and idk how expensive the new graphics cards and cpus are gonna be and if they are gonna be in stock",
      "Get both of them out to power one connector each, you can figure out how to make them look pretty later. Function over form always.\n\nThe pigtails on those cables are generally meant to only be used when you have 3 gpu connectors, you plug the first 2 connectors on one cable each, and for the 3rd connector you use the pigtail. [Like on this graph](https://hardforum.com/data/attachment-files/2020/10/388573_daisy_chain.jpg).",
      "Epic first build! \n\nHow much did ya pay for the 6900xt ?",
      "The problem with that is nothing you can build right now will run new games anywhere close to max settings at high resolution in 5 years.",
      "My first PC build was a beige case 386 PC.",
      "What would the equivalent of this be for the market 5 years ago? 1080 ti? Or was there a higher rated card",
      "I got a 6700xt on vacation for 500 I can't wait to go back and set it up ITS GONNA LOOK GOOD",
      "Mine was an off white 486dx",
      "Nice! Just got a Sapphire 6900xt toxic for 850$",
      "That‚Äôs some expensive ram",
      "oh and the motherboard is a Meg x570 Unify",
      "Thanks! $900"
    ]
  },
  {
    "brand": "amd",
    "generation": "6000",
    "tier": "top",
    "matched_keywords": [
      "6900xt"
    ],
    "title": "AMD Advisor is a meme. 6900XT does not meet the min requirements for anything in my library.",
    "selftext": "",
    "comments": [
      "it is a glorified advertisement page disguised as an \"advisor\".",
      "Oh, you run a 5900X? You should go for a 5950X, just to be safe.",
      "Processor does not meet minimum requirements either. These tools are just garbage. Like with the Windows 11 upgrade advisor fiasco. Threadripper ain't enough but it will run on a potato phone SoC lol",
      "Only noticed when I was using game tuning that all my games had an X in them.",
      "It's the troll answer to the most frequently asked question in this sub. *will I bottleneck with a 5900X?*",
      "Weird I've noticed it because its been posted 3 times a day for the last 3 months",
      "Don't worry, I am sure with FSR you should be able to play at 720p low.",
      "Have you considered upgrading to an Rx 7900 XTX+ from Radeon's underground lab?",
      "Don‚Äôt you know, when your cpu and gpu are too fast, your games end up going backwards in time and makes them totally unplayable!",
      "Has this tool ever been useful? or has it always just been a way to trick users to upgrade their hardware?\n\nPretty upset i cant run wallpaper engine on my rig anymore. /s",
      "Yeah windows update tool said no too. But enabling AMDs TPM thing in the bios of my mobo made me pass it. Assume threadripper could do the same?",
      "Absolutely! When I built my computer last year, I wanted the most powerful AMD system I could get (because I'm a fanboi), so I went for an RX 5700XT, but I couldn't justify spending ¬£700 for an R9 3950 over just over 400¬£ for a 3900 (which is still oversized for most of what I do. So when the advisor war 'recommending' the 3950, I giggled.\n\nAt least the current 'recommendations' are for a more recent generation of CPU and GPU, not that I can put my hands on the latter at reasonable prices anyway (and I don't feel the need to update).",
      "No, it was never useful. It's just a marketing tool. No matter what game you're playing, what software you're using or what kind of performance you're getting, it'll always recommend the top of the line.",
      "mate it told me to upgrade my 6900xt and 5950x. guess I need epyc",
      "Reject windows, return to Linux",
      "I don't think it's ever been useful or ever been affective as a way to get users to upgrade. It *could* have been made both, if it provided real information, but it never did anything but offer the highest end CPU and GPU even when it did have something relevant to say about which games run on what hardware.",
      "This is one of the feature settings that you want to disable every time.",
      "I Just upgraded to a 5600x and sometime next year when GPU's are in stock I'll get a new one lol. It's crazy how much my Vega 64 sells for atm and if I could get my hands on a 6800xt or a 3080 (at MSRP or very close to it) I would sell it in a heartbeat and cover 75% of the cost of upgrading.",
      "Upgrade it to what exactly lmao",
      "AMD Advisor secretly works for the Star Citizen team."
    ]
  },
  {
    "brand": "amd",
    "generation": "6000",
    "tier": "top",
    "matched_keywords": [
      "6900xt"
    ],
    "title": "Black and Red - 5900x paired with 6900XT LC",
    "selftext": "",
    "comments": [
      "Such a nice case. I have one as well.",
      "Because it is a stock cooler. Those 6900XT LC cards are absolute unicorns.",
      "I picked it up from from centrecom which is a local store here in Aus. It comes as an OEM unit so basic brown box with nothing else really. These 6900XT LC cards are certainly rare, haven't see many of them - was lucky enough to jump on one.",
      "Where‚Äôd you get that cooler?  I‚Äôve not seen a 6900XT that has a stock looking cooler like that. I love the LED cover portion.",
      "It is! I am really loving the meshify cases.",
      "When running stock which is 2250/2435MHz game and boost clocks with the default curve it stays around 76C.\n\nI have it running at 1675/2850MHz with memory at 2400MHz and power limit at +15% (400W), with a more aggressive curve and it is hitting around 83C.",
      "because the die on GPUs is 3x bigger than CPU dies, so more surface area to come in contact and cool the GPU more efficiently. Coming from car knowledge, larger rad does not mean lower temperatures, it means sustaining low temperatures for longer (e.g. the 120mm would heat soak faster than a 360mm), but that can be resolved with a faster fan. So even though you have a 360mm rad on CPU, it won't cool it effectively when there is only so much contact area (big cold plate, but small and dense CPU die).  My friend is cooling his 3700X with a 120MM AIO just as well as I am cooling my 3700X with a 280MM AIO, only in sustained workloads his system might be a bit louder and a bit warmer. Plus the GPU core is in direct contact with the vapor chamber of the cooler, not going through an integrated heat spreader, which would lose some efficiency in heat transfer any time you are going from one material to another.",
      "Yep, this is it, easy mistake. The Meshify 2 C has the following distinctions you can use to tell:\n\n* Slotted metal mesh pattern on rear/top/slots. Meshify C has hexagons.\n* No rubber mounting points for the glass. The M2C uses a toolless snap system (you can barely see the snap-in points at the top) whereas the Meshify C uses 4 thumbscrews to secure the glass panel.\n* Mesh panel is slightly more offset in the front panel since the Meshify 2 Compact's mesh front panel is a door that swings open.\n* Feet are different, M2C is blocky like this whereas Meshify C has smaller silver round feet.\n* Screws holding the top panel on instead of just rivets, since the top panel is fully removable now.\n* No branding on the PSU shroud.\n* Cutout in the PSU shroud is now two segments so you can remove only part of it for radiator if you wish.\n\nLooks very much the same but these little differences speak to how much thought was put into redesign work for this series. Many other small differences not visible in this image exist as well.",
      "Better question where did you he get a 6900xt?",
      "I have one of these LC cards and honestly the 120mm does a better job than I thought it would. I have it at 2750mhz and it stays at 60c edge/71c junction at 50% fan speed. Could definitely be better with a 360mm but still pretty happy with it.",
      "Meshify 2 Compact*",
      "Where are the PSU cables from? They look so clean!",
      "I love it! black and red's my fav combo too :D",
      "what case is it?",
      "I got them off Amazon, they are the 'EZDIY-FAB Sleeved Cable - Cable Extension' in Black. They are really good value, very happy with them.",
      ">6900XT LC\n\nSame here, I just feel that 1x 120mm is a bit of a letdown. I don't understand why for CPU we need 360mm rad and for a GPU with 2-3x the TDP we have a 120mm..",
      "Meshify C edit: see below",
      "I have the air cooled 6900xt and but dam i want the lc version so bad.",
      "Not going to lie, one of the cleanest builds I have seen, good job.",
      "how many livers and limbs for that GPU?"
    ]
  },
  {
    "brand": "amd",
    "generation": "6000",
    "tier": "top",
    "matched_keywords": [
      "6900xt"
    ],
    "title": "Rx 6900XT is beast",
    "selftext": "",
    "comments": [
      "Use two independent PCIe power cables on that 6900xt...would hate for your build to burn up",
      "Tnx \n\nI changed it",
      "If by powerful you mean \"raw rasterization performance\" either card can come out on top depending on factors like resolution and the API in question, and even which versions of the card you're comparing due to differences in cooler designs.\n\nIf by powerful you mean \"an overall superior experience in Linux\" then the 6900 XT.\n\nIf by powerful you mean \"consumes more power\" then the 3090.\n\nIf by powerful you mean \"highest ray tracing performance\" then the 3090.\n\nIf by powerful you mean \"compute and productivity potential\" then the 3090, thanks to CUDA and it's wide adoption.\n\nIf by powerful you mean \"video encode/decode performance\" then the 3090 thanks to NVENC.\n\nIf by powerful you mean \"feature set\" then the 3090, due to DLSS being superior in general to FSR where both are implemented and comparable.\n\nIn short, the 6900 XT is a very niche GPU. It's a rasterization monster in the right circumstances, and there are a handful of situations where it is the fastest consumer GPU. But beyond it's limited use cases, it falls short of the 3090 in the majority of circumstances.",
      "Piggytail 8pin power connector detected on a 350 watt GPU, make sure you have a fire extuingisher nearby",
      "I have the exact same card. You really should use 2 independent pci-e power going into that GPU. But you do you üòÄ\n\nAnd get a gpu bracket. That card is massive and heavy \n\nupHere 5V 3PIN Addressable RGB Graphics Card GPU Brace Support Video Card Sag Holder,Built-in 5V ARGB Strip,Adjustable Length and Height Support,G276ARGB https://www.amazon.com/dp/B08YYJ8Z9W/ref=cm_sw_r_apan_glt_i_KVRZ5BPR8AHMZRS0R0VD?psc=1",
      "I really didn't know that\n\nTnx ....\n\nI changed it to 2 separate 8 pin connector",
      "I can smell the sweet burnt smell all the way here",
      "It's not going to burn up, it'll just limit the boosting behavior, since there's a wattage bottleneck. Well, it might, if you push it hard, I can't speak for every individual card, but the more stable voltage from 2 cables helps.\n\nThat being said, when I swapped from daisy chain to dual connectors, my \"game clock\" went from ~2350 mhz to ~2500 mhz.\n\nAlso, LPT, go into the Radeon settings, ***disable Zero RPM mode and set a more aggressive fan curve.***\n\nThe default makes it so the fans don't spin up until the card is already at 50¬∞C, and when I had it on the default, it kept crashing in more intense games or during spikes in the action. I changed it later on and it ended up becoming way more stable.\n\n[Mine is super aggressive](https://i.imgur.com/IqZRF34.png), but it almost never breaks 70¬∞C. The auto-boosting behavior is much better when it's running cooler.\n\nAlso, sometimes when the drivers update, it sets the fan curve back to default, so be sure to save your Tuning profile so you can easily reload it after each update.",
      "If you're asking about the 2-PCIe power cables, then yes. It's more to do with the stability of the power delivery.\n\nSpreading the supply of power across multiple cables reduces the overall wattage each individual cable has to carry from the PSU to the GPU, letting the GPU safely boost closer to it's actual limit rather than one imposed for safety purposes by the VRM or VBIOS.\n\nImagine trying to fill a bucket from 2 faucets rather than 1. If you're trying to fill a bucket once a minute, doing so from a single faucet will require you to turn it up so high that a bunch of water splashes out. If you fill it from 2, you get 2 neat, gentle streams, but they still fill in a minute, maybe even less.",
      "Now THIS is the kind of answer I come to Reddit for.",
      "Finally\nI build my dream pc\n\nCore i9- 12900K\nZ690 Rog gaming-A\nDeepcool castle 360\nRx 6900XT MERC black limited edition \n16 gig vengeance pro Corsair\nRog helios\nRog 1000w \n2TB crucial",
      "For a lot of things, yes.\n\nBut if you're chasing pure framerate on verylow/fillrate - 6900XT eats the 3080 for breakfast. Even the ref 6800 eats the 3090 for breakfast in fillrate.",
      "I have a 6700xt do I still count",
      "3090, but you'd be fortunate to get either. You get DLSS and their more mature Ray Tracing and Drivers.",
      "Really really tnx for your comment...\n\nI never knew that\n\nI change that to 2 separate 8pin connector",
      "I have a wooden shim holding mine up lmao",
      "Congratulations! This thing will be a beast! Im sure it will run well. May your temps be low and your fps be high.",
      "If you look at price or aftermarket price then the 6900xt should be compared to the 3070ti or 3080. People always compare it to the 3090 which isn‚Äôt 100 percent fair.",
      "Ok, if Nvidia wasn't pushing innovation, does AMD do?\n\n\nWhile Nvidia was packing it's software and hardware with new features, AMD was sitting back trying to catch up, they did innovate but only because Nvidia innovated something and they need an equivalent to it so they can still compete, amd SAM was one of the few times where AMD was ahead of Nvidia in adding a feature but even then SAM wasn't new or innovative.",
      ">A niche product is a product that only applies for very specific applications for a small group of people.\n\n\"If I use my own definition of a word then you're wrong.\"\n\nI don't care to argue semantics or definitions of words. I'm sorry that our definitions of niche don't align, but I can't do anything about that other than point out that my usage of the word was appropriate via the common usage definition of the word.\n\n>It has nothing to do with if one product is better than the other.\n\nWhere did I ever say that being a niche product makes it inferior?\n\n>No one is disputing that the 3090 is a better at certain applications than the 3090.\n\nIf you agree with my assessment other than the definition of one word you're hung up on, why are we discussing this?"
    ]
  },
  {
    "brand": "amd",
    "generation": "6000",
    "tier": "top",
    "matched_keywords": [
      "6900xt"
    ],
    "title": "Diablo IV Beta showing some problems with FSR 2.0, particularly with fine lines. Taken using 6900xt",
    "selftext": "",
    "comments": [
      "beta is exactly the time to say when something is broken",
      "It's more specular shimmering. Maybe something the devs can address with better settings.",
      "I mean, im not sure a beta is the time to say its broken. Its likely not coded correctly atm, as im sure they put Nvidia features 1st. That being said, the beta is the tine to show this to THEM, not just shouti g into the void",
      "I'm ok with every game having FSR2. Some people need all the frames that can get.",
      "> not just shouti g into the void\n\nThis is literally the best way to report bugs to the big studios. If they don't see it on social media, it's not a bug and they don't care. Source: worked at big studio.",
      "yeah, I am not saying it's broken, just pointing out that there are some problems with it in the beta.  Not trashing the implementation at all.  I reported the bug.",
      "Horizon has FSR1, completely different algorithm as It is spatial and not temporal. It doesn't work well when the game's native antialiasing is badly implemented",
      "You are talking about Radeon Super Resolution which is technically powered by FSR, but is not the same thing.",
      "Wow. That shimmer is bad. Hopefully Blizzard addresses it.",
      "Even outside of frames, sometimes FSR2 Quality can be a good replacement for poor TAA",
      "cant please everyone.  Earlier someone posted screenshots that FSR2.0 was supported and people complained about no images, video, etc.  Just posting some things i noticed for people who are interested...",
      "You have misunderstood how to use FSR. OP did everything right.",
      "Why is FSR needed on Diablo? How many FPS you get in native resolution?",
      "recommended for what though.. if it's for 1080p60, that's a pretty old target\n\nalso iGPUs exist",
      "FSR has a lot of shimmer in Horizon Zero Dawn also",
      "The best AMD card out, at 1440p you get loads of frames? Colour me surprised.",
      "Yes it is but fully expect to see it go live with everything you reported unless it's a game breaking issue. Graphical artefacts? Ahhh we can patch that when it's live.",
      "7900XTX 1440P maxed out I get 250+ fps",
      "This is literally the whole point of beta testing. As long as people with this error report it properly then it can be addressed.",
      "Not much will change from Beta to Release, Betas are almost entirely complete games with some small fixes at best before release. It's very likely this will stay for release aswell."
    ]
  },
  {
    "brand": "amd",
    "generation": "6000",
    "tier": "top",
    "matched_keywords": [
      "6950"
    ],
    "title": "AMD Radeon RX 6000 Refresh Gaming & Raytracing Benchmarks Leaked: 6950 XT Faster Than RTX 3090 For $1099, 6750 XT Faster Than RTX 3070 For $549, 6650 XT Faster Than RTX 3060 For $399",
    "selftext": "",
    "comments": [
      ">The following results are based on AMD's official data which has been presented to the media.¬†\n\nWill probably need to wait till independent reviews come out",
      "Considering the regular 6600XT beats the 3060 and the non XT 6600 trades blows the 6650XT beating it for $400 isn't anything to write home about \n\n\nIf it beat or matched the 3060ti then that would be interesting but I don't think it will making a kinda obsolete product especially as stock is more and more readily available",
      "I'd like to see 6950xt vs 6900xt @ 1440p and 1080p",
      "RX 6650 XT vs RX 6600 XT = 2% Faster\n\nSo this justified a price increase according the AMD, ridiculous.",
      "Accurate isn't the same as representative.  \n\nCompanies pick benchmarks that show their products in the best light.  That doesn't mean they aren't accurate.",
      "Yeah, whatever, wake me up when anyone makes a video card under $200",
      "I know right. Never trust this until you get independent reviews",
      "Just look at those ray tracing results for the 6950 vs 3090. They're trying to give the impression that AMD 6000 series is a few % behind, or even trading blows with NVidia for raytracing performance. We all know that that is simply not an accurate summary. I think the article was EXTREMELY charitable to AMD when they stated:\n\n>...there's a reason why AMD didn't focus that much on raytracing performance...\n\nThey cherry picked the few results that show AMD cards in a decent light (pun intended) and attempted to pass that performance on as typical. It's disingenuous and just further reinforces the reality that none of these companies are your friend and they all participate in misleading marketing. Early/Mid Ryzen was such a breath of fresh air. A defeated AMD came out and said the truth: \n\n>We got these chips that are \\[OK to great, depending on the generation\\] for gaming, they're really great for productivity and multi-tasking, and we're sellin' 'em cheap enough to be compelling. Also, we're going to have 5 years of socket support so that'll be nice.\n\nThat was enough for me to buy a Ryzen 5 1600, Ryzen 5 2600x, Ryzen 5 3600, Ryzen 7 3700x, Ryzen 9 5900x, Ryzen 9 5950x over that period. The BS marketing is a turn off after being spoiled by a relatively honest 6-7 years from AMD.",
      "They're probably accurate - AMD's benches for the RX 5000 and 6000 GPUs, to date, have been accurate. It is, however, common sense that you wait for independent third-party reviews from people who aren't sponsored by the vendor.",
      "Or when any RT is used.",
      "Because there'd be a huge uproar of gamers who have pre-RT hardware. Considering the (admittedly recovering but still...) state of the gpu market it's good that hasn't happened yet.",
      "That'd be interesting but to be quite frank the 6950XT performs as well as I expect it to. The Infinity Cache does too good of a job that it's up to core clocks to make the rest.\nAMD's focus on memory architecture/hierarchy makes it easy to find where performance is limited.\n\nEdit: By performing well I meant the weak performance increase on the refresh. Memory was never a bottleneck for RX 6800 and up; just like the Radeon VII and R9 Fury series.",
      "the 6800 msrp was $580 and beats a 3070ti and AMD wants you to think a 6750xt which is supposedly faster than a regular 3070 is $550 is a good deal??  Literally I cannot stand AMD the past year",
      "Which makes sense, since it's the only AAA title so far which requires RT to function. Everything else just uses RT as optional window dressing for their rasters, rather than an integral part of the rendering pipeline.",
      "Correct. Fully raytraced lighting is actually simpler to implement and compute in realtime than the compounded layers required for a good raster. Adding RT effects on top of a good raster kills performance, but replacing the raster entirely improves performance on adequate hardware.",
      "To be fair, it‚Äôs looking like the 6650xt will hang with a 3060ti at 1080p, but it obviously will lose ground as resolution goes up.",
      ">Beats the 3090 at what though? At 4K? At 1080p? At ray tracing?\n\nCherry picked AMD sponsored games.",
      "At 3dmark. 3dmark loves RDNA2",
      "According to Hardware Unboxed , the RTX 3060ti and the RX 6700XT have around the same performance\n\nhttps://youtu.be/pnZRuY-jFVM\n\nI doubt that the RX 6650XT would match the RX 6700XT\n\nAlso , according to data provided to reviewers through AMD's official guide , the RX 6650XT is just 2% faster than the RX 6600XT on average\n\nhttps://videocardz.com/newz/official-radeon-rx-6x50xt-series-gaming-performance-leaks-out-rx-6950xt-is-4-faster-than-rx-6900xt",
      "Absolute trash. Raising the prices that much on cards that don't perform better than 5% on average than their older counterparts? Ridiculous AMD, absolutely ridiculous."
    ]
  },
  {
    "brand": "amd",
    "generation": "6000",
    "tier": "top",
    "matched_keywords": [
      "6900xt"
    ],
    "title": "WOOO! Just achieved the second highest 6900xt port royal score in the world!",
    "selftext": "After the latest driver update I was finally able to push my 6900xt to the second highest port royal score in the world! Feels pretty good an I am extremely happy with the overclocking potential of rdna 2 especially if we are ever able to increase the voltage limit.\n\n[https://www.3dmark.com/search#advanced?test=pr%20P&cpuId=&gpuId=1353&gpuCount=0&deviceType=ALL&memoryChannels=0&country=&scoreType=overallScore&hofMode=false&showInvalidResults=false&freeParams=&minGpuCoreClock=&maxGpuCoreClock=&minGpuMemClock=&maxGpuMemClock=&minCpuClock=&maxCpuClock=](https://www.3dmark.com/search#advanced?test=pr%20P&cpuId=&gpuId=1353&gpuCount=0&deviceType=ALL&memoryChannels=0&country=&scoreType=overallScore&hofMode=false&showInvalidResults=false&freeParams=&minGpuCoreClock=&maxGpuCoreClock=&minGpuMemClock=&maxGpuMemClock=&minCpuClock=&maxCpuClock=)\n\nFor reference my build is\n\n\\-Reference 6900xt with ekwb custom loop\n\n\\-5950x on same loop\n\n\\-g.skills trident z 16 gb 4000 downclocked and tightened to 3600 cl14\n\n\\-2tb Samsung 970 evo\n\n\\-Gpu stats, 2740-2840 boost set, 1175mv, power limit increased to 365w max +15%, mem at 2124mhz fast timings.\n\nTo be clear I don't use those settings 24/7 I drop to 2700-2800 clocks and maintain around 2730mhz sustained 100%load in games, power draw around 330w. Still really happy with the score and hoping in the future we can get custom bios options to increase further.\n\n&#x200B;\n\nEdit - just to give everyone some more info, I made a post a while ago about my initial findings with overclocking the 6900xt. Those all pretty much stay true today. Basically if you have good cooling, maxing the voltage to 1175mv (which is what it runs stock btw), and upping your power limit by at least 50w or more through morepower tool should let almost every 6900xt perform about the same as me give or take. If you are power limited (like all stock cards) and you don't want to mess with morepowertool, then an undervolt will give you great results. and if you are thermally limited I'd do undervolt as well. You can see my post here with more details. There is a HUGE misconception that an undervolt with these cards is the end all be all. That is only the case if thermally or power throttled. [https://www.reddit.com/r/Amd/comments/kw0hos/some\\_info\\_learned\\_from\\_6900xt\\_overclocking/](https://www.reddit.com/r/Amd/comments/kw0hos/some_info_learned_from_6900xt_overclocking/)\n\nAlso a ton of people probably have an undervolt setting in place and don't even realize that it's not being used. The radeon software, or powerplay tables seem to do whatever the hell they want if they don't like what you put in. If you have say a undervolt to 1080mv it might not even be applied. To test this simply boot up your undervolt profile. download a program called gpu-z, most of you probably have that already. Launch your game or benchmark of choice that stresses the gpu 100% (this is very important). And then while it is running, launch gpu-z and navigate to the sensors tab, if it reads 1175mv for the gpu core your undervolt settings are being ignored.\n\nPlease be warned though, morepowertool goes past the power limits from amd and if you mess something up it can kill your card. I haven't heard of this happening yet, and it certainly hasn't happened to me but it is a possibility. Know the risk. The chances of it are very small I'd wager since amd tends to over engineer the boards a little but keep it in mind. ",
    "comments": [
      "OP  Nice.  I don't have one...lol   But brag away, thats a great achievement.  Yes I gave you gold because thats kick ass.",
      "Damn a lot of negativity in the comments.\n\nCongrats OP that's super cool! I got mine in the top 9% on air and called it a day haha. Should try again with the new driver.\n\nI really love this card from a pure hardware standpoint. I can't justify using it over my 3090 right now without a DLSS alternative but I very much prefer the 6900XT as a GPU. way less heat output, and OCing is fairly straight forward and rewarding, while for the 3090 wattage gets out of hand really quickly (I'm a SFF enthusiast).\n\nDo you by any chance have game benchmarks of your card as well? Shadow of the tomb raider for example.",
      "Thanks so much for the Gold! Really appreciate it, hopefully stock recovers soon and everyone who wants rdna2 can get it. They really are a great line up of gpu's if you can get them.",
      "That is literally a raytracing benchmark lmao. Though the amd cards simply cannot compete in raytracing, I personally don't care for raytracing so I'm very happy with my card.",
      "It's a raytracing benchmark",
      "Not that hard since 2 in total got produced",
      "Awesome dude.\n\nAlso, I‚Äôm impressed the #1 score is with a 5800X. That rocks.",
      "Thanks man, yeah I noticed quite alot of downvotes from this one lol. I imagine it's because so few people can buy a 6900xt let alone afford one. I totally get why some would be frustrated and maybe take my post as a way to brag(which it's not lol). I was just really happy with my luck and excited that amd is once again at the forefront with gpus. The results you can get on rdna 2 from overclocking remind me of the golden overclocking days 10 years ago. Congrats on getting both of your cards as well!\n\nEdit- also I don't own shadow of the tombraider, which I would be very interested in benchmarking since I know that game typically sees amd far in the lead. I could run through ac valhalla, cyberpunk, and a few others if it's really of interest to people.",
      "just look at all those ryzen cpus in top 50+ :D\n\nas for OP congratz, must be quite nice, how long did it took for you  to reach that score?",
      "lol I def Got lucky being able to snag mine when I did off Newegg. Coming from a vega 64 it made an insane jump that was badly needed for me.",
      "Darn it Ricky Bobby you right",
      "While we're making people feel shit about their purchases, lucky you spent so much on a 3090 so you could get the same score I got with my 3080.",
      "Port royal is a gpu exclusive benchmark, so cpus have little impact. However they probably do influence dropped frames and stuttering a bit so a 5800x with higher clocks than mine could influence the results, albeit only a small amount.",
      "I don't really understand your comment. Amd cpu's are now legitimately better than intel in every use case, hence the higher price now. They have also been killing intel in market share. If you are referring to the scores in port royal. 1. it's a raytracing benchmark and NVidia is way better at that, and 2. cpu really makes almost no difference in this test minus maybe a few percentage points since it's a gpu only benchamrk.",
      "Glad there are other that don't care for raytracing. Lol",
      "Hopefully the rumors are true and stock will start to stabilize over the next few months. But then again we've heard that one before...",
      "I know I can't compete with NVidia when it comes to raytracing but I just wanted to share my excitement from just how much I was able to push out of my card. Before I put a custom loop on it and upped the power, my reference 6900xt was around a score of 9500 in port royal. So it has improved a huge amount. \n\nCongrats on the 3090 btw, that's an amazing card as well.",
      "I wrote \"in the world\" because that's exactly what it is. The second best 6900xt score \"in the world\". I mentioned nothing about any other cards.",
      "Oh, no I wasn't talking about AMD vs Intel in normal desktop use. Hell, look at my flair, I have a 3900X in my own system. I was just more stating the fact that in overall scores, the XOC community seems to still prefer Intel.",
      "Hmm yes, I know some of these words. Congratulations!"
    ]
  },
  {
    "brand": "amd",
    "generation": "6000",
    "tier": "top",
    "matched_keywords": [
      "6950xt"
    ],
    "title": "AMD launches Radeon RX 6950XT, 6750XT and 6650XT graphics cards - VideoCardz.com",
    "selftext": "",
    "comments": [
      "Another difference is the price tag, but not in a favorable way..\n\nNotice how none of those charts AMD made actually compare against their predecessors?",
      "But where is the difference other than power draw and slightly more memory bandwidth?",
      "6650 xt for $400 and the 6750XT for $550\n\nLMAO.\n\nTHis means the 7700xt will be $550.\n\nThe 5700xt was $400 ffs.",
      "My 5700 non xt was 329 before tax. FFS. A full PCIE 4.0 16x card with 8 Gigs of VRAM that could drive anything at 1080p and most games easily at a 1440p. Compared to 2021 / 22 pricing, it seems almost insane.",
      "Its quite telling they are not comparing it to the regular 6600XT, 6700XT and 6900XT because the uplift is probably 5% at most and would make the price incease compared to the models that launched over a year ago comical.\n\nWe're probably in for a trashing in the reviews once the embargo lifts in a few hours.",
      "well ofc there's msrp bump, why wouldn't it be. That was whole point entire time. 18Gbps memory is barely more expensive - otherwise they wouldn't be putting it on RX 6500 XT.",
      "Sadly yes",
      "The MSRP reflects that AMD is in their position to keep increasing margins and milk the desperate consumers a bit more.\n\nAMD keeps pulling one highest profit year after another. Production costs increases are negligible, especially third year on the same GDDR, the same core fabrication which got cheaper with long ago not being the cutting edge node, and with yields continuously improving.\n\nThere's not a single proof manufacturing got meaningfully more expensive for AMD, inflation completely notwithstanding.",
      "Oh no, with his 6900 XT, what a nightmare.",
      "Buying a 5700XT for 400‚Ç¨ felt like the best purchase ever made. Strong card for comparably cheap price. I always thought it would be a stopgap for the next gen big card. Oh how wrong I was. \n\nI hope the 7700XT will be cheaper but I'd guess Nvidia is raising prices and for some reason AMD just doesn't want to compete on price.",
      "7xxx series will probably be positioned way higher performance-wise and price-wise. Only the 6950XT is probably in the same performance tier as N33, but others are higher.",
      "The pricing is likely reflective of what AMD views at the least medium term outlook for GPU pricing to be and they have much more data than consumers/media/etc. to work with. The rumored pricing of Intel's roughly 3060 competitor being $380 also supports similar predictions.\n\nThis means it seems like they feel that the RTX 3060 will likely stall around the $400 mark as opposed to falling down to MSRP range in the low $300s. Likewise the 3060ti will remain around the $500 mark versus falling down to the low $400s. In other words the overall downward price trend for GPUs has reached a stall point.",
      "Well... as nVidia, this is just a cash grab.\n\nI'm tired of this stuff.\n\nThe prices are still a joke, even for the older models...",
      "God, why is AMD so fcking shit again? Why do companies build their reputation up for years and then say \"You know what? Let's forget about that and take the most stupid business decisions we ever could\"",
      "I wonder if they gave salary increases relative to inflation to all their workersü§î",
      "topkek - poor AMD should launch Patreon, so people like you can give them all the money üòÇ",
      "The point is not the performance, absolutely isn‚Äôt. The ONLY point for their existence is to refresh the MSRP. No more, no less.",
      "The 6950 is actually up on Newegg for $1100. The cheapest 3090ti is $2000. I think it is a win simply based on being $900 cheaper for nearly the same performance.",
      ">Don't always whine about businesses\n\nWhat's with the boot lickers in this thread trying to sympathize with a multi billion dollar corporation and defend this blatantly obvious cash grab? We all understand how businesses work, no one expects them to be a charity. If I feel like I'm getting bad value for the price I'm supposed to pay, of course I'm going to point that out.",
      "One of the best purchases I made, gamed like all hell during the pandemic, bought a 3080 at MSRP and sold the 5700xt for like a grand during the craziness"
    ]
  },
  {
    "brand": "amd",
    "generation": "6000",
    "tier": "top",
    "matched_keywords": [
      "6900"
    ],
    "title": "new chunga 6900 xt tuf vs my old 1070!",
    "selftext": "",
    "comments": [
      "Might be unpopular opinion but I don't like that cards are becoming this massive.  I like when a card can fit in my case without a need for a GPU brace.  Even more frustrating is when they slap those huge coolers on a 220w 3070 8gb  or something which seems like a massive waste",
      "Chonky",
      "I was like that with my new card. Had a 1080 zotac amp extreme and I was like \"Chonkyboi, surely ain't gonna get any bigger than that\". Cue the 6900XT Red devil ultimate...",
      "It's ridiculously big üòÖ",
      "Coming from r/sffpc I agree. Need smaller, shorter, thinner and more power-efficient cards!",
      "Feel ya.... Have the XFX Merc which is even bigger and heavier lmao",
      "As a owner of a TUF 3060 Ti, I happily paid 50 extra to get it to be as quiet and high quality as possible. So, it might be a waste, not for everyone though.",
      "That was my next pick, but I I liked the more plain look of the tuf cards.",
      "I'm into SFF PCs, it's even worse. And my case isn't even that small!",
      "Longest, thickest (after the Aorus Master...) and heaviest card",
      "Totally agree but the tdp of the 6900 xt and 3080 ti 0ull upwards 300 watts, it's either this or water for the higher tdp cards.",
      "Still in service best GPU I've ever had price performance etc, awaiting CPU and ram and I'm good to go.",
      "Isn't the Merc one of the longest cards?",
      "Wow 2kg is impressive",
      "why would you buy a 6600xt for $936? where are you lol \n\nThey were available easily under 600$ last week",
      "I bet that 1070 served you well",
      "> Even more frustrating is when they slap those huge coolers on a 220w 3070 8gb or something which seems like a massive waste\n\nBetter cooling and a lower noise level is not a waste. Hopefully we get more 5 slot cards where you can strap regular 120mm fans onto soon.",
      "> I had a 3070 xc3 which is a dual slot 285mm card and it never went above 66c.... There is no damn point, that is plenty of headroom to overclock.\n\nAt what wattage and fan speeds? The point is that you can adjust the fan curve to be quiet or you can go ham with overclocking. \n\n>If you're concerned about noise then people like you will just go water cooling anyways\n\nNope, it's a pain in the ass to assemble and service.",
      "Oh I agree, I'd already waited months. It was my 'retirement gift' build for myself but it took so long to get parts that it didn't get done until months after I retired.\n\nAt some point you just want it over with.",
      "Funny is also how even the TUF looks small when its side by side with the XGX Merc lmao"
    ]
  },
  {
    "brand": "amd",
    "generation": "6000",
    "tier": "top",
    "matched_keywords": [
      "6900xt"
    ],
    "title": "Gaming PC with Radeon RX 6900XT GPU can still cost less than GeForce RTX 4080 alone - VideoCardz.com",
    "selftext": "",
    "comments": [
      "You can build a crazy good PC with a discounted 6700XT or 6800XT right now.",
      "I laughed so hard at [the video](https://youtu.be/UmjhPuMI9Es). He has great delivery.\n\nAs Tim of Hardware Unboxed said, the problem with the 4080 is that people with a lot of money will simply go for the 4090.",
      "Yup, just ordered an Asus TUF 6800XT for half the price of most 3080s in my area. Really excited to install it tomorrow",
      "Yep. If you get a 6800 XT right now you‚Äôre getting about 70% of the gaming performance of the 4080 for about 40-45% of the money. That‚Äôs absurdly good value.",
      "I can say that 6900XT has been a really good experience to me. It was a very expensive purchase at the time (with Brexit and Lockdown), but it was worthy.",
      "I just got all the parts for my son's first build.  5600G, 16GB ram, 6650 XT, 1TB nvme, 27\" 144hz freesync monitor, keyboard, mouse.  Everything.  For $500 (CAD) less than a 4080",
      "Yup, the funny thing is Nvidia is so overpriced that even in RT, AMD trades blows or narrowly loses with them.\n\n6650 XT vs 3050\n\n6700 XT vs 3060\n\n6800 XT vs 3070\n\nHell I saw a 6700 discounted to 300 yesterday, and it's like ~25% faster in RT than the 3050\n\nHowever we have started seeing the 3050 *finally* being discounted to 270. But even at that price the 6650 XT absolutely curb stomps it in raster and wins in RT.",
      "I truly hope NGREEDIA get shit on financially this generation. In Australia where I‚Äôm from, some of the high end 4080 cards cost as much or more than low end 4090 cards‚Ä¶. \n\n$3000 Australian for a Strix 4080, or $2950 for an Asus TUFF 4090 \n\nTime for nvidia to lay down the crack pipe, here‚Äôs hoping the 7000 series isn‚Äôt priced poorly and AMD wins this generation",
      "> For $500 (CAD) **>>>less<<<** than a 4080",
      "I guess there's always something newer and better around the corner. I don't need the best of the best since I'm always behind on new game releases and still mostly play modded Skyrim.The 2070S was overkill for my needs back when I bought it and so is the 6800XT. I don't know your situation, though haha",
      "dont forget to DDU nvidia drivers before installing AMD gpu",
      "The charts were my favorite part haha.",
      "2070 Super. Should give me a tiny little performance uplift ;)",
      "I would rather buy a 6900 XT then a 4080 despite having problems with AMD drivers, but please AMD fix your MPO issues already Nvidia fixed this 2 years ago....",
      "I paid far too much for it than I'd like to admit, but it was an excellent purchase. Cool, quiet and powerful. One of the best cards I've owned.",
      "Thanks for this video, that was really funny tho",
      "What are you upgrading from?",
      ">People rushing in to buy 4080\n\nDoubt almost every store in Germany has a large number of different models still in stock. When compared to 3000 they were basically out of stock everywhere for the first 2-3 months",
      "I somehow struck gold and saw a xfx 6800xt Merc at an online amazon returns auction last week. Won it for $280 and when i went to go pick it up it was sealed unused in the box. Much better than my 1080.",
      "I can find the RX6900XT for the price of an RTX3070 Ti and the RX6800XT for less than the price of an RTX3070.\n\nI really want to buy one of them but the RX7000 are just around the corner :("
    ]
  },
  {
    "brand": "amd",
    "generation": "6000",
    "tier": "top",
    "matched_keywords": [
      "6950"
    ],
    "title": "My RTX 3070 Ti was struggling with 8GB of VRAM in some titles so I bought RX 6950 XT Red Devil for 709‚Ç¨ with The Last of Us game included. This thing is a beast and very quiet too after slight undervolting.",
    "selftext": "",
    "comments": [
      "Oh, the mighty Red Devil! Congrats bro! Enjoy your new GPU!\n\nI also got one recently, mine is a Sapphire Nitro and it‚Äôs been wonderful so far\n\nhttps://preview.redd.it/omwyohjgwova1.jpeg?width=3921&format=pjpg&auto=webp&s=0db60f7949dd14fe6979eb855a3caa058c6ca63b",
      "Seems many may be moving over to AMD from Nvidia . I made that move when the 1060 had 6gb VRAM and the 480 had 8gb",
      "Just out of curiosity, did you manually undervolt or did you leave it to auto-undervolt via the Adrenalin software? Build looks great, I love that all-black builds are making a comeback!",
      "Thanks! I just left core clocks to default which is 2669Mhz and lowered voltage from 1200mV to 1150mV. Any lower and I couldn't pass Time Spy stress test.",
      "It's 300‚Ç¨ more expensive in my country.",
      "Which titles gave you VRAM issues? I have a 3070Ti currently and I‚Äôm just curious where it starts to get bottlenecked in that area.",
      "I'll quote from another post I saw covering this topic, I think the redditor who made the comment nailed it on the head. \n> For years game devs gimped their own games to fit into 8GB VRAM, but now that PS4 support died they have collectively decided. nope. Textures alone will be 12GB or more.",
      "I find the whole VRAM situation pretty strange. I'm on 3060 Ti and I played through TLOU without problems, mostly 60 fps.",
      "Same here, but I got a 580. It really pulled out ahead of the 1060 later in its life.",
      "the 6gb version wasnt even the problem back then but the 3gb ... that card was so fucking shit",
      "With latest patch it's way better even if you don't have enough VRAM. Frame Time isn't great when you don't have enough VRAM, some stutters here and there can be felt. If you played at ultra settings, I doubt you didn't have any issues with a 3060ti, my friend had to lower textures on his 3070 for a stutter-free experience.",
      "Should be about 35-40% faster is raster and double the vram, so if you sell the 3070ti it‚Äôs a pretty solid upgrade.",
      "Are you being serious?",
      "Looks nice! You should adress the sag on the GPU though.",
      "In what way would this be a downgrade? 6950xt is on 3090 ti level performance",
      "Because it wasn‚Äôt comparable to the 6GB version even without taking the VRAM into account. It was such a scam",
      "Last of Us, Hogwarts Legacy and Dead Space Remake would all struggle with 8GB depending on the settings.",
      "A new PSU is not going to help with screen tearing, that's a monitor thing.",
      "I'm still rocking my Merc 319 6900 XT, very happy with it. Doubt I'll upgrade for the next 3-4 years, at least.",
      "I got the Nitro last week.\n\n10% more expensive than the other 6950s, but totally  worth it.\n\nThe overclock/undervolt potential is great so far."
    ]
  },
  {
    "brand": "amd",
    "generation": "6000",
    "tier": "top",
    "matched_keywords": [
      "6900"
    ],
    "title": "Will my Thermaltake 700Watt 80+ White PSU be able to handle Sapphire Radeon RX 6900 XT Limited Toxic Edition?",
    "selftext": "",
    "comments": [
      "If you can afford that gpu you can upgrade your psu.",
      "Don't cheap out on the PSU for a beast like that sapphire. You'll run into problems.",
      "Buy a high quality 850-1000W unit if you're buying a $2k gpu.",
      "This.",
      "In this case it is far from flawed, that power supply is not a good unit, OP NEEDS to upgrade.",
      "Relevant: [https://linustechtips.com/uploads/monthly\\_2021\\_10/image.png.8cce558fcdfd2537514813b6089df2ec.png](https://linustechtips.com/uploads/monthly_2021_10/image.png.8cce558fcdfd2537514813b6089df2ec.png)\n\nAll Smart psu's from Thermaltake are trash.",
      "I'm not saying that because you can afford one thing you can afford another, I'm saying in this case if you can't afford a new power supply, you can't afford that graphics card. \n\nThat particular power supply is not good for 750 watts of load, it is a cheap unit with a big number on the side. OP needs a power supply, or they'll end up killing their current one and having to buy a new one anyways, or they'll kill the graphics.",
      "Yepp get at least an 800 watt or 850 watt and a quality one. Like a Seasonic Prime.",
      "If you want your $1500+ gpu to blow a cap trying to clean up sloppy input voltage it's getting from your psu or regularly trip OCP, possibly leading to you needing to power cycle it constantly, then go right ahead and fill your boots. Iirc, the minimum recommended spec is something closer to 1000 watts +, and you really shouldn't be cheaping out if you want your card's input filtering to last.",
      "I'll be short with you, 700 watts is probably enough for this GPU in some circumstances, but if you want this GPU to hit it's full potential in games, you're running a pretty high end CPU. 700 watts probably isn't enough and AMD recommends higher than 700 watts for a reason.",
      "700 still ain't enough for this card, I have a system with a 5800x and a 6900xt that pulls down 670 Watts in some situations.\n\nOh and it's a card with no overclocks, 700 isn't enough and you don't own the card to advise on this, I do.",
      "....Except a PSU is nowhere near the RRP of a 6900XT and they're directly related?\n\n\nIt's the same exact analogy as saying if you can't afford to maintain a vehicle, you can't afford the vehicle.",
      "I think the 6900xt is a lot more efficient than the 3090.",
      "What do you mean 'nope' lmao, even retail a 6900XT is $1000USD, a quality PSU is <$150.\n\n\nRegion and finances do not matter because power supplies are cheap relative to a literal top of the line GPU - hence why your argument is nonsense.\n\n\nIt's like buying a car that calls for premium fuel and putting lower grade fuel in it because you can't afford it lol, it makes absolutely zero sense.",
      "Okay so lots of replies here aren't going into _why_ the PSU is bad. \n\nThere are two reasons: (1) Brand and quality of components (2) The White rating is very low\n\nQuality of components means a lot more on a PSU than it does, say, a motherboard (though tbf it matters there too, the results just won't be as catastrophic). A PSU with low quality components can perform to _specifications_ (ie can it supply 700W peak) but the average capacity (RMS) will not be anywhere close to that. Which brings me to the White rating\n\nThe ratings of a PSU tell you how efficient the power supply is input vs. output. A higher efficiency (among other things) means less of your input power is wasted as heat. So if you have a super low efficiency PSU, your 800W at the load looks a lot more like 925W at the wall. Taking this (very oversimplification, apologies to any EE who reads this) toy example, we can estimate that 20% of the load (125W) is expelled as heat, resulting in 80% efficiency (the 80+ part). 125W of heat is more heat than your CPU TDP, and the PSU doesn't even have an AIO to keep it cool. So what happens when the PSU starts to get too hot? One of two things:\n\n1. The voltage is what it is and may droop a bit, but the current may be limited at the PSU causing a cascade of components to summarily reduce their performance because they can't draw enough power without reducing their own voltage. This could result in slowdowns or (more likely) hard resets if it happens very fast. \n\n2. The PSU components (being the above brand, this is likely) will fail and either (1) send a voltage spike through your system frying your $2k GPU/mobo, etc. or (2) melt and cause a short (shutting everything down), hopefully before reaching the flash point of any component at the short point and igniting something (or both of these could happen). \n\nMoral of the story, as others have said, if you have this GPU that's awesome, in this climate I'm sure you earned it. But please wait to put it in your system until you can get a better PSU. Patience may save you both money and your dwelling.",
      "Does this \"simple research\" include looking at the website for the actual card itself? Because if it does you need to take a look at your reading comprehension skills. Sapphire recommends an 850W PSU as a minimum. Could you theoretically run it on a 700W PSU, probably, if you use a low power CPU. Should you? Absolutely not, because your options are a) reduced performance/random shutdowns from lack of power, or b) reduced performance due to CPU bottleneck.",
      "Honestly, it probably could with a 65W TDP processor, but if you go all out on a GPU **don't cheap out on the PSU**.\n\n&#x200B;\n\nBTW, spending money on a bigger & better PSU is not a waste, rumors suggest crazy TDP numbers for new GPU's next year, you would need an upgrade anyway.",
      "If anyone thinks that running a PSU at its limit in the long term is a good idea for either the PSU or the expensive components that are plugged into it, then they do not know enough.\n\nEdit: Especially with an 80+ white rating",
      "You are a giant doucher, no doubt about that.",
      "How's this for your logic - if OP can afford that GPU but can't afford a PSU to run it properly then wtf is the point of buying that GPU in the 1st place.\n\nExactly..."
    ]
  },
  {
    "brand": "amd",
    "generation": "6000",
    "tier": "top",
    "matched_keywords": [
      "6900xt"
    ],
    "title": "I just built my first all AMD build with a 5600x and a 6900xt and wow it‚Äôs amazing! My last pcs for the past 8 years or so were all intel/nvidia. Gaming at 4k with zero issues! (new cpu cooler coming soon)",
    "selftext": "",
    "comments": [
      "congrats... and im still frustated to build now or wait for ryzen 7000...",
      "just build now, you would need an overpriced gen 1 mobo full of bugs, as well as over-priced DDR5. Unless you like beta testing than go right ahead and wait. Leaks arent showing much of a jump worth waiting for anyways atleast not in IPC terms. The multicore jump is pretty decent though.",
      "I'm so proud that everyone going for XFX these days. They mastered the design for this generation.",
      "The 2x performance claims I feel are a bit overestimated. They said the same things about this gen and it turned out to be untrue",
      "They also claim the new GPUs will draw 600W on the high end. \n\n2x the performance for 2x the power‚Ä¶I‚Äôll pass and keep my room not a furnace.",
      "I feel you. I‚Äôm in the same place. \n\nI‚Äôm in no rush but at the same time I‚Äôm impatient lol.",
      "Someone offer me this specs for $1200, all parts is brand new, should i get it now?\n\n- Amd 5600x\n- Rog strix RTX 3070 \n- Rog strix b550 wifi\n- Samsung 970 evo 500g\n- Corsair ram 16gb 3600 RGB\n- Rog PSU 650w",
      "You don't need to upgrade to ZEN4 to run RDNA3. The cards are PCIE5 but you can run them on a PCIE4 slot without issue, they still won't saturate the bandwidth available. PCIE5 is more relevant to data transfer on storage.",
      "You can run a 6900xt on PCI-E 3.0 x16 without performance hits.",
      "that's gonna cost $2000 and use 2x the wattage though",
      "10% IPC and 10% clock speed gains is better than most.  Intel incremental gains every year, now we get competition and some real gains.  I really wish games became more multi-core aware.  I am waiting until bugs are worked out, so went ahead and grabbed a 6900XT when prices dropped.",
      "I have the same exact card. Love it.",
      "You have a tiny desk, yet you still put your tower on it. Seems reasonable.",
      "Same CPU/GPU combo with me. I‚Äôm grateful that I am blessed to be able to afford such a rig. Ultrawide 1440p gamer here.",
      "I have a nitro+ 6700xt and xfx are second on my list. I don't care for strix",
      "They are beautiful cards, this one is the merc319 black",
      "LONG LONG MAAAAAAAAN!",
      "Ah.  I was going to ask about that.  If that is the circumstance, it's probably worth it, by the time you put tax/shipping, etc., on there, then that is probably close it sounds like.",
      "Good combo. Have a nice gaming sessions",
      "I like looking at it lol"
    ]
  },
  {
    "brand": "amd",
    "generation": "6000",
    "tier": "top",
    "matched_keywords": [
      "6900"
    ],
    "title": "AMD Radeon RX 6900 XT Scores Top Spot in 3DMark Fire Strike Hall of Fame with 3.1 GHz Overclock",
    "selftext": "",
    "comments": [
      "Honorable mention: The top 2 Time Spy scores are with 6900XT's in crossfire",
      "This in on liquid nitrogen. So not a daily overclock.",
      "to set new world records?",
      "It's technically not Crossfire (driver level multiple GPU rendering) but DX12 multi-GPU rendering (API level multiple GPU rendering.)\n\nBasically the game/program needs to implement DX12 multi-GPU, whereas Crossfire would be handled by the Radeon driver.\n\nCrossfire has indeed been phased out. Whereas DX12 multi-GPU is still a thing (however it's rarely implemented and only a few applications/games support it.)",
      "Jeeeeezzzz Im jealous.\n\n\nMy XTX only does 2,68GHz max lol",
      "i'm fairly ootl, but how do you xfire these cards? i thought the tech's dead and you'd need an xfire cable/bridge?",
      "Key to success for 24/7 OC is MorePowerTool - my 6700XT @ 2.8Ghz sustained is faster then my 2080Ti.",
      "It's like top fuel drag engines. They're basically good for 45 seconds of runtime.\n\n&#x200B;\n\nWait maybe it isn't. Top fuel classes have all sorts of limits and restrictions.",
      "Jzuz I thought 2.7 ghz is much on my 6700xt. I know they are using LN2 or liquid helium, but still RDNA 2 clocks are very impressive.",
      "remember playing rise of the tomb raider with dual rx 480s through dx12 mgpu. That worked quite well with good frame times but also one of the few implementations I can remember.",
      "I set my liquid Devil to 2800mhz and it will go higher but I don‚Äôt want to risk it.",
      "Yeah. That‚Äôs exactly right.",
      "Yeah, because the manufacturers have gotten much better at manufacturing and thus getting out the highest possible clock speed with no instabilitys. But I am just impressed by the gpu architecture itself, because despite of crazy clock speeds RDNA 2 is still more efficient than Nvidia at the moment.",
      "Yeah, you're not running liquid nitrogen cooling for any gaming session. These get turned off super quick after the benchmark is done because of the condensation that builds up on the tubes.",
      "I wanted to go team red so bad when I built my pc a few months ago. Got an opportunity for a 3060ti though after months of looking and had to bite the bullet.",
      "Honestly, compared to the good old days it's not even that much of an overclock over realistic 24/7 use.",
      "What are your settings? I have a red devil ultimate with an alphacool block on it. It runs cold asf but after 2650 it seems to be power starved. I can get it stable 2750 easy but it seems to perform worse because it needs more power. Im thinking I might need MPT?",
      "Its super simple:\n\n\n- 1st use gpu-z to save your current bios\n- run MPT\n- click import, select the bios you saved\n- go to \"power\" tab\n- change the power limit to what you want it to be\n- click write SPPT\n- reboot\n\nNow your card has an increased power limit.",
      "In this application it's crossfire over PCIe since it's a DX11 benchmark and AMD has been doing bridgeless crossfire since the R9 290 series",
      "I have almost the same setup as you. Red Devil (non ultimate) on an alphacool block. My everyday stable settings are: \n\nMPT:\n\n* 330 Power Limit / 350 TDC\n\nRadeon Software:\n\n* Max Freq: 2700 MHz\n* Voltage: 1075mv\n* VRAM: 2100MHz  w/ fast timings\n* Power Limit :+15\n\nThis is good enough for a 22,600 GPU score in Time Spy. \n\nI've read that there may be issues with clock stretching, so even though you have higher clocks, if there's no performance uplift, you're just unnecessarily making more heat for yourself.\n\n."
    ]
  },
  {
    "brand": "amd",
    "generation": "6000",
    "tier": "top",
    "matched_keywords": [
      "6950"
    ],
    "title": "[HUB] Radeon RX 6950 XT or GeForce RTX 4070, Which $600- GPU Should You Buy?",
    "selftext": "",
    "comments": [
      "Preparing for the war in the comments ![gif](emote|free_emotes_pack|flip_out)",
      "Especially since he recommends the 4070.",
      "I'm so incredibly confused. I was repeatedly informed by reddit that Steve was an AMD shill, yet he recommended a Nvidia product?",
      "Tbh the value play would be the 6800xt for $500 (While stock lasts)\n\nNot really a right answer between the two though, pros and cons to both\n\nI'd choose the 4070, getting DLSS and using 150W less is more important to me",
      "For AV1 and lower power draw, which given he streams kinda makes sense for that use case.",
      "Used 3090s average over $800",
      "I went from a 3070ti to a 6950xt. It might just be me but ray tracing isn't what others describe, could be my old eyes. I barely notice the difference in games that are supposed to showcase it like cyberpunk, metro, doom, or dying light 2. That could very well be different on the 40 series but I see no point in following ray tracing till it's more of a standard in games other than triple A titles. I noticed the difference in say Minecraft but that's really just Minecraft getting an update to old visuals. I play loads of single player titles and in every one of them ray tracing was a gimmick for a few things that just tanks fps. \n\nI'm pretty happy with my 6950xt but I also still have my 3070ti if I ever get the itch to stream, record, or play Minecraft with RT on. Similar story with DLSS vs FSR 2, FSR 1 wasn't great but 2 is good from a performance standpoint and I'll see what 3 offers but they all feel like gimmicks.",
      "and 3090s consumer up to 450w, while a 4070 sits at around 200w, not sure about him, but power bills have increased considerably in my country over the last few months.",
      "I haven't seen Intel/Nvidia Unboxed, but I have seen AMD Unboxed and Nvidia Foundry.\n\nFunny how they are fanboys of everyone depending on who you ask though.",
      "Did you play the normal version of Metro? Because Metro RT on vs off has HUGE differences with the Enhanced Edition where they rebuilt the lighting system completely. \n\nTake a look. Side by side it's a complete different game. Runs better than the raster version too (which is strange lol). You should try it, it's a great game\nhttps://youtu.be/pmpwMiSDYP4",
      "I can't even disagree. \n\nAfter using it, DLSS3 is an extremely compelling feature despite its flaws. Running around in RT overdrive at 80-90 fps in CP77 on a 4070 is something nothing from AMD can do (even if they get an FSR3 frame doubler the base RT performance isn't there on a 7900XTX. Maybe RDNA4 will get it right.)\n\nIt's a great experience for single player narrative driven stuff.",
      "I agree with him although the 6950xt generally performs better without RT. I don't think either is a bad choice though at the same price, maybe the 7800 series will be more competitive.",
      "It would have lined up perfectly if the the 7900XT was a 7800XT as it should have been. \n\nAMD wanted that sweet $ upcharge without having the performance/pricing gaps for the rest of the SKUs.\n\n7900XT at $900 was a big blunder. Period. Now it's dropped down to $750ish range headed towards $700ish and leaves little room for a 7800XT. Would not expect anything different from the AMD Radeon team tough. It's no wonder they took ATI's near 50% market share in this segment and pretty much nearly lost it all.",
      "None of the above. New 4070 costs similarly to a used 3090 (if you find a good deal it's within $50 in some cases). Except 3090 has twice as much VRAM and actually performs better in games (it also outperforms 6950XT).\n\nPersonally I **really** don't see a point of spending 600+ USD on a 12GB VRAM card that also happens to be the weakest xx70 in a looong while (compared to full sized dies). This thing is gonna be dead within a generation so there's no difference between it and outright buying a used card.\n\nIf it has to be AMD - there are thousands of 6900XTs on ebay often sold at below $500. It's going to perform almost the same as 6950XT.",
      "> (it also outperforms 6950XT).\n\nit doesn't. \n\nit also consumes almost double the power compared to 4070, and it is a potential risk to buy used due to VRAM temp issues they had. And 3090's are much bigger, so 4070 is more likely to fit your case and you don't have to have a really powerful psu like you do for 3090 thanks to power spikes.",
      "Or you don‚Äôt live in a country where electricity has skyrocketed in the last year.",
      "Majority of my time is spent in FS2020.  I'm leaning towards 4070 for DLSS3 and VR.",
      "I would too. 6800XT for $500 isn't that compelling, I'd rather spend the extra $100 for a 4070. Will make up the $100 difference power cost alone in next couple of years of using it.",
      "I really think a proper DLSS 3 competitor should be an all hands on deck situation for AMD. Doesn't matter if they can get a 15% performance advantage natively if Nvidia can just double or triple theirs at the quality DLSS 3 delivers. \n\nI'd go as far as saying anyone who dismisses the technology simply hasn't tried it.",
      "Why go either or when you can have both."
    ]
  },
  {
    "brand": "amd",
    "generation": "6000",
    "tier": "top",
    "matched_keywords": [
      "6950xt"
    ],
    "title": "First AMD build! 5800x3d, 6950xt, 32gb 3600mhz and of course, torrent:)",
    "selftext": "",
    "comments": [
      "I really want that case...but at the same time my 4000D Airflow was only $90 lol",
      "Yeh, i was between this and 4000 or 5000d. This one was around ¬£160 with discount, not cheap, but ƒ∞ really like its design and the airflow/temps are just crazy!!",
      "ƒ∞ mean, 5800x3d was not exactly cheap but i have the motherboard and the psu and the rams, so came cheaper if you compare it to building a new setup with ddr5 and 7000 series. And was lucky enough to got the 6950xt for ¬£815, even 3080tis was around 900.",
      "Fractal torrent. I have one. One of the best airflow cases on the market.",
      "Real value PC... Epic build My man!",
      "Yup. Like even now, for gaming, a 5800x3d system with a Decent B550 is half the price compared to a 7700x system. And the gaming performance is like equal or close to it.",
      "Exactly! 350 for cpu, 250 for new gen mb, 200 for ddr5 ram, thats 800 for the new gen. ƒ∞ paid ¬£400 for the 5800x3d, 150 for my b550 tomahawk, 100 for the ram, thats 650 and ƒ∞ spetlnt the extra 150 on gpu",
      "Its cheap compared to the shitty new overpriced AM5 stuff.",
      "Absolutely banger! All the hate towards amd, especially gpus and the software. ƒ∞ am coming from a 3060 build and let me tell you, ƒ∞ fucking love the adrenaline and 6950 is crushing whatever ƒ∞ throw at it",
      "Idk about value I'd call that a banger tho",
      "The torrent is truly a master class. I‚Äôd change a few things about it. Like maybe more metal, but that‚Äôs nitpick stuff. It‚Äôs beautiful, spacious, and feels premium even with some of it being plastic.",
      "Yeah, very overpriced and not that great of an improvement if you ask me",
      "What mb and psu is that? Nice build",
      "Is it better than the meshify 2? I'm in the market now for a quiet airflow case.",
      "My setup has x2 180mm fans in the front and three 140mm at the bottom, all intake. The cases usual setup is all intake. It looks like OP has exhaust but in my testing it was pointless. The PSU is mounted at the top and actually acts as an exhaust fan. Very old design, also very effective. You don‚Äôt see it a lot anymore.",
      "5800X3D is not a value cpu, neither is 6950. Step to 5700X/6800XT and you retain 80% average gaming performance but costs 40% as much.",
      "Agreed software is 100x better",
      "Yeah reusing parts you already have is the best part of AMD, my build has been upgraded from the first gen Ryzen AM4 launch in April 2017. If only the bios update came out sooner for my X370 crosshair VI hero I woulda kept using it to this day. Oh well I turned it and my old R7 1800x into a beast server.",
      "That is sweet set up. I really want to build in this case one day. Trying to talk my kids into one. Really like the looks and function of it. You set this up nicely.",
      "Building tmr the same build but in lancool 3 will post soon"
    ]
  },
  {
    "brand": "amd",
    "generation": "6000",
    "tier": "top",
    "matched_keywords": [
      "6950"
    ],
    "title": "Upgraded my 5700 XT to a 6950 XT last week",
    "selftext": "",
    "comments": [
      "You should definitely run two different pcie cables.",
      "Yeah I just made the switch after initially being stubborn about it with another redditor. Never knew that was a thing.",
      "That's around 100% performance boost dude enjoy.",
      "Why people hook hungriest gpu on single pcie cable?",
      "Yeah one of those cables is rated at 150 watts. You‚Äôre drawing over 300 on a single cable + the pcie slot itself. Better to be safe than sorry",
      "Its two 8 pins from single cable, even if its less power hungry than 3090, doesnt mean that single cable can provide enough power for the strongest 6000 series card",
      "If there‚Äôs more than one plug it‚Äôs good practice to always use different cables for each plug",
      "Eat my ass\n\n*With love <3, and a bit of jealousy*",
      "Well, if there's any weird instability you know a probable culprity. This is consided poor \"workmanship\" when building a PC, sometimes the single cable can't keep up with the transient loads and what not",
      "Im far from mad, im amazed how people can be stubborn and ignorant. You have advices from amd directly to use two separate cables instead of piggy tail back on 5700xt models which use half the power 6950x use. Good luck with another black screen/bsod upcoming post",
      "It‚Äôs just really nice to see people can actually buy GPUs at a reasonable price now, and the prices are still coming down too.",
      "A red devil red devil?",
      "You wont, wires and connectors need little time to wear off. Your weakest link is the connector on the right side on the gpu, since both wires from him and other one are in same place. Resistance is the biggest on joints and that will be the hottest part. Depending on environment temps, gpu usage and other factors its judt a time bomb when that one will start to melt. \n\nYou probably have another pcie cable in your psu box. Its 2 min job to hook another one and be safe.\n\nAlso you have bunch of videos on youtube from respective tech tubers, bunch of warnings and posts from both nvidia and amd in order not to use piggy tails on hungry gpus. 6950x even if its more efficient and less power hungry than nvidia conterparts, it still demands more than single cable for the gpu",
      "So much more gooder üëç I'll be going from a 5700 xt to a 3080 come Friday!",
      "That's not how this works at all.\n\nA single cable is rated for whatever the power supply rail it's attached to is capable of or the maximum you can draw using the connectors it has. A PSU designer wouldn't design something that can catch your house on fire for the sake of not adding a couple more cables.\n\nIf your power supply has separate rails to feed the different cables then it's a good idea, but if your power supply only has one cable or one rail then it's fine provided you aren't drawing more power than the PSU is capable of delivering. Even if you did overload the power supply all that will happen is your PC will shutdown.",
      "AMD just measures the GPU itself but not the rest of the card.",
      "It‚Äôs not bs. It‚Äôs risky to use daisy chain on a 3x8 pin gpu with high wattage like around 400-500 and sometimes spikes that are in excess of the limit. It can and has fried other peoples gpu because they didn‚Äôt use 1 gpu pwr cable per 8 pin connector. Better to be safe than sorry\n\nSource: https://linustechtips.com/topic/1277102-psa-do-not-use-daisy-chain-power-cables-for-3000-series-one-cable-per-8-pin-gpu-power-connection/",
      "You are welcome!",
      "And sorry for initially being stubborn about it",
      "Just did it, was relatively painless besides dealing with my shit cable management in the back that looks like Homer Simpson with his fat taped to his back."
    ]
  },
  {
    "brand": "amd",
    "generation": "6000",
    "tier": "top",
    "matched_keywords": [
      "6900xt"
    ],
    "title": "Massachusetts people - MSI 6900xt for $630 at MicroCenter only 6 left!",
    "selftext": "",
    "comments": [
      "I have a feeling that new gen prices will be way better than nvidia.",
      "i have no confidence of that so i picked one of these up before any announcement. Since at microcenter you can return anything within 30 days ...  Its compelling to at least have this for now.",
      "AMD just needs to match or beat the 4080/4070 at a cheaper price.  Should just ignore the 4090 all together.",
      "XFX Speedster $650 on Amazon - https://www.amazon.com/XFX-Speedster-Radeon-Graphics-RX-69XTAQFD9/dp/B09M38TVL2/",
      "It's mad that there's still people paying more than this for a rtx 3070ti",
      "Doubtful. You'll probably be able to get a similarly performing card to the 6900XT for around this price but the top tier new card will be 1200+",
      "You can assign a dollar value to the enjoyment you received over the past year, if that will make you feel better.",
      "XTXH is a binned chip with the limitations on OC and power removed, so that you can benchmark for bragging rights with no practical real world application whatsoever.",
      "It's even a good one",
      "I am in Europe and found 6900xt for 740 euros (which is impressive), only if it was not a amazon 3rd party seller (they are usually shotty drop shippers).\n\nEdit: yeah, i only need a 6700xt, but‚Ä¶\n\nEdit: fuck me, i start to even lower prices, especially higher end cards. C‚Äômon i need a new psu then.",
      "i think they will be able to match it in Raster performance which is all that really matters, then they can undercut it in price and punish them.   They are cutting a big log slowly having something to keep those 3080s and 4080s of them in shelves will not be that difficult once if  they blow the performance and price out.   Nvidias mistake is not having a new gen card within 85% performance  of their flagship at $700 they  gimped the tiers below too much for their price.   Having a card perform better than the stock 4080 is the slot they should be aiming to take and then beating them to the market  with  4060 ti competitor which  will be the market share leader around a $450",
      "Just a little PSA - Trio Z is a guaranteed XTXH chip while Trio X is not",
      "Amazon also has their holiday return policy in place so you can return items until January 31st",
      "I bought my red devil 6900xt for $1800 a year ago fml...",
      "i guess they needs cuda? \n\n*if you are blender  artist, buy enviidiuhh*",
      "Thats what scares me. I jumped on a 6800XT new for $550, and sold my 2080 Super. After seeing Nvidias lineup and the awful price/performance outside of the 4090 (and thus the entire lineup), I pulled the trigger. I could definitely see the 7800 (non XT) being roughly equal to the 6800 XT, but do I see it being sold for less than $550?...If Nvidia can charge those prices, AMD would be downright dumb to leave hundreds of dollars on the table per sale (hyperbole but you get the point)",
      "Thats what drove me to overlook the sometimes-underwhelming drivers considering the cost, perf, vram relative to Nvidia stuff it made 0 sense.",
      "Merc has better heatsink and overclocks much better than swift. I believe Merc cards are also binned higher than the swift cards",
      "Just curious what does this mean? I did not know the chips were varied?",
      "So I could return it and upgrade to 7000 series after they release"
    ]
  },
  {
    "brand": "amd",
    "generation": "6000",
    "tier": "top",
    "matched_keywords": [
      "6900xt"
    ],
    "title": "Ryzen 5950X | Red Devil 6900XT | P600S",
    "selftext": "",
    "comments": [
      "I just have one question.  Who did you have to blow to get your hands on all these parts?  Might be willing to do the same.\n\nEdit: I don't know why you guys are down voting OP for giving a sarcastic answer to my sarcastic question but stop it.  OP did answer the question seriously later in the thread.",
      "Well congrats on snagging some of the most difficult to source computer parts in modern history.",
      "*Ryzen 9 5950X 4.8GHz/4.6GHz@1.275v\n\n*Red Devil 6900XT 2745MHz@1175mV\n\n*ROG Crosshair VIII Formula \n\n*32GB 3800MHz CL14 Trident Z \n\n*EVGA CLC 280 w/Noctua's \n\n*Corsair HX1000i w/Cablemod Pro Carbon's.\n\n*Phanteks P600S case.",
      "Nice build my dude :)\n\nJust be warned, your GPU will get hot.\nI have the same case and although it has a built in capability for vertical mounted GPUs it is still too close the side panel.\nI bought the cooler master vertical mount V2.\nWay better temps",
      "Things usually work out better when you try and not tell others how they should have spent their money. But I'll keep it in mind next time I'm buying.",
      "ü§£ \"Only 32GB\"   \nAppreciate the laugh and downvote",
      "that guy wasn't an actual guy , it was Dbrand :/",
      "Hey I have a old 380 on the shelf.. just saying :)",
      "Appreciate it, took lots of checking and random Microcenter runs to acquire it all.",
      "Beauty of a machine. Black and not white. RGB if needed but not set to unicorn puke. Air cooled GPU because you'd gain very little from liquid. Quality fans. Nice case. Fantastic component choice. Very nice my good sir. Well done.",
      "Thank you, and they are 3600 CL15 DIMMs pushed a bit.",
      "My closest microcenter is about an hour away so it makes it almost impossible to just pop in to check stock.  Guess I'll just wait for things to get back to normal and keep using my R7 4800H 5600M laptop until they do.",
      "Jealous much?",
      "Thick. Tight. Solid. Ready and willing.",
      "Yep he's just mad",
      "The best AMD has to offer! (currently on desktop)",
      "Those are +600Mhz 3200 sticks? What an awesome build man.",
      "The classic \"it's not much but it's mine\" build. \n\nReminds me of that guy on Linus Tech Tips who asked them to build an illuminati pyramid computer with 4 2080 Ti's, a 64 core threadripper, and 256GB of RAM, which changed to 2 3090s and a 5950x. \n\nIt was clear that the guy just wanted whatever was the most expensive parts regardless of whether he'd have any use for it. \n\nTurned out in the end the guy just wanted to game and stream with it and that's it.",
      "It looks great, but what about sitting the GPU in an orthodox manner ?",
      "The case is huge. I was locked in with choices due to card length restrictions in my Meshify C and in this there‚Äôs still space for a melon after the card.\n\nEnjoy"
    ]
  },
  {
    "brand": "amd",
    "generation": "6000",
    "tier": "top",
    "matched_keywords": [
      "6900xt"
    ],
    "title": "I consider myself very very lucky. 5950x and reference 6900xt. I managed to pick up both on their respective launch days",
    "selftext": "",
    "comments": [
      "It's sad when you have to use word \"luck\" when buying computer parts.",
      "Cables. Cables everywhere!",
      "Not sure why you watermarked your reddit username on the pic as no ones gonna wanna take it and pass it off as theirs due to the cable management upfront lmao\n\nEither way congrats as its a solid build!",
      "Truly",
      "Not your desk your PC... sorry but that's some of the worst cable management I've seen in a while. And the hoses... what was the point of getting the more expensive AIO with the digital temperature readout if you can't even see it?",
      "the hoses dangling in front of that Kraken Display is gonna keep me awake tonight",
      "Brother you probably had to move the whole PC to upgrade it, you should have vacuumed while you had it out   xD\n\nIt's too bad the hoses on the CPU cooler don't connect on the other side of the block so they don't block the display on it.\n\nSweet rig though.",
      "Yeah I'm not that happy about AMD and Nvidia! In fact they did a really poor job in 2020 plus you can't get anything for MSRP right now, who's idea was it to release consoles at the same time, that person should get fired and everything on 7nm TSMC ok Nvidia is on Samsung's 8nm but they probably couldn't get enough supply from 7nm TSMC so they went to Samsung which doesn't do much better right now! 2020 is the worst year ever to upgrade a PC or get a new console!",
      "Considering both are out of stock.",
      "The shit show is also caused by vendors not having queue systems, scalpers, and users willing to pay way too much.",
      "The cable management is hurting my eyes",
      "Why would anyone position it like that...",
      "Its one thing if your cable management looks like that and you have a solid case. But a case with a side window? c'mon",
      "Underside of my desk is indeed super messy",
      "Sorry to break it to u dude, general rule of cabling. They dont cross each other. 0 overlaps. Second thing, u can cable from behind the motherboard, or make more efficient routes for ur  cpu can fables cus they're noticeable if lifted off it. Third and most importantly, unplug the gpu and put it through the hole horizontal to ur gpu. U spent the money on a nice pc. Make it look classy üßê. If u need any help just post here and I can give u more advice on better runs for ur cabling. Behind it doesn't matter.",
      "What the fuck is wrong with you!?\n\n.\n\nWhere is the cable management? Also vacuum near those moldings.",
      "It's not like they \"just went with 8nm\". I don't think anyone could have expected this crazy demand we're seeing at the moment...",
      "I believe he means using 2 separate pcie cables, not just piggybacking the one.  Those cables can only supply so much current, so using 2 will give you headroom and avoid overheating the wire.",
      "Too much money.",
      "nice watch"
    ]
  },
  {
    "brand": "amd",
    "generation": "6000",
    "tier": "top",
    "matched_keywords": [
      "6900"
    ],
    "title": "Can't wait to install my brand new 6900 series card! ;)",
    "selftext": "",
    "comments": [
      "i have 6950\n\nstill alive\n\ncan do 6970 flash no problems\n\nbut sitting in a shelf because rx560 is more then 3x more efficant with 20% more performance overall\n\nedit: PSU powering it with 6970 flash,OC and overclocked Q9550 to mere 3.6Ghz died because shit managed to hit 600w\n\nPSU in question was OCZ SXS 600w 80+ gold",
      "Hard to believe they had that puny fan for two gpu's",
      "I know those feels. My R9 290 was fun as heck but between it and my 8ish core bulldozer I did light a PSU on fire.",
      "According to the Anandtech tech review it ran at 94C with 77dba noise while running furmark.",
      "6990? That's at least 90% better than the 6900xt, cuz it's 90 more.",
      "Heck, I only retired my 290x last year, those cards stayed relevant for a *very* long time if all you needed was 1080p 60.",
      "Still running a 290x and a 4690k. Its pretty passable still honestly.",
      "I miss this card. I felt so elite having one but then i realized all i ever did was benchmark. Never played games lol.",
      "I was running a R9 280 with a i5-2500K until last month XD",
      "it has only 375W on 2 chips, thats about 40% less power consumption each chip than that 6900XT single chip hot garbage!",
      "I had a sapphire 6970. Was a beast for a long time",
      "Nice, I had a Gigabyte 6950. Two of them in crossfire actually! Boy was that a colossal waste of money üòÇ",
      "I'd probably still be using mine if I didn't get a 1440p 144 monitor last year.",
      "Something like that yeah",
      "Nvidia 3090 and 3080 says Hi :)",
      "the 2500k is a beast of a chip. Still running at 4.5ghz in my sisters living room PC after all these years...",
      "WTF are you serious? That‚Äôs louder than a vacuum cleaner.\n\nWhat is it with AMD and their atrocious reference coolers? Like every high-end card of theirs for the last 15 years has sounded like a hairdryer while just barely keeping the GPU cool enough to avoid emergency shutdown.\n\nAt least nowadays the 3rd party manufacturers can create a competent cooler. Back in the day, the only choice you had was which ugly-ass decal to get on the reference cooler.",
      "Late 2000s - Early 2010s - that was a good era for Radeon.",
      "I miss the GPU Artwork.",
      "They looked pretty damned sick, though, didn't they."
    ]
  },
  {
    "brand": "amd",
    "generation": "6000",
    "tier": "top",
    "matched_keywords": [
      "6900xt"
    ],
    "title": "Managed to pick up an ASRock Phantom D 6900xt at MicroCenter for $702",
    "selftext": "",
    "comments": [
      "Notes:\n\n1. It was technically open-box but clearly unused. The original peels were still on the card!\n\n2. I realize I'm on the knife's edge with a 650W PSU though under full load I estimate my peak power draw at ~520W. Not efficient at all, but it works. I do plan to get a bigger PSU soon.",
      "Yep upgrade that PSU think 750 would suffice.\n\nCongratulations on the card! Very good deal. Your cable management made me rise my eyebrows tho.\n\nNot using closest openings for the cpu power and some others.",
      "congrats on the deal. \n\n&#x200B;\n\n650 watts is cutting it close although you should be fine as long as you undervolt.\n\nIf you are going to upgrade your psu I would suggest moving up to at least 850 watt gold to make it worth it in case you plan to upgrade your gpu again in the future or upgrade to any power hungry component(s).",
      "In 10 years it'll be $100.",
      "I love Microcenter open box deals! I'm picking up a Asus TUF 3080 12gb for $675 tomorrow.",
      "CPU: R5 5600x\n\nCooler: ID-COOLING SE-214-XT ARGB White. Neat little cooler I got off Amazon for $20. Works well enough.\n\nMobo: Asus B550M-A A/C\n\nRAM: 32GB G.Skill 3200 + 16GB generic 2666 stuff OCed to 3200\n\nCase: Lian Li Lancool 205 Mesh\n\nThe motherboard, CPU, and the generic RAM came from a PowerSpec G508 I bought at MicroCenter in 2020.",
      "Nice.  \n\nMy Sapphire Pulse 6800XT was 1042USD back in march.  Part of me is mad for not waiting just a couple weeks.",
      "Have you tried an undervolt? Might be able to save yourself another ~50W of peak power draw via Radeon Settings' undervolting, or some manual tuning.",
      "Yeah, I need to completely redo my cable management. I know it's inconsistent at the minute ü§£",
      "Open box deals at Microcenter are solid",
      "I've had my Phantom since Feb 2021 and I've had to get a support bracket as well as upgrade my PSU since at 750w it was cutting out under load. Just a heads up!",
      "Nice specs. \n\nYou got a bit lucky on that ram, OC'ing that far and there's at least a small amount of luck involved in a mismatched config like that working at all(there isn't supposed to be, but in the real world, there is).\n\nStarting with a prebuild and upgrading down the line is a great way to do things. \n\nYou got lucky with a cheap cooler too, one that cheap would scare me on a decent CPU but hey, if it works it works. Definitely consider an upgrade if you pull the trigger on a 5900 or 5950, more cores mean more heat. I've got an AIO on my 5950x and even in a stress test I only see a brief moment above 90C, and in actual loads I've never cleared 80.",
      "I got lucky indeed. I randomly saw the ram just sitting in a box and wondered if it would work. It's been rock solid stable, no issues.",
      "EXTRA LONG CABLES",
      "why not white?",
      "Yeah definitely go higher. I wouldn't even look at anything under 750 for that upgrade, and then only if you are at a hard budget limit. 850 should be the baseline you look for. You'd be using somewhere between 600 and 700W, so even in a money is no obstacle budget going past 1400 would probably be a waste(you'd go below the most efficient load percentage at that point).",
      "Thanks for the suggestion, I'll definitely be getting at least an 850 when I upgrade the PSU.\n\nI also do plan an upgrade to a 5900 or 5950x at some point, and my little 650W unit *definitely* won't be able to handle that.",
      "Solid advice there. Unless you are playing in 4K ultra, downvolting with little sacifrice on performance didnt hurt that much.\nAnd lower heating on the summer time",
      "Yeah, I picked up my RAM on one as well. Saved $40-50 on the kit I got a couple of years ago. Still running great!",
      "850 is a good choice but if ya can secure a good deal on a 1000-1500W one, ya golden :D\n\nMade that choice in 2018 after seeing the trends go up and up... Invested in a 1550W Thermaltake TF1 Titanium PSU.\nBest choice ever, basically has no noise whatsoever."
    ]
  },
  {
    "brand": "amd",
    "generation": "6000",
    "tier": "top",
    "matched_keywords": [
      "6900xt"
    ],
    "title": "3700x Asus x570-P, With a Sapphire toxic 6900xt",
    "selftext": "",
    "comments": [
      "Loving everything about the build! And that monitor is absolutely gorgeous!",
      "I love orange :) This makes me want to swap my fans for orange RGB fans as well. Looks so good.",
      "Lol, for sure! \n\nI moved out to the boonies with the wife and kids and we have no cell service out here, so if the internet goes down we have no phone, so need a land line in case the office calls and we have to leave to move equipment.",
      "It does fine for the games I play, I am sure it would bug some people, but I am okay with seeing 50fps in some games. I grew up playing the old consoles where slow down was a added feature haha",
      "Yeah it‚Äôs real nice when contractors send me site plans and I can view the bigger picture.",
      "I went to visit family this Christmas and my dad had me use his 27‚Äù 4k monitor, I realized then that I could never go back to something smaller. \n\nFreesync, 144hz, and screen real estate is something you do not realize you need till you need it.",
      "Thank you!",
      "What monitor is that",
      "Samsung Odyssey g9 I believe, 3840x1080.",
      "In my experience the 3700x is a powerhouse and has no problem playing anything.",
      "Got the same monitor with a 27\" vertical next to it. Gaming and working are soooooo nice!",
      "Hmm I also have a 3700x and cyberpunk holds a solid 60 with everything maxed. It‚Äôll occasionally drop to 58 or 59 but that‚Äôs because of my GPU rather than CPU. These CPUs can be a little tricky to get max output though. Have you run cinebench on it yet?",
      "I love you have the most up-to-date godlike tech and a 20 year old phone right next to it",
      "I feel this is my go to color for most things, it‚Äôs not in your face and it‚Äôs pretty chill.",
      "I agree and also it fits nicely with black.",
      "Cyberpunk 2077 with everything maxed haha. \n\nI like to make my pc sweat.",
      "I work in IT on a level 3 team, so I've always got a LOT goin on my screens. I did have two 27\" monitors but it's just not the same as the 49\". I'll never go back",
      "God orange is my favorite color, but I'm rocking red RGB nice build though especially that widescreen monitor sheeeesh",
      "Love it. Can we share this on AMD social media?",
      "I actually don‚Äôt care for orange at all but this build is changing my mind. Absolutely rocking that orange, gorgeous build."
    ]
  },
  {
    "brand": "amd",
    "generation": "6000",
    "tier": "top",
    "matched_keywords": [
      "6950"
    ],
    "title": "After nearly 7 years of waiting and 2 children I had the chance to build a new rig. 5800x3d + 6950 xt.",
    "selftext": "",
    "comments": [
      "First Asus LC 6950 XT I've seen in the wild. Where'd you even get this thing?",
      "germany ![gif](emote|free_emotes_pack|sweat_smile) yeah I also noticed the lack of LC strix 6950 xt",
      "And soon those children will occupy the computer and game on it üòÇ",
      "Ahahah now you have to wait them to sleep for use it =D only parents understand you !!!\nMerry Xmas from France to your family and enjoy it <3",
      "Let me know the specs when you test it. Been looking at the 6950",
      "In Canada I've only ever seen it in stock on Amazon and they didn't have a large amount either",
      "It uses a flexible PCI Express extension cable to allow the card to be mounted outside of the motherboard slot. The case also has additional vertical slots and screw-down holes to secure it there.",
      "The case supports vertical mount next to the horizontal slots",
      "I will let you know!",
      "[3DMark for you. Is this enough or do you want specific test?](https://imgur.com/a/odT1BVQ)",
      "The real struggle! üòÇ",
      "How do you install the GPU in that orientation?",
      "Damn nice build. How much did you get for the children to build that bad boy?",
      "Mind sharing your bios/cpu settings? I have my 5800x3d scoring 10,7xx, and 6900xt scoring 22,5xx. I've only been able to score 11,5xx once, and I can't pin down the exact reason. Both on custom liquid loop.",
      "i was about to say the same thing lol, maybe 24/24? who knows",
      "For real. I should have waited to buy gpu cause I don't get to use it much.",
      "the specs are awesome! can only recommend so far :)\n\nhappy holidays!",
      "One reason we don't have much stocks here in canada, i noticed that almost everything has less stock compared to US or EU. My guess is that this country blocks the creation of large amount of stocks.",
      "Make sure you're on the windows balanced power plan.",
      "Just built the same spec system with a msi rx6950xt and r7 3dx. Its a beast of a system. Vr sim racing and flight Sims are mostly what I do and I can just about run max settings in everything besides MSFS. On my 1440p 144hz monitor I have everything maxed out and it runs flawlessly. Cyberpunk is the only game I get about 80 fps, everything else is over a 100fps."
    ]
  },
  {
    "brand": "amd",
    "generation": "6000",
    "tier": "top",
    "matched_keywords": [
      "6950"
    ],
    "title": "6950 xt + 5800x3d build done!!",
    "selftext": "",
    "comments": [
      "That AIO is in love with that 6950xt, its the glow in the eyes!",
      "lmao smiley face with tongue out",
      "Top1 cpu and top1 gpu\n\n&#x200B;\n\nClass",
      "hahaha it seems pretty happy indeed.\nuntil it starts to pump all that hot air on it that is‚Ä¶",
      "When the 2nd place is second by mere percentage points and costs only 2/3 as much or less, the \"1st place\" doesn't mean that much.",
      "pretty good it gets toasty at all cores load about 85 c\nbut when gaming its aboit 60-70",
      "Damn, that's quite the pair.",
      "How's that 240aio handle the 5800x3d?",
      "Looks like Arctic 240mm.",
      "What kinda GPU temps do u get with it?",
      "Looks happy anyway",
      "oc vbios edge temp 60-70 and junction 80-90‚Ä¶",
      "The 6900XT and up coolers are actually really good. Even pulling over 300w, the edge temp of my TUF 6900XT is only like 70c with the junction hitting 90c. This is even better compared to my old 5700XT, which pulled half the power and junction would be over 100 whilst edge temp was 70s with almost a 30c difference between them.",
      "That was a fast reply! Thanks for the info my guy",
      "What AIO is that?",
      "yup arctic",
      "Wait for what? To be disappointed in available stock?",
      "i have it on a 1440p screen for competitve games and a 4k tv for casual games",
      "If you undervolt or with CO maybe. At stock you don't get those temps on a 240 AIO unless you have 10C ambient. 85C CB R23? Yeah right.",
      "Niceee. Enjoy"
    ]
  },
  {
    "brand": "amd",
    "generation": "6000",
    "tier": "top",
    "matched_keywords": [
      "6950"
    ],
    "title": "Wow, massive improvement...upgraded GPU from RX 5700 XT Liquid Devil > Sapphire Nitro+ 6950 XT (water cooled w/ Bykski block)",
    "selftext": "",
    "comments": [
      "I‚Äôve looked at Bykski block for my 7900xtx. Where did you get the thermal pads from? That‚Äôs the only thing holding me back. Bykski is the only brand that makes a waterblock for my Gigabyte Aorus 7900xtx from what i can tell",
      "Thermal pads came with the block. There was only one little square I had to double up the pad to make contact. It wasn't RAM or VRM, though, so I'm not worried (although, I don't know what it was). The card is running like a champ.",
      "1. Air is not \"better\" if it comes with noise.\n2. The FPS increase of the 7800 or even the 9070 over the 6950 (non RT'd) at 1440p wasn't worth it when I already had the infrastructure for liquid cooling,  considering any reasonable generational upgrades that I could get a water block for were a ton more money.",
      "A water cooled vertical mount 5700?? What in the..",
      "that tube pathing is giving me anxiety. lol",
      "more room for error with elbows",
      "Hahaha then I had just the build for you. [enjoy¬°](https://i.imgur.com/LRI0kNT.jpeg)",
      "Fine wine pulled the RDNA3 cards up further from the initial launch where they had smaller gains. The XTX Nitro is up there with the 5080 and breathing on 4090 in native raster lmao.",
      "Not even close.  I keep my fans at a fixed 1,000 RPM for a whisper quiet rig.  Running Heaven (maxed out) and Prime95 (small FFTs)  simultaneously for 30 minutes results in the following:\n\n1. Max CPU temp: 72c\n2. Max GPU temp; 53c\n3. Max GPU hot spot: 69c\n\nHeaven + Prime95 is my go to for thermal testing.\n\nRunning more demanding games, my GPU barely reaches 60c and the hot spot never gets out of the mid 70c range, while my CPU is typically in the mid to low 50s.",
      "The backplate on the 6950 came with the block.  I got it from formulamod.  They were \\~$70 less than ordering on Amazon or directly from Byski.",
      "Plus it's a cool enthusiast thing to do.  ;)",
      "Interesting upgrade! Why go for a water-cooled 6950 XT when you could get something better on air? I get that pricing matters, but doesn‚Äôt water cooling add a lot to the cost too? Just curious.",
      "They're cable extensions purely for looks.  I'm using the Asiahorse ones from Amazon and have found them to be high quality compared to other brands.",
      "I ended up not needing it.  It turns out 360mm of radiator is enough for my situation.",
      "What are you talking about? More like 50-100%. I play at 5120x1440.  I'd say that's pretty massive.",
      "Good to know. Thank you for the response. Did the have an option for this back plate or is that from somewhere else?",
      "Nice! Thanks for the reply.",
      "Yeah 6950 XT is still a beast of a GPU.",
      "Exactly.  For pure rasterization, it's still really competitive with newer cards.  And it's even playable with RT if high FPS (>100) isn't important, like in racing games.",
      "Much appreciated bud üôèüèº"
    ]
  },
  {
    "brand": "amd",
    "generation": "6000",
    "tier": "top",
    "matched_keywords": [
      "6900"
    ],
    "title": "Surprisingly good performance on a 6900 XT in Cyberpunk after 2.0 patch. Even running native with ray tracing on. Anyone else experiencing the same? 50-60fps stable at native 1440p with all graphics settings maxed and ray tracing enabled (except path tracing, lighting on Ultra).",
    "selftext": "",
    "comments": [
      "5600X and 6800 XT here.\n\n58-60fps in the city, 100-120fps inside buildings.\n\nCan't be more pleased. Already on my 4th playthrough.",
      "I dont get that big of a FPS jump using FSR or Intels upscaler when setting both to quality/high quality mode respectively. Goes from 50-60fps, up to about 60-70fps. Kinda surprised by the results, but definitely in a positive way.",
      "Its not. He's thinking RSR which is FSR1. FSR inside CP2077 is FSR 2.1 which is superior in every way.",
      "Wait, is this max graphics plus ray tracing at 1440p?",
      "Okay I tried it, a bit of tweaking like volumetric fog on medium and SSR on med-high plus FSR balanced at 1440p and I can get to 55-60fps on ultra RT. It's amazing because if I remember correctly I can only get to 30fps before with RT on",
      "Y'all. If you want good performance gains. With screen space reflections, go from psycho to ultra. It used to be like 40% performance impact.",
      "With my 6800 Xess UQ produces less frames than native",
      "It has stronger image reconstruction quality, but at the cost of extra compute time. The compute time can be long enough that the reduction in internal render resolution isn't enough to make up for the difference. It should otherwise be upscaling from the same resolution at the same quality levels.",
      "Yes, same with 7900 XTX\n\n7900 XTX ‚Äì Avg 63, min 49, max 84\r  \n7900 XTX ‚Äì Avg 71, min 54, max 94 (patch 2.0)\r  \nThis is with AMD 7700X, ASRock Radeon RX 7900 XTX Phantom Gaming OC 24GB\r  \nUltra settings, FSR 2.1 quality, raytracing all (normal) max, 1440p\n\nAlso testers show these results.",
      "Turn down a few settings and cap at 60fps for a fantastic experience!",
      "6700 XT here, playing at 4k stable 60+ fps with texture-related settings maxed out and others around low with FSR on balanced (with FSR 2.2 mod I'll probably do Quality). Using a 1080p monitor but 4k render is a day and night difference.",
      "I have to do RT plus FSR to get 60. What are your settings?",
      "I need 16k native path tracing at 480fps who is selling that product my budget is $300",
      "Xess definitely looks better than FSR, so I imagine it doesnt downscale much, if at all in the Ultra Quality setting compared to FSR in Quality. But I do still see a jump in frames a bit, 5-10fps.",
      "I‚Äôm genuinely so happy that the non-PT RT in Cyberpunk has been better optimized for AMD gpu‚Äôs. Several of of my friends have them, and I always felt bad that they could run games like Control or Metro Exodus with RT fine but Cyberpunk (a game more of them were actually interested in) completely destroyed their systems. Cyberpunk with RT Ultra on looks completely different than the rasterized version, just like Metro Exodus does. But one of those always ran at least okay on AMD gpu‚Äôs, and the other didn‚Äôt until now hahaha",
      "Makes me hyped for my first Cyberpunk playthrough i have planned",
      "This is not possible you must have had fsr on without knowing",
      "Not just you. I‚Äôm playing with RT on now. It‚Äôs not blow your mind good, but by comparison it‚Äôs great. FSR3 will make it even better and remove the dips to the upper 50s I get.",
      "Just an idea. I've heard that xess is better than fsr in this game so that might be worth trying out too",
      "I did noticed a big jump with my 6750 on High, RT OFF and Effects also off and FSR on quality."
    ]
  },
  {
    "brand": "amd",
    "generation": "6000",
    "tier": "top",
    "matched_keywords": [
      "6950xt"
    ],
    "title": "Since 6950XT is now $600, what will the 7800XT be?",
    "selftext": "The 7900XT cost $780.  \nThe 6950XT cost $600.  \nThe 7900XT is 30% more expensive than the 6950XT with current pricing.  \nThe 7900XT must be faster than the 7800XT obviously, but the 6950XT is already pretty close to the 7900XT in raster, so where will the 7800XT be compared to the 6950XT? Will it be slower in raster? For what MSRP, when the 6950XT is $600?",
    "comments": [
      "$499 with 6950xt levels of performance, with less power, and they have a home run on their hands.",
      ">\"6950XT is already pretty close to the 7900XT in raster, so where will the 7800XT be compared to the 6950XT?\"\n\nRelatively might be a bit pushing it a bit. \n\nIts about 15% faster at 1080p and the grap grows as the resolution increses to about 20% at 1440p and over 20% at 4K.\n\nI think its gonna land around 6900-6950XT raster performance so slightly faster than a 4070 but with worse RT. As for the price. Expect the usual Nvidia's price and subtrackt $50-$100. I'd bet on $550",
      "Keep dreaming, and let me dream with you for a while.",
      "My guess is it will match the 6950xt in raster while being far more power efficient and better RT performance.  \n\nI'm hoping this means 600-650 price tag but it will probably be $700 cuz reasons.\n\nI'd love to get a 6950 right now but worried about my PSU being a bit short.",
      "One does not simply leave money on the table.\n\nThat price is to get rid of the 6950XT stock so it will not be available by the time they release a new card with similar performance.",
      "I feel like the 6950 pricing is to clear out inventory before they are left with a lot of stock once faster stuff comes along. \n\nBecause the prices are great, but the power requirements, not so much.\n\nif you can give me card that costs the same or a tiny bit more, but i don't have to swap out my PSU, I'm way more inclined to buy it. \n\nThe 6950's audience are people with really big PSUs in their computer.",
      "Plot twist the 6950XT is the 7800XT because AMD doesn't actually have a 7800XT to release.",
      "Honestly history has shown that many people will buy Nvidia even if AMD is better at the same price point. What they need is mindshare.",
      "It doesn't need to be faster than the 6950. It just needs to be cheaper.",
      "I have a 6950xt with a cosair rm750x psu. Everything runs great and I OC my 5800x too.",
      "More important, when will it be released?",
      "Pointless, that's what it'll be, pointless.\n\nThere's not enough room between a 6950xt and 7900xt for a model.",
      "700$ would make it horrible, literally worse value than 4070.\n\nIt needs to be a more efficient 6950 XT for 599$ tops - and that's what I think it will end up - otherwise it's useless.\n\nBasically, you will get about 15% better raster and more vRAM but without \"nVIDIA\" and the better software stack. This should even things up nicely.",
      "As soon as the 6950 XT stock dries up. Probably in a few months from now.",
      "6950xt performance for $550 would be fine, for $500 would be amazing, for $600 would be boring, and for $650 would be awful/expected.",
      "6800xt was 16 vs 3080 10 and look how that went",
      "A 7800 XT performing the same as a 6800 XT would be a shambles of a product. There are generational and architectural improvements that go with such a new card that would mean something would have to have gone very wrong for them to release the next in the series at the exact same performance, whether it runs more efficiently or not.\n\nThankfully, all indications are that it'll run faster at somewhere around the 6900 XT with lower power consumption, better ray tracing performance and the bonus of AV1.",
      "This exactly. I don't wanna swap the PSU. Because if we did a 6950 + PSU we are in a 7900xt price range where we wouldn't need a new PSU.",
      "Still have a few spots left for dreamers to join if anyone wants in our club!!",
      "That's my point, it needs to be significantly better of a buy to start getting attention.  Like the 6600-6750 were way better price to performance vs NVIDIA and started to pick up momentum.  Still nowhere close to what it could be though. But honestly if it's $700 7800xt that is 10% better than 4070 it's got no chance.  90% of people will go to to 4070 ti or down to 4070, a lot of the rest will go up to 7900xt."
    ]
  },
  {
    "brand": "amd",
    "generation": "6000",
    "tier": "top",
    "matched_keywords": [
      "6900"
    ],
    "title": "ASRock Radeon RX 6900 XT OC Formula Review - This Card is Fast",
    "selftext": "",
    "comments": [
      "Honestly it's gotten to the point where I dont even care about reading the reviews with the current GPU stock situation. \n\nIt's not like I upgrade more than once every three years or so, but the GPU draught has kinda killed my interest in following the industry since there's not even a theoretical possibility I could buy a gpu even if I wanted to.",
      "please correct me if I am wrong - but what is the point in having a theoretical 10% bios overclock, when a standard card with opened up power limit almost reaches the same clock speeds?  It¬¥s the same with ALL the OCSUPERPOWER cards, no matter which brand. \n\nIn that test, alone the fact that the spikes in power consumption are similar to a stock version shows me even a stock card is capable of drawing a lot of power if you let it. (for example, by raising the power limit in the driver...)  Yes, the asrocks components might be of higher quality, yes, the power delivery might be more stable in long term. but TWICE the price? Really?",
      "Yeah, even I sometimes feel like that \"what's the point writing this review, if nobody can buy it anyway?\"",
      "And a theoretical GPU",
      "2000 bucks? Double the price to a reference card, but not double the performance, so not worth it.",
      "I think the most important factor that is never the thing that gets the most attention is the cooler efficiency. I mean, 100% fan speed is nice but you would be going deaf with some fans and cooler designs if your pc were next to you on your desk. For AMD, Powercolor seems to do well together with MSI and Gigabyte, but it differs per 6700, 6800 and 6900, obviously.",
      "I mean, you're basically trying to buy your way out of the silicon lottery. You pay a (substantial) premium to get something OEM validated at those higher clocks with cooling designed to handle it. Is that worth the price? Well, if that's the question you're asking, then it's not an option aimed at you.",
      "Thank you for writing it still. I was interested to read up more on Radeon cards scaling well with core clock, your article kind of confirms it.",
      "The 6900XT already is a marginal upgrade over the 6800XT if you compare it to the MSRP increase.",
      "Not only is this card fast, it's invisible too!",
      "100% agree, the cooling / noise is what matters. that¬¥s why i bought a cheaper 6900xt card, added a water cooler. even less noise, comparable power and paid \\~500$ less. Even if you have no water cooling, adding a custom cooler or even a pre-build water cooler is not black magic.",
      "Stock power draw of 390w? ASRock basically set MPT for you, lol.",
      "Not a fan of the design nor the cooling solution on this card but the performance is impressive regardless. Too bad it will probably sound like a jet engine.",
      "It comes down to binning, the chips in these cards are the higher quality ones. In a lot of reviews and benchmarks the higher end cards are able to overclock higher than reference chips.",
      "Yeah, once you have read one review of a GPU you have basically read them all anyway. It's all mostly minor differences between all the versions and performance is fundamentally within the same ball park.",
      "It might seem counter intuitive, but waterblocks can lead to some surface components getting hotter than heatsinks since no air is flowing over the PCB.  Those components aren't usually super temperature sensitive, but I remember in the days of old when the first GPU water cooling efforts resulted in dead GPUs despite low temperature readings.  Modern blocks will make contact with everything that needs cooling and often will couple to the coils to act as another means for the PCB to shed heat.",
      "TFW: you get scalped by the manufacturer",
      "Yup. I agree 1000000000%",
      "Cool but im not paying $2000+ for a $1000-1500 GPU.",
      "Still not as fast as botters, miners, and scalpers.\n\nI can't be interested in current gen cards when you can't find litterally any of them in stock anywhere."
    ]
  },
  {
    "brand": "amd",
    "generation": "6000",
    "tier": "top",
    "matched_keywords": [
      "6900xt",
      "6900"
    ],
    "title": "Any Particular Reason People Seem To Stay Away From The 6900xt?",
    "selftext": "Hey Ya'll\n\nEvery thursday I see a lot of posts about buying up cards, and see a lot of people avoiding the 6900xt or saying it's overkill or \"too much card\". And while I understand if you are strictly price driven, it is a decent chunk of change more, for only maybe 10-15% improvement over a 6800xt.\n\nHowever a strange thing I've been noticing is 6800xt's seem to be selling at times at the same price or even in some cases MORE than 6900xt's (on ebay mostly or second hand)! I don't know if people aren't aware of the economics of things, but if you're trying to get a card at MSRP, the 6900xt is about the only one you have a real shot at.\n\nAny reasons you guys think, or any particular reason (besides cost I suppose) that people are avoiding the 6900?",
    "comments": [
      "A reference 6900XT is a better deal than a partner 6800XT for now.\n\n\n\nIf you're only considering MSRP of the reference models, 6900XT is not very good on price to performance.",
      "Honestly the only thing I can think of is ray tracing. When they came out the raster performance was great but RT wasn't as good\n\nI'm very happy with mine!  Great Linux support and plenty of frames",
      "It's just mistaken stigma from its MSRP. If we're going by MSRP, it's not a great deal. However, for at least a year now, the 6900XT has **low key** been the **best value** high end GPU out of all cards of this generation if you look at all market prices from a **% of MSRP perspective**. Like you said, a lot of 6800XT's have been priced (scalper or \"official\" reseller, there is no difference) **higher** than some 6900XT's.\n\nPrices have come down a little bit in the last few weeks, but for the longest time it was something like:\n\n3070 $499 MSRP @ $1200+ (240%)\n\n6800XT $649 MSRP @ $1600+ (247%)\n\n**6900XT $999 MSRP @ $1500+ (150%)**\n\n3080 $699 MSRP @ $1800+ (257%)\n\n3090 $1499 MSRP @ $2500+ (166%)",
      "Calling a 3080ti or 6900xt a run of the mill graphics card is a hard fucking stretch",
      "Right now the 6900XT is price parity with the 3080 12GB, which is effectively tied in raster performance, and the 3080 12GB comes with a massively better feature set. It makes the 6900XT a hard sell. Watch HWUnboxed's 6900xt vs 3080 12GB comparison video, they come to the same conclusion.",
      "As big as RT is, it's not just RT.\n\nIt's also:\n\n* Tensor AKA Matrix accelerators (DLSS/DLDSR) - Not present on any current or even future announced AMD hardware, but a core part of Nvidia's Turing/Ampere/Lovelace architectures and Intel's Xe. Clearly the future of GPU's and already shockingly good.\n\n* DSR - Far inferior integration in AMD driver and perhaps hardware.\n\n* NVENC + related video capture API's (Nvidia paid developers to help the OBS team and other developers integrate these API's, AMD doesn't have the API nor the employees)\n\n* Reflex - Not present in AMD software, requires driver and game engine integration. Nvidia identified the need for the tech with a community member, created it, has a bunch of developers assigned to help companies integrate it into their games and engines and now it's in IIRC 8 of the top 10 FPS games and several of the most popular open game engines like Unreal.\n\n* Proper adaptive sync (incl. features like variable overdrive) - Hardware not present, essential for good VRR yet brushed under the rug because it makes them look bad. Third party reviews or Nvidia branding are the only reliable ways to know that your VRR display which VRR's with an AMD GPU will work even half decently.\n\n* OpenGL/DX9/DX11 api performance - been hammering them for this since the 7970 was the shiny new toy, it never happened. This matters to many people who play games like Minecraft, OSRS or generally older games. People are still upgrading their gtx970's to 6900xt's, losing 30-50% of their FPS and asking me why it happened.\n\n* Product support duration. AMD has recently rebadged old architectures as current gen over and over and over again, then dropped support for features that they could run perfectly while they were still being sold as new for no reason other than not having any employees to write the code.\n\nMost people care about at least one of those things, personally i use them all every week and most of them every day. More than a few are nothing short of revolutionary.\n\nIf they want to charge Nvidia pricing they need Nvidia performance, feature set and driver team. If you don't have parity, then every loss needs to be met with an equally sized win (which just doesn't exist) or with a discount. If their hardware was massively cheaper than Nvidia's for a given raster performance then i would recommend them carefully to a few people who don't care about these features, but that hasn't happened in a very long time and the list of people who don't care about any is getting smaller by the day.",
      "I‚Äôm building a computer now and am sticking with integrated graphics cause it‚Äôll be a cold day in hades before I pay upwards of fourteen hundred dollars for a run of the mill graphics card.",
      "For sure, totally agree with that.",
      "Yeah, I think RT is nice, but like I told another redditor, is it worth paying maybe 300-500+ more dollars for better ray tracing on an Nvidia equivalent card? It's one of those things they literally did a study and almost nobody could notice! The DLSS makes a bit more sense especially if you are trying to push super high frames, but AMD looks to be evening the playing field with FSR 2.0, so to me it's almost a wash at this point.",
      "I mean, it is though.  \n\nIt's a mass produced GPU for consumer PCs from one of the major companies that make them.  It's not something so unique that needs a 1000%+ profit margin.  I know AMD and NVidia want you to think so, but you don't need to pretend otherwise for their benefit.",
      "Yup.  Then you factor in the mostly unknown super die XTXH which could be had for an extra 50 bucks lol.\n\n&#x200B;\n\n[https://www.techpowerup.com/review/asrock-radeon-rx-6900-xt-oc-formula/](https://www.techpowerup.com/review/asrock-radeon-rx-6900-xt-oc-formula/)\n\n&#x200B;\n\nFrom the review:  \"Averaged over our 22-game-strong test suite at 4K resolution, the RX 6900 XT OC Formula achieves the unthinkable: It is faster than NVIDIA's GeForce RTX 3090. Long overdue, the day has finally come‚Äîan AMD graphics card is able to overtake NVIDIA's current-generation flagship graphics card! Who would have thought that just a year ago. This makes the ASRock RX 6900 XT OC Formula 7% faster than the AMD reference RX 6900 XT, 12% faster than the GeForce RTX 3080, and 13% faster than the RX 6800 XT. Very impressive numbers. There are still some RTX 3090 custom designs, like the ASUS STRIX and MSI Suprim, that are yet a little bit faster than the OC Formula.\"",
      "Absolutely, again I never thought in a million years I'd even consider a 1k GPU, but when I started doing the math and price shopping (and waiting in the queue) I decided it likely made the most sense to try and get a 6900xt.\n\nAnd to your point, for some crazy reason I have actually seen 6800xt's sell for more than 6900xt's in second hand markets, and considering I purchased a reference one barely used, for the cost of a new one with tax and shipping, it kinda proved my point.\n\nBut yes, the pricing is fucked and my concern is what the next gen of GPU's will be priced at. HOWEVER, I'm hoping there are either changes in ethereum or crypto in general that make the next gen less desirable, OR when they upgrade they flood the market with used 3090's and 6800's at ridiculously low prices in the next year. That could also force manufacturers to lower prices too once the miners get their fill. In late 2019 if you were patient you could find a Vega 64 for under 200 bucks, or a Radeon Vega FE for under 400, we will see that again.\n\nAnd for people worried about buying second hand, linus tech tips did a great video on how used GPU's rarely if ever under perform over their new variants. Especially the higher binned models as well!",
      "Just bought a 6900 xt from Microcenter for $1050 a couple of weeks ago along with a $249 Ryzen 7 5800X. Couldn't be happier!",
      "Let me see those RT Ultra FPS \\^\\^",
      "He explicitly specified in the video that reBAR was enabled for both cards, they changed their policy a month or two go. His benchmarks are also in line with basically every major review site, I just suggested the HWU video because it's a direct comparison.\n\nTy for calling me a gullible clown tho, very mature",
      "I think the prices are going to fall like stones when they finally are able to ramp up production.  I wanted a 6800 XT myself and waited a year for it--but finally settled on a 6700 XT (GB Eagle 6700 XT 12GB) when the NewEgg price dropped to where I thought the real non-shortages MSRP of an AIB card with a triple fan would be...about $100-$125 over AMD store reference design pricing--so I grabbed it.\n\nIt was kind of interesting that while I was completing the order, the Newegg stats said that there were 200 other people with the same GPU in their carts!  I can understand, since the price had dropped suddenly by almost $300.  Went back a couple of days ago and darned if the Newegg price of the same GPU hadn't been raised again another $200 over what I paid...;)  NewEgg must have received a big load of the Eagles and they priced them to sell quickly, which they did.  So, production is still not back to normal, unfortunately.  Let's hope things get back to normal soon.\n\nAnyway, I'm well pleased with this product!  GPU beats my 5700 XT at 4k convincingly, by up to 30-35% in most of my games!  And the image quality has definitely improved.  So, I'm pat on a GPU for a good while.  Next, I'll be looking at the 5700X/5800X or the 5800X-3dVcache!  I've got almost three years on my x570 Aorus Master and I can't see why it won't last another year or two...;)",
      "Those aren't at all close to the same concept. A 6900 XT is much more accessible than a Viper, which many theoretical buyers would have a disastrous time trying to drive. It's also much more bespoke (versus more mainstream Dodge vehicles of the time) than a 6900 XT. A 6800 XT is much closer to a 6900 XT than a Challenger is to a Viper.\n\nYou'd have a better chance at comparing AMD CPUs, putting a Ryzen 5 against a Threadripper Pro.",
      "It just depends on how important RT is to you, to be honest. Totally respect whatever decision people make, I run both AMD and Nvidia, and in many cases the 6900 can push as many frames as a 3090, there are cases where it outperforms because the 3090 has RT cores, whereas if you don't run RT, the 6900 has more dedicated cores meaning it can technically out perform a 3090 in certain use cases and especially if you're trying to push high frames.\n\nWith that said, buy what you want, and what makes you happy, makes no difference to me. JUST AVOID THE FUCK OUTTA SCALPERS AND SITES WITH TERRIBLE MSRP MARKUP!!!!!",
      "Really? In Germany I see the cheapest 6900XT for 1179‚Ç¨ and the cheapest 3080 12GB for 1149‚Ç¨.",
      "im sure Nvidia is just terrified while sitting in their Dagobert Duck vault fulla gold coins"
    ]
  },
  {
    "brand": "amd",
    "generation": "6000",
    "tier": "top",
    "matched_keywords": [
      "6900"
    ],
    "title": "Tight all AMD build, 7800X3D and Asrock RX 6900 XT OC Formula in Fractal Design Ridge",
    "selftext": "",
    "comments": [
      "That's amazing, how are the GPU temps?  Looks like it might have trouble breathing, especially with low profile fans.  How are those being controlled?",
      "I‚Äôm setting 65w ecomode on CPU, fan setting 900-1200rpm, around 70c during gaming session on 4.8Ghz.\n\nAs for GPU, with the help of that dual 14mm intake, it‚Äôs actually very good, fan usually keep at 50% speed, core is around 70c and hotspot on 90c.",
      "I have the 6950xt version of that card‚Ä¶ if you ever get a wild hair put some PTM7950 on it‚Ä¶ dropped\nmy hotspot temp 20C plus.",
      "SFFPC builds always impress me; I *fight* to get mid-tower cases right, you guys are doing it on hard mode.  \n  \nAwesome work, thank you for sharing!",
      "What's 'silly high' idle temps? Because the 7800X3D is pretty trivial to cool even with PBO + 85 degree limit. A tiny SFF build like OP's is an extreme but a 360 rad should have no trouble.",
      "I'm going to need it for my 7900 XTX. Hotspot temp has increased around 12 degrees from first month of use. Howering around 94-101 now which is getting close.",
      "I can't believe that OC Formula actually fit in there! NICE BUILD!!",
      "Odd. I started a game just to remind myself what my temps are like on my 240 rad - 1440p 60Hz running a 3D scene in War Thunder it spikes to 60 before the fans turn on but then holds at 49 with low fan RPM. At medium load (1440p Ultra 165Hz) it likes to hover around 53 and has never exceeded 61. PBO + 85 degree limit, OS power management features disabled.\n\nIf it's fine under load who cares I suppose. The mounting frames are a gimmick when it comes to AM5, although I belive they're valid for some Intel sockets.",
      "I have the same case and CPU, but with a 7900xtx. It breathes just fine. It has fans directly blowing into it. \n\nThe cpu gets a bit less coolong than normal, but this is fine since the wattage is so low on that chip. No issues what so ever. I think I use a NH-L12S or something similar.\n\nFor larger cards, like the 4080 or 4090, the fans for the gpu is removed to make space. In this case it is not a problem also, since it basicly is an open rig with no filter. Air is pulled right through.",
      "You can also die handling a PSU, so ups and downs.",
      "On the plus side the frame can stop excess thermal paste from getting everywhere and they can look rather attractive :p\n\nAs a final Hail Mary before RMA: what are you using to measure temperatures? It's been a minute since I've used Windows but HWInfo was the gold standard for showing you every sensor's temperature, not just one number from who-knows-which sensor.",
      "Awesome, love a well done SFF build. ![gif](emote|free_emotes_pack|thumbs_up)How are temps and noise with the Ridge?",
      "Question, no issue putting the back the side pannel on the back, for the height of the heatsink of the nvme on the back of the motherboard?",
      "Looks awesome! What CPU cooler are you using?",
      "I regret selling my logi mx mech mini white so much üò≠ it's a shame but I don't use macs",
      "What‚Äôs the noise like? My PS5 is basically silent.",
      "That thing looks really cool.",
      "I ended up having to switch from the ridge to a bigger case. I had the same setup with those two lp fans in front of my asrock 7900xtx and the pc was an oven. 90c and above in pretty much every game I played. Lots of driver timeouts back then, I‚Äôm assuming it was hitting thermal limits.",
      "Yeah, it‚Äôs a really a tight fit for this card, spend some time to wiggle it in.",
      "I like it so much. Just use windows powertoy to swap windows and alt key, then it‚Äôs no difference than a regular keyboard."
    ]
  },
  {
    "brand": "amd",
    "generation": "6000",
    "tier": "top",
    "matched_keywords": [
      "6900xt"
    ],
    "title": "Respect to the \"Apollo program\" :) Ryzen 9 5900X+6900XT",
    "selftext": "",
    "comments": [
      "It is really nice looking... But going with the 13... Don't forget to put socks on the air intakes ;)",
      "That thing has gotta have at most 32GB of storage to truly honour the Apollo program",
      "Good idea! :)",
      "This rig looks really cool dude",
      "Impressive aesthetics",
      "Nice rig :)",
      "People: ‚ÄûHow much fans do you need?‚Äú\nOP: ‚ÄûYes‚Äú",
      "The Apollo program was very important to me as a kid. I dreamed of becoming an Astronaut and traveling to the Moon, until my 1st grade teacher, during a period of asking a bunch of six-year-olds what they want to be when they grow up, summarily told me \"oh they shut down the Apollo program and astronauts don't go to the moon anymore\" before moving on to the next kid in line.\n\n&nbsp;\n\n^^It's ^^fine, ^^I'm ^^sure ^^it ^^had ^^no ^^lasting ^^effects ^^on ^^my ^^confidence ^^and ^^ambition ^^:\\^)\n\n\nStill, *Apollo 13* was, and is to this day one of my favorite films of all time though, so this is really special. I've been mulling over how to theme my next build, and now I'm wondering what it would take to create a white and gold satellite-themed project, or maybe white, black and orange after the Space Shuttle - my second love after the Saturn V.\n\nVery interesting OP, thank you c:",
      "Beautiful",
      "Someone needs to do an all stainless case + brushed aluminum backed motherboard. \n\nThe \"Starship\" version of this.",
      "Well my 5900X + 6800XT gets over 330 FPS in 1440p WoT in Ultra.",
      "Hello, of course! \n\nR9 5900X (4950MHz OC)\n\nRX 6900XT\n\nAsus B-550-f mb\n\n32 Gb ddr4 Corsair Dominator 3600MHz\n\nLian Li Galahad 360 AIO with AL 120 fans+6 more AL 120+ 2 SL140\n\nLian Li Strimer Plus cables\n\nPhanteks 4.0 riser cable\n\n2x1 Tb M2 SSD(3.0 and 4.0 gen)\n\n2x2 Tb Samsung EVO SSD\n\nEVGA 1000W 80+Gold PSU\n\nThermaltake Core P6 TG",
      "Nice",
      "Thin will go brrrrt",
      "Easily one of my fav pc builds",
      "Houston, we have a problem\n\n\nWhat?\n\n\nNothing\n\n\nPlease tell us\n\n\nI'm fine",
      "Love it",
      "Missing a Kerbal",
      "That's nice",
      "Now that‚Äôs a fucking build"
    ]
  },
  {
    "brand": "amd",
    "generation": "6000",
    "tier": "top",
    "matched_keywords": [
      "6900xt"
    ],
    "title": "When you're green and blue... but ALL TEAM RED! Halo build inspired by the Halo 6900xt.",
    "selftext": "",
    "comments": [
      "What's this case?  \nedit: i guess it's corsair 280x with magnificient paint job",
      "Correct! 280x! :)",
      "Ok.... I need to know caps those are. :)",
      "I have that case with a 6800XT in it. Trust me and either go to the hardware store for some rubber grommets or 3d print the top glass risers to bring it up about another cm. It will do amazing things for the cooling power.",
      "Got it from ebay in the UK, reddit won't let me post a link! \n\nIf you can't see them on ebay, check etsy!",
      "Very nice. I wanted one for my gf's first build bought couple weeks ago but would've left it white. Couldn't find any at the time so just got her a white (as that and silvery are the themes) 4000D Airflow to contrast with my black one. It probably worked out better as the GPU and other parts I got might've been tricky to fit in a 280X though I still like that case a lot.",
      "I had to make a cut at the front to get my card in ü§£ü§£",
      "Do you have an AIO mounted in the same place?\n\nMy issue atm is that all heat kicked out from the GPU goes right into the CPU cooler!",
      "This thing is sweet!",
      "Also from the UK. Could you shoot me DM with the link to those key caps? \n\nCheers mate!!",
      "I have a 280mm rad in the top as part of custom loop. See pics in an old post on my profile. The rad can handle the gpu air better if the flow is more, so raise that glass some. Also foot extenders help.",
      "Ah I see, just saw your build (damn that thing is PACKED!)\n\nI have a hardware ship just 2 mins from me, I'll get some washers tomorrow!",
      "Rubber grommets not washers, like this but take one with you to check the size https://www.acehardware.com/departments/lighting-and-electrical/boxes-fittings-and-conduit/cable-protectors/3470051\nLet me know how it goes!",
      "Dope AF",
      "Sexy",
      "Wait, is that the face of cortana on your AiO?",
      "One of the few builds I'm actually jealous of. Well done OP!",
      "I wanna see your elite 2 halo edition besides this!",
      "Gorgeous build.",
      "Damn."
    ]
  },
  {
    "brand": "amd",
    "generation": "6000",
    "tier": "top",
    "matched_keywords": [
      "6900"
    ],
    "title": "[Hardware Unboxed] Radeon RX 6900 XT Review, AMD's Fight For the Top",
    "selftext": "",
    "comments": [
      "AMD fans: ray tracing and DLSS don‚Äôt matter because not all games support them\n\nAlso AMD fans: 16 GB memory is a big selling point because it might someday translate to a meaningful performance advantage over 10 GB Nvidia GPUs in a few games.",
      "Ain't this the fucking truth lmfao",
      "But also kinda bad for $300 more than a 3080",
      "so you can run CSGO at 7000 fps",
      "[18-Game Average (4k)](https://imgur.com/9j5UiiW)",
      "Yeah, this card just makes no sense at all. If you play purely rasterized games the 6800xt is so much better bang for the buck especially overclocked.. If you do rasterized gaming and literally anything else get a 3080. And if you need a real workstation/gaming hybrid get the 3090.",
      "my man went from a 3090 to a 6900xt to a 3080 to a 3070 in one line.",
      "And he is absolutely right imho. RT is the future but the future isn't today, neither the SW, and especially the HW power is there, clearly. This hype train, given the implementations out there and the hardware, is yet another astounding success for nvidia's marketing. We're still at the \"preview\" stage at best, and so many people are treating it like nothing else matters. Complete bonkers.",
      "Imo the only reason why the 6800/xt have 16Gb is to try to justify their price, as it stands now 16Gb is overkill for 1440p, even for 4k but these cards are better suited for 1440p high refresh than 4k as the benchmarks show.",
      "Dude it‚Äôs the best card right now price to performance wise. Why the hell omit it because of the size of the graph? Omit other cards not the best one.",
      "at https://youtu.be/nxQ0-QtAtxA?t=799\n\nHe skips 3060 Ti in cost per frame or perf/dollar charts",
      "Whats the point of ray tracing as it stands right now?",
      "4k gaming? Ultrawide 2k? 144 fps on those monitors is really hard to hit",
      "Dirt has so minimal RT its a joke for comaprison",
      "I'm not sure if you are aware but Dirt 5 is a minimal ray tracing implementation. It has barely any features and is basically the least they could have done while claiming it has ray tracing",
      "Not that much better than 6800XT though. It's good but not $350 more than a 6800XT good.\n\nNow if the 6800XT is $800 \\*cough\\*Red Devil\\*cough\\* then might as well get a base 6900XT if you can find one at MSRP.",
      "Not bad for $500 cheaper. Now if only it were... You know... Available.",
      "Because games are more important to test than synthetics?",
      "No one should talk to those people about anything.",
      "Yes; the difference in not having enough and juuuust enough is huge; literally the difference between it works and it doesn't"
    ]
  },
  {
    "brand": "amd",
    "generation": "6000",
    "tier": "top",
    "matched_keywords": [
      "6950xt"
    ],
    "title": "AMD Radeon RX 6950XT to cost $1099, RX 6750XT $549, RX 6650XT $399 - VideoCardz.com",
    "selftext": "",
    "comments": [
      "AMD marketing : 7700 XT faster than 6950 XT for only $899.",
      "Bruh this gives me no hope for next gen. It‚Äôs sucks that the low mid range segment is basically gone. No more 200-250 dollar price to performance king",
      "I'm guessing this pricing model will reflect RDNA3?",
      "Finally GPUs were dropping prices and these companies start raising MSRPs again.",
      "I'm not buying any of this crap 100%",
      "This is literally exactly what I said and predicted would happen. So many posters over the past month or two were on this tangent about how prices would return to pre-2016 levels including the MSRP's and I knew that was never going to happen.\n\nThe mfg's know that people are more than willing to pay these higher prices for these cards, and they have perfect justification for the high MSRP's. Inflation, shortages, R&D costs for the process technology, etc etc. People need to stop buying them at inflated prices in order for the prices to drop, and you cannot get enough people on board with that for that the happen. What we are seeing now with the prices dropping is about as low as its going to get IMO. + or - 10% of the MSRP's until supply is used up before the next gen release.",
      "'budget friendly mid range offer!'",
      "$400, literally same MSRP of the 3060 Ti, for a x8 lane GPU. Can't wait to see this thing be torn to shreds in the reviews.\n\n$550, price is nipping at the heels of the RX 6800, which has 20 more CUs / RAs, 4 more GB of VRAM, a 256-bit bus, and 128 MB infinity cache. With this kind of pricing structure, will AMD stop production of RX 6800s and replace it with RX 6750s?\n\nThe 6950 XT already exists - 6900 XTXH models, which are being panic-sold for less than $1100 because GPUs are available again at sane prices.\n\nI think this is even worse than the Ryzen 3000 XT refresh.",
      "Looks like the gtx980/1060 performance tier is never going to leave the 200 dollar price point. I'd kill for even 2060 performance reaching down there now.\n\nWhen it possibly comes, it's gonna be on x2 and x4 slots, so I'll still end up getting the same performance. Remember when $400 was considered the most you reasonably needed? Now, it's the bare minimum.",
      "Terrible pricing, I thought these were supposed to replace the existing cards as refreshes? \n\n**Bad AMD, bad.**",
      "overpriced for the current climate.. \n\n&#x200B;\n\npeople are cutting spending and stocks are dropping like flies today..",
      "According to leaks , they are stopping production of RX 6700XT , RX 6600XT and RX 6800 . So , the prices probably won't decrease much",
      "Here is my opinion on these prices:\n\n6950 XT at $1099 is asking a bit too much for an overclocked 6900 XT. If AMD ships the XTXH chip for all 6950 XTs it wouldn't be horrible since the premium Navi 21 cards are already more expensive than this.\n\n6750 XT at $549 is BAD, really really bad. %15 price pump would only be justified by a 15% or more increase in performance, which is highly unlikely by only adding faster memory and high clocks without core count change. At this price, the card is approaching the current 3060 Ti market price, the 6700 XT competitor. NVIDIA's feature set is superior and makes a 6750 XT at the same price look very dumb.\n\n6650 XT at $399 is fine I guess. But again, this increase in price should be justified by a proportional performance gains.\n\nAnd a reminder, these prices as shown in the posters aren't \"MSRP\", but the price of the reference models, which definitely are going to be fewer in quantity than AIB models and certainly cheaper.",
      "Yup - looks like budget game is dead. Unlesss.... perhaps I could interest you in YET ANOTHER sub rx580 level performance budget piece of crap with gimped specs for only 250 dollars in 2022?????",
      "Was considering the 6750xt but $549 seems a little steep.  I was hoping for $500 or same $479 as the 6700xt would have been better.",
      "yeah, its a damned shame theres no budget friendly entry cards, if you want somthing \"okay\" for that price its secondhand market or nothing.\n\nYou could buy a xbox or ps5 for whats \"good\" right now and thats never been the case historically",
      "Even with MSRP 6750XT‚Äôs pricing doesn‚Äôt make sense.",
      ">will AMD stop production of RX 6800s and replace it with RX 6750s?\n\nYes. \n\nhttps://www.hardwaretimes.com/amd-radeon-rx-6750xt-to-replace-the-rx-6800-lower-performance-same-price-for-better-profits-report/\n\nObviously this is just info from an inside leak, but we've no reason not to believe it.",
      "That's ridiculous. Guess I'm gonna be using a 1070 for a decade..",
      "It's the same thing as the 3070ti, 3080 12GB, and 3080ti, now the GPU has higher yields they rebrand the card for an higher price and this way they can get more money out of that silicon"
    ]
  },
  {
    "brand": "amd",
    "generation": "6000",
    "tier": "top",
    "matched_keywords": [
      "6900xt"
    ],
    "title": "Woodlicious 5900x 6900xt",
    "selftext": "",
    "comments": [
      "I love how well the noctua colors fit",
      "First time in history",
      "Introducing the Woodlicious!\r  \n\r  \nThis build has been in the making for almost six months, partly due to the GPU shortage but I took my time with this build adding and perfecting mods the best I could. Finally purchased the GPU this January as it was the closest to retail price that I could find.\r  \n\r  \nAll the mods on the case are my own, the top panel EKWB block, PSU and RAM covers are all laser cut from European cherry wood, combined with 3D printing they slot on firmly. The feet are cast from concrete with added black pigment, it‚Äôs closer to anthracite but I love the organic look of wood, stone and copper.\r  \n\r  \nIn regards to the components I decided my build would be built around the 5900x and 6900xt both the CPU and GPU are performing admiringly. CPU temps are between 55-65 under heavy loads, and the GPU sits comfortably and quietly at 64 degrees.\r  \n\r  \nOverall I couldn't be happier with the build it‚Äôs been a long time coming and my 6600k was starting to show it‚Äôs age with only four cores. \r  \n\r  \nFeel free to ask any questions or critique the build, and thanks for stopping by.",
      "That is probably the only build in existence in which the noctua fan color actually looks nice",
      "Yup, came here to say this is the first and only build I actually like these fans in",
      "That is absolutely beautiful. The wood accents on the components looks phenomenal, you are really good at this. One of the favourite builds I've seen.\n\nPlease say you sell these",
      "madlad made a entire build so his noctua fans can blend in ü§£ü§£ü§£",
      "Yea, I've got a woody over this sexy beast!",
      "This is literally the best looking build I‚Äôve ever seen dude. Bar none.",
      "Finally someone posts a build I actually like.",
      "But‚Ä¶ why wood you do this?\nAlso, the lower back side needs some more lumber support‚Ä¶ \n\nOk, I‚Äôll see myself out now‚Ä¶ Great build btw!",
      "I was thinking the exact same thing!",
      "Yeah thought the brown and beige colour scheme would fit perfectly.",
      "I want it!",
      "I think everyone thought the same exact thing",
      "Gorgeous",
      "Your execution for the wood is amazing even before seeing the Noctua fans I thought this build looked Epic, then the Noctua fans only made it that much better! This PC is stunning!",
      "What case is that",
      "Budum tis",
      "Hey thanks for the kind words, and yes I do just pm me if there is anything your interested in."
    ]
  },
  {
    "brand": "amd",
    "generation": "6000",
    "tier": "top",
    "matched_keywords": [
      "6900xt"
    ],
    "title": "Loving the upright GPU! (6900XT, 5950x, O11 Dynamic EVO)",
    "selftext": "",
    "comments": [
      "Sorry but upside down PCs give me anxiety lmfao",
      "Not my favorite thing. Lian li released a 600mm riser to route through the back, but wasn't available here yet",
      "As someone who builds PCs for a living I couldn't agree more with you. They just feel wrong to me, it's like one of those cooking videos where you see an Italian flipping out because someone is not following the traditional recipe.",
      "Ayo your computer is upside-down",
      "OP bought the most expensive parts he could find.  I don't think saving some cash on the CPU was really a concern.",
      "Does the gpu temperature get better that way?",
      "Heat only rises in cases with no fans.",
      "Why not?",
      "It definitely runs cooler than in the horizontal position, both in this case and in the Lancool ii Mesh that I was using before this. I've been able to dial back the fan curve on the GPU and still have it perform as good/better than before. Here's my latest Timespy run:\n\n[https://www.3dmark.com/3dm/74128017](https://www.3dmark.com/3dm/74128017)",
      "The fact that heat rises is irrelevant, considering the amount of fans, but I agree that the back fan is useless, in fact some of the fresh air from the bottom fans just goes out the back directly, not cooling anything.",
      "Yea, I had two spare Noctua NF-P14r that I mounted behind the GPU as intakes, so it's getting lots of air from the back. \n\nMost reviews I've seen have set it up with the side fans as exhaust in an upright GPU scenario. I might switch it up and compare, but I've been pretty happy with the results so far.",
      "Makes me feel dizzy",
      "I think jayztwocents  if I remember  correctly   could have been someone  else but either way they did a video of this case and he ran that riser cable behind the motherboard tray for a super clean look.  Might be something worth looking into",
      "This rig is üî•",
      "Does those PCIE extenders affect the performance at all? Especially the longer ones?",
      "I like it. Makes me want to swap out my O11 XL for the evo. Just waiting for an XL evo.",
      "Is upside down!!!! Back fan(exhaust) not doing much because heat rises. Is this intentional?",
      "So you moved your hottest component out of the way of all of that airflow you paid for.",
      "How TF is the monitor plugged in?!? The GPU's output ports are *inside* the case. If it's more than 15 C cooler under max load, I guess so. But those cables just hanging in the middle completely ruin the aesthetics. This is some /r/firstworldanarchists shit right here.",
      "At this length it should have negligible impact on performance. Lian-Li released a 600mm one that you can route behind the case and it is also supposed to be able to support the full PCIE4 x16. It gets sketchier when you daisy chain multiple short-length risers together (though they also sell a shorter riser that is meant to extend this one, and apparently still works fine).\n\nIn addition to the riser, I'm also running it at x8 speed due to the Thunderbolt card I added to the other x16 slot (AIO is blocking the other slots). Even with that, it's performing better than it did when I had it plugged directly into the slot, likely due to the improved thermals."
    ]
  },
  {
    "brand": "amd",
    "generation": "6000",
    "tier": "top",
    "matched_keywords": [
      "6950xt"
    ],
    "title": "AMD Radeon RX 6950XT, 6750XT, 6650XT RDNA2 refresh with 18Gbps memory now expected to launch on April 20/21 - VideoCardz.com",
    "selftext": "",
    "comments": [
      "More like 1st April.",
      "These are 7nm I presume (although they could be 6nm in which case a clock bump + memory speed bump would make a reasonable refresh with +10% perf or so).\n\nN31 is 5nm GCD + 6nm MCD so they are using different nodes which means they can be built alongside each other without really impacting on capacity.\n\nFurther if N31 is the 1st RDNA 3 part and 2.5x performance is true expect a new price tier for 79xx series parts rather than a replacement of the $1,000 tier 6900XT.",
      "Why, when the 7000 series is supposedly around the corner. With a chip shortage, isn‚Äôt it better to concentrate on getting the 7000 series out?",
      "Same chip, better memory ICs, this is not a new product, but a minor refresh.",
      "tl;dr: based on AMD's behaviour over the last 7-ish years of GPU launches, AMD will service lower price points with older cards based on RDNA2. RDNA3 will only be used for premium SKUs for maybe 6-12 months.\n\n---\n\nRDNA3 will probably follow AMD's tried and tested strategy of, when they have fast products which can compete with Intel/Nvidia, only having high-end and upper-mid range products at launch. They thus use last-gen parts to service the lower-end market segments for 6-12 months. Recent examples include:\n\n* Ryzen 3000 desktop (Ryzen 2000 was lower-end))\n* Ryzen 5000 desktop (Ryzen 3000 was lower-end)\n* Ryzen 5000U (Zen 2 based APUs were lower-end, not Zen 3)\n* Ryzen 6000U (Zen 3 based APUs were lower-end, not Zen 3+)\n* Threadripper 3000 (TR 2000 and the 3950X were lower-end)\n* Radeon RX Vega series (RX 500 series was lower-end)\n* Radeon RX 5000 series (this didn't even have a top-end, and Vega and RX 500 filled in the gap until the 5600/5500 series)\n* Radeon RX 6000 series (gaps filled by RX 5000, Vega and RX 500, until the 6600 / 6500 XT launched)\n\nAMD aren't Intel; they have about a quarter of the manufacturing capacity, so aren't in a position to flood the market with SKUs top to bottom. AMD have, in fact, not done a top-to-bottom SKU launch on desktop within a launch window since maybe 2010 for CPUs (Phenom II) and 2015 for GPUs (RX 300 series). Every other launch since has either been top-heavy (e.g. Threadripper 3000) or bottom-heavy with no real flagship that can compete against Intel (e.g. 1800X and 2700X were still far slower than the i7-7700K and i7-8700K in gaming).\n\nExpect AMD's late 2022 GPU product stack to look something like this:\n\n* Titan-class prosumer card: \"Rage Fury RX Turbo\" with 2.5x the performance of the 6950 XT\n* Ultra-enthusiast: \"7990 XT\" - 2.2x the 6950 XT\n* High-end enthusiast: \"7900 XT\" - 2.0x the 6950 XT\n* Enthusiast: \"7900\" - 1.7x the 6950 XT\n* Lower enthusiast: \"7800 XT\" - 1.5x the 6950 XT\n* Upper mid: \"7800\" - 1.2x the 6950 XT\n* Mid-range: no 7700 XT at launch, just a cut-down 6950 XT\n* Lower-mid: no 7600 XT at launch, just the 6750 XT\n\nProblem is, all SKU tiers will move up in price. I'd expect the 6750 XT, for example, to be far more expensive than the 6600 XT despite filling the same relative performance tier.",
      "new gen every 2 years\\~ish?",
      "Demand is still very high for these parts, new parts are a way off (six months or more), and releasing a very slightly updated existing product doesn‚Äôt detract from anything upcoming. It‚Äôs really just ordering different memory chips.",
      "Tsmc have a certain manufacturing capacity agreed with amd. That capacity needs to be met at all times for both companies profits and future business. Rdna3 may not have been in manufacturing when these refreshes began to be made. Stopgap cards like these arent just to fill a small hole in the market but a small hole in manufacturing capacity too",
      "What are the \"7000 is around the corner\"expectations that I see in comments based on?",
      "*excuse to raise msrps",
      "Around the corner probably means at the end of the year; October or later. Plenty of demand to fill in the meantime.",
      "They are only refreshing the highest SKUs of Navi 21,22 and 23. \n\n6800XT is a cutdown Navi 21.",
      "I don't see the point.  How much extra fps does 2 more gbps give?  My 6900 xt toxic LE is already 18 gbs.\n\nEdit:  That good silicon could be put to use on next gen or bettering the 6500 xt.",
      "5nm process, MCM, refinement of the architecture (RDNA3 is a bigger departure from its predecessor than RDNA2 was). Major improvement to perf/watt once again.\n\nThe 6900XT is a less than 300W card. Efficiency improvements brought by the process and the architectural changes could bring it down to 200-225W. Put two of them together thanks to MCM, and you're at 400-450W, for 2x the perf. And finally add the RDNA3 improvements and you get a 2.2x or so monster of a GPU. Really not inconceivable, it's just that years of +5% yearly by intel and +30% every couple years by Nvidia made us believe we had reached some sort of wall. That was never the case, the issue was always the lack of incentive for any of these companies to really push the envelope. Now we have AMD delivering on both CPU and GPU sides and look, intel just dropped one of the biggest performance leap in CPU perf of the past 5 years. Of course that wasn't just because of AMD, these architectures take many years to develop but it's no coincidence such a big perf jump happens when they have to defend their marketshare.\n\nNvidia Lovelace is also rumored to be a giant leap (but not quite to the level of RDNA3 because of the lack of MCM)",
      "The 6900xt is pretty much a 6800xt with faster clocks so it makes sense why there isn‚Äôt",
      "Navi 31 is projected to be 2-2.5x the performance of the 6900 XT. There's no way the 7900 XT will be $1000 (the same MSRP as the 6900 XT) unless the 7900 XT is only about 1.2x the performance of the 6900 XT.\n\nBeing realistic, the actual 7900 XT will be about $2000. 2.5x the performance, for 2x the price...",
      "This new trend of excusing price gouging with \"performance gains\" is the worst thing MLD unleashed on the technosphere. üò© If we normalize this, all tech products will forever increase in price, which is the reverse of how it has been historically.",
      "It's working for Nvidia with the 12GB 3080, 3080ti, 3070ti, and rumoured 3090ti.",
      "I have no such crashes with a 6800 xt. Their drivers have been solid, maybe try a clean install of them using DDU to remove the old.",
      "7900XT is enough for me, $999 only plz thanks. They have prosumer to take the higher brackets now, leave the $999 bracket for the 7900XT to pair with a Zen 4 7800X for maximum gaming."
    ]
  },
  {
    "brand": "amd",
    "generation": "6000",
    "tier": "top",
    "matched_keywords": [
      "6900"
    ],
    "title": "Even AMD's $999 RX 6900 XT can't cope with Cyberpunk 2077's new Radeon ray tracing mode",
    "selftext": "",
    "comments": [
      "6900 XT? $999? Rookie numbers!",
      "Of course not, \n\nThe performance from Nvidia with dedicated rtx cores sucks with ray tracing. \n\nWe are years away",
      "Enable DLSS then. That's why it's there. Nvidia didn't implement both technologies simultaneously for no reason. RTX with DLSS should look better while performing the same as native without RTX.",
      "True, we are years away from uncompromised RT gaming.\n\nBut if we're willing to compromise a bit, RT does look good.\n\nI just lower down the resolution to 1080p, set RT to medium and use only Ray Tracing Reflection/Shadows, my 6900 XT can run it above 60 fps. Playable! Enjoyable experience even.\n\nWith a DLSS like alternative, it could be running at 1440p, 60 fps with more tweaks.\n\nI say it's better to have a choice to experience a bit of RT than not, on a Radeon card.",
      "For that money you can probably get the now familiar \"jpg file\" of a 6900 XT.",
      "I have only seen those obtainable for 1400‚Ç¨",
      "We always have to compromise, even with the best GPU.",
      "It doesn‚Äôt matter. If they can render the whole thing at 720p and upscale to 4k and it looks amazing then that is a victory not a concession",
      "Yeah, raytracing is still a looong way out. Looking forward to a DLSS competitor atleast, which is a little shorter of a wait üòÇ",
      "Says a person with R9 380.",
      "yeah playing at 1440p RT on and DLSS on my RTX 3090\n\nits sometimes hard to tell that DLSS is actually on and some games do even look better with DLSS on than on native resolutions as certain types of textures (e.g. with stuff written on) looks more crips and is more readable than on native",
      "Chicken and egg problem though. We have to start somewhere or we'll never get to the promised (ray-traced) land.",
      "And the higher quality png file costs an extra 250",
      "It's barely playable with a high-end nvidia card(2080s personal reference) with RT enabled, we already knew that AMD RT was lower performance.\n\nNobody should be surprised by this. And I would say RT is still not really ready.",
      "> which is a little shorter of a wait \n\n*Maybe*, AMD is as bad as Valve for timeframes, until it's released, I'm considering that it's canceled.",
      "I'm getting Ferrari / another supercar for a heck of a money, and then I feel cheated if it doesn't teleportate me anywhere",
      "Not always, depends on the quality setting. You could have 4k DLSS at 1080 or even 720.",
      "It doesn't. I suggest you look at OPs post history he has a massive hard on for DLSS for whatever reason and is down voted constantly for saying bs like this on a AMD sub (which according to him is from shills because if people down vote you for being an outright liar it's because they are shills....)\n\nOn top of that saying poeple who don't have an RTX card think it's flawless and then not having one and saying it's shit should be an indicator that the person is full of shit.",
      "Nvidia let's not forget also might raytrace at a lower resolution internally and use DLSS to upscale PLUS they don't have to do as many passes since they use the AI denoiser as well..AMD needs to catch up",
      "But its extremely playable with RT on nvidia.  Years away? What nonsense."
    ]
  },
  {
    "brand": "amd",
    "generation": "6000",
    "tier": "top",
    "matched_keywords": [
      "6900xt"
    ],
    "title": "Your 6800XT/6900XT is not going to die, chill",
    "selftext": "Made a video about for more explanation:\n\n[https://www.youtube.com/watch?v=GpbEAh\\_5fBc](https://www.youtube.com/watch?v=GpbEAh_5fBc)\n\na TLDW: It's not the drivers and what kris said was borderline insane. Think about it for longer than 10 minutes and you'll realize how ridiculous it is. When seeing news on videocardz and so on already taking what kris said as fact who literally made sht up that doesn't conform to reality and spreading fakenews is absolutely astonishing.\n\nI know kris probably didnt meant to cause such a ruckus and had all good intentions and probably only said those insane things because he probably overworked himself to try to get to the bottom of the defects but good lord did it produce a disaster.\n\nYou guys literally need to learn to process information and not take everything anyone says as a fact the moment you hear it without thinking for yourselves.\n\n**EDIT**: I want to make completely sure you guys understand, this refers to his **part2** video where he is talking about nonsense like he ***thinks*** all cards are from 1 miner and somehow humid and cold conditions somehow magicially blow up the GPU die because reasons. By that logic notebooks would have common blown up GPU and CPU die's and we would see tons of more posts where people report this issue, however we don't. As mentioned in my video, his theory is wild and nonsense, backed up with 0 proof.\n\n**EDIT2:** Because people seemingly cannot stop making dumb arguments about the humidity argument.\n\nIf you think storing cards in a humid enviroment did cause GPU cracking: [https://www.youtube.com/watch?v=V-4\\_uNE1tQU](https://www.youtube.com/watch?v=V-4_uNE1tQU)\n\n*Do you still think storing in humidity caused the GPU to break like kris showed?!*",
    "comments": [
      "Well, every stupid kid out there jumped on the clickbait headline train.",
      "I have had my 6900 XT for nearly 2 years.  I am not worried about this at all.",
      "Well it didn't help that other youtubers jumped on his news and ran to spread it for their own content. I would say they should have been a little more cautious.",
      "Thats what they shouldve asked too",
      "Mostly Nvidia fanboys honestly lol",
      "Click on the profiles of the people posting this stuff.\n\nIt reveals itself real fast.",
      "Hysteria gets views. Remember when AM5 launched and all the YTers had flaming CPU thumbnails over intended, perfectly safe behavior?",
      "What do you want a bar chart or a scientific study? From what I‚Äôve seen, it‚Äôs been mostly people that then go on to say how Nvidia is better etc.",
      "This situation wasn't helped with YouTubers like Jayz2cents jumping on the band wagon and putting vids out about it before anything was fully analysed. \n\nI wish these guys would control themselves instead of pumping out click bate trash.",
      "Ive had 6800XT Gaming X Trio for almost a year and it runs as good as the day I got it. I tested it extensively the last few days after seeing all the news and everything is still tip top.",
      "My comment for the video:\n\nActually, AMD has massively restricted the use of the SoftPowerPlayTables and thus indirectly also the MorePowerTool with the Adrenaline drivers from 2020\n\nWhat people do to overcome this is modifying entries in their VBIOS  So it becomes \"using modified VBIOS\" case\n\nAs for low temperatures, phone and laptop manufacturers usually specify allowed temperature range. Usually it's something like 0C - 40C.\n\nThese devices can work at lower temperatures but there's no guarantee they won't break. \n\nAs for the sealing, miner could clean cards in some sus way (with water), and re-seal them. Not exactly unheard or impossible thing.\n\nThe fact that all those cards don't have official warranty and didn't came from official distributor sorta confirms it.\n\nBasically KrisFix got all those cards in the first place, because they don't have official warranty.",
      "The # of manufactured controversies that all occurred right around the launch of Navi31 is telling. I mean this (driver hysteria), plus derbauer's explosive GPU, along with \"estimations\" on defective cards, plus an endless supply of vague comments from recently created users saying AMD cards just \"weren't for them\" or whatever. It's too much too close together.\n\nAnd this is not in any way a defense of the Navi31 launch which was clearly messed up. This is pointing out that there have been an unusually high number of manufactured controversies with no data whatsoever designed to discourage consumers from purchasing AMD cards. Also, last disclaimer, I've been using Nvidia cards for about a decade until last month, so no attempts to point out bias please.",
      "most sites that are proper news site said old mining cards stored wrong killed the cards",
      "the moment this news popped up i knew this was gonna be a shitshow\n\nthere is and was no way for the card to be killed by a driver because driver has no access to any controllers there\n\nyou would have to modify VBIOS in order to kill a card\n\nmining usually revolves extensive VBIOS mods which touch upon the way GPU core will function which can cause damage\n\npower play table mods or any power related mods are direct way of changing the way card behaves,kinda like changing A/F ratio or timing in engines which we know can absolutely cause serious damage\n\nthis is a warning that cards can and will blow up if treated like shit",
      "KrisFix shouldn't have run with the assumption.\n\nIt is bad science.",
      "define stored wrong and source such a newsite. \n\nIf they said something like \"Old mining cards stored while running in a dusty shed so they choke to death and kill vram\" then they'd be right. If they say deny basic physics and boom GPU die explosion because liquid can now deny solid matter and go whereever it wants, I'd question what you define as proper news site.",
      "That's for the 7900 AFAIK, and it's still a known issue in the driver notes.",
      "He should have tested it before making misleading claims.",
      "The problem is that the truth doesn't pay their bills - clickbait does.",
      "Nvidia pays well in marketing."
    ]
  },
  {
    "brand": "amd",
    "generation": "7000",
    "tier": "low",
    "matched_keywords": [
      "7600",
      "7600xt"
    ],
    "title": "Looking to buy a 7600 XT.",
    "selftext": "My current video card is a 1060 6GB running with a Ryzen 5600X3D (I got a great bundle deal at Microcenter).\n\nIt is a hand me down card that I have been running for about 6 months.  It does surprisingly well for the games that I play.  I'm not unhappy with it and I'm happy to have something that runs well with some settings turned down.  What I really don't love is that it sounds like a jet engine with almost any game running.  I did have some thermal paste that I re-applied to it, which helped a little, but it is just so loud still.\n\nMy previous card was a 5600xt that I bought to finally replace my workhorse - the 760 GTX.  I only used the 5600 for a short bit, though, as I built a budget system for my son but couldn't afford a decent video card (this was during \\~2020-21).  I installed my 5600xt in the system I gave him and I went back to the 760.  The 1060 was handed down from a friend.  All this to say that I have gotten used to lower settings :)\n\nI recently started looking at an upgrade and thought that the 7700xt looked like what I wanted - until I saw that the prices were pretty solid at $429+.  The 7600xt was my next choice.  I didn't love it at $329 but I have a gift card to microcenter to take it down to $280.  With tax that would be \\~$304.  Then I saw one that was open box for $280, which would be \\~$250 out the door.  I feel like that is a price I can afford and not a bad price for a 7600xt.  The cheapest out the door for a 7700xt would be \\~$412.  That's not something I can do right now.\n\nI have a 1080p monitor and have no plans to upgrade that in the near future.  I'm really just looking for constructive thoughts on whether I should move on the open box 7600xt or just hang onto the 1060 for now and see what else comes along.\n\nThanks for any help!\n\nedit:  Adding my \"out the door\" cost for different cards at Microcenter.  I added more thoughts to a comment below but I'm thinking that the 7600xt open box is my best option.  If not for that it would probably be the 7600 with some thought on the 4060.  I'm also thinking that I might keep watching and see if the 7700xt comes down at all - or maybe I find an open box to bring it down a bit.  Although maybe that is just overkill for what I use it for.\n\nAlso added the 6750xt.  I need to look into that one more.\n\n4060\t          $273.39\n\n4060ti\t          $370.41\n\n4070\t          $542.89\n\n7600\t          $241.05\n\n7600xt\t          $305.73\n\n7600xt ob        $252.87\n\n7700xt\t\t  $435.09\n\n6750xt             $348.85\n\n&#x200B;",
    "comments": [
      "The 7600XT isn‚Äôt a great value at all. Barely any improvements over the cheaper 7600.",
      "At 1080p you aren't up against the 16GB VRAM wall, not even close, might as well just get a vanilla 7600 or if you want DLSS etc a 4060 which would be probably $30-40 USD more but still should be cheaper than a 7600XT.",
      "I didn't consider this but I am looking into it more now.\n\nI can't get a 6700xt at MC but I can get a 6750XT for $348.  \n\nThat card looks like it falls in between the 7600xt and 7700xt and close to the 4060ti.\n\nThanks!",
      "6700 xt.",
      "Don't. The 7600 XT is not worth the money. You'd be better off with a 6700 XT.",
      "Thanks for your thoughts!\n\nI'm seeing that the memory bandwidth is the same on the 4060 as the 7600xt.  One review showed the cards being very close, swapping the 1 and 2 spot from game to game, but that the few VRAM heavy games showed a double digit advantage to the 7600xt.\n\nI'm leaning towards more VRAM, not for any need to feel cutting edge but from my history of modding Skyrim :)  It was always one of the key metrics to consider.\n\nStill, I put a list together of what I could buy at Microcenter today.\n\nIf the open box 7600xt were not available I would be looking solidly at the 7600 for $241 - and I'd have to give some thought to the 4060 at $273.  The 7600xt is $60 more at $305 and, other than the extra VRAM, doesn't seem like much of an improvement.\n\nIf the 7600xt open box works out, at $252 it seems like the best option for me.\n\n4060\t          $273.39\n\n4060ti\t          $370.41\n\n4070\t          $542.89\n\n7600\t          $241.05\n\n7600xt\t          $305.73\n\n7600xt ob        $252.87\n\n7700xt\t\t  $435.09",
      "Thanks for the feedback!\nI'm getting set on the 6750xt",
      "$250 for 7600XT is a decent deal for sure.",
      "Yeah, I'm leaning this route.  \nThe 6700xt would probably be my choice but it is completely not available through MC.\n\nThe 6750 is $100 more than I was planning but it really seems like a better future proof card compared to the 7600xt.  The open box price is the only thing that makes the 7600xt more desirable.  Without that it is $50 more for a lot better performance. But a slower memory bus (although the 4060ti is right there with the 6750 - slower bus and all)",
      "I didn't get there yesterday.  Today they have an ob 6750 for $298 out the door.\n\nI'll try that if the box looks ok.  The main negative I'm seeing is coil whine - but I have 30 days to return if it is a problem.",
      "If you check Tom‚Äôs GPU Hierarchy, the 6750xt seems like the clear choice. They have it outperforming every other card on your list except the 7700xt. \n\nBUT - it‚Äôs worth mentioning that the AMD cards don‚Äôt handle ray tracing as well. I don‚Äôt know how these specific cards compare, but it‚Äôs something to consider. \n\nI run a 6950xt (Also Microcenter, $499 with cpu purchase a few months ago!). I was starting to regret the purchase due to driver issues, but I installed the AMD pro drivers and haven‚Äôt had any problems since. I mention this to say that I‚Äôve turned ray tracing on in Hogwarts and Cyberpunk, and didn‚Äôt find the difference big enough justify spending $200 more on a Nvidia card. Just my two cents",
      "Thanks for the info!\nI'm pretty focused on the 6750 right now.\n\nRay tracing enabled really drops the performance but that looks like it's the case with all AMD cards right now. I can live with that.",
      "Today there is a nob 6750 which would be $298 out the door.  \n\nI can't pass that up.",
      "I'd just buy the rx7600 and enjoy the same performance."
    ]
  },
  {
    "brand": "amd",
    "generation": "7000",
    "tier": "low",
    "matched_keywords": [
      "7600"
    ],
    "title": "AMD announces $269 Radeon RX 7600 RDNA3 graphics card - VideoCardz.com",
    "selftext": "",
    "comments": [
      "If what AMD said about the 7600 being 29% faster than the 6600 is true , it should be around 6% faster than the 6650XT (based on HUB comparison video of the 6650XT against the 6600) . \n\nSo, the RDNA 2  CU -> RDNA 3 CU performance jump seems to be quite small (both the 6650XT and the 7600 has 32 CUs) \n\nThe main differences between the 7600 and the 6650XT are -\n\n**TDP :**\n\n7600 - 165W\n\n6650XT - 180W\n\n**Memory Speed :**\n\n7600 - 18 Gbps\n\n6650XT - 17.5 Gbps\n\n**Base Clock, Game Clock and Boost Clock -**\n\n7600 - 1720 MHz, 2250 MHz and 2625 MHz\n\n6650XT - 2055 MHz, 2410 MHz and 2635 MHz\n\n**Bandwidth** -\n\n7600 - 288 GB/s\n\n6650XT - 280 GB/s\n\nThis difference is not relevant but the 7600 has around 13.3 billion transistors and a die size of 204 mm¬≤  as compared to the 6650XT, which has 11.1 billion transistors and a die size of 237 mm¬≤ . The 6650XT is also built on the TSMC's 7nm node while the 7600 is built on TSMC's 6nm node",
      "So around the RX 6700 10gb price, which is likely faster with more VRAM, a wider memory bus and a full x16 lane\n\nTerrible value right now, buy it when it inevitably drops to $200",
      "That's the AMD way! Sell high, review badly, become great value once your brand is tarnished and nobody can afford Nvidia",
      "Remember when new 1080p gpus were 200-250 dollars, like‚Ä¶. 6 years ago?",
      "The RDNA3 CUs on Navi33 have their VGPR trimmed compared to Navi31 (128K vs 192K) while being the same as Navi2x (also 128K per SIMD). So architecture wise it's actually somewhere in between RDNA2 and RDNA3. The \"real\" RDNA3 CU like those on 7900 XTX have \\~17% perf improvements per clock as shown in AMD architecture slides.",
      "And they were *actually good mid-range offerings* rather than a straight-up joke?",
      "'very nice' is an interesting choice of words. Its extremely stagnant, dont compare it to msrps of last gen compare it to current selling price. Its a 6700 with av1 but loses 2gb of vram for the same price with slightly lower power draw. Thats a pathetic gen on gen increase when you compare to previous gens where at least a tier above if not two performance wise for the same price point was expected. TBH its pathetic that in 2023 a 250-300 dollar card targets 1080p when thats what the rx480/1060 did at the same price point in 2016. By now 1080p high settings should be relegated to the 50/50ti class cards especially when you compare it against the experience a console provides at its price point.",
      "For the price difference that is cost of ONE game you can just get 6700xt and play 1440p reasonably well. I just dont get these new 1080p gpus.",
      "unnecessary big brain marketing, but I guess when 5600ti releases everyone will recommend the 7600",
      "So this is basically an \"6675xt\" with av1 encoding.",
      "we reached the point when 60 FPS in 1080p is a selling point.",
      "> So, the RDNA 2 CU -> RDNA 3 CU performance jump seems to be quite small\n\nYeah, iirc it was around 9% IPC improvement from the 6950XT to 7900XT/7900XTX when I did the math, so same clocks+same CU count would only put a card ~9% ahead, although 7600 is on 6nm rather than the 5nm of the 7900XT/7900XTX, so it *might* not even be as good of an improvement.",
      "200 in 2016 is equal to basically 250 in 2023. Inflation pays a part sure but mostly it‚Äôs Nvidia and to a slightly lesser degree AMD getting greedy.",
      "Soooo... the 6650XT is currently at 250 euros while this card costs 300 euros which is 20 euros more than the 6700 and 20 less than the 6700XT. I think that there is nothing more to add in regards to this pricing. Once it drops below 250 euros it will be a fine card, however if it had just a little bit more VRAM it would have been a good card below 250 euros.",
      "The A750 is $249 MSRP. AMD and Nvidia doing their best to increase Intel's market share.",
      "Maybe you want to stone me, but I believe that while 10 or 12 GB would have been nice, I think that f√ºr a 600 level card the 8gb should be fine. On the other hand I think that the 7700xt should have 16gb and the 7700 and 7600xt should have something in between. \n\nBut for the normal 7600 8 gb is ok in my opinion. The will probably be the cheapest card that AMS is going to sell and 8gb for the lowest entry is still fine.",
      "It feels like they're unsure of RDNA3 as a whole, they released the best cards they had and even those underperformed. They're lacking the confidence they had last gen",
      "Eventually, when the 5060ti releases in 3 years and is only 8 % better than a 4060ti, while being worse in some games and costing 499.",
      "They dropped the price to $200",
      "Reviews are today? Even then, a 29% performance increase versus the 6600 (if confirmed) means this is just a 6600XT/6650XT refresh sold as a non-XT card for pricing reasons.\n\n**Edit:** By the way, this is the GPU chip that was supposed to match the 6900 XT according to MLID? ROFL."
    ]
  },
  {
    "brand": "amd",
    "generation": "7000",
    "tier": "low",
    "matched_keywords": [
      "7600"
    ],
    "title": "AMD Radeon RX 7600 XT 16GB launches January 24 at $329, same core count as non-XT model",
    "selftext": "",
    "comments": [
      "AMD: Overprice at launch > bad reviews > Pricecut > okay reviews > repeat.",
      "Idk man, I think this card should be no more expensive than $300 when 6700XT is retailed $320~",
      "More like AMD: Overprice at launch > bad reviews > Pricecut > most reviewers don‚Äôt update reviews for price cuts so still bad reviews > repeat. And then they wonder why Nvidia has more market share",
      "AMD wanted their own 4060 TIs...",
      "The reviews will shred this card to pieces, 4060 ti style. The 6700 xt is simply better.",
      "This or a used RX 6800 16GB which is 50% faster? Jesus Christ the choice is so difficult!",
      "Maybe AMD shouldn't overprice then. Reviewers shouldn't be expected to return to a 6 month old product because it costs $100 less now. If AMD wants favorable reviews, make it $100 cheaper from the start.",
      "It may make sense to overprice it if they're still trying to clear 6700 XT inventory. For the same money you either get last gen with better performance or current gen with worse performance.",
      "Even when they cut prices, it's after gritting their teeth and taking too long.\n\nThe 7900 XT came down it price, but it took 6 months or more. That was to get to a price it should have been at launch. How impressive is it when you get a price cut after 6 months, and it's to where you should have been to start? You're still overpriced, IMO.\n\nThe 7800 XT fits this issue. People talked up that the 7800 XT had value because it replicated 6800 XT performance for $500, while the 6800 XT was a $650 card. Thing it, it released 3 years after the 6800 XT, which was already being discounted into the $500 range.\n\nPeople need to tell AMD (and Nvidia) to keep taking these prices and shoving them up their butts. A $1,000 7900 XTX being $920 (8% off!) during Black Friday a year after release sucks. A 7800 XT being a 6800 XT copycat for the same price as a 6800 XT sucks.\n\nThe market is trying to impose a universal price hike, and consumers need to smack it down.",
      "So more expensive than the 6700 XT but 15% slower?   \nWhat a joke\n\nFor this level of performance even 299 would be stretching it. At 329 it's DOA. Keep in mind, this is literally almost half the performance of a 7800 XT.",
      "The 16GB 4060ti is $120 at a minimum more for a card that's less than 20% faster",
      "So worse than a rx 6700xt but it has more vram (for what exactly?).",
      "My point exactly",
      "This would be sweet at $250.. \n\nThese should be cheap to produce, \n\nBut 6700 and 7700 are always going to be breathing down the neck. 12gb is enough vram at this price performance level.\n\n6800 16gb exists with double the memory bandwidth..",
      "What a waste. AMD going Nvidia way, what a shame.",
      "Well yes, but they could've also not have launched it yet. \n\nUnless 6700xt stock is finally drying up",
      "Because 12GB is plenty for the power the 6700xt have. And the 7600xt will be 20-30% weaker\n\nEdit: Scratch that, its more likely 10-20% difference. [7600 test](https://youtu.be/Yhoj2kfk-x0?si=86GUrkhfcbk5CuGY&t=918)",
      "For the idiots who cry about VRAM quantities but actually know nothing about it.",
      "They aren't wondering, they know why. Nvidia has had a 70+% share of the market for like a decade now, far longer than AMD's \"milk em' while we still can\" pricing strategy. They tried everything and they just lost, every time, regardless of how good or bad their GPUs were. \n\nThey've given up because most gamers just don't care and will shuffle their priorities around in any way possible to justify buying the latest Nvidia XX60 again and again.",
      "When you say \"regardless of how good,\" which generation do you think AMD's GPUs had any business \"winning?\" Thinking back to the last several:\n\nPolaris: Decent offerings with good value, but sat around for WAY too long. Didn't really compete beyond the 1060, meaning the 1070 and 1080 families faced no real competition.\n\nVega: You got all of two products, which launched during a mining frenzy. The $400 Vega 56 and $500 Vega 64 were it, since the Vega Nano got canceled. The V64 was a 1080 competitor that came out a year after the 1080. Yeah, you had the Radeon VII at the end of the generation, but it was just repurposing workstation silicon instead of tossing it, and the $700 price tag made it a non-starter for what it brought.\n\nRX 5000: RDNA came out with a good set of cards, but the 2070 was where they stopped competing. It left the top of the market untouched, while also competing a year after Nvidia's stuff was already in people's computers. If you were the target of an RX 5000 product, you were already a target of RTX 2000 a year earlier.\n\nRX 6000: AMD had a pretty compelling product here. The biggest issue here (other than the hole dug by the previous generations' woes) was the overall market. Everything was being gobbled up, production was spotty, so there was no ground to gain. Whether it was from crazy demand or tight supply, having everything sell through immediately is going to favor whoever's production is higher.\n\nRX 7000: Again, AMD's not competing at the top of the market, is late to market, and is generally not putting products on the shelves. The 7000 family launched with only the 7900 family, and one of those cards (XT) was comically overpriced for what it was. They spent another full year waiting to release the 7700 Xt and 7800 XT, which didn't provide any value or fill a market that was already being taken care of (6800 XT performance for then-current 6800 XT pricing isn't sending anyone running to the stores).\n\nAMD's been spending a long time firing most of its bullets into its own feet. Where Ryzen launched as a competitive product with aggressive pricing, Radeon products are often a combination of late to market, as far behind in performance as they are ahead on price, and generally not offering anything noteworthy for the wait. Ryzen offered a breakthrough in consumer core count for relative bargain pricing, then caught up on performance while staying price competitive on most every level.\n\nAMD's got loads of progress to make, if it wants. It just seems that AMD doesn't consider consumer GPUs to be a significant market. Whether it's superior margins with datacenter, inferior engineering, or something else, GPUs are a market where AMD is failing itself."
    ]
  },
  {
    "brand": "amd",
    "generation": "7000",
    "tier": "low",
    "matched_keywords": [
      "7600"
    ],
    "title": "AMD Radeon RX 7600 to launch with $269/‚Ç¨299 MSRP - VideoCardz.com",
    "selftext": "",
    "comments": [
      "Get a 6700xt",
      "Bought a used 6700 XT off eBay for $275, no regrets",
      "$249 would make it much more enticing. $269 seems like a lot to ask when there‚Äôs current Gen cards with more vram for the same money, like the 6700 and 6700xt",
      "> Instead of what was originally communicated as $299 price, AMD has now  settled on $269 and from what we quickly learned, for European gamers  this means ‚Ç¨299. \n\nJebaited!",
      "Better than expected. And it'll probably drop a bit in price soon.\n\nDon't forget you get AV1 encoding and AI acceleration on this card. But yeah wish it was 12GB..",
      "This is not a terrible MSRP, but I think $249 would have been more enticing and made it the new RX480/580.",
      "Better than expected would be $229\n\nThis is 6700 level of performance for 6700 pricing and 2GB less VRAM. And thats if it reaches 6700 performance.",
      "I got a used 6700 XT off Amazon Warehouse last week for $262.. works perfectly.",
      "I feel jebaited as a European gamer, alright.",
      "Yeah, definitely. The 6700 10GB is the budget card to get right now for 1080p. Performance should be roughly equal to the 7600 with two more GB of memory for only $10 USD more. Luckily, I see this card enjoying swift price cuts before the end of summer.",
      "Euro price is incl vat, USD price isn't.",
      "I wonder how close it'll perform to a 6650XT",
      "Each new rumor makes it cheaper. Keep going.",
      "In terms of hype, perhaps, but factually, it wouldn't have been the new 480/580 due to vRAM alone, 8GB is barely enough in 2023, whereas in 2016 it was actually \"overkill\" for 1080p.",
      "6700XT is the budget king at the moment, and the increase in performance from a GTX980ti would be massive.  That does depend, however, on the rest of your components.  If your CPU, mobo, RAM, etc, are all 7+ years old like your GPU then you may run into some bottlenecking issues on the GPU, particularly at 1080p.",
      "A euro is worth 1.08 dollars though, so by comparison you could lower the US price 8% before adding tax. Euro buyers definitely getting a raw deal as usual.",
      "US prices are before sales taxes. \n250‚Ç¨ x 1.20 = 300‚Ç¨",
      "According to rumors it should be like a couple percentage points slower in 1080p; benchmarks should be coming in a couple days. No big difference in performance anyways but 6700xt has 12 GB VRAM.",
      "I got a 6800 for 300 a week ago.",
      "5% over at best"
    ]
  },
  {
    "brand": "amd",
    "generation": "7000",
    "tier": "low",
    "matched_keywords": [
      "7600"
    ],
    "title": "AMD Radeon RX 7600 drops to ‚Ç¨259 in Spain, just one day after launch - VideoCardz.com",
    "selftext": "",
    "comments": [
      "dont buy before its reach the true cost of 8GB GPU in 2023 is 200$",
      "Nice, honestly it's reasonable at that price. Keep in mind that's tax included.",
      "Tell that to nvidia.",
      "Yep. I just saw it in a Google ad.\nFor reference, in the same shop the cheapest new 6700 is 340‚Ç¨ and the 6700xt is 360‚Ç¨.",
      "Well it price was not bad and if it drops it'll be even better. It is faster than rx 6650xt (basically same as rx 6700). Though vanilla rx 6700 has more vram, bandwidth and full x16 pcie lanes so still it is way to go imo",
      "To be fair, they did dropped the price of the 3050 down to like $220 today (which in all fairness, they shoulda done ages ago), although it's still being beaten by RX 6600 at around $200 anyways.",
      "For God's *sake*, AMD.  Crypto pricing is over. DEAL with it.\n\nYou could have had good reviews.  I sure hope the extra margin from the units you sold in the first 30 hours made up for it.",
      "Yep, that's pretty decent. Without VAT it's like 220‚Ç¨, what's 235$.",
      "To think 8GB in 2016 was only $250.",
      "Exactly. People like to shit on the card because it has 8GB like the 4060 and 4060ti. But people forget that this card costs almost half of the NVIDIA counterpart. \nThe 7600 is an okay deal. The 4060s are a scam.",
      "Yep. Today. Just when AMD released a new card at a decent price. Nice.\nThat's what happens with time. AMD dropped the prices a while ago, nvidia has taken its time.",
      "340‚Ç¨ in Greece üíÄ\n\nI'm sure they will drop soon though, since 6650xt is 240‚Ç¨ and 6700xt 12GB 340‚Ç¨.",
      "In Europe we don't think about cost outside of taxes. It cost X, and that's it for us. Prices in Europe always and in all cases include taxes.",
      "Hahaha Ray Tracing on a 3050 isn't something to brag about",
      "300$ when adjusted for inflation on the 240$ RX 480 8 GB.",
      "259 is including VAT.",
      "bu bu bu bu bbb uuuttttttt, nvidia\\`s ray tracing performance is better hahahaha, I love fanboys, they make me laugh.",
      "Only when it suits them. And then in other situations when you point out that 8gb is hindering 3070 from running RT in newer games it turns into \"3070 and below weren't meant for RT\".",
      "Still 300‚Ç¨ in Germany",
      "1650 vs 570 = reviewers shat on the 1650 and pushed people to buy the 570 instead. 1650 is now the no.1 card in Steam's HW chart.\n\n3050 vs 6600 = youtubers hail the 6600 as the value king. HWU even made a massive 50 game benchmark pitting both cards against each other, saying there's no reason to even consider the 3050.\n\nGuess which card is higher on the charts?"
    ]
  },
  {
    "brand": "amd",
    "generation": "7000",
    "tier": "low",
    "matched_keywords": [
      "7600"
    ],
    "title": "AMD Fails Again: Radeon RX 7600 Review",
    "selftext": "",
    "comments": [
      "If you need a new GPU right now, the RX 6700 10gb is the smart choice\n\n~$280, faster than a 7600, 10gb VRAM,  wider memory bus and a full x16 PCIE lane\n\nIt's extremely hard to argue the 6700 in the current market (While stock lasts)\n\nEDIT - Also keep an eye on the 6700xt prices, 10% faster again with 2gb more VRAM",
      "This generation from both sides is worse than Turing. Like dear God, what a let down. \n\nGetting the 6800xt/3080 at MSRP was about the best move you could‚Äôve made in a loooooong time.",
      "In my country, 6700 xt is only 30 euros more. That's probably a better deal?",
      "Typical AMD GPU release : \n>Release overpriced product\n\n>Get horrible day 1 reviews \n\n>Discount it to the normal price 1-2 months later \n\n> ???\n\n>Profit",
      "The 6950 XT is a really good deal right now. It also comes with a good game, so that's a plus.",
      "Definitely better deal, roughly 10% faster and 2gb more vram.",
      "Ahhhhh, that's just like Radeon likes their day 1 reviews :)",
      "AMD and Nvidia don't want to sell GPUs anymore",
      "The fact that Intel is still competitive is really really pathetic on Nvidia and amds front‚Ä¶\n\nGod Intel, please let battlemage actually be a huge jump.  WE DESPERATELY NEED COMPETITION!!!",
      "I'm gonna write something maybe controversial here:  this card could not be cheaper than 270 until the 6000 series is sold out.  Sure, it's basically the same as the 6650XT (which, when I bought mine 7 months ago for 280, is feeling  even more like an excellent purchase), but until the 6650XT is sold out, they couldn't exactly undercut themselves without also just lowering the price of the rest of the 6000 series.\n\n&#x200B;\n\nWhat AMD should have done is simply not release the card until they've sold off their old inventory, but I think they feel pressured because Nvidia is releasing the 4060s and they want to get at least some press for released products.\n\n&#x200B;\n\nedit:  Note it is very slightly better than the 6650XT, both in average performance and especially ray tracing and.. AV1 encode that I doubt many people will use.  If they're the same price, which they are, I'd get the 7600 if I was buying tomorrow.",
      "What you really get at the end of those cycles is a ruined reputation...  \n\n\nAt any rate the GPU itself is actually a bit atypical, it performs so close to the similarly configured 6650XT (same CUs count, similar memory configuration) that one is left wondering what is the performance uplift of RDNA3 over RDNA2.",
      "Amd competing against amd and still loses /s\n\nAnyways rx 6700, rx 6700xt are the best cards in this price market.",
      "Amazon is selling the 6700 xfx 3 fan model for the same price as the 7600, no reason for anyone to buy a 7600.\n\nI think this is exactly what amd want, push people to buy old tech, while selling the 7600 at this price to the uninformed.\n\nOnce lest gen sells out, this price will drop.",
      "AMD for sure doesn't want to . EPYC makes much more money for them",
      "People still think that AMD drivers are terrible after all those years ( they are not perfect obviously , but not really worse or better that Nvidia ones )  Bad reputation is very hard to get rid of",
      "I think you're exactly spot on. AMD is a business. The PC market crashed. They made a ton of RDNA2 GPUs because of a huge demand which vanished over night.\n\nUntil those are sold there is very little reason to offer better value. Otherwise they will have to write down the old inventory. And writing down old inventory is a loss.\n\nCan't really blame them for it. And if you want the latest gen, worse case scenario overpaying $20 for a GPU is not the end of the world.",
      "It's a fantastic card if power consumption, size and heat are unimportant to you. The 6800XT is a better alternative and only slightly slower while consuming far less power. For the midrange a 6700 10Gb for 270 or 6700XT for a bit more are viable alternatives to these lackluster new cards. If you are on a tight budget the 6600 series and ARC 750 are the way to go since Intel has just dropped the price of a 750 to 200 dollars. Nvidia can spin as DLSS is not worth 100 or more dollars anyhow at this level of GPU. You need 60 fps or more for framge generation to make sense due to latency issues, especially in FPS type games.",
      "So happy with my 6800XT. Got it at a large discount a month ago and have 0 regrets!",
      "Turing had pretty decent improvement; it was just one of the few times where that came with a price hike. \n\nThe 2060 saw a $50 surcharge ontop of the $300 1060. Even then, it beat the 1070 by 10-15%. The 2070 was a lot more lackluster, but still. This 4060ti is in spitting distance of the 3060ti overclocked - that‚Äôs pitiful. I can‚Äôt recall a generation having that issue.\n\nThe Turing era wasn‚Äôt *that* bad after the refreshes. The refreshes were super good 2070S, 2080S. During that time the 5700xt ans 5700 came out which were insanely good for the $ too.",
      "The 6000 cards also come with \"the last of us\". So the value is even better."
    ]
  },
  {
    "brand": "amd",
    "generation": "7000",
    "tier": "low",
    "matched_keywords": [
      "7600"
    ],
    "title": "AMD Radeon RX 7600 is now available for $249 - VideoCardz.com",
    "selftext": "",
    "comments": [
      "People here seem to want AMD to be gone and never sell GPUs again.\n\n\nMeanwhile Nvidia happily sells them a rebranded 3060Ti for 400+ dollars and they buy it. Amazing brand shilling.",
      "If this card was $___ with ___GB it'd be better than the ______.",
      "Who is defending the 4060ti, it's not a good value card at all, bad pricing and bad generational uplift hence it's also dropping in price.\n\nDoesn't make what AMD is doing any better, at first AMD tried to price this 7600 garbage at $300 which was just plain greedy, last minute price drop to $269 which is still too much.\n\nNow look, exactly what every sane person knew would happen, they scooped up bad reviews and the price ended up dropping anyway.\n\nCongrats AMD, you played yourself again.",
      "If this card was $ -1000 with 3.5GB it'd be better than the voodoo3 3000",
      "Compared to Nvidia offerings this is a great deal now.",
      "The 4060 TI outsold every 6000 series card along with the 7600 in a recent mindfactory sales data. That's when virtually everyone was telling people to stay away from the 4060 TI. If the 7600 launched at $200 everyone would be saying go out and buy this card now! with the bearded hipster wow face, people would still be buying the 4060 TI.",
      "AMD is dirt cheap compared to Nvidia. Uncanny. Yet, half of my friends buy Nvidia because that's how brands work after all. It demonstrates that consumers aren't necessarily rational.",
      "the 6600XT/6650XT will just get cheaper again too, people don‚Äôt seem to comprehend how a *clearance sale* to clear out an older product works lol.\n\nEven if the new thing is awesome and amazing, the old thing will be marked down super heavy to move it. 780 ti hit $185 after 970 came out for example, there was never any moment in time when the 970 cost less than a 780 ti, only relative to prices when it was *introduced*.\n\nThe 6600XT/6650XT is always gonna be like $30 cheaper than a 7600 until they start running out of inventory.  Whenever the 7600 gets cut, the 6600XT will get cut too.",
      "I'd bet a lot of money that the vast majority of Nvidia's user base doesn't use those features in the first place.",
      "I mean, if your budget is $250 or less for a GPU, future proofing is the least of your problems. It's still the best GPU if that's your budget, and last a while for the use cases you'd use it on.",
      "It doesn't support Glide though?\n\nWhy would anyone downgrade from 3dfx by buying a GPU unable to run Glide software??",
      "both are bad, there's no inbetween, when im buying pc components i just buy whatever brings the best price to performance, i don't see brands, that's how everyone should be like, i also waited 2 years to buy a new gpu because fuck those prices",
      "Reddit really makes people think that every Nvidia user have some sort of AI server farm running at their garage",
      "Maybe amd should try to be dirty cheap in other countries too, that could help....",
      "The rx 6600 is 30% faster while being 20% cheaper than the 3050. By all metrics it is a \"well-priced\" product.\n\nThe 3050 outsold it 5 to 1.",
      "At $250? Only the $180 RX 6600 is better.",
      "Except... historically, people always wanted nVidia over AMD, even when nVidia was utter dogshit, and AMD was literally doing their best generation ever.  \n\nTwice.  \n\nFirst with FX 5000 series and Radeon 9000, the 9700 Pro being a fucking beast and FX 5800 Ultra being being literal garbage.  \n\n2nd time with HD 5000 series and nVidia's GTX 400 series. Remember that? Thermi, 9 or so months later, still outsold AMD.  \n\nThis is exactly what I'm talking about. AMD WAS ahead, multiple times - hell, even the 6000 series was one of the most competitive generations around, AMD matched nVidia's flagship for 500$ less pretty much, and nowadays even beats it - but people still bought more nVidia GPUs.  \n\nIn fact, there's more 3050s on Steam than... literally every AMD GPU. Same for GTX 1070, 2070s, 1660, 3060 Ti, 1650, fucking 3070 LAPTOP GPUs. Most popular AMD GPU is the 580. A 6 year old GPU.  \n\nFor fucks sake there's more 750 Tis, 960s, 970s, 2080 supers... than any RDNA2/3 GPUs.  \n\nNo they wouldn't. Don't lie to yourself.",
      "Another 50$ and it will be a decent choice over the 6600xt and maybe the 6650xt",
      "At a certain price and performance tier 8gb is fine. The reality is this card isn‚Äôt powerful enough for the 8gb to be the limiting factor, and it still performs great for modern games. \n\nFuture proof isn‚Äôt really that important, you usually save money upgrading every few years rather than buying a higher end card and saving it.",
      "> The 4060 TI outsold every 6000 series card along with the 7600 in a recent mindfactory sales data\n\nNo it didn't.  Here's the mindfactory data for every single week since it's launched, it's an easy claim to check since, you know, it's only been out for 4 weeks.\n\nhttps://twitter.com/TechEpiphany/status/1670515083640995841/photo/2\n\nhttps://twitter.com/TechEpiphany/status/1667537641288417283/photo/2\n\nhttps://twitter.com/TechEpiphany/status/1665965960702963714/photo/2\n\nhttps://twitter.com/TechEpiphany/status/1662401658356133891 (no numbers in this one, but it's not listed in the top 3 bestsellers either)\n\nQuit the hyperbolic \"NVIDIA customers bad, haha, brainless, guys!!!\" circlejerk.  4070 is selling well because it's a good product.  Even HUB endorsed it over the 6950XT etc.  4060 Ti is selling exceptionally bad everywhere, and the 6700XT is selling multiples of it.  So is 7900XT/7900XTX as well, and 6900XT.\n\n/r/quityourbullshit"
    ]
  },
  {
    "brand": "amd",
    "generation": "7000",
    "tier": "low",
    "matched_keywords": [
      "7600"
    ],
    "title": "AMD Radeon RX 7600 XT Specs: 8GB VRAM & 2.6GHz Boost; Only 11% Faster than the RX 6650 XT at Same Power [Report]",
    "selftext": "",
    "comments": [
      "Needs to be under $300 or dead on $300 realisticly.",
      "Arguably it should be cheaper than that. For 300, it would have the same appeal as 4070. It needs to be max 250 in order to be a viable product at all. \n\nIf this rumor is true, this would mean that RDNA3 is one huge flop though.",
      "Then it's a pointless card. The 6700xt could be had for around $300-350ish for months and is already around 10% faster than a 6650. Plus they're 12gb cards.\n\nAt the rumored specs/performance the only way this card is a success is if it's a $200-250 card for the masses.",
      "It's not delusional when you consider current price/performance. A $400 7600XT would fucking suck",
      "I thought that 8gb vram wasn‚Äôt enough for games according to amd",
      "What an utter disappointment. This thing needs to be $299 to not suck, and it might even be bad *then*.",
      "8 GB is officially considered low end now.",
      "It must launch for less than $300",
      "Brother u are delusional. 6650xt was priced at $399 so I imagine 7600xt would be priced the same.",
      ">the card will be paired with¬†8GB of GDDR6¬†memory via a 128-bit or 192-bit bus\n\nIf someone manages to get 8GB of vram working on a uniform 192-bit bus I will eat my shoe. The numbers don't number and the person who wrote this article has no clue.",
      "8GB VRAM for 399 USD  in 2023 makes it meh",
      "6700 XT is between 20% to usually more around 33% faster than 6650 XT.",
      "Each vram memory module uses 32-bit bus to communicate with the GPU. These modules are made in capacities in the powers of two due to how binary addressing works, most commonly in 8Gbit or 16Gbit  densities or with 1GB and 2GB capacity respectively. To have a uniform access to the entire addressing space you have to use the same modules for the entire vram. That means for a 192bit bus you have total of 192bit/32bit = 6 modules that can either be 1 or 2GB capacity so 6GB or 12GB total. For 128bit bus that is 4 or 8GB. Other capacities on these buses are impossible unless you use uneven/non-uniform addressing space by mixing modules. Something similar was once done by Nvidia on a GTX 970 and received a backlash. Basically you would lose bandwidth once you fill up the capacity of the low density modules.",
      "nobody will buy it over a 6650 xt unless they curb the supply. Historically, AMD drivers aren't quite polished either for new product support.  \nHeck even 6700 xt are available for $320-$340",
      "u can get a 3070 for 300 on ebay",
      "It'll launch at $349 and then drop to $329 and then $299 sales once nvidia release their lower end\n\nIt will be noticeably better bang/buck and the vast majority of reviewers will call it the better buy over the 4050 Ti/4060\n\nThe 4050Ti/4060 will still outsell it 5:1 or worse, as is tradition\n\nAMD need to wake the radeon division the fuck up. Nvidias trash pricing and stupid decisions this generation is the best chance they have had in a decade of clawing back market share and they're just doing the same thing they've been doing over and over again",
      "I don‚Äôt think it‚Äôs possible for new cards to compete with clearance priced last gen stuff from AMD. If you want a $325 6700xt you‚Äôd better buy it before they sell out.",
      "You can also get Intel's A750 with 16GB VRAM.",
      "if you play games at cranked out settings yes\n\nbut 99.99% of people turn them down and hover around 5-6gb VRAM usage so we have 1 gen worth of time before 8gb becomes actual mandatory\n\nand old games exist which look pretty for the VRAM usage they have so i don't know whether to laugh or not at people thinking this is the problem XD",
      "Realistically speaking this is more of an RX 7600 (non XT) because of the new naming scheme;\n\n(6900 XT>7900 XTX... 6800 XT>7900 XT etc...)\n\n\nSo this isn't actually that bad if the price is also like the 6600. Although who am I kidding,the change in names is a hidden price increase really."
    ]
  },
  {
    "brand": "amd",
    "generation": "7000",
    "tier": "low",
    "matched_keywords": [
      "7600"
    ],
    "title": "AMD Radeon RX 7600 and NVIDIA GeForce RTX 4060 Ti 3DMark performance leaks out - VideoCardz.com",
    "selftext": "",
    "comments": [
      "Still waiting for the +54% perf/watt increase.",
      "> up to 1.7x faster than the 6950xt at 4K\n\nThis generation is a joke.",
      "What's even the point of 4060/7600 when something like 6700XT with 12GB exists? Is this a joke?",
      "And what about the 3060 Ti -> 4060 Ti perf increase, barely 10% lol. And the 6800 XT -> 7800 XT is shaping to end up the same +10%.\n\nWhat a time to be alive. Good thing my current 6800 has enough VRAM to last me through another generation or two.",
      "Let hope Intel come to the rescue.\n\nFuck me, that wasn't a sentence I ever expected to write...",
      "The 30%+ performance uplift from the 6600 to the 7600 isn't bad. Of course, if one compares Navi 23 32CU to Navi 33 32CU (6650 XT vs. 7600), the difference is lot less impressive. In the end, pricing is what will determine how worthwhile an upgrade this is.",
      "The 4060 has some selling points like dlss 3, rt and stuff.\n\nThe 7600 has nothing over the 6700xt. Maybe efficiency depending on the tdp? That's it....",
      "/r/ihadastroke",
      "Honestly, what a big fat lie that was. Rdna3 does not even have the efficiency gain it should have gotten from JUST the process node change. I honestly don't know wtf they did with rdna3.",
      "AMD literally just started using chiplets for their gpus, in case you missed that.\n\nChiplets are how ryzens CPUs have sold like butter for the past 6 years, in case you missed that too.",
      "&#x200B;\n\n>The 4060 has some selling points like dlss 3, rt and stuff.\n\n&#x200B;\n\n\\+ productivity, ai, ML, and possibly at very low power draw",
      "4060ti ain't competing with 7600,unless I'm mistaken. The regular 4060 is. Also how much you can extrapolate real world performance from this?",
      "The 4090 is the exception. It actually got that 1.7x+ over the 3090 while also getting +54% perf/watt",
      "Yeah 5-10% uplift from 6600 XT , I'm definitely skipping this generation",
      "So basically +15% on a 5700XT :/ depressing",
      "The \"dumb consumer\" narrative is pushed way too hard by folks struggling to cope. \n\nPeople probably pay a premium for Nvidia because Nvidia has superior hardware and features. That's why Nvidia can get better margins while selling nearly 10x as many gpus as AMD. And in many markets AMD is actual more expensive than nvidias competing gpus! \n\nIt's not as simple as the \"dumb consumer\" narrative you're pushing.",
      "7600 with 32CU vs the 6650XT with 32CU\n\nTimespy 1440P 6.8% increase\n\nTimespy 4K 11.33% increase\n\nBasically confirms that RDNA 3 uplift is really low.\n\nThis also means whatever card AMD wants to put on the N32 die will not be able to match a 6800XT.\n\nSo for AMD to release a 4070 competitor they would have to use a cut down N31 die and 4060ti competitor would need the full N32 die. That's a very tough spot to be in.",
      "They made chiplets. They were clearly no easy to get right, but they‚Äôre a big gain for the future. \n\n(They also increased the size of the caches and made the WGPs dual issue, but I think most of the engineering effort went towards the chiplets.)",
      "4080ti can be squeezed between those two.",
      "So just a small increase from the 6650XT based on these?"
    ]
  },
  {
    "brand": "amd",
    "generation": "7000",
    "tier": "low",
    "matched_keywords": [
      "7600"
    ],
    "title": "AMD is a Mess: Radeon RX 7600 GPU Review & Benchmarks",
    "selftext": "",
    "comments": [
      "What a mess this whole GPU generation is.",
      "Scott Herkleman is a fucking clown. Dude legit needs to be fired ASAP before he embarrasses AMD further.",
      "Just don't buy it lol - save your money, people need to realize its not worth upgrading every dang cycle. Save some money, reduce e-waste, maybe in a year or 2 AMD and Nvidia will come to their senses and stop doing dumb crap like this.",
      "Anyone who's led Radeon in the past like decade seems to be terrible at making them a real threat to NVIDIA. It's just so sad...",
      "Last generation would have been good if it wasn‚Äôt for crypto mining‚Ä¶",
      "I'm on the fence. I don't think Scott is the only person in the chain that needs to removed/repositioned.\n\nAMD clearly got high off their own farts with RDNA2. They gloated while having the superior foundry. When NV gets back on the same foundry suddenly AMD is back in the same position its been for a VERY VEEEEEEEEERRRRRRY long time, a distance second. And it seems if Intel continues its growth, that distance second isn't even a sure thing anymore.\n\nThis isn't the first time AMD did this to reviewers, it won't be the last, and I'm still amazed Youtubers (who seem to be the voice for the audience/community nowadays) don't hold AMD more accountable. They just laugh it off, \"Oh you.\"",
      "Few people upgrade every cycle. Majority are upgrading 2-3 cycles. Steam hardware survey shows majority of people are still 2+ generations behind. Like the overwhelming majority",
      "This is just shameful.  Its like the entire GPU market has regressed a decade.",
      "Who would've thought we could possibly go down after the last generation",
      "The A750 matches the RX 6600 performance and price, while drawing more power and being less consistent in older titles\n\nThe value play for any buyer is still the RX 6600",
      "Crypto mining was what opened the eyes of AMD and Nvidia to realize how much they can charge",
      "We only have consumers to blame. We keep buying trash, then trash will still be sold.",
      "In comparative to AMD's prior line - it was AMAZING.\n\nWhen was the last time AMD had a top card throwing shade at NV's top card?",
      "So basically, just go out and buy a $199 Arc A750 LE and screw over both NVIDIA and AMD and get practically the same performance for $70 less.",
      "I hope Intel will make the market more interesting with battlemage and celestial, both nvidia and AMD suck at the moment when it comes to affordable gaming gpus",
      "It‚Äôs not enough though, this card should be $229-$249 absolute max.",
      "INTEL CHADS pls save us from NVIDIA AND AMD !",
      "2 bad gpu launches within 24hrs and both happen to be main stream cards? fucking hell man",
      "Intel are playing the same game (If anything they're worse)\n\nThey're value matching RDNA2 with a first generation product\n\nThey need to be undercutting RDNA2 pricing, not matching it",
      "> AMD clearly got high off their own farts with RDNA2. \n\nIt wasn't even that good. It only got better when they were sitting with huge stocks and did unofficial price reductions to get rid of stocks."
    ]
  },
  {
    "brand": "amd",
    "generation": "7000",
    "tier": "low",
    "matched_keywords": [
      "7600"
    ],
    "title": "AMD Radeon RX 7600 expected to cost ‚Ç¨349 in France - VideoCardz.com",
    "selftext": "",
    "comments": [
      "That's an equivalent of 317 freedom units, for our friends across the pond.\n\nPriced exactly so you lose hope of getting a current 7000 GPU and just buy from the overstock of 6600/6650/6700/6750 cards.\n\nDisappointing? yes, unexpected? not at all.",
      "DOA, get a 6700XT.\n\nRip the 7800xt at 499-550$ dream",
      "Amd will never miss an opportunity to miss an opportunity",
      "YIKES\n\nAnd we all were talking about how 300 would be a bad price point...",
      "it has 8gb of VRAM..... the a770 has 16gb and costs less. \n\n8gb is NOT viable at 1440p anymore. Why the hell would anyone buy this card?",
      "Most likely will actually come in at $299 in the US",
      "Literally only braindead idiots will buy this shit for $349",
      "Already discounted VAT for France (20%)",
      "At this point I am not afraid of saying it :\n\nPricing GPUs (Nv or AMD) has been just arbitrary since the crash of Crypto-Mining\n\nBecause reason has nothing to do with it",
      "Not when there are already GPUs that are cheaper ($270-280) that likely will perform similarly with 2GB more vram, aka the 6700 non-xt.\n\nRX 7600 **needs** to be a $250 or below GPU, unless it performs significantly better than I assume it does (I'm assuming roughly 10% higher performance than the 6650XT).\n\nAdding a small amount of performance while increasing the cost to having a similar FPS/$ to current GPUs only makes the GPU market more of a joke, especially when they don't add more vram.",
      "As a French citizen, we convert usually 1$=1‚Ç¨ (VAT, Transport, etc‚Ä¶)\nSo expect ~349$ in US",
      "At this current market climate I wonder why they even bother developing GPUs that aren't high end. 5700XT to 6700XT was pretty much stagnation already (a bit better performance for the same price increase and rather lackluster RT). And I doubt the 7600 will move the needle significantly. God forbid a 7500...  \nThe only real performance leaps I have seen are from high end cards and they are way too expensive. I'd rather get high end 6000 series card that ages probably better and comes with a significant discount.",
      "5700XT to 6700XT was extra performance and 59% more VRAM.\n\nI'm mostly disappointed they didn't make this a 10 or 12GB card. That would have killed the 4060Ti.",
      "DOA at 300$",
      "what are you doing mate, they already converted it in the article, you just have to read it.",
      "That's really bad and a big disappointment if it's true. For that money you're very close to an actual 6700XT with 12gb. It also means it won't be the 1080p budget gaming card people were hoping it to be. 350 for a 1080p card is just too much at this point. \n\nThe 6650XT is also constantly dropping in price here in Europe, soon it will be under 270. That card will be much better positioned for 1080p gaming, but the hope was that we'd just get a generational improvement for about the same price, which seems reasonable given how long RDNA2 is already on the market. I guess it once again shows that AMD is not our friend.",
      "Agree, I live in France and we started to see the 6700xt below the 350 euros every once in a while unboxed. The used market goes even lower.\n\nTo go for the 6700xt at that price range would make more sense when it comes to performance AND price AND Vram.",
      "Tgat used to be the case, but nowadays we are paying more in euro than they are in dollars. They've got $750 7900XTs sometimes.. Cheapest in europe is ‚Ç¨899 (same for 4070Ti).",
      "They could be gobbling market share right now, *while still turning a profit*, if they would just set their prices low enough. Instead of trying to maximize profit per card, focus on long term profits by getting more people on board with the AMD platform.",
      "they converted and removed the vat, its all there, explained clear as day. You literally just have to read it."
    ]
  },
  {
    "brand": "amd",
    "generation": "7000",
    "tier": "low",
    "matched_keywords": [
      "7600"
    ],
    "title": "AMD Radeon RX 7600 Custom Model Prices Leaked By Canadian Retailer, $304 To $315 US",
    "selftext": "",
    "comments": [
      "If they actually do try to sell it for $300, I see it going about as well as the 7900XT for $900.\n\nIf anything, this is arguably going to be even worse since nvidia has a direct competitor for the exact same price, which should be similar performance but better features.\n\nAs Klunamactuna pointed out, it'll be the usual bad day 1 reviews followed by lowering prices shortly after.\n\nI've been saying two things for a while (I've seen others say basically the same thing as myself as well), if you want *similar* performance with 2GB more vram you can get the 6700 for around $270-280 (It even has full 16 pcie lanes), the 7600 can't be over $250 if they actually want to sell it.",
      "You can get a 6700XT for $60 CAD more. Faster card with 4 extra VRAM.\n\nPathetic.",
      "dont trust the price, there's the canadian tax that increases the price. If a card is 250$ USD, it should be 335-340$ CAD but in reality it's usually much higher.",
      "joke full rude far-flung airport summer sense dog selective piquant\n\n *This post was mass deleted and anonymized with [Redact](https://redact.dev/home)*",
      "Huh, so we‚Äôre probably looking at $299. I‚Äôm still holding out hope for $279, but $249 is dead and gone at this point.",
      "Even worse for the Rx 7600 is the Rx 6700 non-XT which is the same price",
      "THis is a nothingburger story. Here's what 6650 XTs go for in canada. \n\nhttps://www.newegg.ca/p/pl?d=rx+6650+xt\n\nAnd of course here's the american version:\n\nhttps://www.newegg.com/p/pl?d=rx+6650+xt\n\nSo...equals closer to $280. Which is still kinda crap given the 6650 XT already goes for the same amount roughly and this seems to be just a slight refresh of that (basically a 6670 XT).",
      "The problem with AMD‚Äôs lineup compared to its prior gen is that it offers very little to nothing new. I say nothing because what it does offer (AV1 encoding) matters little to consumers in this class.\n\nWhile the 40 series only appears to offer marginal performance gains over 30 series, it does have a feature set to fall back on. One that may be more useful for lower end card like DLSS and framegen. \n\nAMD doesn‚Äôt have a lot they can do besides price and even then, they typically have to be considerably less. \n\n$299 7600 and $299 4060? I don‚Äôt think I have to explain why that won‚Äôt work.",
      "People don't want 6700XT performance for the same money and with less VRAM ?\n\nü§¶‚Äç‚ôÇÔ∏è",
      "If this turns out to be true this card is dead on arrival, in Europe it would mean 350-360 euros and that stuff will be a direct competitor of the RX 6750XT or it will be a 20 euros more expensive competitor of the RTX 4060 which although not a great deal will for sure be faster in ray tracing (for how little it matters in this price class) and will offer more features and a better overall software package.\n\nIf AMD wants to have a fine card they need to have it a 250 dollars MSRP and a 280 euros MSRP in order to match the current pricing of the RX 6650XT otherwise this card is just a waste of money for the consumer.",
      "Running one now, they've seemingly flown completely under the radar, most review sites don't even talk about the 6700",
      "I think AMD always tries to keep the margins just as high as Nvidia, but then they realize that they cannot hold those margins and they reduce the price. Or they just want to profit from all the people that always want to buy on day one. \n\nBut I agree I think AMD needs to be more aggressive with the pricing to gain market share from Nvidia, aber they gained parity it would probably make sense economically to go back to high margins, but for now they really need to get more marker share. And this is not even from a consumer, but more from an investor perspective.",
      "I was thinking $299, but hoping for $249 but we all know amd don‚Äôt care bout us",
      "I mean, AMD does not even have a big of a market share and is acting cocky like Nvidia. DLSS and Framegen increases the longevity of your cards. As for RT, idc much, but in some games like Metro Exodus, which changes the game drastically, it does matter. The only advantage imo AMD have is pricing. I got my 6700 XT for the same price of a 3060 back in October, and for that price comparison, its a hell of a beast.",
      "It's around the RX 6700 in performance according to leaks.  Not as fast as the 6700XT/3060Ti",
      "I actually buy AMD to **not** deal with drivers on my Linux boxes",
      "The 6650 XT is going on Amazon in Europe for as low as 260 euros, Mindfactory has them at 230 euros at time. The 7600 has to come at 270 euros at maximum to be even worth buying.",
      "I can't see the card selling for less than $400cnd and then add our 13%tax. The cheapest 6600 sells for 299-350 when on sale. 8gb cards should be left to the 7500 and 4050 series or less.",
      "if 8gb is hindering your performance at this price point you are doing something very wrong",
      ">The higher worth of the euro compensates for the taxes.\n\nThat was true when the exchange rate was around 1.2+ in favor of the euro, but not now."
    ]
  },
  {
    "brand": "amd",
    "generation": "7000",
    "tier": "low",
    "matched_keywords": [
      "7600"
    ],
    "title": "AMD Radeon RX 7600 final specifications leaked, 165W TDP & 2625 MHz boost clock - VideoCardz.com",
    "selftext": "",
    "comments": [
      "Have budget gamers gotten anything since the RX 480? Especially during the mining boom?",
      "The RX 5700 XT and RX 6600.",
      "It's sad how the price increase over the years has changed the perception of \"budget gaming\" that people consider GPUs above $200 still budget cards.",
      "This looks like an RX 6700 10GB with RDNA3 process.  Shit, 4060 ends up being a better option with less wattage and the CUDA benefit. They just pissed in our mouths.  \nThanks Nvidia and AMD.",
      "When I built my first PC I was still a little shocked at spending nearly $1000 on it. And that was with an RX 580 for $150.\n\nI don't know what the perception of people new to PC building is now, but I imagine for some the cost of entry is way too high.",
      "The big problem they have with this card is why would anyone buy it. \n\nPeople will buy Nvidia still if it's actually worse because \"that's just who you buy\". \n\nAnd if the 4060 is the same or better even if it costs $50 more who gives a fuck about $50. \n\nIf it's not less than $250 no one will buy it.",
      "I'd say the 5700XT was not budget by design, but got put into the bargain bin by force of circumstance. The transistor count was close to that of a 1080ti and it was built on a then cutting-edge 7nm process. It was only the lack of performance that forced AMD to sell it at a lower price.\n\nA couple of years later I still kinda wonder whether that was down to shitty launch drivers as usual, as the 5700XT has FineWined and is now occasionally punching above the 1080ti in certain titles.",
      "It's replacing the RX 6600 and has a supposedly $30 cheaper MSRP compared to it, comes with 4 more CUs and new features. I'm going to objectively say, it is a nice RX 6600 replacement.\n\nThe thing that goes against it is that there's still some RX 6000 series cards on the market, and as such a RX 6600XT, 6650XT, 6700 10G, 6700Xt & 6750XT make more sense to buy today, but in 3-5 months, those cards will be gone, and the RX 7600 and whatever else RDNA3 is on the market will be the only AMD options. \n\nObjectively though, compared to RX 6600 it is a 30% better card for a \"supposedly\" lower MSRP.",
      "Yay? It'll be faster than a 6600, but it also consumes more power? I know that this is functionally a 6650XT replacement, and against that it's not bad, but it seems weird to say to your market \"hey get a faster GPU while consuming more power for the same price\". Was 28CU Navi 33 that bad that they can't release a $200 one?",
      "I mean, that‚Äôs only because the RX 6600‚Äôs MSRP was complete horseshit.",
      "The 5700 XT was the beginning of AMD following Nvidia in price creep and the 6600 launched at $330 MSRP to mixed reception even during the mining boom. If its reputation has recovered since, it's primarily because AMD has been using discounts to clear 6000 series inventory.",
      "Same TDP as the 4060Ti, and 50W more than the 4060. Runs a bit hot compared to the competition, another reason I found Arc uninteresting on release.",
      "6600 was/is a great budget option and has been for a while now.",
      "$200-300 used to be \"mid range.\" Heck I remember when like $100-200 cards were good. Stuff like HD 3850, 4670, 4850, 5770 were MVPs in their day.",
      "It was launched at $399 and it could actually be bought for that price as well.",
      "This was only like 10-15 years ago. You used to be able to get a budget card for $100, a decent lower midrange card for $200, a strong midrange card for $300, and $400-500 were top of the stack. And then you'd have these weirdo dual cards for like $700 which would be the absolute best. \n\nMarket these days is a joke. \n\nThings were fine until 2018 or so tbqh. Then it all went to hell.",
      "6600 is the best budget options today, it launched at $330 MSRP, and sold for $600+ during the pandemic/crypto times, pretty much until February this year it was still around $300. This is replacing it with a $30 lower MSRP. So MSRP to MSRP they are giving us 30% more performance or roughly an overclocked 6650XT for $30 less. \n\nWe can continue yelling at clouds how cards in this performance range should cost around $200-250, but that's just yelling at clouds, the market scape for 4 years now is pricing this kind of performance between $300-400 and nothing will change that, except nobody buying such cards and we know this wont happen.",
      "I've currently got a 5950x and a 5500 XT.  The priority of the system is development and long running CPU intensive simulations but I also do some very light gaming.\n\n\nBut yeah, it's totally not the norm to be that lopsided",
      "At the very least, we got good used GPU markets. Not from AMD/Nvidia of course, but 6700XT at $270 used last year this time was pretty good.\n\nNew gen, on the other hand... AMD not releasing anything beyond their flagship, and NVidia releasing super expensive cards. You'd basically have to go last gen if you're budget.",
      "I loved looking at the image and it saying \"Minimum recommended system power supply wattage is based on a pc configured with a AMD Ryzen 9 5900x...\"\n\nlike bro, cmon..if you're slotting in a 5900x in your board, I'm pretty sure you aren't looking at the low spec GPUs."
    ]
  },
  {
    "brand": "amd",
    "generation": "7000",
    "tier": "low",
    "matched_keywords": [
      "7600"
    ],
    "title": "AMD Radeon RX 7600 8GB graphics card spotted in Asian store - VideoCardz.com",
    "selftext": "",
    "comments": [
      "So it looks like the 7600 is going to be the 32CU card after all, not the 7600 XT. Which means the 7600 XT probably won't exist since they'd need to do an N32 cut down for it, and obviously, the 7600 XT isn't going to have 50% more CU's than the 7600.\n\nSince they renamed the XT to non-XT, that to me signals a lower price. The 6600 non-XT had a $330 MSRP, but that was increased preemptively due to the Cryptofuckening. They might make this 250-280 then.",
      "Its already out, it's just called 7900 xt",
      "Leaked price is 250, says it in the article.",
      "We'll have to see on that.\n\nBut if it is there or close, it doesn't seem like a half bad deal honestly. I definitely wouldn't be buying a GPU with 8GB VRAM for much more than this personally, I can tell you that much for sure.\n\nEDIT: I really think my cutoff point is somewhere between $280-300, depending on performance, assuming ~6700XT at 1080p (because lets be real, 8GB VRAM isn't reliably going to be enough for any higher). Any more than that is just a hard pass if you ask me.\n\nIf performance is closer to 6700, then I really hope this $250 price is right.",
      "Should they really be touting ray tracing on a 7600 of all things.",
      "I mean, the 4050 **6GB** probably will too.",
      "People normally expect next gen GPUs to either have a performance increase at the same price or cheaper at the same performance, for $280 we can already get the 6700 that has 2GB more vram, with the 7600 clocking *similarly* to the 6650XT at a similar price, while not adding much in terms of IPC, it's looking very disappointing.\n\nReminds me of when they released the 6600XT and it ended up having similar performance per dollar to the 5700XT while being on less pcie lines, it ended up with *similar* performance but only 5% cheaper, it eventually did come down, but by then the GPU market kinda died because everyone no longer wanted overpriced GPUs.",
      "$250 is ok. Frankly the most they can charge for it. Partner cards probably reach 300 though. I expect minimal gains over 6600. Most likely slower than 6700. Normally that's really awfulbut gpu market is what it is now.",
      "> But if it is there or close, it doesn't seem like a half bad deal honestly.\n\nConsidering the 6700 is currently around that price and has 10GB, that would be a rather bad deal.",
      ">That's why i think it's not going to happen, it would be all but an open declaration of price war on NVidia, after a decade of implicit price fixing\n\nThis is bullshit. A decade ago AMD came up with an R9 290 which soundly beat GTX 780\n\nWhat did you think happened? GTX 780 outsold R9 290 anyway\n\nSame shit happened with RX 480. Despite the initial strong sales, eventually NVIDIA came out ahead anyway with GTX 1050Ti\n\nSame shit happened again with RX 570, and again with RX 5700XT\n\nUnlike Zen which people actually buy, people don't actually support Radeon when they offer great performance/dollar, and now when they finally give in and just go along with NVIDIA prices, people fucking complain?",
      "I wish they'd let the AIB's decide ram. Then we'd get max-ram versions of every card.",
      "Hey now, it can beautifully ray trace a potato at 720p/30fps.\n\nAmazing value, much wow!",
      "Amd should offer 16gb model as well",
      "It better be. Expectation Gen over Gen is a jump in tiers at same power level and price. Price less so since crypto/pandemic.\n\nI'd expect 6700 performance at 6600 power use and better ray tracing than both.\n\nIf it supports av1, offers those things, and comes in at $250 it'll be the best price/perf* card for 1080p on the market.",
      "Navi 33 is monolithic, so this should fix it.",
      "One leak gets posted and r/AMD starts posting shit like this lmao",
      "Bro what settings are you running in CP77 for 60+fps? If I run all lowest settings and crank FSR I can get decent fps on ray tracing but otherwise my best bet is medium with FSR quality for a 30 lock.",
      "I know RDNA3 ray tracing is a great improvement on RDNA2 but unless I'm very wrong, ray tracing performance on a x600 class card probably isn't worth writing home about.",
      "7970XTX Pro Max 48GB vram",
      "Mate come on, we know that's not gonna happen. How'd you just hype yourself up off of nothing. Calm down and think...wait."
    ]
  },
  {
    "brand": "amd",
    "generation": "7000",
    "tier": "low",
    "matched_keywords": [
      "7600"
    ],
    "title": "AMD board partners expected to showcase Radeon RX 7600 desktop GPUs at Computex - VideoCardz.com",
    "selftext": "",
    "comments": [
      "Im honestly glad I got a 6800XT instead of waiting for the 7700XT or 7800XT. Probably won't be much better than last gen.",
      "i cannot wait for new budget cards any longer so I yesterday I bought 6700xt, im happy i did, came from a 5 year old rx580 4gb",
      "To be honest I don't have any interest for N33 cards at all. They are in 6nm node and offer only minimal performance improvements from last gen. Only the pricing is important here.\n\nWhatever happened to N32 lol. It's completely absent.",
      "32 CU card, that's 1/3rd of the 7900XTX's CU count, according to Techpowerup, the 6600 has roughly 32.25% of the performance as the 7900XTX, this isn't sounding too good unless CU count scales terribly.\n\nComparing core-count with last gen:\n\n6950XT vs the 7900XT, it's ~~20%~~ 5% increase in CU count for a 14% performance increase.\n\n(Added, screwed up the comparison earlier) 6950XT vs the 7900XTX, it's 20% increase in CU count for a 36% performance increase.\n\n6900XT vs the 7900XT, it's only a 24% performance for ~~20%~~ 5% more cores, so per core it's sounding like they offer **very similar** performance, given the 7600 will have 4 more (32 vs 28), I don't see this as much of an improvement.\n\n(Added, screwed up the comparison earlier) 6900XT vs the 7900XTX, it's 20% increase in CU count for a 47% performance increase.\n\nYou can currently get a 6600 for $200, 6600XT for $255, and a 6650XT for $260, if it has 6600XT/6650XT-like performance, I can't see this doing well if it's priced around $250 as it'll be competing with last gen GPUs, most people expect either more performance for the same amount of money or the same performance at less money.\n\nOnly way I can see this sell is if they price it around $200-220, unless somehow it's offering much better performance than I'm expecting.\n\nThis generation (From both nvidia and AMD) keeps becoming more and more of a joke.",
      "AMD missed its performance targets for this entire gen and isn't sure how to proceed.\n\nNvidia bailed them out with the absurd price of the 4080, which let them sell the 7900xtx at $1000. Had the 4080 been priced at $1000 AMD would have been screwed.\n\nNow for the mid and low range they actually have to compete with Nvidia's offerings on price which I suspect isn't going to go so well for AMD this time around.",
      "N21 stock still available would be my guess. Hard to keep selling it when N32 is released or alternatively, N32 looks bad next to N21. Both reasons to delay",
      "Lol what are those number? It's 30% faster and 40% in RT titles 1440p. Which in practical terms actually means the 7900xt can do RT with high settings for a good resolution. Something the 6800xt cannot at anything beyond 1080p.\n\nIm on a 3440x1440p monitor and I've been eyeing the 6800xt but when I actually went to upgrade, the price discount definitely nudged me. I sprang for the 7900xt because it's giving me the ability to comfortably play games at ultra and even ultra with RT still with comfortable 60, and even more with optimized settings. Where the 6800xt simply couldn't enable RT with decent frames. \n\nSo although I agree it's not a great buy especially not at msrp. You don't have to lie to make it worse.",
      "Full navi33 has same shader count as full navi23. Difference being the doubling of L3, and probably a bit more clocks. Probably slower than a 6700 non-xt.\n\nI'm betting on a $300 MSRP followed closely by a price drop, since Radeon seemingly doesn't care about getting bad press on launch prices.",
      "Well, 8GB VRAM on 500 dollars GPUs is ridiculous",
      "Didn't realise I was lying, but thanks for letting me know. When I went for the 6800XT I remember seeing a test where the 7900XT really wasn't much better, I'll look into it more anyway.\n\nEDIT: watched HUB's review again and at 1440p the 7900XT has a 26% lead on the 6800XT, so my numbers were a bit off, but it's still unimpressive on average",
      "pretty sure AMD already made an 7800 xt but the marketing department screwed up and replaced the '8' in the name with a '9', it's just a typo guys it's ok",
      "Interesting, so Igor claim there are barely any profit for 7700XT desktop right now, making its production incredibly risky.\n\nHonestly this just sounds like AMD will use lower priced RDNA 2 to compete in mid range and essentially skip 7700XT and 7800XT altogether, or maybe there will be paper launch later down the line?",
      "It is likely however I truly hope that the base 7600 comes in at 249 USD because it would already be around 300 euros or more in the EU.\n\nThe fact that there are no 7800 rumours is suspect though... I think that AMD wanted to charge a lot for that card but can't because Nvidia is asking \"just\" 669 euros for the 4070.",
      "Monolithic 6nm Navi33 is pretty different from chiplet 5nm Navi31. I expect better clocks from the node refinement, just like 6nm Rembrandt clocked higher than 7nm Cezanne.",
      "It makes sense that a chiplet-based 5nm solution is costly. Navi 33, being 6nm monolithic, would be a lot easier to introduce at a low price. Let's just hope that AMD does release it for a low price, so at least in the sub-$250 market there's something to upgrade to.",
      "I agree they missed their targets, but they would not have been screwed with a $1000 4080 price.  The 7900 XTX has plenty of room to drop in price.",
      "Apparently it was taped out late. Which means that it was delayed into midgen release",
      "I suppose AMD can try to slap tons of memory on mid to low end part and try to argue NVIDIA's 8GB VRAM is insufficient, however, VRAM cost as a portion of total BOM will drastically increase in lower end part, hard to tell whether this approach can work out financially.",
      "6600 released during shortages, 7600 releases during the beginnings of a depression\n\nAlso, N33 is cheaper to make, both by area and by tech maturity, than N23. VRAM costs about 1/4th now that it did when 6600 released.",
      "That's all?????\n\nHonestly I expect nothing interesting out of Navi 33. It'll almost definitely only offer 8Go of VRAM, and we're already seeing severe bottlenecking with that. Whatever extra performance it has over Navi 23 won't be meaningful enough to warrant a buy, I'll still advocate that an rx 6600 is the sweet spot for low budget, low power gaming, and for anything above that to reach into a higher VRAM buffer.\n\nEither Navi 32 starts showing its head, or I'm thinking AMD's having so many problems with RDNA that they can't even start responding to Nvidia at the present time. I mean really, the XTX, 5/6th of an XTX, and nothing for over six months? ROCm support still on release candidates? No Navi 32s? Come on, what's going on..."
    ]
  },
  {
    "brand": "amd",
    "generation": "7000",
    "tier": "low",
    "matched_keywords": [
      "7600"
    ],
    "title": "ASRock introduces Radeon RX 7600 XT cards with 16GB memory and up to 2810 MHz GPU clock - VideoCardz.com",
    "selftext": "",
    "comments": [
      "This is the rx580 successor. This card might be too slow for 1440p gaming moving forward, but as of right now, it's good enough and its 16gb VRAM buffer offers a lot for single player gamers. It can literally fit all the high res textures you want.",
      "COVID happened. Inflation exists. $250 7 years ago is \\~$313 today",
      "16GB don't matter much when it has a paltry 128-bit bus.",
      "To be 580 successor it has to cost 250 max.",
      "It's a slightly overclocked 7600. Still weird that ppl associate more vram = higher settings. 16GB is useful b/c newer games use more vram. Even Borderlands 3 (from 2019!) can use up to \\~13GB of vram if you use the -notexturestreaming launch parameter so the game doesn't stutter. \n\nOn older gpus, the importance of vram amount is second only to API compatibility. GTX 780 6GB version is superior to the 3GB version. R9 290 8GB is superior to the 4GB version. Same limitations, same performance, more vram. \n\nThose who buy the 7600xt will be able to keep the gpu for longer. Potentially a LOT longer, provided the amount of performance offered by the chip remains relevant / sufficient. Same with the 4060Ti 16GB.",
      "Inflation happened to the prices not the wages so they can shove it.",
      "you still can max out textures in every game for some time, thats it. It wont make it a good 1440p card but at least it wont drop to 5fps because of memory.\n\nwhen it is discounted eventually, I think it is a cool budget option. Until then whatever really. <$250 etc is not that bad. \n\nI dont know how useful amd cards are for video editing now, if they are good now then this is still cheaper than a770 16gb.",
      "AsRock uses actual rocks in their cards. Magma cooling.",
      "understatement of the century, people have no idea how big a deal this is for 4k editing, this thing will be a beast for its price.",
      "Fwiw;\n\nUK Minimum wage in 2017, ¬£7.50/hour.\n\nUK Minimum wage in 2024, ¬£10.42/hour (soon to be ¬£11.50).\n\nI know that doesn't represent wages for everyone, everywhere (not by far). But I thought it was relevant all the same.",
      "Probably cause it didn't MSRP at $500 for a low/mid range card",
      "This card's VRAM is actually really nice for Stable Diffusion / LLMs. While it is about half as fast as the Nvidia competitors, it can fit much larger models than the equivalent Nvidia graphics cards. But if this is priced too close to the 7700xt or 7800xt, idk where this will fit in the market.",
      "good for productivity applications like video editing where size matters",
      "The point isn't if it can use 16gb,the point is it can use more than 8gb.",
      "Yeah, and the R9 290 \"had no need\" for 8GB of vram. Heard that argument before.",
      "USA min wage is still $7.25, same as a decade ago.",
      "The 7600XT has more memory bandwidth than a 580 due to GDDR6, and also has infinity cache and better colour compression.",
      "Is this a good argument tho? Aren't tech prices *supposed* to get less expensive as time goes on? This and cell phones are like the only thing that seems to go up each time a new iteration comes out.",
      "The 16GB RX 7600 XT is crippled with 128-bit memory bus vs. the RX 580's 256-bit bus. The RX 7600 XT is a better performer with newer tech and more VRAM, but it is no successor to the RX 580. For budget 1080p gamers, RX 580 (released in April 2017) has been relevant for 6.5 years before getting left behind in the new titles and AMD dropping support. Polaris is legendary. RDNA III will not replicate that or the longevity.",
      "Sure, but it isn't asking 500 bucks, unlike NVIDIA's 4060 Ti 16GB, right?"
    ]
  },
  {
    "brand": "amd",
    "generation": "7000",
    "tier": "low",
    "matched_keywords": [
      "7600"
    ],
    "title": "AMD 6-core Ryzen 5 7600X CPU drops to $199, cheaper than 7600 non-X and comes with Starfield game code - VideoCardz.com",
    "selftext": "",
    "comments": [
      "From watching AM5 for a year my big takeaway is that the motherboard cost is driving people away from buying not the cost of the CPUs themselves.",
      "If people were realistic about their needs on the motherboard, they would find some really decent B650 options around $150-180. Paired with a $200 CPU that's not bad.",
      "I'm getting excited thinking of how much cheaper these will be around Black Friday and Cyber Monday.",
      "Imagine when Zen 5/Ryzen 8000 releases.",
      "3.50",
      "Total back of the envelope mid range build:\n\nMotherboard USD125 [https://www.newegg.com/asrock-b650m-hdv-m-2/p/N82E16813162114?Description=asrock%20b650m&cm\\_re=asrock\\_b650m-\\_-13-162-114-\\_-Product](https://www.newegg.com/asrock-b650m-hdv-m-2/p/N82E16813162114?Description=asrock%20b650m&cm_re=asrock_b650m-_-13-162-114-_-Product)\n\nRAM USD99 [https://www.newegg.com/corsair-32gb-288-pin-ddr5-sdram/p/N82E16820236828?Description=ddr5%2032gb&cm\\_re=ddr5\\_32gb-\\_-20-236-828-\\_-Product](https://www.newegg.com/corsair-32gb-288-pin-ddr5-sdram/p/N82E16820236828?Description=ddr5%2032gb&cm_re=ddr5_32gb-_-20-236-828-_-Product) (Budget RAM - I can't tell the different between 4800 and 6000\n\n7600x USD200 +$20 cooler\n\nUSD425 - not bad and probably on par with the 5800x3d in most applications. Good midrange option if building from scratch.",
      "Classic Reddit advice. \n\n\"Should I buy this $200 thing?\"\n\n\"No, you should buy this $500 thing, it's much better.\"",
      "I looked back at my previous X470 and X570 and I paid $200, which is what I paid recently for B650 Aorus Elite AX , so no difference.  Of course it's not X670 but much higher quality and power stages are the overkill.  Even Gen5. Of course your cheapest boards aren't as cheap, but the budget boards are pretty good.",
      "In a sense, the stock cooler costs $20 now. So the real question is would you pay $20 for stock cooler, buy an aftermarket $20 cooler, or take the $20 discount to get the look/performance you want.\n\nI'd take the $20 discount on an aftermarket cooler",
      "$200 7600X + $40 cooler, or $220 7600 + $20 cooler?",
      "The 7600 only needs 65w worth of cooling, not much at all.  And why are you recommending a $450 CPU + cooler? Literally 2x the price..",
      "Guess it depends what you consider a high end feature. Most of these $150-170 AM5 boards are pretty well appointed in terms of standard features.  I was thinking high end like having CMOS reset and restart buttons on the IO panel, liquid nitrogen overclocking support, high quality onboard RAID, and top-end integrated sound.",
      "What‚Äôs a good estimate on the price these will drop to?",
      "Technically it was way easier to get $300 in 2017-2021, than it is to get $150 in 2023.\n\nNow let's talk about keeping that $150 in 2023.",
      "They do. Terrible 2010 era audio chipset, no rear I/O shield, anaemic number of USB ports, and so on.",
      "I doubt they'll get cheaper to be honest. Those events have pretty much become a collection of the best promos of the year, and highly discounted items usually won't discount further.",
      "Damn it monsta!",
      "I think he meant a month",
      "So now the motherboard costs more than the cpu",
      "6650 XT to round it out and this baby can play anything. Midrange is back boys!"
    ]
  },
  {
    "brand": "amd",
    "generation": "7000",
    "tier": "low",
    "matched_keywords": [
      "7600"
    ],
    "title": "Gigabyte leak lists unreleased AMD Radeon RX 7600 XT with 16GB of memory - VideoCardz.com",
    "selftext": "",
    "comments": [
      "Please be priced reasonably, \\*sips in hopium and copium.",
      "VRAM is more expensive than adamantium according to GPU makers pricing",
      "> VRAM is more expensive than adamantium according to GPU makers pricing\n\nWhy wouldn't you just say \"according to Nvidia\"? It's Nvidia who massively cut down VRAM in order to increase margins and reduce the usable lifespan of their GPUs to drive future upgrades.",
      "That means 128-bit bus and Navi 33. So it is a 7600 on steroids (which is still fairly unimpressive). I was hoping for 192-bit bus and Navi 32, a cut-down 7700XT, but unfortunately that won't happen.",
      "Watch AMD price it at $379, card gets thrashed, then falls down to $300 two month later.",
      "i mean the 7700 XT is already down to 399 so this could be 349",
      "So basically should've been 7700 series",
      "It might still be a cut down Navi 32. Imagine it comes with 40-48 CUs and only 2 MCDs (= 128-bit Bus) for cost saving reasons. Throw in 16GB of ~20Gbps GDDR6 VRAM (so that it's faster than the 128-bit 18Gbps of the RX7600) and voila: A GPU that sits right in-between the RX7600 and the RX7700XT.",
      "The 7700xt doesnt exist to be sold, it simply exists to upsell the 7800xt and this is working unimaginably good",
      "> Unfortunately this is the end result of a duopoly\n\nHow does this make sense? Last generation AMD had high-mid range cards with 16GB and people still ate up the 10/12GB Nvidia cards.\n\nPeople who picked up 12Gig 3080/3080ti's (or worse, the 10gb 3080) just in absolute shambles compared to 6000 users.",
      "Less about margins, more about lifespan and product segmentation. Unfortunately this is the end result of a duopoly. There is no competition at all.",
      "This is overkill for this card, I understand it's because of the bus width and what not but hopefully that doesn't give them the excuse to jack up the price, I would much rather an 8GB card or whatever more reasonable capacity this bus size support if it means more reasonable price around $330.",
      "I don't think they will do 48 as that would be too close to the 7700XT. I'd lean more towards 40 CU and the 20Gbps memory config, otherwise AMD  risks cannibalizing the 7700XT sale numbers (which AFAIK are already bad enough).",
      "It has happened before. 3060 12 GB vs 3060 ti 8 GB. It's because of the bus width. 7700XT is 192-bit so it's either 12GB or 24 GB. With a 128-bit bus you either go 8 GB or 16 GB.",
      "So there is possibility that this is only a slightly higher clock 7600 with 16 GB vram slapped onto it. I honestly prefer better performance (6700 XT - 6750 XT) with 12 GB than 16 GB 7600.",
      "If its just 7600 with 16gb then it should be no more than $299",
      "I bought 7800xt. Because 7700xt was barely any cheaper...",
      "What games are you playing? I routinely see 10-14gb of use on my 7800xt playing new games at 1440p ultra",
      "I'm more interested in a \"cheap\" stable diffusion or LLM GPU and this may fit the bill depending on price.  For gaming .. I don't think the GPU has enough oomph to really need/utilize 16GB.",
      "First off, I'm not bragging, I'm just complaining about the sad state GPU's are in rn.\n\nSecond, my GPU isn't slow, that's kinda the whole problem. It's fine for what I do now but I've been wanting an upgrade for 2 years and there's just nothing worth buying.\n\nIf I paid the same price I paid 5 years ago for a new GPU today, the card would be roughly 30% faster. After 5 years that's a joke of an improvement. If I want double the performance I'd have to pay 50% more, which is insane.\n\nIt's mostly a testament to how bad the 40 series and the 7000 series are, as they barely improved on the 6000 series and the 30 series."
    ]
  },
  {
    "brand": "amd",
    "generation": "7000",
    "tier": "low",
    "matched_keywords": [
      "7600"
    ],
    "title": "AMD Announces the Radeon RX 7600 XT 16GB Graphics Card",
    "selftext": "",
    "comments": [
      "AFMF results as part of the marketing material? They are taking this Frame Gen stuff too far for my liking. Including FSR results in the marketing material was already questinable, and now AFMF, ugh. What about good old real frames at native resolution?",
      "Sadly when your competition is using similar features to market their product you gotta do it to stay competitive in mind share.",
      "I really don't get the hate for this GPU\n\n* I once listened to all people saying that 4GB of VRAM is enough in midrange GPU instead of 6GB at that time. I regretted this as f\\*\\*\\* when Horizen Zero Down whas struggling with that 4GB despite framerate being ok (for me, I'm casual gamer, I prefer better looks over 60+ fps).\n* New gen will likely get better and longer support. Also in things like ROCm which is important for some people.\n* 6700XT is more power hungry. If you are upgrading a few year old PC with 500-550W PSU, it's worth it instead of replacing PSU.\n* Pleeeeease don't compare this with 4060Ti 16G, it's completely different price range.\n* I'll buy this GPU the day the launch tax is done or maybe even earlier beacause I was waiting exactly for this for like half a year.",
      "I‚Äôm running a 6700xt stock settings with a 500w PSU. Doesn‚Äôt exceed 200W during heavy gaming. 7600xt is worth it if you don‚Äôt have a GPU.",
      "Uh?  \nI have an 6700xt and I can play at 1440p high setting and more often than not above 100fps",
      "The 6700 XT is a good 1440p card tbh",
      "And everyone called out Nvidia for those marketing slides. Yet AMD still went down the same road, solidifying that slides that are completely unreasonable are now the norm.\n\nAMD could've taken the high road and compared native to native, or FSR 2 and FSR 2 and they couldve even called out Nvidia's terrible frame gen comparison slides, but they didnt because the 7600 XT is not a competitive product and thus AMD doesnt feel like they can take shots at Nvidia like they could with RDNA 2.",
      "Nvidia announces three solid Super cards and AMD announces this lol",
      "> I really don't get the hate for this GPU\n\nOkay I'll break it down for you.\n\n> I once listened to all people saying that 4GB of VRAM is enough in midrange GPU instead of 6GB at that time. I regretted this as f*** when Horizen Zero Down whas struggling with that 4GB despite framerate being ok (for me, I'm casual gamer, I prefer better looks over 60+ fps).\n\nThats a fair point, you can play as you choose. But this card is really only good for 1080p gaming at maxxed out settings. At 1440p you will have to turn down settings. RT is basically not very good on a card like this. Thus at 1080p not many games will saturate 12GB of memory on alternative cards like an RX 6700 XT and other alternatives exist like a used RX 6800 which is not only faster but similarly priced with the same VRAM. So you're better off with one of those.\n\n> New gen will likely get better and longer support. Also in things like ROCm which is important for some people.\n\nSure but by the time the RX 6000 series is outdated you will have probably upgraded anyways. Think about the RX 480 and how much support it's received and to this day I would say it's not good enough for 1080p max settings gaming like it was back when it released in 2016. Point is, by the time support is an issue, its time for an upgrade anyway. ROCm is cool, but not much of a difference between 6000 series and 7000 series, unless you're looking at buying an R9 390 or older, it's pretty much a non issue.\n\n> 6700XT is more power hungry. If you are upgrading a few year old PC with 500-550W PSU, it's worth it instead of replacing PSU.\n\n[70W between a 6700 XT and a 7600, it's not much of a difference.](https://tpucdn.com/review/amd-radeon-rx-7600/images/power-gaming.png) If you're using an older PC with say a i5-2500 or something like that you're never going to exceed 550W. [i5-2500 draws 150W at most under heavy Prime95 load](https://tpucdn.com/review/intel-core-i5-2500k-gpu/images/power.gif). 230+150W, hmmm 380W. Not an issue at all versus 310W.\n\n> Pleeeeease don't compare this with 4060Ti 16G, it's completely different price range\n\nEveryone knows that card is absolute garbage in terms of pricing. Most people compared it to a 6700 XT or a used 6800 or a RX 6700.\n\n> I'll buy this GPU the day the launch tax is done or maybe even earlier beacause I was waiting exactly for this for like half a year.\n\nGood for you.",
      "A sign that most people looking at a good enough upgrade for 1080p (whose GPU budget is only $350 max) are literally in a conundrum, despite the ~5-10% uplift and a narrow 128-bit bus/uber-large VRAM (that may not see good use well outside of those with PCIE 3.0 boards) for such a GPU in its class.\n\nTo highlight this conundrum (regarding the 7600XT) I talk about:\n\n-Yeah the 16GB may be useless on this level of performance especially that narrow bus, however so is the 4060 Ti 16GB and AMD at least does not ask for $500 lmao. The latter is way faster but so is the 7700XT which may be out of your budget.\n\n-The 6700XT exists and is the better buy for this segment, but it's getting hard to find depending on your market. Where I live it's either not available or prices are stupid (7700XT is sometimes cheaper like literally). If the 7600XT's real world gaming performance is quite close to the former, then it's something to think about at least.\n\n-Some games literally eat >8GB even at 1080p med-high. This card may show relief for such titles if FH5 is any indication. Good for me that rocks BC7 compression 2K custom Fallout 4 textures.\n\n-Some people have PCIE 3.0 boards. That huge VRAM can stave off the ill effects of the GPU's x8 lanes on PCIE 3.0 systems. \n\n\n-Your other choices are either a 4060 non-Ti which is only 8GB or the 3060 12GB which is slower than 7600 non XT.  Choosing the very former is a no-brainer if it were not for this VRAM conundrum we're in. \n\nTLDR: (paraphrased from an Anadtech comment) It may offer a compelling 1080p performance for a possibly reasonable price, that also gets past the 8GB conundrum while possibly undercutting the 4060s.\n\nAll I can say is that I do hope the 7600XT's real world performance is what TechPowerUp's prediction it will have. I can just get that instead (if prices are good) as 6700XT where I live is hard to find. Good enough for me if that's the case. No plans to upgrade from 1080p anyway.",
      "So who's 'ahead' of Nvidia then if AMDs competition (Nvidia) is ahead of them and yet  started doing that kinda crap  first?",
      "Texture resolution is one of the most easily noticeable graphics setting you can change, and having enough VRAM to crank it to the max in the newest games can squeeze quite a bit of extra life out of a card. \n\nHaving a GPU with what today seems like a bit too much VRAM compared to the rest of the card's capabilities helps with this.",
      "AMD shouldnt have waited for CES to announce this, it shouldve come sooner and had a price drop for christmas sales. Launching it at CES at it's MSRP is a joke, its not competitive with anything.",
      "6750xt will still be much better than the 7600xt",
      "I play at 4k60 with it, mostly with a mix of high/ultra settings. I‚Äôm not playing the latest AAA, but I get great performance on CP2077 and Elden ring.",
      "What is there to announce?",
      "I play at 1440p with an RX580. It just obviously isn't current AAA games (nor esports). Sure I have to turn settings down, but whatever the 6700XT and 7600XT can produce at 1440p is leaps and bounds better than an RX580. I think it's a bit unfair to say people wouldn't consider these cards for a budget 1440p setup if they've already got a 1440p capable monitor.\n\nEdit: Assuming the price drops too a good spot",
      "It's significantly slower.",
      "I would understand FSR 3 vs DLSS 3. Fair enough. But AFMF is something activated at the driver level. A lot of users have no idea how to do it. Besides, the contribution of AFMF in gaming is still pretty questionable. I would say it is better to have it OFF then ON, but perhaps I am more latency sensitive than most.\n\n\nRegardless, AMD could still compare the 7600XT to the 4060 both cards running naked. Just pure native frames, the way it used to be.",
      ">the super cards are just pushing the stack up one tier then discontinuing the old stack.\n\nNot really sure what you mean by this. The Super cards are basically upgrading the stack while either keeping pricing the same or improving it which is a much better move than most expected from Nvidia.\n\n4070 Super and 4070Ti Super are both pretty compelling cards imo and I'm probably looking to upgrade to a 4070Ti Super in the next few months to play games maxed out at 1440p. 4080 Super is decent too but mostly because it finally dropped from the horrendous $1200 price point of the original 4080.\n\nOverall these cards make RTX 40 a much better option for the next year until RTX 50 launches and I can't fathom buying an RDNA3 card over these unless AMD greatly reduces prices (which they might but we'll have to wait and see)."
    ]
  },
  {
    "brand": "amd",
    "generation": "7000",
    "tier": "low",
    "matched_keywords": [
      "7600"
    ],
    "title": "[Tom's Hardware] AMD Radeon RX 7600 Specifications Reaffirmed in Leak: 2048 Stream Processors",
    "selftext": "",
    "comments": [
      "god i wish theyd stop with the less than 16 lane BS",
      "The RX 7600 is now confirmed to feature Navi 33 XL GPU with 32 Compute Units and 2048 Stream Processors. The card is equipped with 8GB GDDR6 memory across a 128-bit bus\n\nThe card has limited PCIe interface to Gen4 and 8 lanes\n\nIn terms of clocks, the GPU-Z software reports on 1720, 2250 and 2655 MHz for base, game, and boost clocks respectively. In real-world use, the GPU clock goes up to 2.85 GHz",
      "Good thing it doesn't use siliconE",
      "They are cropping cost by cropping hardware.",
      "That is not true. Cutting 8 lanes saves ~1mm2 die area, and the cost on the PCB is minimal too. So- tiny cost difference, but a significant difference for consumers who are on PCIe 3.0. It can even be a crippling difference, if you look at 6500XT 4GB.",
      "telephone ludicrous snails fertile sulky somber judicious safe smart include -- mass edited with redact.dev",
      "People want a 'cheap' entry level card - 4/8 lanes is a lot cheaper to produce, while the card can maintain its peak performance.\n\n\nWhat you are asking here is to put a 5.5L Twin Turbo into a Ford Focus, because maybe some person will find a use for it...",
      "Market it as \"the venerable $199 mid range card is back\", really lean into the RX 480s legacy.",
      "Lol Nvidia just announced the RTX 4060 for 299$\n\n[https://www.theverge.com/2023/5/18/23728149/nvidia-rtx-4060-4060-ti-release-date-price-specs](https://www.theverge.com/2023/5/18/23728149/nvidia-rtx-4060-4060-ti-release-date-price-specs)\n\n&#x200B;\n\nThis better be 199-250$ max or AMD might as well just cancel the GPU all together",
      "Cost on the PCB is not minimal you can save layers that makes it cheaper. At first I was reluctant too but if you see similar cards from AMD like the RX 6650 XT it as the same 8 lanes and the performance penalty at PCIe 3.0 is around -1%. The problem is with PCIe 3.0 if the card as only 4 lanes (6500XT).",
      "its officially announced, $299 4060, gosh",
      "It likely would have marginal better performance than a rx6650xt while consuming less power. It would also have better ray tracing and new features.",
      "Uses silly cones",
      "How TF is it a leak when the damn chip launched January as the 7600M? The ONLY thing left to reveal is clockspeeds and price.",
      "Honestly it might be doa either way even if they price it at 250$.",
      "Who's gonna tell him",
      "Sounds an awful lot like the 4060/4060ti, which are in pretty much the same position compared to their previous generation",
      "[https://www.techpowerup.com/gpu-specs/radeon-rx-6600.c3696](https://www.techpowerup.com/gpu-specs/radeon-rx-6600.c3696)\n\nrx 580 is 58% of rx 6600 performance\n\nBut do go on, talk shit about it without knowing. Show your arrogance.",
      "Its not even a rumor. Its the GPUz screenshot with the actual GPU",
      "The hell are you on, they already have announced the 4060 price. https://www.nvidia.com/en-us/geforce/news/geforce-rtx-4060-4060ti/"
    ]
  },
  {
    "brand": "amd",
    "generation": "7000",
    "tier": "low",
    "matched_keywords": [
      "7600xt"
    ],
    "title": "Radeon RX 7600XT Review: Can AMD Eliminate The RTX 4060?",
    "selftext": "",
    "comments": [
      "Looks like their older GPU (6700XT) eliminates the 7600XT instead.\n\nEdit: [a quick search](https://imgur.com/RgZEy27) on Newegg shows several models of the 6700XT are in stock and priced between $329 and $349.",
      "that is if you can get one because massive amount of people are buying last gen GPU's\n\nif anything 7600XT over time will become a 6600XT once new cards come out",
      "Will probably get shanked for this opinion but... Want a card now, great, get a 6700xt, but it won't be forever so when it does go, hopefully, this will have drifted down to $300 and I think it's a pretty good upgrade for someone with an RX580 8GB or something.",
      "Needs to be $300 IMO but it will get there eventually, probably after the 6700XTs are all sold.\n\nI am please they tested Halo Infinite as it goes to show how looking purely at frame rate does not always tell the whole story. It also reinforces my belief that someone (and given their expertise I think DF could be really good at this) needs to do testing in the style of [H]ardOCP where you compare maximum playable settings so you make IQ the variable and frame rate more fixed.",
      "AMD always takes the opportunity to miss an opportunity. Continue being 2nd best in the market.",
      "This card is just a joke - it‚Äôs another RTX 3060, where the massive VRAM buffer can‚Äôt make up for the fact that it‚Äôs barely faster than its predecessor while being vastly more expensive, and gets destroyed by discounted last-gen cards. AMD never fails to drop the ball.",
      "AMD sees nvidia release the atrocious 4060 ti 16g and decided they need to do the same‚Ä¶",
      "as is tradition at this point",
      "I miss \\[H\\]ardOCP and Kyle's reviews",
      "I just think it's bad form for AMD to release a new card that performs worse for the money than an old card. The 7600XT IMO should have been boosted in some way to make it perform at 6700XT level for this to be considered ok.",
      "problem with this is that entire product stack got screwed over so cards are in positions they are not supposed to be at\n\nwhy do we have a 7900XTX and 7900XT?\n\nwhy do we have those GRE cards?\n\nwhy does super series exist if we have a Ti series?\n\nwhy did NVIDIA make a abomination of a 4070Ti super?\n\nboth sides this gen pushed their cards up the stack so they can sell them at a higher cost and people for some reason just eat the cost\n\never since turing (don't forget 1060 and 970 fiasco) and RX500 polaris naming scheme has been complete trash (honor mention to polaris because RX590,RX580 2048SP,RX560X and RX560XT are stupid products)\n\nif we were to re-structure card classes people would get pretty upset on things they are being baited into purchase",
      "Another pointless product just like the 4070 Ti Super is, but at the least in case of 4070 Ti Super some may say that it feels like more of replacement of the previous existing outgoing 4070 Ti at the same price point.\n\nWhereas this is 22% more expensive than the 8GB model and it is barely faster, i don't see any reason why people will bother going for this over the 6700XT which feels more balanced with just right amount of vram at its price point and has more raw rasterization performance.\n\nThis is truly a 4060 Ti 16GB moment of AMD.",
      "At least it‚Äôs not at 500 usd price tag.",
      "I have a 580, and yes I‚Äôm eying this card, and the 7800xt.",
      "The profit from the 10 they'll sell?",
      "Well they were my GPU reviews, but sure :)",
      "True. But not true in the case of 7600xt, nobody who is interested in AI is going to buy that card.",
      "I'm not arguing if the stack is fucked up.\n\nI'm saying the 7600XT is too weak of a card for 16GB of VRAM to really impact the performance and they want to sell it for as much as 6700XTs that have better performance and enough VRAM. But because Navi 33 has such a narrow bus they have to clamshell the memory and add 8GB where 2 or 4 would have been enough. \n\nThe 7600XT should have been a 10/12GB card on Navi 32 For around $350 for 3070/3070Ti performance. \n\nI just don't know who would want to spend $60 more than a 7600 for what looks to be less than 10% more performance. It's not a powerful enough card to run all the textures and RT that would use that 16GB of VRAM.",
      "I just did a RX 580 to 7800 XT upgrade last night. Closing out my fool proof Dec 2018 plan. Where I buy a XFX RX 580 8gig for $190 being it comes with a $60 game (The Division 2) I was going to buy on release anyways. \n\nSo +$130 to go from a 380 to a 580? Sure! Figure it's a temp upgrade for about a year. Then the 6000 series drops in late 2020 and I snatch up a surplus 5000 series on the cheap. As I said..... fool proof plan! \n\nand this is the point where I glaze over thinking back to 2020 and just stare off into space.......",
      "What we really need is for the 7700xt to be $350, its shoulda-been price"
    ]
  },
  {
    "brand": "amd",
    "generation": "7000",
    "tier": "low",
    "matched_keywords": [
      "7600"
    ],
    "title": "Gigabyte confirms Radeon RX 7600 8GB and GeForce RTX 4060 Ti 8GB GPUs",
    "selftext": "",
    "comments": [
      "7600 has to be $250, otherwise AMD can f off\n\nAlso imagine buying the 4060 ti with 8gb VRAM for $400-$500. What a joke",
      "AMD: ‚Äú8GB is not enough in 2023!‚Äù\n\nAlso AMD: *Releases 8GB graphics card in 2023*",
      "well.",
      "I honestly wouldnt buy a 1080p card today for 250$ at most... its a joke if any of them does.",
      "If the 7600 xt card for 250$. I see no issues with 8gb.",
      "Or the 6000 series. 6600 is a great card for 1080p, with a great 200 dollar price.",
      "Its the pricing that matters.",
      "No they said you shouldnt pay over 500 dollars for 8gb",
      "I can already hear HU Steve saying \"dead on arrival\".",
      "Each GB, possibly",
      "Fkn e-waste.",
      "For $199 each?",
      "The entire current situation is a great shot for Intel to try something, ngl\n\nA 12-16gb low-mid range card for like $250 would get everyone to buy instantly",
      "No doubt VRAM is an issue these days but Diablo 4 had leaking problems in the last open beta. Hopefully we'll see a significant improvement in the \"server slam\" next week",
      "I bet AMD will price the RX 7600 at 279$. They love their x79$ prices. \n\nx99$ is surely wayy expensive for what we offer, x49 we could do but won't cause ngreedia gave us that leeway, so sweetie let's settle for x79$. See how benevolent we are.",
      "RX 7600 (8GB) for $240\n\nRX 7600 XT (16GB) for $320\n\nAny more than that and its a hard pass. Might as well pick up an RX 6700.",
      "Still fine for 1080p, which is clearly what these cards are for.",
      "Not saying they aren't, but it's a bit hypocritical to say that 8GB is not enough, laugh at Nvidia for it, and then proceed to launch an 8GB card.",
      "Here I though amd said that 8gb wasn‚Äôt enough for gaming anymore?",
      "I think you‚Äôre being downvoted because you don‚Äôt need to spend ~$1000 on a GPU for 1080p gaming unless you want around 400 frames and even then what kind of monitor are you going to put that on now that you‚Äôre free of bottlenecks?\n\nThe power draw, VRAM, and cost are all extremely overkill for a 1080p system. \n\nOne could achieve similar performance at a fraction of the cost. It‚Äôs just so incredibly wasteful."
    ]
  },
  {
    "brand": "amd",
    "generation": "7000",
    "tier": "low",
    "matched_keywords": [
      "7600"
    ],
    "title": "Affordable Ryzen 9 7900, Ryzen 7 7700, and Ryzen 5 7600 could release in Q1 2023 with reduced boost clocks and 65 W TDPs",
    "selftext": "",
    "comments": [
      "Sounds like AMD's going to ask for your first born for 3D V-cache CPUs. First a discount on the original lineup and now potentially non-x SKUs.\n\nWouldn't really be surprised if an extra $50-$100 was taxed to the 3D cache parts over vanilla due to inflation, increased cost of materials and profit (as a business should). Intel has better price/perfomance but people who want the best will overlook value.",
      "we‚Äôll see. rumors of a non-x 5600 being released in February 2021 proved to be false. we had to wait til april 2022 for those",
      "I fully expect the 7800X3D to be either $450 or $500, and a possible 7600X3D to be $350 or $400. Basically about an entire pricing tier above the actual product segment. On one hand, $350 6 core processor. On the other hand, $350 might get you the best for gaming processor by like 10-30% depending on what games you play if the difference between the 7600X and theoretical 7600X3D is similar to the difference between the 5800X and 5800X3D.",
      "I think they're more likely to be released this time around given Intel is much more competitive, but as you said we'll see.",
      "That is amazing and all, but when 3D V-Cache Versions? Can they maybe anticipate that with the next lineup, people want 3D V-Cache versions right away instead of a year later?",
      "As long as the motherboards also don't come down in price, it's still hard to upgrade to Zen4 for a lot of people. Not everyone wants to spend that much money on an upgrade.",
      "Ryzen 9 at a 65W TDP seems interesting. Sad to see that AMD seems to have given up on making a Ryzen 3 that has Zen 3 or 4 cores for desktops.",
      "How bout some affordable motherboards and DDR5 RAM modules",
      "Intel havent done that, atleast not yet.\n\nAnd that doesnt justify it.",
      "Epyc rejects can still be extremely high quality. Epyc chips are for professional workloads and have to meet precise standards that are much more rigorous than the consumer markets.",
      "I'm all for 65W CPUs. 1700 / 3700x... and probably 8700 in the future",
      "Wasn‚Äôt the i7-6950x $1700+ at launch msrp? Like over $700 from the previous gen extreme edition?",
      "naw, they just refreshed 14nm for several gens with 2% more performance and a new socket each time![gif](emote|free_emotes_pack|trollface)",
      "I've been thinking about moving from my 9700k to AMD next year.",
      "Hey AMD, if you‚Äôre reading this, people are waiting for V-cache models. The sooner those are released, the sooner people will hop on AM5.",
      "Sadly that's one of consequences of AMD not having its own factories anymore, as the limited production capacity makes them focus on more profitable chips. Also, the yield is so good it makes no sense to disable fully functional 6 and 8 cores CPUs to make a quadcore Ryzen 3.\n\nWhile Intel made very fast and affordable Core i3-12100(F), AMD released garbage like Ryzen 3 4100, shouldn't have even bothered.",
      "> due to inflation, cost of materials and profit.\n\nMostly that last one.",
      "Current rumours have suggested the 7600x3d and 7800x3d will be announced at ces 2023. Don't believe they've provided any indication on price or actual launch date.\n\nThere may also be ryzen 9 x3d parts, although I think that's gone back and forth. The most current rumour is that they'll be coming late 2023 I believe.",
      "Those CPUs are cheaper, if it was similar / same price, ok then.",
      "AMD losing more to Intel this gen, so to counter that they are releasing shit nobody even wants?  \nRelease the damn 3D Vcache models in Q1."
    ]
  },
  {
    "brand": "amd",
    "generation": "7000",
    "tier": "low",
    "matched_keywords": [
      "7600"
    ],
    "title": "AMD Ryzen 7 7700 and Ryzen 5 7600 non-X 65W CPUs spotted over SiSoftware database - VideoCardz.com",
    "selftext": "",
    "comments": [
      "7600 needs to be $200 or less, frankly.  7600X should be $250 or less.\n\n13600k is $300, cheaper platform, and higher performance.",
      "Realistically, will they even sell? The problem with AM5 has been high motherboard and DDR5 costs. Is someone really going to spend $600 on a mobo and RAM upgrade and only drop <$250 on a CPU? It just doesn't make much sense, especially when Ryzen 5000, Intel 12th gen, and Intel 13th gen are fairly similar in performance and much, much cheaper platforms.",
      "Under 250$ for the 7600 and 300$ for the 7700. Anything else and its DOA.",
      "of course.   OEMs want to have motherboards with cheaper power delivery and costs.  They want cheaper cooling, and can get it all for essentially identical performance in most things people care about.",
      "Top sellers, for sure.\n\nNot to enthusiasts, who have to pay for motherboards capable of 225W+ power delivery and demand 14 VRM phases.\n\nBut to OEMs who will make their own bare bones motherboards that can't support much more than a 65W CPU, and can install small air coolers, and run JEDEC 5200 DDR5 ram?    Yeah, these will sell well.\n\nIn total sales volume, these will sell well because most sales volume is NOT enthusiasts or gamers.  For most users, and most businesses, the iGPU on Zen4 is enough as well and OEMs don't have to buy over-built motherboards with price tags to gouge early adopters.\n\n&#x200B;\n\nBut yes, for those of us who build our own systems and buy retail motherboards?  These are not great, at least until the motherboard costs come down.",
      "Yes. His conclusion was, for gaming, get the 7600X platform. For gaming on a tighter budget, get the 5800X3D platform. For doing productivity along gaming, get the 13600k platform.",
      "AM5 is overpriced and in poor position vs 13th Gen. Current AM5 pricing needs to come down aswell as motherboard pricing. 5000 series only got away with high pricing thanks to an already established platform base so people only needed a new CPU.",
      "OEM only I bet. Like a lot of past CPUs were OEM only from AMD.",
      "Has to be $199 for 7600 or it wont",
      "lol. These should be the prices for \"X\" models in order to compete vs 13600K and 13700K. 7600-non X should be 199$ and 7700-non X should be 249$, or else DOA.",
      "Didn't hardware unboxed put the 13600k at same performance per dollar for gaming, platform included?",
      "The fact that the 13600K is a better deal unless AMD drops the price?\n\nIdeally we'd have cheaper motherboards and RAM, too...\n\nThough I feel like the 5600 is still the best for low end. Will it bottleneck a 4090? Sure, but I don't think anyone is paying $1600-3000 for a GPU to pair with a $150 CPU.",
      "All the 550 and 570 motherboards out there bought with Zen 3 tell a different story.\n\n&#x200B;\n\nZen 3 was a high-ish price, but it flat out beat the competition in many regards, and the platform either cost about the same (newer 500 series) or cost less (older 400 series) than the competition.\n\n&#x200B;\n\nBut no, Zen3 was very frequently bought with a new motherboard, it was not all people upgrading existing systems.",
      "> ...I think the 7600X is the better choice for gaming, just gaming, again, just for gaming, and that's not because it came out ahead in our gaming benchmarks by a very slim margin, but because it is supported by a superior platform that will offer many more CPU upgrade options. Now you might say, I don't care I'll upgrade my motherboard with my CPU in three, four, or maybe five years from now, but the point is, when performance and price are virtually identical, you have to look at other factors, and when doing so the fact is the 7600X is on a superior platform, it does consume less power, and it is easier to cool despite its love for the 95 degree TJ-max. Even if you decide you want to spend as little as possible on the motherboard, I still feel for gaming the 13600k is a bit of a tough sell. \n\n-Hardware Unboxed, \n\nBest Value Gaming CPUs, 13600K, 12600K vs. 7600X, 5800X3D, 5600X\n\nTimestamp: 22:50",
      "People buying prebuilts will get it most likely.",
      "A 300 7700 would kill the 7600x and 7700x, it would beat the 7600x overall and be just a hair behind the 7700x.",
      "I had never thought about that. This is a good insight.",
      "Got a source for that?",
      "HEHEHE, Ryzen 7600 + Radeon 7600 amirite",
      "It took months for it to hit the shelves for retail after the OEM release, though\n\nEDIT: My mistake, I was thinking of the G chips. Regular 5600 was released for both channels at the same time apparently"
    ]
  },
  {
    "brand": "amd",
    "generation": "7000",
    "tier": "low",
    "matched_keywords": [
      "7600"
    ],
    "title": "AMD Ryzen 7900/7700/7600 non-X CPUs reportedly launch on January 10th - VideoCardz.com",
    "selftext": "",
    "comments": [
      "Affordable am5 motherboards when?",
      "Wait another Generation",
      "If they launch 3 non X sku's and 3 X3D skus its gonna be one cluttered lineup from 200-500$",
      "Ah yes the ‚Äú3060‚Äù 8gb treatment.",
      "Could be worse, like a 7700x but it's 2ghz max clock and the box is the same as a normal 7700x.",
      "\"we want cheaper CPUs, these are too expensive\"  \n\"Okay, here's non-X version of CPUs\"  \n\"Waaah, we want x3d versions of CPUs\"",
      "Not really zen2 launched with \n3600\n3600x\n3700x\n3800x\n3900x\n3950x\n\nThat‚Äôs before they added XT and 3900 sku.  Sure Some skus really didn‚Äôt sell at msrp (3600x and 3800x) but it‚Äôs good to have choice",
      "Great! \n\nAM5 motherboards highly unaffordable right now: not so great. \n\nIn fact, it's terrible for AMD that wants to introduce these CPUs just to hit the moba-price barrier that makes people going for intel chips.",
      "A620 launch",
      "Microcenter is offering free 32gb of DDR5 6000 RAM and $20 off motherboards with the purchase of a Zen 9 CPU. I bought a 7900x that way yesterday. It's a pretty amazing deal, especially with AMD's Zen 9 price cuts. I don't know how Microcenter makes money off of it.",
      "Yesh but nothing like that year-revision-generation-cousin-numberofdaysuntilsummersolstice-toenailcolor for mobile processors. \n\n\"..3D\" is pretty well established at this point, so are \"X\" and non-\"X\".\n\nLots of choice isn't necessarily bad if the naming scheme isn't bonkers",
      "OH ALL SEEING GREAT ONE, WILL MY EX SLEEP WITH ME TONIGHT?",
      "What would you do with a mainboard that does not support any RAM at all? Zen 4 has a DDR5 memory controller only, so an AM5 mainboard that does not support DDR5 does not support any RAM at all.\n\nSo, obviously, A620 mainboards will support DDR5 RAM.",
      "Almost 4080",
      "Ahh yes the ‚Äú4080‚Äù 12gb treatment.",
      "I kinda wish they had called them \"eco\" variants instead of just non-X. \n\nI'm certainly tempted to get a 7900. 12/24 cores @ 65 watts, with 90-95% of the performance of the X variant? And at a lower price? Yes please.\n\nElectricity prices are through the roof where I live. I've had to limit my gaming lately because of the cost of running my gaming PC. This is a step in the right direction.",
      "It must be nice to be a computer enthusiast living in the US...",
      "Minor correction, 3950x launched almost five months after the rest (Nov 25th, vs July 7th).",
      "There aren't that many Microcenters out there. None in the Pacific Northwest. Only one in New England. Five across the entire south. One in the mountain west. Eight in the midwest. One in California (near LA, so SF basically doesn't have one). Only two west of the Rockies (CA and CO).",
      "Ds3h 50 bucks when?"
    ]
  },
  {
    "brand": "amd",
    "generation": "7000",
    "tier": "low",
    "matched_keywords": [
      "7600"
    ],
    "title": "Regulatory filing hints Radeon RX 7600 XT, RX 7700 and RX 7800 cards might be coming - VideoCardz.com",
    "selftext": "",
    "comments": [
      "For what? To fill 5 fps gaps? I don't get it, their current lineup doesn't habe big enough gaps for shit like this IMHO",
      "There really isn't much space to squeeze another SKU between a 7700XT and a 7800XT IMO.  54 to 60 CUs and 12 to 16GB VRAM.  What would a 7800 non-XT look like?  60CUs but only 3 MCDs/12GB?",
      "imho that's an EEC typo",
      "The lineup has one gap: between 7600 and 7700XT. $269 to $449 is much too large of a gap. There is also 7900XT to 7800XT, $499 to $899, but there is at least 7900 GRE in that gap even if it isn‚Äôt widely available. I‚Äôm sure AMD WANTS to put something in that lower gap, but I‚Äôm not sure what that card is. A third tier Navi 32 is of course an option, but the confusing pricing of the 7700XT (and quite frankly, the stupid naming of the entire lineup) makes me think that they don‚Äôt want to price any of their chiplet designs any lower for whatever reason - more likely capacity than cost, but it could be either.\n\nFaster Navi 33 seems unlikely as the boost clock is already the highest in the lineup. Of course they could upgrade the VRAM clock to 20GHz effective, but that‚Äôs about it, and I don‚Äôt think Navi 33 is bottlenecking that hard on memory bandwidth anyway.",
      "How I've always seen it:\n\nWhat it's called --> What it actually is\n\n7900XTX --> 7900XT\n\n7900XT --> 7800XT\n\n7800XT --> 7700XT\n\n7700XT --> 7600 XT\n\n7600 --> 7500 XT\n\n\nAnd it's ridiculous that the inflation adjusted price of a 8GB card is the same in 2023 as it was in 2016. Price range for the listed models should be something like $150-$750.",
      "I respectfully disagree. There is a gaping hole in both performance and price between the 7600 and 7700XT.",
      "lower clocks, less W",
      "And what MSRP difference?  It would cost virtually the same to make and there's only a $50 gap to squeeze it into and that's less than the existing difference between AIB 7800XTs.  IDK maybe AMD plan to cut the 7700XT MSPR?",
      "> \"Super\" is never\n\nThe 2070 Super was the same price as the 2070. Same with the 2080 Super.",
      "I couldn't care less about these. My sticking to the 5700 XT is solely about the absurd pricing of the existing lineup. Releasing more overpriced cards won't make me upgrade or recommend an upgrade to anyone else. Just bring down prices to sensible levels. The $7900 XTX barely hitting a 10% discount after a year is crap. Holding the 7800 XT back a year (3 years after the 6800 XT that performs the same) doesn't make the $500 price tag look good.",
      "If enough people are smart like the poster you replied to the prices will fall before that. I‚Äôll also sit on my 3060TI for another few years if I can‚Äôt get a true midrange card again for less than ‚Ç¨400.",
      "IMO 40% is not enough of a jump to upgrade at similar pricing, let alone higher pricing. You would think that 2 gens later, you should be getting at least 2x performance for the same price. Sadly this reflects the trend of diminishing performance gains every gen thanks to inflation and physics. I don't expect to have to upgrade my 6700xt for atleast another 5 years given how slow GPU hardware is improving.\n\nVRAM can be a reason to upgrade if certain games can't run or can only display a blurry mess which is the case with a number of new games on 8gb cards.",
      "7850XT would make more sense to compete with 4070 Super.",
      "It‚Äôs completed in the sense that they have released an SKU for each die. Doesn‚Äôt mean they won‚Äôt release a different variation for each die.",
      "For real, price difference between 7700XT and 7800XT is already so low that it makes no sense to even consider 7700XT and just go for 7800XT. If they significantly drop the price on 7700XT then it would make sense but then the 7800 non XT would become pointless to consider.",
      "Nvidia's rumours are Super refreshes of existing GPUs, which will also come with price rises. How exciting is that?",
      "1650, 1660, 2060 Super were more for more.\n\n2070, 2080 Super were more for the same.\n\nAlthough the 2080 Super was only like 5% more perf.",
      "....\"Rumors state a company that releases updated lineups is going to be creating an updated lineup.\"\n\nIs this really all they have to write about.",
      "The 4070 Super will probably be more expensive than the 7900 XT.\n\nI don't know why people are in denial about Nvidia's pricing. \"Super\" is never a price cut or even price stabilisation; it's something like 8% more performance for 15% more money...",
      "No, there's two possible reasons for the 7800.\n\n1. Vram prices crashed hard just before the launch of the 7700xt. You can get 8gb of gddr6 for $25 pretty much and this happened around June 2023. With the lead time to a product launch, the August release of the 7700xt was likely planned prior to these prices collapsing.\n\n2. Yields of the dies are good enough AMD wants to up the CUs. It could also be AMD found 60 CUs at lower clocks is perfectly stable, so there's no need to cut down to 54 when they could sell 60 just at a lower clock speed.\n\nSo, there are at least two reasons I see for this that make sense."
    ]
  },
  {
    "brand": "amd",
    "generation": "7000",
    "tier": "low",
    "matched_keywords": [
      "7600"
    ],
    "title": "Some 6+2pin power cables may not fully fit into Radeon RX 7600 reference card - VideoCardz.com",
    "selftext": "",
    "comments": [
      "I smell something..",
      "Gamers Nexus tear-down didn‚Äôt show this problem, has there been any more samples of such issues? Hopefully this is just a singular problem and not super widespread.",
      "You won't melt your power cable if you can't plug it in. Good thinking.",
      "That‚Äôs someone‚Äôs gpu burning‚Ä¶",
      "When did he try and plug a 6+2 in? he just tore it apart from memory, I would assume they used a regular 8 pin for their actual testing phase.",
      "That's exactly how you melt them with bad connection they just want to cook.",
      "It's interesting as a note for AMD future designs, though doesn't matter to consumers as reportedly there will be no reference cards sold.",
      "he ran the full suite of tests on it first.  or at least his team did.  According to Techwhatever a certain percentage of their cables didn't work maybe they just happen to have one of those types?",
      "> there is no doubt that this is a clear oversight by AMD, who should know better that there are many types of cables. The least they could do is to add a power cable extender\n\nWhy do I strongly doubt that those making such claims have actually check the standards & specs w.r.t. clearance/keep-out-zones around the connector..?  \nHypothetically, why isn't the fault with the split plugs for A) existing when intended for a monolithic 8pin socket, and B) reinforcing their weak plastic with this specific extra material? If not all 6+2 have a problem, how's it the socket side & standard at fault?",
      "I don't see why they would test multiple power cables / PSUs. It would, under normal circumstances, be a waste of time to do so.",
      "I suspect not, the 8 pin is super over specked. Time will tell tho so we may see problems.\n\n&#x200B;\n\nJust as there have never been large reports of 8pins melting apart from extreme OC & we know a lot of people cant be trusted to push in a plug so there must be a lot of lose 8pin plugs out there. Yet so far no large reports of problems.\n\nAlso the GPU sips power, so I suspect it will work or wont. If not working the user may try to push in the cable until it works.",
      "AMD is like those kids who are smart but always don't do well in exams.",
      "Is it tens of thousands of redditors chomping at the bit for the next scandal or controversy?",
      "?? Why it's literally just plastic moulding.  Is it that you don't trust YOURSELF to plug it in properly?",
      "Apparently there would be at some point, at least directly through AMD.\n\nhttps://www.reddit.com/r/Amd/comments/13rj6a1/rx_7600_mba_coming_soon_on_amd_shop/",
      "The year of gpu power cable issues. It is official.",
      "SATA to 6+2pin fire deathdapters.",
      "yes because no power supply manufacturer i know has such a fat stabilizer piece, let alone most of them are flat or set back and that has its reasons.",
      "I'm not sure what exactly you're confused about but, the issue is that the backplate on the AMD reference card does not have enough clearance around the PCIe power plug and may interfere with some plugs designs (notably the ones that are 6+2).\n\nIf you compare the AMD reference and AiB designs the latter all have extra clearance in that area with their backplate designs.\n\nAMD Reference -\nhttps://www.techpowerup.com/review/amd-radeon-rx-7600/images/cablefail2.jpg\n\nSapphire - \nhttps://www.techpowerup.com/review/sapphire-radeon-rx-7600-pulse/images/power.jpg\n\nPower Color - \nhttps://www.techpowerup.com/review/powercolor-radeon-rx-7600-hellhound/images/power.jpg\n\nAsrock - \nhttps://www.techpowerup.com/review/asrock-radeon-rx-7600-phantom-gaming/images/power.jpg",
      "I do not know of a single power supply out there that is not 6+2, including my Seasonic 1KW power supply."
    ]
  },
  {
    "brand": "amd",
    "generation": "7000",
    "tier": "low",
    "matched_keywords": [
      "7600"
    ],
    "title": "Faster GPU or Faster CPU: Ryzen 7600 + RTX 4070 Ti vs. Ryzen 7800X3D + RTX 4070",
    "selftext": "",
    "comments": [
      "Why do CPU related benchmarks / Reviews never include MMOs? One of the main target audiences for the X3D cache.",
      "The 7800x3d 4070 wasn't ahead  at all, lol. \n\nOf the 8 games, the 4070 Ti with the weaker CPU got more fps in 6 games at 1440p. The ones where it lost was in Fortnite (both exceeded 240fps average) and Spider-Man (both exceeded 120fps average).\n\nThe GPU is still more important in the vast majority of games. As long as your CPU can prepare enough fps for your GPU, it doesn't matter how much faster the CPU is.  \nIn the games where the CPU is the limiting factor, you usually get high fps anyway. \n\nThe results shown in that video seemed exactly like one would expect. 4070 Ti gets more fps in most games. 7800X3D gets more fps in CPU bound games. Pairing a 7800X3D with a mid range GPU very rarely makes sense. Especially if you plan on getting a monitor with less than 240Hz anyway.",
      "I always told people not to buy expensive high end cpus before having something like a 4080. The GPU is way more important and even my 5600x is more than enough for any game really. I would get at least something like a 4070Ti before before even considering a cpu upgrade. Modern Cpus are insanely good and you don't even need the best, while modern game graphics can easily even push the best gpus to their limits. Except maybe for esports on very low settings, but even then the 4070ti combo was ahead sometimes.",
      "I feel like most of them only want to do games with benchmarks. \n\nBut I want to see tests for MMOs, old games, and emulation.",
      "this was kinda surprising when i saw it but i wish they flat out did potato gfx just for the suggestion of cpu/gpu intensive be more evident",
      "Because properly testing an MMO in a CPU limited scenario is a lot of work, while benchmarking a single player game is just about finding a demanding spot and running through that area in a repeatable pattern.\n\nI benchmarked two CPUs in one of the big group map events in Guild Wars 2 to satisfy my own curiosity. Because of the high variance in player count between each event attempt (50-75 people) I had to do many benchmark runs and the event only runs every 2 hours. Just to get the baseline 6 runs each for two CPUs at one settings preset took 12 hours of logged-in time and potentially another 12 hours of wait time if you're trying to do multiple runs back to back.\n\nFor comparison it took less than an hour to run 27 benchmark runs of Cyberpunk 2077 when I was testing upscaling presets. It's no surprise reviewers fall back on mostly single player games for their testing when they're trying to put out regular content. Even if it's mostly uninteresting results.",
      "I'm benchmarking a 7500F (daily is 7800X3D)\n\nOn my 4080 there's barely a difference at all in gaming.\n\nDCS is smoother on x3d. warzone is smoother on x3d.\n\nThat's about it. Can't speak to factorio since i dont play it or care.",
      "Since Sandy Bridge and before, most people should buy more GPU than CPU. Even on new builds if you're on a budget, buy the previous year/gen if that means buying a better GPU.",
      "I agree too .. target audience of the x3d cache is mostly for open world, constantly loading texture, reducing popping etc.",
      "What did you find surprising?",
      "Steve is an editor at this site and Hardware unboxed itself. so himself :)",
      "i think the reason is too much variable to make a like for like scenario? when they benchmark it is not done once per gpu so imagine you have to do it on multiple gpu",
      "5800X doesn't make sense for new systems anyway. Either 5600 or AM5",
      "For the reddit users who prefer video over text, here the corresponding video at Hardware Unboxed: https://www.youtube.com/watch?v=4Ij1CxfKq6g",
      "Even a 5600X would have an easy time feeding a 60hz monitor, CPU is important for pushing past 60 in demanding games. I play at 1440p 144hz and have a 7900XT and 7800X3D, they're pretty perfectly matched for maxing out games at that resolution and refresh rate.",
      "they could run tests with **path of exile** an aprg game [https://www.pathofexile.com/](https://www.pathofexile.com/)  \nThat would show them how the x3d does kill normal cpus\n\nNot an mmo but boy does the game push hardware when you scale density-  \nIt felt so much better with a x3d when playing",
      "This comparison would have been a lot more interesting if it was 5800x + 4070 ti or 7600 and 4070. I see a lot of new builders go with the first combo lately and you‚Äôll lose out of so much performance. I say that as someone who had a 3080 paired with a 5800x and got some really big gains in some cpu heavy game when I upgraded to a 7800x3d. Cyberpunk went from 65 to 100fps in dog town as an example. Similar gains in the last of us, Jedi survivor, spider man and hogwarts legacy.",
      "People game mostly at gpu limits, unless you get into a \"I need 360fps solid on a 240fps screen or I'm not competitive enough\" mindset, then you will play at gpu limits at which point any cpu that is good enough is unsurprisingly, good enough.\n\nif you solely play at low settings and want the highest frame rates you're at cpu limits and a faster cpu will help. 98% of gaming most people do is gpu limited, not cpu limited and in the few cases you are cpu limited, look at fortnite at low res, 283fps average, oh no, so low.\n\nYeah in reality even in the cpu limited situations most of the time the fps is so high the extra fps makes no difference.\n\nkeep in mind that pro gamers who push for lower res and highest fps possible are all sponsored by gpu and cpu manufacturers, there is a reason they act like a 500fps system is crucial and it's not based on reality but on the money in their pocket.",
      ">Wierd that it was exactly the same comparison, who copied who?\n\nIn case this is not a joke but a genuine question: the video and the article have the same author so nobody copied nobody.",
      "Exactly. Any 7000 series cpu with 6 cores is already good enough for any game if you don't need 300fps for competetive. Still I really love the 7800X3D for its insane eeficiency and unmatched gaming performance, although most people really don't need it."
    ]
  },
  {
    "brand": "amd",
    "generation": "7000",
    "tier": "low",
    "matched_keywords": [
      "7600"
    ],
    "title": "Sapphire Radeon RX 7600 PULSE graphics card pictured, features 32 RDNA3 CUs and 8GB VRAM - VideoCardz.com",
    "selftext": "",
    "comments": [
      "Anything above 250$ will backfire with their recent VRAM marketing stance.",
      "Finally going to get a Polaris replacement.",
      "Even that's too much since the 10GB 6700 new goes for $280 currently.",
      "6700 10 GB is a unicorn tho. Most markets don't have it.",
      "It‚Äôs AMD. Ofcourse it‚Äôs gonna backfire with their marketing stance. Where‚Äôve you been",
      "...which is a lower MSRP than 6600. New GPU, lower price that's bound to get lower as time goes on, supposedly 6700 XT tier performance and people still ain't happy lmao",
      "For a entry level product? Yes \nFor a midrange to high end one? No",
      "Yes.  The 7600 XT probably won't exist since they'd need to do an N32 cut down for it, and obviously the 7600 XT isn't going to have 50% more CU's than the 7600. So a 7600 XT would require exceptionally poor Navi 32 yields from TSMC, which AMD won't be getting.",
      "competitive games no problem but don't expect huge FPS on any modern AAA game",
      "Is this going to be the fastest monolithic GPU they are going to release (apart from some possible refresh with faster VRAM, etc.)? Anything higher is going to be multi-chip?",
      "6700 10 GB is often hilariously identical in performance to a 6600 XT. The only thing truly going for it is the 10 GB ram.\n\nBut again, if the card is mostly unavailable to buy it most places, it's irelevant.",
      "I'm playing 1440p with a 5600XT 6GB. As long as you accept that you won't be running max settings (and IMO anything above \"High\" starts becoming diminishing returns extremely fast) it will work perfectly fine and still be above console IQ.",
      "Everyone's hopeful for a disruption in price yes. And I think we have reasons to believe and to doubt.\n\nBelieve:\n\n* It's 6nm, so optimised 7nm\n* TSMC 7/6N factory is half empty right now (official TSMC statement)\n* Card will have no factory pressure and prices should be low for production\n* Monolithic design (no chiplet bugs)\n* No strong complexity, or size, or yield (6nm yield is ultra-done, just look at the prices on the Ryzen 5000s)\n* 8Go is too little but at least it's certain to be cheap\n\nDoubt:\n\n* AMD seriously thought that a $900 7900 XT was a great price vs a $1000 XTX\n* They have this extremely stupid tendency to release for a high price and immediately get panned in reviews then lower it silently\n* They don't seem to understand their market at all\n\nSo we'll see. But in technical terms, this card has zero reasons to not be cheap. Small bus, not enough VRAM, small monolithic chip, on an older node. It's basically an RDNA 2 refresh in terms of factory production. It HAS to be sold for cheap.",
      "At under $270 the 8gb card would be quite a bangin deal tbh, assuming AMD doesn't fuck it up again",
      "For real. Nobody complains about the 3050 having 8 GB. But the same on a 3070Ti? Oof.",
      "32 CU? Can it be used for 1440P gaming?\n\nEdit: usage strategy games, not shooters",
      "$250 or DOA.",
      "Given that 3060 on Newegg are in the $350 range, $400 for the 4060 wouldn't surprise me at all. And if performance is at 3070 levels, well those are $480...",
      "No, 7600 has 8 lanes, just like 6600 did. There are benches for the mobile version out there, so we know almost everything about how it will perform. The one thing remaining is how high they will clock it.",
      "Reusing the same cooler design they already have to make it cheaper"
    ]
  },
  {
    "brand": "amd",
    "generation": "7000",
    "tier": "low",
    "matched_keywords": [
      "7600"
    ],
    "title": "AMD launches Radeon RX 7600 XT with Navi 33 GPU and 16GB memory at $329 - VideoCardz.com",
    "selftext": "",
    "comments": [
      "Will be a great card when it drops sub 280 in 3 months",
      "absolutely useless",
      "This is a $259 card and nothing more.",
      "No. This is about as bad as Nvidias 4060ti.",
      "Pricing makes zero sense, for how small of an upgrade this is.\n\nRealistically the RX 7600 needs to go down to $200 and the RX 7600 XT needs to be $230-$250.",
      "2X the performance at 100$ more MSRP almost 7 years later? Not the generational improvement I thought we'd have by this point",
      "Useless release, yep, but the card will find its market once they price it realistically.",
      "the successor to the RX580?",
      "AMD is exactly the same as every other business out there. They are 100% happy to ride the Nvidia pricing wave all the way to the top of the stack. They could have given the XTX an MSRP of $799 but they didn't. \n\nThis card is hilariously overpriced for what it is.",
      "I remember AMD making fun of nvidia for 8gb VRAM cards, claiming 8gb is not enough....... then launching 7600 with 8gb vram. If only this would have been the 7600 at $279...Its like AMD does not want to defeat nvidia.",
      "I could pay even 260!",
      "It's much cheaper where I'm from, around 200 CAD cheaper. It all comes down to pricing.  No one is going to complain if it's priced at 199",
      "You misspelled corporate greed",
      "This thing looks like a massive waste of sand compared to the 6700 XT.",
      "they seem to be having some trouble understanding post-pandemic pricing lol.\n\npoor lil bastards. they had to buy a USED car. a USED! car.\n\ni feel deeply for the nvidia & amd execs. bring back dogecoin",
      "Right, but the 7600xt isn't a big Mac, and the existence of AMD's own GPU's from previous years out performs this for the same money.\n\nIt's simply bad pricing.",
      "You're gonna get ripped off, then. I'd wait for a price drop to $259. Fuck them scalpers. Just wait.",
      "Wasn't the 4060 Ti 16GB $100 over the 8GB version, while this is $50 more?",
      "Nah, greedflation",
      "Lazy and overpriced card with the same engine, can't handle the games that fully use the double Vram.  \n7700 when?"
    ]
  },
  {
    "brand": "amd",
    "generation": "7000",
    "tier": "low",
    "matched_keywords": [
      "7600",
      "7600xt"
    ],
    "title": "I really do hope AMD release 7600XT with 12GB vram @ 299$ msrp (and decrease the price of 7600)",
    "selftext": "Would be a godsend for 1080p gaming in regions like Europe where electricity prices are outrageous and \\~150W gpus are preferred. The 8GB version seems like wasted money since many games already utilize 8GB vram even at 1080p. (for example Last Epoch which I am currently playing). ",
    "comments": [
      "Pretty sure it‚Äôs going to be named the 7700, according to current patterns.",
      "Thats really hopeful. I think they are gonna release a 7700 12gb at like 450 and then a 7800 16gb at 550-650. And thats gonna do it for the first 7000 series cards. \n\n&#x200B;\n\nInstead of waiting just get a 6700xt and be done with it. Its still a great card and the extra RT performance really isnt that usefull on these cards anyways.",
      "Not exactly - type of chipset matters, but it is way to long for that as 128bit bus was a mistake , it would need to be 192 bit to actually matter.    \n\nAdding vram would still make it \"4060 .. with extra ram\" aka all the same problems and limitations that more ram would not exactly solve.     \n\nBased on the 4060 an 7600 sales i guess both AMD and Nvidia got the \"memo\" what people think about 128bit bus cards with limited memory in 2023.",
      "6700XT is 200W and with PL tweak it even runs at 130-150W tops.\n\nThe 6000 series is super efficient.",
      "The 7600 uses 165w\n\nSo you can forget the 7600xt using less than 200w\n\nAnd it won't be cheap. Navi 32 is 200mm2 + 4 more mcds totaling 346 mm2\n\nMaking the gcd alone bigger than a whole 4060ti (188mm2) \n\nThe whole chip larger than 4070 (294mm2) And over 2x of a 4060 (156mm2)",
      "No way, RDNA3 is barely more efficient than RDNA2\n\nBesides\n\n1. Even at outrageous energy prices, unless youre gaming 12h a day its really just a minor bonus, not the main deciding factor\n2. The 6700XT already does what you want, just undervolt it to 150W with 90% of original performance\n3. Or the 4070 also does what you want, with modern features and superb efficiency, albeit at a higher, yet fair price\n4. Utilizing 8GB is not an issue, stuttering/crashing/missing textures without more is. Is that the case?",
      "AMD mostly names products based on expected pricing, which is determined by performance.\n\nFor example, when Zen 3 came out and AMD wanted to raise prices on 6/8 cores, they upgraded the name of both products to 5600X and 5800X since they were each 50 bucks over the 3600X and 3800X.\n\nWhen Zen 4 came out and AMD wanted to make the 8 core cheaper and the 6 core the same price, the 6 core kept the same name while 8 core's name was downgraded (7700X, not 7800X)\n\nWhen they needed to make cut down Navi 31 more expensive than cut down Navi 21, they upgraded the name (7900 XT)\n\nWhen they needed to make the 32CU N33 considerably cheaper than the 32CU N23 (both launch and whatever the normal market MSRP would've been), they downgraded the brand to the 7600.\n\nThe lone recent exception to this rule was the 6500 XT, and they got a lot of flack for that. The price sucked but the market sucked utter ass too. But what especially confused/soured many was the 6500 XT being slower than the 5500 XT, as that's just misleading.\n\nSo yeah, I think they'll drop the XT suffix on both of these.",
      "The RX 7600 8GB IS the 7600XT. They dropped the XT because there was barely any gen-on-gen improvement over the 6600XT.",
      "7700 12gb@ 450 is not a good deal. Might as well get a new 6800xt.",
      "Highly doubtful, 7600 MOBILE XT has 8GB with paltry 128-bit bus.",
      "You're falling into the nvidia marketing ploy that adding 30mb cache or whatever it is makes up for terrible bandwidth.....it doesn't.\n\nQuite frankly 288gb/s bandwidth is horrendous past 1080p.",
      "You believe that?? Haha well I think you should stop with the rumor mill because there has been nothing about a 7600xt with more vram. Nothing. The article doesnt even show any rumor just some rando clickbaiting people about possible GPUs. He mentions 10-12gb and 16 for a 7600xt? You think this sound like anything credible or usable? \n\nDude you're wasting your own and everybody's time with fictional rumors. Your understand how stupid that is? Rumors that don't exist and we are talking about it? That's some deep level nothing right there.",
      "Just undervolt it until you are satisfied? \n\nHonestly I don't even know what you doing the card you mention won't exist. There's no way evidence or leaks or any information to suggest it. So what are you doing? What do you want?",
      "Currently theres only 1GB and 2GB dies, each connected to a 32bit bus. The 7600 uses 4x2GB dies for 128 bit and 8GB total VRAM. The 4060Ti 16GB uses a clamshell mode (each bus portion is connected to both sides of the PCB, allowing you to use double the capacity, for 2x2GBx(128bit/32bit) = 16GB of VRAM\n\nThe only way of using odd VRAM amounts is changing bus width (e.g. clamshell 96bit with 2x2GBx3=12GB) or odd sized memory chips (which apparently dont exist atm)",
      "To expand on this. Navi 33 (7600) is the full chip already. To make 12gb possible it would have to be reduced from 128bit bus to 96bit.\nSo the extra 4GB ram would hurt bandwidth instead. Not worth it.\nNavi 33 is also monolithic, that's why it's fairly power efficient.  \n\nNavi 32 however uses 4 mcd. The full chip with 4 mcd will most likely be the 7800(xt) with 16GB ram, and the cut down chip with 3 mcd will most likely be the 7700(xt) with 12GB ram. \n\nAnd power consumption will suffer alot compared to 7600, because of the mcd design. \n\nNavi 33 is also 204mm vs Navi 32 that's 200+ three or four 36.6mm mcds\n\nEdit:   \nWatch this to see how bad rdna3 mcd power consumption really is. \nhttps://m.youtube.com/watch?v=HznATcpWldo&pp=ygUbNzkwMCB4dHggcG93ZXIgY29uc3VtcHRpb24g",
      "6400 XT would be an ok name, with the 6300 below it.\n\nThe gap in the naming scheme in the RDNA2 would be odd, but the gap in performance is huge too.",
      "You do realise that amd did the exact same thing rdna -> rdna2 where they reduce bus width and increased cache?\n\nThe 5700 has 256 bit. The 6700 has 160bit\n\nThe 5600xt has 192. The 6600xt has 128 bit",
      "235W is max on basic PL on the 6700XTs.\n\nAdrenaline, lower PL by 15% and you are down to 150W.",
      "235-15% = \\~200W, not 150W",
      "7800 cannot be so expensive as you are getting into area of 4070 and while amd have better cards in terms of pure power ... they need to compete with extra features Nvidia is offering, not mentioning the fact they need to fight for market share.           \n\nFor me 7800 is at most 500$. \n4070 cost like 600$ now and you can get lower with promotions.               \n\nNot mentioning the fact that age of crypto and pandemic is over.       \nMarket got much, much smaller."
    ]
  },
  {
    "brand": "amd",
    "generation": "7000",
    "tier": "low",
    "matched_keywords": [
      "7600"
    ],
    "title": "AMD Radeon RX 7800, RX 7700, and RX 7600 tipped for a June 2023 launch",
    "selftext": "",
    "comments": [
      "Waiting for Nvidia to release so they can price it at the same outrageous prices with little backlash",
      "This makes the most sense honestly considering the cadence thus far.",
      "I'm still waiting for the prices to drop; everything is overpriced now.  \n\nIt's 2023 and prices are still affected by the pandemic from 2020 and mining, which is very bad.",
      "Probably to try and squeeze out a few more 7900‚Äôs before they release the series of cards that most consumers want‚Äîlow end to mid-range. \n\nAMD‚Äôs problem this gen is going to be DLSS 3.0. By the time FSR 3 comes out DLSS 3.0 will have matured and have made its way into games, basically meaning FSR 3.0 is probably going to have the same issue as previous iterations‚Äîadoption rate. Next problem will be RT performance, power consumption, content creation, and probably pricing to compete. \n\nAs seen with the comparison between the 4070Ti and 7900XT, rasterization performance alone isn‚Äôt going to sell a lot of cards, feature sets are going to dictate what card has better value. \n\nI had high hopes for AMD with the 7xxx series, but when I see basically normal generational steps up with their lineup while not pushing the envelop and charging high prices, it really disheartened me. \n\nNvidia, while still expensive, saw some nice gains, especially in the 4070Ti, while also bringing out a much more robust feature set at launch, and nailing the power consumption, unlike AMD that just keeps promising, is why I chose Nvidia this time around. \n\nC‚Äômon AMD, innovate! Quit copying Nvidia while being late to the party. You only get one first impression and they seriously need to up their game in that department.",
      "That's not what price fixing means",
      "Yeah. I feel like there's WAAAAY too much gaslighting on hardware subs on this site over high GPU prices. \n\nI mean, if they sell, you got the free market bootlickers going \"well ackshuilly they're selling so that means the prices are justified\", but if you point out low demand and them cutting back stock to keep prices high, people just find another nonsense argument to push.\n\nIt's like way too many people are trying to contort themselves into pretzels to justify these crap prices.\n\nAnd then they're like \"well ackshully its just out of your budget\", YEAH NO CRAP! The current prices are insane, and the lowest RDNA 2 discounted cards are the only ones that remotely approach what i consider a fair pricing. \n\nSeriously, it wasn't long ago when the top end GPU was like $500. Then suddenly it was $700. And then it was $1000. And then $1200. And then $1600. \n\nIt's insane. \n\nHeck, I remember in the late 2000s you could get like a 9800 GTX for like $250 or something. \n\nI remember my first GPU being a $80 3650 and my first \"REAL\" GPU being a 5850 for like $300 or something.\n\nAnd that was like the fourth strongest single card on the market at the time, only below the 5870, 470, and 480. \n\nI mean I remember when the market had like several tiers of products in the $100-200 price range alone. And anything from $100 on up was fairly \"gaming capable\". \n\nReally, this current market is broken.",
      "and added some new cringe presentation to mock ur competitor but cant deliver performance you promised",
      "Aren't sales at an all time low?\n\nThen there is the \"overpriced for the market\", and \"overpriced compared to previous gens\" distinction.",
      "JUNE?",
      "As a survivor of Fury and Vega...\n\n... don't buy based on promises of future driver improvements. They don't come, are less than you hoped for, and you will never get over the feeling that you're leaving a lot of performance on the table. Those fixes won't actually come without hardware revisions, even when it'd technically be possible to do in software.",
      "Where is the fire extinguisher?",
      "New foundries which were start building in 2020-2021 coming online somewhere in 2024-2025. 2025 was my guess two years ago on when chip shortage would become more like chip abundance again. So still quite a while before chips isn't a limiting factor.",
      "> everything is overpriced now.\n\nCounter-point: They're still selling so it's not over-priced; just out of your budget.",
      "That is not needed, navi31 is on the market for a long time already, and the drivers are ok.",
      "Hello, it looks like you've made a mistake.\n\nIt's supposed to be could've, should've, would've (short for could have, would have, should have), never could of, would of, should of.\n\nOr you misspelled something, I ain't checking everything.\n\nBeep boop -¬†yes,¬†I¬†am¬†a¬†bot, don't botcriminate me.",
      "All overpriced shit, skip this generation.",
      "Clearing RDNA2 supply, which is taking much longer since almost no one is buying any GPUs.",
      "Well said, I would of been fine with the minimal raster up lift with the gen if AMD really hammered down on the other core features like content creation, power consumption, RT performance and competitive pricing. \n\nInstead AMD said sprinkle a little more raster, forget about anything other than raster and let's hike prices.",
      "It'll be interesting, \nIf budget allows, looking forward to a rx7700 later this year. And then probably no upgrades for years....",
      "June!?!??? I was hoping for some time March/April :("
    ]
  },
  {
    "brand": "amd",
    "generation": "7000",
    "tier": "low",
    "matched_keywords": [
      "7600"
    ],
    "title": "AMD \"Strix Halo\" Ryzen AI MAX Spotted in PassMark: Radeon 8050S iGPU outperforms RX 7600 - VideoCardz.com",
    "selftext": "",
    "comments": [
      "To be fair, there are two confounding factors there.\n1. The scores are only 3% apart which is often within margin of error. \n2. APUs usually share a power budget between cpu cores and gpu cores, and the APU with a 8060S has 16 cores while the other faster one has only 12 cores, potentially freeing up alot of power and thermal budget for the gpu parts relative to the higher core model.",
      "These scores should be taken with a grain or salt as the 8050S (32CU) score is even higher than the 8060S (40CU) score.",
      "I was excited for these apus, because they seemed to replace the low end gpus, while also having very good tdp.\n\nHowever they are priced way too high. So what is the point of having an apu. They are pricing these things like they are apple silicon.",
      "Why should it cost the same as something with half the cores, half the memory bandwidth and less than half the CUs?",
      "If they have good tech, why should they charge budget brand prices...",
      "Please... please don't overhype RDNA4.\n\nI'd rather have underhype and overdelivery than overhype and underdelivery.",
      "RDNA4 has little to nothing to do with this topic",
      "Hardware performance in laptops varies greatly due to design choices, TDP, cooling, etc.",
      "Market dominance and lack of any competition also extremely small power profile makes it very desirable for professional users so again why cater to the poor when rich will pay salaries for their products.\n\nTo add to this AMD is doing the same thing Nvidia is doing with their GPUs.",
      "The 890M is on par with the 2050, Strix Halo is twice that. The 890M hasn't arrived in cheap laptops yet (see [here](https://www.notebookcheck.net/Radeon-890M-vs-GeForce-RTX-2050-Mobile_12524_11108.247598.0.html))",
      "Hopefully they make some affordable gaming laptop gpu too. I'm hoping they release mobile versions of a 9060m/9070m for gaming laptops and oems make some affordable models. Seems like laptop rtx 5060/5070/5070ti are also months away from actually being available. I won't hold my breath till I see 3rd party reviews. \n\n Seems like they are costing more and better suited to business slim powerful workstation market. AI users or developers needing big models on local machine are the winners here, for these igpu.",
      "How should this be cheap?\n\nThe thing has 2 latest gen CCDs and a massive 3nm io/GPU die",
      "> However they are priced way too high\n\nWhat pricing?  \nThey aren't even out yet.",
      "Everyone is expecting 4080 raster, 4070 super/Ti ray tracing for 600 USD or less. \n\nIf they give worse performance for more money. Then it is definitely DOA.\n\nIf RDNA 4 is just a holdover gen, they should try to expand market share with Intel-gpu like pricing.\n\nThey are in a much better place than intel, and even Intel knows this.\n\nI'm sorry but if it's a 7900 gre level of performance  the card should be 350 to 400 USD msrp or something. Because the gre is a MSRP of 550 usd",
      "These seem like different boards. The ssd specs are very different. The disk speeds are vastly different and one is using a version 5 drive while other use a version 4",
      "Yes I meant the 890 is priced the same as 4070 laptops. \n\nIt's not a good deal. \n\nI was excited for this apu as I own the ROG Ally and really liked this. But laptops with the 890m are priced more than a Macbook air",
      "Market share. Having everything on a single die is a huge cost savings. They should pass this on to the customer, before Nvidia catches up, which they will. \n\nThe GPU in their current apu (890m) is like an RTX 2050 laptop.\n\nWhy is this in laptops that are priced like 4070 gaming laptops?\n\nThe pricing does not make sense at all. \n\nAMD has a chance to take market share and they are blowing it.\n\nNvidia will have similar apus within a year. \n\nLaptops with this chip should start at no more than 500 to 600$. Like in the same pricing tier as the ROG Ally.",
      "You are getting a thin and light everyday laptop that has 20hr battery life, of course it will cost high.\n\nGood luck carrying your gaming laptop with 4070 around as comfortable as carrying a 1,5kg laptop, and good luck having realistically more than 5hr battery life with every tweak you can ever apply.",
      "There is a 12 core, 40 cu version which personally, is the only one that interests me.",
      "Because they're supposed to be competing against Apple silicon. These aren't replacements for cheap gaming laptops, they're supposed to go against MacBook Pros."
    ]
  },
  {
    "brand": "amd",
    "generation": "7000",
    "tier": "low",
    "matched_keywords": [
      "7600"
    ],
    "title": "RX 7600 review roundup demonstrates disappointing performance/price vs RX 6600 despite RDNA 3 GPU performing 27% better",
    "selftext": "",
    "comments": [
      "The RDNA2 is clearance stock, great while it lasts but will dry up\n\nClassic Radeon, it's a poor buy at $270, but will be fantastic at $200-250 in 6 months when it's been forgotten about",
      "If the two only positive/best things that can be said about your GPU is that you'll stop producing the other better ones to increase margins, and that it'll come crashing down in price soon enough... Well, you're probably AMD. Then again there's nothing positive to say about Nvidia's except the 4090 is a huge leap... When's intel dropping some new hotties?\n\nAnyone in this price tier should either grab a 6700 10 GB while they still exist, or go used. I got a 6700 xt for 220 with 2 years warranty left a couple days ago. And sales tax here is 15% so even more savings there. Receipt price is 1265 from the scalpocalypse... Oof.",
      "I think it‚Äôs aimed at new buyers on a budget or people who skipped a gen or two who are also on a budget.",
      "This. I know it's a poor gen on gen upgrade, it's quite a boring GPU for guys like us but if you already own a 6600/xt/50xt you don't really need an upgrade. \n\nNew people building PCs in a few months will appreciate the 7600. People still on a RX 580 or GTX 1060 who finally decide to upgrade, it's good for them.",
      "I doubt you will ever find a card to buy, with that expectation.",
      "27% faster than the 6600 is a decent gen-on-gen upgrade, *especially* for this market segment.",
      "it's not (just) about margins, it's about getting rid of old stock",
      "4060ti was dunked on by majority of reviewers. What",
      "It's 100‚Ç¨ more my man, I'm not spending that money.\n\nEDIT: proof, before I get any shit for this. https://amzn.eu/d/fs9LMWP",
      "In the used market he very easily can",
      "Usually new gen offers better value than old gen even if it's on its way out. At least if it's interesting. To get better value on a 2080 ti than a 3070, you had to buy used. 980 ti was also terrible value when 1080 ti was launching same for 780 and 980, etc. Otherwise why launch it? Just keep giving us rdna 2 if it's better value. It's not like there's new tech even on offer. Like how is your launch supposed to be exciting if all it's making me wanna do is buy your older stuff?\n\nAnd what's worse is 6650 xt's have been available around this price for like 6-12 months. So who's this card for? Anyone who wanted this type of performance at this type of price could've had it for the last year and been gaming away. It would've been substantially better value, if you buy it now it's more of a giving in \"ughhhh fine\" than exciting.",
      "The used market has its own drawbacks.\n\nDue to AMD's aggressive new pricing, I don't find used RDNA2 cards to be worth it tbh. The price is slightly lower than new, but you still have to pay sales tax and likely much more for shipping.\n\nFor example, after shipping the *cheapest* BIN 6600 on eBay is 160, when you can get a brand new one with a game and free shipping for 180.\n\nHWS is an option, but imo any legitimately good deal gets purchased so quickly that you pretty much have to F5 to actually get anything. And Facebook Marketplace is complete fucking garbage frankly and a huge PITA in my experience.\n\nYou could buy a gen older used, but that has its own clear disadvantages too.",
      "The more you buy, the more you saveüòé",
      "I honestly think that the 7600 is an impressive step forward for a card that performs quite a bit better than the 6600 and 6600xt. \n\nFor the price you are paying for, along with more modernized core architecture, its a good buy. And as per always, AMD normally makes their cards very competitive as time goes on with better drivers altogwther.",
      "Yeah, tbh I dislike how AMD is getting flack for properly clearancing their products instead of artificially holding last gen pricing up and delaying next-gen until they're 98% gone.\n\nOlder cards have always been the better deal because GPU makers need to get rid of them. As they are more expensive to make than newer ones for the same performance tier and use more power. So they kind of have to be the better deal in the current market or they'll never be able to sell them.\n\nWas the 1070 a bad card because the 980 TI was clearanced under 400? I think Nvidia *not* clearancing Ampere pricing for so long really screwed with people's memory.",
      "Reviewers yes, we'll see what consumers think.",
      "After seeing the 7600's price/performance I just bit the bullet and bought an RX 6600 for 206‚Ç¨  \n\n\nWill keep it for as long as I can, next purchase will probably be with an entirely new build.",
      "under $200 is where this card will shine, 8GB above 200 is just a stupid purchase.",
      "panic mode? brother those 2 are making more money than ever. We need to stop pretending gaming gpus are their main market, we are the side chick of this computer relationship, accept that",
      "It's not unusual for a new generation to increase GPU resources for same tier"
    ]
  },
  {
    "brand": "amd",
    "generation": "7000",
    "tier": "low",
    "matched_keywords": [
      "7600"
    ],
    "title": "AMD Radeon RX 7600 XT reportedly launches on May 25th - VideoCardz.com",
    "selftext": "",
    "comments": [
      "12GB or bust",
      "MLID has lost his credential for me when he claims:\n\n- rdna3 gonna beat nvidia ass\n- intel shutdown dGPU unit soon\n\nNeither were true",
      "This is N33, brace for 8gb/32CU once again.",
      "Have been waiting for like 4 months for a 7800XT/7700XT.\n\nAMD: Best I can do is release the 7600XT.\n\nAt this point I am seriously thinking about buying the 4070 despite wanting to go full AMD.![gif](emote|free_emotes_pack|disapproval)",
      "Ought to be released at $250, considering you can easily find a 6700 for $300 nowadays.\n\nWhile the 7600XT will likely be slightly faster, it'll also have less vRAM.",
      "Somehow i doubt it will cost less than 300 $.",
      "The MLID leaks have this at 11% faster than the 6650 XT at the same power draw. If that‚Äôs the case, this has to be $299 to not be DOA, and is going to be mediocre as hell even *then*.",
      "GDDR chips only go up to 2GB each. Each consuming 32 bits.\n32*4 = 128.\n\nThere's place for four GDDR chips, each with 2gb at best.\n\nEDIT: There are larger GDDR6 chips, but they're not massively manufactured for some reason. Presumably economical viability.",
      "To name a few. The cards are underperforming, judging by AMD's slides. There's a reason they haven't announced the rest of their lineup, something isn't working quite right with RDNA 3. It should have much more performance than it has now. \n\nHeard VR performance isn't very good on the 7000 series, not sure if those have been fixed yet.\n\nThe 7900XT should've launched as the 7800XT for a much lower MSRP, due to its relatively poor performance uplift. It's incredibly overpriced, judging by how many times the price has been cut on it.\n\nThe 7900XT also caused a weird situation where they can't really launch their actual 7800XT and not make it look terrible in performance or price compared to their discounted RDNA 2 cards. Basically the performance of the 7900XT is on par with what the 7800XT should've been.",
      "I remember him saying AMD will get a minimum of 2x 6900XT performance, upto 2.2x and Nvidia was in alot of trouble. \n\nSomething went wrong with Navi31, hopefully a refresh will fix it otherwise the GPU market is looking dead for another 2 years until next gen.",
      "Meh. I want N32. Where is that?",
      "So what does it bring to the table that isn't on RDNA2? AV1 that 99% of people will never use?\n\nThey screwed up. Period. It's put them in a tight bind on placing the rest of the RDNA3 SKUs because they are competing directly with their OWN products and there are no features/ incentives to get it over a similarly priced and likely better performing RDNA2 card.\n\nBy the time this actually hits the shelves, prices will likely have dropped even more on current GPUs.",
      ">\"Dude comes out saying that the 7600 is just 10% faster than the 6650XT at the same power. \"OMG GUYS WHY ARE YOU LICKING UP HIS HOPIUM\"\n\nHe literally said N33 will have 6900XT performance in the past lmao.\n\nHe's a snake oil salesman. He has enough knowledge of hardware that he can throw out some belieavable shit and spin them as leaks. He works on the moto of \"if i throw enough shit at the wall something will stick\" and \"even a broken clock is right twice a day\".\n\nAnd when he is wrong he just backtracks or tries to delete all evidence of being wrong.",
      "7600 XT coming out soon with no N32 cards on the horizon, it does make me wonder if AMD might not just skip the N32 DIE for desktop completely and move on from RDNA3 as soon as they can.\n\nIf we are being realistic, RDNA3 doesn't really bring anything new to the table that would warrant paying more for it if you don't need AV1. So anyone looking for value, will buy a discounted RDNA2 card, for everyone else who wants RT and FrameGen, they will grab something from Nvidia at a premium price.\n\nThen we see a number of reports that 4070s are not selling very well, with cards dropping below MSRP in some regions, with Microcenter in the US even offering $100 Steam Gift Cards On All NVIDIA GeForce RTX 40 Purchases.\n\nAMD might decide it's not worth it, push out the 6 class cards asap and call it a day while continuing to sell the discounted RDNA2 stock. Even this 7600XT is going to be a hard sell against discounted RDNA2 cards, $299 MSRP might make it worth a look but it's not exciting in the least.",
      "Honestly as an AMD fanboy, I thought the 4070 looked decent. Basically low power consumption 3080 with all the lovelace features for $600. It's just there are many alternatives at that price point (even the PS5); you might find the 6950xt for $600 which is an alternative. There is no real advantage in RDNA3 over RDNA2 besides performance, so you're not gonna miss out much imo.",
      "Seems to me AMD is eager to move on from RDNA3 and they're just trying to get out what they can for some sales in the mean time. So many issues with this generation.",
      "It won't be, but it ought to be less than that given you only get 2/3rds the VRAM of a 6700xt as well.\n\nBetween that and the fact that that performance for $300 is old news, this thing should be like $229.",
      "Give it a few months and it probably is at $350",
      "I disagree. The 4070 is only a decent option because if the price being somewhat close to reasonable. (Especially with the Microcenter $100 steam card promo). When you bump it up to $800, 12GB of vram is absolutely unacceptable. That‚Äôs the type of card you would be trying to use ray tracing with, which will just make the vram issue even worse. \n\nI would step up to a 4080 before I would consider a 4070ti. At least then I can do the extra things I can‚Äôt do on a 4070 for more than a year.",
      "they literally hired new people to run it and scaled down their designs to a conventional gpu to make enterprise customers happy, meaning they have customers for once in their lives.\n\napparently they have to walk to your door and beat you senseless with a gpu shroud before you stop coping."
    ]
  },
  {
    "brand": "amd",
    "generation": "7000",
    "tier": "low",
    "matched_keywords": [
      "7600"
    ],
    "title": "Custom Radeon RX 7600 graphics cards listed in Canada at 444 CAD - VideoCardz.com",
    "selftext": "",
    "comments": [
      "Instant DOA",
      "Relax, AMD will probably just secure some (bad) day 1 reviews and than quickly and quietly lower the price...",
      "Which, as history tells us won't help them as most ppl watch day 1 reviews a year later as well. Good day 1 first impression is crucial.",
      "So around 350 US$ ?\nDOA . if 4060ti stil 399 US$ , it s already cremated",
      "extreme beach volleyball",
      "Yes and first impressions aside a quickly dropping price is also not a good look... I wonder why Radeon is always viewed as the cheap option ![gif](emote|free_emotes_pack|facepalm)\n\nThe 7900XT secured bad day 1 reviews, teached early adopters a lesson (immediate price drops just scream \"premium product\") and quickly made consumers forget how competitive AMD was with RX6000 (RDNA2). Why? The 6900XT went toe to toe with the 3090... And now any chart will display the 7900XT next to 4070Ti and the 4090 far away. Sooooooo 6900XT \\~ 3070Ti? (I actually had to explain/show how a 6800XT (going for 3070 non Ti prices) is much faster.",
      "Marketing team driving the company off the cliff",
      "4060Ti for $400 will be a no brainer for most people compared to this for $50 cheaper. AMD doesn't seem to realize they're falling behind so much on features that they need drastically lower prices than Nvidia to have a chance to sell.",
      "That‚Äôs around $50-100 too much bruv",
      "Doa",
      "Priced perfectly to sell through last gen's left over stock",
      "Nvidia has given AMD all the room they need to massively undercut them at similar performance level and secure good press and some market share but instead they opted to follow them in their price hiking journey and Lost market share despite technically bringing in more revenue.\n\n\n\n\nAre these companies communicating to not destroy each other? Like all AMD needs is one massive blow at the mid range, and it doesn't seem like they have problem selling for low margin as they've been doing that for half a decade with Polaris and they were doing much worse financially. Nvidia doubled it's price for the 80 class GPU and AMD decided to add $250 to theirs, imagine if the 7900XT remained at ~$700. \n\n\n\n\n\n\nAMD release extremely average GPUs in a market where they're considered a universally worse option and then lower the price when it's not selling well but no one cares at that point, they need something big, 10% lower price for 7% lower performance isn't going to cut it.",
      "Oh AMD please don‚Äôt be so greedy.",
      "I had a slight hope it would be priced at $249-$279. Anything more than $300 is yikes. I'll then just settle for the 6700 10GB. Well, if Newegg still carries it by end of the month, of course.",
      "\\**Clown noises intensify**",
      "Likely less performance and 2GB of vram less than the 6700 meanwhile costing 20% more. Pitiful. This needs to come in at $250 Max.",
      "It is rumoured as such but there is no way Nvidia will price the higher VRAM model at 400",
      "An 8GB card for $400 is not a no brainer!",
      "User base: Repeat after me. \"Release a similar performance card at 10% lower price\"\n\nAMD: Release a similar performance card at 10% lower price\n\nUser base: Got it?\n\nAMD: Got it.\n\nUser base: say it again?\n\nAMD: RELEASE LOWER PERFORMANCE CARD AT SAME PRICE AS COMPETITOR\n\nUser base: OH GOD",
      "Doesn't matter if they released the RX 7800 XT or RX 7600 next, AMD already screwed up their pricing for these cards since day one.\n\n*1080p Ultra Settings starting at 444CAD*"
    ]
  },
  {
    "brand": "amd",
    "generation": "7000",
    "tier": "low",
    "matched_keywords": [
      "7600"
    ],
    "title": "My new 7900 XTX vs my last gpu RX 7600",
    "selftext": "Just got my new gpu in and it‚Äôs a hell of an upgrade from my old one. Both runs were on max settings with everything on high. I am quite satisfied ",
    "comments": [
      "Nice. Congrats! I thought my uplift from a 3070ti to a 7900xt was big ü§£",
      "You mean the cat‚Äôs 7900xtx?",
      "Cat",
      "I got this bad boy in my cart right now. The GPU not the kitty",
      "I like the acr",
      "Cat",
      "Cart",
      "Cat.",
      "I see cat, I up vote.",
      "5E or 6?",
      "I have this same cat. Standard issue tiger cat with mittens. She‚Äôs pawesome, good specs. Even came with a go fetch feature, she a real bitch tho.",
      "Mine did yes. It was a struggle installing it but now it makes a loud engine noise when I run my hand down it so I think it was worth purchase",
      "Cat",
      "üòÇ",
      "Car",
      "I hate you üòÇ Congrats they're all sold out in Australia.",
      "Yeah i went from a 10600k and 2080ti to a 7800x3d and 7900xtx and it absolutely crushes everything in 1440p lol. Not even close to my old system. Love it",
      "I did the exact same. From 7600 to 7900 XTX. Brought me from around 60-80 FPS to 240 FPS :D\n\nWhich CPU do you have?\n\n\n\nHave fun with it :D",
      "Never thought a cat could run realtime graphics this fast",
      "Congrats on your new graphics cat!"
    ]
  },
  {
    "brand": "amd",
    "generation": "7000",
    "tier": "low",
    "matched_keywords": [
      "7600"
    ],
    "title": "AMD Radeon RX 7600 XT to feature 10GB and 12GB memory configs, according to PowerColor EEC filing - VideoCardz.com",
    "selftext": "",
    "comments": [
      "N33 is monolithic, if I recall correctly. This implies that it already has the 192 bit memory controller?\n\nA 12GB 7600XT could be the new 1060GTX - the affordable \"good enough\" card that lasts a whole bunch of gamers a long time.",
      "A 12gb 7600xt @ $300 is where we should be these days. And it would absolutely dominate the market.\n\nSo naturally, AMD will price it @ $400 and continue to lose market share and faith from their consumers.",
      "Now we know why the AMD 7700XT was priced at $450, they probably want to price the RX 7600XT 12GB at $400 and the 10GB model at $350.",
      "If this is a step above the 7600 and has 160/192-bit bus options, it's probably cut down Navi 32 that couldn't be used for the 7700 XT.",
      "$50 for 2 gbs is the worst idea I've heard in a while. Even the stupidly overpriced 4060ti did that better only $100 for 8gbs wowers",
      "If it is a cut down N32, then it will need external memory controllers, each of which is on a 64 bit bus.  For a 10GB configuration, you'd need 5 of them.  A 320 bit memory bandwidth for a \"7600\" would be a... most interesting decision from AMD.\n\nAlso yeah nah not happening.",
      "Almost like both big companies just want money and neither of them are \"looking out for the people\".",
      "It's not \"upsetting people with reality\" it's misrepresenting the argument. Seemingly deliberately, as this shouldn't really have to be explained every time.\n\nAMD is undercutting Nvidia in price to performance but it's not by a wide enough margin to get most people to switch. Nvidia is still dominating market share by almost 9:1.\n\nPricing to market maintains the status quo. If they want to gain market share they need to be as aggressive as possible.\n\nObviously they still need to profit. Nobody anywhere has ever suggested they sell cards at a loss.",
      "They said no more ASIC (chip), not no more SKUs.",
      "Makes the 7800xt look good.",
      "Just like the 7700xt is a stupid card at 450$?\n\nMake one product trash to make the other look good",
      "Exactly. Nvidia still has its CUDA advantages that lock a lot of people in from the jump. On top of that, AMD's now jacking up pricing in a manner similar to Nvidia, but using features that aren't good enough to justify it. They haven't delivered on FSR 3. Their RT performance is inferior. They're losing on efficiency.\n\nWhen AMD's pricing is better value than Nvidia, but worse than last-gen products from AMD currently on store shelves, what's the selling point? When AMD starts using \"the new features are great\" to promote their products that are worse than Nvidia at those things, in the hopes they'll justify their pricing model that sucks, they just make themselves look bad.\n\nFrom one side of their mouths, AMD and their supporters are talking up \"as good at Nvidia at raster,\" while using the other sides of their mouths to tell us RX 7000 is worthwhile over RX 6000 because of new features. They lose at both ends.",
      "Ugh?? \n\nNavi33 as a die has a 128bit memory controller and thus only supports 8GB or 16GB configs where 16GB requires the use of clamshell memory. (16Gbit GDDR6 modules)\n\nAnd 24Gbit (though part of the standard) don't actually exist. \n\n10GB and 12GB cards if they do exist will 100% be using Navi32 die with cut down compute units, but calling it a 7600XT would be very silly as Navi33 and Navi32 are very different.   \nOne is monolithic 6nm, one is chiplet 5nm+6nm with 1.5x VGPR.",
      "Yuuuuup. But I buy Nvidia so that makes me a rube, not someone who wants the features they offer and can afford the cost, and you buy AMD because you're a renegade, sticking it to the man, robbing the rich to give to the....rich.\n\nIt's all bullshit. People buy what they want. This whole Red VS Green shit is no better than console war garbage.",
      "They were saying the 6800 beats the 7700 XT",
      "If they can get it to market for $300-350.",
      "Exactly, I believe the 7700XT is deliberately priced to clear out older stock 6800(XT) cards, and AMD will try to do the same with the 7600XT models; if you price the 7600XT 10GB & 12GB card at $350-$400, it'll make the 67(5)0XT 12GB cards all the more attractive for buyers to clear them out.  After they run out of RDNA2 stock, then AMD can drop the prices on those cards, and trap Nvidia with nothing viable in the $200-$400 range and a ton of RTX 3000 cards rotting on the shelves, it'll be a brilliant move, if true.",
      "\"It's not a fucking charity,\" is a terrible counterpoint. No one's asking them to lose money on cards or give them away for free. AMD's also sitting at a marketshare that's lower than necessary because they keep pushing people to Nvidia with a mix of rising prices, delayed/buggy features, lesser performance, and slow releases.\n\nThis isn't AMD matching/overtaking Intel with Ryzen. They're still floundering from miles behind Nvidia without a path to significant marketshare with products that could earn it. People aren't running around saying \"I want a free card,\" they're saying they'd buy AMD's stuff if AMD were reasonable.\n\nWith as bad as the RX 7000 release has been (7900 XT was too expensive, 7800 XT took too long, both apply to the 7700 XT), I've been sitting on my 5700 XT for basically 2 years longer than I intended. Between friends and relatives, there are probably 10 different PCs that I'd normally have upgraded or helped people upgrade, but I just haven't because the products aren't good enough, and I'm confident that I'm not alone.\n\nIf they released the 7800 XT 6+ months ago, I'd have bought one. Now, I'm fine to wait until Black Friday to evaluate the 7900 family's pricing because buying a 7800 XT that performans like a 6800 XT for the price of a 6800 XT isn't appealing.\n\nPlenty of us here arguging against AMD's pricing are interested consumers. AMD's losing business from it, and it's not like they're gaining on Nvidia in spite of us.",
      "A cut-down version of Navi 32 with 10GB would imply a memory bus of 160bit, which I see a bit strange as every MCD sports a 64bit memory bus.\n\nA 12GB card would use 3 MCDs, being the 4th disabled (probably was already defective), but a 10GB would use 2MCDs and half of the 3rd one. For me, it sounds very strange.\n\nI would not be surprised if they are rebrands of the 6700 10GB and 6700XT 12GB. They also fill the performance gap.",
      "This must be on N32, since N33 cann't suport 10GB at all (unless we have a GTX970 situation) and would only support 12GB with either 24Gbit modules or the cursed clamshell option of 16Gbit+8Gbit.\n\nSlotting these in at 40 and 48CU for the 10 and 12GB respectively would fill out the mainstream lineup, but they shouldn't both be the 7600XT. We got mad at Nvidia over the 4080s, and I don't think we should accept it from anybody else either. 48CU/12GB needs to either be a 7650XT or the RX7700 for the naming scheme to hold up imo."
    ]
  },
  {
    "brand": "amd",
    "generation": "7000",
    "tier": "low",
    "matched_keywords": [
      "7600"
    ],
    "title": "AMD Radeon RX 7600 XT rumored launch on January 24, only custom variants planned - VideoCardz.com",
    "selftext": "",
    "comments": [
      "I expect some stupid price in the EU like 350‚Ç¨",
      "That's a normal price for this card though, I don't understand. EU prices include VAT. 350 euro product before tax is about 291 euro or 323 dollars\n\n12GB 6700 XT currently sells for 350 euro. This new card, if it also has 12GB, will most likely perform the same or better",
      "Because 6700XT is already deeply discounted.\n\n7600XT would start at the discounted price of 6700 XT and get discounted lower later.\n\nNew cards do bring more perf/$ if you go by their MSRP.\n\nIf you currently want a low-cost option, there's older gen",
      "I can't say what a 7600 XT is, but whatever is speculated doesn't make sense.\n\nNavi 32 makes more sense as a 7700.\n\n10GB doesn't make much sense, as it implies a half active MCD.\n\nA higher clock 7600 would make more sense as a 7650.\n\nNot that any of the above are impossible, and if a 7600 XT is released it will certainly be either Navi 32 or 33, but still, that'd just be another strange name from AMD's increasingly delirious marketing department.",
      "What's the point in new cards if the price scales with performance?",
      ">For RX 6700 XT, AMD may opt for the Navi 32 with a reduced core count.\n\nOr it could just be Navi 33 with faster clocks or memory.\n\nIf it's a cut down Navi 32, there's a big space between the RX 7600 and the 7700XT. Halfway it would be around 6700 XT up to 4060 Ti levels of performance. That would be alright around $300, but it's going to be $349 plus, right?",
      "As I said, or an Nvidia product which is what a lot choose to do as clearly shown by the market data.\n\nNice try, removing that part of the argument though.",
      "The 7600 is on 6nm, which tolerates 1.2V pretty much indefinitely, but the 7600 per TPU only averaged ~1V, faster 2GB G6 exists, clamshell is doable for 16GB total, and TPU got a 10% OC even with artificially limited headroom, so I bet a 7600XT is about 15% faster at stock.",
      "It can not be much faster than the 6700xt, otherwise the 7700xt wont be meanigfully faster than 7600xt.\n\n22% perf. separate 6700xt from 7700xt.\nThis 7600xt Will be another 6700xt with better ray tracing, av1‚Ä¶\nNot worth it for me.",
      "The old product is discounted through its time on the market. That way, it doesn't suddenly become dead weight once the new product drops. Both new and old products can be competitive at the same time, it's all about the price.\n\nI'm saying that both 6000 series and 7000 series are a good choice right now compared to competition. If 6700 XT was out of stock right now would you be happier? I feel like your issue is that there's a discounted old cards still lying around.",
      "> Or it could just be Navi 33 with faster clocks or memory.\n\nFaster memory yes - they could probably go with 20 GHz GDDR6 - but higher core clock is a maybe. 7600 already has the highest core clock of any RDNA3 card. There is a chance that they can go a little higher, as 6500XT (on the same 6nm process) runs 160 MHz faster (boost). That‚Äôs 6% faster than 7600 - a fairly small gap - and the card will probably draw 200W if you do that. Doesn‚Äôt seem worth it to me?",
      "6700XT is currently 300 dollars, so you don't even need a 7000 series card to do what you're describing",
      "I would love to see the market share of that, but APUs are still pretty far behind the last generation low end cards.",
      "Heck, even the 7700 XT barely makes sense.  \nIt's a 200mm¬≤ GCD on a node with extremely good yields. They probably could have only made the 7800 XT and the few chips that need to be cut down could have been a China or laptop exclusive.\n\nI don't see how an even more cut down N32 GPU would make any sense. If they launch a 7600 XT, I find it more likely it'd be an overclocked RX 7600 with 16GB of faster VRAM instead.\n\nDrop the 7600 to like $239 and launch the 7600 XT with 10-15% better performance and 16GB VRAM for $299. Something like that.",
      ">it would be an embarrassing release at this point in time.\n\nWhy? Should 7600 not exist? Why would something slightly better be an embarrassment if the price is right???",
      "Still its better to get newer card. If 7600XT will be around 6700XT performance and similar price, i will take the newer card.",
      "AMD has a few selling points over Nvidia, one of them being VRAM. Releasing an 8GB card at a price range above the 7600 in this day and age would be a mistake, given the 7600 itself has borderline the minimum VRAM you could ask for. Whatever comes above the 7600 needs to feature 12+ GB of memory to be a selling point against Nvidia's competing products.\n\n\nAs for the 7600 (non-XT), it was released 7 months ago. Things were slightly different back then, though it still was viewed as a bad product, given it offered very little offer the existing 6600/6600XT/6650XT.",
      "XT version shouldn't be more powerful and have more RAM? \n\n6700 XT, 5500 XT don't count I guess.",
      "That's a good way to not sell the new card at that point. I know the older cards are going for less but it would end up just like the 7900XT and people buying the 6950XT over it (or an Nvidia product).\n\nSame for the 7700XT and the 6800.",
      "This is the worst way I've seen someone describe a card, thank you"
    ]
  },
  {
    "brand": "amd",
    "generation": "7000",
    "tier": "low",
    "matched_keywords": [
      "7600"
    ],
    "title": "First PC Build. All AMD (R5 7600 + RX 7800XT)",
    "selftext": "",
    "comments": [
      "Ha, the same CPU and AIO cooler I¬¥ve got. You will surely be satisfied!\n\nNice and clean build, I like it.",
      "If you can use 2 separate psu cables in the graphics card and not the split one it can cause stability issues on the gpu",
      "7800XT gang üëå Great choice hope you‚Äôll love it as much as I do!",
      "Thank you! Yeah the cooler is awesome. Could‚Äôve maybe got a better value with air cooling but I love the way AIO‚Äôs look",
      "Probably the best no bullshit AIO. I have the 360 variant and it is flawless.\n\nTubing is a little long but better than the opposite, my only complaint.",
      "Potentially. Each cable is rated at 150W, but has a theoretical limit at 288W depending on the thickness. The PCIe slot also provides 75W. 7800xt can have power spikes at around 300W, which is within the theoretical limit so it should be safe, but using 2 cables would be the safer option",
      "Don't buy the Gigabyte card! It is pretty loud and I had to return mine **three times** because all of them had issues. The first card would immediately reach temps of 110C because only one fan was working, the second one had insanely loud fan bearings even at the lowest speed and the third one also had pretty noisy bearings and kept crashing.\n\nI ended up spending 30‚Ç¨ extra for the Sapphire Nitro+ model and it is absolutely whisper quiet with a tuned fan curve and UV+OC.\n\nSo if you care about noise definitely do not buy the Gigabyte card!",
      "Arctic Liquid Freezer II 240",
      "I have this card too sorry do you mean it would be more stable if I used 2 separates instead of the one split cable?",
      "I‚Äôve been using it for a few couple months now (just finally showing it off here) and haven‚Äôt run into any issues yet. I‚Äôll keep that in mind if I run into problems",
      "What cooler is it?",
      "Sapphire owner here. I can barely hear the card even at full load",
      "Nice",
      "I like your cpu cooler. Which one is that?",
      "I'm ording that same card tomorrow",
      "The look, particularly the all-black features, is well-executed. \n\nWelcome to 1440p gaming.",
      "I have the same combo, great combo",
      "Please get some support under that GPU!",
      "Specs?",
      "It‚Äôs very balanced with a 7800XT. I‚Äôd probably move up to a R7 7800X3D if I went up to the RX 7900 XT/XTX\n\nEDIT: If you already have a 7600 you‚Äôll notice the jump over a 7800xt for sure from a 7900xtx, but I miiiight start to look at a bottleneck possibility. Just depends on what you‚Äôre playing/doing on the pc"
    ]
  },
  {
    "brand": "amd",
    "generation": "7000",
    "tier": "low",
    "matched_keywords": [
      "7600"
    ],
    "title": "AMD Radeon RX 7600 XT GPU Benchmarks & Review: Power Efficiency & Gaming",
    "selftext": "",
    "comments": [
      "Leave it to AMD to keep shooting their foot.",
      "The 7600 XT needs to be priced at $300. At $330, you're paying 22% more than for the 7600 non-XT which is priced at $270. But the performance uplift between the XT and non-XT is just under 10% (depends on which reviewer you're citing, but on average I've checked, and it's about a 10% uplift in some games). So pay 22% more for only a 10% uplift? Hmm, if it were priced at $300, then you basically break even.",
      "I also do not like how this tier of card is consuming more than 200W of power. Amd needs to seriously work on efficiency. These cards shouldn't consume more than 120W",
      "This would make sense if they price it at 300$, slightly better raster performance than the 4060 and double the amount of vram, they could also lower the base RX 7600 to 250$ which would make a great entry-level card",
      "The fear mongering is clearly working.",
      "This is a 7600 not a 7600 xt no matter what amd says, extra vram doesn't make a new GPU.",
      "It needs to be $250. \n\nThe 6700xt has been $300-330 for over a year now and beats this by around 10% lol. You can pick a used 6700xt up for $250. If you can't beat your last gen product, don't release a product.",
      "$300 is still too much for this level of performance. AMD cant just undercut Nvidia and hope that people will ignore them being behind in upscaling, RT, AI, encoding, etc. AMD needs to price products to sell, not to be slightly cheaper than Nvidia.",
      "Same power as a 4070 - yikes.",
      "Unserious GPU manufacturer.\n\nCan't even beat their still available brand new last gen product. Or compete with it. At all.\n\nLike come on now if you have a $300ish 6700xt and release a $300ish 7600xt uhhh buddy you ain't supposed to beat yourself.",
      "$0 at that level of performance.\n\n16GB on a card like this is a gross overreach.\n\nWhen someone looked at this they should have went.\" Well the configuration only allows 8GB or 16GB so what should we do?\"\n\nThe answer should have been not to bother with a separate product.",
      "The 6500XT was gimped in every possible way, 8GB would change almost nothing for the card.",
      "Price pundits here on r/Amd are wild.\n\n\n\"330 TOO EXPENSIVE SHOULD BE 300 MAX\"\n\n\n\"300 TOO EXPENSIVE SHOULD BE 250 MAX\"\n\n\n\"250 TOO EXPENSIVE THEY SHOULD PAY YOU TO BUY IT\"\n\n\n\"PAYING YOU TOO EXPENSIVE THEY SHOULD PUT 50% DOWN ON YOUR NEW CARD IN FIVE YEARS TOO\"",
      "You do realise that this was how the gpu market used to be before all the shortages? Price the 6700xt cheap, get rid of all that stock and then focus on the new stuff. I mean, amd literally has to do nothing for this gpu launch outside of sending an email to oems asking them to make clamshell designs for the memory and then just marketing it. They haven't even made a reference card.",
      "YOU SHOULDN'T BE USING THESE CARDS AT 1440P, IT'S NOT GOOD ENOUGH. \n\nThe card - literally as strong as a 2080 super.",
      "At 1080p, not as much as you'd think\n\nAt 1080p with fsr-qual so you're basically at 720p, none.\n\nat 1440p, slightly\n\nat 4K, extremely (but luckily it's not a 4K card, but like you'd be lucky to get 4K60 out of ps4 era titles)",
      "If not that, they are criticizing 4090 owners for spending that much on a gpu, like it was their money or their life to decide what should i do with my money, i lost count of how many times i got atacked by this kind of sick people.",
      "Serious question:  How much is the 7600XT and really the 7600 non-XT hampered/hamstrung by the lower 128bit bus?",
      "Yeah, given it's performance that would be roughly fair. \n\nKeep in mind the regular 7600 is basically a 6650xt which is basically a 5700xt/1080ti. We are talking about the 5700xt, a 2019 release and the 1080ti, a 2017 release, being similar in rasterization to a Rx 7600 non xt. RT on ANY of these cards is kinda irrelevant, it sucks enough you won't use it.\n\nIf you remember, back in 2018 the outgoing Gtx 1080ti cards were getting fire saled for $450. If you bought a 1080ti at that time and kept it because \"the Rtx 2000 series is overpriced\" you'd have survived the mining craze, made thousands of dollars during the mining craze with that card, and still in 2023 have a card that competes with brand new cards costing $250+. Like, that's how BAD this value proposition is.\n\nEven if you bought a 5700xt at $450 at launch in 2019... well you'd have a Rx 6700xt right now because miners were trading new 6700xt cards for used 5700xt cards because the 5700xt was one of the best mining GPUs per watt.",
      "I don't get why amd even bothers releasing these cards so late. A day and a dollar short every time. \n\nBe within the week, or don't bother, really. Unless your product is better, then release a month later."
    ]
  },
  {
    "brand": "amd",
    "generation": "7000",
    "tier": "low",
    "matched_keywords": [
      "7600"
    ],
    "title": "Gigabyte launches Radeon RX 7600 XT 16GB graphics card - VideoCardz.com",
    "selftext": "",
    "comments": [
      "It has 2 times the X‚Äôs as the RX 7600, clearly it‚Äôs 2 times as fast",
      "Price it at 250 and it's a winner.",
      "Why would anyone buy this???",
      "16 gigs of VRAM being accessible at a low price of $330 is good imo. 16 gigs of VRAM can benefit some workloads a lot\n\n4060ti's MSRP is $500 IIRC, which is still high",
      "Most people don't want to buy used.\n\nUsed is ALWAYS better value at every price point so that's never really an argument when discussing the value of a newly released product.",
      "And then it goes below 300$ and reaches goat status for budget cards like the 6600 did",
      "To have more VRAM without spending more money. ML or video editing at home would be a good use since VRAM is important there.",
      "People who do ML and content creation typically wouldnt buy an AMD GPU anyways, as they perform worse than Nvidia and even Intel in those segments.",
      "This might be even worse than the 4060Ti 16GB and that's really saying something",
      "Not necessarily. They use AMD in supercomputers some run ML tasks. Those systems use CDNA rather than RDNA though so it's a bit different.",
      "What do you mean won't have the performance to utilize 16GB? Do you know what you're talking about?",
      "Okay and how much more is the next 16 GB VRAM card? The 6800XT must cost a lot more than this card.",
      "Amd trying to pull an rtx 4060 Ti with lesser gpu and considering how that worked out imma pass. This is just waste of sand.",
      "My guy you don't know shit. I have run actual models on AMD and Nvidia cards. There are literally supercomputers built with AMD Instinct accelerators. You have just fallen for Nvidia propaganda.",
      "The 3060ti on sale is more expensive than the 7600xt at MSRP. And it only has 8gb of vram, which will render the card useless when games will start requiring more. Of course, if you think you will replace your card before then and don't otherwise have a use for the extra vram, you can get the 7600, which is about $100 cheaper than the 3060ti on sale.",
      "Games are using 8GB at 1080P even without RT.\n\nWith RT you can go up to 12GB usage at 1080P. Enabling something like FSR3 frame gen is another +1GB usage. And that is *today.*\n\nThese numbers will only go up over the years. Texture quality is most of the VRAM usage and is NOT impacted by GPU performance so you can crank textures to Ultra even a few years from now with no performance issues, purely because it comes with 16GB VRAM instead of 8GB.\n\nIn no universe is a higher power budget a bad thing. Having the option to overclock more is always good.\n\nWhat GPU do you have, that you consider this card \"disappointing\"? Have you considered that you are not the target audience? Too often I see people commenting about how lackluster a GPU is when they would never buy that performance/price class anyway.\n\nIt's a much better deal than the 4060Ti 16GB. It's even cheaper than the 4060Ti 8GB.",
      "Ahh, I see they are students of Intel‚Äôs ‚Äúbigger number make better‚Äù school of thought",
      "That's cap.   \nEven a [GTX 1060 can run FH4 with ultra](https://www.techspot.com/review/1716-forza-horizon-4-gpu-benchmarks/). [Not even FH5 uses more than 8GB](https://www.kitguru.net/components/graphic-cards/dominic-moass/forza-horizon-5-pc-performance-benchmark-30-gpus-tested/) on the extreme preset at 1080p. The FH games are extremely well optimized and run well on any potato PC.",
      "Idk where you live but there is not a single 6800 in stock here, hasn't been for months.",
      "me with a 5700xt üëÄ"
    ]
  },
  {
    "brand": "amd",
    "generation": "7000",
    "tier": "low",
    "matched_keywords": [
      "7600"
    ],
    "title": "Time To Buy Zen 4? - AMD Ryzen 5 7600, Ryzen 7 7700 & Ryzen 9 7900 Review & Benchmarks",
    "selftext": "",
    "comments": [
      "I wonder what motherboard they use for zen4 that cost $160 and added to those Cost per frame graph.",
      "If PC Partpicker is anything to go by, the only board for $160 is a Gigabyte mATX board. Absolutely insane the lack of serious options for AM5 boards at decent prices.",
      "The power consumption differences vs actual performance differences vs the X parts are eye-opening.  Its clear that X parts were pushed far beyond their ideal volt/freq curve to look better against the then-upcoming Raptor Lake.\n\nIn the blender test, the 7900 had total system power usage of 201W vs 7900X at 302W, a difference of 50%, yet for all that extra power usage, in that test 7900X was only 12% faster.\n\nIMO Zen 4 would have looked much more impressive had it released as 95W and 105WTDP parts with the \\*option to set to 170W mode without invalidating any kind of \"OC\" warranty.",
      "A 7700 being almost the same as a 7700x, with less power, and a free cooler sounds awesome.\n\nBut when do these even go on sale?",
      "7900 is really a good value vs 7900x, same gaming performance for 100w less\n\nand you almost loose nothing in other applications, that we won't never-ever use",
      "I mean it's the opposite, they released them in extreme mode, but you can take them down and not lose much performance.",
      "That graph is typical HUB scumminess though. Look at the motherboard they used for AM5 price comparisons, they chose the single $160 AM5 motherboard to use as their price comparison. There are only 3 AM5 boards under $200, and all 3 have major reasons not to buy them.   \n[https://pcpartpicker.com/products/motherboard/#xcx=0&c=160,161,158,159&sort=price&page=1](https://pcpartpicker.com/products/motherboard/#xcx=0&c=160,161,158,159&sort=price&page=1)\n\n  \nThe reality is, AM5 is still very much costs $200+ for most buyers.\n\n  \nOn Intel's side you have 82 options under $200  \nhttps://pcpartpicker.com/products/motherboard/#xcx=0&c=154,163,155,153,152,162&sort=price",
      "Give it some time, the first am4 boards were awful and expensive too. This [turd](https://www.techspot.com/products/motherboards/asus-prime-b350-plus.162897/) was $150 when top of the line Intel boards were going for $200",
      "I also don't understand the $110 RAM cost for AM4 and Intel DDR4 builds. It's easy to find good sticks for $60 and under $50 is possible.",
      "Before i pull the trigger and get myself one of these Non X versions i want to see what the X3D models perform like gonna hold off untill they release some specs for those",
      "The AM4 equivalent is significantly inferior in several ways though.  They aren't directly compatible.\n\nThey represent the lowest allowed spec on the chipset + socket in both cases.  AM5 requires significantly stronger power delivery, bios capacity, and DDR5, all of which cost more.\n\nThere IS no 'equivalent' AM4 board.  There are none with similar power delivery either.    AM5 has SVI3,  AM4 has SVI2.   This means different power ICs and mosfets -- and these are not yet high enough volume to bring prices down.  (once Zen4 Epyc is ramped up and these have greater supply, it will lower costs quite a bit for AM5).  So you can't compare the # of phases of some AM4 board to an AM5 one and declare them the 'same'.  \n\nAre mobo manufacturers trying to take a larger cut?   Probably.   But there is competition, and when prices don't lower while there is sufficient competition, the reason must be either supply constraints or higher costs.\n\nIts a little of both here:  higher costs for DDR5 mobo traces/layers, higher costs for various power delivery components, and related supply issues for power ICs for those (that essentially keep costs higher).",
      "Meh, mainboard price still shit. DDR5 price is slowly dropping though.",
      "Tomorrow",
      "Explain how the x570 ws ace was one of the first am4 boards.",
      "[To be absolutely fair though, here's the list of boards with DDR5.](https://pcpartpicker.com/products/motherboard/#xcx=0&sort=price&s=40&mt=ddr5&page=1&X=0,20000)  Those are the most comparable to the AM5 boards in terms of specs, a lot of the really cheap LGA1700 boards are DDR4.  But of course both the entry-level Intel and AMD may lack PCIe 5 support, or only have it on NVMe, or other weird bullshit.\n\n(PS: it's easier to just select Socket: LGA1700 unless you want to filter for specific chipsets! ;)\n\nNow of course... does that really matter to users?  DDR4 is still very competitive in gaming and if it allows you to go with a cheaper CPU and a cheaper motherboard maybe that's not an awful decision for losing 5% here and there.  13600K is a very competitive CPU for the price, so is 5800X3D, and if you have memory already and maybe a motherboard then AM5 still looks like an overall bad deal even if \"it's got DDR5\".\n\nAnd Zen4's memory controller is *really fucking bad*, like it probably won't POST with 4 sticks unless they're single-rank and low-speed.  [wendell talks about it here,](https://www.youtube.com/watch?v=P58VqVvDjxo) but it's not really limited to 128GB, it's any dual-rank sticks, and even a lot of single-rank sticks don't do great with 4 slots, and you are going to significantly reduce available bandwidth (from 70GB/s with 2 sticks down to about 50GB/s - this is not insignificant). You are basically buying the ddr5 equivalent of the early super finicky b350 boards.\n\nHUB being HUB of course they completely shat on DDR5 for a year straight when it was Intel-exclusive, it *just isn't ready yet guys*, meaning AMD hadn't launched theirs yet, but the moment AM5 launched that was the moment DDR5 was ready and you were a big moron if you were still buying DDR4.  Truth be told it still is not ready yet, things haven't changed from july or august really other than AMD having their product out now (and it's much worse than Intel in terms of memory controller).  The launch gouging was winding down within a couple months, decent RAM came out within a couple months, but the AMD platform just isn't there yet.  \n\nWe will see what prices do in the future, AMD is supposedly designing their platform around smart power stages, which drives up the cost relative to AM4 (and LGA1700), and AMD is intent on selling you 2 chipsets even if they aren't needed (de facto this is just moneygrubbing from AMD - nobody actually connects more than 3 pcie slots even on a $1300 board, nobody really needs the expansion from the second chipset, it's just a way for AMD to capture a little more revenue selling you something that's hardly even used).  Prices may not come down as much as people are hoping, and when AMD says \"cheaper boards are coming\" what they most likely mean is A620, ie even shittier and worse boards, not so much that decent B650/X670 boards are going to come way down.\n\nEven as someone who is really into the idea of a AVX-512 + v-cache system, I'm really dubious about that memory controller and I think it's probably better to just wait a year and see what happens.  I expect 8000 series chips and better motherboards and lower prices will fix most of the complaints.",
      "The problem is the mobos were massively overbuilt since stock power usage went up so much. Even entry level.",
      "I believe this is because they wanted to compare 32GB vs 32GB.",
      "No. Prices are basically the same from B660 and Z690 MSRP to B760 and Z790 MSRP. The pricing difference is mostly because 600 series is 'old' and thus is on sale now, despite being 95% as good. You can find more 700 series boards under $200 than you can AM5 board.",
      "That's fair enough but I also think it's also just priced really high by the motherboard manufacturers. For instance my $350 Asus Prime Pro doesn't come with a full mobo backplate. For $350, it most definitely should.",
      "meh, still no $110-$125 B650 atx boards + $150 2x16 6000 C30-36-36-89 DDR5 kits = NO BUY"
    ]
  },
  {
    "brand": "amd",
    "generation": "7000",
    "tier": "low",
    "matched_keywords": [
      "7600"
    ],
    "title": "CPU-Overhead: Arc B580 vs. RTX 4060 & RX 7600 on 4 to 24-core CPUs",
    "selftext": "",
    "comments": [
      "According to the graphs, AMD has slightly less overhead than NVIDIA.",
      "So Nvidia now has the lowest driver overhead? Seems like they took the HUB video seriously",
      "The overhead is minimal for both AMD GPUs and NVIDIA GPUs, which is probably why reviewers didn't look at the overhead until Intel GPUs came along.",
      "We know the Arc B580 runs well with a Ryzen 7 9800X3D, which is 8 core/ 16 thread CPU.  According to these graphs, the i9-14900K (8P + 16E = 32 thread) and the i5-13600K (6P + 8E = 20 thread) CPUs do fine.  The extreme budget CPU i3-12100F (4P = 8 Thread) performs with a notable degrade in performance.\n\nMy current hypothesis is Intel's driver is relying on a heavier multithreading with a bit of crosstalking of the driver workload, potentially to take advantage of underused E cores, which the 13600K and 14900K have plenty.  Given the Ryzen 5 series CPUs have similar performance issues as the 12100K, having 6 cores and 12 threads, I would like to see Ryzen 7 non-X3D CPUs (8 core/ 16 thread), Core i5-14400 (6P + 4E = 16 Thread), and Core i5-12500 (6P + 0E = 12 Thread) CPUs compared as well.\n\nPlaying off Intel translating DX11 to DX12 drivers as an example, when DX11 game loads, Intel establishes 2 processes, the DX12 driver and the DX11 translator.  For optimal performance, all threads need to be running simultaneously, the DX11 translator sends command to the DX12 driver in real time.  If there isn't enough room for the threads to be running simultaneously, any data traded between the two have to wait until the next thread is switched in before getting a response.  More threading density means more delays.  Some games don't get impacted either because the game involves less threads or the driver doesn't need the real-time translation threads.",
      "> Unless you're running a CPU that's many many years old, GPU overhead is not really something you need to worry about. \n\nThat's just not true with Battlemage.\n\nCPUs released in 2024 showed the issue in testing.  \n\nIt's not year of release, it's capabilities.",
      "It's probably because the Intel gpu drivers weren't written that well since it was probably ported with little changes from their igpu drivers where there was always a GPU bottleneck which meant that Intel might not have known there was even an issue until more attention was bought to the issue with Battlemage.\n\nAlchemist was a flop, not many people bought it so not much attention was paid to CPU overhead issues.\n\nAMD/Nvidia by contrast have spent the last 20 years painstakingly writing and optimizing their DGPU drivers. Nvidia had some CPU overhead issues a few years ago and they managed to improve it with driver fixes.",
      "No, they do not.  The reason they have overhead can't be solved with software.  They've excluded hardware from their GPU's and required the CPU to do the work of that missing hardware.\n\nThe main example that seems to suggest otherwise is actually a demonstration of nVidia's forced threading of DX11 games, which can increase performance despite the increased overhead it entails, when the CPU has enough headroom overall (i.e. it doesn't eat into the single-thread performance).",
      "On an older post an Intel graphics engineer explained the issue, it isn't what you said. Intel is too verbose in commands which slows everything down.",
      "I‚Äôm pretty sure HUB doesn‚Äôt like Nvidia *or* AMD. They‚Äôre calling it how it is, these parts are too damn expensive.",
      "One thing I appreciate about AMD is having the lowest CPU overhead for their graphics drivers. Makes a difference if you're CPU limited in a game.",
      "HUB used DX12 games that also showed the issue.  It's something else.",
      "I'm fairly sure they use dxvk for d3d9 to 11.",
      "The comment to which I am replying is talking about nVidia, not Intel.",
      "Glad you brought up Nvidia as I didn‚Äôt know this had improved until the testing around Arc showed it had gone.",
      "That's actually... just worse news.",
      "So the money you save on a GPU you will need to spend on a better CPU??\n\nMight as well get a faster GPU.",
      "Interesting that B580 doesn't look bad at all with a 13600k. I wonder what it's like with a 13400 or 12600k. It seems like just having those extra threads provided by the e-cores takes care of the overhead it needs.",
      "Could just be a cache issue",
      "Battlemage drivers use the cpu for software accelerating certain processes that are not being hardware accelerated in the GPU.",
      "Lowest with DX11 and older, but not with the newer APIs"
    ]
  },
  {
    "brand": "amd",
    "generation": "7000",
    "tier": "low",
    "matched_keywords": [
      "7600"
    ],
    "title": "Entry-level RX 7500 specifications leak with 12% fewer Compute Units and slower memory vs RX 7600",
    "selftext": "",
    "comments": [
      "At least it's not as bad as the 6500 XT.",
      "It's not even bad all. This is pretty much a 6600, which is widely considered to be the best value GPU in the current market.",
      "I believe this is pretty much a slightly faster/more efficient 6600 for 200. 6600 is considered one of the best value GPU's on the market, and its Nvidia price competitor is the 3050. That won't stop people from saying it's DOA over 150.\n\nSidenote: 6600 is twice as powerful as the 6500 XT with twice the VRAM. Ironically this will be one of the largest gen-over-gen (by name) uplifts in history lmao.",
      "Lmao, the weakest card of the generation is going to be the most likable one",
      "You know what's sad? The 6600 being the best value gpu out there right now and the fucking 3050ti still outsells it",
      "Nah, this sub will bitch that it's not 150.",
      "People only bitch about AMD's cheaper than Nvidia prices because they aren't low enough to make Nvidia drop theirs so they can buy cheaper nvidia products",
      "Being only $35 cheaper than the 6600, it's still bad.",
      "3050ti in my country, sell for the price of a used 6700xt/6800 (non xt), and it still sold. I can't understand why",
      "We kind of do. There is a mobile variant, which is around 15-20% slower than 4060. Unfortunately it has only 6 gb of VRAM.",
      "Because people just buy nvidia. Only a few of us are informed of the real performance and value of the cards.",
      ">Lmao, the weakest card of the generation\n\nThat's pretty bold to say when we don't know the specs of 4050",
      "Yeah, that tends to happen when you put out a $200 card that loses to your competitor‚Äôs (swiftly memory-holed) $160 card from three and a half years ago.\n\nI wouldn‚Äôt complain about a $219 28 CU RX 7500 that performs the same as, or a little better than, a $350 RX 5700 from four years ago. A 59% uplift over two generations isn‚Äôt great, but it isn‚Äôt the worst thing ever either.",
      "During a massive shortage when the [1650 Super was going for 303 dollars used](https://www.techspot.com/article/2397-gpu-pricing-2022-update/)?\n\n[Obligatory viewing on the 6500 XT](https://youtu.be/tLfMiJjFRz8)\n\nAnd Nvidia released the 1630 for 170 that's slower than a 1050 TI 5 months later during a GPU surplus. The 6500 XT you're discussing is over twice as fast as the 1630. [Link](https://www.techspot.com/review/2498-nvidia-geforce-gtx-1630/).\n\nYou may not, but I'd put money down that people here will say it's DOA regardless.",
      "This will be 8GB of VRAM with 128 bit bus.\n\nYhe article said it would have 8GB and a 96bit bus, but that's an impossible combination. I think it's a lot more likely that the article is wrong about the bus than the VRAM.\n\nI'm assuming it'll have the same x8 lanes as the 6600.",
      "It is 8 lanes. same silicon as 7600.\n\n8 is enough with 3.0 systems",
      "in a healthy market there would be a price war",
      "Then people say AMD can just launch their GPUs at a lower price and take market share lol\n\nTBF though the 6600 has been in best seller lists for a good while now, so it's not all bad. The 3050 might be outselling it because of prebuilts.",
      "If you only look at MSRPs then the 6500xt seemed stupid\n\nBut if you looked at what was actually selling *and* the used market, the 6500xt was routinely the cheapest card in that price range new and at worst was as bad as a 570 4gb which sold for $10-20 less and was 6 years old",
      "3050 Ti is a laptop GPU. 3050 and 3050 Ti are actually available in a wide range of prices on laptops, so you'd need to pay quite a lot more to step up to a 3060.\n\nThe fact people buy a 3050 on desktop instead of RX 6600 (or hell, 6650 XT for the same price sometimes) is what's sad."
    ]
  },
  {
    "brand": "amd",
    "generation": "7000",
    "tier": "low",
    "matched_keywords": [
      "7600"
    ],
    "title": "AMD, you NEED to hire me! - AMD Radeon RX 7600 Review",
    "selftext": "",
    "comments": [
      "It was like that for 2 decades. Then came gpu shortage and nvidia realized they can charge what they wan't. AMD followed.",
      "Am i the only one that expects the new gpus to go head to head with the last gens higher model? For example I expected the 7600 to rival the 6700xt for small price cut. Is that unrealistic ?",
      "I feel like Linus is surprisingly kind to both AMD and NVIDIA. The 7600 looks better when compared to a 4060ti - but that‚Äôs not a win.\n\nAlso why is noone saying that the 6700 beats this card (handedly) at the same price. It also has 2 gigs of VRAM more..\n\n[6700 is the move](https://www.amazon.com/XFX-Speedster-SWFT309-Graphics-RX-67XLKWFDV/dp/B0BCL3L6ZG/ref=asc_df_B0BCL3L6ZG/?tag=hyprod-20&linkCode=df0&hvadid=616157467664&hvpos=&hvnetw=g&hvrand=4639726762715373912&hvpone=&hvptwo=&hvqmt=&hvdev=m&hvdvcmdl=&hvlocint=&hvlocphy=9016793&hvtargid=pla-1840123877710&psc=1)",
      "A normal poop is better than diarrhea, but in the end it's all shit.",
      "I'm not even sure what AMD is doing. They have had so many opportunities now to grab marketshare, and instead lost it. Why not try to be the definite value brand for 1 or 2 generations, and try to grab a huge chunck of marketshare first? No, first overprice the products, then drop soon after when it's too late. I truely don't get what they're doing.",
      "So as expected, mediocre\n\nThe RX 6700 has basically the same performance, 10gb VRAM, a wider memory bus, and a full x16 lane for $280\n\nIf you want AMD for whatever reason, it's the obvious choice right now (While stock lasts)",
      "At this point, Nvidia's pricing is a really strange game of attrition. Stores are sitting on mountains of stock for cards that are an amazingly shitty value proposition and I gotta wonder how much this is costing them monthly in warehouse storage and potential write-offs if we go through summer like this.",
      "I mean, why would they care? 6600 is outright better than 3050 and people still went for 3050. They could make a GPU that shits gold and gives blowjobs for 50$ and people would still find a way to justify Nvidia lmao",
      "Comparing and recommending to buy previous gen cards doesn't work as well for reviews because the 6700 will be long out of production before the 7600 is. Keeping things comparable within the same generation of cards for review purposes gives the videos better longevity. That's also why comparisons generally use MSRP instead of current market prices.",
      "They tried this is the past and all it resulted in was a 50/50 marketshare with Nvidia, but AMD made fuck all money whilst Nvidia made so much money that they barely knew what to do with it. AMD learnt from that to not challenge Nvidia on price/perf too much because it simply isn't worth it.",
      "The new paradigm is that older generations anchor the performance price points while the newer generations offer more performance at newer, higher price points.\n\n\nIt's basically what Jensen alluded to when he said the days of GPUs getting cheaper is over. You currently need to spend at least $1200 USD to get an Nvidia card that's stronger than the Amphere lineup from 2020.",
      "They don't care about market share. Higher profit margins are more of a priority to them",
      "The 6700 is literally 5-10% faster, has more vram, and one of the best 3rd party cards can be had for the same price. \n\nWhat‚Äôs even crazier is according to hardware unboxed they set the initial price to be $300.\n\nI wonder what it‚Äôs gonna take for amd and nvidia to pull their head out their own asses. One can hope intel competition would do this, but call me a pessimist, I have a feeling intel will be right there besides them in a couple years.",
      "In a few process upgrades, they'll need microscopes and extra fine tweezers to handle the GPU dies for the lower end graphics cards.",
      "why would anyone ever choose this over 6700xt?",
      "Holy shit this card is even worse than imagined‚Ä¶",
      "> For example I expected the 7600 to rival the 6700xt for small price cut. Is that unrealistic ?\n\nthe question is \"small price cut\" versus what?\n\nif it's versus MSRP... the problem is a lot of these cards have incredibly distorted MSRPs because they launched into the pandemic/mining.  6700XT is a $480 MSRP card, which was acknowledged to be trash at launch, same for 3070 Ti and so on.  But if AMD/NVIDIA didn't charge a higher MSRP, scalpers would do it for them.\n\nI think a lot of people *think* it should be vs street prices, but RDNA2 prices are currently in an extreme firesale.  And despite a lot of confabulation/false recollection beating firesale prices is not really the norm.  Firesales are firesales, they're intended to get you to take the older crappier thing at a better perf/$ vs the newer, more efficient, more featureful one.  980 Ti for example was cleared out way way below 1070 MSRP, and Pascal is literally held up as the model generation for pricing.  780 Ti was cleared out at $180 or so after GTX 970 came out (I bought two for our machines), and at launch the 780 Ti was a faster card.\n\nAnd paradoxically this discourages firesales because reviewers just go \"buy a 1080 Ti\" instead of a 2070.  Why have firesales if they're just going to get you blasted in reviews?  That's why NVIDIA hasn't done it since Pascal - reviewers shit on them because of the firesales (from their perspective) so \"no more firesales\" is an easy (and profitable) way to make your reviews better.\n\nAMD is, for the first time, having their own \"Turing moment\" where their older RDNA2 cards are on extreme firesale and the RDNA3 cards are not that appealing in comparison, they just didn't make a very good advancement and there isn't a lot of visible perf/$ progression.\n\nAnd again, just like with Turing, and just like with the demands for Ampere overproduction/etc... people can pitch a fit all they want, it's not going to lead to the outcome people want, it's going to backfire on you.\n\nTo me the street price comparison in the days leading up to launch is completely pointless.  What we really need is a more sophisticated handling of whether MSRP was any good for the comparison points.  3060 Ti - really good MSRP, never available.  6700XT - terrible MSRP, way better street prices that are very available.  How do you compare that?  I think you need to set a baseline, like \"3070 for $500 is an average-tier product for last gen\" and make comparisons on both old+new products against that.  Because very obviously some of the MSRPs are trash and others were amazing yet completely fictitious.  But this is *completely* a judgement call and there is no objective way to do this.  And much like reviewers just don't wanna touch image quality anymore (unlike in the old days of FX vs Radeon, etc) it's much easier to just put out a \"product bad\" review.  I'm not saying it's great, but expecting it to beat intense firesale street prices is a little unrealistic - just like 2070 vs 1080 Ti was.  \n\nThis will get me in trouble but:  Turing wasn't *that* bad a launch, but, it had to go up against intense firesales from the second great mining boom and it was just not up to the task of beating 1080 Tis selling at half MSRP.  So NVIDIA decided to never let cards sell for half MSRP again.  Is that what people want AMD to do?  That's a real easy call for them to make.\n\nPeople are really upset because they feel like they've been sitting patiently and waiting for three years and they're *still *getting screwed.*  But the RDNA2 prices *are* the benefit here, those are really good prices and even matching them from a new product generation is great, generally you will not get to double-dip hugely on top of firesales.",
      "Hard to make profit if suddenly no one buys their gpus anymore, long term grabbing market share would make more sense imo.",
      "It‚Äôs better longevity but you lose the real ‚Äòon the ground‚Äô aspect of it. It also gets difficult when,  for one reason or another, MRSP doesn‚Äôt really exist (2080ti, 6000 series, 3000 series, etc). \n\nI‚Äôd much rather have Hardware Unboxed‚Äôs style of reviewing. Especially when they do updates and genuinely do look at regional pricing then rank performance off of that.\n\nIt muddies the waters by making it more complicated, but I really appreciate that sort of thing. These cards are meant to replace the old, and seeing how they stack up (currently) against them is important imo.\n\nI see your point 100% though",
      "Exactly. The 6600 vs 3050 is the perfect example. I knew people bought 3050s but even then I was surprised to see 5x more people own 3050s than 6600s in Steam's hardware charts. Oh, and reviewers also shat on that card."
    ]
  },
  {
    "brand": "amd",
    "generation": "7000",
    "tier": "low",
    "matched_keywords": [
      "7600"
    ],
    "title": "Acer Radeon RX 7600 Predator BiFrost debuts in Spain at ‚Ç¨399, costs more than RX 6700 XT - VideoCardz.com",
    "selftext": "",
    "comments": [
      "Can't wait not to buy it",
      "I honestly have no idea who buys these models...7600 sapphire is 291.90‚Ç¨ here in Slovakia and there is also Asus Rog strix for 375,90‚Ç¨...just why?",
      "And DOA",
      "Cuz Asus tax",
      "payment foolish toothbrush aromatic nutty truck gray entertain apparatus pen\n\n *This post was mass deleted and anonymized with [Redact](https://redact.dev)*",
      "Same",
      "And in Spain, where the average wage is ‚Ç¨1400",
      "More like ROG tax. Other ASUS branded cards are not actually more expensive than MSI, Gigabyte, Sapphire and PowerColor.\n\n\nASUS 7600 Dual normally retails at A$450-460 while other brands are at A$440-450. ROG is above A$500.",
      "wtf :D so tone deaf",
      "Your info is a little outdated, the poorest regions have that average wage but Spain as a whole is ‚Ç¨1,695.",
      "Maybe read the comment he's replying to again.",
      "Better of getting a 6700 non XT if you can find one, more VRAM 10 GB better bus, in my country Romania it's at the price of 370 dollars VAT included same as the 7600.",
      "Who would've guessed?",
      "Most manufacturers have those overpriced and overbuild models. Their margins aren't great, so they try to get it somewhere and they really can only either cheap out on components, or try to sell something that is supposedly \"premium\".\n\nAsus has Strix, Powercolor has Red Devil, Asrock has Steel Legend, Sapphire has Nitro+.\n\nThat said, all of them also make far more sensible \"mid-range cooler\" options that are just 20-30 bucks over the normal price.",
      "Or buy the used one for half the price.",
      "According to Numbeo Spain's average salary is ‚Ç¨1790.40 per month. Barcelona is only ‚Ç¨1816, Madrid ‚Ç¨2509.47.\n\nIt's mathematically impossible to have majority below ‚Ç¨1500 since most \"high income\" cities don't even average above ‚Ç¨2000.\n\nBased on statistics, a significant percentage of people should be in ‚Ç¨1500-1900 per month bracket.\n\nThat aside, spending a week worth of salary on a mid-low end card is indeed still too much. We'd be able to buy a 7900 XT or 4070 Ti (~A$1200) with about one week's salary (~A$1194).",
      "It‚Äôs a bold move Acer, let‚Äôs see if it pays off.\n\n&#x200B;\n\n*\\[It did not in fact pay off\\]*",
      "It is really playing out like AMD is trying to mimic the nVidia strategy on raw performance but they forget they don‚Äôt have a DLSS3 hardware build-in to make the product sound better.",
      "Average is a pretty useless metric anyway, median is a more useful one. It's likely much lower than the average because the upper class (let alone the rich) bring the average way up. the median is 16800/year  so 1400/months, which means half the population gains less than 1400, and most of those that earn more than 1400‚Ç¨ aren't much above that.",
      "I agree with you if we talk about Madrid or Barcelona (expats mainly), but the overwhelmingly vast majority of Spaniards this is a 30% monthly income gone on a low tier VGA. The point is that this is tone deaf and the actual number don‚Äôt really matter that much."
    ]
  },
  {
    "brand": "amd",
    "generation": "7000",
    "tier": "low",
    "matched_keywords": [
      "7600"
    ],
    "title": "RX 7600 vs RX 6600 XT at 1Ghz (architecture test)",
    "selftext": "",
    "comments": [
      "Description API Overhead test from 3Dmark says \"Do not use it to compare graphic cards\" and \"You should not use those scores to compare systems or graphic cards.\".",
      "Doesn't RDNA3 have separate clock domains between shaders and front end, and the latter can't be changed by the driver? \n\nIf they only set the 7600's shaders to 1GHz while the front end is still on \\~2.5GHz, this is obviously going to give a massive advantage to the 7600.",
      "Compare different API's such as dx11/12 and vulkan for the given gpu.\n\n> Dubbed the 3DMark API Overhead Feature Test, this benchmark is a purely synthetic benchmark designed to showcase the draw call benefits of the new API even more strongly than earlier benchmarks. \n\n> . . . \n\n> The end result, as we‚Äôll see, showcases just how great the benefits of DirectX 12 are in this situation, allowing for an order of magnitude‚Äôs improvement, if not more.\n\nhttps://www.anandtech.com/show/9112/exploring-dx12-3dmark-api-overhead-feature-test",
      "So what does the overhead value indicate?",
      "So the 7600 is about 15-20% faster.  Just have to ignore the api tests as they are not valid for comparison of graphics cards",
      "In case of the RX 7600, the clock speed is synced between shaders and front end.",
      "It's to indicate relative performance between APIs on your PC. Judging by ratio between DX11 and DX12/Vulcan I think it test some scenario of being CPU-bound.",
      "Title says 6600, chart says 6650",
      "It indeed is likely clocked higher still. This would make rdna2's cache performance terrible compared to rdna3.",
      "You would expect rdna3 to clock higher though.  So IPC increase + clock speed increase should equal a bigger performance delta than what we are seeing right now.  Looks like finewine is back on the menu.",
      "> So the 7600 is about 15-20% faster. \n\nWith 13,3/11,06=~ 1,2x the transistor budget. Which is pretty much what you would expect.",
      "Sounds like that feature that was supposed to be available in the Vega 56 but was never enabled. I do not recall what the feature was, other than it was supposed to boost performance.",
      "It's technically interesting.",
      "Primitive shaders?\nWe use them since VII/RDNA",
      "Check the source link, the author mentioned that both frontend and shader are running at around 1GHz. The frontend clock is only \\~10MHz higher than shader clock.",
      "Yes this is my mistake. I apologize.\n\nThe difference between the 6650 XT and 6600 XT is the memory bandwidth, the clocks (slightly) and power limit. And all 6650Xts are AIB cards.\n\nNow in this specific case it being a 6650 XT is good since it means the memory situation is close between the two. The 6650 XT has 280 Gbps, the 7600 has 288. Almost equal.",
      "Actually, the dual issue shaders take up relatively little space for the possibility of more shading throughput as only the small execution unit has to be doubled up (it scales well to smaller nodes), while leaving the scheduling and such largely the same. Also RDNA 3 does have quite increased performance per WGP so it is working, though the compiler is not optimal at finding dual issue possibilities.\n\n  \nNvidia also does the same thing although calling it just extra cores, when they made ampere so there must be some logic to it.\n\nAnd looking at the number of transistors, the 7600 has just a bit more than the 6600xt on a similar node, so the \\~15% perf increase is not bad from architecture ipc alone.",
      "Nice metrics! Can you add power draw or consumption please?  üôè",
      "The point is to see what differences in performance come specifically from architecture.  Why this seems lost on so many people here is bewildering.",
      "RDNA3 does not actually clock higher, at least in the case of 7600 vs 6650XT, one is usually around 2.5G, the other around 2.7G"
    ]
  },
  {
    "brand": "amd",
    "generation": "7000",
    "tier": "low",
    "matched_keywords": [
      "7600",
      "7600xt"
    ],
    "title": "RGT - 7800XT, 7700XT, and 7600XT rumored specs.",
    "selftext": "[https://wccftech.com/rgt-radeon-rx-7800-xt-rx-7700-xt-rx-7600-xt-and-rx-7600-gpu-performance-targets-and-specs/](https://wccftech.com/rgt-radeon-rx-7800-xt-rx-7700-xt-rx-7600-xt-and-rx-7600-gpu-performance-targets-and-specs/)\n\nHonestly, those specs don't inspire confidence in team Red for me this go 'round if they're true. The 7800XT is seeing maybe a 25 -30% bump in performance in best case scenarios with better RT performance, and the 7700XT is probably seeing similar results, but when compared to their last gen-counterparts the 7700XT is probably looking more like a re-badged 6800 possibly XT, and the 7800XT is basically a re-badged 6950XT with better RT performance.\n\nThe only card in there that's worth noting is the 7800XT, it'll be almost comparable to a 4070Ti, which I just upgraded from 6700XT to. The 7700XT looks like it'll fall victim to the same fate as the 6700XT, priced in no-man's land with middling performance.\n\nI was talking to some friends earlier about this--for the 7800XT to even succeed it has to be priced \"realistically\" no higher than $650-$700 only because Nvidia is the go-to for a lot of gamers, AMD has a lot of ground to cover, and despite what some might say, Frame Generation is probably the best feature I've seen on a GPU in a long time; that and DLSS support sold me on switching sides for this gen. DLSS has been one of the features keeping Nvidia on top these past few gens, even against comparable AMD cards, and FSR just hasn't had the impact DLSS had, even being open source, the adoption rate and IQ combined versus DLSS has put it way behind.\n\nIt pains me to see how the x700 series being given the treatment it's getting. The 5700XT was such a great card, and the 6700XT improved upon it, but marginally, but still offered performance relative to a 2080Ti. The fact that the 7700XT might not even hit 6800XT levels of performance means this card is going to have to be realistically priced at $400-$450 for it to succeed, otherwise they're just handing Nvidia a victory this generation. The 4070, it's competition is going to be utilizing DLSS 3, and frame generation which is, in the eyes of the average consumer who doesn't understand tech but can read numbers is going to gravitate towards. The only thing that would push people to the 7700XT is if the 4070 is priced outrageously. Even then if Nvidia releases a 4060/Ti, it's probably going to eat the 7700XT's lunch in terms of sales.\n\nThe 7600XT is literally just a rebadge, plain and simple. Nothing to see here. :(\n\nSorry for the long post, but honestly the only card that piqued my interest from this gen would have been the 7700XT, but after pulling the trigger prematurely and getting the 4070Ti, honestly I'm happy I did. As much as it pains me to stray from team Red after six years,but I wanted something that was a step up from mid-range that would give me the option to play in 4k without spending over $1000, and I got the 4070Ti for $900 after sales taxes, which isn't bad for basically 3090Ti levels of performance, and about $132 less than what I would have gotten a sapphire/power color 7900XT. Was it pricey? Hell yes, but with it's performance level I'm easily seeing a good 3-4 years of usage from it, namely at 1440p.\n\nIt should be telling that the 4070Ti, despite it's price, is a card that AMD is going to have a tough time competing with considering it's nearest competitor, the 7900XT is only marginally better for $100-$150 more, and with the prices of the 7700/7800XT being unknown, AMD's got their hands full trying to figure a price that'll entice buyers. That's of course if these rumors are true.\n\nWhat do you guys think? You think AMD is on track, or do you think they blew their load a bit prematurely and forgot about the lower echelon of the RDNA3 cards?\n\nEdit: To clarify I was hoping and praying for AMD to pull a sucker punch on Nvidia and catch them off-guard to bring balance to the GPU market. I'm still hoping they do, or at least sell well, I would love to see AMD continue the trend of keeping Nvidia's pricing somewhat in check and maintaining decent performance, otherwise spending $900 on what can be viewed as mid-range will be nothing but a pipe dream in the years to come. I'm an AMD guy at the end of the day, even when the i7-2600k was god-tier I opted for AMD. ",
    "comments": [
      "Thing is, here in Canada, a 6800s and above are pretty much non-existent, and what's n stock is priced close to a 7900XT, if not higher. It doesn't look much different with Nvidia cards. \n\nSo whereas theoretically the 6800XT and the 6900 cards are a better value at msrp, practically we don't see these prices nor stock available.",
      "I always love how posts reference retail prices like that doesn‚Äôt relate pretty much anywhere in the world other than the USA.",
      "AMD picked the wrong generation to invent the XTX SKU, because they can only really compete with Nvidia's (current) second-best. And that's ignoring the looming Ada Titan/4090 Ti.\n\nRemember when Navi 1 released? The highest model was the 5**7**00 XT, which was a clear indicator that it competed with the 20**7**0 (Super).\n\nLikewise, the 6**9**00 XT at least had a claim to fighting the 30**9**0 when it came to 1080p and 1440p without RT.\n\nBut the 7**9**00 XTX is only a match for the RTX 40**8**0 (which is significantly gimped compared to the 4090), and the RX 7**9**00 is hardly a match for the 40**7**0 **Ti**. Keep in mind that the RX 6**8**00 competed with the 30**7**0 **Ti**. I have no doubt that a 4080 Ti is coming as well.\n\nIt's clear that all RX 7000 products below the 7900 XTX are more gimped versions than they would have been, had AMD decided not to name that SKU as such. Navi 32 and 33 not having more Compute Units than their predecessors (like N31) combined with the name-fuckery means that AMD will have to offset core reductions on low & mid-range products with clock increases to try to have barely-not-stagnant performance. Truly a pathetic showing this generation. I hope for everyone's sake that most people outright reject these.",
      "When the entire launch from both Nvidia and AMD has been a massive disappointment so far (especially with pricing) why would we expect mid tier to be any better. It's gona be overpriced and undersupplied (as per Lisa Su). This generation is a lost cause!",
      "hey bud im not having a go at you personally, moreso the industry as a whole. Also the fact that retail even in the us, is not really a good indicator. So many of the Halo lines people acutally buy are no where near retail, just look at asus strix as an example.",
      "I'm really bummed out by this. If the 7800XT specs are those upon release. I'm just going back to Team Green.",
      "AMD will probably price the 7800XT at 749 and act surprised when Nvidia takes 80 to 90 percent market share again.\n\n7800 XT should be 599.",
      "AMD can never decide if they want to make their cards equal to Nvidia or ahead. The R9 290x and HD 7970 also had awkward naming in relation to the competition.",
      "its simple. Ask 400 for the 7700XT. The issue is quite simple to solve but that would mean that the company caved in.",
      "Same in Europe more or less.\n\nYou either buy overpriced new gen, or damn overpriced last gen that is like 100 cheaper at best then new cards",
      "Ummm.. I'm sorry? I quoted US dollars because that's what I'm familiar with and what directly impacts me. If I lived in the UK, or somewhere else I'd reference those prices, etc. \n\nI know shits expensive, and I know some countries pay more than others, but those things don't impact me. Not that I'm turning a blind eye, just that it doesn't affect me, and my post was my opinion and thoughts based on what I know and am familiar with.",
      "I am aware that AMD have models with the XTX moniker before. It wasn't the best choice of words to say that, but that is beside the entire point I was making. I think it's pretty clear that I'm referring to the fact that the 6000 series did not have a halo \"XTX\" model.\n\nThanks.",
      "What were you expecting them to be?\n\nI think performance estimates are too high, though. The 7900xt had 25% more bandwidth, and 20% more boost clock compute even after the clock bumps. We're probably talking 6900xt performance on average, with better RT and machine learning. Still behind the 4070ti in every way except VRAM.\n\nI guess people were expecting another  navi31 cut, maybe? 72 CU or something?",
      "AMD is not innovating and is just happy to ride NVIDIA's coattails  while only getting money largely from their fanboys",
      "I think all these specs would have been great had AMD achieved the performance targets. Remember NVIDIA actually decreased CU's for cards compared to previous generation. But the performance uplift was so good that the cards still delivered better performance compared to cards with more CU's across the lineup.\n\nAMD didn't have much IPC gains or clock speeds and hence the 7000 series look lackluster in comparison.",
      "AMD is going to have to be VERY competitive with their pricing if they want to move these cards at all especially with the lack of frame generation. Most people without this feature will quickly discredit it and write it off but with my hands on experience it's a game changer.",
      "We're in-line to see maybe a tops 25-30% boost to the 7700XT which is inline with the 6700XT over the 5700XT. Problem that I have is having to upgrade sooner than later. It's almost as if the x700 line of cards are designed to be replaced every gen. They don't leave much headroom for newer games/graphical features when it comes to performance, almost as if they're designed around games that were released the year prior. \n\nI just couldn't bring myself to get excited for the 7xxx series GPU's. I was hyped at first, especially for the 7700XT, but I got hit with what will be ultimately a letdown and a reality check about AMD's mid-range left me wondering when will AMD start offering more than just performance bumps, features for instance. Sure we got FSR and RSR, but compared to DLSS they're inferior, naturally because Nvidia put an AI chip on their cards specifically for DLSS. Now Nvidia's rolling out DLSS 3 with Frame Generator and good lord, once they get the kinks worked out it'll be a monster. \n\nI just hope AMD can figure something out quick, instead of trying to go blow for blow with Nvidia; that's a fight they will not win.",
      "> The 7600XT is literally just a rebadge, plain and simple. Nothing to see here. :(\n\nIf it's based on the N33, then it clearly isn't a rebadge, but it won't be more than 20% faster (on avg) than N23 either, and even that isn't a given. RT should see more of a gain, but not sure how viable that is outside of perhaps RT shadows.",
      "X1900 XTX was the first in 2006 fallowed by the 1950 XTX.",
      "Tbh I'm expecting prices to be a lot better than many doom and gloomers. 7900 XT is starting a hundred less than the 6900 XT and not selling. AMD tends to be quick to adjust prices to market, so I think it'll drop to 800, although probably not formally (AMD seems to favor reimbursing retailers behind the scenes to cut prices rather than formally adjusting MSRP).\n\nThe 7800 XT has 5/7 the CU count and value increases as you go down the stack. 5/7 * 800 = 571. So the 7800 XT is probably gonna be 550-630.\n\n6700 XT and below MSRP's were set during the shortages, 25% tariff, and cryptofuck epidemic. So they were higher than otherwise.\n\nThe 7700 XT is going to be getting 20% more CU's than the 6700 XT, so it will have 80% of the 7800 XT. Again, value tends to increase down the stack until you hit the 6 series. So .80 * 571 = 456.80. So probably 400-450 and it'll perform a bit over halfway between the 6800 and 6800 XT, probably closer to the 6800 XT.\n\n7600 XT is probably gonna be around 6700 XT performance. 7700 XT has 50% more CU's than it, 456.80 * 0.66 = 304). The 6 series is where value tends to drop off, so I think it'll be 300-340.\n\nThe 7600 is 28 CU's, or 7/8 the 6600/7600 XT. So it should be no trouble to match a 6600 XT and will probably come close to the 6650 XT. As for the price, 320 * 7/8 = 280.\n\nA lot of this will depend on what Nvidia is doing, but assuming Intel continues unfucking the drivers and reliably delivers 6700/XT level performance at 250 with the A750, competition is fierce."
    ]
  },
  {
    "brand": "amd",
    "generation": "7000",
    "tier": "low",
    "matched_keywords": [
      "7600"
    ],
    "title": "AMD RX 7600 and NVIDIA RTX 4060Ti/4060 GPUs are already 10% cheaper in Spain - VideoCardz.com",
    "selftext": "",
    "comments": [
      "Good. On the way to more normal pricing - also in the EU. I'd like to see AMD lower the prices in the EU closer to the US, so like 950‚Ç¨ for the XTX and 800‚Ç¨ for the XT and a game bundle. Then I'll bite.",
      "With 8gb ram they should be 30% cheaper at least.",
      "AMD needs to drop more than 10% if Nvidia does as well.",
      "Shocking, people dont want to buy stuff that is mediocre in 1080p ... 10+ years after 1080p gaming became standard. Like who would guess  .... shocking, truly shocking /s",
      "Don't pay more than $200 / 200‚Ç¨ for a 8GB low/mid-range GPU. \n\nNo one did it back in 2016, there's no need to do so in 2023.",
      "XT can be found for ‚Ç¨830 and the XTX for ‚Ç¨999. So we're almost there. \n\nBut still you can't find deal that is better than the ‚Ç¨490 I paid for my 6800 more than 2 years ago. Perhaps the 6800XT for ‚Ç¨539, but other than that?",
      "It's just how how it is. They need to be 15-20% ahead in pure raster performance to compensate for the currently bad rdna3 drivers, worse upscaling, and the fact this card so has the same RT performance as an OC'd 6650xt. Then add the fact AMD cards use 5-10% more VRAM for the same visual settings, and this the 7600 is actually a class below the 4060.",
      "Why do you even consider them mid range?   Those are the lowest cards in ther generation. There is nothing lower than them.",
      "Good, these cards suck. In fact, most new cards suck, when you consider all of the stuff going on with price, performance, and features. I was watching a GN video from a little while ago about the terrible state of motherboards on modern chipsets. They've taken basic features from 20 years abo (like relaying POST codes to the user) and turned it into a premium feature limited to $350+ boards.\n\nAn anonymous employee quoted in that video referred to it as something like, \"malicious segmentation\" of the products. It seems like GPUs are in a similar state. There is a more aggressive stripping of baseline features on newer cards, as if they're trying to lock people with lower- and mid-range GPUs out of options other than \"buy a new GPU.\"\n\nOverclocking is basically left to exotic cooling solutions, as these companies have gotten more aggressive with power deliveryand maxing out cards. It's bad enough that undervolting is the new overclocking--people who would rather have 95% of performance for 85% of the power draw, versus having GPUs pushing 500W out of the box.\n\nThe cut-down PCIe and VRAM seem to be how these companies are doing it today. When your 1080p card has 8GB of VRAM for ~$300, it's pretty awful. The scaling to 1440p is poor, and the ability to sit on the fence between \"higher fidelity 1080p\" and \"lower fidelity 1440p\" gets tougher to pull off. You can't OC, and you don't have the VRAM to handle 1440p as well if you could. These low- nd mid-range products don't seem to be made around budget customers and providing value. Instead, they seem to be intentionally hamstrung to make sure you get punished for not buying at the top of the product stack. The goal isn't giving you something affordable to meet your needs, it's to give you the absolute bare minimum so they can force you into being a repeat customer.",
      "i swear mods need to ban mindfactory, always used to show EU prices when its a german only distributor that can afford to do that like stop using this shit",
      ">$200 / 200‚Ç¨ for a 8GB low/mid-range GPU.  \n>  \n>No one did it back in 2016, there's no need to do so in 2023.\n\n1. 200 euros are not the same as 200 usd. so that doesn't make sense. Why 200? why not 220 or 180?\n2. yes people did in 2016. 1060 6gb was above 250.",
      "I guess I consider them mid range because all the low end has been pretty much gobbled up by iGPUs, so it effectively ceased to exist.",
      "2016 vs 2023 doesn't have a 50% inflation. [Actual inflation from 2016 to 2023 is around 25%.](https://www.bls.gov/data/inflation_calculator.htm)\n\n&#x200B;\n\nThe Navi 33 uses an old and cost-optimized process, the chip is rather small at 200mm\\^2 and it uses a 128bit memory controller + 4x 16Gbit GDDR6 chips. \n\nPolaris 10 from 2016 used 230mm\\^2 chip, a 256bit memory controller + 8x 8Gbit GDDR5 chips.  More memory channels == more expensive PCB.\n\n&#x200B;\n\nEven if AMD is paying more for the ASIC, it won't be a $100 difference for sure.\n\nPlus at some point pre-cryptocraze of late 2017 the Polaris 10 8GB cards were selling for $140. I personally bought one for $180 in early 2017 that I still own.\n\n&#x200B;\n\n&#x200B;\n\nThe RX7600 is a mid/low end card with a small chip and very low memory amount. It needs to be a lot cheaper to become an interesting value proposition over GPUs of the previous generation.",
      "> forgetting about a plethora of other things like, die\n\nHave you seen how tiny the dies are in recent low end parts. The wafer costs going up is less impact than you'd think when each wafer is producing far more dies.",
      "Good, because even at discounted prices they are sht.",
      "Why should AMD lower pricing in Europe further than they do in NA for even pricing? VAT is VAT, AMD can hardly do anything about that.",
      "Mostly just down to needing a stronger euro. 1=1.09 now, needs to be closer to 1.20 for even pricing.",
      "Regrettably, Mindfactory does not ship outside Germany.",
      "In germany the power color XTX hellhound has been fairly stable at 949‚Ç¨ but I still think that's way too much for a GPU, just because the 4080 has an even higher price this isn't exactly a reason to celebrate just yet.\n\nRealistically I would have preferred just 16GB of VRAM with XTX raster performance at 700 bucks, but AMD are cashing in on the nvidia price hike so I went with a used card instead.",
      "I checked out videos on both, saw 25% to sometimes even 40% better performance on the 6500XT, which puts the 780M between 1050 Ti and 1650 performance. I looked at 780M vs 1650 mobile and the 1650 outperforms it most of the time. The 6500XT at gen4 actually performs around 1650 super levels. IDK how you can call that \"marginal\"."
    ]
  },
  {
    "brand": "amd",
    "generation": "7000",
    "tier": "low",
    "matched_keywords": [
      "7600"
    ],
    "title": "[TechPowerUp] AMD Reportedly Adjusts Radeon RX 7600 GPU MSRP to $269/‚Ç¨299",
    "selftext": "",
    "comments": [
      "This was always the plan.  AMD does this strategy a lot. Leak bad price, adjust price at or near launch to garner the perception that it is a \"good price\".  That said, I think they need the extra room in the product segmentation for a future 7600XT.  I was optimistic that this (non-xt) card would come down to $249.",
      "I contest this, them dropping the price BEFORE release is kind of new. Usually they roll out with their initial price point, get roasted in reviews, then price reduce over the next few weeks after all the PR damage has been done.\n\nAt least now they'll get roasted for performance / power reasons, which to me is more fair as price is fluid - hardware is not.",
      ">I contest this, them dropping the price BEFORE release is kind of new.\n\nThey did it with the 5700 series.",
      "People will say it's just $40 more for the 4060 with all its features. I realize AMD can't make these as cheap as they used to and still need to make a bit of profit but this GPU needs to be significantly more powerful than a 4060 at this price. Or way cheaper, like $230 for the basic cards.",
      "Eh, I'll still get a 6700XT (or 6750XT) over the 7600 and even the future 7700XT. Already found a 6750XT for just $320 (same price as a 6700XT).\n\n7600 and 7700 series' - 128-bit bus, 2048 shader cores, 128 TMU's, 64 ROPS, 8GB VRAM.\n\n6700XT - 192-bit bus, 2560 shader cores, 160 TMU's, 64 ROPS, 12GB VRAM.",
      "What features? DLSS that looks like shit in 1080p, and \"better\" RT support on GPU that won't allow you to run game with RT enabled in stable FPS?",
      "It's extremely difficult to see how the 4060 could be faster.  It has 33% fewer FP32 ALU's.  Fewer TMU's.  Fewer ROP's.\n\nEven if you're generous with estimates of nVidia's dual-issue efficacy and miserly with that of AMD, you still end up with 10%+ higher performance for the 7600 at the same clock speed.\n\nWithout knowing the actual clock speeds of either card (both AMD and nVidia now lie about max boost - it's actually *higher* than the advertised value), I'd make a conservative guess that the 7600 is around 15% faster than the 4060.",
      "Radeon always go through the same cycle\n\nSet a high MSRP, get slated in day 1 reviews, discount on the retail market soon after launch\n\nThey need to start settings more competitive MSRPs",
      "There weren't really any leaks really, except the usual prices that get leaked from stores.\n\nIt's probably just a similar situation as with the 5700xt where AMD drops the initial price in response to Nvidia. If the 4060 is $299 then they really can't price the 7600 at that price.",
      "if the 4060 is $299 and the 7600 is $269 then we can expect the 7600 to match the 4060 in rasterization at best. Most likely the 7600 will be slower on average by \\~5%",
      "Nvidia and AMD change prices down to the last min, it's normal.",
      "Since the 4060 matches the 3060, then hopefully the 7600 is the clear winner here. Not because of stellar performance but because Nvidia has made the worst card generational 'improvement' ever seen. Ever.\n\nEdit: Meant 4060ti matches 3060ti. How they are so close being different generations is beyond me.",
      "I concur. The 6700XT/6750XT is pretty much the only card that makes sense from a purely gaming standpoint right now in the $300-$350 category. It's the only thing we have close to a \"fair deal\" outside of used prices. Anything less and you run into the vram situation, anything more and you're facing pretty steep margin increases.\n\nNote: fair deal in comparison to the other categories being pretty much a bad deal across the board. It's still not a great deal unless you find a great open box price with warranty and return policy or a promotion with a free game you were going to buy anyways.",
      "RT is a no go at this performance level anyway. It's irelevant, except for 30 fps cinematic gameplay.\n\nDLSS3 is a no go either because you're doing too few frames at 1440p to make fake frames bearable on input.",
      "Yeah, but with the 5700 series AMD changed prices that had been already announced the day before the cards hit retail.\n\nIn the case of the 7600 is just rumors about previous rumors though.",
      "Really hope this drives down th price of the 6700 and 6700xt a bit, as i've really got my eye on both of them as an update to my Radeon 580.\n\n&#x200B;\n\n$269 is an okayish price, but with the 4060 at 299 the 6650xt at $249 and 6600 at $199, it's  bit of a hard sale for me.  I expect it to get some retailer side price cuts by the time the 4060 hits though.",
      "6600 XT and 6650 XT are already faster than a 3060 12 GB. Same for 5700 XT for that matter. \n\n4060 seems like a standstill vs 3060 12 GB.\n\n7060 will easily match or outperform it a tiny bit.",
      "That's probably not gonna happen I believe.  Why would AMD release 3 products with the same CU count. That's like dumb. I can accept maybe 1 extra product with same CU as some sort of refresh but otherwise it makes no damn sense.\n\n7800XT, 7700XT and 7700 are all probably using N32.\n\nLike 7600 is the max N33 chip. Ain't gonna be anything more.",
      "I'd pay 230 euro for it no more",
      "I contest your contest, good sir!\n\nThere are no bad video cards (assuming they work). Only bad prices.\n\nBut in all seriousness the power use on this thing is firmly in the \"meh\" category. Not good, not great...I'd pick one up if I was in the market for this category only if it was on sale or had a free game. It's pretty decent for the price but it isn't going to turn any heads.\n\nI'd love to do some undervolting and/or overclocking to it to see what if any gain or efficiency can be made."
    ]
  },
  {
    "brand": "amd",
    "generation": "7000",
    "tier": "low",
    "matched_keywords": [
      "7600"
    ],
    "title": "RX 7600 8GB",
    "selftext": "Building my first PC and just wondering if the RX 7600 is still a good GPU for a budget setup in 2025?",
    "comments": [
      "The XT version is 16gb which would be much better, though a bit more expensive. About a $70 - $100 difference in Australia, so probably closer to $50 in the US.\n\nThe 7600/7600XT are still good GPUs. But 8GB VRAM is increasingly harder to work with on new games, so a bit of extra $$ to double VRAM would be well worth it.",
      "Personally I usually avoid any GPU with low VRAM like that if your intention is around gaming.",
      "Try pushing to a 7800xt, amount of vram makes a big big difference",
      "Add 3D modeling/rendering to that.",
      "Totally agree, the 7800XT is a great card. \n\nBut if the price jump is too much go for the 7600XT op.",
      "It's fine if it's what you can afford and what will run the games you play. PC subs never understand actual budgets.",
      "For 1080p gaming, it'll be fine",
      "It's ok but wait for the 9060 and 9060 xt. They're expected to launch in late may-early summer",
      "Thanks. The price jumps are a bit out of the expected range, but I‚Äôll try looking for deals.",
      "Even a base 6800 would be sufficient for the same or cheaper price of a 7600",
      "Buy an intel discrete gpu and you got all the wrong story üëæ... üêë",
      "Maybe used 6700xt / 6750xt? More than 8gb vram will be very nice.",
      "Its worth it, it'll save you from needing to do this again next year",
      "Definitely worth getting 16 still in my opinion. I know it‚Äôs a price jump, but it‚Äôll save you a lot of pain long term. \n\nWhat‚Äôs the rest of the build look like so far?",
      "Then should be avoiding amd",
      "Its fine, I rather have more VRAM than I need over not having enough. Atm I‚Äôm going for a more midrange build so its not too bad.",
      "Gonna pair it with a Ryzen 5 7600x and still figuring out the rest.",
      "better buy a Nvidia 8 gb card than a amd 8 gb one ."
    ]
  },
  {
    "brand": "amd",
    "generation": "7000",
    "tier": "low",
    "matched_keywords": [
      "7600"
    ],
    "title": "Is the rx 7600 xt a good budget gpu?",
    "selftext": "I need a max 350‚Ç¨ gpu, and the rx 7600 xt seemed the perfect choice. Ofc i want to see other people opinioni on this. Not sure if it's good",
    "comments": [
      "1080p? dont see why not...",
      "idk... There's maybe 5% performance difference at best on a good day.. but it costs like 50-70‚Ç¨ more. I don't think price difference is justifiable unless your gonna use those extra 8 GB vram",
      "Not fast enough to get 60 fps on ultra with rt in 1080p in some games. Metro exodus, cyberpunk, rdr2. So you have to reduce graphics. And just 3 games which didn't fit into 8gb - forza 5, cyberpunk, farcry 6 with hd textures. All with rt. I use like a year, guess had to buy 7800xt instead. But if you are ok with some graphics reducing you are good to go. 16 gb would be enough like 5 years ahead.",
      "I've seen used 3080 for $300 US quite often. That would be a MUCH better card.",
      "I'm looking for a similar priced card if you have a good CPU have you seen the Intel Arc B580. In the UK they are only a bit more expensive than a RX 7600.",
      "WHO cares this is not an rt card",
      "Who the hell cares about rt on a 1080p card. This is ridiculous advice",
      "in italy is 370‚Ç¨ on ebay. but why is better?",
      "i have the ryzen 5 7500f. but does it have rt or a dlss kind of thing?",
      "16gb it's good in 2025",
      "Yeah I thought exactly like you before buying. But rt really makes difference in some games. So after you see it you don't want to turn it off.",
      "Think it‚Äôs only you pal",
      "it has 8-10gb of vram",
      "and the end part looks predisely made to do a amd dissing",
      "User benchmark is notorious for being untrusted in the pc gaming community. They shill for intel and Nvidia. They have a grudge against AMD for some reason just go over to the PCMasterRace sub and you will see for yourself. \n\nI have a 7600xt, and it's a great card for 1080p and can do some 1440p.",
      "I hate the AMD vs Intel war. Just look at some yt benchmarks and they have 0 bias. Thz. Gonna buy the GPU soon",
      "Everyone who is not blind",
      "https://gpu.userbenchmark.com/Compare/Nvidia-RTX-3080-vs-AMD-RX-7600-XT/4080vsm2280266\n\nAlso DLSS 4 is better than AMDs implementation and will provide more longetivity. The 3080 performance is very similar to the 7800 XT, but still with better upscaling and much much better RT",
      "Sure, with GTX1660 you have no idea what you are talking about."
    ]
  },
  {
    "brand": "amd",
    "generation": "7000",
    "tier": "low",
    "matched_keywords": [
      "7600"
    ],
    "title": "AMD Radeon RX 7600 price drops to $229 for the first time (MicroCenter in-store pickup only) - VideoCardz.com",
    "selftext": "",
    "comments": [
      "With starfield included it looks like a awesome deal at that price",
      "Good deal. Meanwhile in Europe (Italy) the price is around 300‚Ç¨ (325 usd)...",
      "The AMD Rewards portal does use a utility to validate your platform during key redemption, so you would need to have an eligible GPU installed for that step.\n\nAfter that, it will provide a Steam key which can then be redeemed regardless of your hardware.",
      "It's like buying starfield premium edition and getting a GPU for (almost) free, lol.  \nGranted this one doesn't give the premium edition, but still fun to think about.",
      "Do you have to install it to get the game? \n\nI'm slowely gathering pc components and idk if im fast enough with gathering all the needed components.",
      "Must be nice, I upgraded to an RX 6600 for 267 USD here in South Africa. From RX 570 so I'm still satisfied with my new card for 1080p ultra/high\n\nEverything else was too expensive. RX 7600, RTX 4060, RX 6700 XT,  RX 6750 XT etc too expensive. \n\nI wish I could've gotten the RX 6650 XT instead but prices here make no sense",
      "Indeed, that made me buy the RX 6650XT instead.",
      "A pretty huge chunk of the population can get to those stores though.",
      "Even if you did you'd need to be near a Microcenter.",
      "The lowest price except for the brick and mortar microcenter which is an anomaly even in the US is $254 USD. Add VAT and convert to euro and it's 286 euros. Lowest 7600 on it.pcparpticker is 290. So it's about the same.",
      "That's a better card.",
      "i bought the AMD Bundle with Company of Heroes. I was able to redeem the Key with my Old Rig - Intel CPU and Nvidia GPU (havent received all my new parts and waited until everything was delivered). But i couldnt redeem The Last of Us Key from the AMD Bundle (Friend bought the GPU and sold me the key for some beer). So he had to redeem it and give it to me. It seems like the detection software is bugged sometimes and you are able to redeem the key without the predetermined Hardware.",
      "Unfortunately not. In Italy, only 2 stores have this promotion:\n\nhttps://www.amd.com/en/promotions/starfield-bundle",
      "Wish I lived in the US...",
      ">Italy\n\n275",
      "The gas price to drive would make it not worth if the round trip is over 2 hours",
      "I wonder if [Gamer's Nexus](https://www.youtube.com/watch?v=JM-twyjfYIw) will re-visit the 7600X.\n\nTheir only moan was price, but it spoiled their review.\n\nThey also moaned about temps. They neglected PBO which can drop max temp to 90C-80C without performance loss.",
      "That's why I hate reviews that focus on price. They age like shit after a couple of months to the point to where they're worthless videos. I bought a 6600 after a year or so after release and the review channels had worthless negative reviews.",
      "275 without Starfield promotion.",
      "7600 would be good with 10g ram"
    ]
  },
  {
    "brand": "amd",
    "generation": "7000",
    "tier": "low",
    "matched_keywords": [
      "7600"
    ],
    "title": "The hexa-core AMD Ryzen 5 7600 5.1 GHz processor has dropped to $189",
    "selftext": "",
    "comments": [
      "What stage of \"is six cores enough for gaming\" discourse are we at now",
      "Hopefully the only correct one, it's fine and will be for several more years to come, especially with the Pro consoles sticking to Zen2.",
      "7600x paired with a 7900xt here. Its been plenty of CPU and would recommend.",
      "It's not about number of cores. A 7600 will:\n\n* Match or beat a 5950X in 95% of games\n* Match or beat a 3950X in 99% of games\n* Destroy a 2950X in 99% of games.\n\nWhat matters most is the amount of single-core performance, multiplied by a certain number of cores. That's why clock speed and L3 cache matter far more in gaming than core count.\n\nIt's also why a 5600X3D (6C/12T, 96MB of L3) destroys a 5950X in many games out of the box. If it was clocked the same as a 5950X it'd beat it in almost every game.",
      "> there are definitely games out there that hammer the CPU a lot\n\nare these games using all the available cores?",
      "I've got a 7600 non-x and a 7900xt and I play a lot of modern games on high settings and I've yet to fully utilize the CPU",
      "This is a good deal! With it being the 7600 non-x, it'll run cool, too. No expensive cooling solution required. Thermalright Assassin is less than $20.",
      "Lol, so true. Just like games utilizing more than 4 cores/threads were \"just around the corner\" back in 2011 when Bulldozer released",
      "It matches 5800x3d in some games. Beats it in some games that benefit from DDR5. Doesn't bottleneck RTX 4090. So it's enough. Hardware Unboxed did a video on it. Watch.",
      "I got a 7500f on ebay for 140 and am extremely happy.",
      "There's like a 10% difference between the Ryzen 5 7600 and Ryzen 9 7950X in most games, these cores barely do anything, CPUs in the same generation just don't differ that much in gaming even for intel but the X3D ones are the outliers.",
      "im running a peerless assasin with the 7600 currently. other and a fan speed spike when opening games, it runs very quiet",
      "Even the 7800x3d bottlenecks a 4080 in some cases, even at 4k, so yeah this absolutely can bottleneck the 4090",
      "Yeah ive got a 7600x and a 7800xt and its been amazing tbh, would 100% reccomend.",
      "I‚Äôm running my 7600x with a Thermalright Peerless Assassin 120 SE. while gaming my temps will hover around 55~57c. As long as I‚Äôm not doing anything cpu intensive, the cpu does quite well.",
      "The peerless assassin is a great air cooler, I have one currently on my i9-12900k. It's a large dual fan tower.\n\nIn my comment above, I was referring to the cheaper single fan options from Thermalright that are like $16-17 shipped with prime. Like the assassin x120se or assassin king. The 7600 non-x is only a 65w chip and those cheap 120mm single fan tower coolers are a great pairing with a 65w chip for a budget rig.\n\nThe peerless assassin is still a great price at $40 for its capability though.",
      "A friend of mine got his 7500f for 128 euro (on sale at Aliexpress). Best value for money IMO.",
      "Fine but not optimal, but for what? The only situation in which my 7600 is insufficient is when the game inherently already has a CPU bottleneck. In which case, all CPUs would be suffering and be the limiting factor.  Those are usually either grand simulation strategy games or poorly optimized AAA games, both of which are lot of people including myself don‚Äôt really play anyway.\n\nI‚Äôd love a higher tier CPU but I‚Äôm glad lower tiers are excellent for gaming still. Won‚Äôt be the case in the future I reckon.",
      "It's pretty funny to read that all of the time when my OC'd 7950x3d setup bottlenecked my 3080 so heavily and often. Virtually every MMO, RTS and Sim style game, but many more too. To list some: WoW, FF14, GW2, OSRS, SC2, Stellaris, some newer RTS games, BG3, KSP, Factorio etc.\n\n A 7600 EXPO + 4090 system would be about 2.5 - 3x more severely CPU bottlenecked in those situations by comparison since a 4090 is twice as fast and a 7600 is much slower. In BG3 you're looking at something like the CPU being able to do a stuttery 80fps in city while a 4090 is chill at a smooth 400 plus.",
      "Some certainly do, I used to have a 5900x and got to go to a 5800x3d and I‚Äôve noticed quite a few games use all 8 cores, when previously 4 of my old cores would always go unused. call of duty jumps to mind.\n\n(I was able to sell the 5900x for the same price as a new 5800x3d for my primarily gaming focused PC, that was a damn good upgrade for free)"
    ]
  },
  {
    "brand": "amd",
    "generation": "7000",
    "tier": "low",
    "matched_keywords": [
      "7600"
    ],
    "title": "Kuroutoshikou launches Radeon RX 7600 Blade & Soul NEO graphics card",
    "selftext": "",
    "comments": [
      "We dont want 8gb card in 2025.",
      "it's honestly acceptable for 1080p",
      "I mean if you're getting a rx7600 I think 8gb vram is the least of your worries",
      "Nothing to see here.... they just add some graphics to the box, changed the name ü§¶‚Äç‚ôÇÔ∏è\nstock af, OEM looking card of last gen too ü§¶‚Äç‚ôÄÔ∏èü§¶‚Äç‚ôÄÔ∏è",
      "Why would someone release a new model of 7600? Does anyone care about that card in 2025 to spend money on some special edition? The only people buying this thing now would be people urgently wanting a cheap card for 1080p/60fps gaming, and they are going to pick up cheapest simplest model. Fancy editions for 7600 just don't make sense.\n\nAnd I am saying that as someone who is daily driving 7600.",
      "The 6600 is a great card, I don't see why the 7600 isn't more of the same? You'll have trouble getting super fat framerates in UE5 games, and that's about it. I can get 90~120fps (depends on map) in Marvel Rivals with no issues, I bet the 7600 makes that a little smoother.",
      "Blade and Soul whales",
      "The other part that‚Äôs funny is‚Ä¶ there‚Äôs nothing notable about this card. They couldn‚Äôt even bother to decorate the shroud lol!",
      "Kuroutoshikou is a distributor, not a manufacturer. All they do is repackage OEM products.",
      "Oh right, B&S Neo is a thing. Might be a good time to get into those games finally...\n\nKinda want one, not much of an upgrade over my 6600, wish this was a 7600 XT instead. But this is likely just a stopgap until the 9060s come out, since B&S Neo is probably coming out (in Japan at least) before those. Is it already out in Korea?\n\nI assume 7600s are just really easy to come by right now, or PowerColor just had a bunch sitting around.",
      "It looks like xfx base version.",
      "It comes with an exclusive dress¬†game code.",
      "It really is. And even then, what's so bad with turning your Textures from Ultra to High or Medium? You aren't *owed* Ultra settings.",
      "All that and no fsr in gameü§£ü§£"
    ]
  },
  {
    "brand": "amd",
    "generation": "7000",
    "tier": "low",
    "matched_keywords": [
      "7600"
    ],
    "title": "AMD RX 7600 reference design will be fixed to fit all power cables before market release - VideoCardz.com",
    "selftext": "",
    "comments": [
      "As we already know, no AMD launch without something going south",
      "What even is the problem at this point? No customer is going to face this issue. I seriously don't get it. Someone explain to me what \"went south\".",
      "If an issue was fixed before the product ever reaches the hands of a customer, then how did the launch \"go south\"?",
      "Lol a problem was caught by reviewers and brought up. AMD is fixing it which is great. Would you prefer that if reviewers find a problem they just assume ‚Äúnah man AMD will fix it no biggie‚Äù and not report it at all?",
      "Compared to Nvidia‚Äôs power connector situation hard to come out and say bad guy AMD but here we are.",
      "You have no idea how many fixes happen to a product long before you ever see it.",
      "I like when companies fix a mistake",
      "No one has the card other than media",
      "You're just sad period, especially with that attitude. RX 6700 / 6700 XT / 6750 XT sold like fresh bread due to the new and great nVidia release, RX 6650 XT and RX 6600 are best-buy for their prices also (and actually sell).\n\nThis connector issue was found out and blown up before any user even complained of it, since they aren't usually as wide to not fit. Meanwhile AMD cards are more power efficient for the performance they offer than nVidia's.\n\nNvidia 12-16pin (how you prefer to call it) power connector keeps melting but users are blamed as if they never used 6pin and 8pin and other connectors for decades already and this one is the first one to melt. But I assume that news flew by you even though it is still happening.\n\nAnd Intel consumes twice the power of nVidia and AMD for half the performance, absolute inefficiency but a worthy effort for a 1st gen that keeps improving lots by driver updates.\n\nOnly thing sad and wrong is your pessimistic attitude.",
      "The problem is bad publicity. \n\nIt suggests an oversight in a really basic design element of their GPU, to which people will naturally extrapolate \"if they couldn't get that basic obvious thing right, what other more complicated stuff did they get wrong?\".\n\nAMD deals with a general negative perception from the market already, it doesn't need to help things along with silly unforced errors.",
      "Needing to modify the cards they made is bad for AMD.",
      "It is awful connector from electrical design standpoint - it promises more current through fewer thinner pins than 6+8+8 group of PCie power connectors. Any manufacturing imperfection - hello fire.\n\nSo, please, no.",
      "Reviewers are the only ones with the card. No consumer has it yet.",
      "If that is what you‚Äôd consider a big stink.. the world must literally smell like shit to you my dude.",
      "I think it's more just the \"here we go again\" attitude towards AMD. \n\nThere's the bad meme marketing (betting RX 6000 wasn't going to have availability issues, mocking Nvidia's RAM capacity, poor Volta). There's the unflattering positioning of products (7900 family competing with Nvidia's 80 series, rather than 90, 7600 being more like a 4050 Ti competitor). There's the BIOS issues with the X3D chips.\n\nThe 7600 reviews included inconsistent price messaging to press/AiBs, bad driver availability to press, and then the connect issue. There's just too much sloppiness in AMD's delivery of products, and it's seemingly gotten WORSE.\n\nRyzen did a good job of forcing AMD's into positivity among users and the press. That momentum's really slowed in the last year or so, and they're seemingly reliant on Nvidia's terribly pricing to carry them in sales. It just doesn't feel like AMD has a good grip on its customer base or its products. Having technical, marketing, and design flaws be what feeds the recent bias of the masses isn't good for business, even if this isn't a major problem in and of itself.",
      "I see the connector issue as a design issue. No one thought of users having to plug it in? What does RAM do when it's fully in? It clicks. What does 8-pin connector do? The plastic latch is engaged. Could pull on the cable lightly to check if it is all the way in or look/feel the latch position. What does the main PCI-E slot do when you insert a GPU? A latch locks the card in place. It is not coming out until you push on the plastic bit. If you can pull GPU out, it wasn't in correctly to begin with. Designs with user-error in mind.\n\nThe new connector? Are they expecting people to go in with a magnifying glass to see if it is all the way in? What do they expect?",
      "You're right. The 12-pin issue is still a problem on 4090s. Enough so that the topic is being revisited by YT reviewers and repair shops.",
      "No, he does not need insider info. The wording very much suggests that there are units out there with retailers that have this issue.\n\nEdit: if this was a pre mass production issue and affected only the cards sent to the reviewers, AMD would have just outright said it. Even better, they would have said that in the reviewer guidelines that they send to every reviewer along with the cards. No need to say \"will be fixed\".",
      "Why are you so defensive",
      "It‚Äôs a budget card and that standard is still being adopted. AMD wanted to make it compatible with non-ATX 3.0 compatible PSUs, knowing that the card is a budget one and most people who buy it will not have a ATX 3.0 compatible PSU."
    ]
  },
  {
    "brand": "amd",
    "generation": "7000",
    "tier": "low",
    "matched_keywords": [
      "7600"
    ],
    "title": "AMD Ryzen 7900/7700/7600 CPU pricing and specifications have been confirmed - VideoCardz.com",
    "selftext": "",
    "comments": [
      "So instead of a 7600X for $249 we can now buy a 7600 for $229\n\nby Grabthar's hammer.. what a savings",
      "MB prices are still thrash, unfortunately.",
      "On promo it will be $199 with cooler",
      "Pretty spot on price with extra cooler in the box. With cheaper ddr5 incoming, thw only hurdle is AM5 motherboard prices.\n\nHope A620 come sooner than later. AM5 Deskmini with 7900 on eco mode will be interesting combo.",
      "AMD has burnt a lot of my good grace they‚Äôve garnered throughout these past few years, but this isn‚Äôt that bad.",
      "Yeah but that's when the 5600 is EOL, not at launch.",
      "Incoming US prices.\n\nYou should mention EU prices for laughs and giggles :)",
      "AMD is delusional if they think that 7600 is \"competing\" with 13600. Maybe they have on par gaming performance, but 13600 is WAY ahead in productivity.\n\nAMD is slipping... again... ZEN4 are good CPUs, but the platform cost is outrageous. Radeon 7900XT is DOA and now this....\n\nI fear that we are looking at another ten years of Intel (and Nvidia) \"dark age\"....",
      "Considering they still have some competition in January, it _could_ be worse by then though, AMD's non-x vs. Intel's non-k:\n\nR5 7600 6c/12t ($229) vs. i5 13500 6+8c/20t ($2..?) \n\nAMD has pretty much given up on competing in multicore performance for the lower segments, they're not even trying to unfortunately",
      "I never claimed it was 2.5x faster. I just said it was faster. Everyone values their money differently.",
      "B650 wifi going for $169 already. The total system price is getting much better.",
      "Where ? \n\nShow me a decent ATX board under $200",
      "That's a two year old cpu though. It's fine but the 7600 is quite a bit faster. That might not appeal to you but I think it will appeal to others. It's good to have choices.",
      "They are improving",
      "It's still the cost of the motherboards that kills 7000 series for me. The cheapest one I can get in the UK is still ¬£175, for a bottom tier B650 M ATX motherboard that is still way too much.\n\nThere is just no semblance of a budget tier with 7000 series, and the high end gets beaten by Intel.",
      "Yeah Yeah ... keep downvoting.... It seems that you miss bulldozer days. By not accepting that AMD entered a slippery downfall, you are not helping them realize it and do something about it. AMD fans should first among others start yelling at AMD to fix the problems, fix the pricing etc.",
      "No b550 was $80 at launch. Y‚Äôall have a short memory. When b550 came out people were complaining and saying we should all just buy a b450. Who needs pcie 4.0 anyway. Lol",
      "The problem is MB prices but CPUs.",
      "Jan 9 release date is nice.\n\nLet's all pretend the x3D models release then instead of March.",
      "*\"Just visit you local MicroCenter\"*"
    ]
  },
  {
    "brand": "amd",
    "generation": "7000",
    "tier": "low",
    "matched_keywords": [
      "7600"
    ],
    "title": "AMD Radeon RX 7600 XT's China release date uncertain amid RX 6750 GRE series popularity - VideoCardz.com",
    "selftext": "",
    "comments": [
      "Wait a 16GB GPU at $300, why did this GPU not come out here ages ago?",
      "Needed to get rid of RDNA 2 inventory",
      "Illusion of choice. They wanted you to either spend $260 for the 7600 or cough up $450 for the 7700XT which they priced terribly in order to upsell you on the $500 7800XT with not much in between. \n\nAll while clearing inventory of last gen 6700XT in the $300 range. \n\nNow that inventory is drying up BOOM release a product to fill the gap and give it 16gb of VRAM for those who you couldn‚Äôt successfully upsell the 7800XT to.",
      "Texture settings usually don't cost much performance as long as you have enough VRAM. So this will let you run ultra textures for a long while even if you have to turn down other settings.",
      "if it comes with 40CU, its more like a 6700 XT with 16GB",
      "lol as if radeon marketing division was that competent.  or they were the top choice in gpus.",
      "Not quite. 7600 trounces 6600xt across the board. 6650XT is SLIGHTLY slower then the 7600, but they trade blows.",
      "Golden Rabbit Edition. Supposed to be China exclusive, but I can find all the gre cards in my home country (Southeast Europe)",
      "This is what I don't get, I feel like this 16GB will be used as a crutch to sell it at like $370, because you know, ain't nothing out there with 16GB of memory below $450. Memory is cheap, but that doesn't translate to better prices for us, that 16GB can justify at least a $50 up charge in the eyes of corporates, i don't want it if it means $50 more than what an 8GB card would've been, it's a 1080p GPU, would be nice if there was an option between both.",
      "4060 Ti 16GB enters the chat. $500 launch MSRP for 128 bit LMAO\n\nDamn, some people actually bought that. They got hosed so badly.",
      "They sell all their allocation just fine. Most of it goes to CPUs, consoles, and handhelds so they don't have that many left-over for GPUs. \n\nThey can't be any more of a choice than they already are since it would take years or decades to order more, receive more, and produce more.",
      "I'm looking to buy a RX 6700 XT next week, should I wait for this instead?",
      "But is it fast enough to make use of 16GB?",
      "Exactly.  I picked up a used 7600 and has been working really well as an experiment.  going to pick the XT Up and keep it as my primary machine.",
      "It's almost definitely a 7600 with twice the VRAM and like 10-15% better performance",
      "Its kinda amazing. when it comes to toyotas and japanese automobiles they took all the market by storm. But AMD's \"Toyota\" lineup AM4 and RDNA2 didnt dent the marketshare of other brands. and now AM5 and RDNA3 is fighting for the same picky buyer %20 that already upgraded leaving stock behind. I guess cars are more expensive entitites to push people into value products while Chips are just more like guccis?",
      "Did you forget about the ARC A770? 16 GB variant has been on sale for quite some time now. Can find them easily for under $300.",
      "Agree. Electricity cost is much cheaper in mainland China compared to a lot of states in Us",
      "The 7700xt is already a rx6800 so..",
      "This is a 7600 with dual sided memory dies. It's not 6700xt perf. It's 6650xt performance."
    ]
  },
  {
    "brand": "amd",
    "generation": "7000",
    "tier": "low",
    "matched_keywords": [
      "7600"
    ],
    "title": "Alleged AMD Ryzen 7900/7700/7600 non-X specs and prices emerge, launching in Q1 2023 - VideoCardz.com",
    "selftext": "",
    "comments": [
      "So wait.. The 7700 non-X is going to cost more than a 13600k, that's already better than a 7700x? Okiedokie.",
      "Prices are still not very competitive with intel.\n\n300usd 13600KF is faster than 7700X and it will be even more faster than 329usd 7700.\n\nshould be like this:\n\n7900X-470usd\n\n7900-400usd\n\n7700x-300usd\n\n7700-270usd\n\n7600x-230usd\n\n7600-200usd",
      "Cannot wait for the European 300 euros price tag for the 7600.... AMD needs to do better than that in Europe considering that the euro dollar change is not below 1 like when Zen 4 launched but it is now almost at 1.04",
      "Alright, give us some A620.",
      "Something something AM5 upgrade path.",
      ">13600K cost less and requires a much cheaper platform. 7600X and 7700X are DOA at the price points AMD set.\n\nThis is not universally true, it depends on your region. Where I live now the 7600X is around 60‚Ç¨ cheaper than the 13600K, which in turn is just 40‚Ç¨ cheaper than the 7700X, and similar motherboards are similarly priced. There are cheaper intel boards only because they have some barebones boards, which AMD doesn't (not yet at least), and those don't interest me. I also don't want DDR4 boards since that just gimps the 13600K, I would be much better off going for a 5800X3D  at that point.\n\nSo the total cost for a new 13600K ends up slightly higher than the 7600X (for the specific boards I would choose in each case), and slightly lower than the 7700X. So it really depends",
      "Prices would have been arguable if AMD outperformed intel this round, that's why people dealt with it with 5000 series. But now that Intel has caught up with two great generations of CPU AMD is gonna be dead in the water if they don't try to compete.",
      ">300usd 13600KF is faster than 7700X \n\nReally depends on the workload",
      ">Really depends on the workload\n\n13600K is faster in almost every workload except gaming where the difference is minimal. 13600K cost less and requires a much cheaper platform. 7600X and 7700X are DOA at the price points AMD set. The only option for AMD is to lower prices 7600X --> 200$ // 7700X 300$ in order to be competitive again. If they don't lower prices, then ZERO SALES aka CPUs will be collecting dust on the shelves for an eternity.",
      "My prediction.....the 5800x3d will be the best selling cpu of Jan 2023.",
      "Deepcool has an AK620 and an AG620 if you‚Äôre interested /s",
      "Gaming is what a large part of the audience cares about, but aside from that there are also Adobe, (some) compiling, and other workloads that benefit from faster cores more than a higher number of cores.\n\nBut yes, the pricing is not competitive, though the non-X might be (especially if all you care about is gaming). The prices shown in the article would **not** be **good** value compared to competition either though. Overall platform costs are starting to get comparable though, unless you accept the performance cost of going with DDR4 in which case Intel still holds the edge.",
      "Q1 2023 is barely two months away, dude.",
      "AMDiscount is best feature that AMD has.",
      "The biggest concern with these prices is it implies the x variants stay where they are which means the 3d will be priced crazy and likely not have a value story",
      "This gen is going to hurt AMDs position as ‚Äúthe value brand‚Äù, Intel was smart to add DDR4 support, because people look at the benchmarks with DDR5, but the prices with DDR4.\n\nIt‚Äôs a stupid trick, but most people won‚Äôt feel the difference anyway.",
      "Motherboard prices are still shit in EU so it's hard to justify buying AM5 at this moment.",
      "With 1x ram slot, atleast you still have dual channel with ddr5",
      "They are fantastic coolers for the price though. On par with the NhD15 for about $64.99 Msrp",
      "The way I see is AMD needs to come out with some good CPU + MOBO bundles that are well priced to win back some of the community. Otherwise I ain't moving from my 5900X and B550."
    ]
  },
  {
    "brand": "amd",
    "generation": "7000",
    "tier": "low",
    "matched_keywords": [
      "7600"
    ],
    "title": "How is Radeon RX 7600 XT ?",
    "selftext": "I was looking for a 16 GB vRAM GPU. Shell-shocked to see one available for $350.  \nHow is Radeon RX 7600 XT compared to 4060 Ti and 5060 Ti 16 GB variants?",
    "comments": [
      "maybe wait for the 9060 xt?",
      "It's a 7600 with 16 GB VRAM. It's slower than the 4060 ti and 5060 ti.",
      "Wait for 9060 XT if you want AMD. 7600 XT was all all right but it was a little expensive for what you got.",
      "The 7600XT is not perticulary fast.\n\nThe 4060TI is 30% faster in 1440p, the 5060TI nearly 50%.\n\n350 is not a great price for a 7600XT when you can get a 5060TI for 100 usd more.\n\nBut i would wait for the 9060XT and look at performance and prices compared to the 5060TI.",
      "As a 7600 base user, I'd recommend wait for 9060 XT.",
      "If you are thinking about using it for 1440p gaming, you'll be bitterly disappointed. Maybe 1080p. But its still a 7600 XT. Slower than 4060Ti and 5060TI.\n\nMaybe try and shoot for 9060XT.",
      "yeah this \\^\\^"
    ]
  },
  {
    "brand": "amd",
    "generation": "7000",
    "tier": "low",
    "matched_keywords": [
      "7600"
    ],
    "title": "PowerColor preparing Radeon RX 7600 Fighter V2 graphics card",
    "selftext": "",
    "comments": [
      "If it was the XT model with 16gb, I'd expect quite some demand. \nThis card? Maybe OEM gamer PCs. But these won't take power Color cards.\nMaybe a bigger micro Center sale?",
      "Pass",
      "For some reason the Fighter version of RX 7800 XT has been a popular seller online here in Malaysia. I guess there's an oversupply of that.",
      "Don't know why did they change the design of the shroud. I have 6800 Fighter, and it is an amazingly good-looking minimalistic card. No RGB, no bold color, black brick with 90deg angles everywhere, same with other Fighters, either 2-fan or 3-fan black bricks.",
      "My current GPU is an 8GB RX580 I bought for $180 or $190 in late 2018. Which struggled to beat out the 3 GB 1060 and was itself just a warmed over RX480. Still, the value was decent. \n\nSurely there must be other PC folks who just want to be able to game but don‚Äôt care about ultra high settings or ray tracing. All I want is a sub-$200 card that is not *objectively terrible*. This looks like it could be it, though who knows with the current GPU shortage?",
      "Why not 7600 XTX locked at 1.2V with a 5090 cooler on it, probably 8% faster than XT üò≤ /s (but also not /s that would be funny as hell they should do it)",
      "Them fighters, consume less power than others and perform same although a bit hot.",
      "The 580 8GB is quite a bit faster than the 3GB model,  and the 6GB model is overall slower than the 580."
    ]
  },
  {
    "brand": "amd",
    "generation": "7000",
    "tier": "low",
    "matched_keywords": [
      "7600"
    ],
    "title": "306012gb oc(280‚Ç¨) or 7600 xt 16gb (380‚Ç¨)?",
    "selftext": "I feel like buying a graphics card suck rn but since nvidia is gonna end support for gtx cards its time for an upgrade. Any suggestions are welcome ofcourse!",
    "comments": [
      "At 1080p, a RX 7600 XT is about 30% faster than a RTX 3060 in pure rasterization. That‚Äôs a pretty big margin.\n\nNeither GPU is really strong enough to effectively employ ray tracing, but they perform about the same when it‚Äôs turned on.\n\nAbout the only thing that the 3060 has over the 7600 XT is DLSS in games that support it.",
      "Check 6700xt or arc580 prices they would give more performance, and at least in my country both can be found for about as much as or less than a 7600xt  so check if its similar for you",
      "At those prices I'd buy used lol.",
      "I just upgraded my two rigs with a rog strix 3060ti for 225‚Ç¨ and a gaming x slim 4070 for 475‚Ç¨. Buy used, dude.",
      "fsr3 is pretty good though. dlss isn‚Äôt a necessity.",
      "How is 7600x worse than 6700xt? 7600xt is newer right?",
      "6700xt is twice the price here. Lowesr ive seen is 550‚Ç¨",
      "Look at the hardware, 7600 is a warmed up 6600.  6700 is in a higher class of cards, much more performance.",
      "Which country?",
      "Netherlands",
      "6750xt is ‚Ç¨374 on amazon",
      "6750XT is very close to a 6800 in performance, I would get the 6750XT out of all these.\n\nIf you can find a used 3080 for these prices, get that instead.",
      "Ive been doing some research and the 6650 xt looks alot beter for the price(270‚Ç¨). Its a 100 buck less than 6700xt and the fps diffrence is about 10 depending on the game. I play games at 1080p because thats the my monitors res and it seems to perform good."
    ]
  },
  {
    "brand": "amd",
    "generation": "7000",
    "tier": "low",
    "matched_keywords": [
      "7600"
    ],
    "title": "[Optimum Tech] Everyone Loses. - NVIDIA 4060 Ti vs. AMD RX 7600",
    "selftext": "",
    "comments": [
      "Optimum Tech is an amazing channel with really high production quality.",
      "This generation has just been one big L for both AMD and NVIDIA.\n\nFor AMD, the only cards that make sense are MAYBE the 7900XT for high-end 1440p gaming - and even that could be achieved by a 6950XT or 4070 Ti, and the 7900XTX if you want great 4K gaming, and even then $1000 is a big premium for a card that should be $800 max.\n\nFor NVIDIA, the only cards that could make sense are MAYBE the 4070 for 1440p gaming, DLSS3 and AV1, which even then is $600 and also too much... and the 4090, which is so expensive that most people would never be able to afford it.\n\n4080 is WAY too expensive, you could buy a 7900XTX for cheaper and get around the same performance, and those who have that much money to spend on a video card will just get the 4090 instead because they likely have enough to buy that anyways.\n\n4070 Ti is too expensive and won't be enough to play at 4K with higher texture quality settings due to the 12GB of VRAM. For 4K gaming the 7900XT with 20GB is a far better buy as it has the VRAM to last far longer at that resolution, and even for 1440p gaming you could just get the regular 4070 and have a good experience with the AV1 encoder and DLSS3.\n\n4060 Ti is a joke in every way.\n\nI know people are gonna point out how I own a 4070 Ti and that i'm a hypocrite.\n\nAdmittedly I have a bit of buyer's remorse, and if I knew the 4070 would be so inexpensive compared to the Ti model I would've waited and bought one. I love my 4070 Ti and all, but it's not worth a $200 premium over the regular 4070. But the thing is, I wasn't sure if the 4070 would be any good or not back then, and I doubt most people did either. For all i'd know it could've had 8GB of VRAM, and/or be slower than a 3070 Ti (which it wasn't). But i'm happy with my card even though it's not good value. All I need now is a CPU upgrade, maybe just get a 10900 because I don't want to swap motherboards.",
      "It's also one of the very few large tech channels that don't do sponsorships.",
      "Probably my overall favorite channel esp for his itx builds. He‚Äôs the main reason I went out of my way to buy a used Meshlicious and ITX mobo when I had a perfectly good ATX mobo and NZXT H500i üíÄ",
      "Same performance for the same price is a terrible letdown. Not as terrible as worse performance for the same price of course but still bloody awful. Add on top the existence of the superior 6700 10GB at the exact same price point and it really is awful.",
      "Because both are equally disappointing for very similar reasons in their respective price points.",
      "I'd say the 4060 ti is probably the worst one. Same performance, same price. 7600 at least had the decency to have a lower MSRP, but it shoulda been an additional 20$ off.",
      "There's something about a compact ITX build, so satisfying packing a lot of power into a small box",
      "Honestly, his slides are so well made",
      "It's not a direct perf comparison despite the title\n\nJust a 2 in 1 review",
      "This is what I don't get: Who is out there that is UPGRADING to a 1080p setup? Isn't that what most people play at already? How much of a market can there be for people who are playing at 1080p right now, but would spend $300-$400 to STAY at 1080p and just get better fps? Even if that market did exist, why on earth would you buy one of these new cards rather than buying a used 1080ti or something like that for less money and as good or better performance? I just don't get it.",
      "Yeah he's got impeccable taste and his videos are so aesthetically pleasing it trounces on channels with way more production budget.\n\nPlus he actually games on his setup, which adds a TON of credibility. Everytime I see LTT review CSGO playing against bots I cringe so hard. I will never trust anything they say because they obviously don't play games.",
      "Launching at same time with same memory buffer, and honestly, price-performance ratio is actually not too far apart.\n\n4060ti is 30-40% faster and has some extra features, for 50% more money. It really does come to a fairly similar value in the end.",
      ">I love my 4070 Ti and all, but it's not worth a $200 premium over the regular 4070.\n\nBe glad the price difference is only $200 because here in Finland the price difference is 300-400‚Ç¨, which is ridiculous",
      "[He does not.](https://youtu.be/hfqCVAXjDRM?t=386) Content creators are legally obligated to disclose sponsorships.",
      "I just have to ask because I can't remember correctly. When the 1060 launched, was it able to play everything on high in the current games? \n\nI'm not saying that top tier cards prices arent outrageously overpriced, but I remember when I got a 970 not everything was playable at 1080 in max settings for example. \n\nDo I just have a wrong memory of this? These cards can both deliver well over 60fps in all current and demanding titles at 1080p and a lot of titles with 1440p",
      "He does game with the hardware and that gives his reviews a lot of credibility.\n\nWhat makes his build videos quite unique is the ussage of high end components with real world settings for cooling and noise reasons. \n\nWe have enough other popular techchannels with automated benchmarks and metric generation that talk 30 minutes nonstop about their own pretty looking charts, without mentioning what it means for the gaming experience, **because they dont know**.",
      "Take a look at steam survey, target are those juicy 1650, 1060 and so users. But they will move (probably) to 4060.",
      "He's reviewing those two options, and they are both losers.",
      "1060 was not. Almost nobody ever has expected the 60 class cards to play anything on max settings ever for 1080p back in the day."
    ]
  },
  {
    "brand": "amd",
    "generation": "7000",
    "tier": "low",
    "matched_keywords": [
      "7600"
    ],
    "title": "RX 7600 XT 16gb vs RX 6750 XT 12Gb vs RTX 3060 12Gb vs RTX 4060 8 Gb",
    "selftext": "I don‚Äôt know shit about graphics cards, but I need to buy one. After doing some research on my own, these are the four options I came up with for something around 350‚Ç¨. But as I stated before, I don‚Äôt know shit, and there seems to be a lot of discourse about which is the better option, so I hope one of you who‚Äôs more knowledgeable can enlighten me.",
    "comments": [
      "6750xt is the fastest card in non ray tracing workloads, and has a good balance of vram to speed. 4060 is second fastest but suffers from 8gb vram, it will be OK at 1080p wouldnt go 1440p on it though. Some games can really suffer from the 8gb not all though. The 7600xt and 3060 12gb are about the same speed, the 3060 has the benefit of dlss. The 7600xt 16gb seems nice but it's not really fast enough to play games in a scenario where you would need it. \n\nTldr: I would get the 6750xt if you can still find it for a good price.",
      "If you video edit/ professional 3d work etc., 3060 12gb, otherwise if you're just gaming no rt it's the 6750xt",
      "Gaming? Go AMD. If you can swing a 7700XT it would be insanely good. 7600XT is right behind it, so that‚Äôs fine as well. Definitely not Nvidia in this price range.",
      "What resolution?\n\nThis changes things a little but if it were me I'd play @1440p and I'd pick the 6750XT if prices are okay still with low stock. \n\nOtherwise it would be the 7700XT id budget allows, if not a 7600XT",
      "In that forget Nvidia. The 760pxt will play 1080p very well and do ok in 1440p compared to the 6750xt, that does very well 1440p and has great p2p",
      "Picked up the 6750xt during the holidays. With a 7600x3d, it dominates at 1080 ultra on everything. Space Marine was the toughest title so far,  with average FPS in 70, with dips into mid 50's. Tried it at 4k with Space Marine, and managed an average 60 on low and medium settings with quality upscaling. Most other titles are 100+ fps ultra at 1080.\n\nNot telling you to trust my feedback alone, but I debated my options at length during the building process, just check my post history. The 6750 XT smokes the rest of your options if NVIDIA luxuries are not needed. I purchased at $320, and given the market at the time, it was evenly priced with the rest. I don't know how prices have fluctuated, but be aware that the 7700 XT has come down to $350, and if it's within your budget, you should pick that up instead, if the price difference isn't significant.",
      "It‚Äôs mostly for gaming but I‚Äôd also wanna do some video editing and do some hobby 3d work is the 6750xt still the best option?",
      "assuming you don't make money video editing them yeah sure",
      "Nah I don‚Äôt just for personal enjoyment and potentially social media preciate the help tho also the 3060 is like 40‚Ç¨ cheaper at 320 does that change anything",
      "nah it don't. 6750xt can be anywhere from 30% to 100% faster than the 3060",
      "Alright last question before I press order we‚Äôre both talking about the rx 6750 xt mech 2x 12gb (refurbished but don‚Äôt think thats an issue) cause there is also a 6750 trio",
      "generally a 3 fan should always cool better than a 2 fan card but you should only get the trio if it's the same price as the xt mech",
      "Nah the trio is almost twice as expensive unless I buy a second hand one really appreciate the help man"
    ]
  },
  {
    "brand": "amd",
    "generation": "7000",
    "tier": "low",
    "matched_keywords": [
      "7600"
    ],
    "title": "AMD Radeon RX 7600 Graphics Cards Review Roundup | VideoCardz.com",
    "selftext": "",
    "comments": [
      "Just get a 6700 10GB for $10 more and avoid VRAM bottlenecks at 1080p, at least for the foreseeable future.",
      "This is how duolopolies are supposed to work",
      "This gen is laughable.",
      "I'm going to learn Assembly and go to volunteer at Intel to improve their graphics drivers just to get revenge on Nvidia and AMD.",
      "nvidia is passing off tiny dies as midrange and AMD is basically just re-releasing last gen.",
      "6000 series Reign supreme i guess.",
      "Meta-review analysis: It's trash, don't bother.",
      "The price to performance ratio is really pretty OK on this one. It outperforms the 3060 pretty consistently, which is more expensive. Same with the 6600XT. It has a large generational uplift over the 6600 (seems like around 30% on average) while being in the same neighborhood on price.\n\nI know it's fashionable to hate on GPU manufacturers this month, but really....cmon....this card isn't that bad. For $270, it's not hard to recommend.\n\nThe embarassing part is that AMD's business side seems to be floundering.",
      "That is a second duolopoly...only tsmc and Samsung as distant second.  Just like nvdia with amd distant second.  Nothing stopping both from peak milking.",
      "Get the 6700 it‚Äôs better. It‚Äôs like 7% better than this card and it has 2 Gb more of VRAM. \n\nBest of all[it‚Äôs the same price](https://www.amazon.com/XFX-Speedster-SWFT309-Graphics-RX-67XLKWFDV/dp/B0BCL3L6ZG/ref=asc_df_B0BCL3L6ZG/?tag=hyprod-20&linkCode=df0&hvadid=616157467664&hvpos=&hvnetw=g&hvrand=4639726762715373912&hvpone=&hvptwo=&hvqmt=&hvdev=m&hvdvcmdl=&hvlocint=&hvlocphy=9016793&hvtargid=pla-1840123877710&psc=1)\n\nSeriously. Get this card before stock runs out.",
      "Hmm, and someone with a new build in the works, this isn't making me want to chose this card over a 6700 or 6700xt, especially if the later two get a bit of a price drop.\n\n&#x200B;\n\nNot to mention, why get this over a 4060 in July?",
      "I in fact just ordered that one to replace my XFX Radeon 580.",
      "Functionally a monopoly*. AMD's market share has been shrinking, so it's likely they're gonna go under 10% if they're not there already.",
      "i would say the 7600 is aggressively uninteresting, whereas the 4060ti's are both actually insulting.\n\nAMD needs comes out with a $349 16GB 7600XT that lands within 5% of the 4060tis performance for the current market to be interesting at all, they could probably get away with $399 for that though considering how charged the market is against the 8GB 4060ti",
      "Drop the price to $200.",
      "Which will be extremely more efficient. I mean, the RTX 4060ti is already more efficient than the RX 7600.",
      "I‚Äôm not surprised and never was because AMD, for the past several years looking at the comment section of previous GPU releases, only meets what Nvidia offers.",
      "Not a huge concern for me though, i've plenty of power to spare in my rig.  \n\n&#x200B;\n\nBut more concerning is the 4060ti is like 25-50% faster, and even if the 299 model is half that, that's still a significant bump for only $30 more.  \n\n&#x200B;\n\nNot to mention it's competing against the older 6700 cards which offer great value for the money at 1080/1440 p.",
      "alright im in too",
      "There is no rule on split.  Nvidia is almost a monopoly"
    ]
  },
  {
    "brand": "amd",
    "generation": "7000",
    "tier": "low",
    "matched_keywords": [
      "7600"
    ],
    "title": "How do we feel about the RX 7600",
    "selftext": "Is it good? Bad? Good for the cost?",
    "comments": [
      "For 1080p it‚Äôll be great. I have a 6600 and I only max out the vram in forza motorsport with maxed out settings. For 1440p I‚Äôd definitely consider something with more vram.",
      "man agreed, i wanted the b580 too if i had a choice. Nobody in Denmark wants to buy my RX6800 tho :D",
      "Among the best for that price range is the B580, if your CPU is relatively recent (Intel drivers use up more CPU). If you can manage to get a B580 I highly recommend it, good VRAM for the price, good raster performance, good RT performance (unlike the AMD offerings), usable upscaling, and I've heard that frame generation is also okay if it is implemented. Even if XeSS is not supported you can fall back to FSR like the older non-RDNA4 cards",
      "It's a good 1080p GPU. Goes for around 260‚Ç¨ in Germany. You can't max out the settings though, in newer games gonna have to play on medium settings and or fsr.",
      "Great 1080p value.",
      "Great 1080p GPU as long as you can find it for around $250-$270",
      "If you're still on 1080p it'll do just fine. Put together a parts list for my friend who desperately needed an upgrade. He is now on a Ryzen 5 7600x and an RX 7600 as he needed a budget build and RX 7600 was the only thing available at a decent price at the time. If you can find the Intel Arc B580 for MSRP then I would recommend it more but it is usually price hiked pretty egregiously.",
      "It‚Äôs decent compared to other cards in the price range. Intel has an edge with its new card. Nvidia sucks in this price range. If you can push for a 7700XT I would 100% recommend that card.",
      "i just got it.  afmf2 witcher dx 12 1440p high 165 fps sub 150 watt power draw.  in short, it rules.",
      "We feel that the B580 eats the 7600's lunch and it's not even close.",
      "8GB vram is terribly minimum, some newer games will literally not launch with med-high settings especially if you have raytracing enabled. The 7600xt seems decent but I wouldn't be sure if it'll perform well in 1440p considering the low memory bandwidth. \n\nRemember, its not about FPS, its about the frametimes. the 4060 suffers from sheer stuttering. \n\nAs a 3060 user I am doomed for the theoretical 2 years or so (depending if prices will go down). I'm stuck with this card and there is no other option unless we're selling my internal organs. Intel did release a beast of the name B580 and I'm honestly considering it despite the major driver issues.",
      "I think the 7600xt has a 16GB version just like 4060ti"
    ]
  },
  {
    "brand": "amd",
    "generation": "7000",
    "tier": "low",
    "matched_keywords": [
      "7600"
    ],
    "title": "AMDs RX 7600 is the most underrated graphics card right now!",
    "selftext": "",
    "comments": [
      "I love reviews like this that look at the  card from the perspective of what it's target audience is and not trying to compare it to $1000 cards and 4K ultra resolutions.",
      "You can get a 4060 for around $280 now so I don't know how you justify 7600 for $10-$20 cheaper tbh. This needs a price drop down to around $230 or so.",
      "Not with 8GB of VRAM. RT is hit and miss and Frame Gen can cause performance regressions when you run out of VRAM.\n\nPersonally if DLSS / RT / Frame Gen are important factors the lowest priced card worth buying is the 4060Ti 16GB. You can run stuff like Ratchet & clank at 1080p RT on at 60 + fps (unlike the 8GB model which drops way below 60 with horrible lows) and you won't have to turn textures down in future titles so you can maintain a more stable frame rate and higher IQ for a lot longer.\n\nIf you want a cheap stop gap card then the 6600 is the way to go IMO and then you hope RDNA 4 / Blackwell offer a reasonable perf/$ uplift at the low end while bumping up VRAM a bit to avoid the issues 8GB cards currently have and will continue to have going forward.",
      "It‚Äôs aight 6600 is the monster, back when it was consistently 180 that is.",
      "Go for 4060 at that price difference. You will get DLSS, better efficiency, and can also do RT at 1080p if you care about it.",
      "I think 6700XT will hold on pretty well so if that is an option at a similar price to the 7600XT I can see arguments either way. Me personally would go 6700XT because the extra raster performance will come in handy and 12GB of VRAM is pretty well balanced at that performance tier right now.\n\nOTOH if you like large texture packs then the 16GB on the 7600XT may serve you better so like I say at the same price there are arguments either way.",
      "By not maxing every setting?",
      "You have 16 gigs of vram, my G. 8 gigs is not enough for RT TODAY let alone in 2032, that is an objective fact.\n\nhttps://www.youtube.com/watch?v=Rh7kFgHe21k",
      "3060 had higher fps in hogwarts than the 3080 10 gb before they changed it to lower texture quality and not render things properly instead. So it still has better visuals on a 3060 than a 3080.\n\nhttps://www.youtube.com/watch?v=Rh7kFgHe21k",
      "Most don't have huge vram impact, mainly textures, FG, and RT. And lowering textures makes everything look like cheeks while also having 0 impact on FPS unlike other settings (as long as you have enough VRAM).\n\nSounds great to buy a brand new GPU and hit the ground running by then dropping textures to 144p. Especially great advice for someone who kept their last GPU for 8 years. Will you even download the texture pack in 2032? Or just delete it?",
      "7600 XT, due to the 16 GB VRAM, but sure. I wouldn't recommend 7600 non XT in 2024.",
      "Yep. Blows my mind as a hobby we've forgotten the very old adage - Ultra settings are placebo and you'd be mad to base your whole life and soul (and benchmark) around those almost universally insane and unrealistic settings, unless you have a fetish for photo mode or something.¬†\n\n\nSwitch games to High or even Medium and you'll have almost the same visuals for a vastly faster (say that three times fast) frame rate.¬†\n\n\n(And cos nowadays we all play at being closest academic markers who need citations, look at the mountain of Digital Foundry videos comparing the different quality modes and the frame rate and visual impact thereof to see that, aside from maybe pop in which even happens on Ultra settings these days anyway, there's bugger all difference between High and Ultra, even Medium, and certainly not noticeable if you're actually playing the fecking game).¬†\n\n\nSo yeah. Switched to High settings the 7600(XT) suddenly is well above the magical 60fps barrier and with the ram looks like a good long term bet. That and the underutilized, for now, AI cores, which I do think will be used by a future FSR variant, and all the weird posturing and dismissals by YouTubers, and forum posters will be quietly forgotten in a years time I predict...\n\n\nAlso forgotten by all these supposed professional reviewers is - in High mode, and some of the more recent games in the last couple of years, the 7600 is within a hairs breadth of the 6700xt which is exactly where it sits in relation to their sales price, so the recommendation to just buy that instead isn't as much a better value for money proposition so much as it is bang on the upgrade. (Having said that in older games yes it is a larger jump. Again though for someone like me so wanted a card that could work with a smaller PSU, have 16GB, and potentially have some of that sweet sweet AI core action, and not living in the US, the 7600XT isn't some horrific purchase.",
      "The 7600 is 298‚Ç¨ in my country vs the 4060 for 312‚Ç¨. I've been meaning to pick one of those since my 1060 is dying, but can't really decide. You think the 4060 is better, or should i go for the 7600?",
      "If you want to keep a card as long as your 1060 has lasted no 8GB card will do it and I personally think the 3060 12GB is a little too weak. Options are basically 7600XT / 6700XT depending on price in your region or you spend a bit more a jump to the 4060 Ti 16GB / RX 6800 depending on if RT / DLSS are important to you or if pure raster performance matters more. For a stint as long as the 1060 I think DLSS / RT / Frame Gen may be more beneficial than a bit more pure raster performance but that is your call to make really.",
      "I wasn't looking too much at vram since i don't play graphically intensive games, mostly indie and competitive shooters. The 6700xt is within my budget but since i will be keeping a new card for at least 5 years i wasn't sure if buying a one that's already 3 years old was a good idea. Guess i'll think about it some more.",
      "you should always use upscaling with RT at every resolution, and dlss is fine at 1080p. Not quite as good as native but 30% faster is still an objectively reasonable tradeoff to make, and it‚Äôs not the same thing at all as fsr completely losing it at 1080p.\n\nif you would consider the tradeoff of FSR 2.x acceptable at 4k, in terms of visual quality loss - that's probably roughly where DLSS quality is at 1080p.  But people seem to think the latter is an unacceptable tradeoff while loving the former.",
      "10%, sometimes, right now, doesn't mean a whole lot when it will last longer in time due to VRAM and better driver/features support.",
      "7600XT isn't worth the $80 premium it currently sits at ($250 vs $330), there's also still a 6700XT you can get for $330, in either case the 7600XT makes absolutely no sense.",
      "> can also do RT at 1080p \n\nHow will you do RT with 8 gigs of vram, lol? The real answer is get neither. Either wait or get a 3060, 6700 xt, or 6800. 8 gigs of vram is beyond cheeks now let alone in 2032.",
      "You could get the 4060. Mainly because it sounds like you are a fairly casual user and the 4060 has very low power consumption compared to the 6700 xt. A quieter card and less hot card is less issues to deal with.\n\nThe 6700xt is overall faster and better and should have an easier time running games down the line.\n\nCheck out this video that directly compares the 4060 to the 6700xt. https://www.youtube.com/watch?v=QI0GS0IBMoI"
    ]
  },
  {
    "brand": "amd",
    "generation": "7000",
    "tier": "low",
    "matched_keywords": [
      "7600"
    ],
    "title": "Sapphire Radeon RX 7600 PULSE review",
    "selftext": "",
    "comments": [
      "tl;dr\n\nBooo AMD. Booo.",
      "Why did they make a GPU that performs the same as the model it's replacing?",
      "> significant efficiency gains\n\nPer the article:\n\n7600 idle power consumption: 11w\n\n660xt idle power consumption: 7w\n\n7600 typical gaming power consumption: 160w\n\n6600xt typical gaming power consumption: 165w\n\n7600 max gaming power consumption: 199w\n\n6600xt max gaming power consumption: 186w\n\nPerformance per Watt:\n\n7600: 0.31 frames/Joule\n\n6600xt: 0.30 frames/Joule",
      "It's cheaper to make and has AV1 encoding. Also, there are some AI cores, but they aren't utilized yet.",
      "I like how they have ditched awards for reference(?) cards.",
      "Only guess new arch that allows newer tech? \n\nOther than that, same reason car manufacturers make a new model each year.",
      "Lower power and the addition of Ai cores.  One thing that interests me is that when AMD first started shipping their Zen architecture CPUs based on chiplets, performance was still a little behind Intel.  When Zen 2 launched they closed the gap, and then passed them with Zen 3 and 4 (more or less).  I think that there's some learning that takes place in the transition to the chiplet design, and I'm hopeful that the Radeon RX7000 series basically their GPUs version of Zen 1.  When we get to the 8000 and 9000 series I'd hope to see them more on par with nVidia.",
      "> significant efficiency gains.\n\nThat's gotta be a joke, right?",
      "RX 7600 Pulse - Video Playback 32W\n\nRX 6600XT Pulse - Video Playback 10W\n\nRDNA 3 has issues..",
      "\\- It doesnt perform the same, it is a bit faster in RT and at least somewhat faster in Raster vs the 6600 XT (full Navi 23) and 6650 XT (OCed Navi 23 with better bandwidth)\n\n\\- It replaces the RX 6600 which is now a fair chunk (but still not monumentally!) slower\n\n\\- it is slightly better in perf/watt\n\n\\- It is cheaper to produce actually. So that benefits AMD too.\n\n\\- Gets more people on a new RDNA3 arch over RDNA2\n\n\\- AV1 encoding.\n\n&#x200B;\n\nGranted it ultimately ISNT much. I agree. But it is not nothing.",
      ">ngreedia\n\nThat's putting a hat on a hat. \n\nThey're named after invidia, the Roman personification of Envy. That's why their branding is green and their logo is an evil eye.",
      "Ha, reminds me of the Vega \"they haven't unlocked the full card performance yet, just wait for new drivers\" nonsense.",
      "It's a Rx6600 replacement with ~6650xt performance for 6600xt power consumption.\n\nIt's a decent 200$ card.",
      "This thing sucks as bad as ngreedias last backhand",
      "SHAME, AMD. SHAME. \nFixed it for you.",
      "As far as I know although AMD marketting states there are 'AI' cores there is no new hardware that will actually make these gpus better performing for AI work.",
      "I think they mean insignificant",
      "I have actually done some Assembly testing, and the new matrix ops allow my 7900XTX to go to \\~120TFLOPs FP16. These instructions actually do something.",
      "6700 has better performance + 10 gb vram, and has a 250 and 270$ model on newegg.\n\nPlus I just picked up a used 6700 xt for 220$. This would be interesting at 199-229, not 269 (nice).",
      "Because the one that it's replacing is discounted a lot from when it came out?"
    ]
  },
  {
    "brand": "amd",
    "generation": "7000",
    "tier": "low",
    "matched_keywords": [
      "7600"
    ],
    "title": "The reason why locked i5s are obsolete. R3 1200 OC vs i5 7600",
    "selftext": "",
    "comments": [
      "Half the price but only 5% behind. Ryzen 3 is definitely a much more appealing option than the i3/i5s",
      "Surprised it hasn't been shared, before now. But yes, overclocking potential is always the best.",
      "The best part is that an oced r3 is cooler than the lowest clocked kabylake i5 on stock cooling. Take a look at this [1300x vs 7400](https://youtu.be/bhJXvN4fldM?t=2m21s) comparison.",
      "That's some good glue they got there.",
      "Unlocked i5s should be obsolete as well. For now at least.",
      "So you are saying that the i5 was already obsolete before ryzen due to the Intel celeron.... k",
      "Poorly priced is a better term.",
      "Any locked cpu should be obsolete.",
      "I would think \"unlocked\" i5s are obsolete more than locked i5s.\nThere's still a market for locked i5s.  The 90% of (mostly office) desktop users that:\na) Don't overclock\nb) Care about lightly threaded (<4T) workloads\nc) Need an iGPU\n\nDoesn't mean they are worth the money, but a $180-220 locked i5 does compete reasonably well with a Ryzen 5 (wins some, loses some depending on the flavor of R5 and the benchmark itself).\n\nhttp://www.anandtech.com/show/11244/the-amd-ryzen-5-1600x-vs-core-i5-review-twelve-threads-vs-four",
      "the big ass 110$ vs 219$ in the fucking thumbnail?.",
      "It(i5s costing a boat load) lost because a R3 1200 can be had for $100. What are you on crack?",
      "For lightly threaded workloads you probably aren't considering an i5 but an i3/Pentium.",
      "So which celerons are unlocked? And where are the benchmarks?\n\nI tried to do a quick search and found nothing so far. Ryzen 1200 seems like a safer bet since it actually has 4 real cores compared to celeron.",
      "The thing is the overclocked r3 is cooler than the stock i5 by quite abit. Scroll down and see my reply to another comment to see the results. So in this case the overclocked r3 is actually better than the i5 even in terms of efficency.",
      "Yep, but unlocked i5s are getting wrecked by the r3's brother, the r5s :)",
      "Not when it is worse than a overclocked temp at stock..",
      "Actually you insulted OPs intelligent by implying that he has an agenda and I asked if you we're on drugs or not? I don't care either way, i5 is obsolete  because anyone can order a R3 1200 on eBay for $100. Case closed.",
      "It's definitely not, but a 7600 cost 220 and an r3 1200 is 110. You're literally paying twice the money for 5% more performance.\n\nThe 5% I was stating reffers to performance, not price.",
      "You are the kind of consumer that nVidia and Intel target with their weird graphs, you don't pay attention.\n\nThe i5 wins on every test by 5% at the most. The R3 sells for $110, the i5 sells for $220. The locked i5 at double the price for 5% is the wrong choice. But hey, Intel can still make profits from consumers that can't read, sad to say but that's a lot of people.",
      "5% better, yeah. It's up to you to decide if the premium you pay is worth it."
    ]
  },
  {
    "brand": "amd",
    "generation": "7000",
    "tier": "low",
    "matched_keywords": [
      "7600xt"
    ],
    "title": "Should I get a Rtx 4060 8gb or a Rx 7600xt 16gb ?",
    "selftext": "I currently have a 1660 super and I want to upgrade to a better gpu but don‚Äôt know what to chose.I want to stick with nvidia but 8gb of vram is not enough at this time and getting the 16gb ti version is way more expensive.I found this 7600xt for 319 USD and i don‚Äôt know if i should get it.What is better or more worth it ?",
    "comments": [
      "DLSS can be turned off. VRAM can‚Äôt be added.",
      "Very personal decision, sorry but some people want the DLSS and others want the VRAM.",
      "I am saying that for future games the 4060 makes no sense.",
      "No games need dlss. It‚Äôs a nice to have. It doesn‚Äôt matter as much as you think it does when you have a 4060.",
      "Cyberpunk is an outlier more than anything. And it‚Äôs just Ray tracing its ridiculous and even an 4060 will shit itself trying to run RTX.",
      "6750XT",
      "I went for Vram. I Started to look at the 7800xt (ended at a 7900xtx sice i suddenly had 400usd extra to burn). I would never go for a card with less than 16 gb Vram, it is 2025.\n\n In that price range i would seriously look at Intel ARC aswell, seeing the A770 Titan at 430 euro ish here.",
      "the more vram it has, the better it ages\n\ndefinitely 7600xt 16gb",
      "? I'm saying if you prefer DLSS the 4060 is better.",
      "Well not exactly, because some games need the DLSS more than VRAM, even future games.",
      "Not true. If your game is struggling to run at 1080p then DLSS can help. For VRAM shortage you can turn textures down.",
      "And so can FSR‚Ä¶ yes, DLSS is better. VRAM is more than textures. Personally I would buy neither but people do have different budgets.",
      "Wait until you see some games with normal AA vs. with DLAA. Even at normal res, RTX cards have a big advantage in alot of games. Like Cyberpunk."
    ]
  },
  {
    "brand": "amd",
    "generation": "7000",
    "tier": "low",
    "matched_keywords": [
      "7600"
    ],
    "title": "Can the AMD Radeon Rx 7600 handle 3 monitors",
    "selftext": "My 3 monitors are all 1920 x 1080, 60 Hz. can the AMD Radeon RX 7600 handle that?",
    "comments": [
      "For general use sure, that's 3/4 of 4k and integrated graphics can support that. If you wanted to game on all 3 at once I'd expect it to struggle",
      "dw i aint got the skills to play 3 games at once xD. I assume a game on one, youtube on the ohter and a brower on the 3rd will be fine?",
      "Honestly, you're lowballing the 7600 by only using 60Hz monitors. The only limits to running multiple monitors on modern GPUs are the amount of display outs and desk space you have, you can use multiple monitors of much higher refresh rates if you want to.",
      "Yes even Intel integrated you can do 6 monitors",
      "I would upgrade to atleast an UW 144hz",
      "ah ok thats good to know. I dont quiite have the budget for better monitors atm but its good to know im not stressing the gpu out. My friend warned my 3 monitors could do that so i wanted to check. Thank you",
      "Lmao i don‚Äôt think there‚Äôs that many display ports unfortunately üòÇ",
      "Yeah shouldn't be an issue. The browser and YouTube will need very little GPU work, the game will be the only high demand.",
      "People have tested this before. It does stress the GPU out more... by like 2-5%. It's a negligible difference.\n\nIf you're tight on a budget, I'd recommend buying 1 or possibly 2 mid-range monitors over 3 lower-end ones.",
      "1 Display ports can be used to run multiple displays and then USBC also",
      "ok, thank you. I know very little about PCs so i just wanted to check cuz my friend said it would stress the gpu",
      "are mine considered low end?",
      "Well yeah, 1080p 60Hz is not seen as anything particularly decent these days.",
      "ah ok, as long as it wont significantly damage the gpu im ok with slightly worse monitors"
    ]
  },
  {
    "brand": "amd",
    "generation": "7000",
    "tier": "low",
    "matched_keywords": [
      "7600"
    ],
    "title": "AMD *Almost* Learned Something: RX 7600 Reference Card Tear-Down",
    "selftext": "",
    "comments": [
      "Good video but the title is an unnecessary snipe when Steve had no major complaints about the cooler.",
      "Classic for gn",
      "I made a post on r/hardware recently about how GN has turned to being a lot more sensationalist and the amount of very odd and long-winded comments doing mental gymnastics to defend them was insane. A lot of it could be summed up as \"you're just bored or aren't smart enough\" or everyone's favorite go-to: \"Corporations aren't on your side\"... Yeah, I know companies aren't on our side lmao. Constantly taking shots at companies when it isn't warranted ruins your brand. Luckily, and somewhat surprisingly, it seems as though a silent majority agrees.",
      "They never really explain themselves. Maybe they mean the thermal pads to the backplate. \n\nGN like to be super nitpicky over some odd stuff. By their own admission, the backplates rarely make a huge difference unless the OEM fucks up like MSI.\n\nI dunno, GN always seem like people who are just disappointed with everything. Like some kind of hardware induced depression.\n\nThe card is fine at its price point and is built well enough. Could be cheaper I guess, but then so could everything.",
      "I thought this card was only for reviewers.\n\n**Edit:** ~~Yeah, apparently it won't reach retail, unless AMD decide to change that too:~~ [https://twitter.com/harukaze5719/status/1661368140645670916](https://twitter.com/harukaze5719/status/1661368140645670916)\n\n**Edit2:** It seems that info was inaccurate:\n\n\" CORRECTION:  Previous tweet that AMD won't sell RX 7600 MBA, confirmed to be incorrect. It doesn't apply in global market\"\n\n[https://twitter.com/harukaze5719/status/1661738080427200512](https://twitter.com/harukaze5719/status/1661738080427200512)",
      "It's the main reason I struggle to watch GN despite how good their content is, Steve is too much of a snarky asshole for me.",
      "That‚Äôs actually a bummer, considering it‚Äôs a good design and also good looking. Honestly they‚Äôre missing out on another good way to make some money.\n\nNow that I think of it, putting that much effort into a reference card to send to reviewers and not even sell it kinda odd to me. Maybe an OEM issue that they didn‚Äôt wanna produce any?",
      "I wish EVGA transferred to making AMD cards, they were one of the best aibs",
      "I still give GN my view, but I admit I watch the intro and just skip to the conclusion now. I watched the full lawyer episode and he came off as a petty trying to get the lawyer to basically say \"ASUS is admitting guilt\" through some indirect no-eye-contact befuddled wording. I've never owned an ASUS product, I have no care/love/interest for ASUS, but Steve handled that whole situation poorly. New information made his statements wrong or inconclusive, and in the end him rolling out his watchdog program on the heels of this made me question his integrity.\n\nHis ego is definitely getting out of control. But I guess that's what it takes to survive in this Youtube/Influencer world.\n\nOh well, will continue to give clicks until he completely goes over the edge (or gets pushed off it) haha.",
      "What did amd almost learn?",
      "Honestly they're really starting to become more clickbaity.",
      "No wonder reddit likes gn",
      "Nah let the card manufacturers make the cards. Better for the ecosystem. It‚Äôs basically an opposite position of Nvidia. Their goal is to only make reference cards. EVGA won‚Äôt be the last to jump off the bandwagon",
      "I feel like we are part of the minority, but i can't stand him. Must be working for him considering the view counts and the amount of praise I see on reddit about him though.",
      "I rate his content highly, but he‚Äôs had ego problems for a while now though.\n\nI noticed it first when he made the ‚ÄúRyzen is smoother‚Äù video criticising Reddit users for claiming how Ryzen (1st gen) ran smoother compared to their previous Intel setup and how he felt like that was a total lie and blind fanboyism. \n\nBut he didn‚Äôt take into account that the majority of those comments where from people who moved from 4C/4T Intel to 6C/12T Ryzen or even more and they were simply seeing better frametimes due to better multi core utilisation (which he verified to be the case in his own review). \n\nHe just misunderstood what Redditors meant and  was ultimately very harsh on them for ‚Äúlying and being fanboys‚Äù and he didn‚Äôt really consider a more nuanced view. That is simply very sensationalist and shows an ego.",
      "",
      "> They never really explain themselves. Maybe they mean the thermal pads to the backplate.\n\nIt looked like there were 4 mem chips, in pairs, two at the top, and iirc two on the right, and there was one pad on the back in both those locations...\n\nI think people are disappointed it's performance isn't closer to something like a 6700 or 6800...  But it's still 1080 ti performance for $270...  But I'm happy I got a 6650xt for 250.",
      "You guys are insufferable. If a YouTube channel favors AMD it's your go to channel but let them make one video where they're positive about Nvidia and they are biased all of a sudden.",
      "What are the alternatives in terms of price and performance? Intel?",
      "That's one thing that some reviewers really have a hard time grasping. When they're comparing one platform to the other, they usually just compare the high-end and forget that the average user will most likely be using an i3/i5 or Ryzen 3/5 instead of the higher end. Like you said, going from a lower Intel to the Ryzen 5 1st gen was night and day, even though Ryzen wasn't that mature back then."
    ]
  },
  {
    "brand": "amd",
    "generation": "7000",
    "tier": "low",
    "matched_keywords": [
      "7600"
    ],
    "title": "AMD Radeon RX 7600 XT review: double the memory and higher clocks, still Navi 33",
    "selftext": "",
    "comments": [
      "6700xt died for this",
      "Eywa children",
      "from laughter ?",
      "What's Navi?",
      "At least it won't be bottlenecked by a lack of VRAM.....",
      "honestly r/amd seems a lot more butthurt over it than r/hardware or other \"mixed\" subs lol.\n\nkinda feels like at this point everyone else is fairly sanguine that prices are gonna trend a bit upwards over time, while the AMD fans are still upset it's not $249 for 16GB and $199 for 8GB or whatever impossible standard they're using this week",
      "My problem with the card is that it's not a true XT model. \n\nUsually a non XT is clearly a GPU with cut corners and the XT is an upgrade with more cores, higher memory bandwidth etc. \n\nThis time it's just the non XT with 16G instead of 8. \n\nSo it's not a true XT card for me",
      "The Na'vi (English: The People) are a species of sapient humanoids who inhabit the lush moon of Pandora. Although the Na'vi are hunter-gatherers with technology equivalent of Earth's Paleolithic epoch, they are highly intelligent. The Na'vi and tulkun are the only known extraterrestrial species discovered to have a level of sapience equivalent to humans.",
      "Names for radeon chips",
      "you can simplify it to Navi= RDNA. gen 1, 2, 3 (5000,6000,7000) You really dont need to go deeper than that unless you want to start learning the individual chip names ie navi 33",
      "Ohh okay, so RDNA3 is the architecture used by the chip navi33, which powers the Rx7600xt & others...\n\nAnd the post tells, that it still uses navi33 (which implies RDNA3). I get it a bit now!. Thanks for explaining!.\nu/LordTism u/Westdrache",
      "Navi 33 is the name of the chip that's used in production of 7600 XT, 7600, 7600 laptop version, 7700S laptop version.\n\nOther GPUs are made with other chips. 7700 XT and 7800 XT are made by using Navi 32, 7900 XT and 7900 XTX are made by using Navi 31. They're all RDNA3, so all use Navi 3_ naming. Previous gen used Navi 2_ , andone before that used Navi 1_",
      "Dude, the lower tier offerings by both NVIDIA and AMD are garbage, the main difference between the two is that AMD isn't asking 500 fucking bucks for theirs and that AMD actually puts decent amount of VRAM in theirs lmao (in all of their line up, not only the 7600 XT). With a 2060S I'm not even interested in low tier cards, I'm certainly not interested in a 4060 Ti 16GB with just a 30% performance uplift from a 2060S at 500 bucks. I'm interested on the other hand in a 7800 XT or maybe even a 7900 XT if prices go slightly lower for it. I'm certainly not interested in a 700 bucks Super duper 192 bus 12GB 4070 which VRAM gets eaten up in Phantom Liberty even at 1080p. Get the stick out of your butt.",
      "Effortless and irrelevant card.  \nThis is lazy even for AMD.  \n7700 when?",
      "üôáüôá\nThats a lot of info for my two brain cells.\n\n>they are highly intelligent. \n\nI see, I ain't one.",
      "why even bother moving the goalposts? accept that you were wrong and move on.",
      "No not really, GPU naming schemes are .... Fucked up to be honest.\n\nThe architecture of those (current) NAVI chips are based on is RDNA3 one specific chip is Navi33 and one of these chips powers an rx7600xt (among other graphics cards)\n\nIt doesn't get any easier with Nvidia tbh,\nTheir current architecture is called ada-lovelace one of their chips is called AD102 and it powers the RTX 4090",
      "> A A770 is worse than a RTX 2070 \n\nThat's not even remotely true.\n\n[https://www.techpowerup.com/review/asrock-arc-a580-challenger/32.html](https://www.techpowerup.com/review/asrock-arc-a580-challenger/32.html)\n\nUsing TPU's A580 review because it has relatively new drivers used for Arc (though there have been some big driver improvements since), and actually lists the RTX 2070 in the charts.\n\nA770 = RTX 2080 > A750 = RTX 3060 > A580 = RTX 2070",
      "Hey, Listen!",
      "Dont need to go that far back, there is the 4060ti 16 gig"
    ]
  },
  {
    "brand": "amd",
    "generation": "7000",
    "tier": "low",
    "matched_keywords": [
      "7600"
    ],
    "title": "AMD's New $230 Ryzen 5 7600 CPU | Review & Benchmarks (ft. PBO)",
    "selftext": "",
    "comments": [
      "\\-25w\n\n\\-15¬∞c\n\n\\-70$\n\n\\-1% gaming perf\n\n\\-5% overral\n\n&#x200B;\n\nindeed an overral better CPU imho vs X",
      "These should be out day one.\n\nBut you still have to contend with still not-so-great mobo prices and still expensive DDR5.",
      "Its a good price for a good CPU that should see it stack up favoribly vs the 12400F/13400F. \n\nThe problem remains with the MB's. When a decent non horibly gimped B650 board costs the same as the 7600 CPU itself then we have a problem.\n\nAlso watching some other reviews for the 7700 and 7900 its painfully clear this is what AMD should have released on launch. A 7600, 7700 and 7900 at their prices are all decently competitive against the 13400F, 13600K and 13700K in a way the original models that were priced a tier above where they should have been arent.",
      "Asrock riptides are $170, for 95% of people, they're more than enough",
      "Man I love how hard hitting the 5800X3D is in gaming in comparison. Got mine for $330.",
      "Atleast you can put that extra 70$ into a mobo.... /cry",
      "Exactly. Ddr5 prices has already gotten reasonable enough, but motherboard prices hasn't even budged at all.",
      "They are 250usd in the eu, for that price u get a great z690 board like the mortar.\n\nRiptide b650e and lightning x670e - the cheapest x670e (310 usd) are asscheeks looking barebone mobos that arent worth the price, id rather burn the money.\n\nA good x670e like the asus tuf is 350 usd, for that price u get an overkill z690.\n\nAm5 is only for hardcore amd fanboys at this time.",
      "Realistically, you'd be spending about $550 for a b650 riptide board and 32GB of 5600 ram if you went with the 7600",
      "Wouldn‚Äôt even stress about it with a 3060, the 5700X is still a great cpu for the price.",
      "13600k performs similarly to a 7700x, the 7600x/7600 is a performance tier down and will be competing with the 13500",
      "It's $171/‚Ç¨159 here in Denmark. You have to account for the US price being without VAT.",
      "X is basically what ‚Äúfounders‚Äù edition used to be. The the opposite of kickstarter whereas you get a discount for being the first, you pay privilege for being the first.",
      "Not sure the 6600 sucks ass.   Its almost 1080ti performance level.",
      "Am4*",
      "I'm running a $159 Gigabyte board and I'm getting full speed from everything.\n\nNot really seeing the problem.\n\nMotherboards are the biggest brainwashing that exists right now.  Talk about putting your money somewhere that doesn't contribute at all to performance.",
      "I would argue that \"**Most**\" people barely use 1 SATA port, they would probably have an NVMe SSD for OS/Games and maybe an SATA 2.5\" SSD/ 3.5\" HDD for \"stuff\". 4 SATA ports would be enough for 99% of users. \n\nIf you need more storage, you are more likely to buy a NAS rather then shove 6 HDD inside your PC. Yes there are people that do exactly that, but they are not the majority, and even then -  you can always buy an LSI HBA on ebay",
      "Microcenter has the 7700X including 32GB of DDR5 6000 for $344. Very attractive until you start looking at motherboards and realize a decent B650 board is still going to set you back close to another $300.\n\nFix the board prices AMD/partners, then you won't complain about slow AM5 adoption.",
      "$175 sounds right.",
      "The 5800X3D is exactly why I invested in AM5.\n\nBeing able to just drop in a latest gen CPU and get additional life is amazing."
    ]
  },
  {
    "brand": "amd",
    "generation": "7000",
    "tier": "low",
    "matched_keywords": [
      "7600"
    ],
    "title": "RX 7600 Full Review - Max 1080p in 2023",
    "selftext": "",
    "comments": [
      "Once the 6700 and 6650xt are gone this might end up being decent value for anyone still on mid-range Pascal and Polaris.",
      "It‚Äôs amazing for $150-200 and it‚Äôs good for $200-250. Anything over that isn‚Äôt worth it",
      "If you only had 270 maybe you'd consider it",
      "It's good for $150-$199, 3060 $199 and 3060Ti $250.",
      "$130 is a lot of money for people gaming as a hobby my dude. Also, this GPU is brand new with guarantee and all that.",
      "I hear you, and you're right to an extent, but someone looking to buy a sub $300 GPU isn't going to spend $400.",
      "This, people somehow think that PCIE 3.0x8 is a bottleneck but the reality is, it's going to be insignificant.\n\nThere was a 3090 PCIE scaling done and PCIe 2.0x16 was only 5% lower.\n\nhttps://www.techpowerup.com/review/nvidia-geforce-rtx-4090-pci-express-scaling/28.html\n\nA 4090 doesn't lose that much performance at PCIE 2.0x16. Not like you would.be buying a 4090 and running on a PCIE 2.0 platform anyway but it shows in gaming that PCIE bandwidth isn't much of a limiting factor.\n\nAnd before people are claiming that it matters when your VRAM limited, sure it would, but you wouldn't be getting acceptable performance at the settings that would fill up VRAM and force constant swapping. You would already be tuning down settings anyway.",
      "I'm currently running a Ryzen 5 2400G with an RX 570 with 4gb of vram that I picked up for 180 bucks at the beginning of the pandemic.  I'm currently looking at upgrade paths.  This card in the 200-300 dollar range is very tempting but I'm not sure if my cpu can keep it fed so that's why I'm also considering a cpu upgrade as well",
      "The RX 7600 has only 8 PCIe lanes. Since your CPU (and likely also the mainboard) only does PCIe 3.0, you will have a bottleneck there and maybe see stuttering when the bandwidth isn't enough.\nAn ARc 750 or RTX 3060 wouldn't have that problem.\nBut also, the 2400G will probably be the limiting factor for any of these cards.",
      "Vid in OP has a section comparing pcie 3 and 4 performance. Difference isn't as big as one would expect.",
      "There's a section about pcie 3 vs pcie 4 performance. You may have skipped it.",
      "It was nowhere near 15% faster when it launched it was closer to 8%. Drivers have significantly improved it since then but at the time it launched no one knew that would happen so the 2060 Super was a solid competitor.",
      "There was literally a slide about that there.\n\n7600 ran mostly at same performance on PCI-E 3 and 4, except losing few percent in Horizon Zero Dawn.",
      "Knowing AMD price trend, it's probably going to be $200 a few months down the road. So I guess there's a positive thing about it...",
      "The problem i see here is that all cards were tested on a modern PCIe4 system. I i had a RX 480/GTX 970 and would be looking for an upgrade, the RX 7600 would perform worse than expected due to having only 8 PCIe3 lanes available.",
      "It won‚Äôt be because that market is already saturated. Anyone that wanted that level of performance for that amount of money already bought one of the 2 cards you mentioned. But I definitely see this card as great value once it drops to sub $250 in a few months, just in time for the old gpu stock to dry up",
      "It is a great card it is just getting shadowed by the 330$ 6700xt you can get in the us",
      "Because 1 the cheapest 6800 is $475, and 2 that‚Äôs in a completely different price bracket. Now you would have a great point if you said I can buy a 6700 for $280, why would I buy this.",
      "As someone who ran a 2400G previously, buy both a new GPU and a new CPU. The difference is night and day.",
      "The 6700 doesn't cost 200‚Ç¨ more.\nFor just 50‚Ç¨ extra, you can get a RX 6700 with 2GB more RAM, better performance and a full PCIe interface."
    ]
  },
  {
    "brand": "amd",
    "generation": "7000",
    "tier": "low",
    "matched_keywords": [
      "7600"
    ],
    "title": "Why are people mad at rx 7600?",
    "selftext": "I live in brazil so we are very poor the minimum wage is like 265 dollares it will probably be selled at least 325 dollares here for me the rx 7600 is a gpu stronger than ps5 one but much cheaper with that it will probably be able to do a 500 hundred dollars pc that match the ps5\n\nIts cheap its rdna 3 its good i guess amd should have named it rx7500xt everybody would have get it but now it has the 6 in the name so everybody is mad\n\nAbout the vram for me its developer fault if they cant run 1080 ultra on 8gb the xbox series s even if its dosent play 1080 ultra it is a lot weaker devs should be able to optimazed for that",
    "comments": [
      "I would recommend you look at the product yourself and:\n\nif it fits your needs and your budget: go for it!! \n\npeople will always complain about stuff... and most reviews I see are made for a US/Europe audience with more money than the lot of us that live in \"poorer\" countries. :)",
      "It‚Äôs not horrible but it‚Äôs not great. It‚Äôs a bit faster than old gen, better ray tracing, better encoding, still 8gb of vram, and higher power consumption at a lower msrp. People will complain. Seems to me like they all want a $200 6800xt equivalent.",
      "let's ignore all that happen in the past 7 years and pretend that a 40 bucks increase is unreasonable",
      "> all want a $200 6800xt equivalent.\n\nNo, people expected 6700 performance at 300$. Instead they got 6650XT performance at 10 - 15% higher prices.\n\nAMD should have done what NV did with the 4080 12G: unlaunch it, cut prices and sell it one tier lower - where it belongs.",
      "Because its AMD and they will always get shit on no matter what they do lmao.\n\n\n7600 gets setup against the 6700 because.... Only AMD should be forced to beat a 700 class with an entry level new Gen.\n\n\nMeanwhile Nvidia happily throws a 4060Ti on the market which costs more than a 3060Ti an loses against it. AGAINST ists own fuckin counterpart from last Gen, it doesnt even reach ANYWHERE close to the 3070,yet gets sold at close to 500 fuckin dollars.\n\n\nMeanwhile 7600 beats the 6650XT, evens out against the 6700, while using less power and bringing a better encoder, RT performance and raster.\nShOuLD bE a 199 dolLaR caard!!!!!!\n\n\nLaughable how paid off this shit actually is.\nJust watch the end notes of the 4060Ti reviews and then 7600.\nOMG AMD TERRIBLE!!!!! Meanwhile Nvidia gets a slight slap on the wrist from them.",
      "Well it used to be that we were seeing generational improvements. Let's use Nvidia as an example because before the 6000 series AMD didn't really have any high end card offerings for a long time. The 1060 was on par with the 980, the 2060 was comparable to the 1080, the 3060 was close to the 2080. But now suddenly we should be happy if a card is more than 5% better than its last gen version or that it can barely match a card from last gen positioned just above it?",
      "> Because its AMD and they will always get shit on no matter what they do lmao. \n\nNot when there's a legion of AMD fans supporting AMD's every move. \n\n>7600 gets setup against the 6700 because.... Only AMD should be forced to beat a 700 class with an entry level new Gen. \n\nNo, the general rule is that the previous generations 'next level' card should be around the same as the new generations card, for example a 3070 should perform as good as a 2080, the 2070 should perform as good as a 1080, the 2060 as good as the 1070, etc etc. Both the 4060TI and the 7600 fail this, which is why people are upset over the stagnation of value. \n\nHowever reviews are primarily looking at it versus the equivalent last gen to highlight the lack of performance increase. \n\n>Meanwhile Nvidia happily throws a 4060Ti on the market which costs more than a 3060Ti an loses against it. AGAINST ists own fuckin counterpart from last Gen, it doesnt even reach ANYWHERE close to the 3070,yet gets sold at close to 500 fuckin dollars. \n\nThe [4060ti](https://www.techpowerup.com/review/nvidia-geforce-rtx-4060-ti-founders-edition/34.html) performs 12-6% better than the 3060ti in raster and 20-15% better in RT.  \n\nThe 4060ti performs 100-90% the raster performance of the 3070 and the same in RT. \n\nIt's MSRP is 400 dollars. You can buy a 400 dollar Gigabyte 4060Ti right now, on B&H. \n\nLiterarily everything in that paragraph, except for the 4060TI being more expensive than the 3060TI (which they both had the same MSRP, just the 3060TI is discounted cuz last gen) is wrong. \n\n>Meanwhile 7600 beats the 6650XT, evens out against the 6700, while using less power and bringing a better encoder, RT performance and raster. ShOuLD bE a 199 dolLaR caard!!!!!! \n\nThe 7600 performs essentially the same as the 6650xt in raster, and 100-90% the RT performance of the 6650xt. \n\nTechpowerup found 15% better efficiency in CB, Techspot/HWUB found no real improvements to efficiency.  \n\nIt should definitely be priced, at least the same, as the 6650xt to see a gain in perf/dollar vs last gen. Problem is that I can go get a 6650xt for 250 bucks at amazon, right now. So if I buy a 7600 for 270 dollars right now, I would essentially be paying \\~10% more for a better encoder, and in some cases worse performance than if I went for the 6650xt. Even worse, I can get a 6700 for 280 bucks, 10 dollars more, with an extra 2GB of VRAM.  \n\n> Laughable how paid off this shit actually is. Just watch the end notes of the 4060Ti reviews and then 7600. OMG AMD TERRIBLE!!!!! Meanwhile Nvidia gets a slight slap on the wrist from them. \n\nNope. The 4060TI got flamed as well. \n\nThe fact that this comment is getting upvoted despite having so much info just completely wrong is beyond me, and just goes to show how when people act like AMD is the scapegoat of the PC gaming community, even when it isn't, people go out of their way to updoot and agree, while ignoring the rest of the comment, which has information that is just factually incorrect.",
      "you know you can get 6700 performance for 300 buying a 6700 right?",
      "Nah. I live in Taiwan and the prices for most of AMD 6000 GPUs just wouldn‚Äôt drop. Thus the 7600 actually kind of make sense here. It has been long that we got a decent GPU priced under 9000 NTD.",
      "The 2080 was right between the 3060 and 3060TI. The 3070 was competing with the 2080TI",
      "Not sure in Brazil but the previous generation 6700XT can be gotten for the same price as a 7600 and performs better (50% bigger bit bus and VRAM as well).",
      "This. Everyone keeps repeating just buy the 6700 non-xt instead. I can't even find one here and I can buy from 3 countries thru friends and relatives lol and the rest of the 6000 series' prices aren't dropping either.",
      "Are you comparing pricing to current 6650xt pricing? Cause it‚Äôs cheaper than the original 6600 isn‚Äôt it?",
      "Don't compare it to the 6600 but to the 6600 XT, which is the predecessor. Same performance, same price (or worse), same power consumption. Essentially a rebadge.\n\nThe naming is artificially shifted from 7600 XT to 7600 to make it look like a bigger jump.",
      "Because there is little to none generational improvement, which to be fair the 7600 should be more directly compared to the 6600 not the 6600 xt, 6650xt. Naming scheme aside the performance should be better especially when there's plenty of last gen stock around that preform the same if not better for a better price",
      "WTF are u talking about?  \n6650XT has the same specs with 7600 and we should compare it to weaker 6600? Only because AMD called it 7600 without XT and lowered price?  \n\n\n7600 is 6650XT on 6nm with better RT cores - this is only difference",
      "Then it's a relatively good product for Brazil. That doesn't change the fact that it's a bad/mediocre product in places where 6700xts can be found for around $300.",
      "The cheapest RX 6700 actually costs [340‚Ç¨](https://www.mindfactory.de/product_info.php/10GB-XFX-Radeon-RX-6700-Speedster-SWFT-309-Core-Gaming-GDDR6_1477805.html) in Europe, while the RX 7600 \"only\" costs 300‚Ç¨. But the 6700 is discontinued, so there are not many left. That's by far the cheapest RX 6700, other sellers charge 370‚Ç¨ which is the same price as the RX 6700 XT.\n\nBut the RX 7600 is in the reviews often closer to the [RX 6650XT](https://webshop.asus.com/de/90YV0HS2-M0NA00/ASUS-Dual-Radeon-RX-6650-XT-V2-OC-Edition-8GB-GDDR6-Gaming-Grafikkarte) which only costs 250‚Ç¨. So what am i getting for those 50‚Ç¨ more?\n\nIn RT it's often beaten by a [269‚Ç¨  RTX 3060](https://www.notebooksbilliger.de/inno3d+geforce+rtx+3060+8gb+twin+x2+lhr+784362), and if you really wanted that, the 329‚Ç¨ 4060 will definitely be the better choice anyway.\n\nAMD may have lowered the price, but i still don't see why anyone should buy this card. It's too expensive for what it actually can do.\n\nAnd i don't see why anyone is even trying to defend a card that has so much trouble beating the XT variant of the last gen. It's not FX-level horrible, but it's far from being good or even just ok.",
      "We are one of the worst country in the world to do business to much regulation and we tax like first world country its a nightmare openning business\n\nUsed market gpu is strong in brazil but we buy from china(Aliexpress) but thanks to the northeast region who voted for the left the government want to raise tax in Aliexpress too\n\nOur government sucks",
      "I dont think there is going to be an XT version"
    ]
  },
  {
    "brand": "amd",
    "generation": "7000",
    "tier": "low",
    "matched_keywords": [
      "7600"
    ],
    "title": "When do you think they'll announce the 7600 XT or the 7700 XT?",
    "selftext": "Since the 7900 series is releasing in December does that mean we're going to hear about it in January? Just wanna know your thoughts on this.",
    "comments": [
      "Navi 21 (6900 XT, 6800 XT, 6800) was announced in October 2020.\n  Navi 22 (6700 XT) was announced in March 2021.\n  Navi 23 (6600 XT) was announced in July 2021.\n\nWith Navi 31, AMD chose to release all variants of the chip as 7900. Because it's a smaller chip than Navi 21 (so probably better yields), AMD might not see a need to release a further cut down variant.\n\nSo I'm guessing that Navi 32 will be used for the 7800 XT. Then its cut down variant will either be a 7800 or 7700 XT. It would also depend on what NVIDIA does with the former 4080 12GB and how Navi 32 compares to it in performance.\n\nNavi 33 might be 6700 XT or 6600 XT, or both.\n\nFor release dates, I'd guess that AMD will tease Navi 32 at CES and provide more details later in Q1.\n\nMy feeling is that AMD has an incentive to have a shorter release cycle with this generation, both because it can beat NVIDIA in value and because Navi 33 will be a better use of the 6/7nm production lines than RDNA 2.\n\nEdit: Forgot to say that Navi 33 has been rumoured to be mobile first, and this makes some sense. There's some chance that we will see it announced at CES for mobile alongside next gen mobile CPUs.",
      "If they want to sell a lot of cards, they better release those cards before NVidia sells all their 3000 series stock.",
      "7800 series in February\n\n7700 series in April/May\n\n7600 series in July/August\n\nThese are my predictions.",
      "I swear the last two crypto-booms ruined the market indefinitely in terms of expectations.\n\nThere's nothing great about 6900 XT performance or better for anything more than 500$, considering that card should have been 699$ when looking at 6800 XT's performance.",
      ">Imo the interesting GPU worth waiting on is the 7800xt. If it can hit a $699 MSRP and outperform a 6900xt, in at least a few games, that's exciting.\n\nIdeally, we'll get a 72CU Navi 31 part for the 7800XT that will do more than outperform a 6900XT in a few games, for $700.\n\nJust matching or slightly beating a 6900XT for $700 would not be exciting, that'd be quite disappointing, given how close the $650 6800XT already was to a 6900XT two years ago.\n\nYour standards are way too low.",
      "There is no massive 6000 stock. They could stop producing them right now and go full 7000 series, it would be even wise since chiplets use less of 6nm wafers each.",
      "Once the 6000 stock gets liquidated",
      "It seems they are keeping the same prices as the original 6000 series, so the 7800 XT might be $649?\n\nI don't know what could be the MSRP for the rest of the lineup, since all cards released during 2021 had inflated launch prices already reflecting the crypto craze.",
      "Don't expect that. Navi 31 shows that they used 96 CUs to achieve 1.6x 6950XT.\n\nWith 32 CUs of Navi 33's 7600 XT (just 1/3 CUs of 7900 XTX), you're looking at something like 30-40% less performance than 6950XT, or roughly 6700-6800 level of performance.",
      "As soon as 6800/6900XT stock is gone and people arent buying all of the 7900XTX anymore",
      ">So I'm guessing that Navi 32 will be used for the 7800 XT. Then its cut down variant will either be a 7800 or 7700 XT. It would also depend on what NVIDIA does with the former 4080 12GB and how Navi 32 compares to it in performance.  \n>  \n>Navi 33 might be 6700 XT or 6600 XT, or both.\n\nThere's a big gap in specs from N32 down to N33, so I'm expecting AMD to possibly require three Navi 32 variants to fill out the stack.  \n\nAlso Navi 33 wont be the 7700XT.  It'll have to be 7600XT or below or else the performance improvement will look pitiful.",
      "Based on the benchmarks I have seen for the Ryzen 7000 integrated graphics you are going to get better performance from almost any dedicated GPU released in the last half decade, and even the weakest RDNA3 card (or RDNA2 for that matter) should crush it in gaming.\n\nThe integrated graphics may make Ryzen more appealing to businesses, but really should not be a factor for gaming.",
      "There's a big gap, but it's actually smaller than between Navi 21 (80 CUs) and Navi 22 (40 CUs). The lowest end Navi 21 had 60 CUs, 50% more than a full Navi 22. I think it's reasonable for AMD to release a 60 CU Navi 22 and a 48 CU one with a 192 bit RAM bus, and then the difference between 32 CU Navi 33 and the 48 CU SKU would be 50%, which won't be higher than the Navi 22 to 21 gap.\n\n> or else the performance improvement will look pitiful.\n\nYou mean like the 6500 XT over the 5500 XT? Hasn't stopped AMD before.\n\nIf a 60 CU chip is 7800 XT, then a 32 CU chip could be 7700 XT. That's very close in ratio when compared to the 72 CU 6800 XT and 40 CU 6700 XT. So I wouldn't rule it out.",
      "Yeah with higher clocks. I‚Äôm still expecting the 7800xt to beat the 6950xt and 3090ti in raster",
      ">There's a big gap, but it's actually smaller than between Navi 21 (80 CUs) and Navi 22 (40 CUs).\n\nAnd that's why AMD had three Navi 21 variants rather than just two! \n\nBut that's at the high end.  There tends to be far more granularity in the lower-mid range markets.\n\n>You mean like the 6500 XT over the 5500 XT? Hasn't stopped AMD before.\n\nThe 6500XT would never have been released in the desktop space if not for the wild cryptomining craze that drove GPU demand to infinity, which meant that desperation for GPU's increased prices of even lower end GPU's a huge amount.",
      "3-6 months but you could get a 6800 in the $400-$500 range right now and get similar performance except maybe in ray tracing but if fsr 3 works on RDNA 2, then it will get a boost in performance, too. \n\nImo the interesting GPU worth waiting on is the 7800xt. If it can hit a $699 MSRP and outperform a 6900xt, in at least a few games, that's exciting.",
      "my guess   \nMarch  Radeon RX 7800/XT ‚Äì $699   \nRadeon RX 7700/XT ‚Äì $599  \nJuly Radeon RX 7600 ‚Äì $350  \nRadeon RX 7500 ‚Äì $250  \nPersonally not waiting &  not buying current gen from retailers, used Market will be a rude awakening for Nvidia  & AMD  \nbig Mining Operations  &  Oxygen deprived miners are Hedging against inflation with GPUs hahaha",
      "Nah, AMD wants N33 out as soon as possible, at least for laptops, so it should be released in January, N32 by all rumors should come later than N33, so probably March-April",
      "Nvidia will sell their entire stack regardless.\n\nThough imo they should be competing with the 3000 series, offering cards that are better for value, but they did that with the RX 480 and I guess the mid-range community didnt come out in support.\n\n\nFlagship Ethusiasts might be the ones keeping AMD up.",
      "That would look badü§î the 7800xt only being 15% faster than the 6800xt"
    ]
  },
  {
    "brand": "amd",
    "generation": "7000",
    "tier": "low",
    "matched_keywords": [
      "7600"
    ],
    "title": "AMD Radeon RX 7600 reference card pictured, shorter than 21cm - VideoCardz.com",
    "selftext": "",
    "comments": [
      "Surprised they are even doing a reference model",
      "What do you mean its short? Thats normal sized right?",
      "it's actually pretty huge",
      "Probably, but rn it is the only new low-end card. \n\nI am still debating inside my head whether or not to buy an rx 6650 xt or an rx 7600 for linux gaming + jellyfin server.\n\nAV1 encoding is quite attractive‚Ä¶",
      "NICE and very unexpected... if one DP2.1 also comes as a USB-C(like on 7900XT and XTX) I will need to buy one xD",
      "Guys‚Ä¶this is nothing to compensate about",
      "It's just another guy brainwashed by the current marketing push of 12gb GPU as a minimum for 1080p",
      "What games and what blur are you talking about?",
      "A hd 7950 was roughly $605-665 in todays dollars. So about the price of a 6950xt is today. I could argue this is bullshit or this is about right depending on my feelings as a consumer and this is a very hot topic depending on where you're coming from. \n\nAs a gamer...we're getting pretty ripped off with the latest gen. The last decade's top end is now the price of this decades previous grn top end. Which is horrible.\n\nOn the other hand, as a content creator, I can get so much more out of consumer based cards today, the premium is well worth it.\n\n Also, as long as your card has a significant amount of RAM, today's mid to top end cards should last a lot longer. DLSS and FSR are game hangers for many who can't upgrade every gen or every other gen. Granted, again...you make the choice to get a card with a lot of vram. Im more pissed off about the stingy vram availability on cards today vs pricing honestly.",
      "Shit I would buy that for an SFF system that card probably kicks ass!",
      "The 7600 and 4060's will probably be the worst selling cards in both amd and nvidias history",
      "Same here",
      "Fair point, it's unfortunate we're in a position where wage levels need also consideration. Add in the fact that R and D is flying through the roof in costs, bidding for fab orders is becoming insane, and random issues like trade wars and teriffs can change at any second and we got a shit show.",
      "Tbh, it makes the most sense to do a reference model on the cheapest SKU's since you need the vertical integration to keep the floor costs down.\n\nOtherwise, you end up in the same situation the 6500 XT is right now.",
      "So the 4060 is ok priced then?\nIt‚Äôs 299",
      "No it leads to making 16gb piss low end cards with an extra 200$ added to the price tag.",
      "Yep, its a GPU",
      "wow its my size",
      "Is this satire?",
      "Kind of. In a lot of industries yes. AMD posted a better than expected 8% loss. Intel losses were pretty bad along with Nvidia. Tech is pretty much down across the board as the era of almost free loans is over and demand is lighter after everyone was trying to get whatever they could during the pandemic. I think they're toying around with what they can get away with price wise to try to buffer the losses. Hopefully it'll lead to better prices in the consumer section on mid and low end cards. High end demand never really seems to stop as people with disposable income keep coming back for more despite market conditions."
    ]
  },
  {
    "brand": "amd",
    "generation": "7000",
    "tier": "low",
    "matched_keywords": [
      "7600"
    ],
    "title": "[Tom's Hardware] AMD RX 7600 Could Cost More Than the RX 6650 XT",
    "selftext": "",
    "comments": [
      "Can I politely ask all these rumours to shut up?\n\nIt's getting announced at Computex. That's in one week or so.\n\nIf they're right, AMD can shove it. If not, stop baiting and wait and see.",
      "Yeah, they're intolerable. If you're also into football (the European one), then every other year you get a confluence of PC hardware rumours and transfer rumours. Kills the internet dead.",
      "For sure, saying \"the new version is more expensive than the current market value of the old one\" is a given. That's literally how retail works.",
      "Rumorers never shut up. \"Hey did you guys know the 4070 TI is a rebadged 4080 12...\"\n\n\"YES, WE KNOW. YOU TOLD US 20 TIMES\"",
      "A $300 price for the 7600 also bumps it up against the 6700 XT and one can be found on Newegg for $320 as I type.  How will its performance compare to the 6700 XT?  What happens if 6700 XT's drop further in price?",
      "It's going to be interesting to see how the RT performance of the 7000 drops off below the 7900 cards. It's possible that they'll offer a meaningful improvement on the 6000 the whole way down the stack. Otherwise, it's hard to see why someone wouldn't just get a 6700XT",
      "> A pair of listings on PC-Canada has revealed the price of AMD's upcoming RX 7600 in Canada. One of the listings features a Sapphire Pulse RX 7600 for $451.99 CAD, and the other is $443.99 CAD for an MSI RX 7600 Mech 2x Classic. After converting to USD and factoring in any potential \"early adopter tax,\" we end up with approximate prices of around $299 USD. That's technically less than the launch price of AMD's RX 6600, and well below the RX 6650 XT's $399 MSRP, though these days the various RX 66xx-class GPUs tend to sell far below their launch prices.",
      "A real informative headline would have simply said \"RX 7600 expected to cost $299\". The article would have discussed the source of the price speculation and the reasoning, and compared it to MSRPs and current street prices.\n\nWhich is largely what the article did, it just framed it in \"this chip doesn't seem worth the price\", which is just another bunch of speculations thrown over the price ones.",
      "> And that \"companies are not your friends\"\n\nThat's because yeah, companies are not your friends.",
      "Swear to Christ people are angrier at AMD for not selling a GPU for the price of a McChicken than they are at Nvidia for raising prices.\n\nThis card is cheaper than its predecessor, last gen GPU's have been marked down to even cheaper than that within the past few weeks, this cards main competition is pathetic (4050 6GB of RAM), and people still find some reason to bitch and want the price to be lower.",
      "leaked out of his ass",
      "If only social media extended that same courtesy to Nvidia.\n\nOver the last few months we had some really cool rumors taken at face value, examples:\n\nWhen someone said that RTX 4070ti would launch at $1000 MSRP (increased from $900 after rebadging the 4080 12GB). Ended up being completely false.\n\nWhen someone said that 4070 was $750 ($50 below the $800 MSRP of 4070ti). Ended up being completely false.\n\nYou can still find thousands of angry comments in Reddit threads discussing these rumors.",
      "There has been a general meme trend that AMD is out to gouge consumers by raising their hardware costs, and I fully expect more articles to lean into that overly cynical mindspace\n\nOften when people on the r/amd reddit talk about it, that I have seen, it seems to come out~\n\n that they also expect AMD is currently, or would have, taken all of the anti-competitive actions against their competitors, like that Nvidia and Intel have done time and again.\n\nAnd that \"companies are not your friends\" to the extent that historical pro-consumer actions on AMDs part should be ignored, cause reasons\n\nAnd they get mashed together in various ways to claim that AMD is screwing us, or has been, or would have been if only they could have been\n\nReally, it is just confusing.",
      "Urgh, there's more than one football? Haven't we suffered enough?",
      "Yes and no? If you bench 6950 XT vs 7900 XT in 1440p and 4K, the difference in raster between them is significantly smaller than the difference in RT. Like say if performance difference in raster is 20% in a completely GPU bound scenario, RT will be 40-60%.",
      "Thanks for sharing that. It had big \"The Onion\" energy, and it actually surprises me how keenly they skewered the tactic by showing an example of it right in the article.\n\nThat said, I don't understand people who hate click on things. If I see clickbait, I move along. And if it's in a feed I have control over, I permanently block the source the first time and make sure only to read from places that don't use clickbait titles.\n\nI honestly think that eventually, people catch on and that clickbait's a short term strategy that fails in the long run however.",
      "Wow, so a newer and faster card is more expensive than the *current market value* of the last gen card?\n\nI'm shocked, utterly shocked. Wait until they find about clearance TV pricing...",
      "Seeing that this GPU is essentially the same as a 6650XT, except with dual issue SIMD, thats pretty sad.",
      "That's twice the cost of this class of card, and it would likely require a larger PSU for many people considering this card and most of them probably don't even have 4k monitors.  \n\nThis card is for people building a whole computer for $650, not just graphics card.",
      "Not everyone is into playing the latest AAA titles. Some people will be fine with 8gb for a few years at least. Although a bit extra vram wouldn't hurt."
    ]
  },
  {
    "brand": "amd",
    "generation": "7000",
    "tier": "low",
    "matched_keywords": [
      "7600",
      "7600xt"
    ],
    "title": "AMD Software: Adrenalin Edition 24.1.1",
    "selftext": "  [https://www.amd.com/en/support/kb/release-notes/rn-rad-win-24-1-1](https://www.amd.com/en/support/kb/release-notes/rn-rad-win-24-1-1)\n\n## New Feature Highlights\n\n* **New Game Support** \n   * Like A Dragon: Infinite Wealth\n   * TEKKEN‚Ñ¢ 8\n* **New Product Support** \n   * AMD Radeon‚Ñ¢ RX 7600 XT\n* **AMD Fluid Motion Frames (AFMF) -** Boost FPS up to 97% for a smoother gaming experience by adding frame generation technology to **any** DirectX¬Æ 11 and 12 game. RS-630\n   * AFMF  improves performance by adding frame generation technology to AMD  Radeon‚Ñ¢ 700M, RX 6000, and RX 7000 series GPUs for notebook and desktop  platforms. \t\t\n      * Up to 97% average increase in performance across select titles  at 1080p resolution when AMD Fluid Motion Frames (AFMF) is ON and  upscaled with FidelityFX‚Ñ¢ Super Resolution 2 (FSR 2) at Quality Mode,  using AMD Software: Adrenalin Edition‚Ñ¢Ô∏è 24.1.1 on the Radeon‚Ñ¢ RX 7600XT  GPU, versus when AFMF and FSR 2 upscaling are OFF. RS-630\n      * Up to 103% average increase in performance across select titles  at 1440p resolution when AMD Fluid Motion Frames (AFMF) is ON and  upscaled with FidelityFX‚Ñ¢ Super Resolution 2 (FSR 2) at Quality Mode,  using AMD Software: Adrenalin Edition‚Ñ¢Ô∏è 24.1.1 on the Radeon‚Ñ¢ RX 7600XT  GPU, versus when AFMF and FSR 2 upscaling are OFF. RS-631\n   * AFMF preserves image quality by dynamically disabling frame generation during fast visual motion.\n* **AMD Video Upscaling** ‚Äì Advanced video upscale algorithm to improve video playback image quality for AMD Radeon‚Ñ¢ RX 7000 desktop series GPUs. \t\n   * AMD Video Upscaling can be enabled within the Graphics tab to  enjoy improved sharpness and clarity, for DirectX 11 applications such  as Google Chrome, Microsoft Edge, and Media Player, with resolution  support up to 4K.\n   * For more instructions on how to enable upscaling, please ensure that your version of AMD Software is up to date, and learn more [**HERE**](https://community.amd.com/t5/gaming/amd-software-24-1-1-amd-fluid-motion-frames-an-updated-ui-and/ba-p/656213)!\n* **Additional Video Improvements** \n   * Content Adaptive Machine Learning (CAML) text detection has been updated to support up to 4K gaming for even greater clarity.\n   * Various encoding support within AMD Software including AVC, HEVC  and AV1 codecs have undergone additional optimizations to improve video  encode quality.\n   * AMD continues to work with partners to implement video enhancements into 3rd party apps; more updates to follow in upcoming drivers.\n* **AMD Smart Technology Tab** ‚Äì Access the suite of great A+A features from one convenient location to maximize the power of your AMD-powered system.\n* **AMD Assistant** ‚Äì Automatically enable or disable AMD Software features based on various situations for improved performance or battery life.\n* **Additional OS Feature Support** \n   * Support for Hardware Accelerated GPU Scheduling has been  expanded to Radeon‚Ñ¢ RX 7600 series GPUs on Windows 11 version 22H2 and  newer. Click [HERE](https://devblogs.microsoft.com/directx/hardware-accelerated-gpu-scheduling/) for more information.\n\n## What to Know\n\n* **AMD Fluid Motion Frames (AFMF)** \n   * AFMF can be enabled for¬†**any**¬†DirectX¬Æ 11 and 12 title using HYPR-RX.  \t\t\n      * AFMF may introduce additional latency to¬†games and may not  offer the optimal experience for fast-paced competitive titles. AFMF is  recommended to be combined with AMD Radeon‚Ñ¢ Anti-Lag to reduce in-game  latency while maintaining a minimum in-game fps of 60.\n      * Due to the potential latency impact of AFMF, it must be manually  enabled in the per-game settings for certain fast-paced competitive  titles, even if AFMF was¬†already enabled globally. Gamers¬†are free to  enable AFMF in these titles based on their preference and gameplay  style, however, they may not experience optimal performance¬†‚Äì  specifically at lower frame rates.\n      * AFMF may be enabled or disabled on the fly using the default hotkey of Alt-Shift-G.\n   * AFMF currently requires the game to be played in fullscreen mode with VSYNC disabled. \t\t\n      * For better compatibility with borderless-fullscreen titles, Windows 11 users can enable¬†[\"Optimizations for windowed games\"](https://support.microsoft.com/en-us/windows/optimizations-for-windowed-games-in-windows-11-3f006843-2c7e-4ed0-9a5e-f9389e535952).\n      * For a better visual experience, AFMF is recommended to be used with variable refresh rate enabled.\n   * Users can check AFMF‚Äôs frame generation status using AMD Software: Adrenalin Edition‚Ñ¢‚Äôs in-game overlay.\n   * AFMF adds frame generation technology to boost FPS outside the  game‚Äôs engine. Users can use AMD Software Performance Metrics Overlay to  see the resulting FPS. \t\t\n      * Support for third-party performance monitoring tools is not available at this moment.\n   * For systems setup using Hybrid Graphics (such as laptops featuring  an integrated and discrete GPU), AFMF must be supported on the  displaying GPU to be activated.\n   * Stay tuned for future enhancements and innovations coming to  HYPR-RX with AFMF, focusing on elevating image quality, smoothness, and  latency. Enjoy gaming with HYPR-RX.\n   * **AMD Video Upscaling** \n   * AMD Video Upscaling can be enabled for most DirectX 11  applications to improve image quality. However, certain applications  such as Google Chrome and Microsoft Edge may require an additional step  to activate AMD Video Upscaling. \t\t\n      * For Google Chrome and Microsoft Edge, 'Media Foundation for  Clear' must be enabled. This setting can be configured in the browser  settings accessed through chrome://flags/ or edge://flags/.\n   * Users have the flexibility to adjust the level of sharpness added  by AMD Video Upscaling using the slider located within the Graphics tab.\n* **AMD Technical Preview Driver** \n   * Users had the opportunity to get an early look of AFMF through  the AMD Technical Preview Drivers and provide their feedback to build  and refine the feature. The feedback received through our online  communities and¬†[AMD Bug Report Tool](https://www.amd.com/en/support/kb/faq/amdbrt)¬†helped create a more stable experience for AFMF in AMD Software: Adrenalin Edition 24.1.1.¬†\n   * Users looking for updates of future AMD Technical Preview Drivers can subscribe to our newsletter [HERE](https://www.amd.com/en/forms/sign-up/gaming-software-news.html).\n\n## Fixed Issues\n\n* Performance drop may be observed in some DirectML workloads.\n* Intermittent grey screen after driver upgrade with certain monitors (such as Nixeus NX-EDG274K) on Radeon‚Ñ¢ RX 7000 series GPUs.\n* Graphics API metric may show as N/A in certain UWP applications.\n* Heavy stuttering may be experienced while playing Warframe and loading into a new area or starting a mission.\n* Black artifacts may be observed in smoke effects while playing Call of Duty¬Æ: Modern Warfare¬Æ III.\n* Black texture flickering may be observed while playing Starfield on some AMD Graphics Products, such as the Radeon‚Ñ¢ RX 5600 XT.\n* Intermittent install failure may be observed when using the factory reset setting.\n\n## Known Issues\n\n* Deathloop may experience extended loading times on some AMD  Graphics Products, such as the Radeon‚Ñ¢ RX 6900 XT. \\[Resolution targeted  for 24.2.1\\]\n* Dead Space may experience an application crash after enabling RTAO on some AMD Graphics Products, such as the Radeon‚Ñ¢ RX 6800.\n* Excessive stuttering may be experienced when first playing a match in Overwatch 2. \\[Resolution targeted for 24.2.1\\]\n* Audio may intermittently become out of sync with the video when  recording from AMD Software: Adrenalin Edition using AV1 codec.  \\[Resolution targeted for Q2\\]\n* Oculus Rift S may display with a green tint on AMD Radeon‚Ñ¢ RX 7000 series GPUs.\n* After a system reboot, Parsec host application may experience a  crash on some AMD Graphics Products, such as the Radeon‚Ñ¢ RX 7900 XTX.  \\[Resolution targeted for 24.2.1\\]\n* During Microsoft Teams meetings, the camera may intermittently  display looped footage on some AMD Products, such as the AMD Ryzen‚Ñ¢ 7  7840U Processor.\n\n## Important Notes\n\n* For users that game remotely with AMD Link, one important  announcement is that AMD is ending support for the AMD Link software. We  originally launched AMD Link at a time when there were few alternative  remote gaming solutions for Radeon graphics users. Today, there are many  options available for users to stream their PC content to other  devices. AMD‚Äôs role is to enable and support developers, not compete  with them. As such, we are ending support for AMD Link and focusing our  resources on other core capabilities and features that benefit users. We  will also continue to support developers with our SDKs such as the [AMD Advanced Media Framework](https://gpuopen.com/advanced-media-framework/) that allow them to enable streaming functionality within their solutions.\n* For users who previously installed an AMD Software preview driver,  running AMD Cleanup Utility is recommended before installing this  driver.\n* AMD Software: Adrenalin Edition 24.1.1 will now automatically clear  previously installed drivers located in the C:\\\\AMD folder to save  space.\n\n# ",
    "comments": [
      "I like the new approach, telling us when to expect for fixes.\n\nIt makes the impression that they took the software development much more seriously.",
      "it's happening.",
      "Wow first he turned water into wine, and now this???",
      "> During Microsoft Teams meetings, the camera may intermittently display looped footage on some AMD Products, such as the AMD Ryzen‚Ñ¢ 7 7840U Processor.\n\nCan this be a feature? I want a loop of me pretending to listen.",
      "Jesus, doubled my fps on cyberpunk 7900xtx",
      "I guess someone forgot to push the publish button on this link: https://community.amd.com/t5/gaming/amd-software-24-1-1-amd-fluid-motion-frames-an-updated-ui-and/ba-p/656213",
      "Yeah, the death of amd link /s",
      "They better be bustin their bussy for us.",
      "why is AMD smartaccess video unsupported on rdna2?? seems like something that should be easy to have on a 6950xt no?",
      "Cries in RX 5700XT\n\nWon't be able to use it",
      "but you edited in a comma so now I look dumb :(",
      "Because people don't care about *actual* performance or input latency, they just get a dopamine hit when the FPS counter at the top of the screen is a bigger number than before.",
      "We did it Reddit!",
      "They did this last year to nothing new, they been bussy driver team probably returned now working hard as always.  \nThey still ignoring typical driver issues tho such as the RGB laser show in dying light 2 during the first blood quest line after arena fight with RT off especially more of a RGB flicker lightshow with RT on, issue exist on many 7900 XTX gpu's",
      "There is software for this yes.",
      "I've tested **AMD Fluid Motion Frames (AFMF)**, and it works quite well on the AMD RX 6700XT while playing Alan Wake 2 at 1440p native resolution.",
      "AFMF isn't an FSR3+FG replacement. It doesn't improve FPS when in high motion",
      "Can we have HDR support please already for AMD relive -\\_-",
      "Same ;_; then again it should technically work for the 5000 series if we are vocal about it and they implement it",
      "So video upscaling does not work at all in Firefox? Useless if that‚Äôs the case.."
    ]
  },
  {
    "brand": "amd",
    "generation": "7000",
    "tier": "low",
    "matched_keywords": [
      "7600"
    ],
    "title": "Acer launches Radeon RX 7600 Predator BiFrost series, its first Radeon GPUs - VideoCardz.com",
    "selftext": "",
    "comments": [
      "I know it didn't perform that well in the GN test, but I still love this cooler design, for the uniqueness if nothing else.  Hope to see Acer iterate on it for future designs.",
      "Tbf thats all school laptops, literally every single one of them sucks turbo ass.\n\nEven today a lot of schools have ones that cant even run Half Life 2 well.",
      "\"bad cooler design\"\n\nAcer solidified their foot in the door by coming out with this based ass cooler that got everyones attention, if they came in with a boring dual fan like every C tier Asian based AIB then no one would have noticed.",
      ">And speaking of the price, A750 will cost 7990 TWD (258 USD), RX 7600 OC will retail at 8490 TWD (274 USD) and the OC variant will cost 8999 TWD (290 USD).",
      "It‚Äôs the mullet of graphics cards",
      "I remember Acer for those horrible shitty laptops in highschool back in 2015. They couldn't even boot properly",
      "Acer did made prototype RTX 4080 and 4090 graphics cards shown during Computex tho",
      "You know Acer may have whole range of products, even with business laptops?",
      "Acer? With how they handle their laptops and their stupid thermal design? Not to mention their customer support sucks, and sell  unfinished shit (laptop screens with banding mate... not even they enabled dithering... dude!)\n\nNo thanks...",
      ">  their stupid thermal design? Not to mention their customer support sucks, and sell unfinished shit \n\nYou're basically talking about the big 3 AIBs Asus, Gigabyte and MSI.",
      "Linus has just the right video for your question uploaded just 18 hours ago\n\nP.s. yeston isnt a knock off brand.",
      "yeston designs their own coolers though. just cause they're a chinese brand doesn't mean they're a knock off",
      "Meanwhile nobody wants to do business with ngreedia, only those weird ass chinese knock offs",
      "Agreed. If they can make it work, possibly by adding a second fan somewhere or something, it would be really nice to have on higher end cards",
      "Of course i know that, but like, its Half Life 2...",
      "I love these designs",
      "I like the design, but instead of that huge logo they should have added another fan for better cooling.",
      "For $199?",
      "That's like HP. I've had dog shit plastic cheap laptops from them and then my 2010 Elitebook, which is an absolute fucking tank and these models have even survived people driving over them with cars.",
      "I wonder how good it is compared to the reference model and powercolor's fighter model"
    ]
  },
  {
    "brand": "amd",
    "generation": "7000",
    "tier": "low",
    "matched_keywords": [
      "7600"
    ],
    "title": "Again RX 7600 XT vs Arc B580 ? - My specific case - DaVinci Resolve",
    "selftext": "I'm going to buy a GPU in April.\n\nI wanted to buy something used with 1 year warranty but I saw the prices of this two cards and changed my mind.\n\nI'm in Germany and I can find the Intel Arc B580 for arround 325 ‚Ç¨ and the RX 7600 XT for 350 ‚Ç¨. I would say 350 ‚Ç¨ is my upper limit. I don't really care that much for a 25 ‚Ç¨ difference. If it turns into a more than 50‚Ç¨ difference I'm probably going with the B580.\n\nI don't game that much because I don't have the time, but I like to have a PC that allows me to play with good graphics when I have the chance. I always play 4 to 10 year old games, when they are on really good sales on Steam. God of War, GTA, The Elder Scrolls V: Skyrim remastered, Mortal Kombat, that kind of stuff. I don't like to upgrade very often and I never go for the latest and greatest.\n\nAlmost everyone coments based on gaming performance, but to me it's very importante the video editing performance, because my PC struggles with DaVinci Resolve while editing H265 video from my Osmo Action 4. I also edit some Fuji GOP video and it's also slow. I also edit a lot of photos and do some 3D modeling.\n\nMy PC:\n\nCPU: Ryzen 5 5600 (don't plan to upgrade that soon, but maybe in 2/3 years, staying in the AM4 plattform)\n\nMB: Gigabyte B550I Aorus Pro Ax\n\nRAM: 32 GB DDR4 (don't remember which one exactly)\n\nAsus GTX 970 Strix OC 4GB\n\nPSU: Corsair SF750 SF 80 Plus Platinum\n\nStorage: 4 SSDs, 2 Sata and 2 M.2.\n\nI'm currently still in a 24'' 1080p 60Hz Dell monitor, but I'm planning upgrading soon to a 27'' 1440p 120 Hz, so consider I'm on a 1440p 120 Hz right now and discard the problems with the Intel ARC B580 at 1080p with low end CPUs.\n\nDoes it worth going to the RX 7600 XT for my use case?\n\n  \nI am also considering the RX 6700 XT used with 1 year warranty for arround 275 ‚Ç¨.",
    "comments": [
      "I'd say the ARC B580 because it has far better AI and rendering power than the RX 7600XT. If you choose the ARC B580 make sure you use it with a more modern CPU like at least a Ryzen 7600X or 7700X because it doesn't perform well with older CPUs.",
      "This might help you decide \n\nhttps://youtu.be/6f1wNLfCSKQ?si=zvxKnSLJEAfI5VQY",
      "I was just saying which GPU would be better for AI and video rendering, but if you plan on staying on the AM4 platform I'd go with the RX 7600XT because the ARC B580 has bad driver overhead issues with older CPUs.",
      "I'm aware of the problems with older CPUs, but has I said I'm keeping myself in the AM4 platfform a couple of years and my decision must be based in that fact. Do you still keep your opinion knowing I'm keeping the Ryzen 5 5600 or something from the same generation?"
    ]
  },
  {
    "brand": "amd",
    "generation": "7000",
    "tier": "low",
    "matched_keywords": [
      "7600"
    ],
    "title": "AMD Germany lists Radeon RX 7600 XT graphics card - VideoCardz.com",
    "selftext": "",
    "comments": [
      "You‚Äôre right every single person with a 7600 is experiencing the exact same issues. Your PC is completely stable outside of the 7600 and and that represents all drivers. Memory BSODs? Probably just crappy drivers. SMH why can‚Äôt radeon just work around my unstable hardware like nvidia does? \n\nObvious sarcasm aside, if you‚Äôre getting BSODs it‚Äôs not a driver issue and more than likely a hardware instability issue. I haven‚Äôt seen a driver caused BSOD in a long time and not even on the dedicated help for AMD drivers subreddit.",
      "I would buy a 7600 with 12GB of VRAM. I'd buy one at $300 if it had 16GB of VRAM.",
      "So it's either a 16gb 7600 or it actually has to be a heavily cut down Navi 32. 1 shader engine out of 3 disabled for a 40 cu variant could make sense, but that also seems like a brutally large cut for a relatively small die. \n\nHaving 48 enabled seems like a pretty heavy increase over a non -xt, and feels more like an Rx 7700.",
      "AMD doesnt even have working drivers for the RX7600 yet (owned that card for 10 days)",
      "> It appears that there may have been a typo on the AMD Germany website, where the title ‚ÄúRX 7600 XT‚Äù was spotted on the RX 7600 non-XT product page. This seems to be a simple mistake during the translation process, although it is quite unusual.\n\nIt's just a typo. How is this news.",
      "This probably isn't really news.\n\nAMD used use a similar configuration for the 6650/6600 XT as the RX 7600, so this is likely a vestige of AMD planning to call the RX 7600 the RX 7600 XT. And since RX 7600 still falls behind the RTX 4060, it's understandable why AMD made that choice.",
      "As someone coming from a EVGA 3070ti and upgraded to a 7900 XT I have had less issues with AMD than Nvidia heck Cyberpunk would always crash almost twice every time I played",
      "Sadly that's the MSRP of the 7600 already (even if it's 250 now). It'll probably be 319 or 329.",
      "Neither do they for 780m",
      "Fortnite's settings menu, and the game in general, won't work unless it is in windowed or windowed fullscreen. In fullscreen, every time you select something the UI totally freezes and only adjusts to what was selected if you alt tab out and back in. After you alt tab you can move the cursor around as expected, but the moment you select something you get a frozen image. This problem persists into matches - everything is frozen and won't update unless you alt tab out. God of War and GTA V also had arc-like problems with flickering and hitching in the settings menu.\n\nRocket League's the game that the 7600 won't utilise fully in with a triple monitor config. It literally won't break 70% utilisation. Single and dual works fine.\n\nI admit I don't know why the issue with safe mode  happens (it also happens in bios). It might be on Elgato in all fairness, but I can't say. The only other card I have that will automatically output to the 4k60 in safe mode and bios is the ARC A770. No other card does it.",
      "Hope AMD doesn't fuck up the pricing. (It is) anything above 280 is gonna be garbage",
      "If it matches the price/performance of the 7600 (at it's $250 price), then it's fine (if not boring), imo. It could be $300 if that meant it was 10-15% faster than the 4060, and if it's >20% faster at that price, then it would be amazing. Basically 90-100% of a 4060ti at 75% of the price at that point, and I think that could be a pretty decent deal.",
      "> 3060Ti for ¬£380\n> 4x8GB instead of 2x16GB\n\nHorrible mistakes.",
      "It's in Dx11, I can't say if 12 is affected. Rocket league on high quality settings will max the 7600 and produce a nice high refresh experience. The issues lines up perfectly with having three monitors or less. Three monitors will bug out. One or two gives 100% utilisation and a true high refresh experiemce @1080p.",
      "Working as in you had issues or at all? Because They‚Äôve had drivers available since 5/24/23",
      "I have zero issues with my 7900 xtx.. this is a you problem.",
      "> AMD drivers that are just‚Ä¶ it‚Äôs fucking horrible to have an AMD card.\n\nCan‚Äôt relate. Not even able to find anything about eve online having memory leaks on radeon cards other than game bugs.\n\nI genuinely don‚Äôt understand how someone thinks all AMD cards are bad because of anecdotal evidence lmao.",
      "Complete windows format, AMD default/compact installer doesnt have support for the RX7600, AMD (including their support) directs people to the specific page for RX7600 drivers which is an older version, and there is just 1 driver so you cant pick incorrectly. Either you have the correct driver, or you have no drivers. AMD removed support for the RX7600 in their latest driver build 23.5.2 or whatever the numbers go up.\n\n\nAnd it is no joke, Everyone with an RX7600 have the same crashes. Its such a low quantity card AMD just immidiately abandoned it. Mindfactory has sold 30-40 of them since launch. All retailers in Sweden have combined shipped less than 20 since launch.\n\n\nThese issues happen with all AMD cards but the memory limitations of the 7600 makes the driver memory leak far exceed the cards capacity which crashes or freezes the system. More so in multi-monitor setups.",
      "[Just a few percent behind the RTX 4060](https://redd.it/14phuh8)\n\nPoint being that Nvidia used a tier lower chip than normal (4050) and AMD had to use a tier higher (7600 XT). Since it's a few percent behind, it would be much worse if AMD *hadn't* used the higher core config. So this isn't necessarily a leak about a new product",
      "I run a small benchmark channel (yeah, I know), and the 7600 is honestly giving me as  many problems as ARC did. Flickering settings menus, performance that tanks unexpectedly, an issue where GPU utilisation won't max out under load when you have more than two monitors connected, and even an issue where if you boot into safe mode with a capture card connected then the card will only output an image to the capture card. Even AMDs own hardware recognition tool (for redeeming 'free' games) won't register that there's a 7600 in my system.\n\nThe 7600's drivers needed a lot longer in the oven. They're a catastrophe right now."
    ]
  },
  {
    "brand": "amd",
    "generation": "7000",
    "tier": "low",
    "matched_keywords": [
      "7600"
    ],
    "title": "ASRock preparing Radeon RX 7600 8GB Steel Legend GPU and low-profile Arc A380 - VideoCardz.com",
    "selftext": "",
    "comments": [
      "a low profile a380 woiuld be siick",
      "7600 8GB >= 6650 XT @ or below $250 or DOA.",
      "Except slapping it in an old sff office pc will be disastrous if it doesn't support rebar.",
      "Probably a typo, they likely meant either a 6500XT or 6400.",
      "A 6400XT (full 16CU's LP/75W) would have been much better then that #% 6500XT... probably to late for that.\n\nA380 LP sounds very good.\n\nAs for the 7600... Challenger ITX/USB-C pls.",
      "Well, if that does happen, although redgamingtech did say the 7600 **XT** would sell for around $300, they'll eventually have to lower prices whether they like it or not after the 6000 series sells out if they want to have any chance of selling the cards and gain market share. Mostly because not many people will wanna buy an 8GB gpu with the perf it's expected to have for $300 or more.",
      "Tbh, the leaks have been all over the place as to whether we're seeing the 7600 OR the XT OR both and which is which.\n\n7600 XT is going to be at least 11% faster than the 6650 XT (so at least 6700 level) and has the same CU count and memory clocks.\n\nSo if each CU is 11% better and 7600 is also getting those memory clocks, then 28 RDNA3 CU's ~= 31 RDNA2 CU's. So it should be just a bit shy.\n\nThe 11% figure was also from an engineering sample with not final drivers. So I think the 7600 is going to get up to the 6650 XT level.",
      "8gb isn‚Äôt enough for 1080p???\nBro I guess that means all 5000 series/6600/6600xt owners can‚Äôt play on 1080p anymore?",
      "8gb üíÄ",
      "true, that blows",
      "RX 6650 4GB?",
      "Not with ultra settings and certainly not with maxed out textures. Already had massive issues with my 5700XT due too 8gigs running 2k upscaled to 4k with FSR. Performance wise i could have used it easily for another 1-2 years if it had more VRAM but with recent titles stutter and texture popins became more and more. Tough if u are willing to cut back textures or resolution it will postpone the issue for now...",
      "Wait, what is 6400XT? Is that a typo?",
      "8gb? So AMD is taking a page out of Nvidia's book then?",
      "Imo it doesn't really matter which one they launch as long as it's priced right.\n\nThe difference between the 6650 XT and the 6700 is \\~4% (techpowerup), so hopefully the 7600 XT will at least perform like a 6700 XT with final drivers.\n\nI also heard about the 11% perf boost from MLID so yeah let's hope 7600 is at least 6650 XT perf.\n\nAt a decent price ofc.",
      "It's a likely possibility, the 6650 XT is cheaper after all.",
      "No, it's going for as low as $260, 6600 XT $255",
      ">Isn't this going to be similar in performance to the 6700 but with less VRAM?\n\nYup, and given its price, that's why I said at or below $250 or DOA",
      "Depends on the source. It's like 8-10% on Tom's Hardware's GPU hierarchy.\n\nI'm expecting they launch both. If they don't launch both, then I expect the 32CU 7600 XT and both Navi 32 cards.",
      "Exactly, I completely agree with you. There's a chance they'll take a hint from tech outlets like HUB and MLID and go for a sensible price, but since the 6000 series ended up being good value and selling well (which was precisely because they lowered prices but not sure they realized it) they might opt for the same strat this gen and launch at bad prices again, which would only leave a bad taste in consumers' mouths, just like you said.\n\nEven if the chance is slim, I'm praying for them to be smart about pricing and not fuck up."
    ]
  },
  {
    "brand": "amd",
    "generation": "7000",
    "tier": "low",
    "matched_keywords": [
      "7600"
    ],
    "title": "Rtx 3060 12gb or radeon 7600 xt 16gb?",
    "selftext": "I dont know what to get. These cards are the about the same price in my country (300 euros) and ive seen alot of mixed feelings around these cards.",
    "comments": [
      "7600xt is about 25% faster in raster.",
      "7600xt is 350 7700xt is 450",
      "Lol ya nvm",
      "I would try and get a 7700xt if u could idk how much they go for in Europe ,but if not 7600xt over 3060 imo"
    ]
  },
  {
    "brand": "amd",
    "generation": "7000",
    "tier": "low",
    "matched_keywords": [
      "rx7600"
    ],
    "title": "RTX 4060 or RX7600 or ARC B580?",
    "selftext": "I want to buy a new Gaming PC, but I don't know what gpu I should get. I'm going to pair it with Ryzen 5 7500F.",
    "comments": [
      "Depends on price, if they all under 300 then prob b580",
      "The b580 is great, but it is recommended for 1440p, so don‚Äôt cheap out on the monitor.",
      "Rx 7600 trades a lot of blows with the RTX 4060. Same story with the Arc B580, which may perform slightly better than the 4060 depending on the game, *and* has more vram so it will last longer. Theres been some drama on the B580 having a lot lower performance on CPUs which don‚Äôt support rebar, but yours does and is pretty modern, so I wouldn‚Äôt worry about it. The 4060 has better ray tracing capabilities, and DLSS. There‚Äôs a few factors to consider here, but I wouldn‚Äôt get the 7600 unless it‚Äôs a decent bit cheaper than the other cards, but I‚Äôll make everything simple for you:\n\n**Get whatever is the cheapest**.",
      "Idk if they fixed the overhead issue, unless you're using am5 3d cpus, the b580 will be worse than 4060",
      "Only an issue with weaker old CPUs with no resize bar support, (not even an issue since you can technically mod / update it) \n\nSo for the 7500f the B580 is a great option."
    ]
  },
  {
    "brand": "amd",
    "generation": "7000",
    "tier": "low",
    "matched_keywords": [
      "7600"
    ],
    "title": "Need Advice for a GPU Upgrade: Ryzen 7 5800X3D + ASUS TUF RX 7600 XT OC",
    "selftext": "Hey everyone,\n\nI‚Äôm currently thinking about upgrading my GPU and could use some advice. Here‚Äôs my system:\n\nCPU: Ryzen 7 5800X3D\nGPU: ASUS TUF RX 7600 XT OC\nRAM: 16 GB DDR4 3600 MHz\n\nI mainly play Rainbow Six Siege, but I‚Äôd like to future-proof my setup for upcoming titles and handle higher resolutions better.\n\nI was thinking about a 4060ti 16gb. \n\nAny recommendations would be greatly appreciated! Thanks in advance!",
    "comments": [
      "https://www.tomshardware.com/reviews/gpu-hierarchy,4388.html\n\n4060ti not a substantial jump over 7600xt\n\n3080 used or higher.",
      "In 1440p",
      "Im sorry its 2x16gb",
      "The coil whine is just getting on my nerves as well as the fps drops. I‚Äôm getting like 300-400fps but sometimes it drops to like 4.",
      "My gpu is the oc one with already 16gb vram",
      "Tbh I don't know much about coil whine I've never experienced it so I can't help you there.",
      "I assume you have 2x8 ram sticks, if I were you I would get another 2x8 ram sticks first, especially if you want to future proof (keep in mind that it has to be the exact same model as your current ram).\nAs for the GPU upgrade the 5800x3d could comfortably handle the 7900 gre, or probably even the 7900 xt in most games.",
      "Even better. The thing is going from 7600 xt to 4060 16gb isn't much of an upgrade it's not more powerful it just has more vram, so I personally don't think it's worth it. If I were you I'd save up a little more and make a more meaningful jump, it'll just be much better value.",
      "Ohh right the xt version has 16gb I forgot. In that case there'd be basically no benefit from switching to the 4060 16gb other than some Nvidia features, since they have similar performance. If you want an Nvidia GPU I'd recommend the 4070 ti super. You could also go with the 4070 ti but it has 4gb less vram than the 7600 xt despite being more powerful so I personally don't like it."
    ]
  },
  {
    "brand": "amd",
    "generation": "7000",
    "tier": "low",
    "matched_keywords": [
      "rx7600"
    ],
    "title": "Order it rx6600 from new egg instead got a rx7600 for 189$",
    "selftext": "",
    "comments": [
      "Delete your post on r/Newegg . That is an official sub with actual Newegg customer support. One might be in a bad mood and make you return it.",
      "basically its just 6600 XT",
      "so no complain , right ?",
      "Legally speaking a company cannot force you to return a package",
      "Yeah they might serve you court papers if you don‚Äôt return it",
      "I know but op might not know that and knowing Newegg customer service they might start saying some bs to trick op into sending it back",
      "Ok",
      "You don't even have to delete it but if Newegg tries to contact you do not listen to them",
      "GG",
      "The RX 7600 8 GB card is a slight down grade of the RX 6700 10 GB card. The RX 7600 is substantially better than the RX 6600 8 GB card."
    ]
  },
  {
    "brand": "amd",
    "generation": "7000",
    "tier": "low",
    "matched_keywords": [
      "7600"
    ],
    "title": "The Issue with CPU Reviews... 13 x Ryzen 5 7600 compared",
    "selftext": "",
    "comments": [
      "Silicon lottery is more real than ever, especially with modern boost algorithms taking just about every CPU to the limit (whether that limit might be power, temp, or clock).",
      "Wait until they test GPUs.",
      "He says in the end that all the CPU's are in spec so this is not a problem. Some get lucky and get a great cpu, some just get the baseline.",
      "Good that this gets highlighted, will save we some explaining whenever i build a system for someone or someone in my circles build their own system or buy a prebuild and then they benchmark some stuff and it doesn't perform as they see on LTT, HUB or whatever reviewer they watched, or maybe they have seen at a other friend or the neighbor even.\n\nIts never a issue if they score better than whatever result they compared against, but when they score less all of a sudden they seem to forget that cpu's are not created equal and that within the same Sku you will see different results, and some will be low (but still within spec) and some will be high, and others will be average.",
      "Yep, when I was mining back in 2017/2018 I tested this for the fun of it. The 6x1070s I had of the same model and batch (EVGA and ascending serial number with no gaps) had a 3%~ performance delta in Time Spy at stock. With a larger sample size I wouldn't be surprised if the real delta might have been closer or maybe even higher than 5% of top vs bottom.",
      "And when mining same batch sometimes had huge differences in how much you could underclock them too. I had card that could be undervolted almost 50mv more than one other in the same batch",
      "I built a system for a friend with a 5800x and dude god a frikken diamond tier specimen, went to over 5ghz on PBO2 with mostly -30mv and 2000 flck 4000MT/s RAM. ü§Ø\n\nI‚Äôve never got that lucky with my own CPUs, my 3600 just barely does stock clocks üò≠üòÇ",
      "The main explanation is that these smaller and smaller nodes are very picky.  The transistor density and count is quite high.  The manufacturing tolerances are now the providence of very difficult physics and bleeding-edge facilities.   They are a bit more sensitive to voltage than the huge nodes of the past.\n\nHonestly, we are getting to the point where each CPU simply is a proverbial unique snowflake.  Even after binning, each CPU is going to be a bit picky, doubly so for those that are multiple pieces of silicon packaged together into one final product.  \n\nI think it's just a lesson for us not that companies have changed any more than they were over the previous half decade, but that if you get a CPU that simply can't be made to hit numbers that make sense... it's up to you if you wish to return it, try changing coolers, getting a different SKU, etc.  \n\nThere's no shame in doing a return of an individual product you're not feeling good about.  But if its numbers are normal, just keep it.  I'm not saying people should chase golden samples through returns, as that just eventually gets noticed by customer service and can affect the ability to get future products.",
      "I always get the worst quality.",
      "https://preview.redd.it/8mneubtbccua1.jpeg?width=2436&format=pjpg&auto=webp&s=1d59de4995c40b03b59c20d37d9b541c0de8bcc3\n\n[https://youtu.be/k8II0NoI6cc](https://youtu.be/k8II0NoI6cc) 30 10900k",
      "This was basically what happened with the Fx-8350 before they tiered it into like 8 different SKUs. There were random 5ghz ones on a double stack air cooler and then there were the ones you could throw 1.8v at and still barely squeak in like 4.7ghz.",
      "He did it some time ago, I think it was with 10900k's",
      "You're buying consistency.\n\nThe spec guarantees a 7600 has a base clock almost 1GHz lower than a 7600X, that's a crazy drop but gives them lots of room to sell off these bottom bin chiplets.",
      "Could also be the UPS - PSU that‚Äôs causing coil whine. My old cyberpower unit used to cause coil whine until I swapped it out for a cheapo amazon basics ‚Äúwe steal your successful design‚Äù unit and coil whine disappeared.",
      "Interesting, will he do this for intel too? Would there be even any difference?",
      "He did with the 12900K by buying a binned CPU. The difference was massive as you‚Äôd expect.",
      "You‚Äôve got one thing backwards ‚Äì AMD can surely evaluate CPUs for performance, voltage, clock speed, efficiency, and thermals much more quickly and easily than Der8auer.  It‚Äôs just that the market only needs so much segmentation.  We don‚Äôt really need to see a 7550X and 7650X SKU just to split power efficiency hairs.",
      "Not if he bought a bunch of bottom tier processors, 13400 or something. \n\nThe lower tier professors are all professors that couldn‚Äôt cut it as higher tier products, the lower the tier the more higher tier processors it wasn‚Äôt good enough to be.\n\nSo a 13400 wasn‚Äôt good enough to be a 13900, 13700, 13600 or even a 13500.\n\nConsequently, you get what you get, a bottom tier highly variable CPU.\n\nIt might be you get lucky, it was actually good tier silicone but couple of the cores were faulty so it‚Äôll still run well. But usually it‚Äôs just a bear minimumly functioning within the loser spec piece of silicone.\n\nIf he buys a bunch if 7800x3Ds there would likely be much less variance as the base minimum standard is so much higher for binning for of the silicone to be eligible to be that CPU.",
      "Isn't this a job for the fab to do? AMD places an order and the fab delivers on that contract so many skus in whatever tier, I'm asking cause I don't know.",
      "Talking of mining, I once got a 3950x mining XMR at 0.85v, cruising on all cores using around 40watts (underclocked to 3.2Ghz as the algorithm is RAM bound) sacrificing around 3% hashrate! \n\nUnbelievable sample of silicon that was although running any other kind of workload at that voltage was an inevitable blue screen.\n\nStrange how that workload tolerated such low voltages although again, RAM bound workload. \n\nGPU's always seem to get exactly the same hashrate but again, memory bound algorithm, interestingly the temperatures did vary slightly which certainly could have been binning?"
    ]
  },
  {
    "brand": "amd",
    "generation": "7000",
    "tier": "low",
    "matched_keywords": [
      "7600"
    ],
    "title": "XFX preparing two Radeon RX 7600 XT graphics cards - VideoCardz.com",
    "selftext": "",
    "comments": [
      "The two 8-pin connectors seem a bit unnecessary for a 190W card when 8+6-pin would already be enough for 300W.",
      "i think JayzTwocents did make a video in the past saying \"enhanced\" gpus are a waste for low to mid tier options since they don't need beefy coolers and extras. This does seem to fall in the category of \"why tho\"\n\nbasically, it's what companies want you to think you need, but you don't actually need it. what's worse is people will fall for these.\n\nI bought the lowest end 6800 non xt and customized the fan curve. it's doing fine",
      "It's where the board partners make their profit margins. I feel a bit bad about it because in the past you could overclock a card to be as good as a higher spec model and those board partner cards could let you do that easier. \n\nNow-a-days I feel like graphics cards overclock really poorly and you have to buy the better model to get that performance and not just overclock.",
      "Soon, followed by a price drop.",
      "when do we expect to see reviews for it?",
      "Yeah it's funny, their top 7900XT model also has the 2x8-pin",
      "I have a XFX 6700 (non-XT) and it also has two 8-pins for a card that supposedly sips power.",
      "My powercolor 6700xt had an 8+6 pin rated for 300 watts but it only uses 230 watts.",
      "yeah it depends. sometimes some models are cheaper or more expensive. some models drop in price quicker than others. For me, Gigabyte GPUs are also the cheapest for a 3 fan (or 2) but considering my previous 6700xt from them was acting up, i went with XFX because i've rarely seen or heard people complain about QC issues unlike with Gigabyte.\n\nMy previous 6700XT was fucking up my PC bios. whenever i needed to validate something it wouldn't render properly and text would become lines. It also took me a while before i had a stable card. for at least 2 months i had regular crashes.\n\nWhen i switched to the 6800, the bios glitches were gone and right away it's a much more stable card for me. Guess i got a lemon with gigabyte.\n\nI will probably stick to XFX and if their cards are not available in the future, i still have powercolor and sapphire to look out for",
      "Well, I hope my gpu doesn't get any problems like that lol, and thanks for the explanation!",
      "Looks like a Sapphire Polaris era card, with an extra fan.",
      "With the price it's going to be, I wonder if it's worth getting the 7600 xt over the 6700 xt",
      "yeah but that's 190w on paper like my 7700xt is 245w on paper but as soon as you start  pulling sliders across that changes my 7700xt sits at around 260 in games and as high as 310 in timespy pushing 2850 on the core 2500 mem",
      "I prefer all connectors to be 8 pins, personally. It's easier for me to set up the cables as all the 6 pin connectos I have are either daisy chain, have an extra 2 pins dangling or both while my 8pins cables are all regular 8pin to 8pin.",
      "I don't know much about specific models and all, but for my gpu I bought a 7700 xt from gigabyte in october, the gaming OC version, and found it super beefy, specially when there are 2 fan models... yet it was the cheapest model available for me, a bit bellow MSRP. Is there something else in the card that gigabyte may have cut the price on?",
      "Tomorrow\n\n>**Pricing and Availability**\n\n>The AMD Radeon RX 7600 XT graphics card is expected to be available beginning January 24, 2024, from leading AMD board partners, including Acer, ASRock, ASUS, Gigabyte, PowerColor, Sapphire and XFX. The AMD Radeon RX 7600 XT graphics card has an SEP of $329 USD.",
      "Why are you surprised by this? Nvidia launches are more structured. Reviewers get products well before release date, embargo is lifted day before release and then next day product is released. \n\nAMD seems to just wing the launch.",
      "What‚Äôs the point of 8+6 when you‚Äôre using 2x 8 pins anyway? Just make it 8+8 and have the juice",
      "I'm betting very soon.  Doesn't it release the end of this month?",
      "Release day is tomorrow. So probably then."
    ]
  },
  {
    "brand": "amd",
    "generation": "7000",
    "tier": "low",
    "matched_keywords": [
      "7600"
    ],
    "title": "Asus Radeon RX 7600 XT Dual OC 16GB any good on an Asus B550-F GAMING + Ryzen 7 5700. I got around ¬£300 for gpu for latest driving games. Pro cons and alternatives. Thank you.",
    "selftext": "",
    "comments": [
      "Struggling to understand the naming system of gpu or narrow down the thousands of options :( what should I get ?.",
      "Gonna wait for rx9070xt to see what benchmark and prices look like.",
      "You including used gpus in here or looking for new only? If including used then the absolute best you can grab for 300 euro is a used RTX 3080 10GB. Can't find one, look for an RTX 2080 Ti or RX 6800. RX 6750 XT is a good 250 euro option. I'm from the US so the market may look a bit different where you live.\n\nAs far as new goes, best option is the Arc B580 for about 250-300.",
      "Ah thanks, defo better options, googled a few you've mentioned and far better benchmarks on games. 6700xt  and 3060ti look to be a good bet too. Bit of a minefield out there."
    ]
  },
  {
    "brand": "amd",
    "generation": "7000",
    "tier": "low",
    "matched_keywords": [
      "7600"
    ],
    "title": "HW News - AMD BIOS Issues, 7600 XT vs. 4060 Ti Rumors, Direct Die Fire Extinguisher",
    "selftext": "",
    "comments": [
      "Youre right, we should stop talking about it, pull it under the rug. Im sure multi billion corps would be ecstatic about it . Its fine",
      "Holy shit, what an incredibly stupid take.",
      "I‚Äôm pumped to see what the 7600 XT has to offer. I‚Äôm a little confused about the Navi 33 v 32 discussion; I know this uses the slower chip and people were saying it was WAY slower, to the point performance may not be much better than the predecessor.\n\nHoping that‚Äôs not the case but I‚Äôll probably just hold off til holiday.",
      "Don't want to be sounded like a fan boy, but given that  the last episode of HW news was 2 weeks ago, and the whole burnout saga started after the last HW new. I don't see the problem when they cover the issue in this episode tbh. (Though I'll agree to you if they cover this again in the next episode without any new content or findings)",
      "AMD fanboy accusing someone of being a cult member, ironic.",
      "Unless they try to sell it for like $300. That's way too much for an 8gb budget card in 2023.  \nThis *is* a budget card because the performance is just not there. It will barely be acceptable even at $200.  \nIt would be fine for $300 if it had S tier performance at 1080p, but the performance of this thing will be sad even at 1080p.",
      "But it's 6nm, right? Power consumption shouldn't be that different.",
      "I think it is just funny. Maybe AMD stops taking shots at others and starts focusing on their own products instead. It just keeps backfiring for them every time.",
      "Especially when they spent thousands to perform a thorough investigation of the problem. Yeah, they should simply avoid talking about it /s",
      "I joined this sub because I just got an 7800X3D and wanted to stay up to date with the developments, how to deal with the voltage and so on. After my brand new CPU and MB started smelling funky.\n\nI was a bit worried but I'm glad this sort of fanboy crap is getting downvoted to hell.",
      "Naahh you're fine. Just update your bios and keep checking for new bios updates regularly over the next few weeks.\n\nThere are plenty of threads around asking this same question if you would like more help so make sure to just have a look around this subreddit.",
      "None of our business I reckon.",
      "Yup, it's 6nm with RDNA3 (so far) not bringing many improvements in that regard.",
      "what are these amd burnouts! someone help!!! should i be worried about the 7800x3d i just bought?",
      "I got 6750XT for under 500 eur in more PC-component-expensive part of Europe. And 6650XTs are already around 320 eur here so yeah, this needs to be 300 or less to be worth it",
      "The thought logic hit a wall so hard me trying to keep up hurt me. I can only imagine...who am I fooling there is no critical thought in his post or follow up.",
      "[https://www.britannica.com/science/projection-psychology](https://www.britannica.com/science/projection-psychology)",
      "Given the current 6600 series pricing and the fact N33 is smaller and on a cheaper node selling whatever they name the N33 based cards (probably 7600) for current 6600 pricing is doable.\n\nThe other option is give it 16GB of VRAM but that means a 12GB N32 might look awkward. Maybe make it an option for AIBs.\n\nA final option is that they relegate N33 to the 7500 tier, give it $200 - $250 pricing and use a heavily cut N32 to server in the 7600 tier. A 12 GB 7600XT that performs like a 6750XT / 6800 would do okay at $400 and be really well received at $350.\n\nAMD have options here, just depends what they want to do.",
      "It's always nice to see someone quoting the PHB 3.5e by page and paragraph.",
      "There is a thread pinned up in the main subreddit. Carefully read that. It is happening to some chips, not most chips so for one most people will be fine. Just be careful with the SOC voltage settings."
    ]
  },
  {
    "brand": "amd",
    "generation": "7000",
    "tier": "low",
    "matched_keywords": [
      "7600"
    ],
    "title": "ASUS launches Radeon RX 7600 DUAL EVO OC graphics card",
    "selftext": "",
    "comments": [
      "If you're not trying to cram a 7900/3900 into your SFF build, is it really SFF? :D",
      "I thought this was a dual GPU at first in the vain of the old R9 295X2 and was like ‚Äúwhy the hell would AMD make a dual GPU of RX 7600s, that makes no sense‚Äù",
      "Dual fan",
      "But why?",
      "SFF builds",
      "Someone care to explain what this / dual is?",
      "But it's thicker than 2 slots. For a low tier GPU.",
      "It's a \"spec\" that has a specialist form for OEM PC's like Intel's NUC systems",
      "It's a \"spec\" that has a specialist form for OEM PC's like Intel's NUC systems"
    ]
  },
  {
    "brand": "amd",
    "generation": "7000",
    "tier": "low",
    "matched_keywords": [
      "7600"
    ],
    "title": "Sapphire launches adorable Radeon RX 7600 Party Animals Edition - VideoCardz.com",
    "selftext": "",
    "comments": [
      "It‚Äôs funny. Weird, goofy cards like this haven‚Äôt existed for a little while, and I‚Äôm glad that they‚Äôre coming back in style, even if I‚Äôm not personally into it. I always missed these types of weird cards from the late 2000s and early 2010s.",
      "There's a part of me that still really wants to hunt down the ASUS Z590 Zaku-II to pair it with the 1660S Zaku-II.\n\nThey even made a matching case, monitor, and router.",
      "Nothing has matched up to the rx 580 CUTE PET.",
      "No, I do not want my PC to be a series of ad spots.",
      "Sapphire channeling their inner Yeston, I see.",
      "They had these before? I only ever remember the cards with random anime chicks",
      "Yes Sapphire, YES.",
      "I am perplexed by how you envision that reducing prices, of all things.",
      "Need one for the XTX. Imagine a goofy looking card ripping through 4k 100+ fps",
      "What the hardware looks like is important for many people, yes.",
      "Should pair well with the B650 LiveMixer.",
      "Ah yes, dont you just love the china market?\n\n\nEven ROG there has a waifu, and its all over their white products. Almost all white ROG products have a waifu on them, at least on the box, sometimes on the thing itself",
      "It's Gang Beasts not Fall Guys.",
      "I overwhelmingly choose to buy AMD over Nvidia and also get enthusiast cards, but the Demon Slayer RTX 3000 models looked so cool that I had envy üòÇ\n\nAs well as the OC Formula z590 to go with my Rx6950XT OC Formula.",
      "reminds me of those round zalman coolers. were very popular in brick and mortar computer stores just due to the look alone.",
      "Hail Yesotn's trailblazing cat gpu",
      "Not like *this* specifically, but cards that weren‚Äôt just the standard fare of what you‚Äôd usually see.",
      ">I'm just glad to see that PC gaming isn't quite the boy's club it used to be\n\nI think you are arguing a strawman that never happened in the first place.  The \"boys club\" bit by some overzealous terminally online moral busybodies is an overused cliche used by people who haven't been paying attention to gaming for the past 10 years.\n\nI've literally *never* heard of a conversation where a guy teased a girl for making a computer \"girly\".  In fact, Yeston coming out with those off the wall designs were actually a breath of fresh air to everyone.  It's not because of some ideological premise of wanting PC gaming to have some population equity between the sexes (and there's a high chance it never will), but because the designs were out of the box and unique.\n\nSomeone at marketing at all these AIBs and NVIDIA/AMD themselves thought the overused ultra dark \"edgy\" militaristic/future designs was what everyone wanted.  The only problem is *all* the manufacturers thought this was the case, which led to everything looking samey from a design standpoint.\n\nYeston flipped that market upside down and reminded people that there are different demographics with different interests who would love to see a GPU that isn't just marketed towards the xXxSTEALTHNINJAASSASSINxXx COD crowd.  Japan, for example, actually has occasional Japan-only PC hardware releases that feature all kinds of anime-style designs/promotions.\n\nThe fact it took a company not many of us in the West have heard of to finally turn back the clock on overly edgy GPU designs was a long time coming.  And it's not like the brand itself is a newcomer, its parent company, Shenzhen Yingjiaxun Industrial Limited, has been in the Chinese IT industry since 2000.  Yeston was founded as a sub-brand of the company in the same year, but I guess they finally started making inroads when people started noticing their GPU and case designs.\n\nI am just making an educated guess here, but I'm thinking Yeston was the sub-brand that was given creative freedom to make off-the-wall components designs, and a designer or engineer at Yeston probably thought several years back making graphics cards that move away from the COD player demo might actually be worth taking a shot at.  There were already some older cards that hinted at this move away - I've seen pictures of a GT 730 and an RTX 550, for example, that were in a garish magenta color.  They still sold edgy \"gamer\" cards even back then alongside these weird designs.\n\nSapphire taking cues from Yeston to go nuts with their designs is a very good sign because it's indicating the market is getting tired of the GAMER (tm) aesthetic and AIBs are noticing it as well.",
      "> I'm gonna' go play Destiny and eat some crayons.\n\nIt doesn't happen often, but God damn if it ain't interesting to see a Marine rub two brain cells together.",
      ">Demon Slayer RTX 3000\n\nThat was a pretty cool card.  I was able to snag the Japan exclusive Godzilla 3070 when it came out during lockdown.  Somehow managed to only suffer a couple hundred $ markup (including shipping from Japan) so I feel like it was a steal considering the massive markup at the time"
    ]
  },
  {
    "brand": "amd",
    "generation": "7000",
    "tier": "low",
    "matched_keywords": [
      "7600xt"
    ],
    "title": "4060 v 7600xt",
    "selftext": "Hi guys, I broke my 5600xt which I used for my 1440p monitor and sometimes 4k tv for old AAA titles. I‚Äôm looking to buy a new GPU possibly the ones in the title or 3060 12gb. My 5600xt seems to be able to handle 1440p med settings for most games and 4k fsr med settings for old aaa titles. I‚Äôve read so many bad reviews about the 4060 and 7600xt but getting a 6750 or 6700xt is much more expensive even at second hand prices here in our country. Looking for your kind opinions on which I should get possibly long term for the mentioned things I needed. I don‚Äôt edit much but planning in the future. I plan to use the card in b550 mortar msi board with 3200 mhz ram and 3600 r5. Happy to hear your opinions. I just can‚Äôt decide. Main game is valorant and nba 2k25 and occasionally aaa titles. ",
    "comments": [
      "The 7600 XT is normally 10-20% better at normal gaming, and about the same as the 4060 in raytracing. The 7600 XT does have twice as much vram (16GB), which will be nice in 4K titles. I‚Äôd go with the 7600 XT. The Ryzen 5 3600 will probably be enough, and better AM4 CPUs still cost $200+.",
      "Also, let me know if it‚Äôs necessary for me to up my RAM or CPU. Thanks!!!",
      "Thanks for the comment bro. Honestly really leaning towards that 7600xt. I just hope that the experience from 5600xt to 7600xt is somewhat going to make sense. If I didnt broke the 5600xt I prolly still be rocking it."
    ]
  },
  {
    "brand": "amd",
    "generation": "7000",
    "tier": "low",
    "matched_keywords": [
      "7600"
    ],
    "title": "[HUB] Radeon RX 7600 vs. GeForce RTX 4060, 40 Game Benchmark @ 1080p & 1440p",
    "selftext": "",
    "comments": [
      "The funniest part has to be both of these cards getting outperformed and out valued by their own last generation cards",
      "I'm not laughing, sadly.",
      "He is right if rtx 4060 is 300 the Rx 7600 should be 250 or less",
      "cheapest 7600 is currently 257$ most amd cards are hella discounted a 6950xt was $580 for the past couple of days and stuff like that",
      "Wait, its unusable? I have a rtx 3060 12gb and i can comfortably use ray tracing in spiderman and metro exodus 70fps+ high setting. is the rtx4060 really that bad?",
      "I remember HUB saying the Fortnite RT performance was indicative of strong RDNA3 ray tracing in future UE5 titles, where RDNA3 would be just as good as Ada Lovelace. But not only is the 4060 beating the 7600 in every other ray tracing title, it is also faster in Fortnite RT.",
      "The 6700XT comes with Starfield Premium ($30 difference) however and 12GB of VRAM. \n\nThe 7600 makes no sense to me because you go from $260-$70=$190 to $320-100=$220 to make a gap of $30 for 12GB of VRAM and performance close to a 4060Ti in most titles. All assuming you'd purchase Starfield Premium regardless.",
      "7600 also comes with Starfield.",
      "Yeah. I got a 6700xt for $300 on prime day",
      "I have a 2060 and I have played with RT on with DLSS in several games with over 60fps at 1080p. HUB has brainwashed a legion of users into thinking RT is unusable on low end cards and that DLSS is terrible at 1080p when neither can be further from the truth. A bit of clever settings tweaks and you can get a decent experience with RT enabled even on these cards. And by these cards I mean Nvidia cards because it is unusable on AMD but maybe that's why HUB is trying so hard to invalidate the feature entirely.",
      "I do like their new benchmarking format with the stronger RT showing. Hope they keep this for the 7800/7700 reviews.\n\nKind of odd that AMD prices have actually gone up in the last few weeks. A week after launch you could get multiple 7600 for $250 I think, but now many of those are $10 to $20 higher again. Better just to wait for a 4060 to go on sale for $280-290.",
      "It is sad that while the 4060 is 15-18% faster than the 3060 (which is not nothing, I mean, the 4060Ti is just 5% faster than the 3060Ti), so there is a performance uplift to be had, the VRAM capacity cut down to 2/3 definitely hurts it. The 4060 is quite faster, but once you are out of VRAM that becomes irrelevant, it is game over. The 3060 will be a relevant card for longer than the 4060, even though it is slower and two years older.  \n\n\nFor the 7600 there is nothing to be said. It is for all practical purposes a rebranded 6600XT/6650XT. Ever so slightly faster. An embarrassing product.  \n\n\nStill, if I were to recommend any card between these two, I would say skip both. Get either the 6600XT/6650XT (especially if you want Starfield) which are still available and cheaper than the 7600, or get the 3060.",
      "6700 XT is the best GPU you can buy at the current pricing, it beats all of these crappy so called new gen GPUs.",
      "The problem is that new AMD cards do not have any major advantages/features over last gen cards. You get AV1 encoding and displayport 2.1, but that is it. Both of those things may not even be needed/used by the people buying the cards, FSR2 works with any card, FSR3 doesn't exist, RT gains are almost 1:1 with raster improvements, and the 32CU RX 7600 and 32CU RX 6650XT are within 2% of each other. At least with RTX 40 series cards, you can point to DLSS3 or massive efficiency gains even if the price is trash.\n\nStarfield comes out early September, and everyone will want to play it on day 1. A flash sale $300-330 RX 6700XT/6750XT comes with a key to play it, and I don't expect price/performance to improve from there.",
      "Well, on the bright side this means that both 6000 series AMD and 30 series Nvidia cards will be viable for longer. If performance remains stagnant there‚Äôs no need to upgrade for many years to come.",
      "Is that really very abnormal? Didn't the GTX 1080 outperform the RTX 2060 in FPS per dollar a month after launch with 1080 clearance pricing?1070 vs 1660ti? Didn't the R9 390 and 290 outperform the Rx 480 a month after launch in perf/$? I'm curious to know, but it's hard to find market prices that far back.",
      "Prices went up a couple of days after the Starfield bundle started. AMD has to pay Bethesda/MS for a Starfield license to bundle it. Granted, AMD is paying a FAR lower price than end users, but it's not nothing.\n\nAdding to that, AMD RDNA2 sales likely increased due to the Starfield promotion and the 4060/TI's impotence while supply also decreased, so the prices went up a bit.",
      "The 3060 was also a pretty miserable card to start with being barely faster than a 2060 Super, so for it to still be going for that price is especially sad, 12GB or not.",
      "I am, means I don't have any buyer's remorse that's usually there after the new gen after the one you have comes out.",
      "I don't understand why that is an excuse for RDNA3 underperforming on the 7600 when the 4060 has the exact same memory situation. Both cards are working with the same amount of data transfer."
    ]
  },
  {
    "brand": "amd",
    "generation": "7000",
    "tier": "low",
    "matched_keywords": [
      "7600"
    ],
    "title": "Starfield Supports Nvidia DLSS | RX 7600 XT 12GB | RTX 4070 Price Drop Leak",
    "selftext": "",
    "comments": [
      "Is this channel not banned in other subs?",
      "It 100% should be banned.",
      "Sorry the whole AMD blocked Bethesda from using DLSS nonsense needs to stop. Its Prime bullshit at best.  1-5 explains a lot.",
      "There is a subset of users here that has a particular hatred towards this channel.",
      "To cut through all the noise:\n\nClaims made:\n\n1. Reiterates claim that there was never any technology exclusivity stipulations, citing devs.\n2. Insiders at Nvidia confirm their Starfield drivers are bad/incomplete, citing a lack of funding and reallocation of resources to AI development. (Seems reasonable.)\n3. Per Bethesda insider, Starfield originally used a renderer built on Vulkan API, then switched to DX12 late in development. They partnered with AMD for two reasons: 1) to get help implementing FSR2, and 2) to get help switching from the Vulkan-based renderer to DX12, given AMD's intimate understanding of/contributions to Vulkan (by way of Mantle).\n4. Bethesda didn't have a working version of the game to present to Nvidia and Intel for optimization until late into production. \"A lot of the old Vulkan codebase was there with AMD DLLs that had not been translated yet.\"\n5. AMD insider says \"most of the prelaunch work \\[AMD\\] did on this game was just trying to make it run well on their cards at all\" rather than necessarily optimizing their drivers, hence some lingering issues like the widely-reported stars not rendering.\n6. RTX 4070 has dropped in price to $549 in response to 7800 XT. (Confirmed/corroborated by others as well.)\n7. \"RX 7600 XT 10GB/12GB\" likely not real. Source speculates it could be \"just another example of an AIB staking out a name, or corporate is trying to mess with Nvidia.\"\n8. Intel Twin Lake is a refresh of \"Alder Lake N\" all-E-core CPU, still using Gracemont cores, fabbed on Intel 7 process.\n\n\\---\n\n\\---\n\n\\---\n\nA couple thoughts:\n\n1. Couches dev statements in lots of \"would\" and \"would not\" statements, no \"did\" and \"did not\" ones. In other words, doesn't seem he spoke with many, if any, devs who 1) had AMD-sponsored games, and 2) said definitively whether their contract imposed a ban on competing technologies or not. (That's not to lend the original accusation any undue legitimacy. It's still extremely sus as well, and any self-respecting person should remain highly skeptical, at least in my view of it.)\n2. &#x200B;\n3. Does his own analysis a major disservice when he discusses the Starfield partnership and mischaracterizes the announcement as \"self-described \\[by AMD\\] as a surprise.\" As proof he cites a Digital Trends article that begins, \"AMD has just announced an unexpected ‚Äúexclusive‚Äù partnership with Bethesda and Starfield...\" where it's clear he completely misreads it and twists it to fit the narrative he's building, ie that Bethesda contacted AMD late in development for help with Starfield, and AMD were caught off-guard by the request. There's plenty of decent evidence and analysis otherwise, making that bit wholly unnecessary.\n\nThe rest seem reasonable enough.",
      "This is \"Moore's law is dead\".\n\n1-5 explains nothing because nothing this man says is worth listening to. Simply ignore this lying clickbait youtuber, whether he's positive or negative about something doesn't matter, whether he \"has insider claims\" or \"walking talking tree told him\".",
      "As valid as any other leaker here, sometimes they are right sometimes they are wrong. You'd have to ban all leaker Twitter accounts and sites like videocardz then also. At least this guy gets devs on his podcast.",
      "> profit (grift) from some weird GPU wars.\n\nyeah unlike you did with this bs post:\n\nhttps://www.reddit.com/r/nvidia/comments/11rgwwm/hardware_unboxed_to_stop_using_dlss2_in/",
      "Well, in cases like this, a \"control group\" isn't really appropriate. What would a control group look like? Games that have both technologies? AMD-sponsored titles that have one? the other? both? neither? Nvidia-sponsored titles? Non-sponsored titles? And so on. There is no real control group. The hypothesis postulated by Wccftech is \"AMD blocks DLSS from its sponsored titles; Nvidia does not block FSR from its sponsored titles.\" So it's fair enough to do a simple observational study and rudimentary statistical analysis; Wccftech were right on that mark.\n\nUnfortunately, as you say, the sample size they drew conclusions from - 20 titles total, 13 AMD-sponsored, 7 Nvidia-sponsored - was simply too small to, well, draw conclusions from. Gamers Nexus, [as part of basic background research for its news summary video that week](https://youtu.be/w_eScXZiyY4?si=Y9wCRJyQidHmNGvo&t=320), managed to find ***29*** AMD-sponsored titles (123% more than Wccftech managed), of which 14 were FSR-only. They also found [this Reddit post](https://www.reddit.com/r/hardware/comments/14f2nlw/comment/joy38sp/?utm_source=share&utm_medium=web2x&context=3) with a more general analysis of all games that have some form of image reconstruction tech. From that data, it's impossible to say with any great deal of certainty that any vendor is/was doing any amount of blocking of any technology.\n\nRegarding AMD's \"No comment\" response to GN...\n\n\\- Given the specificity of GN's question (\"Does the contract between AMD and Bethesda have any language which intentionally blocks ***or could be construed as blocking or limiting*** Bethesda's ability to integrate alternative upscaling technologies within Starfield?\" (emphasis mine)), and...\n\n\\- Given what Frank Azor said in a recent The Verge interview (something like \"Yes, we request that partners prioritize our tech, but it's a request, not a demand.\"),\n\n...it's not surprising that AMD would choose not to comment.\n\nOf course, Azor's statement to The Verge could just be a smokescreen and they indeed did have such contractual language in place that they walked back after the backlash... but without a smoking gun pointing to any of that being the case, that suggestion holds about as much water as me suggesting that Lisa Su regularly dices onions super fine for Jensen Huang, who then takes them and massages them into his open eyes for fun.",
      "I'm a programmer, I have a game open in the background a lot. And I do stuff in Unreal a lot. There's a lot of usage of my 3D card.",
      "Seems reasonable.",
      "What irritates me the most is that regardless of whether AMD *did* block DLSS or not, the initial accusation itself is so poorly-written and so poorly-argued that it should have been dismissed out of hand but was instead uncritically taken up by almost everyone, including members of the media, and ESPECIALLY including outlets like HUB whose judgements I generally held in high esteem beforehand. Literally the only group I saw treat this with a proper amount of skepticism was Gamers Nexus, who rightly saw too little evidence to give it the time of day. HUB and others gave the accusation a token nod of skepticism, but for the most part treated it as fact, to the point where they were posting whole videos uncritically arguing with AMD fanboys uncritically defending a practice that hadn't even been proven.\n\nIt's a whole ass controversy built on such an obviously *stupid* base. Like, if the Wccftech article had been written better, if it had hidden its intentions better, I could at least appreciate the subtlety. But it wasn't, and it didn't, and IT STILL WORKED. JFC, lol.",
      "I'm still waiting for that control group I keep asking for. This whole thing went off the rails because someone made a list of a select handful of games (non-exhaustive) from both sides with no control group and came to an incomplete conclusion. And then when AMD marketing fumbled the response people used that to corroborate the shitty data...as if we trust AMD marketing to be competent all of a sudden.",
      "Bottom of the barrel click bait content and spreading lies to profit (grift) from some weird GPU wars.",
      "> Otherwise, my computer is on 24/7 \n\nso you don't care about efficiency and energy usage so this whole point is moot.",
      ">just \"accidentally\" unanimously decided not to implement DLSS?\n\nDid I say anything about anyone either accidentally or unanimously deciding not to implement DLSS?\n\nBut to your point: The data so far shows you're wrong, which is entirely my point. Your statement - that \"pretty much only the \\[devs\\] paid by amd ... unanimously decided not to implement DLSS\" - only holds true if you trust the small sample size of 20 games provided by Wccftech (13 AMD-sponsored, 7 Nvidia-sponsored). I wrote in another response, you might have seen it, that Gamers Nexus managed to look at 29 AMD-sponsored games - over double the 13 Wccftech did - and found that less than half (14 of 29) were FSR-exclusive. Gamers Nexus were doing little more than the most basic of background research; you would expect Wccftech to have at least been able to find that many.\n\nSo, does \"pretty much half the \\[devs\\] paid by amd ... unanimously decided not to implement DLSS\" sound nearly as nefarious? No, it doesn't.\n\n>DLSS and FSR take roughly the same amount of dev time to implement, DLSS is superior and Nvidia has an 80% market share.\n\nThe way I understand it, implementing either one takes a bit of effort, then substituting the other in is fairly simple. However, implementing is one thing; QAing and testing is another entirely. You have to make sure the menu toggle works correctly. You have to make sure the algorithms switch correctly. You have to make sure the game recognizes which cards can and can't use DLSS and eliminate that option as necessary. And so on and so forth. It might not be a lot of extra work, but it might be enough that you decide to go with the broadest coverage option rather than the one that provides the best picture quality.\n\nAs for \"market share,\" just citing Nvidia's market share is disingenuous when it comes to discussing the use of DLSS. As you know, DLSS requires the use of an RTX GPU, and my rough math using the Aug 2023 Steam hardware survey shows that only 40% - or half of the total 80% Nvidia market share - are RTX GPus. This means, obviously, that 60% of the market can't use DLSS. However, 100% (or close to 100%, anyway) of the market can use FSR2.\n\nAgain, this isn't to say whether AMD did or did not, or does or does not, block DLSS from its sponsored titles. It IS to say that the Wccftech article that launched this whole controversy was poorly-written and poorly-researched, and it should have been dismissed out of hand almost immediately rather than be taken up uncritically as gospel by the gaming community writ large.",
      "yeah thats cringe. i cant imagine myself watching this. i dont gain anything from keeping tabs on this stuff. hes getting paid though so its different. im not getting paid",
      "He has been 70-80% legit last videos, including navi 4c or 7900GRE die shot. Prices cuts too.",
      "Yep, people feed into it. It's like some mental virus, just like console wars and other fanboyisms.",
      "If you want to measure FPS when using upscaling then using the same algorithm across the board to keep variables to a minimum is required.\n\nIf you want to measure IQ then you use the best upscaling method available for each GPU/Game combo.\n\nWhen HUB used FSR across the board for a test it was for the former case, they were not testing IQ, they were measuring FPS so were doing it in a way that kept the workload the same across all GPU hardware which is the correct way to do it.\n\nThey also mentioned (and showed in a later video) that DLSS will give even better IQ for broadly the same kind of frame rate increase so where available always use DLSS instead.\n\nIt is a very logical approach to take in the scenario they were using it for."
    ]
  },
  {
    "brand": "amd",
    "generation": "7000",
    "tier": "low",
    "matched_keywords": [
      "7600",
      "rx7600"
    ],
    "title": "should i upgrade from a rx7600 8gb to the new intel gpu ? ",
    "selftext": "specs:\n\n‚Ä¢ Ryzen 5 7800X3D \n‚Ä¢ ASRock B650M-C System Board\n‚Ä¢ AMD Radeon RX 7600\n‚Ä¢ 16GB DDR5 RAM\n‚Ä¢ 1TB Solid State Boot Drive \n\nyay or nay ? ",
    "comments": [
      "Probably not. According to techpowerup it's only a few % faster. Not much of an upgrade apart from having 50% VRAM.",
      "Definitely not. The B580 is a better pick over the 7600, but not a good upgrade for someone who already owns one. You‚Äôd be better off waiting for the upcoming B770, or RX8000 series.",
      "gotcha, thanks for the suggestion :)",
      "Not sure why you would unless you can get a refund. That's more of a side grade than an upgrade.",
      "thanks for the comment :)",
      "understood. thanks for the comment :)"
    ]
  },
  {
    "brand": "amd",
    "generation": "7000",
    "tier": "low",
    "matched_keywords": [
      "7600"
    ],
    "title": "Arc B580 or rx 7600",
    "selftext": "So I‚Äôm building my first gaming pc that I also want to stream on but I‚Äôm stuck in between the b580 or the 7600 \nMy specs are \n\nRyzen 5 7600\n32 gbs of ddr5\n1tb ssd\nB650m motherboard \n650 watt power supply \n\n",
    "comments": [
      "Why only choose between the Intel ARC Battlemage B580 12 GB or the AMD RX 7600 8 GB? Why not the RX 7600XT 16 GB card?\n\nIf they are both around 250 US dollars, then the RTX 3060 12 GB and RX 6700XT 12 GB are both far better than either of the two you mentioned.",
      "This end of the market is really lacking. The 7600 is good for the money the 7600XT IMO isn't. I like the look of the B580 but the CPU thing worries me. I have a 5900X which is old but perfect for what I need.\n\nThe only other route for me is 6800XT's used but they are almost at 7800XT new (¬£60+).",
      "Two reasons the build guide I used has the b580 and then the 7600 as the alternative and also I want my gpu to be new and not used"
    ]
  },
  {
    "brand": "amd",
    "generation": "7000",
    "tier": "mid",
    "matched_keywords": [
      "7700"
    ],
    "title": "Possibly cheaper RX 7800 outperforms RTX 4070 by 5.2% while RX 7700 beats RTX 4060 Ti by 15% in leaked benchmarks",
    "selftext": "",
    "comments": [
      "Spoiler Alert: They won‚Äôt.",
      "If amd prices these right, it could finally be a W for gamers. Doubt it tho",
      "I mean how many times have we seen this?\n\nNvidia releases a shitty priced GPU -> \"Massive opportunity for AMD to seize market share at a given price point, if only they take it!\" -> AMD releases equally shitty priced GPU, just slightly cheaper  -> Wait for a year of constant price cuts for the said GPU to actually make sense -> New generation comes around -> Nvidia releases a shitty priced GPU",
      "So another way of saying basically within margin of error of the RX 6800 and RX 6800XT?  \nDoesn't sound as great if you put it that way right? lol",
      "Spoiler Alert: You'll probably have to wait 3-4 months",
      "These percentages are gonna mean basically nothing if they're not priced a lot lower then what they're competing with.\n\nThat 7800 especially is gonna have to be a good 100-150 cheaper then the 4070 to make a dent.",
      "RDNA2/RDNA3 cards do better in Timespy compared to their respective NV competition so this means nothing\n\nA 6800 XT for example easily beats a 3080 in FS/TS but they're similar in gaming (raster anyway)\n\nSame for 7900 XTX/4080",
      "Sad to see an 800 class competing for dirt with a 70 class. This gen is a giant failure for amd.",
      "It's idiotic that these didn't launch before Starfield. They get the sponsorship for arguably the biggest game of the year and they don't have any new cards in the most mainstream segment.",
      "Well, for nvidia too, 4090 being the only exception.\n\nThat nvidia's \"70 class\" is a 60 class with a new, fancy name.",
      "I mean 6800 XT performance at current 6800 XT pricing is closer to trolling than sensible imo.",
      "as if timespy scores matter",
      "No they didn't. And it worked with Ryzen. Way better product for cheaper.",
      "That's been the message for 3 years running. However, AMD never has. It's why Radeon doesn't see the success Ryzen did.",
      "it would have to be ¬£500 at the absolute highest to make sense",
      "yup! 4060 is actually 4050. dumbsterfire of a GPU gen.",
      "Which, in the end, isn¬¥t THAT long! But yeah, coming with the right price from the start would be so much better PR.",
      "4080 bs 7900XTX -tie, AMD cheaper\n\n4070ti vs 7900XT- AMD win, AMD cheaper\n\n4060 vs 7600-  Nvidia win, AMD cheaper\n\nOnly one clear performance winner although AMD is cheaper at each performance tier, however the market adds a premium for Nvidia RTX branded technologies over Radeon RX technologies",
      "talking 7700 roughly 6800 and 7800 roughly 6800XT, should have clarified",
      "5% for worse RT, worse upscaling, worse VR, worse power efficiency, generally worse software etc. it better be $100+ cheaper, or the 4070 is a way better buy.\n\nEdit: i agree adrenaline is better, but afterburner and rivatuner is better than adrenaline/geforce. So I dont really think thats all that relevant."
    ]
  },
  {
    "brand": "amd",
    "generation": "7000",
    "tier": "mid",
    "matched_keywords": [
      "7700"
    ],
    "title": "AMD announces Radeon RX 7800 XT 16GB and RX 7700 XT 12GB graphics cards - VideoCardz.com",
    "selftext": "",
    "comments": [
      "The RX 7700XT has a much higher CU count than anticipated. A lot of people were expecting 48CU.\n\nIt will all come to the price now. Those cards are not bad on paper but the price will decide everything.\n\nIf priced between 399 and 429 USD, the 7700XT could be a killer. There is a performance gap with the 4060Ti so they could charge it higher, but with the memory deficit it would be hard to justify.\n\nThe 7800XT is really in a weird place though. 499 USD could be really good. 549 would be meh.",
      "Specs on the 7700 XT look better than expected. The fact that they are positioning it against the 16GB 4060 Ti, a $500 card, doesn't bode well for the price though.",
      ">If priced between 399 and 429 USD, the 7700XT could be a killer.\n\nTo be honest I don't see that happening based on the slides in that news article. They are comparing the 7700XT to the 4060Ti 16GB, so $449 for 7700XT is more in line with that.\n\nEDIT after the prices were announced:  \n$499 for the 7800XT seems OKish, but $449 for the 7700XT is ROFL pricing. It says in EU the prices will be 549 es 489 respectively and right now you can still get the 6800 for 459 and 489EUR which seems like a significantly better option than the 7700XT.",
      "Disappointing that 7800XT=6800XT in terms of performance. Pricing at 449 to 499 dollars would be ideal but knowing AMD they will price it at 549 or similar which is terrible compared to a 599 dollar 4070. The 4070 has all those extra features.\n\nFinally some generational per CU performance improvement.\nThe 60 CU 7800XT is matching 72 CU 6800XT. Not much but it's there.",
      "Its gonna be ~450 and ~550\n\nThere is a reason why they compared it to a $500 and $600 card.\n\nIf it was $500 for the 7800xt they would have compared it to the 4060ti 16 directly .",
      "AMDs marketing department is unhinged. I'm guessing $479 and $579 right now.",
      "That's actually fine if you suitably reduce the prices across the board\n\nFor eg. A 7700xt at 429 or something with 6800XT level of performance.\n\n7600XT at 299 with 6700xt level of performance. That way even if there is no performance improvement you reduce the prices low enough that lower tier cards can enjoy higher tier of performance for the same cost.",
      "AMD will *technically* undercut, just not enough to matter.",
      "7700 XT actually seems interesting, if it really is 12% faster than a 4060 Ti that puts it around 20% ahead of 6700 XT, not an impressive gen to gen performance gain but way better than 7800 XT's literal similar exact performance compared to it's predecessor 6800 XT which is an oof 4060 moment for AMD.\n\nNow, it just depends on the pricing, if 7700 XT is priced at over $400 then it is disappointing, same can be said with 7800XT if it is priced over $500.\n\nIdeal pricing should be:\n\n**7700 XT:  $400 or less**\n\n**7800 XT:  $500 or less**",
      "At 399 it's just... worse value than the 6700xt? Same amount of vram, uses slightly more power, bit better performance, but it costs way more?",
      "All cards this generation are worse value than previous generation honestly. But at 399, it might be equal value (in terms of FPS) depending on how much more performant it is than the 6700 XT. At the very least, 6700 XT is better value because AMD themselves made it so by reducing it up to 25% from what it was in January.",
      "my heart hopes you are wrong, but my brain says he is right....",
      "It is the same though. Sure no one with a 6800XT would ‚Äúupgrade‚Äù to a 7800XT, but if they price it exactly at or above what the 6800XT is available at right now, then why did those ‚Äúnew people‚Äù wait? \n\nThe answer is they were waiting for 6800XT performance for 6700XT price or less, because that‚Äôs the precedent for the past decade or more. Improving energy efficiency and keeping the price the same while shouting ‚ÄúINFLATION!‚Äù isn‚Äôt good enough to justify these cards‚Äô existence - especially not when RAM chip prices are way down, AMD is building these on a mature previous gen node, and while they‚Äôre not breaking record profits, they‚Äôre still more than profitable and being down 18-20% from the COVID spike is misleading at best. \n\nIf the XTX had simply been the 7900 XT and everything else got bumped down a tier, this lineup would look great. A 7700XT (current 7800XT) with the performance of a 3080 12GB or 6800 XT for $450? Awesome! Positive momentum and genuine reason to justify a purchase or recommend. \n\nInstead we got the ‚ÄúBiff is King‚Äù timeline, but without real hoverboards.",
      "No FSR 3.0 info in the slides so probably a no show. AMD must move on to next gen sooner rather than later if they hope to stay relevant in the gpu market. Nvidia has pushed ahead in RT and AI and AMD seriously needs to catch up.",
      "If it‚Äôs true that the 7800 XT more or less matches the 6800 XT in performance, I genuinely wonder what AMD plans to do to fill the gap between that and the 7900 XT. There‚Äôs quite a big performance delta between the two. I know the 7900 GRE exists, but are they planning on giving it a wider release?",
      "The radeon playbook",
      "No, but if you were AMD, it would be wise to compare it to the 16gb card, because its priced so ridiculous. Here's hoping for $399 still.",
      "For new people? It's not \"the same\", it has similar performance but greater power efficiency and new feature sets.\n\nThis isn't really for people who bought the 6800xt to \"upgrade\", its for people buying a card today to get something better overall.\n\nIt's not a far out idea, its what most companies do and have always done.",
      "I predict:\n\n$579 for 7800XT\n\n$499 for 7700XT",
      "Now watch AMD burn their market share by pricing themselves out of the market, get horrible reviews, only to go back to reasonable price 3-6 months after damage is done.\n\nEdit: Well, color me surprised for 7800xt. \nThey still pulled that shit for 7700xt, though."
    ]
  },
  {
    "brand": "amd",
    "generation": "7000",
    "tier": "mid",
    "matched_keywords": [
      "7700"
    ],
    "title": "AMD teases upcoming Radeon RX 7800/7700 XT GPUs to be unveiled at Gamescom this week - VideoCardz.com",
    "selftext": "",
    "comments": [
      "The only way this will be a good unveiling is if the 7800XT launches at $499 and the 7700XT launches at $399.",
      "Can't wait to see AMD release a card with worse value than the current 6800 XT at 520$ - which one could buy 6 months ago now - it's going to be great, especially after DLSS3.5 and 4070 being already 6 months old, and probably still offering better value overall.",
      "They will just wait until the 500$ 6800xt's run out and release a 600$ 7800xt with 7% better performance.",
      "If they give 6800xt performance for 6800xt price i won't be surprised.",
      "Its not a case of 'giving up', just evaluate each one as it comes out.",
      "And for 50$ more!\n\nWhat a bargain haha",
      "7900 GRE is already cutting it close to the 6800 xt in performance. 7800 xt matching 6800 xt is the best possible outcome now.",
      "GRE - aka \"Greatly Reduce your Expectations\"",
      "And the crowd goes mild haha.  It's just disappointing at this point how AMD is terrible at generating interest in their GPUs.",
      "Yeah I think I've given up on AMD GPUs now.",
      "...IF it has better performance.  It may not.  It may end up being a mere 7800 that beats the 6800 but lags the 6800 XT.",
      "Crypto days are over and you cannot do much AI work on AMD cards. They just for gaming.",
      "i saw someone else say that GRE meant \"Gimped Radeon Edition\" lmao",
      "No.\n\nRumour source is \"Moore's Law Is Dead\" and he doesn't have a good track of legit leaks.",
      "HD 5870 to HD 6870 vibes. The 6870 was slower...",
      "GRE = GREED, but they were so greedy that they cheaped out on the remaining letters ED.",
      "> $399 vs $269.\n\nJesus, I know this is beating a dead horse, but god damn those GPU prices.",
      ">*Yes I do take advantage of those features.\n\nWith your 5700xt?",
      "Is there any hint of FSR 3 being unveiled at Gamescom officially from AMD themselves?",
      "At some point AMD HAS to realize that they're not on an even playing field with Nvidia, right? They can't keep releasing cards with nearly the same price to performance, but worse features and power consumption, and expecting them to sell right?"
    ]
  },
  {
    "brand": "amd",
    "generation": "7000",
    "tier": "mid",
    "matched_keywords": [
      "7700"
    ],
    "title": "Official AMD Radeon RX 7800 XT & RX 7700 XT gaming and synthetic benchmark leaked ahead of launch - VideoCardz.com",
    "selftext": "",
    "comments": [
      "So the 7800 XT has 39% better value than the 6800 XT did at launch (1.07/0.77). That's pretty decent (about the price to performance uplift as the 3060 TI was to the 2060 Super), but I'm sure the goalposts will migrate soon enough.\n\n(For the record I think 7800 XT was a stupid name and it should've been called a 7800, but the price is perfectly fine. And relative to Nvidia it's quite excellent.)",
      "tl;dr (based on leaked gaming benchmarks)\n\nRadeon RX 7800 XT 16GB vs. RTX 4070 12GB\n\nRASTER:¬†+6.9%\n\nRT:¬†-11.6%\n\nAVG:¬†+0.5%\n\nRadeon RX 7700 XT 12G vs. RTX 4060 Ti 16GB\n\nRASTER:¬†+15.9%\n\nRT:¬†-5.4%\n\nAVG: +8.5%",
      "planning on getting a 7800xt. upgrading from a 1060 6gb.\n\nwas already loooong overdue for an upgrade and it seems like good value.\n\nedit: although I am eyeing the 4070",
      "It's better to wait 1-2 days for HUB and GN reviews. \n\nAs usual, \"official benchmarks\" and leaks are not very trustworthy.",
      "The 7800XT would be like a 6900XT but slightly more efficient if those numbers are accurate.\n\nI'm more puzzled by the 7700XT, which would be like a 6800 non-XT, with similar power consumption but less VRAM?",
      "direction yoke nutty dinosaurs melodic silky jar merciful cheerful fuzzy\n\n *This post was mass deleted and anonymized with [Redact](https://redact.dev)*",
      "Rational posts like this are a breath of fresh air in this sub lately. Nice stuff. Agreed, the naming is bad, but at least the price is right.",
      "Basically, the 7800 XT is a win, but only because nVIDIA didn't release the 4070 as a 4060 Ti for 499$, which I'm pretty sure they could have - but of course, no point where ***cough*** AI ***cough***.",
      "People speculate the 7700xt is overpriced on purpose to push people into buying the 7800xt. Also supposedly the fabrication process has an 85% yield rate, so in theory only 15% of all cards should be 7700xts, but at launch it's 50/50, so they are pushing people into buying all the 7809xt stock. They e been accumulating the chips for many months, not selling the cards yet to get rid of 6000 series stock, then they play this game to push out more 7800xt stick, then will drop the price of 7700xt in a month or two to sell those 15% yields. Assuming I understood the YouTubers correctly, who spread unverified rumors with nameless sources.",
      "Well, that's because the 4060 is objectively bad value though?",
      "Yeah, it‚Äôs decent in isolation. I‚Äôm still kind of annoyed that this particular generational uplift took nearly *three years*, but at least it is one. That hasn‚Äôt happened since the 3060 Ti, maybe the 7600 if we‚Äôre being generous.",
      "The 7800XT....if the leaked performance is true, you get 4070-level performance (high fps 1440p ultra) for 15-20% cheaper. That's solid value (yes not amazing, but reasonable). 500$ is a price many people can afford for a GPU, and now you can get a solid 1440p experience or even 4K for that price.",
      "Note the RT data is quite skewed towards Cyberpunk. They even included RT overdrive benchmarks for w/e reason which was never meant to run on Radeon lmao... even with Cyberpunk benchmarked **4 times** out of the 9 results, the RDNA3 GPUs are still holding up against their counterpart in RT. If you ignore Cyberpunk overdrive, 7700xt is 1.875% faster than 4060ti on average in RT (with Cyberpunk being benched 3 times). The 7800xt would be 4.375% slower than the 4070 in RT as well.\n\nThat brings me to conclude that the 7700xt is actually decent value vs 4060ti 16 GB on paper even if they are both \\~$450. With the 4060ti, you mainly gain DLSS 2 and 3, which isn't always present in all games (or you can pay for it lol ...), and 4GB more VRAM. The 7700xt has roughly equal RT and 15% better Raster on the other hand.",
      "The main reason that happened was oversupply of last gen stock, so AMD fronted the generational value uplift via discounts, then slotted in these two more or less based on that.\n\nPersonally, even if it makes reviews boring, this strategy is **far** more customer friendly than the typical one. These GPU's are designed, and prototypes are made WAY ahead of time, so selling you reheated leftovers for full price one day and then immediately launching something that makes that price look silly is kind of entrapment...\n\nThey would have came out earlier, but people were incensed that last gen clearance pricing was better value than the 7600 (since last gen is more expensive to make for a given tier of performance so selling through it is top priority).\n\nSo since everyone told AMD that launching the 7600 when they did was an unwinnable situation, they held off releasing these two until last gen products were almost out of stock.",
      "The same people defending the 4060 will be screaming the 7800xt is bad value.",
      "AVG isn't useful because it's dependent on the ratio of RT vs non-RT games tested. Ie if you just picked cyberpunk path tracing and one non RT game, the 4070 would be \"AVG 60% faster\" than the AMD card.\nLikewise, they could leave CP2077 PT out and avg RT performance suddenly looks a lot better for AMD.\n\nNevertheless they look like competitive options (though I don't understand why anyone would buy the 7700xt for $50 less).",
      "7700XT is a bad value at 449.\n\n&#x200B;\n\n7800XT at 499 is OK",
      "They're both completely fine nowadays. Both have AV1 for streaming and content creation, and AMD's RT is perfectly fine as well, just slower than Nvidia on matching tiers. It really comes down to personal preference.",
      "You trade dlss 3 and better rt for fsr 3, 100$ saved, more performance and 4gb extra vram.\n\nIf this card even remotely lives up to AMDs claims it should be a no brainer for pure gaming at 1440p +",
      "fwiw, the average RT scores (which tbf, are not in the original data, but videocardz's summary) are unfairly biased by cyberpunk being included 4 times in the overall averages (i mean, all these games are cherry picked to a certain degree, but having the worst AMD performing game included multiple times is particularly egregious)   \n  \nIf only RT ultra is included, which seems reasonable since the 4070 only manages 18fps in overdrive, the 7800xt vs  4070 changes to -4.3% in RT, and overall to +3%. \n  \nNot a big practical difference either way - I just don't like seeing averages just being applied blindly!"
    ]
  },
  {
    "brand": "amd",
    "generation": "7000",
    "tier": "mid",
    "matched_keywords": [
      "7700"
    ],
    "title": "People waiting for the 7800/7700 cards: is it getting hard to justify the wait?",
    "selftext": "I am on this boat. But every week that goes by, I see myself close to jumping off from it.   \n\n\nI will give some thoughts and I would be happy to be proven wrong, and that the 7700/7800 are worth the wait, but I am finding it hard to justify. Here we go:  \n\n\n1. The upper tier of RX 6000 cards are being priced very aggressively as of lately. Namely the 6800XT and the 6950XT. Besides, we pretty much know that whatever price/performance ratio the 7700 and 7800 offer at launch, it is unlikely the beat the discounted 6000 cards. The 7600 vs 6600XT/6650XT was a good example of that.  \n\n2. Free Premium Starfield. That is a $100 game being offered with upper tier RX 6000 cards and we can't tell for sure whether it will be offered with the 7700/7800 cards. These cards are unlikely to be released before Starfield is (which is just 7 weeks away). Moreover, 2023 has been an incredible year for gaming - arguably the best year out of the last 5 years, if not longer. Some are suggesting it is the best year for gaming ever. That might be a stretch. Regardless, each month of this year that goes by without a GPU upgrade, well, it kinda sucks.  \n\n3. RDNA3 offers no significant technological improvement over RDNA2, other than a small performance/watt gain. FSR3 will work for both. Memory (a strong selling point for AMD) won't improve either: the 7800/XT will offer the same memory capacity as the 6800/XT.  \n\n4. AMD is not necessarily under pressure. Their stocks are doing pretty well - the only time in history they were higher was during the peak of the mining boom. Nowadays AI is where the money is. GPUs for gaming is not AMD's top priority, whether we like it or not.",
    "comments": [
      "Your point 4 is incorrect.\n\nThey are under pressure. IP that has been developed and productized needs to make a ROI. Every month it waits, is another month that AMD is losing out on revenue.\n\nIt is likely that AMD is trying to get rid of its 6xxx stock.\n\nBut yeah, I wouldnt wait. The deals are too good right now.",
      "Is the cheapest, on sale RX 7900xtx still $900+?\n\nThen I have no trouble waiting.",
      "I was considering waiting, but looking their product stack and their pricing, there's literally nothing they could release that would be better then a 4070 for me.\n\nI would pretty much need to get a 7900xt performance wise, but using less power, for the price of a 4070, to want to give up the ray tracing performance, DLSS, cuda, reflex, and other nice Nvidia features. Those features really put in work and I'm tired of getting second class support all in the effort of raster performance. We're well past the point of raster being the only thing that matters, I'd happily give up 10-15% or more of my performance if it meant the card was better in all other aspects, and unfortunately that's the position I'm in with Nvidia and AMD.\n\nThis coming from someone currently on a 5700XT. When I bought that card over a 2070 super, ray tracing and DLSS were jokes. But if I could know how much better they were gonna get in the future I would have happily spent more on the 2070s.\n\nThat, and AMD's pricing here in Canada sucks right now anyways and I couldn't get a 6950XT for anywhere close to the price of a 4070 even if I did want that card, which I don't.",
      "What are you even talking about?\n\n> *nothing* is standard except the VRAM config\n\nThey are literally all the exact same card and will perform within 5% of each other, the only difference is the coolers and the warranty. \n\nPaying extra for better overbuilt coolers is stupid, you won‚Äôt get any better performance.",
      "I can understand someone not wanting the 6950xt due to the high power consumption, but the 6800xt is much more reasonable, and is appearing at or below $500 right now. Not much point in waiting. I got mine for $479 a couple months ago.",
      ">Moreover, 2023 has been an incredible year for gaming - arguably the best year out of the last 5 years, if not longer. Some are suggesting it is the best year for gaming ever. \n\nWait, what? Did I miss something? What games are you talking about to call it \"best year for gaming ever\"?",
      "Agreed, I think they're really missing out a chance to grab the 2023 mid-range GPU market by the balls. I'm in a similar boat as OP's except I'm waiting on a bit of money to come in which I will use to make a purchase and I've been crossing my fingers for a 7700xt release. Really didn't want to buy 2+ year old hardware. Sigh",
      "> Really didn't want to buy 2+ year old hardware. Sigh\n\nTheres always pros and cons to buying brand new hardware. 7000 drivers were a mess at launch and it took months to fix them. Meanwhile, 6000 series drivers have been stable for well over a year. Another example, when I got my 5900x and x570 mobo in late 2020 (when 5000 series cpus launched), my ram wouldnt run at the frequency advertised (3600 mhz) without my system crashing like crazy. I had to run it at 3200 for over 6 months until there was a bios update that fixed it. So I ended up losing performance and paid for something I couldnt fully use for 6+ months. New tech is almost always overpriced at and around launch too.\n\nI get the allure of buying the brand new, shiny thing, but is it really that big of a deal to buy 2+ year old hardware? When you go car shopping, do you only look at the 2023 models and ignore everything 2021 and earlier? Even if you get most of the performance/features for a lot less money? What about TVs or monitors? The latest lg c3 is 25% more money than a c2 and has marginal performance increases at best. Most would say it's a waste of money to buy the c3 over the c2. \n\nI just think we need to change our mentality when it comes to these things. You shouldnt feel bad because youre buying something thats a couple years old. Especially when that thing thats a couple years old is priced well and is a big performance increase to whatever youre currently using.",
      "I just bought a 6800xt and not feeling bad at all. Couldn't wait for a release that no one even heard rumours about the date.",
      "> ‚Ä¶an MMO without class system as everyone is a DPS, with no economy‚Ä¶\n\nIts an ARPG. It‚Äôs not an MMO. You literally described any character in an ARPG. Maybe next time check out the genre of the game before jumping into it?\n\nNot disagreeing that its a disappointment still tho. But it‚Äôs certainly for others reasons than the ‚ÄúMMO‚Äù reasons you‚Äôve stated.",
      "What‚Äôs wrong with asus, msi, and lower end asrock cards? they perform the same as other brands since they are the exact same PCB under the hood.",
      "I jumped off and bought a 6950xt for $570 USD brand new lol",
      "It's incredible year for gaming, just maybe not that good for PC gaming due to horrible ports, but we got Hogwarts Legacy, Atomic Heart, Everspace 2, Dead Island 2, Jedi Survivor, Diablo 4,  Street Fighter 6, FF16 and more on consoles like new Zelda. There are also many potentialy good games coming like Starfield, Baldurs Gate 3, Mortal Kombat 1, Lies of P, Alan Wake 2 and thats mostly big names there are more that I'm forgeting",
      "I gave up 7-8 months ago. Not as in i gave up and bought another card, i gave up on this entire generation. Currently I'm waiting till next gen.\n\nAt first i was targeting a 7800 this gen....but then we found out it was not navi31 based and thus not released with the first wave; so then i was begrudging considering tiering up to a 7900xtx...but its value just was not good enough for me once the benchmarks came out....if it was $850 7 months ago i would have bought one, but not anymore, too late for amd/nvidia...do better next gen....\n\nMy desire for a new card is building again....the 8gb card i have now is not enough even at 1080p. To clarify its enough to play every game on the market at 1080p....but its not enough for me, i have had to lower settings a few times already this year because of the 8gb vram limit, which is becoming more and more undesirable.",
      "Newegg has a couple that are *technically* under $900 pretax right now:\n\n[Asrock Phantom](https://www.newegg.com/asrock-radeon-rx-7900-xtx-rx7900xtx-pg-24go/p/N82E16814930081?Item=N82E16814930081&nm_mc=AFC-RAN-COM&cm_mmc=afc-ran-com-_-PCPartPicker&utm_medium=affiliate&utm_campaign=afc-ran-com-_-PCPartPicker&utm_source=afc-PCPartPicker&AFFID=2558510&AFFNAME=PCPartPicker&ACRID=1&ASID=https%3a%2f%2fpcpartpicker.com%2f&ranMID=44583&ranEAID=2558510&ranSiteID=8BacdVP0GFs-QepXz8tfA44LmkS17.zQrg)\n\n[MSI Trio](https://www.newegg.com/msi-radeon-rx-7900-xtx-rx-7900-xtx-gaming-trio-classic-24g/p/N82E16814137781?Item=N82E16814137781&nm_mc=AFC-RAN-COM&cm_mmc=afc-ran-com-_-PCPartPicker&utm_medium=affiliate&utm_campaign=afc-ran-com-_-PCPartPicker&utm_source=afc-PCPartPicker&AFFID=2558510&AFFNAME=PCPartPicker&ACRID=1&ASID=https%3a%2f%2fpcpartpicker.com%2f&ranMID=44583&ranEAID=2558510&ranSiteID=8BacdVP0GFs-3gx3XaUBtMGT4Iiwc0EqnA)\n\nWhich I know is probably close enough to not really change your point, but there's a few more which are getting close to $900; it wouldn't surprise me to continue to see price drops.",
      "And even when 7800 comes out, it won't be officially able to run ROCm, unlike all nVidia GPU's.\n\n[ROCm supported GPUs](https://rocm.docs.amd.com/en/latest/release/gpu_os_support.html#supported-gpus)  \nvs  \n[CUDA supported GPUS.](https://developer.nvidia.com/cuda-gpus)",
      "Yeah AMD really dropped the ball on productivity. I learned that the hard way when AI upscaling first started taking off and I really wanted to try it out and learned all the popular upscalers people were recommending all uses cuda and pytorch.",
      "Typically most cards use the reference PCB design. Which means the VRMs, traces, power delivery capability, all of that is exactly the same. The only difference being the cooler.\n\nMaybe you're overestimating how many cards bother going off reference design? Usually it's much more expensive cards and at the top end, stuff like what EVGA did with their Kingpin variant of cards, but not their more standard lineup.",
      "Most of those games aren't even that good.",
      "I've had enough and went with Intel.\n\nI got an A380 and all AI and deep learning tools just work.\n\nIntel even integrated AI image generation into GIMP.\n\nhttps://github.com/intel/openvino-ai-plugins-gimp"
    ]
  },
  {
    "brand": "amd",
    "generation": "7000",
    "tier": "mid",
    "matched_keywords": [
      "7700"
    ],
    "title": "AMD Radeon RX 7700 XT drops to $349 for the first time, includes $60 AMD game bundle",
    "selftext": "",
    "comments": [
      "If prices stay low that might finally be a decent 2070 Successor.",
      "The entire lineup from rdna3 is probably gonna receive a ton of price cuts from prime day to black friday. Rdna4 is right around the corner so they wanna clear out all the old stock they have from previous gen.",
      "Bought my 6700xt for $330 2-3 years ago. Crazy that RDNA3 is taking this long to fall.",
      "This is really a value card with afmf2",
      "6750Xt is still $330 brand new.  Let that sink in.",
      "But folks gonna keep buying shitty 4060s because muh RT!",
      "Pro equivalent GPU for $350 is a good deal. Should've been the price from launch maybe AMD would've moved some units.",
      "The true neckbeards buy the 8gb 4060 Ti.",
      "The raster is plenty fine on the 7700XT, along with the extra VRAM. It's only lagging behind primarily with RT, which most mid-tier cards are not capable of providing a stellar experience, especially a bottlenecked 4060.",
      "Lossless my arse üòÖ but use whatever, gives good value to the card",
      "There is absolutely no guarantee that FSR4 will be supported by RDNA3. There is absolutely no way that one will run out of VRAM on textures in any conventional setup at 1080p with 12GB VRAM. At higher resolutions this GPU will run into compute problems MUCH-MUCH earlier than it will run out of VRAM.\n\nStop being obsessed with something that doesn't deserve it. If VRAM is enough - it is enough. Having more is a waste.",
      "I actually picked up mine for $389.99, mere weeks before this price drop, but luckily it qualified for 2 bundles with 2 games each so I ended up getting Space Marines 2, Lies of Pi, Starfield (not just standard but the $100 premium edition) and then later when it comes out, Unknown 9: Awakening (although honestly, i don't really care too much for Unknown 9 and Starfield but free games are free games)",
      "Pretty much the same",
      "As a 6600XT owner it's annoying, I want an actual upgrade that doesn't cost $500",
      "lossless scaling is absolutely garbage",
      "Would be a much easier sell if it had 16GBs of VRAM like the RX6800.",
      "It's on steam, a piece of software that can give older games fsr support and/or frame generation, currently you can get up to x4 'fake' frames, with x2 being the lowest setting.\n\nHighly recommended for lower performance graphics cards on older games if you want a more 'smoother' feel. Mid tier, for some modern heavy GPU reliant games I'd recommend it if the game doesn't support framegen/fsr. Wouldn't recommend for higher tier GPU's as you'd have AFMF 2 or DLSS if you're NVIDIA and both are good for their uses.\n\nDigital foundry did a video on it 2 months ago here:\nhttps://youtu.be/69k7ZXLK1to?si=L8PL7mRa8C3W8UZ3\n\nThough the information might be a bit outdated.\n\nAnd here's some secret sauce for how it actually works and how you can manipulate the program to gain up to x8 fake frames: https://youtu.be/dQw4w9WgXcQ?si=XaztyfW2Ba34YlOp",
      "Isn't 4060 power efficient tho?",
      "Yea I got on the Zen 4 price cuts earlier in the year. Looks like AMD is not afraid to do stuff like this.",
      "In my country the 6750 xt Gaming x trio costs around 500$......"
    ]
  },
  {
    "brand": "amd",
    "generation": "7000",
    "tier": "mid",
    "matched_keywords": [
      "7700"
    ],
    "title": "AMD Navi 32-based Radeon RX 7800/7700 series reportedly targeting September launch - VideoCardz.com",
    "selftext": "",
    "comments": [
      "Just in time for the 6700/6800xt stock to finally dry up probably",
      "Really wondering how these will be positioned. With the 'low' price of the 7600 there is plenty of room to price these competitively - but I somehow have very low hopes.\n\nAMD can only really go for value with either card, since their price to performance is capped by the generationally rather mediocre 7900XT(X).\n\nMy guess is it'll be another very underwhelming release that's not going to excite anybody for AMD who isn't already, and disappoint those who already are. :D",
      "Yeah prices are already going up again due to lack of stock here in europe",
      "If the 7800XT is $600, then it's DOA. (Like the rest of RDNA3 has been)\n\nThe 4070 is already $600 and it isn't selling all that well.",
      "I can already see titles ‚Äúto little too late‚Äù",
      "Calling it now, 7800 is going to slot somewhere in between the 6800xt and 6950xt performance wise and they‚Äôre going to charge 600 for it. DOA",
      "A month ago I'd say you'd be spot on butttt the 7900xt and xtx have drifted down quite a lot.",
      "got a xfx 6900XT for 250‚Ç¨ (pre-owned)",
      "Narrator from the future: it did not make sense.",
      "I hope they don't do their usual idiocy where they overprice product on launch, collect negative reviews from most reviewers and then silently drop prices to competitive levels anyway a month later, a masterclass in failed marketing. Just go for a good price upfront",
      "The 7800 XT really needs to be no more than $600",
      "AMD is currently sitting at 17% more fps per dollar on a GPU with equal raster performance, with EQUAL VRAM. 7600 vs 4060. \n\nAnd with the 7900xt they are offering 5-10% more fps per dollar compared to a 4070 ti with 66% more VRAM.\n\nThe next gen cards should slot right in the middle then to not look embarrassing. \n\nIf you drew a \"line of best fit\" through the middle it should look like this:\n\n7700 should have 10% more fps per dollar with 50% more VRAM than a 4060ti. So I'd guess $399 at 10% faster.\n\n7800 at 10-15% more fps per dollar than a regular 4070 with 33% more VRAM. $529-$579 depending on if it's equal to or 10% faster.",
      "They have which is why the 7700 and 7800 will have to be priced even lower to make any sense. :)",
      "They'll target 549 with similar performance to a 4070 and 16GB of VRAM, because that's a \"good deal\" from AMD's point of view.",
      "Because it is a bit to late.     \nI know that companies don't want to acknowledge this but crypto times are over, hopefully with some extra regulations crypto will also die out.",
      "They gotta to do what they gotta do to get those sweet poor reviews they love so much on the launch day and then drop the prices in a couple of weeks to reasonable levels.",
      "And then I woke up, realising it was only a dream",
      "Wat how.",
      "You're not excited for the 50$ cheaper than Nvidia and 5% slower?",
      "That is sweet damn. If they think that people will upgrade this gen when they made these deals they are crazy. Almost no perf/watt improvement for amd and the cost is up for both."
    ]
  },
  {
    "brand": "amd",
    "generation": "7000",
    "tier": "mid",
    "matched_keywords": [
      "7700"
    ],
    "title": "AMD officially lowers the price of Radeon RX 7700 XT to $419 - VideoCardz.com",
    "selftext": "",
    "comments": [
      "This card shouldn't even cost more than $350, that price should be for the 7800XT.\n\nAnyway, I will keep my previous gen GPU which is doing great and got it for way less, these GPU prices gotta drop a LOT if they are just gonna improve some meaningless % every year.",
      "Demand must be great...\n\nThe washout from the Covid boom probably going to be insane",
      "7800XT should be 399. (shareholders, downvote me!)",
      "I'm so disappointed with the gpu market that i don't even care to upgrade anymore. I will keep using my rx 480 till it's last breath and not give these greedy gpu makers my money.",
      "You are reading it wrong. He wants the 7800XT to cost 419$",
      "Idiots. First of all why not launch at that price. And secondly why not lower to $399.",
      "***used*** being the keyword",
      ">7800XT should be 399.\n\n![gif](giphy|q5VgPxwf8gzxyeUJrz)",
      "350 for a 7800xt? Are you delusional or am I reading your comment wrong?",
      ">Still delusional.\n\nFound the dude who was \"happy\" when they launched the 1k+ GPUs with barely 20% improvement.",
      "I've read that the 7700 class cards are just cut down 7800 class cards that didn't bin so well, so they price high initially then taper the price down as time goes on because inevitably they'll create more 7700 stock as they continue to make 7800s.",
      "Still too high, should really be $399.",
      "I really liked the AMD 6000-series/Nvidia 3000-series generation, but you could tell the company strategies really pivoted once the pandemic demand and the associated supply issues hit. The effects of that are finally dying down, but yeah, it's still different than before.",
      "you can get a used 6800xt or 3080 for $400 lol",
      "I agree. No point to buy the 7700XT unless price is over $75 less than the 7800XT which needs to be dropped to $450 or less quickly as well.",
      "But no warranty and 3+ years old. When it breaks you have a $400 paperweight.",
      "2012 would have it at 199. It's a smaller total GCD die area than the RX480 and the MCD's are $2 each",
      "which really shows how insane nvidia pricing is, if we think the 7800xt should be that much lower",
      "It probably will be. Most of the AMD GPU'S are selling below MSRP anyway.",
      "Yeah let's compare new against used. Because you could buy this card used too"
    ]
  },
  {
    "brand": "amd",
    "generation": "7000",
    "tier": "mid",
    "matched_keywords": [
      "7700"
    ],
    "title": "AMD Radeon RX 7700 XT drops to $399 for the first time - VideoCardz.com",
    "selftext": "",
    "comments": [
      "The price it honestly should be, though I‚Äôd still recommend a $390 RX 6800 over it.",
      "If you can find a brand new 6800 with warranty for that price, it is a no brainer. Otherwise the 7700 XT is no slouch.\n\nBoth are still better picks than 4060 Ti 8GB.",
      "That should have been the launch price. By now, it should be around 349-379.",
      "I have a friend that bought a 4060ti 16gb.\n\nI tried.",
      "The 7800XT probably should've launched at 400 and knocked this down to 340. Both cards make no real sense compared to last gen launch prices",
      "The price it should have launched at, I wonder when AMD will understand this and launch cards at the price that actually drives sales and gets people excited.\n\nSure if you launch higher you also capture those willing to pay more, but you also reap the reviews that mention poor pricing and value... Get that launch right and these things would fly off shelves.",
      "F",
      "Bestbuy had them at that price 2 days ago. \n\nThen I bought a 385 ASRock , 6800xt from Newegg yesterday. My wallets on fire.",
      "Whoa, that is a steal. Basically only slightly slower than 7800 XT, less features, same 16GB VRAM but way cheaper. I call that a jackpot.",
      "I love the fact im seeing\nBunch of GPUs like AMD and NVIDIA\nGoing down in Price \" that they ACTUALLY SHOULD HAVE BEEN FROM THE FUKING LUNCH\"\n\nAnd thats after over 1 year and people call that crap cheep and good ü§¶üèæ\n\nNever going to support this madness",
      "That's way too nuanced for your typical online pc community.",
      "The problem is they don't want to compete with the last gen Radeon but Nvidia's RTX. RX7800 XT is 50-80 euro cheaper than RTX 4070 and I think it sells well for AMD gpu.",
      "hell you can find 6800 even cheaper sometimes , its fantastic card for the price .",
      "This card was released 4 months ago",
      "AMD knows what they are doing, they charge the most they can get away with. They are focusing on maximising their margins instead of market share. And realisticly it's probably the only way amd can survive for now sadly.",
      "Inflation doesn't make a 1000$ card go to 2500$ in couple of years lol üíÄü§¶üèæ\n\nStop justifying it and just accept it",
      "I mean if he wants DLSS then why not? It's a fantastic card, just too expensive for what it is.",
      "The 4060 Ti 16GB is not better than the 4070 in price to performance.",
      "I‚Äôm OK with the 7800XT priced at $500, given where the rest of the market sits. The problem is the 7700XT, which was way too close to the 7800XT while also leaving an enormous gap to 7600.\n\nSame thing as 7900XT, really. 7900XTX is expensive, but it is the top card and it is up against the 4080, so OK. 7900XT is just too close in price.",
      "The 6800XT was $650 at launch. It‚Äôs a decent but not exciting price drop of $150"
    ]
  },
  {
    "brand": "amd",
    "generation": "7000",
    "tier": "mid",
    "matched_keywords": [
      "7700"
    ],
    "title": "Radeon RX 5700 XT vs. 7700 XT, 2024 Revisit",
    "selftext": "",
    "comments": [
      "I got my money's worth out of the 5700x such a good card. I would still be using it but wanted to spoiol myself and picked up a 6800",
      "Still using my 5700xt. Before that an r9 fury. They seemed to hold on longer compared to my previous NVIDIA cards but the drivers are pretty iffy at the start I just had copium about it lol",
      "Why is the 5700 XT being compared to 2060 Super now? Yes, i am aware of the MSRP similarities but as far as i remember back on 2019 it was being often compared more to 2070 Super by most benchmarkers back then as both has similar rasterization performance, and the 2070 Super was just a bit more expensive, kind of like the way 7800 XT is compared to 4070 non Super nowadays.",
      "At the launch event, AMD compared the 5700 XT against the vanilla RTX 2070. What Steve 'forgot' is that the RTX 2070 Super launched just two days after the AMD event, if the dates on Wikipedia are correct.\n\n5 years later, spending $100 more on the 2070 Super would seem like a much wiser choice compared to the 5700 XT, reasons being - \n\n1. Support for all three upscaling technologies, and FSR lagging behind in image quality - which is the only option for the 5700 XT as it doesn't support XeSS due to not having DP4a.\n\n2. Faster rasterization performance.\n\n3. None of the 5700 XT driver issues that was a daily feature of this subreddit back in those days.\n\nNavi10 aged terribly.",
      "The 2070 Super retailed for $499, the 5700 XT $399. Is it really any wonder he didn't see them as competing directly with each other? And he made a good point - ray tracing these days on a 20XX class card is a very poor experience, so it's not much of a knock against the 5700 XT that it can't support it.\n\nFor rasterization it was a decent card and as Steve says, remains one given where it stands, even if it's 8GB is limiting it more these days. It not supporting DLSS or XESS are negatives but it doesn't negate that fact.",
      "when they came out the 2060s was actually slightly pricier than the 5700xt. 2070s was a different price bracket altogether.\n\nso 5700 xt plays in 2060s terrirory",
      "Also a more expensive card by almost double..",
      "> The 2070 Super retailed for $499, the 5700 XT $399\n\nThe price gap was much wider here in Europe. I helped a friend of mine build a PC in late January of 2020, and prices were around:\n\n* 5700XT = ‚Ç¨400 or less.\n* 2070S = ‚Ç¨550 or more.\n\nSo, yeah, the 2070S was hard to recommend. He ended up getting a 5700XT.\n\nThat said, the driver issues were definitely real: his computer crashed randomly ~once a week, even *months* after the original launch. Those issues magically disappeared at some point, after a driver update I assume.\n\nAlso, Turing ended up aging better than expected in a way. DLSS was a complete joke of a feature until v2.1/2.2 in 2021, and was supported only by a handful of games until 2022+. These days it's the main reason to buy Nvidia over Radeon, but it took a *looong* time to get to this point.",
      "God, hoping this Christmas I can finally upgrade to a new Radeon card. I love my 5700xt but 5 years for an upgrade is an eternity.",
      "alternately, it's pretty cool that it soldiered on for 5 years and is still a decent card.",
      "I got a 5700XT to replace my 8 year old HD7970.\n\n5 years is not that long. not anymore.",
      "I did this but bought for msrp and sold it fr ¬£800 due tio th crypto boom and bought a RX 6800. \n\nPrior to those shenanigans it was a geat card. \n\nI really wish they put respectable bus width in new cards rather than this 128 bit nonsense",
      "Maybe it‚Äôs just me but my drivers are still kinda shit lol. I still occasionally get the green screen of death and have basically just given up trying to fix it since it only happens maybe once every 20 or so gaming sessions. Had a lot of trouble with HellDivers 2 when it came out as well I would get a crash with the PlayStation pop up like every hour it seemed like. Made me basically stop playing the game since you don‚Äôt keep progress when you disconnect from a mission :(",
      "I've got a red devil 5700xt in my HTPC, and I've thrown some pretty demanding games at it and even in 1440p. It's been a solid card from day 1.",
      "Ahh yes, the green screen beast, aka 5700xt.\n\n\nNo matter what benchmarks show, if you had to endure this pos, anything is better.",
      "Can do 1080p 60 but you won't be sad if you upgrade :P  ... think that's basically it",
      "My 5700xt has never crashed or given me a black screen in all these years I've had it. However I built a friend of mina a PC with a 5700xt as well and his crashed all the time. At the time, changing PCIe to 3.0 instead of 4.0 solved most of the issues.",
      ">None of the 5700 XT driver issues that was a daily feature of this subreddit back in those days.\n\nThose issues were horrible. Never solved that stuttering. Everything else? Flawless. Even when I replaced my card via RMA, the stuttering was still going. Upgraded the machine, replaced almost everything, it was still there. No error on event log, no issue in the games themselves, the stuttering was common across the board. I'm certain it was a driver issue - everything I had to replace in the hardware side, I did! Then I replaced the GPU itself with the RTX 3070 Ti, and boom, works just fine.\n\nThat generation had some horrible driver issues, but a lot of people on this subreddit just glanced over them because it comes from their favorite brand.",
      "> $500 isn't a \"different price bracket altogether\" compared to $400. \n\nIt's 25% more.  It's a completely different price bracket.",
      "My daughter gets my hand me downs too.  She's got my old 480 red devil.  It works for what she plays."
    ]
  },
  {
    "brand": "amd",
    "generation": "7000",
    "tier": "mid",
    "matched_keywords": [
      "7700"
    ],
    "title": "Typo: Ryzen 7700 non X Labeled As 10 Cores On AMD.com",
    "selftext": "",
    "comments": [
      "Probably time to let go whoever has been updating the website this past month",
      "Their last event had mistake throughout the slide too. Their marketing has been a disaster lately",
      "They also have the [R9 7900](https://www.amd.com/en/products/apu/amd-ryzen-9-7900) listed as 14 cores and the [R9 7600](https://www.amd.com/en/products/apu/amd-ryzen-5-7600) listed as 8 cores.\n\nThe older 7600X, 7700X, 7900X and 7950X are all listed correctly, so it's just the newer, low TDP variants which seem to be borked.",
      "Buy it sue later ‚Ñ¢",
      "They‚Äôre including the iGPU cores there.  Notice it just says ‚Äòcores‚Äô in the title, whereas in the specifications it lists the correct number of ‚Äòcpu cores‚Äô and ‚Äògraphics cores‚Äô separately. Definitely misleading and kinda scummy, but not technically incorrect.",
      "Disaster? That's a strong word for a couple of typos. Unless you're referring to other issues?",
      "AMD has never presented their CPU core count in this way. That's some [Wish.com](https://Wish.com) shit.",
      "water normal apparatus middle toothbrush sugar smell unique chase enter -- mass edited with https://redact.dev/",
      "They might refer 8 CPU cores + 2 iGPU CUs there.",
      "Yes, you're right. Zen 4 CPUs have an RDNA2 GPUs, which still counts CUs as \"graphics cores\". Whoever did data entry for the 7000 non-X listings was either told to count GPU cores as \"cores\", or took it upon themselves to do so.\n\nIt's not a typo; it's intentional.",
      "books unused sable offer lush shelter whole point public absurd -- mass edited with https://redact.dev/",
      "The American way!",
      "They did it on their APUs prior to Ryzen.\n\nMy 7850K was listed as ~~'12 core'~~ edit: '12 compute cores' on the box.",
      "I might be wrong. But I think they are mentioning that LTT (Linus tech tips) has also been putting out information with small bits being incorrect such as this typo. That's how I read it at least.",
      "I remember I got a check in the mail from a class action lawsuit about AMD misleading advertising",
      "Yea, they are counting the CPU cores + GPU cores",
      "I see where you're coming from, but do disagree. The shop information box item descriptions are correct for the other SKUs (linked below), and they also incorporate the same 2CU iGPU cores as the recent parts.\n\nOccam's razor hasn't dulled; I think they simply goofed up again. :)\n\n[https://www.amd.com/en/products/cpu/amd-ryzen-5-7600x](https://www.amd.com/en/products/cpu/amd-ryzen-5-7600x)\n\n[https://www.amd.com/en/products/cpu/amd-ryzen-7-7700x](https://www.amd.com/en/products/cpu/amd-ryzen-7-7700x)\n\n[https://www.amd.com/en/products/cpu/amd-ryzen-9-7900x](https://www.amd.com/en/products/cpu/amd-ryzen-9-7900x)\n\n[https://www.amd.com/en/products/cpu/amd-ryzen-9-7950x](https://www.amd.com/en/products/cpu/amd-ryzen-9-7950x)",
      "That's just fraud tbh...\n\nWhen people ask how many cores a CPU has, they're referring to CPU cores. Not CPU cores plus an arbitrary number counting the iGPU.\n\nAMD knows this, and displayed the information intentionally misleading. If they wanna' say 10, it's \"8 CPU + 2 GPU\".",
      "is there a summary of what LTT has fucked up lately, for me to check out?",
      "I think AMD should hire people who understand that those two things are very different."
    ]
  },
  {
    "brand": "amd",
    "generation": "7000",
    "tier": "mid",
    "matched_keywords": [
      "7700"
    ],
    "title": "RX 7700 XT gets much needed official price reduction in move that could see card wipe floor with RTX 4060 Ti 16 GB",
    "selftext": "",
    "comments": [
      "$419.99",
      "Can someone tell me what the new price is without me needing to click the link?",
      "RX 7700 XT already wiped the floor with RTX 4060 Ti 16 in terms of cost per frame, having an advantage of around 17% $/FPS.",
      ">The 16gb and the 8gb model are equivalent .   \n\n\nYou might wanna watch \"[The issues with 8GB of VRAM (In-Game Performance)](https://youtu.be/WLk8xzePDg8?si=HJxPgNeGGXQ0iDwC&t=1138)\"",
      "That's not bad, I paid roughly 360$ for the RX 6700 non-xt about a year ago.",
      "Should be $350 or less. This is a 60 class GPU at best.",
      "Still too high, unfortunately.",
      "I got the 6800xt for 450‚Ç¨ about 1,5 years ago, and see zero reasons to upgrade, not to mention that the only upgrades worth considering are 7900xtx/4080/4090. And I refuse to pay more than 500 for a card, period - no matter how good it is.",
      "Both of these cards don't play well with RT.",
      "For raster I like seeing that 12gb vram sweetspot. Tired of the jump being 8 to 16 so often. \n\nWould like to move up to this from my 6600xt but hard to justify even at what I pricing that isn‚Äôt high margin for AMD",
      "Wipe the floor? Who is buying 4060 ti 16 gb for gaming perf dear op? while they can get the 8gb if they cant get to the standard 4070 budget or a 7800xt. Nothing new to say this op. 4060 ti 16gb buyers thrilled with the vram and the cuda not raster lol.",
      "There‚Äôs pytorch for AMD as well! \n[Pytorch for ROCm](https://rocm.docs.amd.com/projects/install-on-linux/en/develop/how-to/3rd-party/pytorch-install.html)",
      "Okay, fair point, but aren't these 1440p advertised cards? I think changing the resolution from 1080 to 1440 would be far better than staying on 1080 but with RT on. IMO",
      "AMD GPUs actually almost the same RT perf per dollar below $600. Case in point: the 7800 XT is only 4% slower in RT compared to the 4070, in Hardware Unboxed's testing. https://www.techspot.com/review/2736-geforce-rtx-4070-vs-radeon-7800-xt/\n\nThat's the trick Nvidia play. They have a massive advantage in RT...at the ultra high end. You need to spend $600+ to get a playable RT experience (4070 up) at 4K60, and AMD can't get anywhere close close to Nvidia's RT perf at $800 (4070 Ti Super) or above.\n\nHowever, the lower you go down the stack, the better AMD's RT is relative to Nvidia. Nvidia's lead is typically 5% for frames per dollar if you look at RT. AMD's raster lead is usually something like 10-20% per dollar, though...",
      "[Toms has an average performance for 9 games in rasterization and 6 with RT](https://cdn.mos.cms.futurecdn.net/2xFof3KQdFZ8gygYPYwRDV-1200-80.png.webp) and 7700 XT performs better that 4060 Ti 16GB.",
      "That was an abnormally good deal tbh.",
      "It already wiped the floor with the 4060 Ti, because the 4060 Ti blows ass.",
      "still way too expensive",
      "Nobody at that price range is doing RT",
      "what softwares do you use I dont think pytorch works on amd?"
    ]
  },
  {
    "brand": "amd",
    "generation": "7000",
    "tier": "mid",
    "matched_keywords": [
      "7700"
    ],
    "title": "Alleged Prices of AMD's RX 7700 and RX 7800 Leak",
    "selftext": "",
    "comments": [
      "TLDR: AMD is thinking about pricing the RX 7700 for $449 and the RX 7800 for $549.",
      "Oof",
      "If they lowered both by 50 bucks to 400 / 500 it still wouldn't be the great generational uplift people want but the reviews would be much better.\n\nSeems like they need to squeeze every dollar tho before prices inevitably fall.",
      "Whales don't buy 450 and 550 GPUs...",
      "Eh I'll skip this generation absurd pricing üòî",
      "At this point if someone wants better RT they might as well be shopping green though.",
      "No great. Not terrible. Everyone will just wait for the inevitable price drops. Or AMD will change the price last minute anyway.\n\nDrop $50 and it‚Äôs probably a good deal.",
      "The 6800xt goes for $480-520 now, has a higher timespy score according to leaks, and they're trying to sell the 7800 at $550 with no significant extra features, atleast Nvidia's new cards have DLSS 3. This is DOA until price drops like the 7600.",
      "Genuine question, is anyone here getting GPU upgrades every generation? I just upgraded from my 1070ti and I don't plan on getting a new one for atleast 5 years.",
      "Normal people don't upgrade every gen. \n\nBut reddit is a small town, so most intense people are very vocal in here.\n\nIf you come from old gens is fine to upgrade",
      "They need to sell some to the \"whales\" first.  Then when they're had their fill and stop buying, AMD will have to drop the prices.  By the time that happens the free Starfield deal will probably be long over, but maybe Fall Zipfest will come around again.",
      "AMD and nVidia have effectively set up a duopoly. It seems like AMD isn't willing to compete for market share.",
      "So the 7800 is a slightly more expensive 6800XT. A whole new process node and R&D for...AV1 encoding I guess?",
      "The name isn‚Äôt important. The price and performance is what matters. If a 7800 is the same or slightly better than a 6800xt for $499, with some newer features and more efficiency, then that‚Äôs a pretty good offering, and a good improvement over previous gen price to performance.\n\nAt $549 it‚Äôs not BAD, it‚Äôs just not that exciting.",
      "We need a better competitor than AMD in the GPU market. AMD just doesn't care.",
      "Neither of these prices are competitive enough, AMD just seems to be following the same trend again, price just close just to Nvidia to ‚Äúseem‚Äù better. \n\nIMO they need to be way more aggressive if they have any intention to capture market share. But even 400 for 7700 isn‚Äôt looking exactly great when the leaked/rumored benches say 15% better than 4060Ti and having 12GB VRAM, while the public sees DLSS, Frame Generation and RT as better on Nvidia. And that‚Äôs ignoring the previous gen market prices.",
      "The issue is price drops generally only happen in USA, in other places prices can be quite sticky. Which is quite sad, Nvidia on the hand is just giving an even larger FU to consumers making AMDs dirt bag money squeezing look like a good deed.",
      "Well not exactly whales, but if there‚Äôs just some fraction of people out there willing to buy at 550, selling at 500 at launch could mean fewer profits.",
      "you are comparing the wrong product and the wrong time. \n\n6800XT launched at $649 while 6800 was $580.\n\nthis 7800 non-XT will be lower than both at launch for $550.",
      "Used will always be cheaper than new. Is this a new concept to you? If new was 399, used would drop to 299. The marketplace decides the price given time."
    ]
  },
  {
    "brand": "amd",
    "generation": "7000",
    "tier": "mid",
    "matched_keywords": [
      "7700xt"
    ],
    "title": "Graphics Cards Retail Sales Week 36 2023 (mindfactory.de) - RX 7700XT/RX 7800 XT Launch",
    "selftext": "",
    "comments": [
      "People with less than 300eur who want DLSS2 and/or 12GB VRAM",
      "No matter what anyone says, 7800 XT is one of the greatest value cards launched in the last few years.",
      "Who is still buying the 3060",
      "If you depend on CUDA and tensor Cores for productivity, you wouldnt be looking at a 3060.",
      "Maaan, you can get a 6700xt that smacks tf out of a 3060 for that and it's only missing DLSS lol.",
      "It's one of the best if you're down like 2 gens+ (I'm one of those people and am now the proud owner of a PC Hellhound 7800XT for a fresh build). Slightly improved 6800XT power for less than it, yeah that's a good deal! Plus a guaranteed fresh card. But other than that, I get why people aren't awfully pleased. I can see it from both sides.",
      "Some absolutely insane takes in this thread. From everything I've seen:\n\n\\-7800XT offering 6800XT performance for $100 cheaper is apparently a great deal but 4070 offering 3080 performance for $100 cheaper is a ripoff.\n\n\\-RT is still a gimmick only worth using in several games and no one actually cares about it\n\n\\-Frame gen is trash and no one cares about it\n\n\\-FSR is \"good enough\" therefore you don't need DLSS\n\n\\-12GB VRAM is only good for 1080p. If you have an 8GB card you miles well use it as a doorstop at this point.\n\nIf all of that was true AMD would have a 50%+ market share in the GPU space right now. Then you go look at the real world and realize that the PC gaming market is generally pretty enthusiast skewed where people do care about new features like RT, good upscaling, and frame gen and Nvidia happens to dominate in all of those aspects atm.",
      "15 Intel employees keeping those stats up.üëç",
      "The 3060 is way better value than the 4060 and often beats it when memory limitations happen.\n\n\nBetter question is who the fuck bought a GT 1030",
      "> AMD outsold Nvidia in this week's sales\n\nOnly in a single store in Germany (called mindfactory). In reality, it's getting worse for AMD. 4090 alone outsold all of Radeon 7000 series.",
      "So you pay more to get less performance just to compensate it with DLSS instead of paying less to get way better performance natively. Wow..nvidia buyers are different.",
      "am i the only one that thinks that people are being too soft on the 7800xt ?\n\nyes its half decent for the current market\n\nits not good\n\nno wonder they keep pushing these ridiculous prices when the customer base acts like this for a card with the same performance of a card released three years ago",
      "But the 4070Ti is still 18-20% faster",
      "Yes that's unfortunately the gap between these performance tiers now, it's not like AMD is doing much better, the 7900XT is around 28% faster also for 60% more money.",
      "4070 is a decent card, the main problem with it is the price",
      "It‚Äôs probably people wanting the performance of a 3090/3090 Ti at half the price.",
      "Same perf for 20% less msrp.\n\nIf someone needs to buy a GPU for gaming only, what would you recommend then?",
      "opinions like yours are exactly why companies like nvidia use and abuse their customer base\n\nyou may think im wrong and disagree with me but at the end of the day look at how much more you are paying for a midrange gpu compared to a few years ago\n\nand lets not go to the high end\n\nthese new generations are too soft and that reflects directly on the prices",
      "(Germany has only 1% of the world's population)\n\nSteam charts are international, and they show that 4090 outsold entire Radeon 7000 series. So that is why you see so many people on reddit with 4090s - people are actually buying them.",
      "i recommend this gpu 100%\n\nbut i wouldnt call it a good deal or amd¬¥s gift to gamers ...\n\nthis is still a greedy inflated price"
    ]
  },
  {
    "brand": "amd",
    "generation": "7000",
    "tier": "mid",
    "matched_keywords": [
      "7700"
    ],
    "title": "AMD cuts Ryzen 7 7700 price to $247, making it the cheapest AM5 8-core CPU - VideoCardz.com",
    "selftext": "",
    "comments": [
      "The thing is, when I was shopping for AM5 system parts, 7700X got all the good bundle prices. Never saw a 7700 in a bundle, so it was always more expensive to buy. I would have been just as happy with either. I just wanted the better price, so I went with the 7700X.",
      "It wasn't the cheapest 8 core AM5 cpu before?",
      "Bought one on aliexpress for 170 USD instead",
      "Price cut in 1st world countries*",
      "The 7800x3d still hovers around $300 on Aliexpress so this CPU isn't that much of a steal at $247.",
      "Finally\n\nThat made no sense when you can get a 7800x3d for not much more",
      "not enough",
      "True, I don't engage in overclocking as it doesn't significantly benefit my usage, which primarily involves playing Fortnite, Minecraft (i already get 1000+ fps in Minecraft), and performing some light Blender rendering. Thus, any performance gains from overclocking would likely go unnoticed. However, I've heard that overclocking the 7700 can yield speeds comparable to the X variant, although I haven't tested this myself and probably won't. There's likely a comparison available on YouTube, or Blogs.",
      "thats fair. now that you put it that way i think i may try and OC because i have been seeing my bill go up LOL",
      "Yeah... Mine just arrived from Amazon. :D",
      "woah these prices are really starting to drop finally",
      "I found mine on aliexpress for 170usd",
      "Got the 7700x for abt 115$ with the Microcenter bundle 180 mobo and 105$ G.Skill Ram (400$)!. Hell, it's even cheaper now for 100$ for a 7700x 175$ mobo and the g.skill ram still being at 105$  (sub 400$) microcenter goated, just get the 7700x!",
      "Yeah.....\n\nBecause it's not Zen5.",
      "I bought 7700 on aliexpress 3 months ago for 160$ XD and it works fine",
      "I want to Build a new pc. Would you buy a ryzen 7800X3D on sale or should I wait for ryzen 9700X ans buy this ?",
      "the 7700x offers no real benefit as far as performance goes so there would be no reason other than the bundle price. theres only about a 2% increase in performance over the non X variant.",
      "You probably don't have a real 7700....",
      "I'd personally spring for the 7800x3d because it doesn't appear that the new CPUs are actually going to outperform the 7800x3d in most gaming oriented cases (they seem to only be aimed at getting close to it). They're more efficient but the 7800x3d was already a leap ahead of the regular 7000 chips for efficiency anyways. If you don't wanna wait for the 9800x3d I'd go ahead for the 7800x3d.",
      "Ofc but the bundle is goated. If u wanna overclock and undervolt it can go higher than non x variant. Now that the 9700x is out the 7700x is even better priced in microcenters bundle. I have it and it's been insane in overclocking and undervolting. Aswell as video editing after the undervolt. 7700x is goated"
    ]
  },
  {
    "brand": "amd",
    "generation": "7000",
    "tier": "mid",
    "matched_keywords": [
      "7700"
    ],
    "title": "Affordable Ryzen 9 7900, Ryzen 7 7700, and Ryzen 5 7600 could release in Q1 2023 with reduced boost clocks and 65 W TDPs",
    "selftext": "",
    "comments": [
      "Sounds like AMD's going to ask for your first born for 3D V-cache CPUs. First a discount on the original lineup and now potentially non-x SKUs.\n\nWouldn't really be surprised if an extra $50-$100 was taxed to the 3D cache parts over vanilla due to inflation, increased cost of materials and profit (as a business should). Intel has better price/perfomance but people who want the best will overlook value.",
      "we‚Äôll see. rumors of a non-x 5600 being released in February 2021 proved to be false. we had to wait til april 2022 for those",
      "I fully expect the 7800X3D to be either $450 or $500, and a possible 7600X3D to be $350 or $400. Basically about an entire pricing tier above the actual product segment. On one hand, $350 6 core processor. On the other hand, $350 might get you the best for gaming processor by like 10-30% depending on what games you play if the difference between the 7600X and theoretical 7600X3D is similar to the difference between the 5800X and 5800X3D.",
      "I think they're more likely to be released this time around given Intel is much more competitive, but as you said we'll see.",
      "That is amazing and all, but when 3D V-Cache Versions? Can they maybe anticipate that with the next lineup, people want 3D V-Cache versions right away instead of a year later?",
      "As long as the motherboards also don't come down in price, it's still hard to upgrade to Zen4 for a lot of people. Not everyone wants to spend that much money on an upgrade.",
      "Ryzen 9 at a 65W TDP seems interesting. Sad to see that AMD seems to have given up on making a Ryzen 3 that has Zen 3 or 4 cores for desktops.",
      "Intel havent done that, atleast not yet.\n\nAnd that doesnt justify it.",
      "How bout some affordable motherboards and DDR5 RAM modules",
      "Epyc rejects can still be extremely high quality. Epyc chips are for professional workloads and have to meet precise standards that are much more rigorous than the consumer markets.",
      "naw, they just refreshed 14nm for several gens with 2% more performance and a new socket each time![gif](emote|free_emotes_pack|trollface)",
      "Sadly that's one of consequences of AMD not having its own factories anymore, as the limited production capacity makes them focus on more profitable chips. Also, the yield is so good it makes no sense to disable fully functional 6 and 8 cores CPUs to make a quadcore Ryzen 3.\n\nWhile Intel made very fast and affordable Core i3-12100(F), AMD released garbage like Ryzen 3 4100, shouldn't have even bothered.",
      "I've been thinking about moving from my 9700k to AMD next year.",
      "I'm all for 65W CPUs. 1700 / 3700x... and probably 8700 in the future",
      "Wasn‚Äôt the i7-6950x $1700+ at launch msrp? Like over $700 from the previous gen extreme edition?",
      "Those CPUs are cheaper, if it was similar / same price, ok then.",
      "Hey AMD, if you‚Äôre reading this, people are waiting for V-cache models. The sooner those are released, the sooner people will hop on AM5.",
      "> due to inflation, cost of materials and profit.\n\nMostly that last one.",
      "Current rumours have suggested the 7600x3d and 7800x3d will be announced at ces 2023. Don't believe they've provided any indication on price or actual launch date.\n\nThere may also be ryzen 9 x3d parts, although I think that's gone back and forth. The most current rumour is that they'll be coming late 2023 I believe.",
      "The benefit is almost purely for gaming.\n\nJust one example, I had a 5800X and a 3090 and when playing Escape From Tarkov there were certain maps where I would average 70 FPS. With the 5800X3D and the 3090 I average over 120 FPS in the same maps. It was a massive improvement. But that game uses the Unity engine and that engine benefits massively from increased cache. Some other game engines do not see as drastic of an improvement. Some others do.\n\nSo it depends on what you play and if you are targeting very high FPS. If you have a mid range GPU I think you probably made the right choice."
    ]
  },
  {
    "brand": "amd",
    "generation": "7000",
    "tier": "mid",
    "matched_keywords": [
      "7700"
    ],
    "title": "AMD Ryzen 7 7700 and Ryzen 5 7600 non-X 65W CPUs spotted over SiSoftware database - VideoCardz.com",
    "selftext": "",
    "comments": [
      "7600 needs to be $200 or less, frankly.  7600X should be $250 or less.\n\n13600k is $300, cheaper platform, and higher performance.",
      "Realistically, will they even sell? The problem with AM5 has been high motherboard and DDR5 costs. Is someone really going to spend $600 on a mobo and RAM upgrade and only drop <$250 on a CPU? It just doesn't make much sense, especially when Ryzen 5000, Intel 12th gen, and Intel 13th gen are fairly similar in performance and much, much cheaper platforms.",
      "Under 250$ for the 7600 and 300$ for the 7700. Anything else and its DOA.",
      "of course.   OEMs want to have motherboards with cheaper power delivery and costs.  They want cheaper cooling, and can get it all for essentially identical performance in most things people care about.",
      "Top sellers, for sure.\n\nNot to enthusiasts, who have to pay for motherboards capable of 225W+ power delivery and demand 14 VRM phases.\n\nBut to OEMs who will make their own bare bones motherboards that can't support much more than a 65W CPU, and can install small air coolers, and run JEDEC 5200 DDR5 ram?    Yeah, these will sell well.\n\nIn total sales volume, these will sell well because most sales volume is NOT enthusiasts or gamers.  For most users, and most businesses, the iGPU on Zen4 is enough as well and OEMs don't have to buy over-built motherboards with price tags to gouge early adopters.\n\n&#x200B;\n\nBut yes, for those of us who build our own systems and buy retail motherboards?  These are not great, at least until the motherboard costs come down.",
      "Yes. His conclusion was, for gaming, get the 7600X platform. For gaming on a tighter budget, get the 5800X3D platform. For doing productivity along gaming, get the 13600k platform.",
      "AM5 is overpriced and in poor position vs 13th Gen. Current AM5 pricing needs to come down aswell as motherboard pricing. 5000 series only got away with high pricing thanks to an already established platform base so people only needed a new CPU.",
      "OEM only I bet. Like a lot of past CPUs were OEM only from AMD.",
      "Has to be $199 for 7600 or it wont",
      "lol. These should be the prices for \"X\" models in order to compete vs 13600K and 13700K. 7600-non X should be 199$ and 7700-non X should be 249$, or else DOA.",
      "The fact that the 13600K is a better deal unless AMD drops the price?\n\nIdeally we'd have cheaper motherboards and RAM, too...\n\nThough I feel like the 5600 is still the best for low end. Will it bottleneck a 4090? Sure, but I don't think anyone is paying $1600-3000 for a GPU to pair with a $150 CPU.",
      "Didn't hardware unboxed put the 13600k at same performance per dollar for gaming, platform included?",
      "All the 550 and 570 motherboards out there bought with Zen 3 tell a different story.\n\n&#x200B;\n\nZen 3 was a high-ish price, but it flat out beat the competition in many regards, and the platform either cost about the same (newer 500 series) or cost less (older 400 series) than the competition.\n\n&#x200B;\n\nBut no, Zen3 was very frequently bought with a new motherboard, it was not all people upgrading existing systems.",
      "People buying prebuilts will get it most likely.",
      "> ...I think the 7600X is the better choice for gaming, just gaming, again, just for gaming, and that's not because it came out ahead in our gaming benchmarks by a very slim margin, but because it is supported by a superior platform that will offer many more CPU upgrade options. Now you might say, I don't care I'll upgrade my motherboard with my CPU in three, four, or maybe five years from now, but the point is, when performance and price are virtually identical, you have to look at other factors, and when doing so the fact is the 7600X is on a superior platform, it does consume less power, and it is easier to cool despite its love for the 95 degree TJ-max. Even if you decide you want to spend as little as possible on the motherboard, I still feel for gaming the 13600k is a bit of a tough sell. \n\n-Hardware Unboxed, \n\nBest Value Gaming CPUs, 13600K, 12600K vs. 7600X, 5800X3D, 5600X\n\nTimestamp: 22:50",
      "I had never thought about that. This is a good insight.",
      "A 300 7700 would kill the 7600x and 7700x, it would beat the 7600x overall and be just a hair behind the 7700x.",
      "not really same performance, they'll be alder lake based which will fell behind in gaming slightly, but imagine a 13400f as a reincarnated 12600k, so better MT than $300 7600x for under $200 will be the deal. AMD is milking too hard on platform longevity rn.",
      "Yeah I mean how many dozens or hundreds of dell optiplexes or similar do you think are in schools and businesses around the world? Alot more than there are custom built gaming pcs.",
      "Got a source for that?"
    ]
  },
  {
    "brand": "amd",
    "generation": "7000",
    "tier": "mid",
    "matched_keywords": [
      "7700"
    ],
    "title": "Premilinary RX 7800 XT and RX 7700 XT performance and specifications leak alongside possibly-doomed RX 7800 XTX",
    "selftext": "",
    "comments": [
      "The leak cycle:\n\nMLID->Videcardz-> Wcctech->Tom's hardware-> Redgamingtech->notebookcheck.net->Twitter->MLID\n\nand so on and so forth",
      "This whole gen has just been so blah. The only amazing card is the 4090 and you have to sell a kidney to afford it.",
      "Too much.",
      "The real question is, what is the price going to be of these cards.",
      "As someone with zero industry connections, I feel like I could pull out of my ass that the 7800 xt competes with RTX 4070 and the 7700xt competes with 4060 ti and be 100% correct.",
      "It's really the only card worth getting if you already have a 30 series or 6000 card. The high end of last generation is still excellent",
      "Using the 7800XT as an example, if it has 6950XT performance I would expect it to be about $20 more than the 3-4th cheapest 6950XT.  If it came put right now, Newegg had a $579 6950XT, but $600 is where the next cheapest ones land, so a 7800XT would be $629. If it is a little slower than a 6950XT expect the same price.\n\nPut another way, there will be a lot of posts on reddit asking \"should I get a 7800XT or a 6950XT\" with no clear right answer until 6950XT inventory runs out.",
      "Considering they have to compete with a $600 6950xt they should be pretty well no?",
      "one with more vram",
      "If true seems like a pretty disappointing gen all around both AMD and Nvidia. The 7900 cards might be the only real outlier. If you can get a 4080 for $1k or so not bad if you really like RTX but I think the 16gb VRAM will hamstring it a few years from now. 4090 is obviously awesome but yeah it's just too much $$$",
      "It's not MLID, though. It's RedGamingTech, who has an even worse track record, but is just way less egotistical about it.\n\nAlso, these RAM specs make no sense. It's 21gbps? N31 is only 20gbps. Lonely trolls desperate for attention just making shit up to send him. I remember he had specs like a year ago of the 7900xt and the whole lineup, which all ended up being wrong.",
      "Woah, Nostradamus over here.",
      "3080 12GB and above will last for a while still IMO. The 10GB 3080 and below have a much shorter shelf life for AAA gaming on high settings.",
      "MLID also claims that 7600 XT is only 11% faster than 6650 XT at 175W",
      "Imaginary Sources->MLID->Videcardz-> Wcctech->Tom's hardware-> Redgamingtech->notebookcheck.net->Twitter->MLID.\n\nFTFY.",
      "Yeah it's an easy pass on every card from both of them at this point unless MSRP dumps for all of them. Which to be fair, the 7900 XT/x has been falling and the market seems to be forcing the 40 series to dip as well as much as Im sure it riles Black Jacket's feathers lol\n\nIt's looking very likely I hold onto my 2080 for like, 7 years at this point, which is kind of crazy to think about because even when I bought it at the time I kind of grumbled about it not being enough of an upgrade but it was the option I had at a time I needed to upgrade. Now it's looking like the thing will be by far the longest I've ever held onto a GPU ü§∑‚Äç‚ôÇÔ∏è\n\nHindsight can be funny sometimes lol ...",
      "I really wish MLID and Redgamingtech would be barred from Reddit as 'sources', the way UserBenchmark is.",
      "8800 XT is looking more and more promising",
      "> The 7900 cards might be the only real outlier.\n\nSurely the 4090 is the only real outlier. It's an insane card for people with massive budgets. It shits on everything else and looks like a truly generational leap.",
      "I‚Äôm just gonna get a 6800 xt lmao"
    ]
  },
  {
    "brand": "amd",
    "generation": "7000",
    "tier": "mid",
    "matched_keywords": [
      "7700"
    ],
    "title": "Hardware Unboxed \"Zen 5 Performance Improvement Update\" testing the 5800X3D, 7700, 7700X, 9700X and 7800X3D with updated AGESA and W11 24H2",
    "selftext": "",
    "comments": [
      "The whole reason he is testing now is because the 9800x3d and arrow lake are coming out. Waiting for the product to be physically in his hands to test takes way too much time even with review samples. You can't expect someone to test 20+ cpus with the amount of games and productivity tasks they test all in the time of a week. They need fresh data now so when the cpus actually do get tested, they already have all the info they need to compare the new chips to.",
      "He should have just waited until Ryzen 7 9800X3D comes out.\n\nThere probably going to be another BIOS update, which means that he‚Äôll have to retest.",
      "i was considering going full Linux so zen 5 might be a sensible option in that case lol\n\n\nprobably",
      "I've found performance to be more consistent/stable on the latest AGESA with my 7950X3D. That's in combination with W11 24H2, which immediately fixed all of the scheduling issues I had with my 7950X3D (having to use Process Lasso to manually restrict Tarkov to the VCache CCD, for example, no longer needs to be done). Outside of these factors, I also have the latest chipset drivers installed, these also had some major work done to them by AMD not long ago.\n\nThe 7950X3D, these days and with the above considerations, \\*finally\\* feels how it should have at launch. If only that were the case, you know, at launch.\n\nBIOS flashback support is standard on AM5 anyway, so you could always backup your settings and update, then if something doesn't end up sitting right with you, just flashback to the older BIOS version and re-apply your settings from a USB.\n\nSince the AGESA you're currently on, there have been multiple vulnerability patches, fixes to GPU and M.2 compatibility, stability improvements and other motherboard/vendor-specific fixes in addition to all of the above.",
      "The 9800X3D certainly won't be worth upgrading to from 7800X3D.  Single-gen upgrades are only worthwhile if you're going from bottom-end gen A to top-end gen B.",
      "Their results are in line with other good reviewers and with amd's own internal testing. What more would you want?\n\n\nThese are factual results, you can either accept them or keep coping.",
      "It's pretty crazy to see how fast people have turned on hub ever since zen 5. People keep calling their work bad and inconsistent when they are one of the the most reputable testers. Half of this thread is just people shitting on hub and calling their results questionable with no evidence to back it up. Like this guy above is saying the windows mess is hub's fault. Like how does that make any sense lol",
      "I can't quite suss out the meaning of your comment. \"Hand-picking the ground\" is throwing me off I don't know what \"dog lake\" is.",
      "I'm still on AGESA version AM5 PI [1.0.8.0](http://1.0.8.0) with a 7950X3D, is there a reason to upgrade to any of the latest AGESA versions? Any performance/stability improvements for example?",
      "> He should have just waited until Ryzen 7 9800X3D comes out.\n\nPublish or perish -- that's how content creation works.",
      "Any improvement to 5800X3D?",
      "They are both still available to download if you look hard enough",
      "\"The CPU is not as good as I want it to be, therefore I will cry and call reviewers names\"",
      "> Besides, why is he even using Starfield? It's clear that said game is under-performing with ZEN 5 and Bethesda won't even care to fix it.\n\nSo people who play Starfield can get an idea of how it runs? You think he should just cherrypick the best games to show Zen 5 in the best possible light?",
      "It‚Äôs the AMD subreddit, due to confirmation bias many people reflexively downvote anything critical or negative towards AMD. No real way to fix that problem I‚Äôm afraid.",
      "Waiting for the 9800x3d vs 7800x3d review to see if it‚Äôs worth upgrading for emulation performance mainly, if the 9800x3d only hits 5.2ghz vs 7800x3d 5050mhz I can‚Äôt see it being much of an uplift, however if 9800x3d gets decently higher clocks it might be worth it",
      "What mess with Windows?",
      "Intel didn‚Äôt overpromise. Intel didn‚Äôt go around saying their chips will be 15% faster in gaming.",
      "Being \"disappointed\" has everything to do with expectations. If you say \"hey this is similar to the other thing because we chose to fix other things\" and then you accomplish that, no one is going to be disappointed.\nIf you say \"hey this is a lot faster than the previous one\" and then it's not, guess what it is disappointing, and morally bankrupt, and in my eyes, should be punished by law, for deceiving marketing",
      "It's almost never a good idea to ignore updates unless one very specifically causes new problems.  Early AM5 days were dark but I haven't really had problems with BIOS for a long time."
    ]
  },
  {
    "brand": "amd",
    "generation": "7000",
    "tier": "mid",
    "matched_keywords": [
      "7700"
    ],
    "title": "AMD Ryzen 7900/7700/7600 non-X CPUs reportedly launch on January 10th - VideoCardz.com",
    "selftext": "",
    "comments": [
      "Affordable am5 motherboards when?",
      "Wait another Generation",
      "If they launch 3 non X sku's and 3 X3D skus its gonna be one cluttered lineup from 200-500$",
      "Ah yes the ‚Äú3060‚Äù 8gb treatment.",
      "Could be worse, like a 7700x but it's 2ghz max clock and the box is the same as a normal 7700x.",
      "\"we want cheaper CPUs, these are too expensive\"  \n\"Okay, here's non-X version of CPUs\"  \n\"Waaah, we want x3d versions of CPUs\"",
      "Not really zen2 launched with \n3600\n3600x\n3700x\n3800x\n3900x\n3950x\n\nThat‚Äôs before they added XT and 3900 sku.  Sure Some skus really didn‚Äôt sell at msrp (3600x and 3800x) but it‚Äôs good to have choice",
      "Microcenter is offering free 32gb of DDR5 6000 RAM and $20 off motherboards with the purchase of a Zen 9 CPU. I bought a 7900x that way yesterday. It's a pretty amazing deal, especially with AMD's Zen 9 price cuts. I don't know how Microcenter makes money off of it.",
      "A620 launch",
      "Great! \n\nAM5 motherboards highly unaffordable right now: not so great. \n\nIn fact, it's terrible for AMD that wants to introduce these CPUs just to hit the moba-price barrier that makes people going for intel chips.",
      "Almost 4080",
      "I kinda wish they had called them \"eco\" variants instead of just non-X. \n\nI'm certainly tempted to get a 7900. 12/24 cores @ 65 watts, with 90-95% of the performance of the X variant? And at a lower price? Yes please.\n\nElectricity prices are through the roof where I live. I've had to limit my gaming lately because of the cost of running my gaming PC. This is a step in the right direction.",
      "Yesh but nothing like that year-revision-generation-cousin-numberofdaysuntilsummersolstice-toenailcolor for mobile processors. \n\n\"..3D\" is pretty well established at this point, so are \"X\" and non-\"X\".\n\nLots of choice isn't necessarily bad if the naming scheme isn't bonkers",
      "OH ALL SEEING GREAT ONE, WILL MY EX SLEEP WITH ME TONIGHT?",
      "It must be nice to be a computer enthusiast living in the US...",
      "What would you do with a mainboard that does not support any RAM at all? Zen 4 has a DDR5 memory controller only, so an AM5 mainboard that does not support DDR5 does not support any RAM at all.\n\nSo, obviously, A620 mainboards will support DDR5 RAM.",
      "Ahh yes the ‚Äú4080‚Äù 12gb treatment.",
      "Minor correction, 3950x launched almost five months after the rest (Nov 25th, vs July 7th).",
      "Ds3h 50 bucks when?",
      "Ryzen 7 also"
    ]
  },
  {
    "brand": "amd",
    "generation": "7000",
    "tier": "mid",
    "matched_keywords": [
      "7700"
    ],
    "title": "AMD Radeon RX 7700 XT is currently available for only $353 - VideoCardz.com",
    "selftext": "",
    "comments": [
      "The price it should‚Äôve been all along? Nice.",
      "This is a very tempting price.  Currently using a 5700 XT.",
      "IMO that is a great deal on a product that is only like 10 to 15 % slower than a 7800XT.",
      "So $20 over the 7600XT 16GB? Yeah, that's a hard choice of which to buy, isn't it...",
      "My 6750xt crushes my 5700xt and was the same cost as this (Plus starfield).",
      "> IMO that is a great deal on a product that is only like 10 to 15 % slower than a 7800XT.\n\nthe price/performance isn't as far out of whack as people think - [at MSRP it's 95% of the perf/$ of a 7800XT.](https://www.reddit.com/r/hardware/comments/16guxrk/amd_radeon_rx_7700_xt_7800_xt_meta_review/)\n\nyeah, the value curve is inverted at MSRP, but not by much.  cards are pretty much gonna swing 10% one way or another.  \n\n(also, just as a general statement, the value curve being inverted at the low end is *normal* - GTX 960 or 7750 were always worse value than 970 or 7850, for example.  And for MCM configurations, the 7700XT is a low-end configuration - too low to see the benefits in cost scaling, but still incurs penalties for performance overhead/power and uses more total silicon.  Really arguably N31 should have been the starting point for MCM configurations, that seems to be the lowest point where it makes sense as a design tradeoff right now.  N32 would have been better off monolithic (it can't be a contender in laptops without being monolithic tbh)\n\nKnock 10% off the price and It's Fine.  I honestly didn't think they'd be willing to go this low but yeah, $350 is fine for what it is.\n\n7700XT is another example of a perfectly Fine card that's gotten caught up in the hysteria around this whole generation (from both brands), just like the 7600XT.  At $350 you are paying maybe a 10% perf/$ premium for RDNA3 over RDNA2, and that is a bet that I'm willing to take especially in the low-end market.  5nm > 7nm, better RT, better AI (opening the door for a proper DLSS competitor), guaranteed Antilag+ support, etc etc.  The value of the newer thing isn't zero, and perf/$ isn't the same thing as value.  For a bet of maybe $30 of actual value, I'll take the newer thing.\n\nIt's gonna be fine folks, RDNA2 inventory will eventually sell through and open a gap for RDNA3 prices to slide downwards a bit too.  And at that point the 7600XT/7700XT/etc will be utterly Fine.\n\nAMD is learning the same lesson NVIDIA did the hard way after the 2018 mining crash - in a world of slowing progress, letting clearance sales get too out-of-hand will lead to a wave of bad reviews and salty consumers.  Locking in the value of those clearance sales isn't good enough for people anymore, and even if you adjust the prices later (like 2070S) people will stay butthurt about the whole generation forever.  If people continue being weird about clearance sales, if reviewers continue blasting every product in every generation for \"the clearance-priced thing is better!\", the obvious answer is to not have clearance sales.  AMD doesn't have to provide MDF or discounts at the end of the gen to get things gone, they can just wait for it to sell through like NVIDIA does.  Be careful what messages you're *really* signaling.",
      "Unf in the EU the RX 7700 XT starts at 450 euros (VAT included).",
      "In the same boat. I want to spend what I paid for my 5700xt close to its launch (+inflation) with ~50% perf increase, and this is getting close",
      "You'd be crazy not to jump on this 7700XT instead",
      "The 7600 and 7600XT both have 32 compute units of shader power. 7700XT has 54 - a lot more. That alone is reason enough to go with the 7700XT, so do that, \n\n12GB or 16 GB VRAM is not going to matter this generation, and even when it will matter, a 7600XT is unlikely to be fast enough for it to matter. That 8GB is not enough in some cases now is because of some games being heavily optimized for the consoles, and the weakest (Xbox Series S) can access 10GB from the GPU. It will be slower for the last 2GB, but it can do that, so some games optimize their texture sets against that. That kills performance on 8GB cards. As long as the Series S is supported, 12GB will be enough - and when it isn‚Äôt, a 7600XT is too slow anyway.",
      "270 is good, though I'd prefer if it was 150-130. Heck, let's go for 50 USD, that would be somewhat reasonable for this GPU. But I personally won't upgrade unless it's just a couple bucks /s",
      "I got the 7800xt hellhound for $329 lol i had a $200 credit i used :)",
      "You are wrong",
      "God I wish. That's an amazing deal! I got the nitro+. Thing is a beast. Very happy with it. Now the decision is whether to upgrade to am5 or stay am4 for now. Currently using a 3700x and it has done very well for me.",
      "Shame it's sold out and it's only the long 3 fan versions (I've been eyeing a smaller card to fit into my case). But the $350 price is a pretty decent price for such a card, graphics card prices have really just gone crazy, if this is a sign of things to come maybe I'll actually upgrade one of these days.",
      "It should be 250$ instead.¬†Thank¬†you¬†for¬†protecting¬†shareholder¬†value",
      "Upgraded to a 7800xt from 5700xt. If this is your price range, definitely go for it!",
      "Asrock Challenger was 419‚Ç¨ on Mindfactory yesterday - Mindstar deal.",
      "lol what",
      "None, the worst situation is the 7600 matching the 6650XT.\n\nThe only regression on the AMD side recently was the 6500XT from the 5500XT."
    ]
  },
  {
    "brand": "amd",
    "generation": "7000",
    "tier": "mid",
    "matched_keywords": [
      "7700"
    ],
    "title": "Regulatory filing hints Radeon RX 7600 XT, RX 7700 and RX 7800 cards might be coming - VideoCardz.com",
    "selftext": "",
    "comments": [
      "For what? To fill 5 fps gaps? I don't get it, their current lineup doesn't habe big enough gaps for shit like this IMHO",
      "There really isn't much space to squeeze another SKU between a 7700XT and a 7800XT IMO.  54 to 60 CUs and 12 to 16GB VRAM.  What would a 7800 non-XT look like?  60CUs but only 3 MCDs/12GB?",
      "imho that's an EEC typo",
      "The lineup has one gap: between 7600 and 7700XT. $269 to $449 is much too large of a gap. There is also 7900XT to 7800XT, $499 to $899, but there is at least 7900 GRE in that gap even if it isn‚Äôt widely available. I‚Äôm sure AMD WANTS to put something in that lower gap, but I‚Äôm not sure what that card is. A third tier Navi 32 is of course an option, but the confusing pricing of the 7700XT (and quite frankly, the stupid naming of the entire lineup) makes me think that they don‚Äôt want to price any of their chiplet designs any lower for whatever reason - more likely capacity than cost, but it could be either.\n\nFaster Navi 33 seems unlikely as the boost clock is already the highest in the lineup. Of course they could upgrade the VRAM clock to 20GHz effective, but that‚Äôs about it, and I don‚Äôt think Navi 33 is bottlenecking that hard on memory bandwidth anyway.",
      "How I've always seen it:\n\nWhat it's called --> What it actually is\n\n7900XTX --> 7900XT\n\n7900XT --> 7800XT\n\n7800XT --> 7700XT\n\n7700XT --> 7600 XT\n\n7600 --> 7500 XT\n\n\nAnd it's ridiculous that the inflation adjusted price of a 8GB card is the same in 2023 as it was in 2016. Price range for the listed models should be something like $150-$750.",
      "I respectfully disagree. There is a gaping hole in both performance and price between the 7600 and 7700XT.",
      "lower clocks, less W",
      "> \"Super\" is never\n\nThe 2070 Super was the same price as the 2070. Same with the 2080 Super.",
      "And what MSRP difference?  It would cost virtually the same to make and there's only a $50 gap to squeeze it into and that's less than the existing difference between AIB 7800XTs.  IDK maybe AMD plan to cut the 7700XT MSPR?",
      "IMO 40% is not enough of a jump to upgrade at similar pricing, let alone higher pricing. You would think that 2 gens later, you should be getting at least 2x performance for the same price. Sadly this reflects the trend of diminishing performance gains every gen thanks to inflation and physics. I don't expect to have to upgrade my 6700xt for atleast another 5 years given how slow GPU hardware is improving.\n\nVRAM can be a reason to upgrade if certain games can't run or can only display a blurry mess which is the case with a number of new games on 8gb cards.",
      "I couldn't care less about these. My sticking to the 5700 XT is solely about the absurd pricing of the existing lineup. Releasing more overpriced cards won't make me upgrade or recommend an upgrade to anyone else. Just bring down prices to sensible levels. The $7900 XTX barely hitting a 10% discount after a year is crap. Holding the 7800 XT back a year (3 years after the 6800 XT that performs the same) doesn't make the $500 price tag look good.",
      "If enough people are smart like the poster you replied to the prices will fall before that. I‚Äôll also sit on my 3060TI for another few years if I can‚Äôt get a true midrange card again for less than ‚Ç¨400.",
      "7850XT would make more sense to compete with 4070 Super.",
      "For real, price difference between 7700XT and 7800XT is already so low that it makes no sense to even consider 7700XT and just go for 7800XT. If they significantly drop the price on 7700XT then it would make sense but then the 7800 non XT would become pointless to consider.",
      "It‚Äôs completed in the sense that they have released an SKU for each die. Doesn‚Äôt mean they won‚Äôt release a different variation for each die.",
      "Nvidia's rumours are Super refreshes of existing GPUs, which will also come with price rises. How exciting is that?",
      "1650, 1660, 2060 Super were more for more.\n\n2070, 2080 Super were more for the same.\n\nAlthough the 2080 Super was only like 5% more perf.",
      "The 4070 Super will probably be more expensive than the 7900 XT.\n\nI don't know why people are in denial about Nvidia's pricing. \"Super\" is never a price cut or even price stabilisation; it's something like 8% more performance for 15% more money...",
      "They could always buy an used card for a more reasonable price a few years down the line if it comes to a point where the RX 5700 XT is too outdated.",
      "No, there's two possible reasons for the 7800.\n\n1. Vram prices crashed hard just before the launch of the 7700xt. You can get 8gb of gddr6 for $25 pretty much and this happened around June 2023. With the lead time to a product launch, the August release of the 7700xt was likely planned prior to these prices collapsing.\n\n2. Yields of the dies are good enough AMD wants to up the CUs. It could also be AMD found 60 CUs at lower clocks is perfectly stable, so there's no need to cut down to 54 when they could sell 60 just at a lower clock speed.\n\nSo, there are at least two reasons I see for this that make sense."
    ]
  },
  {
    "brand": "amd",
    "generation": "7000",
    "tier": "mid",
    "matched_keywords": [
      "7700"
    ],
    "title": "ASUS TUF Gaming RX 7800 XT and RX 7700 XT Launch - Official Q&A",
    "selftext": "Hi everyone! I'm Jake, a new community manager for the ASUS NA team. Going forward, I'll be around to bring you all some news, answer questions, and (hopefully) be of some help to you all :)\n\n&#x200B;\n\nTo kick things off, I'd like to open discussion about our recent launch of the TUF Gaming RX 7800 XT and RX 7700 XT cards.\n\n&#x200B;\n\n[TUF Gaming RX7800 XT Black](https://preview.redd.it/v5lmto2c6tkb1.png?width=2092&format=png&auto=webp&s=f2a7cb82af226b302135a7f4798a607467a962eb)\n\nhttps://preview.redd.it/utfbow6g6tkb1.png?width=2400&format=png&auto=webp&s=97644a287bcca9257c9f701cde35245165441f86\n\nhttps://preview.redd.it/neggxkql6tkb1.png?width=2400&format=png&auto=webp&s=db2e2d1d5e4625e3bba758da8d07e5ace3e65f7a\n\n[TUF Gaming RX 7800 XT White](https://preview.redd.it/pc55uel45tkb1.png?width=2400&format=png&auto=webp&s=caf0a6a1547dd946dd2ec8e0814fd17c2ab4e813)\n\nhttps://preview.redd.it/1g6xiel45tkb1.png?width=2400&format=png&auto=webp&s=e3895a95ce32454368246ebcded1ef410d45a487\n\nhttps://preview.redd.it/y8o4qfl45tkb1.png?width=2400&format=png&auto=webp&s=2f5d0fc9e88d4f6d1ae8b1d0d11aeac4bafc728c\n\n[Accessories pack included with cards; phone holder, screwdriver\\/gpu support brace, collector's card](https://preview.redd.it/2bz0mhl45tkb1.png?width=2400&format=png&auto=webp&s=3981a1be6869334d5aeb2a8a72820c050b13ef4c)\n\n&#x200B;\n\n&#x200B;\n\n&#x200B;\n\n&#x200B;\n\n&#x200B;\n\n[TUF Gaming X670E-PLUS for design comparison](https://preview.redd.it/k2ngbxvn5tkb1.png?width=2400&format=png&auto=webp&s=949e3c548f3137fb85a968e2efe276b51f0fc6a8)\n\n[TUF Gaming B650-PLUS for design comparison](https://preview.redd.it/d1jygqho5tkb1.png?width=2400&format=png&auto=webp&s=24fe9afa957a2f50c7756c3ff6b133669bc70fc7)\n\n&#x200B;\n\nThe main things to note are the continued use of the same cooling design from the TUF Gaming RX 7900 XT that features the triple Axial-tech fans, full aluminum shroud and backplate, and the subtle bit of RGB lighting. New to this launch is the white version.\n\nSize:319.8 x 150.9 x 59.2 mm12.6 x 5.94 x 2.33 inch\n\nAvailable now\n\nTUF Gaming RX 7800 XT Black - $529.99\n\nTUF Gaming RX 7800 XT White - $539.99\n\nTUF Gaming RX 7700 XT Black - $469.99\n\nMore info on the TUF Gaming RX 7000 Series: [https://edgeup.asus.com/2023/tuf-gaming-radeon-rx-7800-xt-and-tuf-gaming-rx-radeon-7700-xt-intro/](https://edgeup.asus.com/2023/tuf-gaming-radeon-rx-7800-xt-and-tuf-gaming-rx-radeon-7700-xt-intro/)\n\nMore info on the RX 7800 XT Black: [https://www.asus.com/us/motherboards-components/graphics-cards/tuf-gaming/tuf-rx7800xt-o16g-gaming/](https://www.asus.com/us/motherboards-components/graphics-cards/tuf-gaming/tuf-rx7800xt-o16g-gaming/)\n\nMore info on the RX 7800 XT White: [https://www.asus.com/us/motherboards-components/graphics-cards/tuf-gaming/tuf-rx7800xt-o16g-white-gaming/](https://www.asus.com/us/motherboards-components/graphics-cards/tuf-gaming/tuf-rx7800xt-o16g-white-gaming/)\n\n&#x200B;\n\nNow for the questions! :)\n\n1. How do you feel about the current TUF Gaming design language?\n2. Is the focus on the TUF models preferred or regrettable to you?\n3. Do you prefer the black or white variant or would you prefer a different color?\n4. Are you excited for Starfield? :D\n\n&#x200B;\n\nPlease also feel free to ask anything or provide additional feedback!",
    "comments": [
      "MSRP + $100 incoming...",
      "Just please keep them as close to MSRP as possible. Especially the white because we all know there is usually a ridiculous added charge on white gpus",
      "Jake,\n\nA 850W PSU is recommended for the 7800XT...is that a mistake?\n\nWhen will the clock speeds be announced?\n\nThanks.",
      "1. The cards look great,  but tbh they need to stay as close to MSRP as possible,  or else they're DOA.   \n2. The white model looks the best in my opinion, but I don't like the yellowish logos.   \n3. A giveaway would be a good way to connect with consumers and give back to the community.  Just saying ;)",
      "Considering that the Suggested PSU for 7900 XT is 700W (750W in the ASUS PSU Table), that should be a huge overestimation.",
      "If they cost 10% more than MSRP then they're not worth it",
      "This, unfortunately. White is a real pain and challenge to get the color matching perfectly. Black blends better but white shows everything and even a slightly different hue can be apparent.",
      "We should have pricing soon and I‚Äôll update when we do. Part of why we‚Äôve targeted the TUF series was to help keep prices a bit more reasonable compared to some other options.",
      "That seems like an oversight to me OR that the article was written prior to actually receiving confirmed numbers, which is likely. I‚Äôll pass this along. Like u/poppoo143 mentioned, the higher tier card already states a lower wattage psu.",
      "Personally I feel like the TUF Gaming line as a whole is missing on an opportunity to distance itself from \"gaming\" and be a sleeker more minimalist brand (as it is your cheaper option). I think at this point the whole \"gaming\" marketing in the computer component world is very oversaturated and as of today you could go as far as calling it \"gimicky.\" I'm a gamer, I don't need my components to say it on them. I'm aware I can game on my GPU and Mobo, that is what I bought it for after all. You already have the ROG brand, the TUF Gaming brand is starting to = cheaper asus brand, more than just gaming computer components which I think was the original intention when TUF Gaming launched.\n\nSimply put, if I were the VP of marketing I'd drop \"Gaming\" from \"TUF\" and try to capitalize on the anti-rgb movement and have it be a minimalist, sleek line and pivot from the \"cheap, downgraded ROG\" line that it has become synonymous with. Kind of like pro-art, but again not targeting any specific group. Let's be real, it's not like the consumer hardware itself would physically change if gaming was the focus or not. No board partner made \"mining\" focused hardware brands for example. Your Pro-art GPU dies aren't any different from your TUF or ROG brands.\n\nI would never buy Asus TUF Gaming branded products new unless they were steeply discounted, which is almost never the case, because I assume they're just intentionally built worse than they could be and usually they're not priced as such. And conversely I'd never buy your Strix brand new because I assume that the relative performance increase doesn't align with the price increase. Maybe what I'm asking for is to merge TUF and Pro-art into an economy brand, that is a general economy brand, priced at the bottom of the stack that doesn't feel \"gimicky and intentionally cheaper.\" Like a brand I'd buy for myself and not my 8 year old nephew because he can't have nice things yet. A big part of the problem is the Strix line is infamously overpriced at this point so it makes the TUF Gaming line seem way worse than it is.\n\nYour competitors do a much better job of differentiating and blending their brand tiers in my opinion. Take MSI for example, they have the ventus, Gaming trio & Suprim cards. When I think of the two Asus brands I think of intentionally worse thus overpriced gaming, and very overpriced, high quality gaming. MSI? Ventus is cheap and crappy, gaming trio is more expensive but performs to that bump while establishing a middle ground and then suprim is splurge. Not to say Strix doesn't compete with Suprim, but there's no middle ground for Asus and the juxtaposition between TUF and ROG is too big and obvious. MSI boards? I couldn't even tell you how that branding works, but all I know is they're not clearly pitted against each other as cheap vs overpriced. And Asus mobos still aren't out of the woods from voltage-gate from a public perception standpoint. ASRock? Same story as MSI, unique branding, no \"gaming\" overkill and sensible tiering.",
      "It‚Äôs actually not ridiculous for white to be a more expensive color. It is harder to get good yields on white injection molded parts and painted parts. Which means either parts are rejected and then scrapped or reworked. In either case that leads to more money be necessary to make a unit. The auto industry does similar. The white colors tend to be an up charge color.",
      "Recommended means nothing dude. I have a 850w psu for my 7900xtx. You're 750w psu is more than enough.",
      "Bro 3080 10GB is arguably the worst to get right now, the 7800xt will probably match its performance or slightly supersede with 6GB more vram for proper 2k or 4k textures in the near future. \n\nThese recommendations are really meant for typical buyers who usually have shitty Psu ... for example a noname 850w psu (such as that infamous series from Gigabyte) cannot match a solid 650w from FSP. Hence, they have to inflate these recommendation numbers in case some dumb ass uses these no name psus\n\nJust have a solid 650-700w and you should be fine with these mid range gpu",
      "I would like to know whether the coolers are repurposed nvidia ones or not. Some ASUS radeon cards have coolers designed for nvidia models, probably to save cost of development idk.",
      "Haha giveaways aren‚Äôt off the table though my personal preference is to first have some open and honest dialogue. Giveaways can muddy the waters on feedback and honest discussion.\n\nThanks for the feedback on the cards!",
      "Car paint =/= plastic parts for GPU.\n\nAlso white color isn't always the cheapest for cars, sometimes you need to pay extra for white.",
      "Yeah, ASUS GPUs are notoriously overprices to point I just pretend they dont exist. I like ProArt series with more reasonably sized coolers for motherboards with dual x8/x8. But again 2.7 slot sized cooler is going to kill any GPU with 2nd expansion card if it bit longer than wifi which you never put into x8 slot anyway. Usually HBA cards or 2nd GPU or high end 40G fiber NIC that actually needs the lanes.",
      "I like the rgb, it's not over the top. Looking at an 7800xt for a friend just waiting on availability and price in NZ, really happy with my tuf xtx",
      "I liked the older TUF Sabertooth(X99/Z87/990FX etc.) aesthetic more than the more recent yellow TUF design. Seems like a massive downgrade.   \nROG/Strix lines seem super upcharged while being hit-or-miss quality wise.",
      "I run a 6800xt with a 850w and its nowhere near maxing it out plus 6800 xt is less efficient compared to a 7800xt."
    ]
  },
  {
    "brand": "amd",
    "generation": "7000",
    "tier": "mid",
    "matched_keywords": [
      "7700"
    ],
    "title": "I get the controversy behind the mislabeling of the 7900/7800 series but why is the 7700 XT getting the same hate?",
    "selftext": "I'm seeing numerous posts on here saying that the 7700 XT is really just a 7700 or even a 7600 XT class card. Heck, even the 7600 is not spared although I think it performs fine as a 6600 successor. Are people just parroting what others online are saying?\n\nLet me break it down for you:\n\n* Architecture: They are both Nx2 classes (N32 vs N22)\n* Memory Capacity: Both 12GB\n* Memory Bus Width: 192 bit\n\nBut that's where the similarities end. It is much closer to a 6800 non-XT than it is to the 6700 XT\n\n||RX 7700 XT|RX 6700 XT|\n|:-|:-|:-|\n|Core Count|54 CU|40 CU|\n|Boost Clock Speed|2544 MHz|2424 MHz|\n|TDP|245W|230W|\n|MSRP|$449|$479|\n\nIMO, it a worthy successor to the 6700 XT and at a $30 discount, bringing much more features and significant performance uplift.\n\nIf anything that the 7700 XT should be guilty of is that it is priced too high or too close to the 7800 XT.\n\n**EDIT:** Again I want to clarify, not spotlighting the price (that is a separate debate), it's that people won't stop labeling it as a 7700/7600 XT. Even if they do label it as a 7700, people will complain the price is too high, but the performance would be greatly above its predecessor (6700).",
    "comments": [
      "Yeah it seems good but people are pissed it's priced so close to the 7800 XT. I think a $70-80 difference would set them apart better (either increasing one or decreasing the other).",
      "GN nailed it - at $50 gap it's not worthwhile, at $100 it's extremely compelling.",
      "You can't really compare release MSRPs because the 6700XT is now selling for $330.   \nPeople are disappointed that the 7700Xt is priced at $450 because the 7800XT is \\~20% better and 11% more expensive, essentially funneling everyone toward a higher price bracket.   \n\n\nThe 7700XT doesn't really fill a meaningful position in AMD's GPU lineup right now, at the $450 price point.",
      "Because if they released it at $400 they'd have the $330 6700xt and $350 3750xt collecting dust. Inevitably the 6000 GPUs will sell out and the 7700xt price will drop to $400 or less. Sucks but if they got stock to move they're going to price it around making it move. \n\nBasically where it sits now pushes people up to 7800XT or pushes them down to a 6750 or 6700. Once the bottom of this tier falls out (6000 series sold out and done), the price of the 7700Xt falls in response. Its pretty basic business and is done with almost every product you buy that has recurring releases.",
      "I live in Europe, and the price gap is actually roughly ‚Ç¨100 here. The 7700 XT retails for around ‚Ç¨520-550 and the 7800 XT is around ‚Ç¨620-650, depending on XFX/Sapphire/Asus etc. (including all taxes and stuff).",
      "Yeah, people easily forgot what happened just a generation ago. if 7800XT is really priced that good then keep saying that 7700 should drop in price, can't the opposite also happen in which the 7800xt might actually increase in price? \n\ni am in a region where GPU prices tend to stick to what is release price and dont decrese BUT will actually increase in price if its always sold",
      "So AMD should just raise 7800xt prices! \n/s",
      ">Are people just parroting what others online are saying?\n\nthey're all saying the same thing because it's true, why would you buy the 7700 XT when you could get the bigger 7800 XT for just $80 more?\n\n$80 is a small gap for the current GPU economy today, and it's certainly better than the $170 difference between the 6700 XT vs 6800 XT.\n\nthe 7800 XT is not only faster, it also has 16GB of VRAM, quite a few RT cores and should only draw like 50-60watts more.\n\nthe 7700 XT is not a bad card, I've not seen anyone say that anywhere. it's position in the market is just weird.\nhere's hoping for a price cut for the 7700 XT.",
      "Then why would you ever buy a 7800xt or 7700xt when 6800xt is 500 brand new.",
      "If 7800xt rises more in price, then there is less actual incentive to chooce 7800xt over 4070 so i doubt it will go that way if amd is smart.",
      "What a level-headed take",
      "Mindfactory sold many 7800 xt units for 559‚Ç¨, sadly other countries tend to get screwed with pricing.",
      "So AMD should raise 6800xt prices too!!",
      "It's even more pointless to compare it to heavily discounted 6800xt cards, that will disappear from the market in a few weeks. \nThe 7600 was compared to the 6700 10GB discounted to sub $300, which never had many cards on sale to begin with.",
      "Not everyone makes purchasing decisions from the mindset of \"what is the absolute maximum amount of money I can possibly spend?\"\n\nI could afford a 4090, but there's no chance Nvidia is getting $1,600 out of me. I could afford a 7950X3D, but it would be a waste. If the price:performance is close, yeah, I'll eat a bit of value for more performance (say, 30% more performance for 40% more money). However, with stuff like the 7700 XT and 7800 XT, it's easy to fit another $50 in the budget.\n\nHeck, there are times I'm debating between going all-out for a top-tier product to keep for a long time or getting something with much better value and upgrading more frequently.\n\nThat said, neither of these cards really does it for me. If the 7800 XT were $50 cheaper, I'd maybe get it. The 7700 XT needs to be more like $80-100 cheaper, IMO. If the 7800 XT comes down a bit for Black Friday, I might pick it up, but the 7700 XT has to be stupidly good value to convince me it's enough of an upgrade from my 5700 XT AND that I shouldn't just buy a 7800 XT for a little more.",
      "You can't really compare \"is now selling for\" prices either.\n\nA 6700 XT here (Philippines) is still $460. However, a 6750 XT is $440 - because the retailers got newer stock for it at a lower price. It used to be $540. It's also why a 6950 XT is cheaper than a 6800 XT.",
      "I'm so fuckin confused why every outlet insists on basing their review on MSRP and not *performance*. In 6 months none of their conclusions will make sense because the prices have shifted. \n\nI mean go watch everyone's reviews of 6700 XT or 6800 XT etc from last year. They all shit on it for being too expensive, and some even *re-reviewed* it after prices normalized. \n\nPeople use your recommendations well after launch. Like years later even. Including MSRP as a consideration is absolutely pointless beyond mentioning its current price. Because when you watch it a year later for a recommendation, suddenly the videos telling you to not buy a perfectly good card because they think it's not a good deal.",
      "Higher? The 7800xt is at the highest price to make sense at all, any higher price and the 6800xt gets a far better alternative...\nIt should be named the 7800 and the 7700xt should be a bit less. I'm sure prices will go down a bit soon, but for now Amd again somewhat fuck up the lunch with the naming and will get hate again.",
      "All that matters is current relative prices. Why would you buy a 6700xt when 6750xt is cheaper or 6800xt when 6950xt is cheaper. \n\nJust like why would we buy a 7800xt when 6800xt is cheaper. \n\nMsrp doesnt matter what matters is new avaliablity prices.  \n\nJust look back at 30 series and 6000 series releases. Msrp didnt mean a thing.",
      "Yeah, I live in Sweden and our taxes are pretty high (and our currency is kind of crap right now) so that may explain the slightly higher prices. Still, the difference between the 7700/7800 is roughly ‚Ç¨100ish (depending on board partner)"
    ]
  },
  {
    "brand": "amd",
    "generation": "7000",
    "tier": "mid",
    "matched_keywords": [
      "7700"
    ],
    "title": "AMD Radeon RX 7800 and RX 7700 graphics likely to rely on high clocks for performance",
    "selftext": "",
    "comments": [
      "and I need oxygen to live",
      "I just got the 6800XT Red Devil, don't think ill change for a few years to come, i'm not missing much am i?",
      "I don‚Äôt think you‚Äôre missing a whole lot. The 7800xt will likely be at best on par with the 6950xt, which while faster than a 6800xt, it‚Äôs not 300 dollars faster",
      "Yeah AMD renamed 6800XT successor to 7900XT and charge 900USD for it.Literally same shit as Nvidia tried with RTX4080 12GB/RTX4070.But they didnt get away with that.Looks like no one cares AMD doing same thing.I dont know how/why, but because of this we will get very underwhelming 7800XT.\n\nInstead +50% performance uplift at +- same cost(7900XT alias 7800XT at 650-700USD) we will probably get samall die as 7800XT barelly faster than 6800XT/6900XT(like 15-20% faster instead of 50%)\n\n&#x200B;\n\nEdit:to be honest GPU market looks like both AMD/NV just price fixing.Nv do some crap like RTX4080 12GB and AMD do same crap.They dont even try compete.They could realease 7900XT as 7800XT for 700 and gain market share.But Noooooo lets just do same shit as nvidia and lets continue price fixing.Someone should take them to the court.",
      "It won't be on N33. 8GB 128bit 32MB cache just does not cut it for 1440p and entry 4K.\n\n7700XT will be a cut N32 die with 3MCDs, 192bit bus and 12GB ram.",
      "Well it's obvious that 3Ghz boost is becoming standard, question is how high can we go in next few years?",
      "bust me tro",
      "I doubt they would gain marketshare. In usa 6800xt is like 300 dollars cheaper than 3080, same price as 3070. But still people buy 3080 and 3070. 6600 is 50% better than 3050, ans costs 80-100 dollars less yet people are buying 3050.",
      "Source",
      "> They could realease 7900XT as 7800XT for 700 and gain market share\n\nWhy do you think this? AMD has been offering the better value product at every price point for years and people still choose Nvidia.",
      "I hate this. I would like graphics cards to be on the best performance per watt curve. Pushing an extra 10% performance for significantly higher power draw i dont like..",
      "ITS OVER 9000",
      "Clocks have a major impact on performance??\n\nHOLY SHIT GUYS",
      "7700XT on navi 33 would be a real dick move",
      "Only slower in ray tracing, faster in practically every other way while using less power and costing considerably less.",
      "My room temp cares. 900 watts of the heat pump in my room is still 900 watts. A PC is not like a console we have them closer to us.\n\nI remember buying my 5700xt on December 3 years ago, the heat was welcomed at that moment, but later in the year became unbearable had to resort to uv.",
      "Breaking News: AMD reduces GPU IPC to enable super high clocks up to 10GHz!",
      "Same as N22 then to make up for the difference in CU count",
      "It would be insane, for AMD\n\nNot only do they still have 6000 series to sell (but not as many as nvidia has 30 series), they also don't have the wafers to supply the demand a half priced 4080 beater would generate.\n\nThey are already undercutting nvidia by 25%, while offering what looks to be better performance.",
      "Source?"
    ]
  },
  {
    "brand": "amd",
    "generation": "7000",
    "tier": "mid",
    "matched_keywords": [
      "7700"
    ],
    "title": "Sharing my R7 7700 Panda Build ",
    "selftext": "",
    "comments": [
      "What screen do you have showing your temps? I have been looking for something like that to show my temps externally.",
      "So much hate.\n\n\n\nIt looks amazing man. ü•≥",
      "Lots of options out there, Google aida64 sensor panel and you will find what your looking for.",
      "Well, some people prioritize asthetic over performance. But in this case, it looks really amazing, don't you think?",
      "I usually don't comment ever on people's builds but love the colour scheme and layout. Nice work person.",
      "Why not? It's essentially a 7700X with lower thermals and lower power.  Still has great single speed so who cares?",
      "Why do you even care in the first place is the real question. It‚Äôs not like you paid for it, do whatever you want with your money and let others do the same with theirs.",
      "Depends on where the OP lives I guess. Where I live the 7800X3D is 60% more expensive than the 7700 which simply isn't justified by the performance difference.",
      "their ego.... they cant help themselves bing ass",
      "Give the person the money and they might? A 7700 is far from slow lol",
      "Comment wasn't about CPU aesthetics but about prioritizing the look of the machine over CPU performance.\n\nPeople have limited amount to spend so in order to ensure they got a machine to look how they want a sacrifice on CPU power may have been needed to be in budget. All depends on what you want to achieve with the funds you have.",
      "Because this looks awesome too?",
      "Right. He prioritized the look.\n\n  \nAre you okay with taht?",
      "It depends on what he wants, not you.",
      "46 at idle with a 360 aio on a 7700? High ambient?",
      "Reading less than 33w on screen",
      "Just for some context, most of the stuff that I had came from my previous build and also bought used, but just to give more context to your pointers:\n\n1. Already had it on my previous build. No reason to change it. \n\n2. Again already have it on my previous build, and also the original cables that came from my psu have those extra dangling PCIE cables. They tend to hit the fans when I tie them.\n\n3. I'm only gonna save about a 100 dollars from  buying again a new AM4 motherboard. ( My B550 crapped on me)\n\nSo I sold my AM4 CPU and went AM5. Also DDR5 prices are not that far off from DDR4, at least based on when I purchased it. Better to invest for a latest platform for that cost on my opinion. \n\n4. My GPU cooler hits the metal components of my Motherboard near the  PCIE X16 socket. Had to vertically mount it to alleviate the problem.\n\n5. AIO's where on sale during the time of my purchase.\n\n6. I do look on my big ass screen given that I placed all of my PC components on my table. Kinda overkill I know.\n\n7. Bought the 7700 from one of my buddies. 150 bucks for a 7700 is a no brainer for me. I also use an Ultrawide monitor. Not really seeing that much of a  reason to go 7800x3d if my 3080 ti is already maxed.\n\n8. I feel that the 100 to 150  bucks going to aesthetics is a worthwhile investment given that it serves a decoration in my room and  this is also my work PC. Might as well have something nice to stare during my Work.\n\nBut I do understand where you're coming from.",
      "![gif](giphy|r5SxJYcU21Auk)",
      "Thatssss so beautiful",
      "Yeah, this real crispy."
    ]
  },
  {
    "brand": "amd",
    "generation": "7000",
    "tier": "mid",
    "matched_keywords": [
      "7700"
    ],
    "title": "AMD Radeon RX 7800 XT Features up to 60 CUs (3,840 Cores), RX 7700 XT with 32 CUs (2,048 Cores): Rumor | Hardware Times",
    "selftext": "",
    "comments": [
      "So much for 7700xt that will be as fast as 6950xt rumors",
      "Should really be called speculation, as the SKU stuff is just *guesswork* by the writer. They even said that in the article.\n\nThe actual info only concerns the GPU, not what it's being used in.",
      "Those were pretty much dead the moment AMD revealed N31 performance.",
      "No. 7700XT will be cut N32. Maybe 2SEs so 40CUs or maybe 16 CUs per SE so 48CUs.\n\n7600XT will be 32CUs and it will use N33.",
      "7800xt will have 12gb vs the 6800xt which has 16, and it's not even GDDR6X.\n\nSounds like AMD is following nvidia's footsteps in card naming and has turned the real 7800xt into the 7900xt and then its all downwards from there.",
      ">as the SKU stuff is just guesswork by the writer.\n\nThey do this every fucking time!  And every time, everybody in the comments just eats it up unquestioningly.  So frustrating. \n\nThe actual GPU die specs are correct, we basically know this by now.  But how AMD decides to segment out the rest of the lineup is very much up in the air.  There's several different ways they could go about it.",
      "They were dead as soon as we saw the very credible Angstronomics article about the specs of Navi 31/32/33 and saw that not only was Navi 33 still gonna be using a 7nm-family process node, but it would only be 200mm¬≤ in size, rather than the \\~350mm¬≤ or so many were predicting(though even that might still not have been enough).  \n\nIt was immediately obvious that there was no way such a small GPU was gonna punch that high.  RDNA3 architecture(minus TSMC 5nm) would have needed to have been a *miraculous* leap in performance efficiency to achieve that.",
      "ITT: people who don't know how segmentation by die size works",
      "There's no way the 7700 XT is gonna be on navi33 with 32 CUs as the article suggests. Angstronomics said that navi33 is mobile first and only outperforms the A770 which means it's gonna be at the level of a 6650 XT. Plus your average consumer is gonna look at the 8 GB VRAM of the \"7700 XT\" and compare to the 6700 XT and see the card as a downgrade.\n\nAnd even if you ignore all the above and just do the math, navi33 with 1/3 the CUs of a 7900 XTX is never gonna outperform the 6800 XT even if it throws power efficiency out the window",
      "As long as it eclipses the 6800XT by a decent amount, uses less power, and costs less.\n\nAlso, drivers need to be solid on release.",
      "if you think 15% improvement in 2 years at the same price it's good, well that's a problem.\n\nmaybe because there is a lot of people like you out there the companies letting themselves keep raising prices like crazy and give us poor value for money",
      ">coincidentally the 7900xt & 7900xtx also has an 8 CU difference\n\nThat's not the case. XTX has 96 CU and XT is 84.",
      "Higher clockspeed so 20% off the 7900xt performance.  \nif priced right it can be a new golden age for radeon cards",
      "Yeah, what's worse is that  7900XT is cut even further from the full die than 6800XT was but priced $250 higher.",
      "Yup. This is exactly what they‚Äôre up to. A shame that nvidia has gotten so out of control that AMD thinks they can do the same with their pricing.",
      "With the same clocks as 7900xtx a potential 7800xt would hit just 11% above rx 6950xt raster ( which is 7% more than rx 6900 xt)  with possibility  of TBP 235W.  Key idea is to not price it higher than 6800xt official launch MSRP.",
      "In what world is 15-20% not a whole lot? You must be confusing the 6900xt with the 6950xt.",
      "It isn't their first time, the 5500XT 8GB is faster sometimes than the 6500XT",
      "It has a 256-bit bus, so 8 or 16 GB, according to Angstronomics / SkyJuice. There might be lower end variants with fewer MCDs, but no reason to assume the top model would have.\n\nedit: Angstronomics was 100% accurate with N31, so no reason to assume they aren't accurate with N32",
      "The leaks is about navi32 and 33. But not their position.\nSome leaks sugested n32 will be in both 7800 series and 7700 series. N33 for 7600 series."
    ]
  },
  {
    "brand": "amd",
    "generation": "7000",
    "tier": "mid",
    "matched_keywords": [
      "7700"
    ],
    "title": "AMD Radeon RX 7700 XT is now available for $399 - VideoCardz.com",
    "selftext": "",
    "comments": [
      "Idk why AMD thought they'd sell it for more than the RX 6800.",
      "They don't. They're trying to clearance out the last generation cards.\n\nGPU's are mostly priced according to their performance in the market, and the 7700 XT can be produced for cheaper than the 6800 but performs about the same.\n\nThus, AMD wants to replace the 6800 with the 7700 XT (more profit at a similar market price). Since performance/$ is almost always increasing over time, the longer they take to sell 6800's, the lower the profits.\n\nIf you buy a 6800 over a 7700 XT and think you're pulling a fast one on AMD, you're wrong.",
      "Should've been this at launch or even a bit cheaper. AMD just continues to shoot themselves in the foot with pricing and it's pretty clear they don't care much about gaining market share vs Nvidia.",
      "You mean the price that it should've been all along? but in typical AMD fashion they had to first collect all the negative criticism ruin the gpu's reputation then lower the price",
      "When AMD launches the new RX 8000 series later this year it's gonna be funny/sad seeing 3 generations of cards selling for roughly the same price with roughly the same performance",
      "Drop the 7800XT to 450 dammit",
      "I think they just didn't have many \"broken\" 7800xts to turn into a 7700 so they inflated the price to drive down demand and boost 7800 sales\n\nI'm kinda glad I bought my 7800xt before this drop a few weeks ago\n\nAt 400 vs 519 I would haven't even considered the 7800\n\nBut then when I went to buy I found the 7800 for 490 and the 7700 was still 449. Easy choice",
      "More options is good for everyone. Maybe someone wants this level of performance, doesn't mind the VRAM hit, and intends on using AV1. Plus, you get your products in the news cycle.\n\nThe 7800 XT was received well, and it needed a little brother due to imperfect yields.",
      "could have just said \"when nvidia raises prices in the low end, so does AMD\"",
      "Yeah and totally missed the hyped. People who wanted to buy GPU badly already bought something on releases and now the rest wait for another release",
      "Push your budget and get the 7800xt, it's a significantly better card.",
      "comments like this show that the vast majority of people that come to these forums don't understand why AMD and Nvidia priced their new generation this high to begin with.  \n\n\nThey both have plenty of old, overproduced stock of their previous generation hardware. If the new stuff is too good, the old stuff won't sell.",
      "GPU retailers where I'm from:\n\n\"No, I don't think I will.\"",
      "Well in that same way of thinking, just another 50 and you're at 7800xt, which is way better.",
      "Lol I can't wait for it to hit 350 and suddenly it's was a 250 dollar card the whole time.",
      "It's still a 20+% advantage in raster while also being 10% cheaper (400 vs 440). That matters.\n\nThink of it this way: it's literally 95% the raster performance of a 4070 while also being cheaper than the 4060 TI 16GB.",
      "AMD probably has near perfect yields of the Navi32 die, and would rather sell a 7800 XT than a 7700 XT",
      "7700xt is about equal with the 4060ti in RT and clobbers it in raster.  you have to go further up the stack for nvidia to curbstomp amd's RT.",
      "Man i brought a 6750 for 400 pound not long ago big yikes",
      "The best part is how AMD waited so long before initiating a price war with Nvidia. Glad to see it begin but I hope they don't wait this long next time."
    ]
  },
  {
    "brand": "amd",
    "generation": "7000",
    "tier": "mid",
    "matched_keywords": [
      "7700"
    ],
    "title": "7800 Xt vs 7700 XT vs 4060 Ti 8GB and 16GB- Tested in the newest games!!! (Starfield, UE5, RT, DLSS)",
    "selftext": "",
    "comments": [
      "4060ti is such a bad card",
      "AMD kinda just shit all over Nvidia in most of these tests. You basically have to use dlss to even be competitive if your using a comparable rtx card.",
      "Yeah the 4060 Ti has been an insult from day 1. NVIDIA taking $50 off their insanely priced 16GB version doesn't save those duds.",
      "AMD didn't even have to upgrade their cards to compete lolol",
      "It's a 4050 and everyone knows it",
      "4060ti is an example of how Nvidia loves to fuck their customers.",
      "Even with a bad value the 7700 XT still manages to absolutely murder both 4060 Tis, and the Nvidia fanboys and dumbasses who don't do research will still buy it in masse lmfao.",
      "It could be 'good' at 250$ for 1080p, but that memory bus has a lot of *massive* situational performance issues.\n\nAnywhere the 3060 outperforms a 4060, it will likely outperform a 4060 ti 16GB by a similar margin due to the bus bottleneck.",
      "I knew I made the right decision months ago with 6800xt. The performance is good for the price and the 7800xt is just that mild bump and lower power. Go get em if you haven't already.",
      "People were buying garbage tier GTX 1050 Ti for a HIGHER price than the RX 470.",
      "when (not if) the 7700XT drops to 400 bucks there really will be no rational reason to buy a 4060ti",
      "Don't forget \"RT performance beats Radeons in most cases! Cyberpunk RT shows Radeon sucks! If you want RT, NEVER BUY AMD!\"\n\nSure, 7000 series RT might not be as good as 4000 series, but it's not that trash now. 7900 XTX is roughly equal to 3090 Ti RT performance and nobody said 3090 Ti had shit RT performance...",
      "Even at $350 most of the market won't consider AMD",
      "It's just a matter of price and performance and NVIDIA has done a horrible job with the mid-range. They like to pretend that DLSS3 numbers should be counted the same as raw performance. Let's not forget AMDs 7**8**00**XT** faces off against a plain old 40**7**0 and their 7**9**00**XTX** can lose badly to the 40**8**0 depending on the scenario.",
      "Nowadays I've seen people who insisted on getting the RTX 3050 over RX 6600 / 6600 XT. \"because it's Nvidia\"",
      "the thing people who talk about dlss vs fsr always ignore is that most of the time, amd cards have better fps without upscale vs nvidia with dlss",
      "And even then, in a lot of newer games it seems like AMD wins in ray tracing at equal price points now too. Literally the only argument I can see anyone making for Nvidia cards for purely gaming at this point is DLSS or if you're willing to spend $1500+ on a 4090 and imo DLSS isn't strong enough to justify it.",
      "Jacket man: I heard you guys like vram, so I make a 16GB model for y'all.",
      "Well like most people I didn't drop $2000 just to play Cyberpunk with RT enabled. I could care less about RT performance because personally I can't really tell that much of a difference and the majority of games don't even have RT options.",
      "[Hmmm](https://tpucdn.com/review/amd-radeon-rx-7900-xtx/images/average-fps_3840-2160.png)"
    ]
  },
  {
    "brand": "amd",
    "generation": "7000",
    "tier": "mid",
    "matched_keywords": [
      "7700"
    ],
    "title": "AMD Radeon RX 7800, RX 7700, and RX 7600 tipped for a June 2023 launch",
    "selftext": "",
    "comments": [
      "Waiting for Nvidia to release so they can price it at the same outrageous prices with little backlash",
      "This makes the most sense honestly considering the cadence thus far.",
      "I'm still waiting for the prices to drop; everything is overpriced now.  \n\nIt's 2023 and prices are still affected by the pandemic from 2020 and mining, which is very bad.",
      "Probably to try and squeeze out a few more 7900‚Äôs before they release the series of cards that most consumers want‚Äîlow end to mid-range. \n\nAMD‚Äôs problem this gen is going to be DLSS 3.0. By the time FSR 3 comes out DLSS 3.0 will have matured and have made its way into games, basically meaning FSR 3.0 is probably going to have the same issue as previous iterations‚Äîadoption rate. Next problem will be RT performance, power consumption, content creation, and probably pricing to compete. \n\nAs seen with the comparison between the 4070Ti and 7900XT, rasterization performance alone isn‚Äôt going to sell a lot of cards, feature sets are going to dictate what card has better value. \n\nI had high hopes for AMD with the 7xxx series, but when I see basically normal generational steps up with their lineup while not pushing the envelop and charging high prices, it really disheartened me. \n\nNvidia, while still expensive, saw some nice gains, especially in the 4070Ti, while also bringing out a much more robust feature set at launch, and nailing the power consumption, unlike AMD that just keeps promising, is why I chose Nvidia this time around. \n\nC‚Äômon AMD, innovate! Quit copying Nvidia while being late to the party. You only get one first impression and they seriously need to up their game in that department.",
      "Yeah. I feel like there's WAAAAY too much gaslighting on hardware subs on this site over high GPU prices. \n\nI mean, if they sell, you got the free market bootlickers going \"well ackshuilly they're selling so that means the prices are justified\", but if you point out low demand and them cutting back stock to keep prices high, people just find another nonsense argument to push.\n\nIt's like way too many people are trying to contort themselves into pretzels to justify these crap prices.\n\nAnd then they're like \"well ackshully its just out of your budget\", YEAH NO CRAP! The current prices are insane, and the lowest RDNA 2 discounted cards are the only ones that remotely approach what i consider a fair pricing. \n\nSeriously, it wasn't long ago when the top end GPU was like $500. Then suddenly it was $700. And then it was $1000. And then $1200. And then $1600. \n\nIt's insane. \n\nHeck, I remember in the late 2000s you could get like a 9800 GTX for like $250 or something. \n\nI remember my first GPU being a $80 3650 and my first \"REAL\" GPU being a 5850 for like $300 or something.\n\nAnd that was like the fourth strongest single card on the market at the time, only below the 5870, 470, and 480. \n\nI mean I remember when the market had like several tiers of products in the $100-200 price range alone. And anything from $100 on up was fairly \"gaming capable\". \n\nReally, this current market is broken.",
      "and added some new cringe presentation to mock ur competitor but cant deliver performance you promised",
      "That's not what price fixing means",
      "Aren't sales at an all time low?\n\nThen there is the \"overpriced for the market\", and \"overpriced compared to previous gens\" distinction.",
      "JUNE?",
      "As a survivor of Fury and Vega...\n\n... don't buy based on promises of future driver improvements. They don't come, are less than you hoped for, and you will never get over the feeling that you're leaving a lot of performance on the table. Those fixes won't actually come without hardware revisions, even when it'd technically be possible to do in software.",
      "New foundries which were start building in 2020-2021 coming online somewhere in 2024-2025. 2025 was my guess two years ago on when chip shortage would become more like chip abundance again. So still quite a while before chips isn't a limiting factor.",
      "That is not needed, navi31 is on the market for a long time already, and the drivers are ok.",
      "> everything is overpriced now.\n\nCounter-point: They're still selling so it's not over-priced; just out of your budget.",
      "Where is the fire extinguisher?",
      "Hello, it looks like you've made a mistake.\n\nIt's supposed to be could've, should've, would've (short for could have, would have, should have), never could of, would of, should of.\n\nOr you misspelled something, I ain't checking everything.\n\nBeep boop -¬†yes,¬†I¬†am¬†a¬†bot, don't botcriminate me.",
      "Well said, I would of been fine with the minimal raster up lift with the gen if AMD really hammered down on the other core features like content creation, power consumption, RT performance and competitive pricing. \n\nInstead AMD said sprinkle a little more raster, forget about anything other than raster and let's hike prices.",
      "It'll be interesting, \nIf budget allows, looking forward to a rx7700 later this year. And then probably no upgrades for years....",
      "All overpriced shit, skip this generation.",
      "Clearing RDNA2 supply, which is taking much longer since almost no one is buying any GPUs.",
      "June!?!??? I was hoping for some time March/April :("
    ]
  },
  {
    "brand": "amd",
    "generation": "7000",
    "tier": "mid",
    "matched_keywords": [
      "7700"
    ],
    "title": "XFX Radeon RX 7800 XT launches at $539 on Amazon, RX 7700 XT available for $459 - VideoCardz.com",
    "selftext": "",
    "comments": [
      "Let see how the EU pricing will look like        \n\n-------------------------\nedit: at least here are decent  aka at MSRP or 20-30euro more for higher version                \nhttps://www.mindfactory.de/search_result.php?search_query=7800+xt     \n\nedit 2: managed to get Shaphire Nitro+ for 630 euro in my local store so like 11 euro more than in mind factory, less if you consider shipping & stuff - it will be also delivered tomorrow.   \n\nedit 3 : today supplier called that they need to move my order by 2 weeks as \"they had less in warehouse than they assumed\" .... well canceled order looking for other supplier             \nI wonder how good supply will be.",
      "Snagged one.\n\nThank you for sharing! Because of you I have my first new GPU on the way in almost 10 years :)",
      "Well I am sure the price in Finland for me will be something like ‚Ç¨900 lol ^/S\n\nedit: Just checked, the most expensive one is the powercolor red devil and it's ‚Ç¨700",
      "AMD promused 550 euros including vat in the eu.",
      "litterally anything would be a uprgade at that point",
      "EVGA ACX 2.0+ GeForce GTX 960 4 GB (https://pcpartpicker.com/product/cBjWGX/evga-video-card-04gp43965kr)\n\nI was really starting to struggle with modern games and had to buy a subscription to GEForce Now to be able to play Darktide with my friends when it came out.\n\nBig upgrade. Quadrupling my VRAM xD",
      "You are missing the fact about what is EU.",
      "The official release time is in 1.5 hours I think.",
      "it is, just wait for official release in an hour",
      "I wish it was eligible for the Starfield promo :(",
      "6800 XT performance at 6800 XT price. What a time to be alive. üòÇüòÇ",
      "Ayo, where reviews at?",
      "> litterally anything would be a uprgade at that point\n\nik ik poverty gaming",
      "You can get a new 6950xt for 520?  Lowest i see is 620 or are you including the starfield promo?  And im assuming the rest of the world its more.",
      "Well you can order from anywhere in EU.             \nI assume that quite probably i will order from mindfactory and use some shipping service ... but who knows maybe one of the local sellers will actually surprise me (i would be honestly surprised).",
      "Yes; when I built this PC a while back I made sure the power supply would last me. \n\nI have this one: Thermaltake Toughpower 750 W 80+ Gold Certified Semi-modular ATX Power Supply (https://pcpartpicker.com/product/MVrG3C/thermaltake-power-supply-pstpd0750mpcgus1)",
      "Amazon Spain still waiting......",
      "It‚Äôs not? That was one of the reasons I waited for this.\n\nEdit: It is",
      "Yeah. For their shop offer. It's a different story for other models.",
      "Well in most of the cases bigger radiator mean that stuff will be cooler, thus you can push it more."
    ]
  },
  {
    "brand": "amd",
    "generation": "7000",
    "tier": "mid",
    "matched_keywords": [
      "rx7700"
    ],
    "title": "GTX1060 to RX7700 XT, PC is no longer as effective as a space heater. Now I have good framerates and cold legs",
    "selftext": "",
    "comments": [
      "Except it doesn't work that way.\n\nThe 7700 XT is still a 245W card vs 120W for the 1060 and will naturally generate more heat.\n\nAnd your new 7700 XT being cooled better doesn't change that.",
      "7700XT would easily consume much more power than GTX1060. More power efficient, of course, but it's raw power that heats up your legs. Might want to do a check up on your cardiovascular system if your legs are cold. :-)",
      "> PC is no longer as effective as a space heater.\n\nWhat? GTX 1060 uses half the power, that makes no sense.\n\nEven idle power consumption is lower on the 1060 from what I could find.",
      "But I'm not maxing out the card, and gaming at 1080p. the rx is going to use less power than the 1060 to do that. No new display so refresh rates haven't changed and I keep vsync on because I'm only 144hz. 1080p 144hz is going to be much easier for the 7700 than it is for the 1060",
      "That post title is all kinds of wrong. No need to make stuff up for the sake of it, not even when posting in an AMD sub.",
      "Depends on whether there is a frame rate limiter or not",
      "More Watts = more heat. How good the cooler on your GPU is doesn't matter for this. Your 1060 could be running at 100c and it would still significantly produce less heat than a 7700XT at -100C with LN.",
      "Even at 1080p raster only the 7700XT managed to[ average 126fps at 1080p](https://youtu.be/_LEBEqsCwiM?si=vDv7tQMMOShYu85S&t=444) (which would be full load). I guess if you're playing *really* old games exclusively you wouldn't be pulling much power but it's not like the 7700XT is some powerhouse being limited by 1080p.",
      "Blud doesn't know basic thermodynamics.",
      "It's just not working as hard as it did in the games I would play with the old card. 1080p v-sync on 144hz monitor",
      "head dinosaurs society selective existence unpack scale engine test lip\n\n *This post was mass deleted and anonymized with [Redact](https://redact.dev/home)*",
      "Jesus. Just accept that you have no clue what you're talking about. Not knowing stuff is fine as we all learn new things every day but this doubling down is just embarrassing. You aren't even reading what people are telling you. \n\nDo you know why your 1060 was at 55C? Because it most likely had a zero RPM idle mode like most GPU nowadays. I guess we'll just keep repeating this but the temp of your GPU tells you nothing about how much heat is being generated. A GPU at 200W could be at 50C or at 80C and it'll produce the same amount of heat. In the 50C example the cooler is just better at transfering the heat to the air.",
      "Guy is probably still using his intel 4790k lol. Natural/organic  fps limiter. Ain't  touching 60fps with that now a days",
      "Of course it can but who's going to buy a 7700xt to run it at sub 50% utilization. In a realistic scenario the 7700XT will draw more and thus generate more heat.",
      "![gif](emote|free_emotes_pack|joy)![gif](emote|free_emotes_pack|joy)![gif](emote|free_emotes_pack|joy)Blud doesn't know what a heat sink is either. [What is a Heat Sink? (youtube.com)](https://www.youtube.com/watch?v=qO6AuFc72AA)",
      "It doesn't work like that. I might edit this later to explain if you're interested, but don't have the time rn.",
      "Looking good! I splurged for the 7900xt and my legs are definitely toasty.",
      "Those games are benchmarked on Very High/Ultra settings which often has a big impact on framerates compared to High settings.\n\nAny sensible gamer would tone it down to High and enjoy significantly better framerates (often up to 20-30% more), while maintaining almost as good image quality.",
      "This is not how it works",
      "This is wrong on so many levels"
    ]
  },
  {
    "brand": "amd",
    "generation": "7000",
    "tier": "mid",
    "matched_keywords": [
      "7700"
    ],
    "title": "RTX 4070-beating RX 7800 could cost US$549 as RX 7700 and RX 7900 MSRPs allegedly fall under US$700 and US$500 respectively - NotebookCheck.net News",
    "selftext": "",
    "comments": [
      "Ah can't wait for the 7800 to beat the 4070 by 5% in some cases, lose in others, cost 50 dollars less, use 50-100w more power, and sell approximately zero units due to the bad reviews.\n\nYou know a gen is terrible when even the *rumours* about the upcoming cards suck.",
      "Don't forget the part where AMD ends up slashing the MSRP to where it should have been to begin with after a month or two.",
      "DOA. \n\nI can already grab a 4070 for 560 where I live. \n\nTo be even worth considering AMD need to be at LEAST 20% cheaper at around the same raster performance especially if they have worse efficiency. \n\n7800 is pointless at anything over 450. Just get a 4070 or buy second hand.",
      "And don‚Äôt forget that it will badly lose in RT, and it doesn‚Äôt even carry new unique technologies over RDNA2",
      "So they aren't worth buying until 2024.",
      "Those TDP numbers MLID leaked made no sense. At least that's where I'm assuming you're getting your 7700 power numbers from. More likely the 260w and 245w is for the 7900 GRE and 7800 rather than 7800 and 7700.\n\n245w that he claimed for a card that is 3/4 of the full die in almost every way would be insane for a cut down die. 15w for disabling 1/4 of the die and memory? That would mean they are pushing the frequency target for the 7700 way higher than the 7800, which is the opposite that usually happens on cut down cards. Often they are also sold as lower chips because they can't hit frequency targets.\n\nThe 260w lines up more with the 7900 GRE,  and 245W with a full 60 cu 7800 with a N32 die pushed to it's limit. I don't think anyone knows the 7700 TDP. Either one of his contacts is confused, or it's all made up.",
      "source mlid  \nThen we turn off the tv",
      "The 7700 uses 50W more already than the 4070, what makes you think the 7800 will have the same TDP as the 7700?",
      "Personally for my next build, a second hand (or even brand new) rx6800 non-xt starts to make more and more sense around this performance level both for the budget and for the efficiency. Card has been a sleeper beast, undervolts well, smashing the 3070 and closing in on the 3080 and 4070 in many titles. Its existence is making the 3060,3070,3080,7600,7700,7800 and even 4070 kind of redundant unless you care for RT performance. Current amd gpu gen is looking so pointless, at these prices, unless you are going for a 7900xt or 7900xtx. Makes the 4070 look like a decent deal when it is oh so very far from that. 6000 series were killer gen and aged so well.",
      "It's really hard to believe just how badly AMD have dropped the ball on this generation, especially when compared to the RX 6000 series that seemed like a solid alternative to the RTX 3000 series (although I'm sure the pressure of availability helped).\n\nWith equal core configurations, RDNA3 products have measly performance improvements over their previous gen counterparts. AMD no longer has a **90 competitor, yet they've reintroduced the XTX SKU for some reason. RX 7000 GPUs have all the downsides of being MCM products with none of the benefits. They don't even have a dual GCD product to show for it. I really hope it pays off, because this generation seems like a flop architecturally.",
      "What's interesting is that the 4070 is more like a 60ti class card this generation and AMD is releasing an X800 class card that seems to be it's competitor if rumors or true.",
      "Recently it's been down to a day or two\n\nBefore launch",
      "I don't necessarily believe this is exactly how it will play out but it's just disappointing and confusing to see AMD be so strong in cpus and then screw the GPU division up so bad that they can't capitalize at all  while Nvidia is weak in the consumer market.",
      "The 7900 GRE uses a cut-down version of the Navi 31 GPU, has uncertain global availability and possibly quite limited supply.\n\n7800 is expected to be based on the Navi 32 GPU, meant for mass production.",
      "7700 at $300 and 7800 at $400? Keep dreaming lmfao.",
      "You're dreaming. AMD would need to sell the dies to AIBs at the cost they buy them from TSMC and make no profit in order for that to happen. Or at least they'd be making no more than 10% margin on the dies. Maybe when RDNA4 gets announced, and they try to liquidate old GPUs you'll see those prices.",
      "Yeah that's why Nvidia was able to pull this. They got such a large boost in performance in this archicteture that they can rebadge their cards with no problem.",
      "Dude have another fantasy about amd, then state it as a leak. Probably true for his pants.",
      "They had a large boost when you compare the area/die version.\n\n4070 is using what would be the 4060 die in another generation. \nCompare the 4070 and the 3060 and you are going to see a major boost in performance. \n\n4090 had a massive boost because it's not using a lower spec die.",
      "What a cancerous article title....jeez. There are *so many* better ways to arrange those words."
    ]
  },
  {
    "brand": "amd",
    "generation": "7000",
    "tier": "mid",
    "matched_keywords": [
      "7700"
    ],
    "title": "AMD Announces \"This is Why We Game\" Game Bundle with Radeon RX 7800 XT and RX 7700 XT Graphics Cards",
    "selftext": "",
    "comments": [
      "If someone hasn't gotten an RDNA3 card by now I don't think this is what's going to move the needle to convince them. The entire line needs price drops to clear space for RDNA4 tbh.",
      "Good to see the 7800 XT and 7700 XT bundled together. If someone asks me why I have both, I'll tell them this is why we game.",
      "\"this is why we game\"\n\n\\*starfield\\*\n\nIs this backhanded insult?",
      "Yes, i got myself a 6750xt and is enough for my daily use on 1080p, would only make Sense going to 7800xt which IS close 4070 super and not such a big price Gap to TI version, what makes 7800xt/7900gre useless at this point\n\nVery little reasons to move to 7000,",
      "Honestly even for 1080p, a 6750XT is still bordering on overkill. Given that a lot of gaming lately seems to be marketing 1440p and 4K, 1080p gaming has kind of seen diminishing returns as these GPUs get faster and faster. Most of the time you're gonna get capped by the CPU at that resolution. \n\nSo unless you are planning to go 4K any time soon, that 6750 is gonna carry you a *long* way.",
      "You misunderstand my point, which had nothing to do with Nvidia, but just to point out that a blanket statement of declaring the 6750xt overkill for 1080p would serve someone wanting to enjoy rt/pt games very, very poorly.",
      "Probably because they're the ones whose unit sales are the most below AMD's projections.",
      "Hmm, sounds to me like a move to clean up the stock and make room for successors",
      "2023 titles, most of which can be found in a subscription(gamepass/Ubisoft+) and only for 2 gpus.\n\nPretty disappointing ngl.",
      "Well that depends on what games you play. With all the graphical ray & path tracing, something like Alan Wake 2 / Cyberpunk would absolutely annihilate a 6750xt even on 1080p, and upscaling+fg at such a low res and baseline framerate just isn't good.  \n\n\nIt always depends.",
      "Why the specific 7700 XT and 7800 XT GPUS only?",
      "It clearly says that the promo is for 7700XT and 7800XT...",
      "I upgraded from my 1080 this weekend to the 7800xt. Found a local guy on fb marketplace selling it for $375. This was still a better deal",
      "lies of p is best pick.",
      "Aren't these just the same rotating games that come with a GPU purchase on Newegg anyway? How about you finally slash the price of the 7900 XTX instead?",
      "7700xt struggled in sales because it doesn't differentiate itself enough from previous-gen 6700xt and 6800.\n\n\nThe 7800xt was selling okay, but with the 7900 gre releas e (and the 4070 super), unless your budget is absolutely hard capped at $500, you can now spend just a little more to get a significant performance boost with other options.\n\n\nThis is likely an attempt to move stock for both.",
      "its called scraping the bottom of the barrel.  Starfield a dead game that tries to sell you a quest line for 7$.",
      "I wouldn't suggest Avatar nor Starfield to use as advertisement, associating mediocrity to their brand sound like a bad move.",
      "more like \"this is why we pay 500$ for 5% performance 3 years later\"",
      "I‚Äôd wait at least another generation. The upgrades are (mostly) slowing down, and the 3070‚Äôs still a fantastic card."
    ]
  },
  {
    "brand": "amd",
    "generation": "7000",
    "tier": "mid",
    "matched_keywords": [
      "7700"
    ],
    "title": "Alleged AMD RX 7700 and RX 7800 GPU Performance Leaked",
    "selftext": "",
    "comments": [
      "It's sad how predictable it is that AMD will try and release these at way too high a price point, get absolutely panned in the reviews, have terrible sales and then slink away to drop prices to a more reasonable level after everyone has already decided to buy something else.\n\nIf the 7800xt come out under 500 dollars it'll be a good launch.  But you just *know* AMD are going to try for 600-650",
      "I mean we already had an upper bound with the 7900xt's performance, what could people have reasonably expected? Anything genuinely good? no way. All those rumors about some purported hardware defect that's fixed in navi 22 were clearly hogwash in the first place.",
      "Unlikely 600.\nRTX 4070 (non Ti) had a $599.99 MSRP on release and I'm pretty sure they'll try to price it less.",
      "The problem are the powerspikes, not the average load.",
      "> Anything genuinely good?\n\nBefore rumors speculating on the disappointing performance of the 7700 and 7800 started to leak out, I had been hoping for a 16 GB 7800 XT = 6950 XT with lower power consumption and a 16 GB 7700 XT = 6800 XT with lower power consumption on the level of the 4070 allowing for some short cards.",
      "No, 7900 XTX competes with 4080.\nAlready priced lower and have matching performance in raster (see reviews)\n\n7900 XT vs 4070Ti and 7800 (XT?) vs 4070.\n\nNo competitor for 4090.",
      "6950 XT has some disadvantages, namely power and size.\n\nYou're gonna need an 850W+ PSU for one, and many people buying a 500-600 dollar GPU won't have one.",
      "Without watching the leak i can tell you also my \"leak\" or my guess. It would be same as from rx 6700xt to rx 6750xt improvement (for 7700 over 6750). This AMD gen is failure. The only way they \"win\" is more vram lower prices.",
      "Yet the 6950 XT is still in widespread stock everywhere and is markedly better than the 4070 and I suspect at the best-case scenario price of ‚Ç¨530 they're near breakeven.",
      "Unfortunately, it is not. It is more like 4-5%.\n\nHave you seen the 7600 reviews? See how it compares against the 6650XT, both cards feature 32 CUs, one is RDNA2 and the other is RDNA3. This is the best CU to CU comparison and the difference is 4% (source: [techpowerup](https://www.techpowerup.com/review/amd-radeon-rx-7600/32.html)).",
      "Wouldn't expect a 7700xt to have 4070 power use when nothing else in the stack has been that efficient",
      "The 4090 jump isn't that much smaller than the 1080Ti jump. The 4090 is like 70% faster than the 3090 at 4K.",
      "That's kind of cheating, given the 5700xt was only 251mm¬≤ chip.",
      "It's hard to say exactly how the 7700 and 7800 will compare to the 6700 XT and 6800 XT based on what was leaked, but as anticipated it does not look very encouraging.  If the 7800 has the same performance as a 6800 XT, it might be difficult to choose a 7800 over a 4070 unless the 7800 is at least $100 less.",
      "I had higher expectations as well, but after learning that CU per CU, there has been almost no generational improvement, it became clear that the 60 CU RX 7800 (XT) wasn't going to be much faster than the 6800 non-XT.",
      "6950XT reasonable expectation? For the 7800(XT)? I wish.  \n\n\nThe 6950XT is \\~10% slower than the 7900XT ([HUB](https://youtu.be/NFu7fhsGymY?t=585) shows a \\~9% gap at 1440p). And it features 80 CU. Unfortunately there is no chance the 7800 with just 60 CU will come close to the 6950XT.",
      "Why would you even consider upgrading after just one generation",
      "My 750 watt psu works great with my 6950xt",
      "Except many can't, because the power spikes on some cards went well beyond anything reasonable. There was, and still is, a lot of back and forth between the gpu and psu makers over this.\n\n\nEdit: there was even an update to the atx standard over this.",
      "https://www.techpowerup.com/review/sapphire-radeon-rx-6950-xt-nitro-pure/36.html\n\n(also confirmed by many other sources)\n\nEdit: how well a psu can handle those short spikes varies **a lot**, and designing for them is a tradeoff, both in price and performance/safety. You could simply throw on more output capacitance, but then e.g. a short circuit will become a lot more exciting.."
    ]
  },
  {
    "brand": "amd",
    "generation": "7000",
    "tier": "mid",
    "matched_keywords": [
      "7700"
    ],
    "title": "MSI not listed as launch partner for AMD Radeon RX 7800/7700 XT graphics cards",
    "selftext": "",
    "comments": [
      "same for 7900xt/7900xtx. Busy selling SUPRIM for Nvidia. Also no Lightning models for years",
      "https://videocardz.com/newz/msi-preparing-twenty-geforce-rtx-40-gaming-slim-graphics-cards\n\nlol maybe this is why.",
      "Thats fine. Get a sapphire.",
      "Looks like xfx will be making a 7800xt.  I'll more than likely go with them, I 've had really good luck with their gpus.",
      "MSI has never made good AMD cards anyway. They put all their efforts into Nvidia designs.",
      "They have a gaming trio classic model for the 7900 xtx no?",
      "They follow suit with asus to save production costs since the 40 series coolers were overdesigned for a tdp that will never be reached under gaming loads so they make \"slim\" aka cost cut version coolers now",
      "It was the same when the 7900 series launched: https://videocardz.com/newz/msi-to-launch-custom-amd-radeon-rx-7900-graphics-cards-in-q1-2023",
      "Shit temps, crappy quality and lower PL than a reference model.\n\n\nMSI should just stop making AMD GPUs.",
      "I don't think they were complaining. \n\nIt's well known in the industry that Nvidia withholds details about their power limits from manufacturers until the last minute, and in the meantime the AIB's are stuck designing coolers for the absolute maximum TDP they think a generation can ever reasonably expect to hit. That's why the 4080s and 4090s were pretty much universally overbuilt, everyone built them to be able to reasonably dissipate the heat from a 600w load. \n\nRealistically, the 30-series coolers would have been adequate for the 40 series. \n\nThe size bloat is Nvidia's fault. They determined power limits too late in the development cycle, even their own FE cooler is overkill for what these GPUs can be expected to do.\n\nNone of this is a slam on any of the AIB's or even Nvidia, it's just the way it is, and it bloated both size and production costs. We would hope that Nvidia would learn from this and finalize their engineering earlier in the development but the 4090 was an unprecedented success and all their efforts are going into AI now so we consumers will just get what we get going forward.",
      "7800 xt meh?! Beats a 4070 and is 500$.  Not a rich guy and am actually pretty broke but am still picking one up because of how good a deal it is. I think your just delusional. Unless you mixed up 7700 xt and 7800 xt. Cause 7700 xt isn‚Äôt a good deal.",
      "And the 7900 xt that i have.  Superb no issue at all.",
      "For AMD Asus is just utter shit.",
      "MSI AMD GPU just get released a bit later. My MSI Gaming Classic Trio 7900 XT  was release about 3 months after the MBA one.",
      "Sapphire and PowerColor are sitting together quietly snickering about MSI during lunch in the cafeteria.",
      "what ? i buy MSI since my HD 7950, R9 390,  RX 5700 XT and now 7900 xt and all these card worked well and still work well,  i upgrade each 3-4 years.\n\nMy MSI Gaming R9 390 still working perfectly after 8 years. >\\_>\n\nSome model had a bit of a failure design a launch like the MSI 5700 XT Evoke, but the cooler and thermal pad issue was fix after the launch batch, and it's not complicate to RMA with MSI when these thing happen.  \n\n\nBref I never got a bad AMD GPU from MSI.",
      "You mean RTX3090 cooler for AMD?",
      "Which they discontinued, offering replacements to all \"affected\" customers not long after launch:\n\n[https://www.techpowerup.com/260696/xfx-revises-rx-5700-xt-thicc-ii-cooler-offers-replacements-to-current-owners](https://www.techpowerup.com/260696/xfx-revises-rx-5700-xt-thicc-ii-cooler-offers-replacements-to-current-owners)\n\nNot relevant information at all honestly... One bad release does not make them a bad option. They've been perfectly good cards for many, many years.\n\nI'd still go with something like a hellhound though since they're much nicer looking imo.",
      "What ![gif](emote|free_emotes_pack|dizzy_face)",
      "At least we got Biostar! lol."
    ]
  },
  {
    "brand": "amd",
    "generation": "7000",
    "tier": "mid",
    "matched_keywords": [
      "7700"
    ],
    "title": "Tom's Hardware - RTX 4060 Ti vs RX 7700 XT faceoff",
    "selftext": "",
    "comments": [
      "TLDR:\n\n7700xt stomps on the 4060ti at rasterization so hard its not funny (12% better at 1080p and like 25% at 4k) but is a little worse at ray tracing (10% worse at 1080p and like 2-3% worse at 4k). However at 1440p the 4060ti is still only getting like mid 40‚Äôs fps ray tracing so ray tracing is kinda pointless for cards at this level",
      "The main draw isn't ray tracing, the main draw is dlss vs fsr. Personally, I'll pick the Rx 7700xt just for the VRAM. Even if dlss is better, it doesn't look any better if I have to drop texture quality.",
      "Why is this being released now, and not back when the 7700 XT / 4060 TI cards released?",
      "But 8 gigs of vram isn't enough even at 1080p in modern games. What looks worse, unrendered textures, or no upscaler? 8 gb is doa at this price.",
      "12%-25% better at rasterization, verse 2%-10% worse at ray tracing.\n\nthere is a huge difference between 2-10 and 12-25 broski. If you are in  the RTX product stack, that jump is like a 200$ price premium to jump to the 4070 to get that raster bump.",
      "7800 XT outperforms the 7700 XT by \\~15-20%. If this is worth the extra cost to you, then go for it.",
      "7800xt absolutely smokes the 7700xt. If you can stretch the extra you won‚Äôt regret it.",
      "So AMD stomps when it‚Äôs 12% better at rasterisation, but AMD is only a little worse when it‚Äôs 10% worse at 1080p‚Ä¶![gif](emote|free_emotes_pack|facepalm)",
      "> -7700xt **stomps** on the 4060ti at rasterization so hard its not funny (..)\n**12%**  better at 1080p \n\n> -**a little** worse at ray tracing (..) **10%** worse at 1080p\n\n\nBRUH cmon. You can argue that 7700xt is a better card using legitimate reasons, there is no need to do what you did sounding like a fanboy",
      "Hey guys, seen a lot of discussion about 7700xt and 7800xt is 7700xt better option if the price gap brtween those two is 120e ?",
      "Only with FG, and even then that's because you're not actually rendering those extra frames.",
      "The 16GB model of the 4060ti has come down in price quite a lot in the EU. \n\nIts now pretty much on par with the 7700XT both at around 420‚Ç¨.\n\nWhich makes it a really tempting option unlike when it was in the high 400's.\n\nIt just depends what you value more. Better raster performance or better RT, better Frame-Gen, better upscaling, better AI perormance, reflex and +4GB of VRAM.",
      "Absolutely worth imo. I've had since release and I've had 0 issues with it and it's been fantastic for 1440p in literally any game.",
      "DLSS loses to itself at 1080p. You shouldn't use it at that resolution unless you're desperate",
      "RT is utterly useless on a 4060ti. I think it's going to take another generation or two until it hits the mainstream. Looking at how a 4090 struggles with RT in newer titles like  Alan Wake past 1440p let alone 4k. I doubt it's going to be important anytime soon. Look at how RT turned out for the 2080. New technologies always punish early adopters.",
      "But they are not 4k cards so those numbers are irrelevant. Might as well say that 4060ti is [190%](https://www.techpowerup.com/review/cyberpunk-2077-phantom-liberty-benchmark-test-performance-analysis/6.html) faster in cp2077 path tracing but who cares when framerates are unacceptable",
      "I really love how RT is used as an pro Nvidia argument even on those cards that are basically unable to run it. Yes, some folks will buy crap GPU like RTX 4050 arguing it does ray traycing better. Plus DLSS on 1080p isn¬¥t exactly peachy either, so maybe focusing on pureraster power in these low segments isn¬¥t such a stupid thing to do?",
      "Honestly, you're an idiot if you're using rt with either card.",
      "Sapphire. No brainer choice. It was one of the cheapest for me.\n\nI'm heavily against buying Asus/Msi/Gigabyte since I don't like when they do both AMD and Nvidia. \n\nI prefer main-amd/main-nvidia partners.\n\nI have the Nitro+ and I don't think I've ever heard those fans ramp up. Very good cooling.\n\nXfx is also very very good and also powercolor.\n\nPick whichever fits your budget best.",
      "No it was a good card all though it was power hungry. \n\nMine dying was my own fault not the fault of the cards. I had mine water cooled and spilled water on it when I was upgrading the cpu."
    ]
  },
  {
    "brand": "amd",
    "generation": "7000",
    "tier": "mid",
    "matched_keywords": [
      "7700xt"
    ],
    "title": "ASUS launches Radeon RX 7700XT/7800XT DUAL graphics cards - VideoCardz.com",
    "selftext": "",
    "comments": [
      "Guess they took notice how many ppl actually buy these GPUs and want a piece of the cake aswell.\n\nLet's just hope they actually do a proper design and not just reuse the nvidia components and kind of make them fit like MSI did with the 6XXX series 'custom' designs.\n\nKind of sad we don't have anyone doing full two slot only variants of these cards by now.",
      "It's actually funny how TUF was supposed to be the budget option in the beginning and as soon as people started actually buying it they cranked up the prices to Premium and charged even more premium for ROG.",
      "More like their TUF cards were way too expensive and they realised they had to find a way to make a cheaper card without affecting the reputation of ASUS cards (that being more expensive=better)",
      "Still a flipping 3 slot design :(",
      "I thought the same thing, but if you read the article, ‚ÄúDual‚Äù is just the name of the two fan card design. It's an ‚Äúupdated‚Äù design specifically for the 7700,800XT with a $100 premium over the TUF models. TUF models have higher clocks so it's dumb.",
      "Can someone ELI5 what a dual card is? Are they combining two GPUs into one?",
      "Dual fan",
      "Okay, just another model to skip. Sapphire, powercolor, xfx, or bust",
      "if you are in budget then 100% sapphire pulse, not this thing",
      "No it's not. Powercolor Hellhound Spectral, Asrock Steel Legend, Sapphire Pure all exist and usually aren't that much more than MSRP. Even ASUS has a white TUF",
      "everytime i read dual i expect a 2 graphics core crossfire design but then i realized companies arent fun anymore so meh",
      "Well that‚Äôs good, cos the ASUS TUF Gaming 5700 XT had terrible cooling",
      "TUF was initially introduced with the Sabertooth Z87 motherboard and even then it was meant to be a semi-premium model.\n\nOn GPUs TUF basically replaced the \"GAMING\" line which sat just below STRIX and above the base model cards.",
      "Dual was always ASUS budget branding for GPU?",
      "It's down to 399$ now , i say that's pretty good unless you wanna buy used cards",
      "Yeah if that's in stock",
      "TUF was competing with MSI Military branding. It was meant to be the \"Middle-tier, high durability/better warranty\" bracket.",
      "After [ASUS blamed AMD for their trash design](https://www.youtube.com/watch?v=H7lnBCFnBok), they can shove these cards up their a\\*\\*.\n\nASUS is not the legendary 90's company they once were.",
      "I think this is true but in practice however, due to ASUS negligence of actually producing TUF products that made it through the review cycle unscathed - they were forced to make them \"budget\" offerings for a long time. And their TUF motherboards are also priced towards the low end.\n\nIt's only really this current GPU generation where a \"TUF\" GPU is actually of good quality - but still hardly a first choice on AMD.\n\nAnd their TUF motherboards continue to be very inconsistent. \n\nTL:DR asus can't consistently make quality TUF branded stuff so the pricing is equally inconsistent.",
      "Don't buy AMD Gpu's from ASUS they just use the leftovers coolers from Nvidia\n\nBuy Sapphire, PowerColor or XFX they are much better and cheaper"
    ]
  },
  {
    "brand": "amd",
    "generation": "7000",
    "tier": "mid",
    "matched_keywords": [
      "7700"
    ],
    "title": "AMD Announces Radeon RX 7800 XT & Radeon RX 7700 XT: Enthusiast-Class RDNA3 For 1440p Gaming",
    "selftext": "",
    "comments": [
      "Everything is \"enthusiast\" nowadays.",
      "$500 flat for the 7800 XT is pretty good, that's a 9% discount on the 6800 XT's current price along with some RDNA3 improvements and lower power consumption.\n\n$450 for the 7700 XT is bad. That's around the price of a 6800, but with less VRAM. Plus you can find 6800s for $430, which is the maximum this card should have been. AMD probably saw how bad the 4060s were and got a little too confident.",
      "On AMD's own slides the 7800XT is 20% faster than a 7700XT for 11% more. There is definitely something weird going on like yields are really good, so they are making many more 7800XT and don't really want to sell 7700XT???",
      "Its probably both cards cost a similar amt to make, like the 7900xt/xtx, and they want to push folks into the more expensive SKU. In a few months, the 7700xt will be down to 399.",
      "Honestly? Wait for benchmarks, you stand to benefit by waiting until Sept 6th and seeing how the 7800xt stacks up against your current card and the existing lineup.",
      "Glad I jumped on a 6700XT + Starfield Premium for $255 (open box from MC).",
      "7700xt = DOA, just like 7900xt at launch",
      "I would wait for the 7800XT same performance, lower power more features, and the same price",
      "There seems a very large gap in price between 7800xt and 7900xt. Any chance 7900xt will drop a little in price?",
      "Or they want to finish selling 6000 series stock.",
      "Lol enthusiast 70 class card for $450 that competes in the 60 class segment that's really a 50 class segment.\n\nIt's 2023 and you get to pay $450 for a \"7700xt\" that competes against a \"4060ti\" which is really a 4050ti but Nvidia *also* shifted their product stack.\n\nPeople really do fall for this shit.",
      ">$450 for the 7700 XT is bad.\n\n7700xt is clearly there to upsell 7800xt and would likely be disounted later like 7900xt was.\n\nHonestly 7800xt seems like an amazing 1440p card  after their FSR3 presentation that will last years. Both need independant testing though.",
      "The whole point is to upsell 7800xt, yes, to be discounted later. Atleast 7800xt looks amazing unlike 7900xtx for its price as long as FSR3 lives up to DF expectations.",
      "I don't think it's \"falling for\" anything as much as it is making the best out of a shit sandwich.",
      "sucks for the countries that don't get AMD discounts though.",
      "People have been brainwashed to consider mediocre products good after travesties such as 7900 XT or even worse, the absolute potato 4060 Ti.\n\nIf 4070 was a 4060 Ti sold at 499$ - which it should have been - anything more than 449$ would have been outrageous for this 7800 XT which should have been 7700 XT or at most 7800 to begin with.\n\nBut with Ada being mildly (4070) to very underwhelming (4060 Ti), 6800 XT performance for 499$ and newer tech sounds very compelling out of nothing - **because in the current market, it is.**\n\nBesides, AMD has a (recent) history of not actually competing with nVIDIA at launch in terms of MSRP, so the fact that they have at least read the room this time makes this launch better than it actually is.",
      "It's terrible.  Why is the 7700XT so expensiveüò≠ I hope half a month goes by and the price drops to at least 400‚Ç¨... My RX580 is about to die, I can't wait anymore, I want to play starfield...",
      "And any iPhone is an \"enthusiast phone\" because most people in Latin America, South (East) Asia, and Half of Continental Europe which make up the majority of world population are using cheapo $100-$300 phones.",
      "Because 7000 series supports Anti-lag+ and driver-level Frame Generation. It has AI cores that would be needed for future iterations of FSR and therefore those cards would last longer than 6000 series despite their similar raster performance right now.\n\nThat's objective. 'Upscaling looks horrible' and 'Fake Frames are not real frames' are subjective.",
      "I can see it continuing to come down just like were seeing for other higher end cards. But not by big leaps. I bet we see a few $699 deals pop up around black Friday."
    ]
  },
  {
    "brand": "amd",
    "generation": "7000",
    "tier": "mid",
    "matched_keywords": [
      "7700"
    ],
    "title": "AMD Radeon RX 7700 XT falls below $400, making it a much better choice than Nvidia RTX 4060 Ti",
    "selftext": "",
    "comments": [
      "Should be 350 at most.. and to say that something is a better choice than a 4060ti is not impressive at all..",
      "The rx 7700xt does however have uplift over the rx 6700xt, unlike the rx 7800xt, which is on par with rx 6800xt.\n\nSo for FPS per dollar, the rx 7700xt is probably a decent buy.",
      "Still. Weak ass Generation especially in the low to midrange.",
      "Agreed. Its a refresh generation essentially. But anyone buying a GPU now, the rx 7700xt is one if the most attractive offerings.",
      "future normal books wakeful silky follow sugar telephone deliver cause\n\n *This post was mass deleted and anonymized with [Redact](https://redact.dev/home)*",
      "What's weird is by dye sizes and such this generation had a chance to stomp out rdna3. If the prices were equivalent then most graphics cards handily out-performed their equivalent last gens (eg, 7600, 7700xt). And the 7800xt was in dye size and such more similar to the 6800. If it was priced like the 6800 instead it would have been a complete steal, instead they priced and named it similar to the 6800xt, which made it basically the same fps per dollar 3 or something years later.",
      "Generally I find Nvidias offerings way too overpriced, and that's on top of overpriced chips.",
      "Yes, but the price is pretty consistent with the rx6700 xt launching at 480$ MSRP",
      "Denmark there is ~130‚Ç¨ (1000DKK) difference",
      "> The rx 7700xt does however have uplift over the rx 6700xt, unlike the rx 7800xt, which is on par with rx 6800xt.\n\nThat's all just the naming scheme and irrelevant. The 7700 XT could have been named the 7800 non-XT and then you'd say neither card had uplift.\n\nPrices are also hard to compare, given the price inflation we saw with the shortage.",
      "What? Nvidia control panel is leaps and bounds behind AMD's Radeon software. Dont even get me started on Nvidias geforce experience.",
      "This is funny, reviewers were saying that 7700 XT would've been a good card if it released $420 instead of $450, now people are saying it should be $350. People really just want lower prices in general and will still buy NVidia in the end.",
      "last ones in the shelf, they'll be gone soon enough.",
      "It's a bit difficult when clearance lasts the entire lifecycle of the new product.",
      "Still $100 more than they should be charging for such a mediocre GPU.",
      "Just bought a sapphire 7700xt for a build I'm gonna flip it's a good deal fer the performance",
      "It was always a better choice than the 4060 Ti. Might eve",
      "It's OOS",
      "But...but...but muh raytraycing!!! Love that argument when we are talking about GPUs witch such low performance, that RT would kill it. But sure, we can then introduce upscaling even though we know too well, that upscaling in 1080p is kinda crap on DLSS as well.\n\nOh boy, some of them Ngreedia rabid fans be crazy. But then again most of the fanbois are, no matter the brand, right? It's just that the leather jacket man is perhaps too good of a cult leader.\n\nEDIT: Harsh truth is that this whole GPU gen is a mess. That is ofc partly due to previous crypto craze & insane GPU prices.\n\nWhat saddens me most are two things. Nvidia being so dominant to the point of making extra sure as not to provide \"too much\" of performance at each perf tier while also skimping on VRAM. \n\nAnother thing is AMD super closely following Nvidia's greedy price scheme and trying to give as low discount as possible to remain interesting choice.\n\nI think that if at least ONE of these factors improved drastically, it would be so good for gamers in general. Oh well, one can still hope that Intel can become somewhat viable?",
      "Never had issues with AMD software lol. Sounds like a skill issue"
    ]
  },
  {
    "brand": "amd",
    "generation": "7000",
    "tier": "mid",
    "matched_keywords": [
      "7700"
    ],
    "title": "AMD Radeon RX 7700 XT and 7800 XT will go up against Nvidia‚Äôs 4070 and 4060 Ti",
    "selftext": "",
    "comments": [
      "They should have named 7700 and 7800 as per specs .\n\n7900GRE should have been 7800xt .",
      "Yeah, the naming scheme is not helping here",
      ">The 7700XT is dumpsterfire trash \\[...\\] should have been $399\n\nIf just a 11% discount would make the product acceptable I don't know if we can call it dumpsterfire trash.",
      "To be fair, who cares what the model numbers are. It's the price/performance comparison that's the real deal.",
      "Well *actually,* the 5700XT was the top RDNA1 card, there the so-called \"6900XT\" was really the 6700XT\n\nOh wait, inter-generational numbering conventions have always been aspirational at best and have never really been very consistent.\n\nJust let it go and talk about the price and the performance.",
      "The 7800XT is a good enough product if these performance claims hold.\n\nThe 7700XT is dumpsterfire trash though only existing to upsell you to the 7800XT. One would have thought AMD learned their lesson with the 7900XT. The 7700XT Really should have been $399",
      "7900XTX ‚Üí 7900XT\n\n7900XT ‚Üí 7800XT\r  \n7900GRE ‚Üí 7800\r  \n7800XT ‚Üí 7700XT\r  \n7700XT ‚Üí 7700\r  \nThis is better, IMO. Would've been similar to 6000 series then.",
      "Because paying ‚Ç¨35 more for a bit worse raster but much better RT, upscalers, potentially frame gen (though FSR3 does seem potentially almost as good), and ~80W less power draw is honestly a no brainer.",
      "This was always going to happen. The 7900 XTX is a 4080 competitor. AMD liked to tout that they didn't raise prices between generations, but they pushed their product names up a tier and skipped a 6900 XT successor.\n\nIt's why I hate AMD's pricing and naming this generation. On value, AMD loses at every tier. In value, RX 7000 loses to RX 6000 at every tier, since 7000 uses the price and name of a higher tier than it should.",
      ">The 7700XT is dumpsterfire trash \n\nIt's overpriced by about $30-40.  that's all that's wrong with it.  Calm the heck down.",
      "The 6800 XT competed with the 3080 for $650. Its successor is the 7900 XTX, which competes with the 4080 for $1,000. Nvidia's preposterous pricing is what keep's AMD afloat in the \"value\" discussion.\n\nThe 7800 XT is \"only\" $500, but it's realistically replacing the 6700 XT that was $480.",
      "The only argument for pricing that makes sense is that their costs on the 7700 XT are high",
      "Yeah, that's how generational improvement used to work. You got more at a faster pace than before. You'd expect the 6800 XT's successor to be a higher-powered card for the same money. Instead, it's a similar-powered card for less money.\n\nEven then, it's generous to consider. It's around the same price the 6800 XT is selling for now. Where we'd expect a new GPU roughly a year after launch, the 7800 XT is launching almost 3 years after the 6800 XT. So, it's on-par with a 3-year-old card that's been on sale for about the same price as the 7800 XT.",
      "Perhaps they don't have many partially defective Navi32 die for 7700XT.",
      "It makes no sense, the 6800XT was 650$, the 6800 580$ and the 6700XT 480$.\n\nAssuming we go by price the GRE should have been called 7800XT and the 7800XT should have been called either the 7800 or 7700XT.",
      "Im curious to see how well the 7800 xt compares to 6950 xt so I can either cry or laugh üòÉ",
      "In Germany the rtx 4070 can be had for 585 euro. AMD must drop the 7800 price from its ‚Ç¨550 retail if they want it to succeed.",
      "I am saving to buy me a pretty sapphire 7900 xtx, these lower specs gpu just don't cut it for me",
      "I think they did that naming scheme for the price",
      "What makes it matter is a lot of consumers just don't know enough. They check in every 3-5 years, look at the numbers on the box, then make a choice.\n\nThis lets AMD slide their cards' branding up a tier. People will see \"$1,000 7900 XTX vs. $1,600 4090\" and not realize they're buying a 4080 competitor. They'll see a 7800 XT and not realize it's a 4070 competitor that's not much better than the 6800 XT. They won't realize they're buying a 7700 XT with a different name."
    ]
  },
  {
    "brand": "amd",
    "generation": "7000",
    "tier": "mid",
    "matched_keywords": [
      "7700"
    ],
    "title": "Forget MSRP: Multiple Radeon RX 7700 XT cards now available at $399 - VideoCardz.com",
    "selftext": "",
    "comments": [
      "Still more than a 6800, not interested",
      "6800 was just really good value at its price point. Really hard to beat with the new card generations.",
      "6000 series was goated. 6700xt is also amazing",
      "Still too much should be $350",
      "I bought one at $399 yesterday. I wanted more than 7600 performance but didn't want to spend more that $420. Sapphire Pulse",
      "6800 stock is almost gone though :/",
      "I remember when the 5700 XT and XTX were these prices. These ‚Äúdeals‚Äù are what the MSRPs are suppose to be.",
      "The entire GPU market is overvalued.  Mid tier cards should be much cheaper than they are.",
      "felt so good coping at 150$ last year lol",
      "crazy 20 dollars saved",
      "Only after dropping in price, the 6700XT was one of the worst cards at its MSRP.",
      "What card is offering better performance for the price?",
      "It's more expensive, has less vram and performs the same as the 6800. It should be cheaper.",
      "Oh no a newer product is more expensive than an old product that's going out of stock?\n\nWho'd have thunk?",
      "Lmfao 5700XTX wasn't a thing\n\nEdit: Wow, a downvote! Thanks ü§°",
      "The 50th anniversary variant of the 5700xt had the navi 10 xtx die with slightly higher stock clocks but was otherwise the same as the navi 10 xt version",
      "Should‚Äôve launched at this price.",
      "Never mind lol it was the 50th Anniversary edition. The CHIP though was a Navi 10 XTX",
      "Very unfun fact, the price/performance for GPUs has remained static from 2020 until now.",
      "Got mine for $300. Super happy with it."
    ]
  },
  {
    "brand": "amd",
    "generation": "7000",
    "tier": "mid",
    "matched_keywords": [
      "7700"
    ],
    "title": "AMD has just leaked its dual-fan Radeon RX 7800 XT and RX 7700 XT reference GPU design - VideoCardz.com",
    "selftext": "",
    "comments": [
      ">AMD is anticipated to provide updates on its FSR 3 and HYPR-RX technologies\n\nI wonder how these comments are gonna be like.",
      "Update: Yep we're still working on it. It'll be out soon^TM",
      "Beat me in posting this.\n\nPrefer the 6700 XT reference design more. the 7800/7700XT fan positions are asymmetrical and its missing the Team Rocket logo.",
      "Nvidia doing a discount AND MLID is claiming it?\n\nIt's definitely not happening then.",
      "I hope to God it's taking so long because they decided to add Reflex to it\n\nEdit: Baffled by the downvote. What on Earth was offensive about my statement? I'm just saying I hope the reason it is taking so long is because they're adding functionality to it as the current version is just a toggle for functionality we already have...\n\nEdit 2: Whelp it wasn't an AMD equivalent to Reflex but it was additional functionality. It's a win!\n\nEDIT 3: Hol' up. Anti-Lag+? There's a plus there. We might be getting that Reflex competitor after all! BUT reports also say HYPR RX is RDNA 3 exclusive. A moment of silence for our RDNA 2 brethren",
      "80 class gpu with dual fan? That's something I have not seen for a long time.",
      "They absolutely will if Nvidia prices stay where they are. AMD has proven over and over that they are terrible at initial pricing. Then they drop to a good price eventually.",
      "The cooler design screams 7700 class all over it, but yeah, why sell it for 449$ tops instead of ~ 549$?",
      "Probably not a lot of comments due to everyone just waiting",
      "An unreleased way to use RSR, Radeon Boost, and Radeon Anti-Lag at the same time.",
      "Why do these GPUs just look AI generated? Look at the Radeon logos",
      "it was a small resolution image that was upscaled and sharpened with AI. the original picture looks fine, just grainy details as you would expect from a small picture.",
      "We won't know until reviewers get their hands on it, but I'm going to guess probably not.",
      "They actually named it 7800XT lmao\n\nShrinkflation at its finest",
      "Just been waiting for any leaks on pricing so I was just quick on the draw",
      "the 7700 XT will actually have more cores than the 6700 XT so it very well deserves that name. \n\nthe 7800 XT on the other hand is a rebadged 6800",
      "Quack quack",
      "im gonna call $530 for 7800 XT\n\nedit: $499 for RX 7800 XT confirmed!!!",
      "Or because they're desperately trying to come up with a better name.",
      "HYPR-RX is going to be extremely difficult to get right without errors"
    ]
  },
  {
    "brand": "amd",
    "generation": "7000",
    "tier": "mid",
    "matched_keywords": [
      "7700"
    ],
    "title": "Sapphire formally introduces its Radeon RX 7800 XT & RX 7700 XT NITRO, PULSE and PURE series - VideoCardz.com",
    "selftext": "",
    "comments": [
      "I like the Pulse. It's all you need. And probably very close to or at AMD's MSRP.",
      "Nice, the nitro+ is 320mm. Powercolor, xfx... have monstruosities of +340mm.",
      "I agree. These are midrange cards and deserve midrange sizes. Tired of monstrous heatsinks for no reason",
      "Still far to large",
      "Would have been nice if it came with vapor-x",
      "Why the hell are 2 slot cards not a thing in the 7700 series range? Guess I shall have to wait for the next generation again..would just change cases but like an utter fool I fell for the Loque ghost just prior to the 3000/6000 series gigantism problems ruined it all for us ITX users.",
      "Not everyone has the space for a large case (Even then, many mid towers won't fit them)\n\nIn addition, there's no performance reason for cards of this power tier to be this big, the power draw doesn't warrant it",
      "My guess is that since the 7800 XT and 7700 XT have TDP's so close together and have the same PCB and die, AIB's are just using the same coolers for both.",
      "Nitro + is probably my favorite GPU design ever. RGB without looking super tacky. Just a clean, minimalistic design.",
      "I miss the old Vapor-X cards, with the nice metallic blue colour scheme. I'll take that over all the RGB stuff, personally.",
      "I don't think it'll be a problem. PSU recommendations tend to be overkill to account for people with multiple 3.5\" hard drives, 150W+ CPU's, a weak 12V rail, etc.\n\nI'm using a 6700 XT and 5600 on a 550W.",
      "7900xt and xtx have vapor-x.",
      "Imo you had a dud PSU or have a power guzzling CPU. I use a 550W with a 6700 XT and 5600.",
      "Pretty!! Nitro looks so clean, I wish cards looked more like this and less like gaming mice.",
      "Even at 320mm it's ridiculous.\n\nThese cards make my evga 3080ti ftw3 ultra look small and no longer fit in a lot of smaller case.",
      "Pure üëå",
      "Nah man. There is no reason for GPUs to be this big.",
      "It's what my 5700XT is... hopefully it's priced reasonably close.",
      "Any 650W PSU beyond poo tier will be fine. Could run a 4090 off a 650W psu",
      "Sapphire, please make a RX 7700 XT ITX to replace your RX 570 ITX\n\nSigned,\n\nYet Another ITX User"
    ]
  },
  {
    "brand": "amd",
    "generation": "7000",
    "tier": "mid",
    "matched_keywords": [
      "7700"
    ],
    "title": "Competition Works: AMD RX 7800 XT/ RX 7700 XT Review vs RTX 4070/ RTX 4060 Ti Review",
    "selftext": "",
    "comments": [
      "\"Is Nvidia worried\"\n\nHaha. No. They lead the market over 8:1.\n\nDropping their prices isn't a sign of being \"worried\" it's a sign that they are bending the consumer over and charging as much as they possibly can and have plenty of headroom to drop prices if, and only if, someone else comes out with something remotely close.\n\nJust because they are screwing customers *slightly* less doesn't mean they are \"worried\".\n\nAMD definitely has the potential to make them worried by severely under-cutting them but AMD would rather play the same game and maintain the status quo, prioritizing quarterly profit growth, over long term market share growth.",
      "Pre-post disclaimers: I have a 7800 XT and I believe most modern games have shit native anti aliasing; DLSS (and especially DLAA) tend to provide better images than native does.\n\n&#x200B;\n\nSince upscaling became widespread, NVIDIA and even Intel (based on my experience with the XESS mod in Starfield) can claim \"video games look better on our hardware,\" whereas AMD cannot. It's an inconvenient truth, but one that no performance superiority on AMD's end is going to be able to overcome.",
      "AMD undercut them enough to threaten them into lowering prices, and Nvidia has higher margins. Imo Nvidia has 8x the marketshare in the entire market, but it's gotta be more even than that in the DIY market. Otherwise, they wouldn't be cutting prices.\n\nSo why do you think AMD undercutting them even further won't just result in Nvidia cutting prices. Then everyone will thank AMD and go buy Nvidia.",
      "At least the 7800 XT launch price is cheaper. That's something.",
      "> Well the 4070Ti is half the price of a 3090\n\n3090 was shit value from launch tho, so that doesn't say much",
      "if it did we would still have 200 dollar gpus",
      "i had a 7900xtx but i had to return it for a 4080 because VR was just not there",
      "Nah, in Germany it's 545 Euro for 7800 XT vs 599 for the 4070.",
      "REALLY hoping FSR 3 pulls through, DLSS is the only reason why I still hesitate between AMD and Nvidia",
      "\"Competition works\" company releases a 7800xt with the same performance as a 6800xt....\n\nNvidia releases a 4060 near a 3060ti.... welp.",
      "6600 *am I a joke to you*",
      "Also its previous gen, 3070ti was 200$ less than the 4070ti. The buyers that want 70 ti class perf probably dont wanna pay 200$ more",
      "Nice flair.  Are you a time traveler?  Can I get some future stock tips or something?",
      "Reflex and DLSS are good enough to warrant a premium in my opinion. Everyone wants to keep making excuses for AMD but they need to be significantly cheaper to even be a consideration. Slightly cheaper doesn't interest me or others which is one of the reasons why their market share is horrible.",
      "I don't think AMD can under cut them significantly in the Windows enthusiast market because of Nvidia's bulk production advantage thanks to OEM contracts. AMD's only hope to make progress vs Nvidia is getting OEMs on board.\n\nArguably AMD is focused on long term market share growth, by working on pushing Nvidia up market selling SoCs to OEMS at the low end, and growing the Linux market where AMD have a 3:1 advantage over Nvidia which continues to grow rapidly.",
      "200 on release gpus",
      "I've been playing Witcher 3 & CP2077 a lot recently, testing FSR2, XeSS and DLSS on the 2nd rig (3070). \n\nFSR 2.1+ already looks better than \"native\" TAA. It only suffers from shimmering of distant objects compared to DLSS, not in terms of texture or detail reconstruction. It does fine details really well, like power lines, fences, gates, grills vs TAA.\n\nIf FSR2 iteration fix shimmering, to me, there's no real advantage to XeSS or DLSS2 anymore.",
      "Well the issue with AMD is consistency. They have years of having the \"bad driver\" stigma, hardware that runs extremely hot, consumes a lot of power, etc. They finally latched onto something good with the Vega series but never put much into it, then released RDNA with the 5700XT which was a great performer plagued with serious teething issues for quite some time. Then finally got it right with the 6000-series with an awesome performance to the dollar ratio, but then they released the 7000-series which strayed away from what was getting them there by trying to price match Nvidia at the outset, while not offering the consumers anything extra bona-fide features like DLSS, FG, or Reflex, and learned really quickly what the market is willing to bear considering their market share and had to drop prices, but only after it was too late. To add, yes, I know FSR 2.2 is decent, but it's available for all GPU's, meaning it's not an AMD only feature, and it's inferior to DLSS so I wouldn't even bring it up when talking about feature sets. The only worthwhile feature on the AMD side is SAM, but even so, it's not a real selling point. \n\nNvidia can afford a misstep because they've time and time again over 25 years have shown that for every misstep follows a series of great GPU's, and while they've had their fair share of controversies, the numbers never lied hence why they've maintained a solid lead for quite some time now. People call it mind share, well yes, it is mindshare when you're known for consistently releasing quality products while your competitors are hit or miss. Average Joe's don't want to fuck around and gamble with hundred's if not a thousand dollar purchase by going with AMD, they'd rather go with Nvidia because of the reputation, which is the same reason people just buy iPhones over Samsung's or whatever other top Android brand there is, reputation. \n\nI agree though on the everyone wanting to make excuses for AMD. Being an avid AMD user myself, and having owned the last three generations of GPU's from AMD I used every excuse under the sun from price to performance, to VRAM, to power consumption to justify buying a 6700XT over a 3070/Ti. It only occurred to me when I went back to Nvidia with my 4070Ti that I was an idiot for trying to justify a poor purchasing decision, not saying the 6700XT was bad, but the 3070 is a better overall GPU when considering the whole package. While yes, you can make the argument that I could have gone with the \"technically\" better 7900XT, at the time the cost difference between the two was $135 in favor of the 4070Ti, and in hindsight, the sheer amount of features alone would have still pulled me over to team green even if the two were priced similarly. \n\nAMD's niche is VRAM, they slap a ton of it on their GPU's, but unfortunately once we get to the point to where 12GB isn't enough for 1440p or below, people will be looking at the 60-series/9000 series GPU's, and that 20GB on the 7900XT or 24GB on the 7900XTX won't mean shit except for being able to pump up texture quality, all the while Nvidia 40-series GPU's will still get by with it's feature set. I know a lot of people are probably going to start quoting FSR 3, but look, it has to be implemented into the game by the developer for it to properly work. If PureDark is anything to go by, DLSS and Frame Generation can easily be added without the developers needing to be involved and still work properly, unlike FSR 3, which means it is more readily available to the end consumer--which that right there automatically gives Frame Generation a big W. \n\nTo end this essay--AMD needs to invest in features, and embrace things like RT more seriously. While I won't say raw power isn't preferred, at the end of the day eventually that raw power isn't enough, and developers can only optimize so much, which is where feature sets, like you said, will be the deciding factor and something like DLSS, Reflex, and Frame Gen will easily be worth the extra cost, even if AMD's product offers better out of the box performance.",
      "Early bird gets the worm. Nvidia being the first to embrace RT, and temporal upscaling has been a tremendous boon for them. You'd think AMD would follow suit and invest more resources into combating DLSS, but they seem to be happy with what they have, but they forget that it's the consumers who they should be aiming at making happy, not just themselves. If AMD offered a serious competitor to DLSS that was on par, I'd seriously consider going back to using AMD. It's just their track record doesn't instill confidence in me, and their thing about making everything open source doesn't exactly help them when combating  Nvidia. People cite open source like it's some kind of bastion, but really it's more for hobbyists, the average consumer doesn't care about \"open source,\" they care about what's better. \n\nHow many folks are willing to jump through hoops, browse github, or spend hours on end improving on something when they can just buy a competing product that offers the best experience right out of the box? Ease of use and peace of mind are worth the couple hundred dollar differences.",
      "Oh, come on, you obviously know that the 3090 was shit value from the start"
    ]
  },
  {
    "brand": "amd",
    "generation": "7000",
    "tier": "mid",
    "matched_keywords": [
      "7700xt"
    ],
    "title": "ASRock lists Radeon RX 7800XT 16GB and Radeon RX 7700XT 12GB graphics cards at EEC - VideoCardz.com",
    "selftext": "",
    "comments": [
      "AMD just price them right for once‚Ä¶. Please",
      "It's the first time we see the 7700XT.  \n\nI guess AMD is releasing both GPUs during Gamescom. \n\n&#x200B;\n\nAMD's marketshare has been in the mud this year, so here's hoping they'll rock the world with excellent pricing on both cards (I don't think they will).",
      "And because the 4060Ti is in reality a 4050Ti designed for maximum milkage",
      "AMD RTG have been exceedingly stupid with their marketing and then make the [face](https://media.tenor.com/ZhKMg4_yCTgAAAAC/surprised-pikachu.gif) when they got rejected.\n\nTheir only competitive cards against Nvidia right now are 6800 XT/6700 XT against 4060 Ti 8GB/16GB, aka the only card in living memory that lost to previous generation in some games.\n\nSo that's not saying much. They need to offer +20% overall performance and better than -10% RT performance in order to compete with Nvidia's market inertia alone, not to mention objectively better features.",
      "550 and 450 respectively are my bets, although I hope they do 400 and 500.\n\nEven if they do 400 and 500 where they demolish the 4060 TI's in value, this sub will still bitch.",
      "Just high enough that you'll go and buy the 3xxx series oversupply instead, I promise.",
      "Absolute doormat type of thinking. Don't care about AMD and their profits. My job is to push them for the best performance for the lowest price. Not that they care. Also, both the 7600 and 7900XT are cheaper than the 6600 and 6900 XT, so not sure why you think it's impossible, or even not folloeing the trend.",
      "Confident price and performance is gonna be shit. Gonna try to get a new GPU next year when/if prices are better. üôÉ",
      "So a card that's basically just the 6800xt again is going to cost at least as much? Very cool AMD.\n\nWhy buy that when I can just go get an actual 6800xt for less.",
      "Rebranded 6650xt",
      "500 and 400 USD would be decent pricing, but yeah i also think AMD will do their tried and tested \"NVIDIA - 50 USD\" strategy again. hopefully we're wrong though",
      "I wonder what people think is a good pricing. You think it'll be good to have them at 375 for 7700 XT and 525 for 7800 XT? Though it probably will be 400 and 550, so it'll be around 150 dollars difference between each, assuming 7900 XT at 700.",
      "Waiting for AMD to mess up the pricing.",
      "It's strange that they gave the XT suffix to these after correctly dropping it from the 7600.\n\nThe 4070 at 600 is the price ceiling for a Navi 32 card. So any Navi 32 card is going to have to be below the 6800's MSRP, so why call it the 7800 XT?",
      "The 7800 XT naming has really discouraged me. Maybe I‚Äôm just jaded, but I genuinely think that card‚Äôs going to be $599 now - it‚Äôs not like the AMD of the 2020s to destroy their precious GPU price anchors for piddling things like decent value.",
      "The thing ls they're also competing against the 6800 and 6800 xt at this point, which also offer excellent value (see hw unbox's recent video on the 6800 xt vs 4060 16 gb).\n\nRDNA3's biggest issue is its competing against AMD's own 2 year old offerings at a discount, and its not really winning.",
      "The 7900xt lost to the 6950xt and 6900xt in 1or 2 games because of unoptimized drivers.\n\nFrom what I've seen the 4060ti losing to the 3060ti in DOOM Eternal seems to have been fixed a month after launch, if I look at later 4060ti model reviews from techpowerup. \n\nAlthough I suspect the main reason it really lost is because some people were testing it with RT and max textures enabled. So it'll still likely be slower because of a limited PCIe bus vs the 3060ti if you play at settings that use like 10-12gb of VRAM.\n\n... Essentially the same reason the 6500xt was technically capable of the same performance of a 5500xt 4gb, but dropped off further when playing at settings that use like 5gb+.",
      "Is that really a problem? Those products are cheap specifically because they need to be clearanced.\n\nIf the prices were 300 and 400 for the 7700 XT and 7800 XT, the 6800 and 6800 XT would be dropped the 270 and 370. Then this sub would blow a gasket and declare there's zero value uplift after 2 years (while using only current pricing lmao), because somehow that makes sense.\n\nIt's like saying new LG OLED's are badly priced because clearanced ones are better value. Like yeah, clearance is supposed to be the better value, that's how it works. It's one of those things that seems so obvious that it's strange that it needs to be explained.\n\nIt's a bit hilarious how efficiency and RT matters a shit ton when it's an AMD card vs an Nvidia card, but when it's RDNA3 vs RDNA2, it matters little.",
      "They won't lose money on $400 GPUs if AMD doesn't put too high of a margin on the core.\n\nPS5 has been making money since 2021 at $500 with *several times* longer and more expensive Bill of Materials than a 200watt class GPU. If the partners bleed at these prices, it's only because NVidia and AMD are stabbing them in the face.\n\nStop fucking trying to justify these absurd prices.",
      "I‚Äôm on an RX 6600. I‚Äôm happy with it but if the 7700 XT comes in at a reasonable price I will upgrade. I overestimated how long 8GB VRAM would last."
    ]
  },
  {
    "brand": "amd",
    "generation": "7000",
    "tier": "mid",
    "matched_keywords": [
      "7700"
    ],
    "title": "Time To Buy Zen 4? - AMD Ryzen 5 7600, Ryzen 7 7700 & Ryzen 9 7900 Review & Benchmarks",
    "selftext": "",
    "comments": [
      "I wonder what motherboard they use for zen4 that cost $160 and added to those Cost per frame graph.",
      "If PC Partpicker is anything to go by, the only board for $160 is a Gigabyte mATX board. Absolutely insane the lack of serious options for AM5 boards at decent prices.",
      "The power consumption differences vs actual performance differences vs the X parts are eye-opening.  Its clear that X parts were pushed far beyond their ideal volt/freq curve to look better against the then-upcoming Raptor Lake.\n\nIn the blender test, the 7900 had total system power usage of 201W vs 7900X at 302W, a difference of 50%, yet for all that extra power usage, in that test 7900X was only 12% faster.\n\nIMO Zen 4 would have looked much more impressive had it released as 95W and 105WTDP parts with the \\*option to set to 170W mode without invalidating any kind of \"OC\" warranty.",
      "A 7700 being almost the same as a 7700x, with less power, and a free cooler sounds awesome.\n\nBut when do these even go on sale?",
      "7900 is really a good value vs 7900x, same gaming performance for 100w less\n\nand you almost loose nothing in other applications, that we won't never-ever use",
      "That graph is typical HUB scumminess though. Look at the motherboard they used for AM5 price comparisons, they chose the single $160 AM5 motherboard to use as their price comparison. There are only 3 AM5 boards under $200, and all 3 have major reasons not to buy them.   \n[https://pcpartpicker.com/products/motherboard/#xcx=0&c=160,161,158,159&sort=price&page=1](https://pcpartpicker.com/products/motherboard/#xcx=0&c=160,161,158,159&sort=price&page=1)\n\n  \nThe reality is, AM5 is still very much costs $200+ for most buyers.\n\n  \nOn Intel's side you have 82 options under $200  \nhttps://pcpartpicker.com/products/motherboard/#xcx=0&c=154,163,155,153,152,162&sort=price",
      "I mean it's the opposite, they released them in extreme mode, but you can take them down and not lose much performance.",
      "I also don't understand the $110 RAM cost for AM4 and Intel DDR4 builds. It's easy to find good sticks for $60 and under $50 is possible.",
      "Give it some time, the first am4 boards were awful and expensive too. This [turd](https://www.techspot.com/products/motherboards/asus-prime-b350-plus.162897/) was $150 when top of the line Intel boards were going for $200",
      "Before i pull the trigger and get myself one of these Non X versions i want to see what the X3D models perform like gonna hold off untill they release some specs for those",
      "Meh, mainboard price still shit. DDR5 price is slowly dropping though.",
      "Tomorrow",
      "The AM4 equivalent is significantly inferior in several ways though.  They aren't directly compatible.\n\nThey represent the lowest allowed spec on the chipset + socket in both cases.  AM5 requires significantly stronger power delivery, bios capacity, and DDR5, all of which cost more.\n\nThere IS no 'equivalent' AM4 board.  There are none with similar power delivery either.    AM5 has SVI3,  AM4 has SVI2.   This means different power ICs and mosfets -- and these are not yet high enough volume to bring prices down.  (once Zen4 Epyc is ramped up and these have greater supply, it will lower costs quite a bit for AM5).  So you can't compare the # of phases of some AM4 board to an AM5 one and declare them the 'same'.  \n\nAre mobo manufacturers trying to take a larger cut?   Probably.   But there is competition, and when prices don't lower while there is sufficient competition, the reason must be either supply constraints or higher costs.\n\nIts a little of both here:  higher costs for DDR5 mobo traces/layers, higher costs for various power delivery components, and related supply issues for power ICs for those (that essentially keep costs higher).",
      "The problem is the mobos were massively overbuilt since stock power usage went up so much. Even entry level.",
      "I believe this is because they wanted to compare 32GB vs 32GB.",
      "Explain how the x570 ws ace was one of the first am4 boards.",
      "meh, still no $110-$125 B650 atx boards + $150 2x16 6000 C30-36-36-89 DDR5 kits = NO BUY",
      "Didn't know hoodies had an age limit.",
      "[To be absolutely fair though, here's the list of boards with DDR5.](https://pcpartpicker.com/products/motherboard/#xcx=0&sort=price&s=40&mt=ddr5&page=1&X=0,20000)  Those are the most comparable to the AM5 boards in terms of specs, a lot of the really cheap LGA1700 boards are DDR4.  But of course both the entry-level Intel and AMD may lack PCIe 5 support, or only have it on NVMe, or other weird bullshit.\n\n(PS: it's easier to just select Socket: LGA1700 unless you want to filter for specific chipsets! ;)\n\nNow of course... does that really matter to users?  DDR4 is still very competitive in gaming and if it allows you to go with a cheaper CPU and a cheaper motherboard maybe that's not an awful decision for losing 5% here and there.  13600K is a very competitive CPU for the price, so is 5800X3D, and if you have memory already and maybe a motherboard then AM5 still looks like an overall bad deal even if \"it's got DDR5\".\n\nAnd Zen4's memory controller is *really fucking bad*, like it probably won't POST with 4 sticks unless they're single-rank and low-speed.  [wendell talks about it here,](https://www.youtube.com/watch?v=P58VqVvDjxo) but it's not really limited to 128GB, it's any dual-rank sticks, and even a lot of single-rank sticks don't do great with 4 slots, and you are going to significantly reduce available bandwidth (from 70GB/s with 2 sticks down to about 50GB/s - this is not insignificant). You are basically buying the ddr5 equivalent of the early super finicky b350 boards.\n\nHUB being HUB of course they completely shat on DDR5 for a year straight when it was Intel-exclusive, it *just isn't ready yet guys*, meaning AMD hadn't launched theirs yet, but the moment AM5 launched that was the moment DDR5 was ready and you were a big moron if you were still buying DDR4.  Truth be told it still is not ready yet, things haven't changed from july or august really other than AMD having their product out now (and it's much worse than Intel in terms of memory controller).  The launch gouging was winding down within a couple months, decent RAM came out within a couple months, but the AMD platform just isn't there yet.  \n\nWe will see what prices do in the future, AMD is supposedly designing their platform around smart power stages, which drives up the cost relative to AM4 (and LGA1700), and AMD is intent on selling you 2 chipsets even if they aren't needed (de facto this is just moneygrubbing from AMD - nobody actually connects more than 3 pcie slots even on a $1300 board, nobody really needs the expansion from the second chipset, it's just a way for AMD to capture a little more revenue selling you something that's hardly even used).  Prices may not come down as much as people are hoping, and when AMD says \"cheaper boards are coming\" what they most likely mean is A620, ie even shittier and worse boards, not so much that decent B650/X670 boards are going to come way down.\n\nEven as someone who is really into the idea of a AVX-512 + v-cache system, I'm really dubious about that memory controller and I think it's probably better to just wait a year and see what happens.  I expect 8000 series chips and better motherboards and lower prices will fix most of the complaints.",
      "No. Prices are basically the same from B660 and Z690 MSRP to B760 and Z790 MSRP. The pricing difference is mostly because 600 series is 'old' and thus is on sale now, despite being 95% as good. You can find more 700 series boards under $200 than you can AM5 board."
    ]
  },
  {
    "brand": "amd",
    "generation": "7000",
    "tier": "mid",
    "matched_keywords": [
      "7700"
    ],
    "title": "AMD Radeon RX 7700 XT reportedly outperforms Radeon RX 6800 in 3DMark TimeSpy - VideoCardz.com",
    "selftext": "",
    "comments": [
      "For $449 it better.",
      "I'd sure hope so considering it's only a half-tier lower and a newer generation. \n\nI'm not sure what the precedent is with hard data, but my recollection is that newer gens usually out-perform 1-2 full tiers above the last generation. Otoh, I really don't want to think about how to organize an appropriate chart organizing the last 7 generations of AMD GPU tiers (and getting the community to agree with it)",
      "Doubly so when considering the VRAM difference...",
      "Oh timespy is my favorite game.  I just beat it on legendary for the third time.",
      "Timespy has never been accurate of real world performance.",
      "The tiers aren't really usefully comparable.  The 7700XT is an N32 die; the 6800 is an N31.  The 6800 has a VRAM, bandwidth and L3 cache size advantage.  The 6700XT has 1/3 fewer CUs. And so on.\n\nAll we can compare is what price is asked and what performance is delivered.",
      "RX 6800 has 16GB",
      "It's a single data point. It's no different than using a single game. Results in TS aren't really different than some games.",
      "Hope it would've beat the RX 6800TX\n6800 is the minimum.",
      "Exactly. Everyone should forget branding, number of cores etc.\n\nPrice / Performance is the main thing that counts, with any extra features people want/need",
      "6800 has 16gb",
      "Or outperforming the 6800XT even.",
      "It's meant to outperform the rx 6800, not the rx 6800 xt",
      "Should have been 429$. But I suppose AMD just wants to use the 7700XT to upsell people into the 7800XT. Will laugh if they overproduced 7700XT‚Äôs like they did 7900XT‚Äôs and the price drops by 100$ in a few months",
      "TimeSpy, my favorite game. :p",
      "RX7800XT is the better choice due to just $50 more for a huge performance bump (and 16GB VRAM).\n\nRX7700XT is nonsense, only exists to upsell you a RX7800XT.\n\nIn the long run, the market will adjust RX7700XT prices somewhere sensible.",
      "54 CU's, a heavily cut down memory bus, and chiplet overhead.",
      "6800 not 6800XT",
      "It will be 429 in a few months maybe even 400 if RDNA 2 cards stocks run low.",
      "It's a x700 tier product, why shouldn't it cost less? The $50 gap between this and the next tier is ridiculous"
    ]
  },
  {
    "brand": "amd",
    "generation": "7000",
    "tier": "mid",
    "matched_keywords": [
      "7700"
    ],
    "title": "Ryzen 7 7700x cheaper than 7700 non x?",
    "selftext": "",
    "comments": [
      "Probably a mix of that store still having stock from when AMD did a limited-time sale on the X CPUs and the 7700 being new, which usually add a premium for a short while.",
      "europe AM5 market is totally nosense. Prices are random, it is a total mess thk amd store not selling the non-X cpu yet (will it?)  \nFun fact: that's the price of the 7600x in italy, consider yourself in german to be lucky with those prices D:",
      "Stores want to clear out inventory. Zen4 hasn't been selling well.",
      "It‚Äôs because of the wraith fan that comes with the 7700 non x. I‚Äôm sure that cooler is at least a $50 cooler. The current overclocking state of processors these days is a waste of time. It‚Äôs not like the olden days of getting 800-1Ghz out of a chip anymore aka 2600k.",
      "> I‚Äôm sure that cooler is at least a $50 cooler.\n\nIt's less than 20c of extruded aluminium.\n\nedit: Thought it was a wraith spire/stealth, it's a wraith prism, so probably around $5-6 actual value.",
      "More like 15$. For 25$ you can get some serious upgrades.\n\nActually, 20$ is a serious upgrade already.\n\nhttps://www.amazon.com/Thermalright-Refined-SE-ARGB-Technology/dp/B09LHBFPJ6\n\nhttps://www.amazon.com/Thermalright-Refined-SE-ARGB-Technology/dp/B09Y869Z8B\n\nhttps://www.amazon.com/Thermalright-Refined-SE-ARGB-Technology/dp/B09XWKQ2KS",
      "if we exclude the \"VAT-players\" stores (that are also only e-commerce, and good luck if u have any problem later on), and we consider retail stores actually we have:  \n7600   listed at 280‚Ç¨  \n7600x listed at 300-400‚Ç¨ (nosense)  \n7700   listed at 399.99‚Ç¨  \n7700x listed at 450-490‚Ç¨  \n7900   listed at 520‚Ç¨  \n7900x totally out of charts, from 530 to almost 700‚Ç¨ lol.  \nOn amazon the situation is not much different tho\n\nfun fact, the X versions can be bought cheapper at [amd.com](https://amd.com), ship included.  \nRly envy U.S. with microcenter :/",
      "No way it‚Äòs that bad in italy‚Ä¶I‚Äòm so sorry for you",
      "Not a $50, more like $25.",
      "It's because the X CPUs have been on the market for a while, sitting on shelves. So, stores have them heavily discounted. The non-X CPUs are just launching, so they're at their MSRP. It's not rocket science.",
      "Its simply that for now traditional OC is close to dead PBO with CO makes more sense in my opinion.",
      ">I‚Äôm sure that cooler is at least a $50 cooler.\n\nNo way. In Finland Wraith Prism coolers are worth 20‚Ç¨ ($22) max. in the second hand market. Most are unused.\n\nIf you have $50 to spend on a cooler, I have no idea why you would buy the Wraith Prism and not some decent tower cooler.",
      "Because they know that everybody is going to buy the non X variants in the future. Therefore they want to sell the x variants as fast as possible.",
      "it cost them like 5$ and is worse than a standard 20$ cooler.",
      "Buy 7700X and one of the popular $20-25 HSFs.\n\nIf you want a 7700, buy the 7700X and put it in eco mode. Remove eco mode if you want performance. \n\nIMO I think it better than going 7700 then pushing up the settings to stock 7700X at those prices.",
      "With the cooler, it's actually the better deal.",
      "They're the same cpu\n\nUsually xs cost money though, they saved not having to paint on the x\n\nWhy is it lower priced?\n\nuH",
      "Mindfactory constantly does this. They change prices based on availability. That's what OP is seeing in that screenshot.",
      "According to this post, the 7700X even gets a **gain** in performance for around 40-50C. I guess this would make it faster than a 7700 non-X or faster/cooler than an OCed non-X.\n\nhttps://www.reddit.com/r/Amd/comments/xp5yj5/eco_mode_is_very_good_performance_increases_for/",
      "Even those of us far too far from microcenter, which is most of the country geographically, have little fear of ordering online. After 30 days if it has an issue you just RMA it with the manufacturer and that's that. It's not as fast as a store swap but it's also not that common you need it. \n\nBut I've lived in Asia and people there are the same as Europe where they avoid ordering anything online that is important over return issues. No idea why an RMA is so much less of a concern here."
    ]
  },
  {
    "brand": "amd",
    "generation": "7000",
    "tier": "mid",
    "matched_keywords": [
      "7700xt",
      "7700"
    ],
    "title": "RGT - 7800XT, 7700XT, and 7600XT rumored specs.",
    "selftext": "[https://wccftech.com/rgt-radeon-rx-7800-xt-rx-7700-xt-rx-7600-xt-and-rx-7600-gpu-performance-targets-and-specs/](https://wccftech.com/rgt-radeon-rx-7800-xt-rx-7700-xt-rx-7600-xt-and-rx-7600-gpu-performance-targets-and-specs/)\n\nHonestly, those specs don't inspire confidence in team Red for me this go 'round if they're true. The 7800XT is seeing maybe a 25 -30% bump in performance in best case scenarios with better RT performance, and the 7700XT is probably seeing similar results, but when compared to their last gen-counterparts the 7700XT is probably looking more like a re-badged 6800 possibly XT, and the 7800XT is basically a re-badged 6950XT with better RT performance.\n\nThe only card in there that's worth noting is the 7800XT, it'll be almost comparable to a 4070Ti, which I just upgraded from 6700XT to. The 7700XT looks like it'll fall victim to the same fate as the 6700XT, priced in no-man's land with middling performance.\n\nI was talking to some friends earlier about this--for the 7800XT to even succeed it has to be priced \"realistically\" no higher than $650-$700 only because Nvidia is the go-to for a lot of gamers, AMD has a lot of ground to cover, and despite what some might say, Frame Generation is probably the best feature I've seen on a GPU in a long time; that and DLSS support sold me on switching sides for this gen. DLSS has been one of the features keeping Nvidia on top these past few gens, even against comparable AMD cards, and FSR just hasn't had the impact DLSS had, even being open source, the adoption rate and IQ combined versus DLSS has put it way behind.\n\nIt pains me to see how the x700 series being given the treatment it's getting. The 5700XT was such a great card, and the 6700XT improved upon it, but marginally, but still offered performance relative to a 2080Ti. The fact that the 7700XT might not even hit 6800XT levels of performance means this card is going to have to be realistically priced at $400-$450 for it to succeed, otherwise they're just handing Nvidia a victory this generation. The 4070, it's competition is going to be utilizing DLSS 3, and frame generation which is, in the eyes of the average consumer who doesn't understand tech but can read numbers is going to gravitate towards. The only thing that would push people to the 7700XT is if the 4070 is priced outrageously. Even then if Nvidia releases a 4060/Ti, it's probably going to eat the 7700XT's lunch in terms of sales.\n\nThe 7600XT is literally just a rebadge, plain and simple. Nothing to see here. :(\n\nSorry for the long post, but honestly the only card that piqued my interest from this gen would have been the 7700XT, but after pulling the trigger prematurely and getting the 4070Ti, honestly I'm happy I did. As much as it pains me to stray from team Red after six years,but I wanted something that was a step up from mid-range that would give me the option to play in 4k without spending over $1000, and I got the 4070Ti for $900 after sales taxes, which isn't bad for basically 3090Ti levels of performance, and about $132 less than what I would have gotten a sapphire/power color 7900XT. Was it pricey? Hell yes, but with it's performance level I'm easily seeing a good 3-4 years of usage from it, namely at 1440p.\n\nIt should be telling that the 4070Ti, despite it's price, is a card that AMD is going to have a tough time competing with considering it's nearest competitor, the 7900XT is only marginally better for $100-$150 more, and with the prices of the 7700/7800XT being unknown, AMD's got their hands full trying to figure a price that'll entice buyers. That's of course if these rumors are true.\n\nWhat do you guys think? You think AMD is on track, or do you think they blew their load a bit prematurely and forgot about the lower echelon of the RDNA3 cards?\n\nEdit: To clarify I was hoping and praying for AMD to pull a sucker punch on Nvidia and catch them off-guard to bring balance to the GPU market. I'm still hoping they do, or at least sell well, I would love to see AMD continue the trend of keeping Nvidia's pricing somewhat in check and maintaining decent performance, otherwise spending $900 on what can be viewed as mid-range will be nothing but a pipe dream in the years to come. I'm an AMD guy at the end of the day, even when the i7-2600k was god-tier I opted for AMD. ",
    "comments": [
      "Thing is, here in Canada, a 6800s and above are pretty much non-existent, and what's n stock is priced close to a 7900XT, if not higher. It doesn't look much different with Nvidia cards. \n\nSo whereas theoretically the 6800XT and the 6900 cards are a better value at msrp, practically we don't see these prices nor stock available.",
      "I always love how posts reference retail prices like that doesn‚Äôt relate pretty much anywhere in the world other than the USA.",
      "AMD picked the wrong generation to invent the XTX SKU, because they can only really compete with Nvidia's (current) second-best. And that's ignoring the looming Ada Titan/4090 Ti.\n\nRemember when Navi 1 released? The highest model was the 5**7**00 XT, which was a clear indicator that it competed with the 20**7**0 (Super).\n\nLikewise, the 6**9**00 XT at least had a claim to fighting the 30**9**0 when it came to 1080p and 1440p without RT.\n\nBut the 7**9**00 XTX is only a match for the RTX 40**8**0 (which is significantly gimped compared to the 4090), and the RX 7**9**00 is hardly a match for the 40**7**0 **Ti**. Keep in mind that the RX 6**8**00 competed with the 30**7**0 **Ti**. I have no doubt that a 4080 Ti is coming as well.\n\nIt's clear that all RX 7000 products below the 7900 XTX are more gimped versions than they would have been, had AMD decided not to name that SKU as such. Navi 32 and 33 not having more Compute Units than their predecessors (like N31) combined with the name-fuckery means that AMD will have to offset core reductions on low & mid-range products with clock increases to try to have barely-not-stagnant performance. Truly a pathetic showing this generation. I hope for everyone's sake that most people outright reject these.",
      "When the entire launch from both Nvidia and AMD has been a massive disappointment so far (especially with pricing) why would we expect mid tier to be any better. It's gona be overpriced and undersupplied (as per Lisa Su). This generation is a lost cause!",
      "I'm really bummed out by this. If the 7800XT specs are those upon release. I'm just going back to Team Green.",
      "hey bud im not having a go at you personally, moreso the industry as a whole. Also the fact that retail even in the us, is not really a good indicator. So many of the Halo lines people acutally buy are no where near retail, just look at asus strix as an example.",
      "Same in Europe more or less.\n\nYou either buy overpriced new gen, or damn overpriced last gen that is like 100 cheaper at best then new cards",
      "its simple. Ask 400 for the 7700XT. The issue is quite simple to solve but that would mean that the company caved in.",
      "AMD can never decide if they want to make their cards equal to Nvidia or ahead. The R9 290x and HD 7970 also had awkward naming in relation to the competition.",
      "AMD will probably price the 7800XT at 749 and act surprised when Nvidia takes 80 to 90 percent market share again.\n\n7800 XT should be 599.",
      "I am aware that AMD have models with the XTX moniker before. It wasn't the best choice of words to say that, but that is beside the entire point I was making. I think it's pretty clear that I'm referring to the fact that the 6000 series did not have a halo \"XTX\" model.\n\nThanks.",
      "Ummm.. I'm sorry? I quoted US dollars because that's what I'm familiar with and what directly impacts me. If I lived in the UK, or somewhere else I'd reference those prices, etc. \n\nI know shits expensive, and I know some countries pay more than others, but those things don't impact me. Not that I'm turning a blind eye, just that it doesn't affect me, and my post was my opinion and thoughts based on what I know and am familiar with.",
      "AMD is not innovating and is just happy to ride NVIDIA's coattails  while only getting money largely from their fanboys",
      "AMD is going to have to be VERY competitive with their pricing if they want to move these cards at all especially with the lack of frame generation. Most people without this feature will quickly discredit it and write it off but with my hands on experience it's a game changer.",
      "What were you expecting them to be?\n\nI think performance estimates are too high, though. The 7900xt had 25% more bandwidth, and 20% more boost clock compute even after the clock bumps. We're probably talking 6900xt performance on average, with better RT and machine learning. Still behind the 4070ti in every way except VRAM.\n\nI guess people were expecting another  navi31 cut, maybe? 72 CU or something?",
      "Yeah, you're right. I know they haven't always been that way (RX 480 ‚âà GTX 1060, as a recent example). I think my point was more that the past two generations *did* align with Nvidia's name scheme for the most part, and this generation doesn't. It's not so much a problem if the naming is consistently inconsistent, but suddenly no longer matching can lead to some bad expectations.\n\nI think the name of the 7900 XTX alone was a significant factor in making people believe AMD was going to match/beat the 4090.",
      "I think all these specs would have been great had AMD achieved the performance targets. Remember NVIDIA actually decreased CU's for cards compared to previous generation. But the performance uplift was so good that the cards still delivered better performance compared to cards with more CU's across the lineup.\n\nAMD didn't have much IPC gains or clock speeds and hence the 7000 series look lackluster in comparison.",
      "> The 7600XT is literally just a rebadge, plain and simple. Nothing to see here. :(\n\nIf it's based on the N33, then it clearly isn't a rebadge, but it won't be more than 20% faster (on avg) than N23 either, and even that isn't a given. RT should see more of a gain, but not sure how viable that is outside of perhaps RT shadows.",
      "Tbh I'm expecting prices to be a lot better than many doom and gloomers. 7900 XT is starting a hundred less than the 6900 XT and not selling. AMD tends to be quick to adjust prices to market, so I think it'll drop to 800, although probably not formally (AMD seems to favor reimbursing retailers behind the scenes to cut prices rather than formally adjusting MSRP).\n\nThe 7800 XT has 5/7 the CU count and value increases as you go down the stack. 5/7 * 800 = 571. So the 7800 XT is probably gonna be 550-630.\n\n6700 XT and below MSRP's were set during the shortages, 25% tariff, and cryptofuck epidemic. So they were higher than otherwise.\n\nThe 7700 XT is going to be getting 20% more CU's than the 6700 XT, so it will have 80% of the 7800 XT. Again, value tends to increase down the stack until you hit the 6 series. So .80 * 571 = 456.80. So probably 400-450 and it'll perform a bit over halfway between the 6800 and 6800 XT, probably closer to the 6800 XT.\n\n7600 XT is probably gonna be around 6700 XT performance. 7700 XT has 50% more CU's than it, 456.80 * 0.66 = 304). The 6 series is where value tends to drop off, so I think it'll be 300-340.\n\nThe 7600 is 28 CU's, or 7/8 the 6600/7600 XT. So it should be no trouble to match a 6600 XT and will probably come close to the 6650 XT. As for the price, 320 * 7/8 = 280.\n\nA lot of this will depend on what Nvidia is doing, but assuming Intel continues unfucking the drivers and reliably delivers 6700/XT level performance at 250 with the A750, competition is fierce.",
      "Which cards did Nvidia decrease SMs for? For everything currently released, it seems to be more."
    ]
  },
  {
    "brand": "amd",
    "generation": "7000",
    "tier": "mid",
    "matched_keywords": [
      "7700"
    ],
    "title": "Upgraded from RX Verga 64 to RX 7700 XT",
    "selftext": "I've upgraded my vega 64 to 7700 xt. It has served me for the past 5 years and I'm hoping my new gpu will serve me more.",
    "comments": [
      "A la verga guey! Nice upgrade! Don't let the annoying people make you question your decision - as long as you're happy that's all that matters!",
      "Might want to look up what's the english translation of Verga ü§£",
      "Forgot to take a picture coz I was excited",
      "When from rx 5700 xt to 7800 xt Monday this week, hope it feels as worthwhile as it did for me.",
      "Yeah who wouldn't love to upgrade his Verga, congrats!",
      "This post was so funny cause spanish is my native language",
      "No more new stock of 6800xt and 6700xt here in our area and I don't have the extra money for 7800xt",
      "Why no side by side of the cards",
      "Thank you",
      "I'm happy with my purchase and my monitor's 1440p. Just the right spot for the upgrade.",
      "Yes not in the US. I don't want to buy used cards though.",
      "64 Verga? At the same time?",
      "Nice! I went from RX 6600 to RX 7700 XT. Runs insanely cool even when OC‚Äôd which is a plus.",
      "Almost perfect 2x\n\nhttps://www.techpowerup.com/review/amd-radeon-rx-7800-xt/32.html",
      "No worries I had that vega 64 strix too did you also do the thermal pad mod?",
      "Vega56 still rocking solid.",
      "And even Funnier because VEGA dedicated cards were, actually, a verga jaja.",
      "But it is still higher price, and higher power consumption. Sweet spot for most people isn't always the best option for everyone. That's why there's a whole stack and not just one \"best\" card per generation.",
      "We get it you love the 7800xt, the 7800xt is the best option, now let the dude enjoy his card",
      "Im still using my vega 64 Sapphire Nitro +, it still rocking but I dont know if upgrade or wait de 8000 series"
    ]
  },
  {
    "brand": "amd",
    "generation": "7000",
    "tier": "mid",
    "matched_keywords": [
      "7700"
    ],
    "title": "Here's a look at Radeon RX 7700 XT and 7800 XT models from ASRock, ASUS, Sapphire, and more",
    "selftext": "",
    "comments": [
      "Yeston bringing out the Sakura Hitomi!",
      "Interesting that MSI didn't make the list, maybe AMD was mad that they never updated their designs, instead they relied on those \"Classics\".\n\nOh well, ASUS, Gigabyte, and especially Sapphire, XFX and Powercolor will do. :)",
      "Looking at the MSRP's on these two--the 7700XT is dead in the water. $449 for the 7700XT, and $499 for the 7800XT, it would be a no brainer to spend the extra $50 for the additional 4GB of VRAM, extra CU's, etc. \n\nCan't wait for reviews to come up.",
      "You shouldn't be leaning to anything 7700 xt at MSRP or more",
      "Good, one less garbage Nvidia partner for AMD GPUs with subpar quality.",
      "I assume it'll be a disappointing card whose only purpose is to upsell to a 7800t...  like the entire nvidia 4000 lineup other than the 4090.",
      "I'm leaning towards either the [**ASRock Steel Legend RX 7700 XT (white graphics card)**](https://static.tweaktown.com/news/9/3/93021_01_radeon-rx-7700-xt-and-7800-models-from-asrock-asus-gigabyte-sapphire-more.jpg) or the [**Sapphire Pure RX 7700 XT (also a white graphics card)**](https://static.tweaktown.com/news/9/3/93021_07_radeon-rx-7700-xt-and-7800-models-from-asrock-asus-gigabyte-sapphire-more.jpg). Which ones are you guys interested in?",
      "Is one of the 7800s actual dual slot?",
      "Steel legend is cool and the phantom gaming 7800 xt. Gotta decide between when it releases. Really depends on which ones rgb looks betterzz",
      "Yah i noticed the same thing, they have even released one of AMD GPUs (i dont recall which one) late to the party, looks like MSI is leaning more towards Nvidia after EVGA exited the market.",
      "Their new design is pretty cheap looking, not something you want from a $1000 product. Glad they're backtracking to the old design for the mid-tier GPUs.",
      "Honestly, if the 7700 XT/7800 XT split is anything like the 7900 XT/XTX split, the 7700 XT could get some pretty hefty discounts that would make it pretty attractive.",
      "Just wachtched GN video. The XFX does not look dual slot to me. ![gif](emote|free_emotes_pack|feels_bad_man)\n\nhttps://imgur.com/fVmxeup",
      "They go through phases of being bad and being alright, but its pretty brief. As long as reviews pan out and you can't get anything from the 3 trusted board partners (Sapphire, XFX, PowerColor) they're probably the best alternative. Gigabyte tends to just undersize designs and Asus loves to not do any work porting a Nvidia design to AMD. They've fucked up at least 3 cards this way the past decade",
      "I'm also curious about that. As far as I can tell from the available photos, ASRock, Asus and Sapphire models all look around 2.5 slots. The only one that seems promising so far is from XFX: Gamer's Nexus had a 7700 XT from XFX in the video, and it looks like it may be a true 2-slot design. Still waiting for the official specs though.\n\nGiven that 7800 XT and 7700 XT are close in TBP, XFX could save money by using the same cooler. So it's plausible they could offer RX 7800 XT in a 2-slot form as well.",
      "Usually, brands have a \"premium\" product and a \"standard\" product. Like Sapphire has a \"standard\" Pulse while a \"premium\" Nitro+. They add more fans, and so higher headroom for overclocking in their premium products. While the standard is still fine but not as higher headroom.",
      "Dude it might go cheaper on holiday sales you never know",
      "Firstly wait for reviews.",
      "They also are the AMD GPUs with the most stock here in the Philippines. I'm glad I got an Asus 6700 XT that's $100 cheaper than the cheapest MSI Ventus, that didn't go down from crypto prices lmao. Imagine an MSI Ventus 6700 XT selling at $450, while I got my Asus 6700 XT at $360.",
      "Are brand models more expensive than the AMD Model, if so why? And some have 2 fans vs 3 as well. Its my first time actually building a pc and waiting for a pc. Ive bought and built everything except for the GPU in my Terra case, which is why I'm asking. I need to know if the 7800 xt will fit"
    ]
  },
  {
    "brand": "amd",
    "generation": "7000",
    "tier": "mid",
    "matched_keywords": [
      "7700"
    ],
    "title": "AMD Radeon RX 7800 XT Pricing Slides to Below its $500 MSRP, RX 7700 XT Below $440",
    "selftext": "",
    "comments": [
      "Wake me up when 7700XT drops to $400 where it should have launched to begin with.",
      "No you won't. You'll ask why it isn't lower, then go and buy another overpriced nivida counterpart.",
      "with the performance of a 6800 which is sitting pretty at $400 - I completely agree",
      "AMD has shown it can't, or doesn't want to, bring Ryzen-like competition to Nvidia. Ryzen wasn't an absolute champion when it launched, but it was bringing technologies (specifically, higher core counts) to CPUs with near-Intel performance for a LOT less money.\n\nRadeon's version of that is being way behind on features and using \"we're pretty much even in raster\" to justify being close to Nvidia in price. I still don't get why people would laud the 7800 XT for bringing the $650 6800 XT's performance tier to $500 when the 6800 XT was 3 years old and already selling at $500. In the 7900 family, the XT was an embarrassment at $900, and the XTX's only selling point was \"Nvidia's pricing is worse.\"\n\nBoth companies are shit with their pricing, but AMD's lack of a mature, consistent product stack and set of features means they need to be consistently able to win on price. AMD hasn't done that in a while. I really hoped the 6000 series was a sign they were moving forward, but the 7000 series has been a wreck.",
      "While offering 4gb less of vram, which means it should be cheaper.",
      "AMD always releases GPUs $100 over what they should be and reviewers rightfully shit on them. Then, 6 months later they cut prices but only a niche market cares because everyone who looks up the reviews even a year later thinks the GPU is still shit.\n\nIf AMD is seriously confused as to why their GPU market share is an extreme minority, this is one issue they need to tackle first.",
      "Exactly lol\n\nIts the same posts everytime anything drops in price",
      "By then, it'll probably have been long enough to where reality should have had it discounted int othe $300-350 range. That's where the 7900 family is.",
      "I'll refrain once I see this sub stop bitching about amds prices and then seeing worse price to performance nivida gpus in the flair.",
      "And?",
      "Yes that's unfortunate. Amd will never learn.",
      "A card reaching MSRP isn't really \"dropping in price\". Even if it was slightly above MSRP it's not really news worthy.",
      "I'd bet that's more of an Intel financial flex than anything. They probably get a lot of bundled discounting on Arc+Core parts as an OEM.",
      "Raw performance isn't always better",
      "Glad I got the 7900 xtx at 800",
      "It's a shame that all models are over 260mm :(",
      "Oh, they learned, they learned that they will never beat Nvidia even with better price. Back to the RX470/480/570/580 era they were super well priced but people still bought the GTX1050. That card still outsells Polaris line up. AMD can't change people's minds. When they have a better card, people will say their card might be fast, but their drivers sux. TLDR: They just want AMD or Intel to put pressure on NVgreedia to lower their prices.",
      "You have a 3070 flair lol",
      "Drop another hundred and I'll buy",
      "Shit my 6900xt is 340mm!"
    ]
  },
  {
    "brand": "amd",
    "generation": "7000",
    "tier": "mid",
    "matched_keywords": [
      "7700xt"
    ],
    "title": "7700xt or wait for 5060 (Ti)",
    "selftext": "I‚Äôve been planning a new 1440p setup. Im wondering if I should wait and see how 5060 performs. What do you guys think? I haven‚Äôt seen any news about performance or price yet. \n\nEdit: Thank you all for your input! I‚Äôll wait for new models from both teams and keep saving for some more time to get a more future proof gpu. \n\nAlso: I‚Äôm mostly dual boxing eve online and rarely anything more demanding. My monitors are both only 60hz",
    "comments": [
      "1440p gaming? Just find a used 6800XT and you're golden, or an RTX 3080 Ti if you're inclined for a bit more RT performance.",
      "If you need it now go for it, if not wait for 5060(ti) benchmarks to compare. I kinda agree with the OP, depending on the games you play 8gb of VRAM may become an issue sooner than later.",
      "5060 and the Ti variant will be 1080p cards nothing more",
      "The 5060TI will not be a 1440P card.",
      "Wait for the 9070 non xt. It will best those for sure.",
      "Why would you want only 8gb of vram for 1440p ? \n\n16gb is the minimum VRAM id recommend. \n\nIf your this limited by budget, go older gen or used if you want 1440p performance instead of low tier 1080p GPU's.",
      "I thought it would still be a whole lot better than my gtx 1080 and I‚Äôve played 1440p on it for 7 years. And it is only 8gb vram. Am I missing something else? Prices are not so good in Finland.",
      "The best value video cards for the mid-level 1440p resolution setting is either the RX 6800 16 GB or the RX 6800XT 16 GB, since both cards have recently been selling between 300 and 450 US dollars. Most Nvidia hardware cannot compete against either card in the under 500 dollar range unless the RTX 4060ti 16 GB card can be found in that budget which rarely (never) ever happens.",
      "wait for the 9060(xt)",
      "I snagged a 4060 after owning a 7700xt I got a 7700xt for $450 then I found a clearance open box 4060 at my local Best Buy for $245 and bought that barely noticed a difference at 1080p high refresh rate",
      "Wait for the 9700 prob a similar price with the 4060 ti",
      "Why would you buy a 5060 if a 3080 will do 1440 just fine?\n\nGot a lot of cash, heh?\n\nLast time I bough a current gen GPU was in 2008. It was the amazing ATI HD 3850. Not even PCIe - it was an AGP card.\n\nThen I realised that I made a mistake immediately after installing it on my Pentium 4 HT 3.2 system, with incredible 256MB of RAM and a 120GB HDD.\n\nNot worth it. It's price deprecation is ridiculous. I paid a lot for it and a year later, it was worth less than half of what I paid. Not to mention that I was already an adult, I had a job, I had bills to pay. I had no time to play games and hardly ever used it.\n\nThat GPU lasted till 2011 with me when I finally upgraded my system to a x64 architecture. Then this 2011 system lasted till 2018. And my current system is still this 2018, with some upgrades. AM4 platform, with 32GB of DDR4 and a 2080Ti. Runs perfectly at 1080p.",
      "Seeing existing 50xx series cards then it's clear they have given one level higher tier names to the cards, so expect the 5060(ti) to be just 5050 - just like shitty 3050 cards, whom nobody needed or cared about!\n\nAnd for 2k gaming you will need better card, or just look at some existing one as there are many who have dropped the price",
      "Eh I reckon it will do fine at 1440p if you buy the 16GB version and you're willing to use DLSS and turn down the RT settings a bit.\n\nIt sure isn't like a 60Ti from the glory days (3060Ti and 1060), but it will probably be a decent card. It shouldn't be nearly as bandwidth starved as the 4060Ti 16GB either due to GDDR7 offering a boatload of extra bandwidth on the same bus width. It should have similar bandwidth to the 4070 Ti.",
      "I run 1440p with 7900 GRE (16 GB VRAM). Games routinely consume around 10 GB. Highest I‚Äôve had is 12 GB.",
      "I returned said 7700xt",
      "Used card prices are not good where I live. Found some 3080 new but the prices can‚Äôt be right. 1700‚Ç¨ and upwards.",
      "If you want a 1440P card then you want a 4070 TI or super or higher (800 / 900 bucks). 5070 ti (900+??) most likely but they will have just 12gb and cost a boatload more then just a 7800xt.\n\nPersonally im done with Nvidia's practices and its high prices and low Vram, the 7800xt (500 bucks) is a great 1440P card for like half of what the 5070TI wil cost.",
      "Ray Tracing, DLSS and Frame gen are extremely VRAM intensive. 8GB works on the 1080 because it doesn't have any of those features.\n\nPersonally I'd wait for the RX9070 and 5060Ti before deciding. The 9070(and XT) are looking like they might be really solid options with AMD bringing a true DLSS alternative and actual RT hardware on them.\n\nThe 9070 is looking like it might be roughly like a 4070 Super with 16GB of VRAM with decent RT performance, unlike the 7700XT.",
      "New games are using alot more when using high or ultra textures at 1440p. \n\nSome older games don't use alot, but some new ones definitely are, 8gb isn't even enough for 1080p tbh"
    ]
  },
  {
    "brand": "amd",
    "generation": "7000",
    "tier": "mid",
    "matched_keywords": [
      "7700xt"
    ],
    "title": "Thoughts on possible 7700XT and 7800XT releases",
    "selftext": "AMD are being very tight lipped about the 7700XT and 7800XT GPU's. One has to wonder if they will even launch them. With the mess of the 7600 and 4060 Ti launches it has me wondering. Could we see a 12 or 16GB 7700XT and 16GB 7800XT launch sometime around July to rain on Nvidia's parade? Or will we see AMD holding out indefinitely? Especially if they still have a massive overstock of 6000 series cards gathering dust.\n\nWe are already seeing price cuts but are AMD and their partners (as well as retailers who paid in advance for stock) unwilling to make those cuts? Particularly if they are making significant losses on each card?\n\nAt any rate if they do launch them I do believe they need to come in at around 400 and 500 dollars respectively.\n\nI'm not seeing any rumors or leaks on these cards so I am just throwing this out there for discussion.",
    "comments": [
      "They'll probably be released after the stock of 6900/50 XTs and 6800 series sell out so that there's a more well-defined market niche that those cards would fill. I wonder if they'll release Radeon 7700, 7800, or even 7900 cards or if they're worried they'll create intra-brand confusion with the AM5 CPUs\n\nEDIT: That said, I realize they're about to reach the 7600 non-XT so maybe that's not a concern of theirs.",
      "I don't think with the current line-up that we will see 7700XT and 7800XT.\n\nMore probable will be a 16gb 7700 with performance between 6800 and 6800XT, and a 7800 with 16gb with a performance within 5-10% of the 7900XT.",
      "I don't know for sure but considering everything released so far I wasn't confident enough to wait for a 7700/7800xt. Also the 7800xt was released, AMD just called it a 7900xt and tried selling it 250$ over what the MSRP should have been.\n\nThis gen was a huge skip for me so I bought a used Nitro+ 6900xt for 400$ and don't regret it.",
      "I could see a 7800XT with performance right around the 6950XT, so \\~15% less than the 7900XT.\n\nI don't think a non-XT part would be placed that close to a next tier XT part, 6900XT is \\~30% faster than 6800, 6800XT is \\~40-50% faster than a 6700XT.\n\n&#x200B;\n\nAlso they need something against the 4060Ti, which is \\~30% faster than the 7600. With a 7700 between a 6800 and 6800XT, that would be \\~50% faster than a 7600, I could see that also as an 7700XT and then a 7700 10% below that.\n\n&#x200B;\n\nThe 7900XT is \\~2.3-2.5x as fast as the 7600, there is room for many GPUs in between there.\n\nSo my lineup would be\n\n7600 - full N33 (32 CU) - 165W - 100%\n\n7700 - heavy cut N32 (40 CU) - 185W - 120%\n\n7700XT - cut N32 (56 CU) - 230W - 160%\n\n7800XT - full N32 (64 CU) - 265W - 190%\n\n7900XT - cut 31 (84 CU) - 315W - 240%\n\n7900XTX - full N31 (96 CU) - 355W - 270%",
      "There would be little to no performance gain over 6700XT/6800XT. RDNA3 was a failure tbh, pretty clear the rumors of the hardware bugs limiting the clocks was true. I think initially AMD was hoping to have all of these clocked over 3GHz out of the box and it just wasn't happening.",
      "Yeah the naming scheme is a mess",
      ">I think the 4090 is actually the best sold model despite the price tag.\n\nThat's because it's the most powerful graphics card that money can buy. If you're building a gaming PC with unlimited money, that's the card you want.\n\nFor people who aren't rich, the 4000 series cards are all overpriced.",
      "This was my thoughts exactly. There just doesn't seem like there will be a place for anything from the Navi3X lineup",
      "Radeon Pro W7800 is already announced with 70 CUs so I expect that's what the 7800XT will also have. (W7900 is an exact match for 7900XTX aside from double VRAM and reduced clocks/TDP)",
      "Makes no difference if they come or not. All that matters now is pricing. Anything north of 700 and it's already DOA. The second hand market is still going strong for a reason.\n\nPeople just aren't spending that much on a GPU anymore.",
      "It doesn't seem like they're worried about more releases or cooking up anything interesting. They're comfortable occupying this silly GPU lane of \"half the headlining features of an Nvida card for a 20% discount\" so what do they have to worry about. Innovating? Seriously competing? They just aren't that into the market. They want to be the cheapo knockoff that has never felt more like the cheapo knockoff.\n\nI really wish Intel would start fighting it out with a heavyweight card. Yeah it's against the odds, but if you ask me if I think there's any hope in hell AMD picks up the pace in desktop GPUs... no, I don't see it happening.",
      "If they release them now they must price RDNA2 super low, which in turn makes the old cards very good value and few will buy the new ones.\n\nThey just made too many last gen cards. This is also why the RTX4000 series is selling extremely poorly, I think the 4090 is actually the best sold model despite the price tag.",
      "Uh no.\n\nOne could argue that the 7900XT is the 7800XT but that would be quite an impressive improvement, 25% more VRAM and like 30% faster than a 6800XT and very capable of 4K gaming which the 6800XT wasn't due to low memory bandwidth.\n\nThe 7900XT is more like.. Between a 800 and 900 class card. And it has a very impressive memory bus alongside the infinity cache. I can kinda understand why they went with this naming scheme as the 7900XT is too fast for an 800 class card. Both are 900 class cards by specs.\n\nA 16GB 256-bit 7800XT is basically guaranteed and it will likely trade blows with the 6950XT in Raster and slightly faster in RT. Possibly better 4K performance depending on memory clocks.\n\nI wish the 7800XT would come with 20GB VRAM and the 7700XT with 16GB but it's likely going to be 16GB and 12GB this generation.\n\nExpect RDNA4 to be a bigger leap than RDNA3 was. Meanwhile for Nvidia the opposite is expected, Blackwell likely won't be that much faster than Ada, they have kinda hit the limit of a monolithic die with the 4090. But with Blackwell I expect a significant VRAM boost, with 24GB on the RTX5080 gaming flagship and 32GB on the 5090.",
      "In my PC.",
      "After they make AI accelerators actually do something they might.",
      "Yeah I can't wait to see what's coming in June, hopefully either a 7800/7700 series gpu.",
      "The channel is fubar with old stock. This gets forgotten. The 7800 isn't around because there is no place for it ... yet.",
      "I hope there will be a 7800XTX that has 20GB of vram. A man can wish.",
      "N32 should definitely not be too slow for 7700 XT, as it should at least beat the RX 6800 non-XT, though.",
      "It isn't, I don't get why people keep pushing this narrative. In terms of cost per frame it's like the second worst card in the lineup, it beats the 4080 but not by a huge margin. \n\nThe 4090 only looks good because it's the only card that had a big performance and cost per frame uplift compared to its predecessor, the problem is that the 3090 made zero sense compared to the 3080 at their respective MSRPs."
    ]
  },
  {
    "brand": "amd",
    "generation": "7000",
    "tier": "mid",
    "matched_keywords": [
      "7700"
    ],
    "title": "XFX unveils its Radeon RX 7800 XT and RX 7700 XT MERC and QICK series - VideoCardz.com",
    "selftext": "",
    "comments": [
      "Almost ( at-least on amazon ) the only brands thats always exact price as MSRP",
      "Sapphire gonna take a ton of sales, they‚Äôre apparently the only one making a medium-sized card",
      "On the other hand, their coolers have a good reputation for a reason.",
      "Right? It's ridiculous how long these XFX cards are...",
      "[The duality of man](https://i.imgur.com/BOs8DII.png)",
      "And one of if not the first to lower prices from msrp if they arent selling. Xfx and asrock are the best at that hands down.",
      "I‚Äôll take a bigger card for bigger cooling",
      "And still nothing that fits in an ITX case with a true dual slot design.",
      "Are you arguing for the sake of arguing? If your case can fit a bigger GPU that has a lot of cooling potential compared to other AIBS for the same price then why not?",
      "XFX has been doing extremely long bois for a long time, you should be looking for other manufacturers if the card being short is of concern.",
      "true, xfx 6800xt is now 480$ on amazon, really amazes me how they mange to make any money!",
      "But, theyre quiet.",
      "Good cooling absolutely matters. Plenty of people live in warmer climates where on hot days their PCs will start to thermal throttle.",
      "I know it isn't cool to post earnest, positive comments but that 7800 XT QICK looks like exactly what I want.   I don't mind massive cards, I have a ton of space in the case.  I'd actually rather a larger, quieter card than a small one that runs hot.  It'll take waiting for the reviews to know how loud it is though.\n\nThe price is higher than I've ever paid for a card but compared to the market it is fair for the performance.  It's AMD so it'll have the Linux support I need.  This one really seems to check all the boxes for me.",
      "Please be under 320mm long.\nEven the 4090 was only 295mm. The Sapphire Nitro 7800xt is 320mm, but their Pulse is only 265mm.",
      "Assuming the same power usage (I.e. not thermal throttling) the same watts of heat will be dissipated with any design. The difference is that an overbuilt cooler can run its fans slower and quieter. \n\nIt will also have more headroom for overclocking before thermal throttling - yes, putting more heat in your case - if that‚Äôs your sort of thing.",
      "That‚Äôs not what I‚Äôm saying, I‚Äôm saying that because of how hot it is in some parts of the world, a GPU running at 60c vs 80c, can mean the difference between thermal throttling or not. As someone who used to own a graphics card that did just that, you can bet your ass the next one I bought featured a big fuck-off cooler.",
      "yeah, for true dual slot cards this gen the best bet would currently seem to be the 4070 (or the 3080/3080 Ti FE if you don't mind the extra heat). either the 4070 FE or the few AIB models of that card that are truly dual slot. everyone seems to be obsessed with giant coolers nowadays, even if those GPUs don't need coolers that gigantic.",
      "Cooling-wise, this would likely be better than the dual-fan Pulse, but not the pricier Nitro+.",
      "Better buy a PlayStation if you think these are overpriced"
    ]
  },
  {
    "brand": "amd",
    "generation": "7000",
    "tier": "mid",
    "matched_keywords": [
      "7700"
    ],
    "title": "[HUB] Best Value AMD 8-Core CPU in 2023... Ryzen 7 5800X3D or Ryzen 7 7700?",
    "selftext": "",
    "comments": [
      "I paid $450 for my 5800X3D (a while ago, obviously) and it‚Äôs worth every damn penny",
      "Yes, when you‚Äôre testing CPUs, you want to eliminate the GPU as the bottleneck to see how the CPUs compare.  Even with the 4090, there are games where the 7700 can‚Äôt maintain 60 fps at 1080p because the game is horribly threaded (Hogwarts with RT).  Jedi: Survivor with RT would be another title where you will see big differences and sub 60 fps performance.  HUB only tested without RT, but the real cpu hit comes when you enable RT.\n\nThe idea with these tests is to show relative rather than absolute performance as future games tend to be more demanding - and there are always outliers. \n\nIn general, if you know you‚Äôre only targeting a specific fps, you can look at reviews like this and determine if the CPU generally provides that performance in games you care about.  Remember that the performance today is likely to be better than what you‚Äôll see in 2-3 years let‚Äôs alone 5+.",
      "Love my 7700x",
      "Both of those games were console ports that are widely unoptimized",
      "X3d is huge huge huge to sims and VR (doubly so, VR in sims.) too.",
      "Oh look, it's that guy again, who has no idea what CPU testing actually is and how it should be done.",
      "This. The average buyer at this range is far better off buying a 5700x or 13400f at best and investing elsewhere.",
      "All these CPU reviews tend to be very FOMO videos, *with a 4090. Most people likely wouldn't see a difference between a 5600 and a 7800x3d. At least now it's actually testing at Ultra 1440 and 4k, rather than; 4090, 7800x3d, 720p/1080p low which literally no one will ever use outside of CSGO or Valorant. But then most CPU reviews don't even test CSGO or Valorant so...",
      "As always, it depends on the games you play. I‚Äôm in a Discord channel for both TLOU and Jedi: Survivor, including a DLSS frame generation mod for each game. Several users with a 5800x3D cannot run Jedi: Survivor on a 4090 at a locked 60 fps (120 with FG) with RT because the CPU can‚Äôt handle it.  RT is integral to the lighting in that game - in fact it cannot be disabled on the consoles (or at least it couldn‚Äôt at release).\n\nTLOU scales much better up to 16 threads, but it really likes fast memory, and a user with a 5800x3D reported micro stutter which I could not reproduce at much higher fps on a 7800x3D with fast DDR5 memory. Locking the game to 60 or 120 with FG eliminates the microstutter, as it appears to be a memory bottleneck. \n\nHogwarts: Legacy is sub 60 fps on the 7700 with RT.  The 7800x3D is a massive 47% faster at 1080p - and you‚Äôll see it at higher resolutions because you‚Äôll still be CPU limited. \n\nNote that these tests don‚Äôt account for DLSS.  Cyberpunk shows major gains with RT on the 7800x3D which disappear at 1440p given the GPU demands of RT.  However, at DLSS quality at 1440p, you‚Äôll be cpu limited again.  On a 4090 and 7800x3D, I see cpu limits at 3440x1440 DLSS quality at around 120 fps.\n\nThis testing does not account for frame generation - which really does miracles for CPU-limited games.  In such scenarios, you see true doubling in FPS and much smoother frametimes as you‚Äôre eliminating the CPU bottleneck. A locked 120 FPS with FG in Jedi Survivor at Epic settings with RT looks and feels great - and even on a 7800x3D or 13900KS, there are areas where you are limited to 70 fps without FG (Koboh town).",
      "As the other person said, they use these setups to make gaming artificially CPU bound in the assumption that the performance in CPU bound gaming situations would scale/compare the same way. They do what they do for a reason (and it's not FOMO), but it's also true that a lot of actual gaming setups don't benefit that much from high end CPUs (outside probably of the ones where they're being mated to equally high end or even higher GPUs)....",
      "The only real difference you'd notice would be going from the 5800x3d to the 7800x3d and that would still be barely noticeable in 1440 or 4k which us where most if not all gamers using a 4070 or higher are gaming.",
      "I want CPU reviews to tell me the comparative performance levels between CPUs so I can make an informed decision. This requires seeking out CPU bottlenecking.",
      "No, the 5900x is a good CPU. Turn off the FPS counter, and enjoy! :)",
      "Why?",
      "not true if you upscale to 4k, even with DLSS performance you render at 1080p",
      "Comments like this makes me miss the times before gamers learned the word \"bottleneck\".",
      "Also, HUB does GPU scaling videos as well, but because that would be a massive increase in workload, they get their own separate videos.",
      "If reddit doesn't price gouge for API's, someone needs to make a bot that explains CPU testing methodology.",
      "Gaming, AI/Deep learning and a bit of hobbyist dev stuff.",
      "Yeah I paid roughly the same a while back and couldn't be happier, it's a fucking beast of a CPU. With a 5800X3D and EVGA3090ti I think I'm good for a while."
    ]
  },
  {
    "brand": "amd",
    "generation": "7000",
    "tier": "mid",
    "matched_keywords": [
      "7700"
    ],
    "title": "ASRock now has the cheapest Radeon RX 7900/7800/7700 models, 7900GRE drops to $529 - VideoCardz.com",
    "selftext": "",
    "comments": [
      "We're finally approaching what should have been the launch prices for these things. Hooray!",
      "Wow, i wish we had those prices in Norway.  \nHere the 7700XT launched at ~$600 and still costs $550.  \n7800XT: $700 and $660....  \nGrrrr....   \nThats including 25% VAT, but still....",
      "Great for u guys. In my 3rd world country the 7700xt still costs like 500usd.",
      "GRE is an underrated card. It makes a GOAT linux setup for 4K gaming, and can even moonlight doing LLMs",
      "Honestly cant see a reson to buy a 7800xt near $500 anymore. The 7700xt and 7800xt need significant price drops.",
      "Hey! Don't call NZ a 3rd world country like that!",
      "So highest AMD model (7900) now costs basically the same as some of the cheapest nVidia ones (4070)?\n\nAlso, what is the point of 7800XT now, that GRE is at the same price or even cheaper?",
      "Except they aren't selling. There are lots of every model in storage and the retailers are just doing ok.  \nNo wonder, when they charge that much and never really lower the prices.   \nUsed marked is wild too because of it. 6700Xt for $400 for instance. That was 400-450 new.",
      "Why is that? I have a phantom 6800 xt and it's been flawless for years now.",
      "Same. Zero issues and I'd 100% buy another.",
      "ASRock goated",
      "Does Challenger have much worse thermals than Phantom Gaming?  50% more fan ... 50% lower temp?",
      "Thats because of higher buying power. If people pay stupid prices, stores will continue to sell with stupid prices.\n\n\nIf \"no one\" bought them at that price point, they'd be forced to lower the price. Alas....",
      "Everytime I look at an Asrock product they're always the cheapest option but they don't actually look cheap, everytime I look at motherboards there's an Asrock PG something with RGB and fully Heatsinked VRMs and built-in IO shield at the same price as a basic MSI pro series motherboard or a Gigabyte DS3H board.\n\n\nMy motherboard is a B450 Pro4 which I bought for $70 years ago, it was the same price as B450s with 2 RAM slots, except it had 4 slots and heatsink on the VRMs.",
      "Bro it's a giant shire.",
      "If you're in US this is illegal just fyi\n\nIirc you can drop a dime on them to the FTC. Apparently per Gamer's Nexus the FTC is going after warranty/RMA stuff pretty hard atm too.\n\nOften times these companies are all sauce no taters, tho. You send them an email with the statute and threaten to send a letter to the FTC and they'll fold. \n\nTheir entire game is to try to give you an initial \"no\" at first because most people just give up after a single no. If you give them any amount of hell they usually just cave.",
      "Philippines has same pricing, then 7800 XT at $600",
      "It‚Äôs much bigger if you overclock the 7900gre",
      "Smae here in the Philippines. Prices barely go down. And used prices are essentially what should have been the proper new prices. FFS",
      "I sent letters of complaint to the California DAs office and attorney general. Filled out all sorts of forms. \n\nEveryone said \"we can't represent you but we'll talk to the vendor\" and the vendor replied to them saying I voided the warranty cause of the sticker. \n\nThe two CA agencies I complained to basically said \"we can't do anything. You gotta sue em\". \n\nWhich I knew about the FTC complaint form all those years ago.\n\nFuck AsRock."
    ]
  },
  {
    "brand": "amd",
    "generation": "7000",
    "tier": "mid",
    "matched_keywords": [
      "7700"
    ],
    "title": "AMD Ryzen 7900/7700/7600 CPU pricing and specifications have been confirmed - VideoCardz.com",
    "selftext": "",
    "comments": [
      "So instead of a 7600X for $249 we can now buy a 7600 for $229\n\nby Grabthar's hammer.. what a savings",
      "MB prices are still thrash, unfortunately.",
      "On promo it will be $199 with cooler",
      "Pretty spot on price with extra cooler in the box. With cheaper ddr5 incoming, thw only hurdle is AM5 motherboard prices.\n\nHope A620 come sooner than later. AM5 Deskmini with 7900 on eco mode will be interesting combo.",
      "AMD has burnt a lot of my good grace they‚Äôve garnered throughout these past few years, but this isn‚Äôt that bad.",
      "Yeah but that's when the 5600 is EOL, not at launch.",
      "Incoming US prices.\n\nYou should mention EU prices for laughs and giggles :)",
      "AMD is delusional if they think that 7600 is \"competing\" with 13600. Maybe they have on par gaming performance, but 13600 is WAY ahead in productivity.\n\nAMD is slipping... again... ZEN4 are good CPUs, but the platform cost is outrageous. Radeon 7900XT is DOA and now this....\n\nI fear that we are looking at another ten years of Intel (and Nvidia) \"dark age\"....",
      "I never claimed it was 2.5x faster. I just said it was faster. Everyone values their money differently.",
      "Considering they still have some competition in January, it _could_ be worse by then though, AMD's non-x vs. Intel's non-k:\n\nR5 7600 6c/12t ($229) vs. i5 13500 6+8c/20t ($2..?) \n\nAMD has pretty much given up on competing in multicore performance for the lower segments, they're not even trying to unfortunately",
      "It's still the cost of the motherboards that kills 7000 series for me. The cheapest one I can get in the UK is still ¬£175, for a bottom tier B650 M ATX motherboard that is still way too much.\n\nThere is just no semblance of a budget tier with 7000 series, and the high end gets beaten by Intel.",
      "Where ? \n\nShow me a decent ATX board under $200",
      "That's a two year old cpu though. It's fine but the 7600 is quite a bit faster. That might not appeal to you but I think it will appeal to others. It's good to have choices.",
      "B650 wifi going for $169 already. The total system price is getting much better.",
      "*\"Just visit you local MicroCenter\"*",
      "No b550 was $80 at launch. Y‚Äôall have a short memory. When b550 came out people were complaining and saying we should all just buy a b450. Who needs pcie 4.0 anyway. Lol",
      "They are improving",
      "The problem is MB prices but CPUs.",
      "It won't even be 10months before there are cheaper AM5 boards, DDR5, and X3D Zen4 CPUs in plentiful supply.",
      "Yeah Yeah ... keep downvoting.... It seems that you miss bulldozer days. By not accepting that AMD entered a slippery downfall, you are not helping them realize it and do something about it. AMD fans should first among others start yelling at AMD to fix the problems, fix the pricing etc."
    ]
  },
  {
    "brand": "amd",
    "generation": "7000",
    "tier": "mid",
    "matched_keywords": [
      "7700"
    ],
    "title": "‚ÄúThe 7700‚Äù",
    "selftext": "‚ÄúThe 7700‚Äù Build\n\nThere was a build post last weekend for an all 7800 build (CPU and GPU). I‚Äôd like to now share the lesser cousin of it‚Ä¶ the 7700.\n\nRyzen 7 7700\nGigabyte RX 7700 XT\n\nIt‚Äôs my first build in 15+ years. I couldn‚Äôt find a 7800 XT which I originally wanted but jumped on a good price (a bit below MSRP when converted from CDN$ to US$) for the 7700 XT.  I‚Äôm okay with the change as it kept me under my budget and I got both of the 7700 parts for a great price. Bonus points for this build as I was also born in ‚Äò77.",
    "comments": [
      "The stock amd cooler is so damn nice looking.",
      "Your cables are going into your fan lol",
      "7700¬∞ C",
      "It does look like it but they just rest against the fan guards. No danger of the fan hitting them.",
      "i guess you're now obligated to get any potential X770 motherboard that drops for next gen AM5 lol",
      "I was thinking the same.",
      "Looks fine. Under the GPU or through the same hole as the mobo cables would have less cable exposure.",
      "Temps seem good so far but I‚Äôm keeping an eye on things. The case is a Torrent so airflow is great. Thought I‚Äôd try the stock cooler for a bit but a new air cooler is my first upgrade if needed.",
      "Hello cousin :)",
      "But not in hwinfo ü§£",
      "I can see it now :  Ryzen 9 8950X3DXT",
      "nice triple 77 setup! ;)\n\nits giving me ideas, but its not going to be cheap :(",
      "Looks very clean, nice",
      "Hello. Thanks for the inspiration on the name.",
      "Fractal Torrent Compact\n\nIt came with the two front large fans. I added the bottom and rear ones.",
      "Oh it‚Äôs not the best performance cooler. But damn she sure is a beaut.",
      "How's the temp? I know the 7700 is pretty cool on temp, I always would consider an aftermarket cooler.",
      "what case is that?",
      "I did the opposite, was going to get 7800x3d and 7800xt, outa stock so got the 7900xt.  Like the look other than cable management.. but case doesn't seem too good for cable management.\n\nI still need to cable manage mine better,  but psu shroud on bottom makes it so easy to look good.",
      "Nice! I built a 7900 build a few weeks ago."
    ]
  },
  {
    "brand": "amd",
    "generation": "7000",
    "tier": "mid",
    "matched_keywords": [
      "7700"
    ],
    "title": "AMD Ryzen 7 7700 non-X CPU allegedly features 8 cores and 65W TDP - VideoCardz.com",
    "selftext": "",
    "comments": [
      "Ryzen 5 and Ryzen 7 SKUs are really bad placed in terms of absolute pricing and relative performance if compared to the competion (yes there is finally competition back again!) and this especially true in Europe where the 7600X starts from 369.99 euros.\n\nI truly hope that the 7700 will get a 320 dollars MSRP and that they perhaps drop the MSRP of the 7600X to 250 dollars with a 7600 at 200 dollars otherwise the Ryzen 7000 series is not a choice in the low end for European costumers.",
      "no one cares, the 13600k is too good for the price. None X cpus do nothing to alleviate this, amd needs to pivot to a new stepping ASAP.",
      "Yep\n\n7600X-200USD\n\n7700X-300USD\n\n7900X-420USD\n\nAnd next time with next gen increase core count across board.\n\nR5-8core\n\nR7-12core\n\nR9-16core\n\nNo1 gives a shit about AMDs 6core at 300USD when intel selling 14core at same price lol.\n\nAMD is pretty much intel from before ryzen launch.They keep same core count across board since first ryzen.\n\n1600X\n\n2600X\n\n3600X\n\n5600X\n\n7600X\n\nAll 6cores.\n\nMeantime intel went from I5 4core/4threads to 14core/20threads.Its insane",
      "OP this is a rumor",
      ">and this especially true in Europe where the 7600X starts from 369.99 euros.\n\nThe problem in Europe is the strong dollar, 13600K sells for 385‚Ç¨ on Mindfactory atm, everything will get more expensive and I would really skip on any upgrade for the time being, unless one really needs it. AMD's actual issue is the price of motherboards, they can even release a $250 7600 non X, it won't sell if you have to match it with a circa $200 B650 mobo.",
      "Gasp. Who could have seen that coming. /s",
      "The 13600K is much better in MT  than the 7600X but otherwise AMD is competitive and the 7950X stays faster than the 13900K in MT. Don't know what you are talking about.",
      "Now only need cheap motherboard.",
      "Plot twist: they will sell 7700X as 7700; 7700X will cease to exist and X3D series will arrive for each X variant with X variant prices..",
      "automod is on sick leave.",
      "ok but those haven't been released yet",
      "good bot!",
      "Competition has been back for a few years",
      "Than the auto mod needs to be activated.",
      "I think it was a poor choice of words. Probably meant \"now that 13th gen is out and performing better than 7000 series at a lower price\"... Since the \"competition\" came from AMD having good performance to begin with. Also I would figure that the prices of mobos and ddr5 will start to drop as people start to adopt the newer platforms. They were probably trying to capitalize a bit on the initial time between launches. At least I hope that was the plan. AMD and board makers will have to make adjustments or Ryzen 7000 series will not sell anymore with the exception of the few things that it dominates at.",
      "This is exactly what I think. \nTBH seeing Meteor Lake early rumours 8 core Ryzen 5s for the next gen may not be enough to compete with a resurrecting Intel.\nWe needed competition so hard and now I am happy!",
      "Are we talking about price or performance? \n\nAM5 is expensive, yes but socket 1700 is also dead now. Will  i buy a new socket 1700 system now? No.\n\nKings of performance? Even in your mentioned HWUnboxed video the 7600 beats the 13600k in the games average ([https://www.youtube.com/watch?v=I7-2ArdYvfA](https://www.youtube.com/watch?v=I7-2ArdYvfA)) and the 7950 beats the 13900K in Multitasking on average. I give the 13600K that it shreds the 7600X in Multithreading but it is a gaming CPU and who is interested in MT buyus the bigger models anyway.",
      "I changed it.",
      "The rumors are they will double core counts next gen, with Zen4c cores as small cores, and Zen5 cores as big cores. so 6+6,8+8,12+12 and 16+16. \n\nWe shall see if the rumors are correct.",
      "The problem is that those CPUs don't match up in performance.\n\nThe 13600k rivals the 7700x, not the lowly 7600x.\n\nIt's the 13400 and 13500 that will be the performance competitors to the 7600x, and they will be $230-$250"
    ]
  },
  {
    "brand": "amd",
    "generation": "7000",
    "tier": "mid",
    "matched_keywords": [
      "7700"
    ],
    "title": "Alleged AMD Ryzen 7900/7700/7600 non-X specs and prices emerge, launching in Q1 2023 - VideoCardz.com",
    "selftext": "",
    "comments": [
      "So wait.. The 7700 non-X is going to cost more than a 13600k, that's already better than a 7700x? Okiedokie.",
      "Prices are still not very competitive with intel.\n\n300usd 13600KF is faster than 7700X and it will be even more faster than 329usd 7700.\n\nshould be like this:\n\n7900X-470usd\n\n7900-400usd\n\n7700x-300usd\n\n7700-270usd\n\n7600x-230usd\n\n7600-200usd",
      "Cannot wait for the European 300 euros price tag for the 7600.... AMD needs to do better than that in Europe considering that the euro dollar change is not below 1 like when Zen 4 launched but it is now almost at 1.04",
      "Alright, give us some A620.",
      "Something something AM5 upgrade path.",
      ">13600K cost less and requires a much cheaper platform. 7600X and 7700X are DOA at the price points AMD set.\n\nThis is not universally true, it depends on your region. Where I live now the 7600X is around 60‚Ç¨ cheaper than the 13600K, which in turn is just 40‚Ç¨ cheaper than the 7700X, and similar motherboards are similarly priced. There are cheaper intel boards only because they have some barebones boards, which AMD doesn't (not yet at least), and those don't interest me. I also don't want DDR4 boards since that just gimps the 13600K, I would be much better off going for a 5800X3D  at that point.\n\nSo the total cost for a new 13600K ends up slightly higher than the 7600X (for the specific boards I would choose in each case), and slightly lower than the 7700X. So it really depends",
      "Prices would have been arguable if AMD outperformed intel this round, that's why people dealt with it with 5000 series. But now that Intel has caught up with two great generations of CPU AMD is gonna be dead in the water if they don't try to compete.",
      ">300usd 13600KF is faster than 7700X \n\nReally depends on the workload",
      "My prediction.....the 5800x3d will be the best selling cpu of Jan 2023.",
      ">Really depends on the workload\n\n13600K is faster in almost every workload except gaming where the difference is minimal. 13600K cost less and requires a much cheaper platform. 7600X and 7700X are DOA at the price points AMD set. The only option for AMD is to lower prices 7600X --> 200$ // 7700X 300$ in order to be competitive again. If they don't lower prices, then ZERO SALES aka CPUs will be collecting dust on the shelves for an eternity.",
      "Deepcool has an AK620 and an AG620 if you‚Äôre interested /s",
      "Gaming is what a large part of the audience cares about, but aside from that there are also Adobe, (some) compiling, and other workloads that benefit from faster cores more than a higher number of cores.\n\nBut yes, the pricing is not competitive, though the non-X might be (especially if all you care about is gaming). The prices shown in the article would **not** be **good** value compared to competition either though. Overall platform costs are starting to get comparable though, unless you accept the performance cost of going with DDR4 in which case Intel still holds the edge.",
      "Q1 2023 is barely two months away, dude.",
      "AMDiscount is best feature that AMD has.",
      "Motherboard prices are still shit in EU so it's hard to justify buying AM5 at this moment.",
      "The biggest concern with these prices is it implies the x variants stay where they are which means the 3d will be priced crazy and likely not have a value story",
      "This gen is going to hurt AMDs position as ‚Äúthe value brand‚Äù, Intel was smart to add DDR4 support, because people look at the benchmarks with DDR5, but the prices with DDR4.\n\nIt‚Äôs a stupid trick, but most people won‚Äôt feel the difference anyway.",
      "None of this matters as it does nothing to motherboard and DDR5 prices",
      "As long as they don't lower the prices for their chipsets, none of this will matter. The whole platform is too expensive for what it delivers.",
      "With 1x ram slot, atleast you still have dual channel with ddr5"
    ]
  },
  {
    "brand": "amd",
    "generation": "7000",
    "tier": "mid",
    "matched_keywords": [
      "7700"
    ],
    "title": "HUB - AMD Radeon RX 7700 XT Review, It's The 7900 XT All Over Again!",
    "selftext": "",
    "comments": [
      "Steve back from the grave!\n\nYep, the writing was on the wall once they announced specs and pricing. The 7700XT fulfilled its role in upselling the 7800XT, I guess. Once it goes down in price it would be a great option, like the 7900XT or the 6700XT before it, which also got roasted in reviews based on MSRP.",
      "Best ad for the 6800 I've seen. You save some money while winning some vram and getting the same/better performance. Somehow it doesn't even use more power than the 7700xt",
      "RX 6800 are rare though and is about to be discontinued, even if it is more appealing product due to extra vram buffer, AMD knows this exactly hence they will discontinue it soon.",
      "It‚Äôs almost like they don‚Äôt want you to buy this specific GPU",
      "The pricing obviously makes sense if you are AMD. You either buy the overpriced 7700 XT or you pay extra and buy the more expensive 7800 XT. It's a win-win either way for AMD. And let's not pretend there aren't people who would buy these on launch day at the absurd MSRPs, so those sales are still coming in. Then once the initial demand drops, the price is dropped, which lets in a new wave of sales. No one even cares about day 1 reviews at this point in the age of YouTube and influencers. It's only the reviewers who still think their day 1 negative reviews have any real-world impact on sales and how large corporations operate.",
      "Pretty much.\n\nN32's price floor is 450 because any lower would put downward pressure on N22, which in turn puts pressure on N33. They also have *some* 6800's left, but not many since yields are good, and they don't need 3 N21 SKU's within a small range. The 4060 TI is trash, and Intel doesn't have a card up here, so it's basically AMD competing with itself.\n\nN32's price ceiling is 500 because any higher and the 4070 starts making more sense.\n\nHowever, despite such a small price range, yields aren't 100% perfect; they need two SKU's.\n\nThey're prioritizing 7800 XT's since that card has higher margins (both cards cost nearly the same to make). Thus, the only 7700 XT's are defective 7800 XT's, and yields are excellent, so there aren't many.\n\nThe market for a GPU also decreases exponentially as you go up in price. So if the 7700 XT was 400 dollars (price where it'd make sense on-paper), it would sell out considerably faster than the 7800 XT while still putting *some* downward pressure on the rest of the stack. Thus, its price can be made higher than that equillibrium point.\n\nNow, making a lineup of products is like protecting a goal: you need coverage. AMD has N22 for the 300-400 dollar market, and the 4060 TI 8GB hasn't really dropped enough in price to merit a large response (it's specs are also hilariously imbalanced). If the 4060 TI's drops to 330 and 380, respectively, and N22 is gone, AMD will need a response. When that happens, they'll likely balance N32 production between the SKU's more, which lets a price gap open up between them (maybe 400 for 7700 XT, 480 for 7800 XT)\n\nWe may see a late cycle 7700 with 48CU's, made from the collected dies too defective to be 7700 XT's (kind of like the 5600x3D). That and discounts will also counter Nvidia if they drop the 4060 16GB drop to 350 (if we get to that point, they're just gonna ol yeller the 8GB model lol). It'll also counter Intel, although jury's out on how good Battlemage will be.\n\nI understand that reviews are more based on objective value, but with context, it makes sense why the 7700 XT is 450. That being said, the 7900 XT and 7900 XTX had a proportionately identical price gap to these two cards, but they made a lot more of the cheaper one. My theory there is that it was up in the air on if the renamed 4080 12GB would get a price cut and they had too much N21 left.",
      "Yeah the 7700xt is almost certainly the price it is to sell off RDNA 2 stock.",
      "Pretty clear your best deals are at least 3-6 months after launch, if you don‚Äôt manage to get a flagship product for msrp at launch",
      "Prices will go down, but by then the $100 Starfield Premium promo will be long gone.  \n\n\nPossibly this promo will be replaced by something else, who knows (AMD is not always consistency with these promos), but whichever game it happens to be, it won't be as hyped as Starfield. Besides, it is unlikely to be a $100 Premium Edition - basic $60 editions of games is what we tend to get as bundles.  \n\n\nAnyway, I am just pointing this out. If someone is waiting for the 7700XT to go down by $50, but then they plan to buy Starfield, might as well pay $450 for the 7700XT (or get the 7800XT if they can find one).",
      ">You either buy the overpriced 7700 XT or you pay extra and buy the more expensive 7800 XT. It's a win-win either way for AMD.\n\nOr you decide to save some money and go for the 6800XT because it's such good value, and help AMD clear old stock they want gone. It's a win-win-win for AMD.",
      "$8 us for a small popcorn, $10 for a medium, $12 for a large that comes with a free refill. Meanwhile the small is 1/3 the size of the large.  Even kids look at their parents crazy if they try to order a small popcorn.",
      "you go to the movies they offer you popcorn and a soda for 10 bucks then they have the offer of two for one at 20 bucks then they have the big one at 35 bucks.\n\nUsually you end up with the 20 or 35 deal as its prefered as more value than the other options.\n\nHumans cant handle their own brains when they buy things",
      "Performance is good - way better than the 6700xt (which launched at $479) and way better than anything Nvidia has in the price range. According to Techpowerup its overclocking potential is great and they had it running at >3ghz, giving 4070/6800xt performance.    \nAgreed on the 12gb.   \n  \nMy guess is AMD *know* this will be a great seller at 400 (it will have zero competition at that price), but for now:  \nA. they are using it to upsell the 7800xt,  \nB. Its very competitive vs Nvidia even at $450 so isn't completely DOA.  \nC. The 6700xt is still selling well at $330, and launching this at $400 would force that to drop to $300 and have a cascading affect on lower priced cards like the 7600.",
      "My 6800 is here for the long haul. It‚Äôll let me skip these terrible priced/performance cards for a little while longer",
      "Yeah its a bit funny when people act like they're getting one over on AMD by buying the last gen product when it's what clearance pricing is *designed* to do lol.",
      "Or downselling to the 6800 haha",
      "Just bought this haha",
      "Looks like a placeholder price to me. \"Buy this if you're dumb enough to give us money, otherwise we're happy enough selling 7800 XTs and the rest of last gen's stock.\"",
      "I think most people look at a GPU that draws \\~240 watts, shrug and says \"fine\". Power efficiency on the 4060Ti is without a doubt very impressive, but I think for most people (though there are exceptions, for sure) sub-160 watts power draw is not a must have feature.  \n\n\nWhen a GPU pulls over 300 watts, I am sure most \"mid-range\" buyers would scratch their heads (I certainly would), but below that - and surely below 250 watts - power consumption enters acceptable territory, and going further than that starts to have diminishing returns.",
      "7700 XT has fewer CUs than the 6800"
    ]
  },
  {
    "brand": "amd",
    "generation": "7000",
    "tier": "mid",
    "matched_keywords": [
      "7700"
    ],
    "title": "Buy RX 7700 XT now or wait",
    "selftext": "I built a new PC weeks ago (B650/Ryzen 9600X/32GB). I have been using Ryzen 9600X's IG until I decide, in regard of graphics card-wise. I have my eyes on the RX 7700 XT, I have a 1440p monitor, so I want to be able to play 1440p decently, not necessarily the latest titles or the highest settings... here in my (west European) country it goes for 450‚Ç¨ the lower you can find it, I don't know if I should wait or is a good moment now before the tariffs potentially drive prices higher... ¬øwhat do you suggest me to do?\n\nThanks y'all",
    "comments": [
      "That's not an incredible price but I assume that is a new gpu. I have the 6700xt and can say that the 7700xt is 100% worth it",
      "The maximum impacts of tariffs will be ahead, assuming they stay in place which is a big assumption. Trump could reverse them or the courts could knock them down. But tariffs are lagging in that they are charged to the importer at the time goods enter the country. It's several weeks before an item that has been charged a tariff from Vietnam, for example will hit the shelves.",
      "7700xt is not the best value imo right now. Just because 7800xt is so close in price.",
      "Yeah, that's the price of a brand new unit in Amazon",
      "That's seems to be the case in the US, but I'm my region it's almost 100‚Ç¨ more...",
      "Where are their prices comparable in the US lol. Even Micro Center lists the 7800 XT as at least $100 to $200 more.",
      "May i ask which country? Coz i just saw in germany that 7800xt is ‚Ç¨488",
      "Not in the US, in the question it mentioned euros. And as i said in the other comment, in germany, its ‚Ç¨38 difference",
      "Spain. This is the best I could find\n\nps://www.coolmod.com/gigabyte-radeon-rx-7800-xt-gaming-oc-16gb-gddr6/",
      "Huh really? just bought a 7700xt because cheapest 7800xt were all ‚Ç¨500+ that ai could find.",
      "Meant to reply to OP sorry",
      "A little less on amazon\nhttps://www.amazon.es/dp/B0CGRMJF6C?tag=pcp02-21&linkCode=ogi&th=1&psc=1",
      "7800 xt\n\n[powercolor ‚Ç¨482.13](https://de.pcpartpicker.com/product/KBqNnQ/powercolor-rx7800xt-16g-p-radeon-rx-7800-xt-16-gb-video-card-rx7800xt-16g-p)\n\n[xfx ‚Ç¨486.99](https://de.pcpartpicker.com/product/7WWJ7P/xfx-speedster-swft-210-core-radeon-rx-7800-xt-16-gb-video-card-rx-78tswftfp)\n\n[asus ‚Ç¨489.90](https://de.pcpartpicker.com/product/tXNYcf/asus-dual-oc-radeon-rx-7800-xt-16-gb-video-card-90yv0jj1-m0aa00)"
    ]
  },
  {
    "brand": "amd",
    "generation": "7000",
    "tier": "mid",
    "matched_keywords": [
      "7700"
    ],
    "title": "RX 7700 XT vs. RX 6750 XT for game development and 3d work",
    "selftext": "Hey all.\n\nI'm planning to upgrade from my current laptop (i5-2430M, Radeon HD 6470M, 8gb DDR3-1333) to something faster. Way faster.\n\nI'm torn between these two cards (RX 7700 XT and RX 6750 XT). I have heard something about the RX 7000 series being better for productivity than the RX 6000 series, I don't know if this is true.\n\nThe price difference between these two cards is 63 euro.\n\nI'm planning to use it for Unreal Engine, Unity, Godot and Blender. I don't know much about these programs since I have never used them before.\n\nDoes anyone know how much more the RX 7700 XT is better than the RX 6750 XT for game development and 3d work?",
    "comments": [
      "Between those two I'd say the 7700 XT is the better choice, but you can't go wrong with either. AMD cards will do fine in all of those but Nvidia is just superior in blender thanks to CUDA.  I've done unity dev work on a 6800 XT and it was perfectly fine. \n\nIn all honesty, except for blender your CPU matters more than your GPU with these tasks- Unity will use all the threads you can throw at it when compiling and if choosing the 6750 XT over the 7700XT gives you the budget to go for an 8-core chip instead of a 6-core chip, do it.\n\nThat being said i agree with the other commenter, a used RTX 3080 10GB is the best value in that price range right now. Those that work are well within the valley of the bathtub curve and you'll probably get at least 5 years out of a used one. (Just maybe avoid the zotac trinity model of the 3080 those are cheaper for a reason)",
      "Excuse my ignorance but aren‚Äôt nvidia cards better at these tasks?",
      "used 3080",
      "I think you will be better with Nvidea hardware as they might be better at handling productivity...",
      "All this info is very helpful, thank you!\n\nBoth options feature a Ryzen 7 7700.",
      "Probably, yes. Sadly, the best nVIDIA card that fits in my budget (430 euro) is the RTX 3060 12gb.\n\nIsn't the RX 7700 XT better than the RX 7700 XT for all my use cases (except Blender ofcourse)?",
      "They are said to be, yes.",
      "I don't really know about buying used. It's quite risky.",
      "Might be, yes.\n\nAlthough the best nVIDIA card that fits in my budget (430 euro) is the RTX 3060 12gb, what costs 290 euro here.",
      "Well productivity wise nvidia seems like your best bet. Although I don‚Äôt do any of these tasks and only game, so I went with AMD. But for productivity go for nvidia. Where are you from? 430 for a 3060 seems a bit steep imo.",
      "Less than you'd think. the biggest risk is the lack of warranty",
      "Bro Actually sometimes 7900xtx performs similar to 4060ti in Productivity so it will be better to research if AMD support those applications. It's all on your applications.",
      "I'm from the Netherlands btw.\n\nI mean't my max. Budget for a gpu is 430. The 3060 12gb costs 289 at a minimum here.",
      "I'm afraid when the buyer protection of the platform is over, That then for some (random reason) the gpu dies, and I've then lost a lot of money.",
      "Yeah, I'm researching. But it's quite difficult to find a benchmark or anything for Unreal, Unity and Godot.\n\nAtleast I found out that the RX 7700 XT is quite close to the RTX 3060 on blender.\n\nNVIDIA GeForce RTX 3060\tMedian score:2147.17\tNumber of benchmarks:411 AMD Radeon RX 7700 XT\tMedian score:2128.77\tNumber of benchmarks:59\n\nSource: [opendata.blender.org](https://opendata.blender.org/)",
      "Thats an idea. Yes, you may need the VRAM. You may want more modern features though. Just a thought.",
      "That doesn't really happen with GPUs a ton UNLESS they've been reflowed. If they've lasted 2 years, they'll probably last another 5 if cared for properly.",
      "I have had a used 3080 for 2 years with no issues. I always buy used cards. No risk and way more performance per dollar.",
      "If possible try the things physically at a Centre near you. Whichever satisfies you buy it... I think this suggestion is sounds good but I don't know if the seller can let you check these things.... Gamers love AMD but Nvidea shifted focus to AI...."
    ]
  },
  {
    "brand": "amd",
    "generation": "7000",
    "tier": "mid",
    "matched_keywords": [
      "7700"
    ],
    "title": "7700 XT and 7800 XT officially added to Starfield Premium bundle eligible products",
    "selftext": "",
    "comments": [
      "There was some speculation whether or not the 7700/7800 XT are gonna be eligible for the Starfield premium bundle and AMD has just revised their terms and conditions here: https://www.amdrewards.com/terms",
      "It's funny how I posted that an hour ago, but it got flagged immediately.",
      "If I buy a GPU from amazon does it have to have the message \"Get starfield w/ select AMD radeon GPUs\" or will any GPU on this list be eligible even if it doesn't have that message? right now there are a lot of AMD cards for sale on amazon without that message so I want to make sure.",
      "It wasn't ready lol",
      "I just ordered an asrock 7800xt from newegg and the starfield game bundle was included",
      "That was never promised, just speculation on our part.\n\nIt's probably coming in a couple weeks, but again, that is just speculation.",
      "You'll need that message.\n\nOn Amazon only eligible items Sold & Shipped by Amazon count. Not third party sellers at all.\n\nThat will trigger the email from Amazon with the code in it.\n\nAmazon is the problem here as they don't make this 100% clear, but the terms are all laid out on the promotion page.\n\nhttps://www.amazon.com/promotion/psp/ACHKWB63YKPQJ?ref=psp_external&redirectAsin=B0BR6JWP1Q&redirectMerchantId=ATVPDKIKX0DER&ref=cxcw_psp_ACHKWB63YKPQJ&source=dp_cxcw",
      "It might take a bit of time for the retailers to update their listings after AMD updates the terms. You're most likely safe buying now since if you don't get it, customer support will assist as they've probably been briefed on it. Otherwise, you can threaten to return and repurchase if they don't give you the code.\n\nIf you wanna be completely safe, though, wait about a day or two or get one from a retailer who updated the listing on time.\n\nI have no idea why AMD revises the terms at the last minute like this, as the 7600 launch had similar confusion.",
      "can someone confirm is the pulse 7900xtx on amazon comes with starfield premium, I tried asking their customer service and they kept going in circles\n\nhttps://www.amazon.com/gp/product/B0BR6HZZ6Z/ref=ox_sc_act_title_1?smid=ATVPDKIKX0DER&psc=1",
      "I ordered the XFC Merc 7800xt last night on Amazon and it doesn't say the Starfield is included, it sold out around 2am last night so i was glad i grabbed it but idk if i have to wait for it to get here and then try to get the code?",
      "Bought the one on Amazon yesterday. Really hoping to retroactively receive a code from XFX/Amazon",
      "Ordered the same card as well, hoping we‚Äôll get sent a code at some point. I‚Äôm gonna keep checking the page for the card and if they add a message about Starfield being included, I‚Äôm gonna contact Amazon support and see if they‚Äôll help.",
      "Having trouble as well. I can't connect my Steam login to amdrewards, which is apparently how you actually redeem it.",
      "It's eligible for the standard edition",
      "I didn't get one for a cpu and both amd and amazon didn't want to help so I returned it and bought from a different retailer",
      "Yup, refer to the promotion page. I got a r5 7600 and 6950xt but only got the promo on the 6700 as the 6950xt was a 3rd party seller. Amazon isn't clear, mentioned that it would be eligible but the promo page clarified that it wasnt",
      "Do you if it is the premium version of Starfield? Can't seem to find where it states that",
      "AMD breaks down what products get what from the bundle. \n\nhttps://www.amd.com/en/gaming/featured-games/starfield.html",
      "Perfect. Thanks!",
      "My guess is retailers don't get sent the codes until AMD amends the terms, and for some asinine reason that doesn't happen until the cards are always on shelves.\n\nHonestly, the way GPU launches are done is such a confusing clusterfuck that it's ridiculous. There's been several times of furiously googling and F5'ing trying to find the listing.\n\nMy favorite was the 4060 TI, which didn't even have a listing on Amazon or Newegg US until THE NEXT DAY lmao. Like stop gaslighting me, I can read a calendar!\n\nThe fact that we need journalists to make \"Where to Buy X\" articles every launch is so fucking ridiculous. Why would these companies make it *harder* for people to give them money????? Imagine if Target or Walmart moved the electronics department to a random location in the store before Black Friday, or if a vending machine put the card reader in a different spot every single time. Wouldn't that be moronic?\n\nImo, all product listings should be up at 9am Eastern, 24 hours before release when the review embargo typically lifts, but marked as \"In stock tomorrow.\" That gives them time to fix nonsense like this.\n\nOh, and AMD.com or Nvidia.com should have links to the ACTUAL listings and/or the AIB's product page for the card. The current approach is basically \"Let me Google That For You,\" as it just links to a search of the retailers' site for the product name lmao. I know what bestbuy.com is, and I know how to type, so doing that for me is just pretentious.\n\nI shouldn't need to rely on third parties and furious googling of various articles to figure out which AIB cards are coming out, it should just be on one fucking page with the dimensions, clocks, and links.\n\n/rant"
    ]
  },
  {
    "brand": "amd",
    "generation": "7000",
    "tier": "mid",
    "matched_keywords": [
      "7700"
    ],
    "title": "AMD confirms Radeon RX 7800/7700 XT GPUs were to use 12VHPWR connector, but the idea was dropped - VideoCardz.com",
    "selftext": "",
    "comments": [
      "Good, it's a terrible connector and the blame keeps getting passed between manufacturer to user. Honestly in my opinion a connector that's too hard to plug in properly to avoid a fire is still a defect but Nvidia gets away with it because they keep calling it user error.",
      "it's shittily engineered, so thin wires in such a small space can't handle that amount of wattage, period, they were ignoring physics when \"designing\" that thing, it's why I never bought a nvidia 4000 series and just waiting out 5000...my 3080 still kicking lol",
      ">a connector that's too hard to plug in properly to avoid a fire is still a defect\n\nPersonally I blame the engineers for thinking that its a good idea to over tighten the end points of the connections.",
      "I hope they will never use it. It is electrically unsound design for amount of current it promises.",
      "good choice. better safe than sorry.",
      "Nonsense, its not the \"thin wires\" its the fact the sense pins should have been further recessed to stop the short and ideally a slightly better clamp lug.  \n\n\nIts a bit more susceptible to user error which is a failing in design but its no where near the level you make out and some minor adjustments can make it a \"solid\" design.",
      "LOL AMD used common sense where Nvidia saw none.",
      "> Is there anything wrong with the connector? Nope.\n\nA connector where Psu companies have to paint in order to let the user know that it is entirely in is not a suitable connector.\n\nStop smoking, because your brain is a fried as many 12vh connectors.",
      "They‚Äôve updated the plug so it won‚Äôt pull power if it‚Äôs not seated correctly.",
      "Nah, we have seen folks test the connector pulling well over 1kw without issue. This is just a narrative redditors made up. \n\nThe root issue causing burnt connectors was addressed in a revision that reduces the chance of the cable pulling current when not fully inserted.",
      "Nvidia designed the original 12-pin connector that first appeared on RTX 30 series Founders Editions that would eventually evolve into 12VHPWR. Intel took Nvidia's 12-pin design and added the four sense pins to the connector for communication between the graphics card and the power supply for how much power needs to be supplied. Nvidia and Intel were the ones who actually designed the power connector. AMD's only role in the creation of 12VHPWR was that they are a member of PCI-SIG which nearly every technology company is, including Apple, Asus, Gigabyte, MSI, HP, IBM. PCI-SIG has hundreds of members.",
      "consortium was planning to release it, while nvidia rushed and made their own version before the standard officially was out.",
      "I think it should've been designed with a 90-degree mounting option (or maybe that's 180-degrees, lol!), to lay on the back of GPU backplate, due to the strict wire bending guidelines the connector has. The connector housing could be designed in a way to fully capture the terminals so that they don't move and cause localized hotspotting and excess receptical-terminal strain.\n\nConnector should not be difficult to fully insert either.\n\nAll of these things should have been considered before allowing high current on effectively the same amount of 12V/GND wire pairs as 2x8-pins (6x 12V/GND pairs).",
      "the v2 of it seems good.",
      "Wasn't that just for the 3090 Ti? I thought all Ada GPUs didn't use the same connector and do use the one from the actual spec?",
      "I like the idea of 12VHPWR where a GPU can be powered with one cable and the sense pins allow the GPU to be aware of what power consumption can be handled by the power supply. The problem is that Nvidia for some bizarre reason tried to make the connector as small as a standard single 8-pin PCIe power connector. Trying to push 600W through such a tiny space leaves such little room for user error. The connector could have easily been slightly larger and chunkier, similar to 8-pins, with a definitive click when it is fully inserted and there would not have been as many problems with it as there have been.",
      "Yeah it's a sound idea to have a new connector, but when I had my 4070 I hated that connector with a passion. It felt like I had to break the damn card to unplug it and it never felt like it was \"in\" like you get with a normal 8 pin. Terrible experience.",
      "if nothing is wrong, why did it get a redesign and manufacturers try to make it better themselves?",
      "More people need to realize how cheap the power supply manufactures got with this. PCIe 8 pins carry a max of 150w so each one of them is designed to be physically capable of carrying 300w to ensure that they'll always be able to hit that 150w spec regardless of manufacturer tolerances. Maybe that's overengineered, but HPWR is designed to carry 600w so the cable is specced to carry... exactly 600w. \n\nAny hardware engineer worth a damn could have predicted that'd be a complete disaster that'd result in actual fires, and what do you know!",
      "Honestly what they should have done is built the connector as a split style design, much like the 20+4 atx or 4+4 12v cpu..\n\nNewer lower tier cards could use half of it with more than sufficient power delivery and the high tier cards use the full connector. And imo, concentrate it into more of a sqaurish block rather tna a long thin connector. Specially for including the sensing pins. Honestly the design of it looks like it was clearly engineered to meet napkin level math and application and takes ZERO consideration into real world use scenarios. The rule of thumb should always be, whatever the requirements are even after adding for some variables, double the reliability and strength capacity."
    ]
  },
  {
    "brand": "amd",
    "generation": "7000",
    "tier": "mid",
    "matched_keywords": [
      "7700"
    ],
    "title": "RX 7700 XT Matches RTX 4070, RX 6800 Performance In Leaked Time Spy Score",
    "selftext": "",
    "comments": [
      "Why do these posts exist? AMD's own numbers show the 7700XT being 12% faster than the 4060Ti which makes it around 20% slower than a 4070, this thing isn't matching a 4070.",
      "So AMD intentionally presented lower scores? For what purpose?",
      "I believe AMD cards do better in timespy relative to Nvidia.\n\nThe 6800 is behind a 4070 in games",
      "Timespy is not a good way to compare competing architectures.",
      "Reading comments in here really shows that half this sub straight doesn't know how to read.\n\nArguing with comments that agree with you because you misread them, mistaking the 6800 for the 6800xt, confusing prices, arguing that AMDs own numbers aren't what they say they are, etc...\n\nThis sub goes full-blown dogshit at every GPU release.",
      "If they lied they would make it look better not worse.",
      "Ppl are just stupid, AMD claims the 7800xt are 2% better than 4070 overall, and I saw ppl saying that it could be 10% better than Rx 6800xt",
      "Are we talking raster + ray trace + productivity? :) or leaving out the parts that humiliate you yet again amd?\n#\nBtw before the downvotes (which I will get anyway), I am also an amd user. I just don't agree with clickbait titles. Omfg loook loook we finaly have equal performance. No you fucking not. You just cherrypick what you like and comfortably leave out what you don't. Sit down.",
      "Yes",
      "hopium",
      ">Did you not see the 7900 xtx beat the 4080 in every game for 200$ less\n\n\n\n\nYes i did. But You were talking about the 7900XT the whole time not the XTX, did your brain fart or something.",
      "Dude do you even realize the sheer insanity of your comment?\n\n\n\n\n>We‚Äôll amd has gotten stuff wrong before.\n\nYes they've gotten it wrong before but always make their cards look better not worse than they are.\n\n\n\n\n\n>So maybe it will match. And maybe rx 7800 xt will match 4070 ti. Which makes sense since it is the one below the 7900 xt which matches 4080.\n\nNone of this is even close to reality, the 7900XT matches the 4070Ti, it's much slower than a 4080. 7800XT will only match a normal 4070.",
      "my guy, the 4080 wins most of the time in the video.\n\n\n\nThe only time a 7900XT matches a 4080 is in games that favor AMD hardware, otherwise the 4080 is much faster. You can go and watch any reputable reviewer like Gamers Nexus or Hardware Unboxed instead of this and you'll see that the 4080 performs like a 7900XTX while the 7900XT only competes with the 4070Ti.\n\n\n\nYou're high bro.",
      "Upvoted",
      "I was giving context to what you were saying. Regardless, a 4070 is only 10% faster than a 6800 on Tom's Hierarchy. So if the 7700 XT has 90% of the performance for 3/4 the cost it'll do fine. 6800 only went to 430 less than 2 weeks ago because these cards were coming out, not because the 4060 TI's are putting up such a good fight lmao.",
      "Am not gonna even bother.",
      "hmmm I'm hoping for $399 but if it matches a $600 4070 then $430-450 wouldn't be to bad.  If it falls below a 4070 because a 6800 is below a 4070 and they still charge $450 then AMD will never learn....especially when you can get a 6800 is like $430 now with starfield",
      "I doubt it, even if it matches in Time Spy, in games I don't think it comes even near",
      "I would only expect a 54CU RDNA3 GPU to beat a 60CU RDNA2 GPU by 5% max.  There's definitely a lot less performance per clock gained than they claimed.",
      "Performance wise right now a 12 to 16GB difference isn't really going to make a difference. I don't know of a game yet that needs more than 12, though they are probably coming this console generation."
    ]
  },
  {
    "brand": "amd",
    "generation": "7000",
    "tier": "mid",
    "matched_keywords": [
      "7700"
    ],
    "title": "7700/7800 - Definitely not a paper launch",
    "selftext": "I've seen people already calling this a paper launch today.\n\nI checked my local MicroCenter's inventory and they have 52x 7800 XT and 38x 7700 XT of various models! There's no way of knowing with Amazon, Newegg, etc how many they had in stock initially but it appears these cards are selling fast at least online.  Amazon has scalpers selling the 7800 XT Nitro+ for $599.99 and it's still moving.  Every hour another one disappears now down to 1 left.  When it comes to launch day never underestimate the desperation of your fellow gamer.\n\nAlso at Amazon the XFX Speedster MERC319, PowerColor Red Devil, and Sapphire Pulse 7800 XT are all still in stock.  Newegg still has the MERC319, PowerColor Red Devil Limited Edition, and all three of the Asrock 7800 models in stock.\n\nNobody but the absolute youngest should be at all surprised that the one particular model they lusted after is already out of stock.  That happens every time.  Set up email notifications and learn to live with it.",
    "comments": [
      "Imagine taking everything mlid says at face value",
      "as of right now all stock on newegg for 7800xt is sold out",
      "We already know that they have a year worth stockpile of 7700/7800. They'll send more cards around the world depending on the continents asking for more.\n\nsource: https://youtu.be/IPSB_BKd9Dg?t=977\n\n*NB: If you watch the video you'll also know who created the rumor that AMD refused DLSS on AMD sponsored games... :p*\n\nedit: typo",
      "Ah yes, paper launch because the first half day it sold out. Yep. Nothing to see here everyone. What are considered launch windows are never more than a handful of hours. Nope.\n\nThis sub and its posters. Absolutely hilarious.\n\nHow about this. If in 2 weeks we find out that cards basically remained sold out since day 1 then it's a paper launch. Because you apparently don't know what the definition of a paper launch is.",
      "It's pretty well defined.\n\nA paper launch is when a company \"releases\" a product, but it is not available for a couple of weeks. That's a true paper launch. \n- There's an addendum where extremely limited quantities are included in paper launch definition. That's an effective paper launch because quantities are so limited, it's effectively nothing.\n\nHigh demand making products go OOS in a short time doesn't qualify. There weren't limited options either.",
      "so glad I put my order in this morning and didnt wait.",
      "there is plenty of cards available from amd. just have to wait a bit and they will come back. amd already has enough aib for the rest of the year\n\nmost of the cards on newegg were 2 day shipping so they definitely had them",
      "I don't know where to put this, but just as a small tangent, it's hilarious that the first shop that has the 7800 XT listed has the cheapest brand (Gigabyte) here in the Philippines is selling it at $756 while the cheapest 4070 is at $659. The main selling point of the 7800 XT is that it's much cheaper than the 4070, around $100 cheaper. I dunno what the shop owner is smoking, even the 7700 XT is at $616.",
      "Congrats mate. Enjoy your GPU",
      "The same scalpers that were on Amazon are on Newegg too.  PlatinumMicro.  They are still selling some models of 7800 XT but at $30 markups.",
      "Moore's Law is Dead should be banned on all respectable forums.\n\nMoore's Law is Dead's bull$@!# doesn't matter.",
      "Can't speak for other countries, but in Slovakia/Czech Republic it was definitely a paper launch, I haven't seen a single one available in the big stores. Everything is just for preorder.",
      "Most people just bought 4070 at a slightly cheaper price. Not even a comparison when they are practically the same A$900.",
      "In Italy they aren't even up for preorders, they are not listed on any online shop",
      "Going OOS in 30 min or longer is quite generous. When the 7900xtx launched it was off the shelf in 5 seconds on every website.",
      "It's priced as 7700xt.",
      "I was really surprised to see Red devil, gigabyte and few other 7800xt models already sold out at my local microcenter. I didn‚Äôt see sapphire but hellhound and asrock were the only ones in stock",
      "I think there is a hurry to buy these cards while the Starfield promo lasts (3 weeks left).",
      "Just need to have some patience. Online ordering was a complete mess of scalping and price gouging over the past 24 hours, but now it's just a matter of catching restocks at the right time and backordering. I was able to grab a 1-day estimated backorder for a Sapphire Nitro+ 7800 XT on Newegg for MSRP about an hour ago, but now it's showing as sold out again.",
      "It's a paper launch in Europe, that's for sure. Sites are estimating to have stock in at the end of the month. Thanks for that, AMD."
    ]
  },
  {
    "brand": "amd",
    "generation": "7000",
    "tier": "mid",
    "matched_keywords": [
      "7700"
    ],
    "title": "AMD Ryzen 7 7700 65 W Ryzen 7000 Review: Able Core i9-12900K and Core i5-13600K challenger that is US$70 less than Ryzen 7 7700X",
    "selftext": "",
    "comments": [
      "Long live price wars.",
      "Now do motherboards",
      "intel has cheap platform cost(mobo ddr4) you guys will mention long term support from amd but you forget they only updated the x370 only after we all bitched at amd with their quotes and even then it took months with 0 communication that they would be updating bios' because they hoped you would cave and buy a new motherboard for the 5800x3d",
      "X370 only got BIOS updates after Alder Lake came out. Your thinking of B450/X470.",
      "Eh, a lower price part doesn't hurt either.",
      "If you wanna go cheap, go AM4, ddr4 and zen3d. It will outmatch any other ddr4 build you can put together.",
      "They wanted to drop Zen 3 support on B450/X470 even, that took some pushback. Some bullshit about not having enough space on BIOS. X370 was dead in the water. People seem to keep forgetting that when suggesting AM5 over AM4 or Intel 12/13th gen. You're at AMD's mercy, and first generation products are always dodgy (I will keep hammering about USB issues that still persist on AM4 especially if you're mixing and matching CPUs and Motherboard chipsets).",
      "More SKU doesn't help zen4 for better selling. The trash am5 motherboard start with (150$-200$) killing all zen4 cpu.",
      "Really? From what I saw the 7700X was a consistently high performer in gaming",
      "I only game so it doesn‚Äôt matter to me. I don‚Äôt use blender lol.",
      "No it doesn‚Äôt.",
      "Power (at least here in Europe) is very expensive. It very much depends how you use your computer.\n\nA lot of computers sit at idle (or very close to) a lot of the time.\n\nPersonally I WFH so my PC is on for probably close to 50 hours a week, mostly chrome/zoom and some IDEs, the CPU is rarely over 10% utilisation. However I game 1 night a week for about 3-4hours.\n\nA PC idling/low power at 15W for 46-47 hours a week will use far less than a pc idling at 30-40W. And the difference isn‚Äôt really made up by a few hours of gaming where say a 13900k vs 7950x where it seems under artificial loads (worst case) intel uses 50W more.\n\nThere are also use cases like home servers where a server will sit idle for most of the time apart from in the evening to do some transcoding for instance. These are on 24/7, idle consumption is a very high priority.\n\nThe commenter I replied to was claiming intel was a power hog (which under load it certainly uses a lot more) but overall it might give a lower energy bill.\n\nThis isn‚Äôt to say I advocate for intel over AMD, My current build is AM4 as the price was excellent, and I‚Äôm planning an AM5 build, but my homelab is all intel.\n\nAs always, it‚Äôs about really assessing what your requirements are.",
      "Lets wait and see what (promised?) cheaper AM5 boards + 7000x3d + slower but maybe by cache compensated cheap ddr5 will bring to the table.",
      "Based on numbers its probably not the best bang for the buck. I got one and I'm happy with it. I just wanted the Zen 4 8-core chip.   \n\n\nIts hard to find a bad product these days, just badly priced ones.",
      ">Some bullshit about not having enough space on BIOS.\n\nthat was hilarious to read, considering every manufacturer moved to 32mb BIOS eeprom after Zen2 launch, since the bios image was already getting big enough that some eyecandy was cut on older mobo bios updates",
      "it's also a much bigger power hog",
      "Raptor Lake refresh late this year will be the final cpu for LGA1700",
      "Linux gaming is really not limited these days -- everything I've tried to play in Proton or Lutris has worked great on both my laptop and desktop. Steam \"just works\" -- it's a dream.",
      "Please",
      "Whilst intel seems to use a lot of power when loaded, I‚Äôve seen the argument that at idle where a lot of pcs spend most of their time intel are much better.\n\nMy older i7 3770 / 4770 systems both idle at 15W from the wall (no dGPU), whereas it seems am4 systems typically idle at 30W+ (no dGPU). Can‚Äôt say I‚Äôve tested this with my am4 system as the older i7s were used for a homelab 24/7 so idle was important to me."
    ]
  },
  {
    "brand": "amd",
    "generation": "7000",
    "tier": "mid",
    "matched_keywords": [
      "7700"
    ],
    "title": "Any idea when the RX 7700 XT will be released?",
    "selftext": "I'm in the market for a new 1440p card, and am disenchanted with Nvidia at the moment. Does anyone have a guesstimate as to when we might see the 7700 XT?",
    "comments": [
      "Eh, both companies are greedy POS.  Chances are both AMD and Nvidia are going to overcharge for their mid-range cards as well.  I say screw them both.",
      "6700xt was released around 6 months after the initial RDNA 2 launch, so probably around June, give or take a month. 7700xt on a cut down Navi32 will probably be the same performance as a 6800xt, based on the leaks that got Navi31 100% right, so not exactly exciting unless prices are cheaper than discounted 6800XT prices.",
      "LOL sony is just as greedy",
      "I remember wanting amd to prosper so we get a competitive market but now that not happening they got big and become the same awful nvidia fuck this just get a ps5 chill and watch this market collapse",
      "Name one Shareholder based company that isn't greedy?",
      "Not everyone lives in the US, retailers here don't really react on price cuts for eg. The cheapest 6800 XT here I can see is $560 before tax and the cheapest 6700 XT is $330, that is a huge price difference and if by waiting for 4-5 months I can get a newer architecture with the current 6700 XT pricing and 6800Xt performance, that's a no brainer for me.\n\nPersonally I am also waiting to see how good the Nvidia's live video upscaler is, if it actually works well I will have to consider the 4060 ti/4070 too.",
      "> and am disenchanted with Nvidia at the moment.\n\nAnd you're not with AMD? AMD's been pulling the exact same stunts as nvidia, I don't see how you're not tired of AMD as well.",
      "Well said\n\nBoth vendor are contributing to the high prices, with the 7000 series essentially matching the 40 series for value\n\nAt least with Nvidia you do get the performance and feature set for your wad of cash",
      "We would if 6800xt wouldn't be selling here for 1000‚Ç¨ and 6900/50xt for 1300‚Ç¨",
      "Same sentiment I wanted to post. The cheapest 6800 XT is 680‚Ç¨, the cheapest 6800 is 570‚Ç¨ and 6750XT is 470‚Ç¨. \n\n6900XT and 6950XT don't seem to have gone down in price at all, cheapest at roundabout 1000‚Ç¨ or more.",
      "They just assume everyone is in the US, just saw a XFX 6950 XT going for $730 on Amazon US, must be nice living there right.\n\nSome states there even have no sales tax and the ones that do have low tax rates like 5-7-10%, here we have 18% tax on electronics and that's the medium tax slab, the highest VAT goes upto 24% if the good happens to be in the luxury list.",
      "Buy a last gen card, if you are staying at 1440p then a 3070/6700XT is already good enough.",
      "November for N31\n\nMarch for N32",
      "At 1440p it's about 30-32% slower.",
      "It is 25% slower. (or the 6800XT is 32% faster) https://www.techpowerup.com/review/amd-radeon-rx-6700-xt/29.html",
      "You‚Äôre making an assumption that the 7700xt is going to be a good value. It‚Äôs more likely going to be overpriced because they don‚Äôt want to cannabalize their own sales of the 6800xt.  See also, 7900xt that‚Äôs clearly what the 7800xt should have been but priced $250 higher because they can be produced at the same time.",
      "I'd say about May or so, we'll probably get the 7800 series cards real soon.",
      "In 2023.\n\nIt's rather hard to tell what the 7700 XT will be and how it will be priced. The top end RDNA 3 chip went to the 7900 XTX and XT. My guess is that the next chip will go to the 6800 XT and 6700 XT, but who knows. AMD might push Navi 33 up to 6700 XT.\n\nRelease dates for RDNA 2, [according to Wikipedia](https://en.wikipedia.org/wiki/Radeon_RX_6000_series):\n- RX 6800, 6800 XT (Navi 21) - 18 Nov, 2020\n- RX 6900 XT (Navi 21) - 8 Dec, 2020\n- RX 6700 XT (Navi 22) - 18 Mar, 2021\n- RX 6600 XT (Navi 23) - Aug 11, 2021\n\nSo at least last gen there was a difference of 4 months between Navi 21 and Navi 22 releases. Navi 23 was released 5 month after Navi 22, 9 months after Navi 21.\n\nOn the other hand the 6600M XT (mobile Navi 23) was announced on the 31st of May 2021, so about 6 months after Navi 21 was released, while the 7600M XT (mobile Navi 33) was announced at CES this year, less than a month after Navi 31 was released, although this doesn't mean much for shipping.\n\nAnyway, that's the info. The rest is speculation.",
      "For 1440p I think 6800xt Will be on par with the 7700xt. I doubt it will release that soon. AMD is dealing with a lot of problems atm. Prob mid year",
      "TBH, I rather pay a bit more for my GPU than living in that hell hole."
    ]
  },
  {
    "brand": "amd",
    "generation": "7000",
    "tier": "mid",
    "matched_keywords": [
      "7700"
    ],
    "title": "When do you think they'll announce the 7600 XT or the 7700 XT?",
    "selftext": "Since the 7900 series is releasing in December does that mean we're going to hear about it in January? Just wanna know your thoughts on this.",
    "comments": [
      "Navi 21 (6900 XT, 6800 XT, 6800) was announced in October 2020.\n  Navi 22 (6700 XT) was announced in March 2021.\n  Navi 23 (6600 XT) was announced in July 2021.\n\nWith Navi 31, AMD chose to release all variants of the chip as 7900. Because it's a smaller chip than Navi 21 (so probably better yields), AMD might not see a need to release a further cut down variant.\n\nSo I'm guessing that Navi 32 will be used for the 7800 XT. Then its cut down variant will either be a 7800 or 7700 XT. It would also depend on what NVIDIA does with the former 4080 12GB and how Navi 32 compares to it in performance.\n\nNavi 33 might be 6700 XT or 6600 XT, or both.\n\nFor release dates, I'd guess that AMD will tease Navi 32 at CES and provide more details later in Q1.\n\nMy feeling is that AMD has an incentive to have a shorter release cycle with this generation, both because it can beat NVIDIA in value and because Navi 33 will be a better use of the 6/7nm production lines than RDNA 2.\n\nEdit: Forgot to say that Navi 33 has been rumoured to be mobile first, and this makes some sense. There's some chance that we will see it announced at CES for mobile alongside next gen mobile CPUs.",
      "If they want to sell a lot of cards, they better release those cards before NVidia sells all their 3000 series stock.",
      "7800 series in February\n\n7700 series in April/May\n\n7600 series in July/August\n\nThese are my predictions.",
      ">Imo the interesting GPU worth waiting on is the 7800xt. If it can hit a $699 MSRP and outperform a 6900xt, in at least a few games, that's exciting.\n\nIdeally, we'll get a 72CU Navi 31 part for the 7800XT that will do more than outperform a 6900XT in a few games, for $700.\n\nJust matching or slightly beating a 6900XT for $700 would not be exciting, that'd be quite disappointing, given how close the $650 6800XT already was to a 6900XT two years ago.\n\nYour standards are way too low.",
      "There is no massive 6000 stock. They could stop producing them right now and go full 7000 series, it would be even wise since chiplets use less of 6nm wafers each.",
      "I swear the last two crypto-booms ruined the market indefinitely in terms of expectations.\n\nThere's nothing great about 6900 XT performance or better for anything more than 500$, considering that card should have been 699$ when looking at 6800 XT's performance.",
      "Once the 6000 stock gets liquidated",
      "It seems they are keeping the same prices as the original 6000 series, so the 7800 XT might be $649?\n\nI don't know what could be the MSRP for the rest of the lineup, since all cards released during 2021 had inflated launch prices already reflecting the crypto craze.",
      "Don't expect that. Navi 31 shows that they used 96 CUs to achieve 1.6x 6950XT.\n\nWith 32 CUs of Navi 33's 7600 XT (just 1/3 CUs of 7900 XTX), you're looking at something like 30-40% less performance than 6950XT, or roughly 6700-6800 level of performance.",
      "my guess   \nMarch  Radeon RX 7800/XT ‚Äì $699   \nRadeon RX 7700/XT ‚Äì $599  \nJuly Radeon RX 7600 ‚Äì $350  \nRadeon RX 7500 ‚Äì $250  \nPersonally not waiting &  not buying current gen from retailers, used Market will be a rude awakening for Nvidia  & AMD  \nbig Mining Operations  &  Oxygen deprived miners are Hedging against inflation with GPUs hahaha",
      "As soon as 6800/6900XT stock is gone and people arent buying all of the 7900XTX anymore",
      ">So I'm guessing that Navi 32 will be used for the 7800 XT. Then its cut down variant will either be a 7800 or 7700 XT. It would also depend on what NVIDIA does with the former 4080 12GB and how Navi 32 compares to it in performance.  \n>  \n>Navi 33 might be 6700 XT or 6600 XT, or both.\n\nThere's a big gap in specs from N32 down to N33, so I'm expecting AMD to possibly require three Navi 32 variants to fill out the stack.  \n\nAlso Navi 33 wont be the 7700XT.  It'll have to be 7600XT or below or else the performance improvement will look pitiful.",
      "Based on the benchmarks I have seen for the Ryzen 7000 integrated graphics you are going to get better performance from almost any dedicated GPU released in the last half decade, and even the weakest RDNA3 card (or RDNA2 for that matter) should crush it in gaming.\n\nThe integrated graphics may make Ryzen more appealing to businesses, but really should not be a factor for gaming.",
      "There's a big gap, but it's actually smaller than between Navi 21 (80 CUs) and Navi 22 (40 CUs). The lowest end Navi 21 had 60 CUs, 50% more than a full Navi 22. I think it's reasonable for AMD to release a 60 CU Navi 22 and a 48 CU one with a 192 bit RAM bus, and then the difference between 32 CU Navi 33 and the 48 CU SKU would be 50%, which won't be higher than the Navi 22 to 21 gap.\n\n> or else the performance improvement will look pitiful.\n\nYou mean like the 6500 XT over the 5500 XT? Hasn't stopped AMD before.\n\nIf a 60 CU chip is 7800 XT, then a 32 CU chip could be 7700 XT. That's very close in ratio when compared to the 72 CU 6800 XT and 40 CU 6700 XT. So I wouldn't rule it out.",
      ">There's a big gap, but it's actually smaller than between Navi 21 (80 CUs) and Navi 22 (40 CUs).\n\nAnd that's why AMD had three Navi 21 variants rather than just two! \n\nBut that's at the high end.  There tends to be far more granularity in the lower-mid range markets.\n\n>You mean like the 6500 XT over the 5500 XT? Hasn't stopped AMD before.\n\nThe 6500XT would never have been released in the desktop space if not for the wild cryptomining craze that drove GPU demand to infinity, which meant that desperation for GPU's increased prices of even lower end GPU's a huge amount.",
      "That would look badü§î the 7800xt only being 15% faster than the 6800xt",
      ">So the 7800XT will actcually be the 7700XT\n\nOr it could be the 6800 equivalent.  We dont know.  They can play with naming, as you already pointed out. \n\nIt also depends on what it actually is.  Is it a further cut down N31 part?  Or is it a N32 part?",
      "Yeah with higher clocks. I‚Äôm still expecting the 7800xt to beat the 6950xt and 3090ti in raster",
      "Nvidia will sell their entire stack regardless.\n\nThough imo they should be competing with the 3000 series, offering cards that are better for value, but they did that with the RX 480 and I guess the mid-range community didnt come out in support.\n\n\nFlagship Ethusiasts might be the ones keeping AMD up.",
      "It's not gonna be anything like that person is saying.  \n\nIt'll be around \\~6700XT in performance, for $300-350."
    ]
  },
  {
    "brand": "amd",
    "generation": "7000",
    "tier": "mid",
    "matched_keywords": [
      "7700xt"
    ],
    "title": "7700xt vs 9070xt",
    "selftext": "I've recently been decided on parts for my first computer and I've had a conundrum. I really like the $/performance of the 7700xt, specifically the Sapphire Nitro+. I was hoping someone here with more experience with GPUs could tell me if it's be better to get the 9070xt version of the nitro+ when that's available and risk scalping or to pick up a 7700xt now and maybe get it for much cheaper?",
    "comments": [
      "It would be better to wait for reviews first. If the cards are being scalped, wait until they aren't being scalped.",
      "9070xt will kill the 7700xt in value",
      "Unlike a lot of the other answers on here I'm not going to go by AMD's presention on how their GPUs perform nor the suggested MSRP because I alway wait for reviews from independent reviewer outlets and MSRP pricing means nothing because supply, demand and what the AIB partners are going to charge. Once these things come out it should be 100% obvious what's going to be a better value. As for definate performance regardless the RX 9070XT is going to better looking at it's specs.",
      "I like your answer. The original question was about which is a better value. We can't automatically assume the RX 9070XT will a better value until independent reviewers have results and we see actually sale's prices. These days MSRP means next to nothing. Just because the RX 9070XT on paper is a better GPU doesn't mean it's going to be a better value yet.",
      "There is no one with any experience out there because we all have to wait for reviews and real world prices.",
      "Any version of 9070XT for $600 will be way much better than 7700XT. Its actually on par if not bit better than 7900XT."
    ]
  },
  {
    "brand": "amd",
    "generation": "7000",
    "tier": "mid",
    "matched_keywords": [
      "7700"
    ],
    "title": "RX 7800 / 7700 XT Benchmark Leak: AMD doesn't need Starfield to Win[MLID]",
    "selftext": "",
    "comments": [
      "I have no doubt Nvidias spin doctors in their PR are gunning for any negative story about a competitor I think we should remember it was AMDs own bad statement which fed the media frenzy with the original starfield FSR rumor.",
      "His \"source\" leak",
      "none of their sources or them \"confirmed\" that it will have fsr3 but they were essentially speculating since the timing of the announcement lined up so perfectly",
      "No, he speculated that it might be.  He did not claim that such a thing had been leaked to him.",
      "AMD's initial statement - to the Wccftech request - read to me like standard PR speak: Answering without answering, boasting while being noncommittal, etc. There were enough other red flags to the article that I felt comfortable simply brushing it off. It's a shame that media outlets didn't notice those other red flags, but whatever the case, AMD's NEXT response - a \"No comment.\" to Gamers Nexus's follow-up - is what really struck me as being a major PR misstep... even if in retrospect I can understand why they they chose to not comment.\n\nBut the media frenzy was already well under way by the time they said anything, and the media frenzy likely would have continued despite anything they said, because AMD seems to just perpetually occupy this nigh second-class citizen status in the gaming space. Gamers writ large have just been so conditioned and are all too willing to write their efforts off and/or uncritically accept whatever criticism is made of them.\n\nLike, the Wccftech article REALLY should have raised some eyebrows. Even re-reading it again now, I'm struck by how clearly slanted the language is, how poorly-written it is, how scant the evidence is, and I'm noticing again how it often uses the tactic of speaking on behalf of its audience. Phrases like \"...this leads to one of the biggest questions that most gamers have right now and that's the DLSS support in some of the biggest recent releases...\" and \"...it gives gamers a very clear message that NVIDIA-sponsored titles are friendlier and open to competitors than AMD.\" should have instantly given any reader, and ESPECIALLY any journalist, pause. That is not the language of a neutral third party. That is obviously loaded language being put to a specific purpose.",
      "Wait for real benchmarks in less than a week and decide from there.",
      "Didn't MLID say that starfield was gonna be the first fs3 title",
      "You don't give up, lol",
      "No. [Here is the slide from his video.](https://ibb.co/n86GsMs)\n\nThis sub likes to post articles that editorialize for clickbait...and then take that shit as fact. This sub just did the same thing with that AMD \"efficiency/Ray tracing\" article from Wccftech. It never ends.\n\nIt's why I basically don't listen to what people here say and just watch/read the sources directly.\n\nAs far as the FSR3 statement he made...he was basically spot on. In addition to the slide above, he merely said that it would be awesome if they did release it with Starfield but nobody told him that it would.",
      "Nobody said AMD needs starfield to win?",
      "What benchmark leak is this guy talking about? The TimeSpy thing?",
      "OK i posted this another time,as apparently rule 10 is very strict. Here are the timestamps:\n\n0:00 Why AMD has Priced the 7700 XT so close to the 7800 XT  \n3:15 RX 7700 XT & 7800 XT Long Term Pricing Leak  \n5:32 RX 7800 XT & RX 7700 XT Benchmark Leak ‚Äì TWO 4070 Killers!  \n10:51 Nvidia‚Äôs Anti-Competitive Response to Underfunding Starfield   \n15:34 Navi 32 Supply Update ‚Äì Stock will keep flowing this holiday!",
      "Sure why not.\n\nGets some new goodies as well, encoder, less wattage etc",
      "Mlid himself on alt account",
      "Guy is wrong so often. Dlss will be driver level one of y favorites. He buries stuff well. And glosses over with slick videos. Just another fanboy with army of misinformed lemmings.",
      "I remember when he said Navi 33 (RX 7600) was going to be as fast as the 6900XT, and it wasn't too long ago he defended AMD blocking DLSS.",
      "It was like watching someone accelerating off a cliff and blowing out the window to make it go faster.",
      "Which *has* happened in the past. I believe HUB has shown some of his stuff to MLID prior to embargo lift.",
      "Then I'll get something else. I was having buyers remorse after seeing the internet call the 4060ti a poor value.\n\nIf the 7800xt blows, then I'll return that too and grab something else.",
      "You're conflating a lot of disparate things and drawing one unrelated conclusion from them. In short, you're doing bad data analysis, probably from a position of extreme ignorance.\n\n>Intel cards don't even work in Starfield,\n\nIntel cards are managing to boot the game, so they \"work,\" but they feature a lot of rendering bugs... which is hardly new to Intel cards. Their drivers and software suite have improved since launch, yes, that doesn't mean that Arc is suddenly not still a very experimental generation. Bugs are to be expected with Intel GPUs, growing pains are to be expected. you know that (or should know that) when you buy in.\n\n>and Nvidia cards are being underutilized\n\nIt stands to reason that AMD, who sponsored the title, would work with Bethesda to ensure the game has no speed bumps interacting with its hardware. All games hit different speed bumps with different hardware. That's what driver updates and game patches are for. In this case, AMD and Bethesda have simply \"pre-\"updated drivers and \"pre-\"patched the game to remove their specific speed bumps.\n\nThey didn't (or likely didn't, anyway) *create* any speed bumps for Nvidia hardware. AMD simply haven't helped Bethesda smooth the existing ones over. And Bethesda, because of the sponsorship, have simply bumped AMD speed bumps up to the top of the queue for fixing.\n\nSo it's not that Nvidia cards are being underutilized, but that 1) Bethesda may have deprioritized any Nvidia-specific fixes, and 2) Nvidia haven't had the chance to do its respective optimization passes. (And, according to MLID, the team within Nvidia responsible for driver development haven't received the budget to do so.)\n\n> let alone have XeSS, .... on top of not having DLSS.\n\nThe decision to implement a software feature - any software feature - is ultimately up to the developer (barring, of course, the possibility of contract stipulations).\n\nAdding XeSS and/or DLSS on the developer's side adds more work, even if the integration itself is relatively simple. QA, testing, etc. If there's one solution that works on all hardware, from a dev's standpoint, why wouldn't you want to use that? Simplifies the entire dev process.\n\nI'd even argue that it being so easy to mod in DLSS support is only MORE reason to just include FSR. You cover every single hardware solution in one go with an upscaling solution, you minimize the work you have to do, and the people who want DLSS can still use DLSS.\n\n>Meanwhile... the 7900XT 20GB beats the 4080,\n\n...which it has done on multiple occasions, just as the 4070 Ti has beaten the 7900 XTX on occasion. Heck, the 7900 XT can beat the 40***90*** in Call of Duty. Are you going to argue that AMD paid Infinity Ward to cripple Nvidia cards in CoD? Well, you might, but of course you'd be wrong."
    ]
  },
  {
    "brand": "amd",
    "generation": "7000",
    "tier": "mid",
    "matched_keywords": [
      "7700"
    ],
    "title": "RTX 4060 Ti 16gb vs RX 7700 XT",
    "selftext": "Would you guys recommend the rtx 4060 ti 16gb or the rx 7700 xt for a graphics card (upgrading from gtx 1660Ti) if they are even worth getting in 2025?\n\ncurrent main specs:\n\ngtx 1660ti\n\nRyzen 7 5700 processor\n\n32gb of ram\n\n1tb SSD",
    "comments": [
      "Which one is cheeper? Generally the 7800XT is close enough to the 4060ti 16gb making that the better choice. \n\nId probably pick the 7700xt but it depends on the price, also might be worth waiting 1-2 months for new mid tier GPUs to launch.",
      "It really comes down to the target resolution you play in as well as the types of games you play. If you're primarily playing esports games and want as many fps as possible, the 7700XT is probably the better choice. \n\nIf you're looking to play the latest and greatest, graphically intensive games it's impossible to match the value DLSS adds in regards to performance for such a slight quality loss and how prevelant it is. You can also use ray tracing on the 4060ti, which can make some series differences visually. Sure, FSR is available, but the visual quality isn't really close to DLSS, that may change with FSR 4, assuming it comes to the 7xxx GPUs and that's setting aside it's potential adoption rate. \n\nCurrently FSR 3 is the best offering AMD has, and while it's been available for a while now, it's not uncommon for games to still ship with FSR 2.xx still while DLSS is generally available in the majority of new or major releases. \n\nFrame generation comes with both benefits and negatives, while I have a 40xx series GPU I tend to opt not to use it regardless. Before that, I used to mod FSR frame generation into games to use with my 3070ti, mostly to see what the hype was about",
      "Bruh what are you saying?",
      "If you‚Äôre going AMD, I‚Äôd try and stretch it a little more to a RX 7800xt or 7900gre if possible.  If going NVidia I‚Äôd go 4070 if you can stretch also, if you can‚Äôt you can get some decent used deals on r/hardwareswap.",
      "Honestly wait till the 9k amd cards are announced in 2mo.the used market on 7k series will drop by a good 20% at least. Between saving up and the used market dropping prices. You should be in a better position to get what you need. I'd suggest you do overtime or a 2nd job, weekend job, get some experience, ask to be a supervisor, assistant manager or something. Don't ever be content to cruise along with shit pay, specialise or go up in title. Check your company for training and promotion internally. If not, look around for a new job. Feb is when hiring starts again.",
      "ripe kiss sleep obtainable ghost doll relieved rhythm sand nail\n\n *This post was mass deleted and anonymized with [Redact](https://redact.dev/home)*",
      "money is a tad issue, as a teen making barely over minimum wage in Canada, I was hoping for help picking one over the other",
      "I don't have one right now, never applied for one",
      "use your credit card",
      "you could buy them both , & after a period of experience sell one out"
    ]
  },
  {
    "brand": "amd",
    "generation": "7000",
    "tier": "mid",
    "matched_keywords": [
      "7700"
    ],
    "title": "AMD RX 7700 XT & RX 7800 XT GPU Specs, Price, & Release Date (& FSR3)",
    "selftext": "",
    "comments": [
      "Literally every comment in this sub leading up to this was \"it better be 500 dollars or it won't be good value!\"\n\nNow it's \"500 is way too expensive\". What the hell do people want.",
      "people want to dislike it, no matter what. Considering current prices of nvidia cards 500 was exactly the perfect spot to put it. 7700xt is neither here nor there at 449, but i suspect it will drop to 399 once the stock of 6700/6750's drops lower. \n\nSo both are poised to undercut both 4060ti 16gb and 4070 which is a good place to be. And with 6700/6750 being an easy choice when compared to 4060ti 8gb it kind of looks like midrange is where AMD is putting it's chips in.",
      "Anybody know when the review embargo lifts?",
      "as evidenced by the reply from Merdiso, apparently not.",
      "This entire fucking sub was \"it better be 499 or its a rip off!\" For the last month. Now that you got your wish, your just moving thr goalposts?",
      "6700xt comes with premium, so it‚Äôd be bizarre if the 7800 and 7700 xt did not.",
      "People are great at moving goalposts. Never fails.",
      "September 5th I think",
      "Can everyone stop bitching now? 500 dollar price point for a 7800xt",
      "It was 400 back then because GPU's aged like milk since progress was rapid. It's not like these companies just started to become greedy.\n\nIt was common for a PC bought in the late 90's to early 2000's to struggle just a couple of years later. So of course they couldn't sell thousand dollar cards, since they'd be beaten by cards half the price or less in 18 months or less.",
      "The 6800 XT launched at 649$ though. If you say it's not a big improvement to have the same performance after almost three years for 150$ less, I agree though.",
      "To gamers: \"Moore's Law is dead\"\n\nTo AI/business: \"Moore's Law is probably currently running at about 2 times\" - Jensen",
      "This entire sub was on the \"it better be 499\" train for thr last month. Now that it is, the goalposts have moved",
      "Nvidia fanboys are good at moving goalposts, because thats what their perfect master leatherjacket does as well. \n\n30 times the performance!!!",
      "7800XT is priced well IMO, but the 7700XT should be $399. No reason to buy that unless you really can‚Äôt find the last $50. It‚Äôs the 7900xtx and 7900xt all over again.",
      "No, it's 6800 xt at 6800 xt price. Why don't we get more performance/money per generation like it used to be?",
      "Thats the logic of people that want AMD to be cheap just to get NVIDIA card at a lower price",
      "Mostly to not be told to pay for 6800 XT performance 3 years after the 6800 XT released for the same pricing we can gee a 6800 XT now.",
      "[Guru3D](https://www.guru3d.com/news-story/amd-unveils-radeon-rx-7700-xt-and-7800-xt-gpus.html) has an article saying they can release reviews when the embargo lifts on September 6th. So release day. That sucks.",
      "Looks like this will be my next GPU assuming there's stock at launch and the performance is better than 6800xt. \n\nThough if 6800XTs drop to $400-$450 this fall I'll probably buy that instead."
    ]
  },
  {
    "brand": "amd",
    "generation": "7000",
    "tier": "mid",
    "matched_keywords": [
      "7700xt"
    ],
    "title": "Which should i get?? 4060 ti 8gb or rx 7700xt",
    "selftext": "",
    "comments": [
      "7700 XT, the 4060 Ti has terrible value.",
      "That depends if it's at current prices you are better off getting 9070, but between these cards you'll be getting way better performance plus more ram with 7700xt.",
      "If you're choosing between the two, 7700xt or maybe wait for the 9070(non xt). . ."
    ]
  },
  {
    "brand": "amd",
    "generation": "7000",
    "tier": "mid",
    "matched_keywords": [
      "7700"
    ],
    "title": "ACER Radeon RX 7700/7800 XT Predator & Nitro GPUs are now available in the US - VideoCardz.com",
    "selftext": "",
    "comments": [
      "Oh, Acer Nitro and Sapphire Nitro+ won't cause any confusion or issues.",
      "Only For The Low Price Of $520! \n\nAt this point just spend another $30 and get the 7900gre for $550",
      "Nitro is probably too generic to trademark by itself. I imagine that's why Sapphire went with \"Nitro+\". Acer probably had a lawyer or two look at this before releasing it.\n\nAlso it's a bit of a marketing blunder to release a product that immediately looks inferior to your competitor when placed on the same shelf. They've basically committed to charging less than the competition. Otherwise why would Joe Average Consumer pick the non-plus model?",
      "isnt this trademark issue?",
      "why are they pcie x8?",
      "Before I ever considered buying an Acer GPU I'd want to hear at least several accounts of how Acer handled GPU RMA and warranty service before I'd ever consider buying one.\n\nPersonally, every experience I've had with Acer's warranty services has been at or very near the bottom of the barrel, to the point I won't even touch any of their products again.",
      "Here I am, with two Acer monitors...",
      "Nah, I think it's too coincidental.",
      "Yup. \n\nI got 7800 XT last year. \n\nThe GRE is a solid 15% more in performance. \nIn a lot of cases even more. \n\nIt's what I would have gotten instead. \n\nOh well. \nNot selling to lose money and buy the GRE.",
      "Don't think so https://uspto.report/company/Sapphire-Technology-L-T-D",
      "I mean its not about Nitro trademark, but Nitro GPU.",
      "Acer monitors are probably one of the few things they don't do a bad or inadequate job at, but \"At least we didn't fuck these up!\" isn't a great look for a company.",
      "My first high refresh monitor back in 2017 was an acer. Really price competitive for the time, only real issue is the lack of a proper stand that seems to be where all manufacturers cheap out on, having height and swivel adjustment is so crucial for competitive games but an easy issue to solve with a vesa mount",
      "I had a decent experience with Acer's RMA during the pandemic when I bought a 4k Predator monitor that had an issue with the backlight. They sent a full replacement at no cost.",
      "wdym? 2x8 4.0?",
      "I had an Acer Nitro laptop (GTX 960M with 4 GB VRAM, 16GB RAM and Intel Core i7-6700HQ) before I stepped in to building my my own PC. Got it for 8 years without issues, used it for my study and thus traveled a lot with it. It only died because a screw came lose and damaged the GPU (oops).  \nThey're not that bad and it depends how people take care of their stuff of course. \n\nMy mother is also using an Acer laptop, without any issues. Although I can't say anything about their desktop products.",
      "Hey OP ‚Äî Your post has been removed for not complying with rule 12.\n\nLow effort, non-notable and spam posts, including shitposts and memes are not allowed on /r/AMD.\nIf you have a post you believe warrants an exception, please [message us via modmail](https://www.reddit.com/message/compose?to=%2Fr%2FAmd)\n\nPlease read the [rules](https://www.reddit.com/r/Amd/about/rules/) or message the mods for any further clarification.",
      "? After 2 months i don't even remember the topic.",
      "Not saying this will happen to you, but as a cautionary tale, here was my first encounter with Acer.\n\n1. It's 2007, got my first decently paying IT job, spent $670 on a really nice Acer 1920x1200 24\" P-MVA panel with excellent viewing angles, color reproduction, and a very decent response time for the panel type and time period.  \n2. After 1 year, the monitor starting randomly powering off, and then it started taking longer and longer to power on (probably bad caps).  \n3. RMA'd it to Acer (it had a 2 year warranty). 1 month later I got the monitor back and it worked for 6 months before it failed exactly the same way again. So I RMA'd it again.  \n4. Another month later, a brand new 1920x1080 23.5\" TN panel that was selling for $350 shows up with terrible viewing angles, awful color reproduction, and response times no better than the P-MVA panel I sent in. Contacted Acer and told them it was not what I paid for, what they sent me is unusable junk, and I either want the panel I bought repaired and returned to me, or I want a full refund. They responded that they had no replacements available, they were sorry, and that their customer service would be contacting me to work something out.\n\nI never heard from them, they stopped responding to my e-mails, and I got hung up on several times when I tried (politely, mind) talking to them on the phone. That was the first and last time I ever bought an Acer product.\n\nI've since dealt with Acer a few more times for clients, but those are different stories (and it only went marginally better).",
      "You can also argue that most people know Acer, but not Sapphire that well."
    ]
  },
  {
    "brand": "amd",
    "generation": "7000",
    "tier": "mid",
    "matched_keywords": [
      "7700"
    ],
    "title": "Sapphire Radeon RX 7700 XT Frostpunk 2 Edition GPU launches in July - VideoCardz.com",
    "selftext": "",
    "comments": [
      "Just glad to see Frostpunk get some love. The first game was extremely good, gave me literal chills.",
      "Just make a toxic already!!",
      "not worth it this gen",
      "Oh man, this gets me wishing for replaceable backplates with gaming themes. I mean I would not buy new GPU for every new game I like, but to get option to swap the backplate or just some kind of thematic addon \"plate\" would be great. Ofc it should not negatively influence cooling.",
      "bit late to make \"special\" versions of an old not very impressive card and since it is \"special\" it prolly won't be cheap either",
      "Yeah you're probably right, maybe with Navi5",
      "Depending on the actual pricing, for someone needing an upgrade or doing a mid range build and wanted to buy the game anyway this could be a solid options.",
      "looks like an early 2000s card.",
      "PowerColor made swappable backplates for their 7000 series Red Devil cards using magnets. You could probably copy that idea and 3D-print some backplates or just use some flat backplates with full sized printed stickers.",
      "It's an extra layer of insulation so it probably does change it a little bit, assuming there are any thermal pads connecting the backplate to the PCB in the first place.",
      "Nope! We did the testing. For example the Generative backplate is actually pretty open, so plenty of airflow ;)",
      "Who pays for these kinda of collabs? Is it the game studio or AMD?",
      "Late to the party but currently if you buy this on Newegg they're offering FOUR free game downloads with it , but unfortunately you lose some value because this version is like $40 more than the other 7700xt versions",
      "If anyone is still contemplating this card it currently comes with a free digital download for the new warhammer game",
      "It's at a pretty good price point now, around $120 cheaper than 7800 XT where in Amazon. But since the reviews all had it as bad value, even when it's now good value, current buyers will see the release review and pass them up. AMD really always shooting themselves in the foot.",
      "Ah those magnetic backplate addons sounds really interesting. Do you think they were negatively impacting the cooling?",
      "It's much better now than in release that it was only $50 cheaper. It's now $360 in Amazon while 7800 XT is at around $475",
      "Thank¬¥s for info!",
      "compare it to the price of 7700 XT obviously a 7800 XT is more expensive"
    ]
  },
  {
    "brand": "amd",
    "generation": "7000",
    "tier": "mid",
    "matched_keywords": [
      "7700"
    ],
    "title": "Which model of rx 7700 xt should I buy there are too many options to choose from",
    "selftext": "I'm new to building pc \n(Need help)",
    "comments": [
      "Doesn‚Äôt really matter, the differences are miniscule. Go for the best priced you can find."
    ]
  },
  {
    "brand": "amd",
    "generation": "7000",
    "tier": "mid",
    "matched_keywords": [
      "7700"
    ],
    "title": "Well, that‚Äôs one hell of an upgrade from an i7 7700. First time on the red team! :P",
    "selftext": "",
    "comments": [
      "I‚Äôm doing a similar upgrade. 7700k to 5950x. Can‚Äôt wait!",
      "I hope he is prepared to be dissapointed.",
      "I just went 2600k -> 5900x.\n\nTell me about it...",
      "You're a brave man holding that baby with one hand and a phone in the other.",
      "Such an insane difference! Now I can even play Warzone AND minimize it to search something up in my browser!",
      "Ngl, I was VERY nervous while taking that photo :v",
      "the issue is the game is set to high priority in task manager. i always set it to lowest when the game starts to keep windows from hanging.  \n\n\nalso im upgrading from a 6600K to a 5800X, im tottally stoked. hope i can get 5GHz all core like others.",
      "I'm going from a I7-3770k to a 5900x my poor gpu wont be bottle necked anymore.",
      "I went from 2500k to 3950x last year. Damn...",
      "Very probably not gonna happen. Don't be disappointed tho, 5GHz on AMD is more performance than 5GHz on Intel.",
      "Yee yee",
      "I get my 5900x tomorrow, from my old and faithful i7-4770k to the new shininess is gonna feel so good!",
      "Great time to upgrade right now congrats and welcome to the team",
      "was lucky had the same upgrade! but still it wasnt easy... got very lucky with a a minor site",
      "Congrats on converting to team Red! We hope you stay with us for the foreseeable future; don't see any reason to go back to shitty team blue anytime soon anyway.",
      "What gpu you pairing it with?",
      "Congrats! I'm doing the same upgrade from a 7700k but currently on a stop gap 3100 (basically same perf) while waiting for my chip!",
      "My last Intel was the i5 3570k, only had AMD since then. \nTiny steps with 1700X, 2700X, 3950X and now 5950X üòÇ",
      "congrats and welcome to ayymd",
      "I'm upgrading from a i7 6700k to a 5600x, it's going to be a good upgrade"
    ]
  },
  {
    "brand": "amd",
    "generation": "7000",
    "tier": "mid",
    "matched_keywords": [
      "7700xt"
    ],
    "title": "Intel B580 vs Gigabyte rx 7700xt",
    "selftext": "I am running a 10700f but have a 11900k coming and I have a Gtx 1660ti. Should i pay $530 for the B580 or $749 for the 7700xt? I have the B580 now and haven't opened it but should I keep it or send it back and get the 7700xt?",
    "comments": []
  },
  {
    "brand": "amd",
    "generation": "7000",
    "tier": "mid",
    "matched_keywords": [
      "7700"
    ],
    "title": "Sapphire Radeon RX 7700 XT Pulse Review",
    "selftext": "",
    "comments": [
      "Definitely think the 7700 XT @ $400 would have been a huge home run.\n\nAt $450, you got better options for a small increase, as TUP's conclusion reads.\n\nOh well, AMD gonna AMD. When the inevitable price cuts hit, the 7700 XT will be a decent recommendation as old RDNA2 dries up.",
      "Techpowerup really are the best reviews by far. Great charts if you just want performance numbers, but well written analysis if you're interested.",
      "My only complaints with this release is that I wish each respect card was $50 less and that the 7800 XT dropped the XT as the naming scheme is a little misleading. \n\nThat said, they‚Äôre occupying a market that Nvidia doesn‚Äôt currently command, and asking for a price reduction is probably asking a little too much from AMD in 2023. \n\nSolid release, just in time for one of the biggest games of the year.",
      "AMD is basically encouraging consumers to buy the 7800XT and the suckers who buy the 7700XT at MSRP are a bonus. So yeah, always wait for the price to go down.\n\nI hate the current state of the consumer GPU market...",
      "Something I like about them, and most tech review sites as a whole, is that they don't vomit Javascript/Angular everywhere and make the site run like ass on phones.\n\nSwitching from reading a Techspot article to say, a CNN one is night and day.",
      "Is there already a review for the 7800XT Pulse out there? Tempted by the card, but would like to know more about how good the cooler is.",
      "At 399, this will be the value card king. Black Friday time maybe?",
      "Thank you <3",
      "I just got this card (Pulse 7800xt) and it is great! GPU temps are in the low 60s (I didn't look at the hotspot temps). It's also very quiet. I can't hear it over the other fans in my system. The cooler is impressive, especially since it's only a dual fan setup.",
      "I would have preferred if they used Cyberpunk RT for testing OC. 3DMark benchmarks are very skewed for RDNA3 GPU OCs and don't tell the full story (e.g. my 7900xtx can run them at 1020mv but games typically need 1100mv).",
      "It costs $50 more than the $400 you are asking, and it comes with a free $100 game.",
      "If the 7700 was priced closer to (or at) $400, I'd be all over it to replace my 5700XT.",
      "Probably much sooner since Nvidia dropped the price of the 4060Ti to undercut this card.",
      "I think because I had to sit out the 6000/RTX30 series and scalpers, I have no issue with the current market. My 4080 cost me less than the 2080 ti it replaced, offers huge improvements and I didn't have to fight scalpers.\n\nBut everyone is different. AMD is definitely going to try to maximize profits, and they should, but consumers should do everything in their best interest.",
      "Not that I've seen. I bought it though and judging from the 7700XT Pulse review, I'd expect identical performance to the stock version of 7800XT but better temps and noise. I can post what I've got once the card arrives.",
      "I assume there's not enough defective dies to have enough supply for a 400 dollar 7700 XT, yet.",
      "As I mentioned it wouldn't. In case you didn't see what TPU said, you need to undervolt to get higher clock speeds for RDNA3. This also means Timespy can get insane gains from a unrealistic undervolt, because it somehow still runs at ultra low voltage, yet for gaming you're only stable at around 1080\\~1100 mv at best. Vex did a test with 15% PL, and it was only like a 5% fps increase. I'd bet there's another 4\\~5% from gain undervolting which he failed to realize since he didn't understand the architecture. It's probably only 10% better at best which is still insane imo as an OC.",
      "Same results with me. Temps hover around 60-62C during gameplay, my case fans are louder than the GPU so can't complain about that. Upgraded from 5700XT Red Dragon so getting generally near double fps with what little testing I've seen. No coil whine either.\n\nThis is with default settings, haven't tried undervolting yet.",
      "Now we wait for NVidia to undercut it so we can get it at $400, oh how the turntables /s",
      "Yeah, curious to see what the pricing does in the coming weeks/months. I can wait a couple months before buying a new system, i wouldn't be surprised if the price on these drops in that timeframe."
    ]
  },
  {
    "brand": "amd",
    "generation": "7000",
    "tier": "mid",
    "matched_keywords": [
      "7700"
    ],
    "title": "Acer's EEC filling lists Radeon RX 7900, RX 7800 and RX 7700 non-XT models - VideoCardz.com",
    "selftext": "",
    "comments": [
      "I‚Äôm all for meeting every price point to suit every customer. But it‚Äôs getting hard as it is to decide between a 7900 gre, XT, and the 7800 XT. This may end up cannibalising sales because customers won‚Äôt be able to decide without watching a few dozen YouTube benchmark videos.",
      "More price points below $500 would be nice.  Cheap 6000 series availability is running down.",
      "Seasonic also lists 7700 non-XT, so that GPU is likely to be released soon.",
      "Really does feel like they continually expand the 7900 tier but give anything less than a 7700 no attention at all. \n\nLike how many versions of a 7900 are there now? The 7900, the XT, the XTX, and however many GREs there's been. And we even learned recently they had planned for 7950XTXs and 7990XTXs before canning those plans.",
      "How many GPUs AMD is making around 7800 performance?",
      "This post has been flaired as a rumor. \n\nRumors may end up being true, completely false or somewhere in the middle.\n\nPlease take all rumors and any information not from AMD or their partners with a grain of salt and degree of skepticism.",
      "Why 7800? Just a 7900 gre?",
      "I would walk a mile around them.\n\nBeen in enough of Acer's laptops to dismiss them as viable.\n\nHeck, all the big oem make some price point hot garbage.\n\nWhich means going up a tier for a decent unit.\n\nAcer doesn't do that at all.",
      "No, this is a cut down 7800 XT.  Probably lower bin chips so lower max clock speeds.  This is like a half tier between a 7700 XT and 7800 XT.",
      "Just as many as they have around the 7900.",
      "I suspect these filings are just placeholders for RDNA4 GPUs. It's been a long time since you could rely on EEC filings to mean anything concrete."
    ]
  },
  {
    "brand": "amd",
    "generation": "7000",
    "tier": "mid",
    "matched_keywords": [
      "7700"
    ],
    "title": "ASUS reveals Radeon RX 7800 XT and RX 7700 XT TUF Gaming GPUs in black and white - VideoCardz.com",
    "selftext": "",
    "comments": [
      "Just announce the price already , it's the only thing that matters  at that point",
      "If they come out with $399 for the 7700XT and $499 for the 7800XT, I think they will have some very compelling options.  If it‚Äôs close to the 4070, people will just buy that for all the extra features.",
      "sadly 7700xt is at $449",
      "Hahaha Asus will price it at least $100 above MSRP‚Ä¶better luck with AMD‚Äôs exclusive partners",
      "trust me, all these bs teases no one cares about.",
      "$499\n\nOnly a $50 difference between the two cards",
      "It's probably because they aren't going to do non xt versions, that's my guess. The 7700xt will go down tho much like the 7900xt and 7900xtx have. The 7800xt is big slap Nvidia when it comes to prices",
      "That is surprising to me, no point in getting the 7700XT when $50 gets you extra VRAM.",
      "They are out on September 6th, literally together with Starfield. :)\n\nI'd return the 6800 for a 7800 XT if I were you, to be fair, unless the price difference is something like 100$, at which point I'd probably keep the 6800.",
      "I know this was before you watched the Livestream but:\n\nWorst case scenario for 7700XT at $449 (I bet the market will drive this down anyway because at $50 people are just going to buy 7800XT) but best case for 7800XT at $499.\n\nAlso FSR 3 update provided a reasonable timeframe and listed specific game support so 4070 doesn't really have \"all the extra features\" anymore. Including FSR 3 on the driver level actually gives AMD a feature that 4070 doesn't have (although we have to wait until Q1 24 and AMD doesn't have the best track record for release schedules)",
      "That's the early adopter price. They'll come off of it if people wait them out.",
      "Lol. UK here: 7900XTX and XT prices haven't changed since launch.",
      "It's [**$449 USD for the RX 7700 XT and $499 USD for the RX 7800 XT**](https://www.reddit.com/r/bapccanada/comments/1614bs3/rumor_449_rx_7700_xt_499_rx_7800_xt/?ref=share&ref_source=link). I posted in another subreddit because r/AMD only allows posts from trusted members. :\\",
      "They came out with 500 for 7800 xt and 450 for 7700 xt. Which is good price for 7800 xt and bad for 7700 xt. What‚Äôs the point of getting a 7700 xt lmao.",
      "This. Reference model seems the only viable option.",
      "The 7800 xt is 499 though",
      "I know now, I posted this before prices were released.",
      "That's a good deal, but personally, I'd still go with the new card if I had the money, since it doesn't consume a lot more power, it does have those better RT/AI accelerators - for instance, the new Antilag+ for FSR3 is only supported on RDNA3, AV1 encoding, longer driver support and tends to perform better than the RDNA2 counterpart in games like Cyberpunk 2077/Modern Warfare 2.\n\nObviously, this assumes you will be able to get at least one copy of Starfield, otherwise it's way too much money, but at 70$, I'd still make the trade honestly.",
      "449 for 7700 xt and 499 for 7800 xt",
      "That's for AMD Fluid Motion Frames (AFMF) i.e. Driver level frame gen which is rolled into HYPR-RX. I'm not sure if HYPR-RX will release at the same time or if it will be launched ahead of that feature. There's also \"Anti-Lag+\" to be included with HYPR-RX, but it sounds like AMD doesn't want to talk about that yet. Based on the name, we can presume it is their competitor to nvidia Reflex.\n\nThe GPUs will launch on September 6th. FSR 3 is going to be rolling out on a per game basis like any other upscaler, starting with Forspoken and Immortals of Aveum in a few weeks.\n\n[Here](https://www.eurogamer.net/digitalfoundry-2023-amd-reveals-long-awaited-fsr-3-tech-and-frame-gen-for-every-dx11dx12-game) is an article that fills in some gaps that the live stream left. Based on this report, HYPR-RX may be RDNA 3 exclusive, but FSR 3 was out-right stated to be supported on any GPU including consoles.\n\nEDIT: HYPR-RX is reportedly coming to RDNA 3 on Sept. 6 with the launch drivers for 7700XT/7800XT. AFMF will be added later though. It's still unclear to me if Anti-Lag+ will be part of HYPR RX at launch.\n\nThere's also come discussion on FSR3 requirements. Some reports are saying that only GPUs past a certain release date will be able to use, that it is available to any GPU brand and not necessarily any GPU. Supposedly that is RDNA1 or equivalent. I've seen some sites report that could mean GTX 900 or later, it depends, but for sure RTX 2000 or later and results on RDNA 2 and 3 will be better than RDNA 1."
    ]
  },
  {
    "brand": "amd",
    "generation": "7000",
    "tier": "mid",
    "matched_keywords": [
      "7700xt"
    ],
    "title": "Better to buy last gen? RX 6800 vs RX 7700XT Tested in the newest games!",
    "selftext": "",
    "comments": [
      "6800 ez",
      "after the reviews i personally decided on just buying a 6800xt, went with the xfx merc319 for $500 new.",
      "If‚Äôs it‚Äôs available",
      "Rdna2 has incomplete [power monitoring](https://www.igorslab.de/en/graphics-cards-and-their-consumption-read-out-rather-than-measured-why-this-is-easy-with-nvidia-and-nearly-impossible-with-amd/5/). 6800 isnt as efficient as it looks.",
      "Seems like the 6800 had the worst availability even before RX 7000. Its not even mentioned on the steam chart which 6800 XT and 6900 XT are.",
      "I love how AMDs biggest competition is their old stuff.",
      "People were saying the 7700xt only exists to upsell the 7800 I said it was to downsale to the 6800. As long as you can find them in stock it's a easy choice",
      "Did the same, but decided to take my chances and go secondhand when I found a Liquid Devil on eBay. Won the auction for $416 ($459 after shipping/tax).\n\nLuckily the card turned up in flawless condition, I run it at 1070mV @ 2600MHz, and more often than not it's 7800 XT performance for 7700 XT money. I have zero regrets.\n\n$449 for the 7700 XT is not good value. It's not as bad as the 4060, but it's also not far off.",
      "The bizarre thing is watching the power consumption between these two.\n\nWhat most commonly happens, and what you'd expect to happen with a new architecture and node shrink, is seeing the newer and lower SKU card drawing less power to output similar performance as the older and higher SKU card.\n\nBut the 7700 XT is usually the one consuming more power to output the same level of performance as the 6800. That is not a great showing for RDNA3.\n\nI could probably find some redeeming things to say about the 7700 XT if it launched at $399. But $449 has it firmly in secondhand 6800 XT territory, and the 6800 XT is just a whole lot more GPU for the money.",
      "I will buy either soon, the one I find cheapest.",
      "fr i got the 6800 and am so happy with it. the xt premium wasn't worth it for my build(i play esport titles) and looking back I probably could have gotten a 6700xt and a better CPU and still have been happy.",
      "Same boat, I have a 5600 and 5700 XT and don‚Äôt feel it‚Äôs age anywhere other than graphics performance",
      "Igor told me current gen Radeons have significantly better monitoring, closer to nvidia's than to previous Radeons.",
      "Like I said don't pay more than 400$ for the 7700 XT because it isn't worth it, get a 7800 XT or 6800 XT instead",
      "Nice! I considered going the ebay route but decided to just go new as $500 felt reasonable for a top end 6800xt. Going to try and undervolt and overclock to squeeze a bit more performance but the cut cores on the 7800xt cemented the decision for me.",
      "Interesting.\n\nHas the same testing been done on the 7700 XT and shown the power reporting as accurate?",
      "It doesn't really. Most of the testing where that is shown is an OC'd AIB 6800 XT vs stock 7800 XT.",
      "That's not correct, I bought 6800 (non XT) during COVID issues from amd.com\n\nAugust 2021 and price was 630,88 ‚Ç¨",
      "You won't regret it\n\nMy one still goes strong at 1440p.",
      "My dude he says in most vids that RDNA2 under-reports its power in the software he uses."
    ]
  },
  {
    "brand": "amd",
    "generation": "7000",
    "tier": "mid",
    "matched_keywords": [
      "7700xt"
    ],
    "title": "Purchased RX 7700XT!",
    "selftext": "Upgrading from a 2070 Super. I know I could of bought the 7800xt but since I play at 1080p 240hz i would be seeing an average 10% bottleneck paired with my 5800x3D according to PC-Builds Bottleneck Calculator. Where as the 7700xt is less than 1% and also cheaper.",
    "comments": [
      "Congrats! I wouldn't sweat the bottleneck thing too much in the future it's really not as big of a deal as some make it out to be unless you're trying to run a 4090 on a Core 2 Duo or something.",
      "Enjoy!",
      "You made a good choice, have fun!",
      "bottleneck calculators are ass",
      "There would absolutley not be any bottleneck worth mention on a 7800xt.  Bottleneck calculators are trash.  \n\nYou'd need 4090 to really Bottleneck it.",
      "Thanks! I also got a $40 off coupon so it was only $409 wasn't sure when this deal would be back around or if i would have the money to spend so i bit the bullet. Its still in the mail but ill probably update this post with my benchmarks for 1080p low / competitive settings. Its hard to find anyone using this card at 1080p low because everyone wants to go 1440p.",
      "Thanks!",
      "Ignore the bottle neck calculator, they are pretty much complete BS. The 5800X3D is on par with the 14900K in some games and is only consistently beat by the 7800X3D, so it is still basically the 2nd or 3rd fastest gaming CPU on the market.",
      "I just use them as a guide. I am sure i would still see more performance between the 7700xt and 7800xt at 1080p but if the difference is 20-30fps when im already at or above my 240fps monitors refresh rate then it doesn't matter to me to be honest.",
      "Yea I can always return my 7700xt and go ahead and buy the 7800xt if I feel like it doesn't perform the way i want. But if i can reach 240FPS at 1080p low / competitive settings in all the FPS games I play then I saved me $80-$90.",
      "No problem!",
      "Oh yeah, a 7700XT should be perfectly capable of that. My RX 6700XT is as far as I can tell.",
      "nice! you using FSR or at Native?",
      "Mostly native or FSR highest quality.",
      "Hey guys btw just bought 6700 XT not sure should I upgrade my cpu or not at 1080p with 11400f",
      "An 11400f will be just fine with a 6700 XT.",
      "I am back! I went from 160-180 fps in call of duty with my old RTX 2070 Super to now being over 250-300 fps (depending on the map) with my 7700xt at 1080p using Fidelity FX CAS. 100% worth $409 I paid for my card",
      "yea I just know running at 1080p you are more likely to run into bottlenecks cause you will be pushing so many frames when playing at low/competitive settings haha but yea I'm not worried to much!",
      "I am looking at this same ASRock dual fan card at Microcenter.  I haven't been able to find any user reviews on it but stumbled onto your post here.  \n\nHow has this card been for you?  Any issues?  Any regrets?  \n\nI am currently running a 1060 6 GB that sounds like a jet turbine when any load at all hits it.  I know the 7700xt is going to be an immense upgrade - I just want to vette out the specific card a bit.\n\nThanks!!",
      "Right. Bottleneck calculators are good for a guide.  Certainly more accurate than the fake videos that compare one cpu against another one in live gameplay."
    ]
  },
  {
    "brand": "amd",
    "generation": "7000",
    "tier": "mid",
    "matched_keywords": [
      "7700"
    ],
    "title": "AMD Ryzen 7 7700X CPU drops to $295, cheaper than 7700 non-X - VideoCardz.com",
    "selftext": "",
    "comments": [
      "You mean - for the \"X\" series, right? The non-X do actually have coolers.",
      "7700 having the same perf as 5900 with 50% better single and cheaper, still amazes me",
      "What do you mean? Just buy the cheapest whether it's X or not. Right now the 7700x is cheaper than the 7700, so get that and enable eco mode if you really need a non-x",
      "Just don‚Äôt forget you‚Äôll need to buy a cooler separately for the non-X versions in the 7000 series.",
      "I don‚Äôt get why would someone need that",
      "This trend continues for pretty much all X vs non-X CPU's. 7900 kept the value here while 7900X now has small discount and became cheaper :)  \nI personally don't see any reasons for getting X over non X knowing what if you need to - you can PBO it to the same specs...",
      "That makes no sense.\nSame TDP results in the same temperature.\nThe X turboes beyond the TDP limit of non-x, but that can be tamed with manual PBO TDP limit. Then you get a better performing chip (higher chance of quality silicon on X parts, so lower PBO) with the same TDP. It‚Äôs also cheaper",
      "Many web apps are singlethreaded. And most of the apps we use are built on web technologies sadly ü•≤",
      "Well no, if we go by what the conclusion has been - that ASUS and other boardmakers are ignoring AMD's voltage limits and aren't using their own embedded controllers to prevent hardware failures, that sounds an awful lot like they're rushing out bioses and boards. The socket itself seems to be very competent with exceedingly flexible I/O, and what's hopefully a very long lifespan as AM4. \n\nWhat do you find to be the \"design flaws\" of AM5 in particular then?",
      "Because nonx runs cooler at same tdp",
      "I picked up a TUF B650-Plus that has 3 nvme slots, with one of them that runs at pcie5. It costed about 200‚Ç¨..",
      "I guess that‚Äôs the culprit. AMD knows that the X parts can OC higher, so they push them to extreme clocks/voltages, way beyond the efficient point. They do this by default to get a slight edge over Intel. If you dial them back manually, you lose max 5% of performance for 50% less power (heat). It‚Äôs crazy..",
      "That‚Äôs merely a cooler to get you going. If you want a more silent experience you‚Äôll need a better cooler. The X chips offer more performance (as a space heater) and can be regulated in bios to act like non-x parts. Go for cheapest or need of cooler",
      "So you want to be pure nvme, not even sata ssds, but also want a cheap mobo? Why would they even make that",
      "NP..\nJust buy a large ssd at this point :)",
      "Any X670 should have 4. Check out the Asrock or msi entry level, should be mid $200s",
      "Just picked up the 7700x as there was a great sale! Now I just need to find a motherboard",
      "At least 3 choices in the $200s, and 5 in the $300s.",
      "Have 7700, had to upgrade cooler.     \nStock maybe ok if you live in Iceland and like to have windows open, but when it is bit warmer ... you need something more.      \nNo i am not fine with 85deg , paid 35$ for Perless Assasin and my heavy load temps are below 65 now.",
      "Absolutely crazy strategy by amd. My last cpu was fx8150 which I hated. But I loved ryzen 7900.\n\n1 zen 4 core = 8 bulldozer cores lol"
    ]
  },
  {
    "brand": "amd",
    "generation": "7000",
    "tier": "mid",
    "matched_keywords": [
      "7700"
    ],
    "title": "7700 (non-x) won‚Äôt all core boost/of",
    "selftext": "7700 non-x \nWraith prism cooler\nAsrock b-650 pg lightning \n7900xt\n32 GB crucial pro 5600 cl 46\n\nIt‚Äôs been a few years since I‚Äôve overclocked and I‚Äôve never done it on a Ryzen system.  But for some reason I cannot get all my cores to overclock at the same frequency as I‚Äôve done in the past.  Not looking for anything drastic as I‚Äôm using stock cooler, though in pc world review they said they reached 5.3 all core with wraith prism.\n\nWondering what setting I‚Äôm missing, I‚Äôve tried through Ryzen master and also bios.  It does happen when I multi core test in cinebench23.\n\nBut when I fire up a game (csgo, D4, Forza) my clocks are all over the place on every core.\n\nTemps seem to match or be close to reviews, high 70s gaming it running unlocked frame rate.",
    "comments": [
      "> Could enabling or an auto pbo and also setting a static core freq cancel each other out? \n\nYou are telling it to do two contradictory things, what did you expect?\n\nNever set a fixed frequency on modern CPUs, it is either going to cripple your performance or destroy the CPU in a brief period of time if you raised voltage to set anything close to full speed.\n\nReset it and leave it at stock, if you dont know what you are doing. It will boost to full speed by itself if cooled.",
      "It‚Äôs on a per core basis from what I understand. Ryzen 7000 will boost the highest performing core by default and PBO will push it further for longer. \n\nWhen you enable CO, you can select an all core or per core curve. I typically do all core and adjust a negative offset until I hit instability (governed by my weakest core).",
      "And am I chasing something pretty irrelevant in wanting an all core static oc with these processors.\n\nWhen I was on Intel you wanted to chase that static all core for performance usually.",
      "Yes you are. No need to static overclock as the best performance in most use cases is through using \"dynamic overlock\" which is another word for PBO.",
      "I‚Äôd recommend making the changes in the BIOS instead of with in Ryzen Master. Also, make sure you‚Äôre setting a NEGATIVE offset. It‚Äôs counter intuitive but the goal is to pull the boost voltage down so the CPU runs cooler, which will give more headroom for the boost algorithm.",
      "Make sure precision boost overdrive is enabled in the BIOS and maybe add a negative offset with curve optimizer. You‚Äôll have to do a bit of trial and error to find what‚Äôs stable.",
      "Cinebench just has each core do a static render so it pushes each core to its highest.  In games cores have ALWAYS boosted to different speeds depending on what it is required to do.\n\nIt sounds like you want to use the most electricity that you can just to have the cores sit at the highest boost clock. Maybe stop looking at the core clock speed to help with any OCD.",
      "I have enabled pbo. Have not run curve optimizer yet though",
      "I ran cinebench last night, and my results compare to yours.  I was hitting 95c temp though‚Ä¶\n\nCurve optimizer gave me a -50 offset and a max of 5.5ghz, but obviously I need better cooling",
      "CS:GO is a CPU limited game. At those framerates, you're finding physical limitations in terms of latency within the hardware. It's shocking that the game engine can even run framerates that high, as normally games simply can't do that. Even 2D games have a limit; there is a minimum amount of processing that must occur between frames, and that takes time.",
      "Because it‚Äôs cheaper, uses less power, has included decent cooler, and performs almost on par with the x.\n\nI didn‚Äôt buy it with the intention of overclocking it, but reviews said it does overclock well.  Reviews also said they were able to all core overclock to 5.3 with stock prism cooler.\n\n I haven‚Äôt been able to get it to all core overclock when gaming (it did on cinebench R23) so I was posing questions to see if I was missing something, not asking for buying advice.  I did put a bunch of time into research and deciding between Intel and amd, and the ability to overclock amd led me this way. \n\nI‚Äôve been out of the hardware loop for 5-6 years now.",
      "CO is a good tool to pull the voltage frequency curve down so for a given frequency the CPU will apply less voltage. On Ryzen 7000 you can squeeze more frequency out of it since it‚Äôll use less voltage and in turn less heat. The tricky thing is to find a negative offset that is still stable for all core workloads.",
      "this. turn PBO on, static freq off, but set PBO boost offset to +200",
      "So- I used Windows PowerShell to enable the Ultimate Power plan for my PC, It‚Äôs typically hidden but you can find the command line options to enable it, I then deleted the other power plans to prevent Windows 11 from reverting back to the balanced mode. \n\nI‚Äôm not totally sure if it really does anything other than preventing hard drives from hibernating. But I figured why not.",
      "Not sure if this still holds true, but PBO is more for all core workloads, where actual overclocking is more for single threaded apps.  I personally just use auto-overclock.  But might depend more on which chip you have.",
      "If you have a non-X CPU, then your BIOS settings should look like these:\n\nPPT = 88 (W), TDC = 75 (A), EDC = 150 (A). For a TDP of 65W.\n\n*(in some BIOSes it can be 88000 instead of 88, so be careful with the units)*\n\nYou can try these settings:\n\nPPT = 142 (W), TDC = 110 (A), EDC = 170 (A). For a TDP of 105W.\n\nThat should basically turn your 7700 non-X into a 7700X. Like I said, 40% more power draw, but only for a marginal performance increase.\n\nMaybe you can go even further, but all that is of course at your own risk, and you'll need a good cooler, possibly better than the Wraith Prism.\n\nOne last thing: before attempting this, it would be wise to restore BIOS to default settings.\n\nGood luck!\n\n|TDP & Stock PBO Settings|PPT (W)|TDC (A)|EDC (A)|\n|:-|:-|:-|:-|\n|45 W|61|65|140|\n|65 W|88|75|150|\n|95 W|128|100|160|\n|105 W|142|110|170|\n|125 W|162|120|180|\n|170 W|230|160|225|",
      "Overclocking on ryzen is nowhere near the same as on intel cpus. Just do all core curve optimizer with a negative voltage offset. You get more performance out of tuning your RAM than you do getting higher clocks. Also getting all cores to boost to the same frequency is meaningless.",
      "Oh perfect. I actually just went and learned how to format tables in Discord after reading your post to share and pin the information for some others. Thanks for taking the time to make this!",
      "Could enabling or an auto pbo and also setting a static core freq cancel each other out? \n\nI belive pbo is functioning correctly in the chip, as I do get some boosts.  Does pbo for you clock all cores the same?",
      "So in CSGO im not reaching 100% gpu usage, usually hovering around 80 or so‚Ä¶ I think my \"insecurity\" is that i feel the 7700 should be able to feed my 7900xt 100% for this game in 1440p‚Ä¶ maybe im misguided in that thought‚Ä¶\n\n\nYes I have framerate uncapped.  cpu wattage right now with running pbo at stock settings is between 35-45 watts while playing."
    ]
  },
  {
    "brand": "amd",
    "generation": "7000",
    "tier": "mid",
    "matched_keywords": [
      "7700xt",
      "7700"
    ],
    "title": "Sapphire PURE 7700xt and 7800xt availability",
    "selftext": "Update September 13: The PURE 7800xt model is now listed on Newegg, sold and shipped by Newegg. It is currently out of stock at the time of update. Thanks to u/fdiv for sharing this!\n\n [SAPPHIRE PURE Radeon RX 7800 XT Video Card 11330-03-20G - Newegg.com](https://www.newegg.com/sapphire-radeon-rx-7800-xt-11330-03-20g/p/N82E16814202439?Item=N82E16814202439&SoldByNewegg=1) \n\n&#x200B;\n\nUpdate September 12: I now see a listing for the PURE 7700xt model on Newegg, sold and shipped by Newegg. It is currently out of stock at time of update.\n\n[SAPPHIRE PURE Radeon RX 7700 XT Video Card 11335-03-20G - Newegg.com](https://www.newegg.com/sapphire-radeon-rx-7700-xt-11335-03-20g/p/N82E16814202438?Item=N82E16814202438)\n\n&#x200B;\n\nOriginal post below:\n\nDoes anyone know if Sapphire will be releasing the PURE 7700xt and 7800xt models in North America anytime soon? I can only find them on European and Australian websites. And the only reviews I have seen with them are from Europe and Australia too. I have searched on Sapphire's own website and social media and there is nothing about where to buy this model. None of the videos I have watched with the PURE model show purchasing details either.\n\nSapphireNation website article link featuring the new model here:\n\n[https://www.sapphirenation.net/sapphire-customized-lineup-for-the-amd-radeon-rx-7800-xt\\_rx-7700-xt](https://www.sapphirenation.net/sapphire-customized-lineup-for-the-amd-radeon-rx-7800-xt_rx-7700-xt)\n\nKitGuru website article link featuring new Sapphire 7700xt and 7800xt models:\n\n[https://www.kitguru.net/components/graphic-cards/matthew-wilson/sapphire-rolls-out-new-rx-7700-xt-and-rx-7800-xt-pure-series-graphics-cards/](https://www.kitguru.net/components/graphic-cards/matthew-wilson/sapphire-rolls-out-new-rx-7700-xt-and-rx-7800-xt-pure-series-graphics-cards/)\n\nHardware Unboxed video link with Sapphire PURE 7700xt here:\n\n[https://youtu.be/\\_LEBEqsCwiM?si=qtgmFwPfx\\_JVskPp](https://youtu.be/_LEBEqsCwiM?si=qtgmFwPfx_JVskPp)\n\neTeknix video link with Sapphire PURE 7700xt here:\n\n[https://youtu.be/xlWLmTge2hk?si=ppo3A0HrQM6mdAm1](https://youtu.be/xlWLmTge2hk?si=ppo3A0HrQM6mdAm1)",
    "comments": [
      "I think did saw pure on Amazon or new egg at launch of the card idk what happened to it now",
      "I think it will be a few weeks at least. White cards are always sought after and it seems like AIBs like to play into it even harder when they can.",
      "Is anyone else bothered by the random red accent in the middle of the card? It would look better if it was all white since the red will clash with many builds",
      "I too have been waiting patiently for these to show up in the states...it's the last missing piece of my new \"white and brown\" build. Been spamming F5 since the morning of the 6th and nothing has popped up...",
      "The 7800 XT Pure just popped up on Newegg in the last few minutes, showing \"out of stock\" from the get go. Must be placeholders for when inventory appears in the system. Must be getting close!\n\nhttps://www.newegg.com/sapphire-radeon-rx-7800-xt-11330-03-20g/p/N82E16814202439",
      "7800 XT just became available to backorder (ETA 9/21/2023) and 7700 XT is in stock at newegg for USA.\n\nEDIT: Oddly, they are the only two Sapphire models that don't come with a starfield code - guessing a newegg oversight for the recent listing.",
      "I didn‚Äôt see it but maybe it was gone in an instant or maybe it was a 3rd party seller? I‚Äôve been checking daily since launch and I haven‚Äôt seen a listing for it in the U.S.\n\nedit: Both the 7700xt and 7800xt PURE models are now on Newegg. I updated my post with links.",
      "Noticed this. I want to go ahead and put in an order, but not if I'm going to get screwed out of Starfield. Also, does Newegg not take AMD reference models for their trade-in program?",
      "Just wrote this to AMD after getting pushback from both Newegg and Sapphire about the Starfield not being included.  Still awaiting AMD reply:   \n\"Hello, I just purchased new release PURE AMD Radeon‚Ñ¢ RX 7800 XT 16GB yesterday from Newegg (which is a consumer authorized merchant partner for Sapphire as well as most of your AMD graphics cards.) According to all marketing from AMD as well as the Sapphire website: https://www.sapphiretech.com/en/consumer/pure-radeon-rx-7800-xt-16g-gddr6 , this graphics card qualifies for the Starfield Premium edition bundle. I already wrote to Newegg, and they said it does not qualify. Reading the Sapphire website disclaimer, it states \"Available through participating retailers only.\" Newegg is definitely a participating retailer, as they are showing this Starfield bundled with other 7800 XT brands (ASRock, etc...). Also, since the Sapphire website here shows the 7800 XT as a qualified graphics card, and the only place for a consumer (non commercial) to purchase this specific Sapphire 7800 XT, by default this would have to be a participating and qualified purchase. Sapphire summarily wrote back to me to contact you at AMD directly, as AMD is handling the Starfield game code distribution. I could almost understand the participating vendors disclaimer if there were multiple storefronts offering the Sapphire 7800 XT, however Newegg is the only storefront for consumer purchase. So with one default storefront, combined with the Sapphire 7800 XT as a qualified graphics card, this purchase on Newegg has to qualify, since Newegg is a participating merchant.\"",
      "Ok, the Yeston is partially white; and will probably have the ‚Äúwaifu tax‚Äù but I‚Äôm ok with that.  The color card will determine the color case I get.",
      "The sapphire looks better than the as rock imo.  I don‚Äôt plan on over clocking or anything, just going for a visually appealing build.",
      "There is also the ASUS TUF White model, it has a very clean white look. I won't buy it because I prefer Sapphire's business model, but it's an option.\n\nhttps://www.asus.com/us/motherboards-components/graphics-cards/tuf-gaming/tuf-rx7800xt-o16g-white-gaming/",
      "Hmm.  I do have a TUF mb.",
      "This or the Yeston are the only white 7800 xt cards, right?   Whichever is cheaper or comes out first, I‚Äôm gonna jump on it.",
      "Still can't buy the 7800 xt in UK",
      "Real question is, will it have a starfield code?",
      "Just got a message that 7800 was in stock at Newegg.  Was able to add to cart and purchase.",
      "Just fyi, my backorder went to packaging about an hour ago.",
      "Good news on this front - I just got mine today and out of curiosity disassembled the shroud. **Turns out the red accent is fully removable!** Just two screws and it can pop out and you can leave LED wire in the shroud.",
      "Finally got the writeup done with proper photos, if anyone is curious what the PURE cards look like once the red accent is removed. https://www.reddit.com/r/mffpc/comments/17dly0v/hunting\\_wabbits\\_ap201noctua\\_build/"
    ]
  },
  {
    "brand": "amd",
    "generation": "7000",
    "tier": "mid",
    "matched_keywords": [
      "7700"
    ],
    "title": "LTT 1080 TI Review: Showing good Ryzen vs 7700 4K results! Fury X 2nd with price/perf",
    "selftext": "",
    "comments": [
      "o man he tested Doom in Open GL",
      "Rather interesting to see processor results here . It performs very similarly to the 7700k. The minimums always favor \n\nAlso the Fury X now takes 2nd place on that price/per chart where all flagships are being compared.",
      "It does now.",
      "what the fuck is wrong with you",
      "7700k is going to be a stutter-fest going forward for games. \n\nIt's a cute little power-hungry quad-core for legacy games, though.",
      "Is imrovement bad?",
      "I'm sorry, but anybody who talks about \"amd fanbois\" on this sub should be slapped. It's seriously fucking annoying to be blanket-insulted and have any arguments or claims dismissed as fanboi bullshit IN THE GODDAMN AMD-SPECIFIC SUBREDDIT.",
      "Not sure how many people will be disappointed - it depends on performance AND price.\n\nIt also leaves AMD in a tough spot because Volta is likely now only a year out while Vega is still not even here - so if Vega is slower than Pascal - even if it is cheap enough to be a better value - it'll spend half its life against Pascal and half against Volta which is a bad spot to be in.\n\nRealistically the top Vega really needs to be priced slightly less than and perform slightly better than the 1080ti - that way it can stand against Pascal and gain market share for a few months till the Volta leaks start.",
      ">forced\n\nI don't think you know what that word means",
      "Poor VEGA",
      "deleted  ^^^^^^^^^^^^^^^^0.2407  [^^^What ^^^is ^^^this?](https://pastebin.com/FcrFs94k/30460)",
      "> Oh in 4K! Almost every single processor will perform the same at 4K.\n\nExcept in GTA5 where Ryzen has **double** the minimums, 35 vs 17, which absolutely matters at values this low. \n\n\nBut no no, CPU is not important when GPU is bottlenecked, stop comparing CPUs in 4k /s",
      "Oh in 4K! Almost every single processor will perform the same at 4K. Useless way to see if it's a good CPU for gaming. \n\nGuru3d did tested the 1800X vs the 5960X on the 1080Ti and there were two games in which the combo 1800X + 1080Ti performed worse than a 1080 at 1080p. http://www.guru3d.com/articles_pages/geforce_gtx_1080_ti_review,31.html",
      "Nice troll there buddy.",
      "No because it was in OPENGL.. vulkan adds alot more performance...",
      "Need and Want play no real factor, so yeah... if nothing directly competes with the 1080ti and someone wants/needs a top end card (and has the funds to do so) then they're forced to go with the one available option despite any other loyalty they may have to take a different action (in this case buy a competitors card, which is non-existent in this scenario).\n\nIf you take things literally though, then yeah, no one is pointing a gun at their head saying \"BUY THE 1080TI!\"... but that would be silly given the context.",
      "When you're benchmarking CPUs it doesn't make much sense to benchmark the GPU.",
      "Well it's uhh, a GPU test at that point.\n\nOf course the scores are basically the same.",
      "> Whatever the fuck the guy's name is\n\nhahahaha\n\n> A fucking 2600k isn't a stutterfest 6ish years after its release, why would the 7700k be anything different?\n\nI did say going forward. Games now run pretty well on 4 physical + 4 logical threads. But then again, games used to run fine on one thread. Then two threads. Now 4 threads. Wait, now the i5 is getting beaten by the i7, make that 8 threads...\n\nSome of the 1080ti reviews already show Ryzen beating the 7700k because it ends up being a CPU bottleneck on total throughput. To an extent, games do generate additional operations for the CPU as resolution and settings are dialed up. Consider shadows, particle effects, physics, etc. Some of this work is done by the CPU, varying in degree by engine. These tasks are often parallelizable, so Ryzen should have a big advantage with such work. And we are already seeing it.\n\nLow settings, low resolution to check for CPU bottlenecking is horseshit, IMO, since that really only tests the main game loop and none of the auxiliary work.\n\nNow I'm REALLY laughing my ass off at the people who cancelled their Ryzen/AM4 orders and insta-switched to 7700k cookie cutter builds.",
      "i5s are turning into pentiums  as games take advantage of more cores and SMT. Hopefully now that Ryzen is a thing Intel will stop making i5s (or make i7s 6c/12t i5s 4/8 and i3s 2/4)."
    ]
  },
  {
    "brand": "amd",
    "generation": "7000",
    "tier": "mid",
    "matched_keywords": [
      "7700xt"
    ],
    "title": "Why isnt the promo on amazon for the 7700xt-7800xt",
    "selftext": "Will it be on? or am I dumb? Should I still purchase from amazon?",
    "comments": [
      "I'm pretty sure I saw multiple post of people not getting Jedi Survivor code with their purchase from Amazon back then.",
      "I'd rather look for another retailer that is listed on AMD's website as one that takes part in the promo in your country.",
      "Because Amazon is shit at times.",
      "If it's not listed, don't order.",
      "Not to mention that it would take over a bloody month and a half for the card to be delivered even with a Prime membership. I‚Äôll be buying on Newegg instead.",
      "Not really. It weighs about 9kg but I hardly notice it. I also have a bag for it that I bought from Amazon that straps onto luggage. It‚Äôs just a simple i5-12600K/6750 XT in an NR200P. All of my peripherals fit into the bag as well as the portable monitor.",
      "You have to buy sure the item is covered. Some seller called Fennec sells a lot of them but this does not come with any promotional codes.",
      "Should I just wait a bit then ? Idk",
      "It‚Äôs up now",
      "So after talking to customer service, I had to cancel my order and re-order to get starfield. REAL dumb. Also for whatever reason I could order the 7800xt pulse, was giving me an error, but I was able to order the Hellhound.\n\nEdit: Also wondering if we should post a PSA.",
      "I just settled for the ASRock Challenger because I can‚Äôt be arsed to wait for the reference card to be restocked. Never owned one of ASRock‚Äôs cards but from what I‚Äôve read, they‚Äôre not the worst of the bunch. At least I won‚Äôt have to worry about the PCB like I would with a Gigabyte card lol.\n\nEdit: Newegg just emailed me stating that my backorder has been delayed lmao. Screw all this, mate. I'm just going to wait until next week for restocks.",
      "Mine is showing Sept. 25-26. I'm surprised yours is showing October. \n\nYou just have to redeem the code by October 28th(And you can't fully claim it without your hardware)\n\nFor my processor, I received the code about 5 days after I ordered it?",
      "I got it and starfield yay!",
      "My home system has the 7900 XTX. I have a travel rig that I take with me because I have to fly often for work. Along with a portable monitor and peripherals, I can set up in an airport or at a hotel. Right now I have a 6750 XT in there but the 7800 XT just looks too good to pass up.",
      "Bruh post that setup. That sounds like a haul to carry around",
      "Seems as though Amazon has now added Starfield, at least to the 7800xt I'm looking at, the pulse.",
      "I chatted with Amazon about an hour ago and they confirmed the 7800XT doesn't come with the Starfield promo as of this time. They didn't answer me when I asked if it would eventually be included with it.\n\nUnfortunately, I'm stuck with buying through Amazon since I have a large gift card on account there.",
      "It's there now, just check again.",
      "I bought my 6950xt on prime day from Amazon (as seller) and didn't get my starfield code (I'm still communicating with support and all that)",
      "Looks like the pulse, hellhound, and merc have the promo now."
    ]
  },
  {
    "brand": "amd",
    "generation": "7000",
    "tier": "mid",
    "matched_keywords": [
      "7700"
    ],
    "title": "AMD Ryzen 7 7700 non-X tested, 13% faster than Ryzen 5 7600X in Geekbench Multi-Core test - VideoCardz.com",
    "selftext": "",
    "comments": [
      "A 7700 non X model would make sense if AMD had a price point to put it in where it won't be embarassed by the 13600k.\n\nThe thing is they don't. The 13600k is 330$ so this part would need to be 300$-ish but the 7600X is already 300$.\n\nI wonder how long AMD will stick to their prices.",
      "I have a feeling this is going to be for OEMs only.",
      "The 13600k rivals the 7700x in performance, not the 7600x.\n\nSo the pricing is actually not favorable. Even before you get into the motherboard and RAM costs.\n\n[13600k is ¬£361](https://uk.pcpartpicker.com/product/LfNxFT/intel-core-i5-13600k-35-ghz-14-core-processor-bx8071513600k)\n\n[\n7700x is \t¬£409](https://uk.pcpartpicker.com/product/WfqPxr/amd-ryzen-7-7700x-45-ghz-8-core-processor-100-100000591wof)\n\n[HUB/Techspot did a 13600k comparison](https://www.techspot.com/review/2555-intel-core-i5-13600k/) with DDR5 and cheap DDR4-3600, compared to the 7600x in gaming its 3% slower with DDR5, 8% with cheap DDR4. But the big issue is, the 13600k is 53% faster in MT. The MT gap is simply too big to care about the marginal gaming difference, it reminds me of early Ryzen, where the 1800x was a moderately slower in gaming than the 7700k, but dominated it in MT. Consumers dont ignore such a big MT difference even if gaming is weaker, and that big MT gap is what sold early Ryzen CPUs.",
      "Lower prices first. Get on it.",
      "That's... kinda low? Shouldn't it be more like 25% based off of core count alone? I presume setting more aggressive PBO targets would probably fix it.\n\nIn any case this doesn't mean much unless AMD can clamp down the motherboard prices",
      "I look at these numbers and think that part wouldn't be worth releasing to retail. 5% worse ST, 13% better MT is probably less useful at this performance level than a base 7600X. It looks incrementally worse against 13600K even at $299.",
      "> the 13600k is 53% faster in MT. \n\nAnd the real slaughter on the MT front, will be when the locked i5s come out. The lowest 6+8 SKU (13500 I think) will essentially be the Zen 2 situation but reversed. Get 75-80% of the gaming performance but much higher MT/$ at a considerably lower price.",
      "Sweet, that'd be a nice $225 CPU.",
      "the 7700 uses 40 watts??",
      "They're already poised to dominate international markets if they could just get those motherboards down (the most affordable variants being incredibly basic 2 ram slot 1 pcie 1 nvme boards and still moderately pricy).\n\nIn the UK 7600X is ¬£320 and the 13600K is ¬£380 ($436!). That alone compensates for the price increase of lower tier DDR5, there's also the matter of the benchmarks always comparing like-for-like as opposed to people buying 13600K and running it on cheaper DDR4 for the maxdimum price advantage, where I assume performance will favour the cheaper 7700 much more. I'd honestly like to see a 'cheap' 13600 system (i.e. not 4000+Mhz RAM) compared to an AM5 system, instead of people pointing at the 13600 dominating somewhat on a DDR5 system where the total platform costs are much closer to AM5 anyway.",
      "The $50 difference between Intel vs AMD procs isn't what's hurting AMD though it doesn't help, it's the insanely overpriced motherboards and necessary DDR5.",
      "> These two markets don't really conflict with each other. \n\nThere is only market for one \"the best gaming chip\", everyone else is shopping for some form of price/performance trade-off.\n\n>so basically one tier below in terms of gaming performance.\n\nConsidering the 7600X isn't really crushing chips like the 12600K at stock, I think calling it a \"tier\" is being extremely generous. ALD still holds up better against Zen 4 than Zen 3 does in gaming.\n\n>BTW AMD also have low-end productivity chips that could get 75-80% gaming perf at good price-to-MT perf ratio... it's called AM4.\n\nAnd Intel i5s will offer better/similar gaming performance and better MT at the same price point than AM4 as well.\n\nNow what?",
      "When AMD will reduce their 7000x price? Next months? Or until 7000XD release? If it latter, AMD will lose a huge buyer potential because of Intel price is cheaper",
      "But it consumes 120 watts less :)",
      "> In the UK 7600X is ¬£320 and the 13600K is ¬£380 ($436!). \n\nThe UK is a special place. Because they had the \"event\" affecting the GBP between Zen pricing was set and RPL launch. With the pound recovering you can expect Intel pricing to come down in a few weeks/months.\n\nThe situation you describe exists essentially nowhere else in Europe. Here in Sweden the 13600KF is cheaper than the 7600X and the 13600K is like 10-15 bucks more. Over at Caseking in Germany the 7600X and 13600K are both ‚Ç¨359 (slightly less than the UK price for the 7600X) and the 13600K is ‚Ç¨389 (‚Ç¨ to $ is nearly 1:1)\n\nAnd before someone comes with the \"at mindfactory the 7600X is just ‚Ç¨349\"\n\nWell, [13600KF Tray at ‚Ç¨342](https://www.mindfactory.de/product_info.php/Intel-CORE-i5-13600KF-TRAY_1471141.html)",
      "I dont see how the 7700 would fit in the lineup right now. Worse ST than the 7600x and merely 13% more MT. Pricing/system cost for the 7600x and 7700x are already bad, simply putting the 7700 between the two doesnt solve anything.\n\nAMD would need to launch a 7600 for $210 and 7700 for $240 to compete against the upcoming 13500/13600 (6+8, $250?) and 13400 (6+4, $230?). And that is assuming board+RAM pricing is the same, but in reality it currently favors Intel.",
      "Probably a bit worse due to worse bin",
      "What‚Äôs next? You‚Äôre going to tell people it‚Äôs also not about the price?",
      "> while 7600X is 13% higher than 12900K \n\nAnd perhaps you should use aggregate data, rather than the reviewer on the whole net that posts the best AMD results because of his testing setup and choice of games. Two can play this game, I could take TPU results and show you how the 7600X is [slower than a 12600K at 720p](https://tpucdn.com/review/intel-core-i9-13900k/images/relative-performance-games-1280-720.png)\n\nThe truth lies somewhere in between. HWUB is one extreme, TPU is close to the other. The 7600X stock is roughly as good as a 12900K with stock DDR5 and a bit faster if the ALD has stock DDR4. But 12900K has the benefit of gaining A LOT from memory, be it DDR4 or DDR5. \n\n>In Hardware Unboxed review (1080p gaming), 13900K has 8% higher gaming perf than 7600X, while 7600X is 13% higher than 12900K and 17% higher than 12700K with DDR4. Meanwhile, 12700K with DDR4 is just 6% faster than 5950X in gaming.\n\nHWUB DDR4 DRAM benchmarks are in general worthless. After the used G2 at 4000MHz on locked ALD chips rather than just running at 3800/3900 G1, he lost the last shred of credibility he had in that department. His results are also all over the place, with some ALD chips scaling better than others with \"the same RAM\" and game/settings, great consistency there!\n\nSteve is also benching with the questionable hand picked, provided by AMD DDR5 kit from the review package iirc. If Intel had sent specific 7000Mhz+ kits to test RPL with, what would this community have said then? You would have been screaming about bloody murder. AMD does not support 6000MHz DDR5 fyi. Either test at stock or with memory you sourced yourself at reasonable \"max settings\", anything else is just trying to shift the narrative in whichever direction.",
      "10 bucks its for OEM only"
    ]
  },
  {
    "brand": "amd",
    "generation": "7000",
    "tier": "mid",
    "matched_keywords": [
      "7700"
    ],
    "title": "AMD Finally Targets Nvidia? RX 7800 XT & RX 7700 XT Details, Pricing, FSR 3 and More",
    "selftext": "",
    "comments": [
      "$500 7800XT: Everyone liked that\n\n$450 7700XT: My disappointment is immeasurable and my day is ruined.",
      "7700xt will be down to $400 in a few months. With the 7800xt being 20% faster and only 10% more expensive, it makes the 7700xt priced $50 too high. \n\n$50 for 20% more performance and 4gb more vram = no brainer",
      "MLID claims an awful lot of things.",
      "The the 7900XTX vs 7900XT launch price all over again.",
      "500 looks like a decent price for the 7800xt, 450 seems high for the 7700XT.\n\nNext to the last gen 6700xt launch price 450 doesnt look all that bad, with a decent generational uplift. But among the current overpriced cards, 400 would have been a much better price, possibly even 420 depending on benchmarks(and for the meme). 450 is a clear upsell to 7800xt price point, reviewers will not be kind to it at 450.",
      "7700xt should‚Äôve been $400. This is gonna be like the 7900xt all over again.",
      "If the slides are to be believed, the 7700 xt's performance is closer to the 6800 than the 6700 xt. With the cheapest 6800 being $430, the 7700 xt's price makes a little more sense, but yeah, still slightly higher than what's ideal IMO. No doubt it's going to drop eventually, just like the 7600 is now available for $250-260 in some places.",
      "I think a $450 7700xt is AMD‚Äôs last attempt to get rid of 6000 series cards. \n\nDidnt want to ruin the launch by overpricing the 7800xt also, but needed to give the market some incentive to buy up rnda2. It‚Äôll be $400 by thanksgiving",
      "Yup. Push people to the more expensive card, then drop the lower end one in a few months time to the real price.",
      "I want to see what the European prices look like before making assumptions. Nowadays announced msrp means nothing.",
      "Exactly, at $450 it's too close to the 7800 XT. I see this gpu getting to $400 months from now.",
      "If you predict everything, you're always right (taps side of head).",
      "He also claimed Starfield would have FSR3 and be shown off with it today.",
      "This subreddit is mostly Nvidia shill girls who have AMD CPUs and ngreedia GPUs. Their whole purpose on this sub is to shit on Radeon.",
      "It's going to be MSRP in USD converted to euro plus VAT (19-25% depending on the country) like it always is.",
      "Yeah I hope 7700 XT gets down to $400 before the end of this year.",
      "Do you have a link to one of those videos where he claims that? I don‚Äôt remember seeing something like that.",
      "I haven‚Äôt seen him claim that as a leak from a source, but he did ‚Äúspeculate‚Äù that it was probably going to happen when discussing what he thought AMD‚Äôs strategy would be. He didn‚Äôt claim it would be shown off today though. I think people get too literal with every single thing he says. He‚Äôs allowed to have an opinion.",
      "Can somebody explain to me if this would be a good fit for a Ryzen 5 7600x? Thinking about upgrading my 3070",
      "Which is entirely the point. You aren't supposed to buy the 7700XT."
    ]
  },
  {
    "brand": "amd",
    "generation": "7000",
    "tier": "mid",
    "matched_keywords": [
      "7700xt"
    ],
    "title": "7700XT vs 4070 Super?",
    "selftext": "I got a [build list](https://pcpartpicker.com/list/4YYmvj) ready for my PC. Now, something I realized the other day was that I needed to make it a priority to get a new monitor too, and that cuts into my budget - I'm trying to shave a few hundred off wherever I can, and I'm wondering if the RTX 4070 Super I so wanted is what has to go.\n\nFrom [this benchmark](https://www.youtube.com/watch?v=UgBO2ScltgM) it looks like the 7700XT gets about 80-90% of the performance on average, for about 60% of the cost, at least for non-ray tracing. That makes it seem like the least painful way to trim my build cost - I should still be happy with the GPU for years, and I can upgrade it if needed down the line.\n\nI do have some questions though.\n\n1: I know that AMD cards are worse at ray tracing per dollar than Nvidia. However, I only plan to use ray tracing for the novelty - I'm not sold on it being vital to the gaming experience. Can I expect to run ray traced games at 1080p 30FPS on high settings? As long as I can test it out for a few hours without it being painful to look at, I'm satisfied on that front.\n\n2: I saw in a very old thread something about AMD being more prone to needing troubleshooting than Nvidia is. Is there any truth to that still in 2024?\n\n3: Is there anything else you think might be helpful for me to know?\n\nBonus question about general PC building - are there other parts in this build list that I could change out to save more to go towards the monitor and peripherals, without being much of a performance loss?\n\nBonus question 2: if I don't buy a Windows 11 activation key immediately and just use the free version for a month or so, what limitations would that impose?\n\nBonus question 3: I DO want my PC to look nice. Between [case 1](https://pcpartpicker.com/product/QnD7YJ/fractal-design-pop-air-atx-mid-tower-case-fd-c-poa1a-02) and [case 2](https://pcpartpicker.com/product/3nD7YJ/fractal-design-pop-air-atx-mid-tower-case-fd-c-por1a-01), which do you personally think would look better with black internals? I like the idea of RGB fans in an otherwise no-RGB build, just as an accent, but I'm not sure whether the white case on black internals would \"pop\" or if it would clash. Also, how can I verify that the parts I pick fit inside the case, alongside a [support bracket for the GPU](https://www.amazon.com/Graphics-Brace-Support-Holder-Bracket/dp/B09FPJL1KY/ref=sr_1_1?crid=22N6M82BND9DR&dib=eyJ2IjoiMSJ9.Y0Ec4wY79HC-EUw6I9gqsmIn4fTWGAyDbE0TrshyDOeoFEwowCxGl4_g4XBy7HEziikoVIAbHXnN9dY4nRyQ94VQYGSHwMA_fSiLsSEnBP9_90BHLq6Xl92-D5MG8MMyQ97XsEk4yePU_2q6jaNl-8g89uFe8Rzq9X5p_TTqg8FdipCmWIoaQziYDdaQtr5VGEGRDrwwPToXjtwM-sbOZLJNqyivx8d7nkAW9ZBk6Wg.Nk4YIqzP0R40yA1jju8ZPwVgIdHp0k7fzbVp1UaYwNw&dib_tag=se&keywords=gpu%2Bsupport%2Bbracket&qid=1709404390&sprefix=gpu%2Bsuppo%2Caps%2C262&sr=8-1-spons&sp_csd=d2lkZ2V0TmFtZT1zcF9hdGY&th=1)?\n\nAnyway, I don't have a hard limit on what my budget is - I have about $1100 USD set aside for this right now, and I'm not willing to make the cuts to fit that budget for a PC/monitor/some other peripherals, therefore I'm gonna need to set aside a portion of my check every month for a while. All the budget determines is how many months I need to wait.\n\nThank you",
    "comments": [
      "You'll probably get more traffic/responses over at r/buildapc but I'll offer my opinion\n\n1. The expectation regarding RT performance varies per game. I'd suggest checking out benchmarks for the 7700xt in some RT games. Alan Wake2 / Cyberpunk being two which will give you an idea on RT performance on titles that have heavy use of RT.\n\n2. I'm not sure there's any data out there to quantify whether or not AMD is more prone to troubleshooting than Nvidia. I personally have had less problem with nvidia cards than AMD. But my experience is anecdotal and not necessarily representative of the experience you will have with your hardware. My personal recommendation would be nvidia but that's because of said personal experience.\n\n> Bonus question 2: if I don't buy a Windows 11 activation key immediately and just use the free version for a month or so, what limitations would that impose?\n\nA watermark on your screen I'm pretty sure; but I've never run windows unregistered before. \n\nGenerally speaking a black case is going to look better with black internals; IMO - but aesthetics is a very personal thing.\n\n> Also, how can I verify that the parts I pick fit inside the case, alongside a support bracket for the GPU?\n\nThe biggest concern tends to be whether or not your GPU will fit. Cases will have specs on how large a GPU they can accommodate; look at them and compare them to the size of the GPU you are planning to buy.\n\nFor a support screw tower you'll need to know how much room you're working with as they come in different lengths.",
      "You can get a Windows key online for around 20 dollars.",
      "Just wait longer and save more money honestly will be worth the wait but have you not looked into the 7800xt? It's cheaper than the 4070 super and performs 5-10% better in traditional gaming",
      "I read here on Reddit, that the Sapphire Nitro 7900 XTX is fairly reliable, they stated they had it for 2 years. If you're willing to extend how long it takes to build your PC, I believe that GPU may be worth looking into. I'm personally looking to upgrade to it as well. By the way, look at the reviews on the GPU you buy, before you buy it.",
      "You can also paste irm https://massgrave.dev/get | iex into powershell and it generates a license",
      "- I already ordered\n- my Sapphire 7700xt already arrived\n- even if I had decided to go for the 6800 ($380 used vs $420 for a new 7700xt), once shipping was accounted for since Ebay doesn't have free shipping, I would have saved $20, which does not seem worth the risks of buying secondhand\n- benchmarks put the 7700xt at (depending on the game) anywhere from neck-and-neck to about 15% faster, average was probably something like 7-8%\n\nUltimately I don't think it really matters much, they're pretty similar cards for pretty similar prices. So between an extra 4gb of vram and a warranty, I chose the warranty. I heard someone else say that for mid-range cards or lower the vram is not something you're likely to be bottlenecked by at the power they can output anyway.\n\nNot trying to discount what you're saying, or your personal experiences - but I got so many conflicting pieces of advice that I can't possibly follow all of them, and I made a decision about 3 days ago.\n\nAnd yes, I realize this conflicts with what I said about needing to save for a few months before making any purchasing decisions. I got impatient and ordered everything for a price *near* my budget.",
      "It's kinda a waste imo like you have a fully funtioning gaming pc you might as well wait a lil longer to get a 4070 super or a 7800xt because they're SIGNIFICANTLY better than a 7700xt.\n\nThen you're better off starting to save for your next pc in the 3-5 year range like you said instead of \"justifying\" to upgrade sooner which is more of enabling yourself to spend money sooner realistically when saving up for 3-5 years for your next pc is the better move cause then you cna upgrade everything at once.\n\n7700xt is technically the lower range for this generation of gpus with midrange being 7800xt-7900 gre or 4070super-4070ti super\n\nImo saving for a bit longer to get a more solid pc is worth the wait but that's just what I think",
      "Great :) seems like it ticks all the right boxes for you. And realistically you wont notice the difference between 80 ans 95fps in a single player game. Good luck",
      "The 7700xt is basically a 6800 with 4gb less vram. Save and get a 16gb card.",
      "Fuck is with the bonus questions? this isnt a quiz contest üòÇ",
      "This is a Fakespot Reviews Analysis bot. Fakespot detects fake reviews, fake products and unreliable sellers using AI.\n\nHere is the analysis for the Amazon product reviews:\n\n>**Name**: Graphics Card GPU Brace Support, Video Card Sag Holder Bracket, GPU Stand \n\n>**Company**: Visit the nkomax Store\n\n>**Amazon Product Rating**: 4.7 \n\n>**Fakespot Reviews Grade**: B\n\n>**Adjusted Fakespot Rating**: 4.7\n\n>**Analysis Performed at**: 03-01-2024 \n\n[Link to Fakespot Analysis](https://fakespot.com/product/graphics-card-gpu-brace-support-video-card-sag-holder-bracket-gpu-stand-d054ffe0-913e-432a-b4f6-cbb8cf3a8d34) | [Check out the Fakespot Chrome Extension!](https://chrome.google.com/webstore/detail/fakespot-analyze-fake-ama/nakplnnackehceedgkgkokbgbmfghain)\n\n*Fakespot analyzes the reviews authenticity and not the product quality using AI. We look for real reviews that mention product issues such as counterfeits, defects, and bad return policies that fake reviews try to hide from consumers.*\n\n*We give an A-F letter for trustworthiness of reviews. A = very trustworthy reviews, F = highly untrustworthy reviews. We also provide seller ratings to warn you if the seller can be trusted or not.*",
      "the 4070S should be compared to 7800xt price and performance wise. I'd get the 7800xt as I dont care much about RT and FSR is getting there but nowhere near nvidia upscaling. but the 7800xt is more raw fps and better price :)",
      "Thanks.\n\nSupport screw tower meaning the part to support the GPU, right?\n\nAnd how do I tell if the GPU will fit? The dimensions on Amazon say the Gigabyte 7700 xt is ‚Äé11.1 x 4.53 x 1.97 inches, but I don't know what spec I'd be looking at on [this product page](https://www.bhphotovideo.com/c/product/1720368-REG/fractal_design_fd_c_por1a_03_pop_air_rgb_core.html) to determine if that would fit.",
      "I'm using a GTX 970 now, whatever I get will be miles better than that in every single way.\n\nThe way I started thinking of it,\n\n- if I buy a cheaper one than I initially planned I can order the parts a month sooner (which would be, now basically, I already ordered the case I wanted because it was on sale)\n- the money I don't spend on a higher-end GPU now mean I can justify upgrading sooner rather than later, like 3-5 years\n- my brother suggested it could be good to do my first build with mid-range parts so that if I screw something up, it isn't as big a deal to replace the part\n\nThe overall build cost, peripherals and everything, that I was envisioning yesterday was about $2000, which was both more than I wanted to spend on it and WAY more than I have budgeted right now. A few cuts (like a more budget-friendly GPU), non-necessary parts put off (I can put up with my old monitor and keyboard for a few more months), and shopping around for good prices got the amount I'll pay now to $1162 ($1252 after sales tax), and what I'll pay later to around $450. Around $300 saved, and what I would need all at once I can swing for now.",
      "I didn't want to make a whole other post and there's enough overlap between this sub and general PC building that I was reasonably sure I would get answers. If memory serves, I did.\n\nWhy are you here 7 months later",
      "Appreciate the input, already considered it and decided\n\n- the 7700xt better fits my budget and I can buy it sooner (next few days instead of a month from now)\n- the 7700XT is something like 10% more power efficient, which is moderately important to me\n- benchmarks place the 7700xt at significantly above what I consider \"good enough\" performance (anything beyond a stable 1080/60/high settings is a cherry on top and the 7700xt does 1080/90/ultra or better in most games) so there's plenty of headroom to last years\n- with the recent price cut to the 7700xt, the 7800xt is about 19% more expensive. Benchmarks I saw put it at roughly 20-21% more performant. Technically it's the better value, but not by enough to sway the other bullet points",
      "> Support screw tower meaning the part to support the GPU, right?\n\nYup\n\n> I'd be looking at on this product page to determine if that would fit.\n\nThat is a vendor page, look at the MFG's page: \n\nhttps://www.fractal-design.com/products/cases/pop/pop-air/\n\nSpecification -> Compatability, GPU max length = 405mm with front mounted fan\n\nMy 4080S is not that long, I can assure you your 7700xt will fit.",
      "Thanks.\n\nI went ahead and ordered the case since it was going off sale soon, gonna make some final decisions on the other specs but I think I've pretty well decided",
      "Benchmarks said the 7700xt was 80-90% as powerful as the 4070 Super for traditional rendering\n\nMaybe I could swing for the 7800 xt? That's about on par with the 4070 Super aside from RT and DLSS, right?\n\nI'm only gonna be gaming at 1080p on a 60hz TV anyway though, I'm not sure if I'll even hit the cap of what the 7700 xt can do with those limits in place",
      "Thanks"
    ]
  },
  {
    "brand": "amd",
    "generation": "7000",
    "tier": "mid",
    "matched_keywords": [
      "7700xt"
    ],
    "title": "Sapphire launches Radeon RX 7700XT Frostpunk 2 Edition, available for $439 - VideoCardz.com",
    "selftext": "",
    "comments": [
      "I'm glad vendors are finally realizing they can make their video cards in colors other than xXxStealthAssasin420xXx black lol",
      "Can we get our waifu GPUs back? We can align the vertically now so we can actually see the card.",
      "Found in EU also, costs 623‚Ç¨. For a reference, cheapest 7800 XT starts from 551‚Ç¨.",
      "\"We made the shroud on our GPU a different color, that'll be 100$ extra please\"",
      "7800xt fighter is 474‚Ç¨ here",
      "I‚Äôm sure getting the cheapest 7800XT and manually lowering the power limit would be a more effective quiet option that‚Äôs still faster.",
      "i love how amd and their partners make really cool and affordable cards while their competitors just enjoy wasting my time and money",
      "Wow thats a great price"
    ]
  },
  {
    "brand": "amd",
    "generation": "7000",
    "tier": "mid",
    "matched_keywords": [
      "7700xt"
    ],
    "title": "Any chance a 7700xt has similar performance to a 6800xt and priced more then a current 6800xt prices?",
    "selftext": "6700xt was released at $479 and AIB cards were alot higher. Let's assume AMD does a Nvidia and increases the price $100 to $579 making AIB cards over $600.   \n\n\nIf 7700xt is practically a 6800xt would it be wise to pull the trigger on the 6800xt now for $550ish (and get a free game)?   \n\n\nOr  \n\n\nIs it better to wait and see? Don't worry about 6800xt being unavailable",
    "comments": [
      "Lmao that‚Äôs gonna be the case I can feel it.",
      "yeah i wouldn't be surprised if they once again went with their tried and tested \"whatever nvidia's price but 50 dollars less\" tactic",
      "AMD have put themselves in very a strange situation. Because they shifted the sku names up a tier and delivered a rather lackluster generational performance improvement, they have to market their way out of apparent stagnation.\n\nThe 7900 XT is a 4070 Ti competitor (6950 XT/3090).\n\nSo, the 7800 XT will likely be a 4070 competitor (6800 XT/3080).\n\nThat should give you pause. The only way it makes sense is if AMD don't call it the 7800 XT and simply call it the 7700 XT. How could they justify it performing basically the same as the previous generation's product?\n\nAs for pricing, AMD's upcoming 4070 competitor (whether called the 7700 XT or 7800 XT) will have to undercut the 4070, so I'd expect models to be $50-100 cheaper and offer one or more free games. Nvidia's rebate of the 4070 is indicative that they know the 4070 is priced beyond demand, so it'll be interesting to see where prices end up from both sides.\n\nAs for waiting, I'd say buy for your needs. If you need it now, get a 6800 XT. If you can wait for June, and you care about RT/AV1, do that.",
      "7800 XT with the same performance as the 6800 XT some 3 years later is such an indictment of the greed of the 7900XT SKU.",
      "I mean, the 6500xt performs the same as the 5500xt so it wouldn't be the first time they make a good joke like that.",
      "If it even reaches it lmao rdna3 is such a joke. the 7900xt has 84CUs and is only 10% faster than the 6950xt at 80CUs. The 7800xt will have 60CUs while the 6800xt has 72. It might actually end up slightly slower. Rdna3 is a bugged architecture soo many more transistors for the same perf. per CU as rdna2",
      "I was gonna wait for the 7700/7800xt myself but after seeing AMD rebrand the 7800xt and called it the 7900xt, it looks like the mid range will be meh generational uplift. It's also why I think people aren't going to see these cards until Q4 this year or Q1 24. My guess is the 7700xt will be about the same performance or slightly better than a 6800xt but with 4gb less vram, and be 500$\n\nI decided to skip out this gen because both companies pulling some BS, more so nvidia. So I opted to vote with my wallet by buying a used gpu for a new build. Went from a 1070 to a Nitro+ 6900xt for 400$. No regrets, its like 2.5-3x the performance uplift for me and I paid the same cost as I did for my new 1070 6 years ago.",
      "im praying for $550, 100 discount, same performance as 6800xt. just like the 4070, 100 dollar discount but same performance as the 3080",
      "I thought about waiting for the 7600xt but after seeing that the 7900xt was only marginally better than the 6950xt, it didn't make sense. I think this gen is gonna be a \"5700xt\" gen where they only have like max 3 tiers",
      "AMD msrp always make me angry .",
      "Not a fair comparison nvidia used the node jump to bump the clocks up significantly at a much higher efficiency while amd did what exactly? The clockspeeds arent much higher and at the same clock getting 9% more perf. on average for doubling the fp32 part of the CU is insanely innefficient.",
      "Some 6950xt‚Äôs can be found for like 550-600 rn in America",
      "ü§Ø good points!",
      "Got downvoted for this but yes and on top of that everyone sees the NVIDIA 9 (not even Ti) at the very top while AMD's 9 (XT!) is trading blows with NVIDIA's 7Ti xD\n\nNow I don't care but most consumers (who already don't seem to even acknowledge AMD's existence) will think NV = better and quickly forget how the 6900XT (for whatever reason selling at 3070 Ti prices btw  ![gif](emote|free_emotes_pack|shrug)) was a decent 3090 competitor! It is as if RDNA2 never managed to catch up to NVIDIA.\n\nHow much worse can marketing be ffs...",
      "I bought a 6950xt for $610 and it came with a game.\n\nCouldn't pass up that deal.",
      ">The 7900 XT is now 800 and has 24 more CU's than the rumored 60 CU GPU below it, while the 7700 XT has 48 CU's.\n\nHow do we know the 7700XT is going to have 48 CU? Did we get any updated info since the Angstronomics article back in August last year?",
      "Yeah, although I think that was more because they didn't plan on bringing that particular die over until the shortages were becoming severe.\n\nImo they should have just called it the 6500 or even 6400 and called the 6400 the 6200 or something.",
      "Look again at the 7900xt card and tell me how a die below that is supposed to have more than 16gb of vram???",
      "https://www.computerbase.de/2022-12/amd-radeon-rx-7900-xtx-xt-review-test/6/#abschnitt_rdna_2_vs_rdna_3_wie_viel_mehr_leistung_bringt_die_neue_technik\n\nRDNA3 performance per CU is up clock for clock.\n\nMeanwhile a 4080 at 78SM loses clock for clock to a 3090 at 82SM despite a two node jump and over double the xtors per SM.",
      "No it was a used mining card. I was skeptical at first because I never bought a used card before but after looking into it, and how mining cards are usually in better condition (because less heat cycles), I decided it was worth the risk to skip this terrible gen. No regrets, card runs perfect and very cool. Getting a 6900xt over a 6800 non-xt was just lucky. Although either of these cards will be perfect for 1440p for years with the 16gb vram."
    ]
  },
  {
    "brand": "amd",
    "generation": "7000",
    "tier": "mid",
    "matched_keywords": [
      "7700"
    ],
    "title": "Render of the unreleased 2-slot RX 7700 XT Reference Design - Should AMD produce this model?",
    "selftext": "",
    "comments": [
      "Yes, desperate for a modern 2-slot to replace a 1080ti in a mini-itx case! Finally go full team red ![gif](emote|free_emotes_pack|sunglasses)",
      "I wish in general more 2-slot GPUs were produced for those of us which have a higher potential noise budget than *SPACE* budget in our systems",
      "yes thats why i posed it as a question, should they produce the reference model for sale to general public",
      "yeah we need more 2slot models",
      "same, but I prefer the 6700 XT design more with its symmetry and Team Rocket logo",
      "I personally love the clean look of the references models.",
      "Damn it AMD why won't you release the smol 7600 reference design, it's so tiny and cute! I bought the pulse instead since it wasn't available.\n\nThe 7700 XT and 7800 XT reference designs look great! They share the same look as the 7900s but they look unique in their own way.",
      "For real. I run a decently big, but still space limited mATX case. I can't do 4 slots. I can't do more than 325mm, 300mm ideally. I made 328 fit for a 7900XTX but it's touching the inside of the front psu mount.",
      "if you are referring to the actual page on AMD, seems like copy paste from the 7800 XT. the picture clearly is within 2 slot bracket whereas the 7800 XT extends past the bracket.",
      "They do have the 7600 reference for sale, at least in North America.",
      "There's surprisingly few truly 2 slot ones. Pretty sure it's just the reference, eagle, and maybe one more.",
      "I actually thought both the 7700 XT and 7800 XT were dual slot. There goes my hope for skipping nvidia. I guess 4070 it is.",
      "Apologies, I didn't read the full title, just seen unreleased reference design. It would be nice, but no point hypotheticalising over something that's never going to happen. Hopefully, AIB will come out with some dual slot cards, but even that's looking unlikely for most part.",
      "The RX 6700 Fighter is pretty small",
      "Yes.",
      "I wish they would have done both in the smaller cooler tbh. The difference in wattage doesn't warrant that much more cooling, and if it did, spinning the fans a little faster would cover it. I would legitimately like to see somebody so a cooler swap for the 7700XT and 7800XT just to see if they could have made that work.",
      "Does this mean the RX 6800 series will have price drop?",
      "Reference cards should be smaller so fully agree with this design choice. AIBs on the otherhand can make them as big as they want. Gives buyers options which is always great.",
      "Yeah, a 2 slot model is needed.\n\nAlso AMD doesn't really produce those thought, they designs and sends to their board partners to make them.",
      "or supply is drying up. 6800 will have its own market since it still has 16gb"
    ]
  },
  {
    "brand": "amd",
    "generation": "7000",
    "tier": "mid",
    "matched_keywords": [
      "7700"
    ],
    "title": "ASUS announces Radeon RX 7800XT/7700 XT TUF Gaming GPU series - VideoCardz.com",
    "selftext": "",
    "comments": [
      "Manufacturers tend to overstate the required PSU wattage because lots of people have crappy PSUs that can't deliver the rated wattage reliably. If you have a high-quality PSU you can get away with lower wattage than the manufacturer recommended.",
      "A nice, reasonable, relatively clean design.\n\nI wonder if they will still make overpriced/overbuilt Strix versions of these, or if they will just stick with the TUF line.",
      "I was looking at the RX 7800XT TUF, but it's disappointing that it requires a 850 watt PSU.",
      "Unfortunately 80+ rating only test the efficiency and many thing that truly determine the reliability of a PSU are left out such as ripple and effectiveness of protection mechanism.\n\nI'd recommend searching for your PSU on this tier list:\n\n[https://cultists.network/140/psu-tier-list/](https://cultists.network/140/psu-tier-list/)\n\nIf it's Tier B or above you should be fine.",
      "Looks like they use a variation of the rtx 30 cooler",
      "As of right now, no immediate plans I‚Äôm aware of",
      "Does it? I‚Äôve seen people with higher tdp cards with relatively small PSUs like 700-750w",
      "Good point",
      "Nvidia doesn‚Äôt allow the halo designs to be used for both their and AMD‚Äôs cards. The Strix design for the 7600 is very old.",
      "Brands always recommend overspec'd PSUs so if there's an issue with power, you don't go blaming them for it.\n\nYou can run this on a 650w easily, provided that you're not running a modern high-end Intel CPU with it. I've ran a 6900 XT (which has a higher TDP than the 7800 XT) paired with a 5800X3D on a 650w PSU before, no issues to speak of.",
      "You should be fine than. I am able to run a rx 7900XT just fine on a 650w psu.",
      "It‚Äôs basically the generational update design wise. Not the same, but a similar look with some improvements for sure.",
      "You can look at the recommended PSU wattage from AMD directly, as well. Outside of unique cases like the MATRIX, our cards won‚Äôt require a higher PSU than whatever AMD officially recommends.",
      "It says so in the ASUS website, but you're right. Maybe it's a mistake, since their RX 7900 XT requires 750w.",
      "I plan to mention it to the team. My guess is it‚Äôs a safety placeholder until finalized info was out and available.",
      "Thank you for the link! It seems that my PSU falls in Tier A.",
      "I was able able to do the same, ran 6900xt with a 5800x no problem. I did upgrade to a 1000w psu so I can mess with overclocking.",
      "A B-tier 700w PSU should be able to handle the vast majority of components except the most power-hungry ones. What parts do you intend to build with?",
      "I have a 5800x3d and 7900xtx,I have yet to see over 550w pulled from my UPS. And my GPU pulls as high as 390w according to AMD overlay with a factory OC, that boosts up to 2900 and if I limit it to 2500, it's well under 300w. Undervolt is a joke with my card, just makes the driver crash..lol",
      "Thanks! I have a 750w 80 plus gold PSU, so I'll look into it."
    ]
  },
  {
    "brand": "amd",
    "generation": "7000",
    "tier": "mid",
    "matched_keywords": [
      "7700"
    ],
    "title": "Ryzen 7 7700 w/ 4070 ti super vs Ryzen 7 7800X3D w/ 4070 super ",
    "selftext": "The usage will be strictly for simulator golfing, running the gs pro software. The software minimum recommendations don't even list a cpu so I'm guessing the GPU is the most important?\nThoughts on which is better for this application or confirm my bias? (I already have the ti super build on order for a couple hundred less than the super build, refurbished but assuming it will be in like new condition) ",
    "comments": []
  },
  {
    "brand": "amd",
    "generation": "7000",
    "tier": "high",
    "matched_keywords": [
      "7900 gre"
    ],
    "title": "AMD Radeon RX 9070 series gaming performance leaked: RX 9070XT is 42% faster on average than 7900 GRE at 4K - VideoCardz.com",
    "selftext": "",
    "comments": [
      "**Edit:** After doing a per game comparison using data from TechPowerUp and Computerbase (the ray tracing comparison set is very limited, only 3 games matching AMD's slide) the relative performance might look something like this:\n\n**Edit2:** Added numbers from AMD's new launch presentation slide with direct comparison to the 5070 Ti\n\nGame (2160p)\t\t\t\t| 9070 XT\t| 5070 Ti\t\t| 9070 XT AMD's new slide\n:-\t\t\t\t\t\t\t| -:\t\t| -:\t\t\t| -:\nAssassin's Creed Mirage\t\t| 111.2%\t| 100.0%\t\t| 107.0%\nBlack Myth Wukong\t\t\t| 91.4%\t\t| 100.0%\t\t| 94.0%\nCoD Black Ops 6\t\t\t\t| 123.2%\t| 100.0%\t\t| 129.0%\nCyberpunk 2077\t\t\t\t| 103.4%\t| 100.0%\t\t| 105.0%\nDragon Age Veilguard\t\t| 96.2%\t\t| 100.0%\t\t| 106.0%\nF1 24\t\t\t\t\t\t| 94.4%\t\t| 100.0%\t\t| 90.0%\nFinal Fantasy 16\t\t\t| 99.7%\t\t| 100.0%\t\t| 103.0%\nGod of War: Ragnarok\t\t| 91.4%\t\t| 100.0%\t\t| 99.0%\nSpace Marine 2\t\t\t\t| 89.9%\t\t| 100.0%\t\t| 90.0%\nStalker 2\t\t\t\t\t| 78.2%\t\t| 100.0%\t\t| 86.0%\nStarfield\t\t\t\t\t| 103.0%\t| 100.0%\t\t| 105.0%\n**GeoMean**\t\t\t\t\t| **97.7%**\t| **100.0%**\t| **101.3%**\n&nbsp;\t\t\t\t\t\t| \t\t\t| \nCyberpunk 2077 (RT)\t\t\t| 81.6%\t\t| 100.0%\t\t| 86.0%\nF1 24 (RT)\t\t\t\t\t| 93.8%\t\t| 100.0%\t\t| 95.0%\nStar Wars Outlaws (RT)\t\t| 90.5%\t\t| 100.0%\t\t| 95.0%\n**GeoMean**\t\t\t\t\t| **88.5%**\t| **100.0%**\t| **92.0%**\n\nThe Cyberpunk 2077 RT number is the same, and the average ray tracing performance makes more sense since the Radeon card *should* be gaining ground rather than losing ground when including games where RT has a lower performance impact.\n\n&nbsp;\n\n&nbsp;\n\n**Old post:**\n\nBorrowing some numbers [from TPU](https://www.techpowerup.com/review/msi-geforce-rtx-5070-ti-ventus-3x/34.html) for comparison:\n\nTLDR:  \n\n**RX 9070**  \nRaster: 2% behind 7900 XT, between 4070 Ti and 4070 Ti Super  \nHeavy raytracing: = 7900 XTX, between 4070 and 4070 Super  \n\n**RX 9070 XT**  \nRaster: 3-5% behind 7900 XTX / 4080 / 5070 Ti  \nHeavy raytracing: 20% better than 7900 XTX, between 4070 Ti and 4070 Ti Super  \n\n&nbsp;\n\nGPU\t\t\t\t\t\t| 1440p\t| 1440p RT\t| CP2077 RT\n:-\t\t\t\t\t\t| -:\t| -:\t\t| -:\nRX 7900 GRE\t\t\t\t|  73%\t|  53%\t\t|  50%\nRX 7900 XT\t\t\t\t|  87%\t|  64%\t\t|  58%\nRX 7900 XTX\t\t\t\t| 100%\t|  74%\t\t|  67%\nRX 9070\t\t\t\t\t|  85%\t|  66%\t\t|  67%\nRX 9070 XT\t\t\t\t|  97%\t|  78%\t\t|  82%\n&nbsp;\t\t\t\t\t| \t\t| \t\t\t| \nRTX 4070\t\t\t\t|  66%\t|  69%\t\t|  63%\nRTX 4070 Super\t\t\t|  76%\t|  77%\t\t|  72%\nRTX 4070 Ti\t\t\t\t|  83%\t|  84%\t\t|  81%\nRTX 4070 Ti Super\t\t|  88%\t|  89%\t\t|  86%\nRTX 4080\t\t\t\t| 101%\t| 103%\t\t| 101%\nRTX 5070 Ti (Ventus)\t| 100%\t| 100%\t\t| 100%\n\n&nbsp;\n\nGPU\t\t\t\t\t\t| 2160p\t| 2160p RT\t| CP2077 RT\n:-\t\t\t\t\t\t| -:\t| -:\t\t| -:\nRX 7900 GRE\t\t\t\t|  69%\t|  51%\t\t|  49%\nRX 7900 XT\t\t\t\t|  84%\t|  60%\t\t|  57%\nRX 7900 XTX\t\t\t\t|  99%\t|  70%\t\t|  66%\nRX 9070\t\t\t\t\t|  82%\t|  64%\t\t|  65%\nRX 9070 XT\t\t\t\t|  95%\t|  77%\t\t|  82%\n&nbsp;\t\t\t\t\t| \t\t| \t\t\t| \nRTX 4070\t\t\t\t|  61%\t|  54%\t\t|  59%\nRTX 4070 Super\t\t\t|  71%\t|  61%\t\t|  68%\nRTX 4070 Ti\t\t\t\t|  78%\t|  67%\t\t|  78%\nRTX 4070 Ti Super\t\t|  85%\t|  87%\t\t|  84%\nRTX 4080\t\t\t\t|  99%\t| 101%\t\t| 100%\nRTX 5070 Ti (Ventus)\t| 100%\t| 100%\t\t| 100%",
      "Instead of using the average, I compared game by game with the results in TechPowerUp (and I do realize that what AMD tested may not be the same as TPU custom scene).\n\nIn rasterizer, the Radeon RX 9070 XT almost exactly matches the Radeon RX 7900 XTX with some games being slightly faster and some slightly slower.\n\nIn ray-tracking, the Radeon RX 9070 XT is well ahead of the Radeon RX 7900 XTX.",
      "Wow, 9070 performance leaks every other day it seems, with varied results nonetheless",
      "Yeah, I ended up with rasterization being on par with the 7900 xtx and ray-tracing performance being slower than a 4080 but still ahead of the 7900 xtx. Looking like a cheaper 5070 ti with worse RT that‚Äôs still a significant jump from the 7900 xtx.",
      "Even AMD failed to procure a 5070Ti for testing, eehehehehe",
      "These are official numbers from a press briefing so these are the best ones to go off on atm.",
      "The number is right above you...\n\nRT is on par with 4070 TI. \n\nIf your eyes are completely blinded by Nivida, you are not going to buy AMD not matter what the price is, you just want lower Nvidia price.",
      "Waiting for prices to declare which one!",
      "I've lost track, is this \"And we're back\" or \"it's joever?\"",
      "Cause AMD isn't going to officially announce the cards until February 28th.",
      "649$- meh, as soon as nvidia come down to msrp, people will flock to 5070ti again\n\n599$- it should sell really well at launch and okay after nvidia card have stock at msrp\n\n549$- crazy deal and will be instant hit like b580.",
      "this is from the AMD presentation",
      "Thank you for putting this together. A+ work and timely!",
      "When I look up gamersnexus benchmarks of the rtx 5080 review, the difference between a 4070 fe and RX 7900 XTX, is nearly a 100% at 1440p on FFXIV, I know gains can be game dependant, but a 34%/31% difference between the 4070 and 7900 xtx & 9070 xt seems rather low on the chart doesn't it? Can it really vary that much where you see like 10% gains in other games and +100% in some as well to balance the scale so the chart makes more sense?",
      "Someone broke the NDA.",
      "if the 9070xt releases at $599 or lower its easily the best buy in that price range. With all of the bs surrounding the 50 series launch AMD has a huge moment here that could gain meaningful market share.",
      "I've noticed alot of people saying \"650 is a good price and I'll buy it\".... Those are the same people that will say AMD missed the opportunity to not miss an opportunity when the card releases\n\n650 isn't a good price, it's DOA, 100$ off the competition when the 5070ti eventually comes back down in price is not enough, we've seen that before and it failed, 7800xt vs 4070,  the 7800 was better than the 4070 in except RT and Upscaling tech, but people bought the 4070 anyway. The 4070S came and its actually the better buy when it's at msrp\n\n650$ gives their AIBs the chance to bump prices close to the 5070ti... And we all know no matter how many times Nvidia screws the customers, everyone still buys them anyway. This price affects the products down the stack as well, what's the 9070 going to be priced at? 20% less than the xt? That's close to a 5070, and the general consumer market would just buy the 5070 anyway because of the brand\n\nThese performance numbers, are somewhat impressive, but then if the price is still just 100$ off Nvidia, it's good as dead.",
      "While DLSS 4 is amazing, FSR 4 is supposed to be still pretty good, much better than before. If the AMD card is $100-150 cheaper or more, it‚Äôs the better value for most people (if these rumors are accurate). It‚Äôs faster natively than the 5070Ti, and only falls (slightly) short in RT, but not by a CRAZY margin it seems. With 5070Ti barely in stock and at $900+ when it is, the 9070XT at a rumored $650 would be a STEAL. Even at MSRP $750, 9070XT would be a good deal at $650, but no higher.",
      "Yes the relative performance between two products can vary a lot. Especially when they're difference architectures.\n\nYou can see that in the OP videocardz article where the 9070 XT is allegedly anywhere between 23% and 68% faster than a 7900 GRE. Or in [RTX 5070 Ti review](https://www.techpowerup.com/review/msi-geforce-rtx-5070-ti-ventus-3x/35.html) where the 5070 Ti is anywhere from 15.9% slower than a 7900 XTX to 32.3% faster than the 7900 XTX.\n\nAlso the variance is a little lower than you're assuming:  \n\nIn the case of GamersNexus review, the RX 7900 XTX Nitro+ is 80.4% faster (211.8/117.4) than the RTX 4070 FE in FFXIV.  \n\nIn the TPU review the RX 7900 XTX is 51.5% faster (100%/66%) than the RTX 4070.",
      "The ‚Äúrumored‚Äù price is bullshit.\n\nAMD doesn‚Äôt set the price until right before it is announced."
    ]
  },
  {
    "brand": "amd",
    "generation": "7000",
    "tier": "high",
    "matched_keywords": [
      "7800",
      "7900 gre"
    ],
    "title": "AMD Radeon RX 9070 series to have \"balance of power and price similar to the RX 7800 XT and RX 7900 GRE\"",
    "selftext": "",
    "comments": [
      "> Rdna 4 cards will not be priced at $300 but will also not be $1000\n\nGee thanks for confirming 2 prices that nobody thought the 9070 xt was gonna be lmfao. Next they'll tell us that the 9070 xt was also not gonna be $900",
      "‚ÄúHappy to share more details today such as that it will cost money, and will also go into your computer. The GPU will require power.‚Äù",
      "I'm done with this mental masturbating about the card. It's ridiculous.",
      "It might even take up physical space!",
      "They definitely pulled the announcement after they realized $649 wasnt going to be a viable price for the card lol",
      "This has got to be the weirdest gpu launch in history. Never in my life have I seen a company refuse to announce their new gpu generation yet they simultaneously deny all the rumors floating around their gpus while not providing any information about them whatsoever. Won't give you specs, won't give you pricing, won't give you a release date. On top of that, even confusing their board partners that rdna 4 wasn't officially announced and not telling them why to the point their board partners just reveal their new gpus themselves. What a rollcoaster.",
      "If it just replaces 7800xt - 7990gre price/performance then it‚Äôs pointless. People will just buy 5070‚Äôs",
      "He wasnt saying that the new cards were performing like 7800 XT and 7900 GRE, he was trying to say that the performance per dollar or how much power u get for every dollar u pay would be similar. Relative to those cards when were launched back then.\n\nEven if he says that, we have to wait the price and the performance.",
      "That doesn't change the fact that this launch is a giant clusterfuck. I'd be pretty mad if I was one of the board partners who flew down to ces to show off my partner model cards just for them to not announce rdna 4.",
      "If this thing isn't <499 it's going to be DOA. Even at 499 it'l be a stretch when you can get a 5070 for $50 more.",
      "From amd view they don't know the real performance of the 5070 other than nvidias marketing claims. They are deciding if it should be $50 or $100 cheaper with the vram advantage",
      "Reference at 480, AIBs 500. Performance will be approximately equal to the $550 5070 barring frame gen: higher raster, lower RT, but not far off on either. That's what I'm calling.\n\n\nReviewers are wise and will be looking for exactly this attempt to manipulate price/performance. Despite this, AMD will spend the next almost two weeks fighting with itself and ultimately miss the opportunity, as it always does.\n\n\nProve me wrong AMD, I dare you.",
      "Leaks have CONFIRMED that the 9070XT will be a GPU.",
      "oh shit, I've only cleared some mental space",
      "The whole event was such a clusterfuck of glazing AI it felt like an investor meeting not a consumer show.",
      "Fucks sake people gotta STOP LISTENING TO FRANK AZOR.\n\n\nI honestly don't know what that man's employed to do! He never says anything useful or even accurate. He's been a major public face of nearly 5 years of botched launches and receding market share...\n\n\nWhat's the fucking point of him? How does he manage to clog up the tech news cycle every year when he isn't trustworthy?¬†\n\n\nDo people interview him because they haven't read his previous interviews? Is it just because he has a title that should mean something?",
      "AMD still probably has no clue how to price their MSRP",
      "I bet they wanted to sell it for like 700 bucks until they saw leaks of 5070 being priced at 550, and now they can't figure out what to do  \nEdit. Feb 28 2025 looks like they figured it out haha",
      "I think they were expecting nvidia cards to be more expensive. Thats what all the leaks were suggesting. But the 5070 series ended up being $50 cheaper than last gen.",
      "It would show the 5070 is nowhere near the 4090 like they claim. Gotta keep that lie alive as long as possible."
    ]
  },
  {
    "brand": "amd",
    "generation": "7000",
    "tier": "high",
    "matched_keywords": [
      "7900gre"
    ],
    "title": "After 9070 series specs leaks, here is a quick comparison between 9070XT and 7900 series.",
    "selftext": "[7900XTX\\/XT\\/GRE \\(Official\\) vs 9070XT \\(Leaked\\)](https://preview.redd.it/zzkyaed2akde1.png?width=1856&format=png&auto=webp&s=27ea1619fbf4fe055753420f5e8726de1698bcd0)\n\nOverall it remains to be seen how much architectural changes, node jump and clocks will balance the lack of CU and SP. \n\nPersonal guess is somewhere between 7900GRE and 7900XT, maybe a tad better than 7900XT in some scenarios. Despite the spec sheet for 7900, they could reached close to 2.9Ghz as well in gaming.",
    "comments": [
      "Interesting, still waiting to replace my 1070ti for 1440p gaming. Undecided between 9070 XT or 5070 TI, definitely need at least the 16GB of ram for some future proofing. The 5070 regular sucks.",
      "All the missing compute units agains the 7900XT are replaced with clocks. So that is the bottom line. Now it remains to be seen how the architectural improvements impacts performance.",
      "I'm also waiting to decide between these two cards, my focus is raster performance in 1440p gaming.",
      "keep in mind that historically the higher CU count does not scale very well with AMD. If you compare 7800XT with 7900XTX thats 60% more CU but results only in 44% higher performance. 7900XT has 40% more CU and 28% more performance. The sweetspot always seems to be around 64 CU (Scaling from 7700XT to 7800XT is way more linear).\n\nAlso RDNA3 used Chiplets while RDNA4 is monolithic. Performance might be 5-10% shy of an XTX. It comes down to architectural changes and if the chip is not memory starved.",
      "I bet AMD did something to make these additional ALUs more useful. Something like adding more register space and extending the types of instructions the second set can perform to allow for single-cycle Wave64 execution more often.\n\nHaving less CUs also means having less scheduling overhead btw. I believe one of the reasons the command processor in flagship RDNA3 clocked higher than the shaders was because of such overhead.\n\nAnyways, the rumored 390mm¬≤ seem considerably large for a die with just 64CUs and a 256bit memory interface. Something in that chip is needing tons of space and I don't think it's the fixed-function units or shaders (although the latter are probably less dense than usual to allow for higher clock speeds).\n\nI can't wait to see the architecture reveal and test results from reviewers - I love seeing how these technical aspects affect performance.",
      "I mea, the 7800XT can match the 6800XT despite having 12 fewer SM's. So it is possible.",
      "Sumilar raster, weaker rt.",
      "Sure cause we all know it's impossible to OC+UV new cards.",
      "A 7900 XT can do 2,9Ghz quite easily while gaming (will draw 380W tho) in synthetic benchmarks it breaks the 3ghz over 420W (air cooled) I‚Äôm still coping they bring at least a 9080 XT during Super release",
      "Isn‚Äôt the 7900xtx sufficient for native 1440p ultra wide? There‚Äôs no need for upscaling",
      "Clocks can't solely compensate for missing SM/SP. I'm hoping the node change/monolithic design adds something. The performance is definitely going to be between the 7900GRE & 7900xt. Hoping it's closer to the 7900xt.",
      "Are 7900xt/xtx even the right comparisons? These are the lower end of rdna4 reworked to be suitable stand-ins until udna. Aren‚Äôt they even monolithic like rdna2 and small rdna3?",
      "why would someone buy 7900xtx or 4800 super to play at 1080p? I think comparing at 4k is more relevant",
      "Not cheap anymore after 20 Jan.",
      "It's because if someone is paying $1000 or more for a gpu they'll just go Nvidia.¬† People on the mid and low end are more willing to go with amd because of the price to performance.",
      "2-7% faster depending on the outlet/games used.",
      "Any idea how it might compare to a 6900xt? That's what I would be upgrading from.",
      "Also between the two for 4k, and we still have yet to see any verified independent benchmarks for either card. For me its gonna come down to how much value the 9070 xt is gonna have over the 5070 ti, and how FSR4 and DLSS4 compare to each other.",
      "That's where I'm at also, very curious how this will perform and the cost.  Flying to the US next week as well! Land of \"cheap\" PC parts.",
      "First of all isn't it basically what I said? The difference increases as the resolution does. 1080p Numbers for 4080s and XTX are the least useful numbers you could find."
    ]
  },
  {
    "brand": "amd",
    "generation": "7000",
    "tier": "high",
    "matched_keywords": [
      "7900 gre"
    ],
    "title": "AMD Radeon RX 7900 GRE reaches End-of-Life",
    "selftext": "",
    "comments": [
      "I bet the 7900XT would've sold a lot better if AMD released it with a good MSRP.\n\nInstead the 7900XT was trashed by reviewers for being overpriced at $900, then after a few months the price of it was dropped anyway because of lack of sales.\n\nMany people only watch day 1 reviews of products so despite the 7900XT being a good card, many people didn't buy it and instead chose the 4070ti or 4080 for their rigs.\n\nSame thing happened with 7700XT's $449 MSRP\n\nAMD need to dramatically improve their product launch strategy going forward.",
      "Isn't the title kinda clickbaity? EOL means end of drivers support while the card is just rumored to be stop being produced.",
      "This seems to strongly suggest the 8800XT will likely perform around the GRE at a lower price.",
      "100%. Discontinued != End of life",
      "Idk, seems to suggest to me that navi 31 is expensive and they want to quit making it altogether. I wouldn't be surprised if it's just a bit faster than the 7800xt though. Almost the same number of cores, it would be depending on architectural improvements and clock speed bumps. If it hits 7900xt levels of performance with better ray tracing for 600 then idk I guess that's a win. But if you don't really care about ray tracing then you could have gotten a 7900xt for 650 back at mid year prime day. AND it has more vram.",
      "Interesting, considering the RTX 4080 was $1199 at launch. If people chose that card over 7900XT, it wasn't really about price, as even the XTX was $200 cheaper. The 4080 Super was priced similarly to 7900XTX.\n\nHowever, the price of 7900XT was certainly artificially high to push buyers into the XTX for \"only $100 more.\" I think that was AMD's primary mistake.\n\nNvidia has consistently shown that consumers will pay higher prices, but only if they're getting the very best performance and features on the market (something AMD can't claim when RT is enabled).",
      "> Whats funny about the 7700xt is the release price point was exactly what everyone was asking for. Then complained about it. I know, made an entire rant post about it at the time.\n\nNo one was asking for GPU that is depending on resolution 15-20% slower than 7800XT to be priced only 10% less.",
      "Farewell price-performance legend",
      "I'll be honest, I watched the Hardware Unboxed video about RT noise \nhttps://www.youtube.com/watch?v=K3ZHzJ_bhaI\nand most of the time I thought \"Am I dumb? Because I can see the images are different, but I can't say that the RT ON side is actually better or more accurate?\"\n\nThe rest of the time I felt that RT ON just made things way too fucking shiny.",
      "That‚Äôs a very revisionist perception of how that card‚Äôs launch went down. People were saying $450 was too high and too close to the 7800XT‚Äôs price before the card even launched",
      "I agree. For a massive performance hit too. I'm quite content with much higher frames than having RT.",
      "And it‚Äôs turned on by default and cannot be adjusted. It‚Äôs been extremely optimized by the devs so it runs and looks beautiful even on AMD cards! I have a 7900XT and Indiana jones looks incredible with ray tracing and it runs buttery smooth.",
      "7900 GRE is the best all round card of this generation IMO. I‚Äôm biased because I bought one but that‚Äôs the reason I bought it. I think I got it for $550 (plus tax).",
      "ur not feeling ur dreaming, amd will never do that unfortunately",
      "I don't really agree. the 7800xt at 500 looked alot better than the 7700xt for 450 at launch. the price to performance was significantly worse on it and 10% more for 25% more vram and 18% more 1440p speed is very substantial. Really it should have been 400 at most it would have gotten really good reviews at like 350-380. The 7800xt and the 7900gre were the only rdna 3 cards that had a decent launch price I think.\n\n\nThe sales since then have been pretty good with the 7900xt especially but the launch prices have really hurt amd imo I think it costs them money and pisses off consumers at the same time. The current people deciding the pricing structure have zero idea what good reviews and word of mouth marketing is worth. They are picking up pennies and losing dollars with the high release price strategy. Ironically Nvidia is the one who should be doing that on the 90 tier cards but they don't. They let them get scalped for months and never drop prices even 2 years later.",
      "Whats funny about the 7700xt is the release price point was exactly what everyone was asking for. Then complained about it. I know, made an entire rant post about it at the time.\n\nAS for the 7900 series, yeah it was over priced at launch. I got my 7900xt for 739 open box. Couldn't be happier. But I had someone here tell me that even at 739 a 4080 at 1100 was a better deal.",
      "Very happy with my sapphire nitro+ version,lovely card in every possible way",
      "The 8800XT performing close to a 7800XT would be extremely disappointing, it would be the third time AMD releases the 6800XT basically.",
      "RT needs framegen and or upscaling, in almost every case. So you increase fidelity then throw it out the window with visual artifacts, what's the point? Too costly and too soon.",
      "You are not losing much fidelity unless you are going with performance or ultra performance on DLSS."
    ]
  },
  {
    "brand": "amd",
    "generation": "7000",
    "tier": "high",
    "matched_keywords": [
      "7800"
    ],
    "title": "RX 7800 XT massively outsold GeForce rivals in Q1 2024 on German retailer reportedly helping AMD take share away from NVIDIA",
    "selftext": "",
    "comments": [
      "As mentioned many times before, Mindfactory data is mostly for the DIY segment, which is small within the PC market in general.\n\nAMD could be outselling Nvidia 2-to-1 in the DIY space and still be losing market share because most PCs are either laptops or prebuilts.",
      "AMD is however gaining market share in the general AIB market: https://www.jonpeddie.com/news/shipments-of-graphics-add-in-boards-increase-for-third-quarter-in-a-row/\n\nThey went from 12% to 19% of the market from Q4 2022 to Q4 2023, and their total unit shipment more than doubled (+117%).\n\nSo while Mindfactory isn't representative of the total market, the title isn't wrong about AMD taking away market share from Nvidia.",
      "Time for the monthly mindfactory stats to pretend Radeon is taking the market by storm?\n\nIt's like the computing equivalent of the \"UK console retail sales charts\" not real useful for extrapolating to a much bigger global market.",
      "I was one of the people buying it.\n\nPretty easy, there were many deals for the 7800XT in Q1. I bought mine for 430‚Ç¨. 7700XT were going for 320. even 7900GREs where 520",
      "Unless these rogue purchasers of AMD cards all collectively refuse to use Steam hardware survey or aren‚Äôt using Steam altogether then the end market share result has remained largely steady over the past two years. Shipments of boards looks great, but are there actually massively increased sales to match those shipments or are they pumping out more supply in a certain quarter to look good?",
      "These monthly Mindfactory threads are always the same. If it had any any meaning (it doesn‚Äôt) it would show RDNA 2 cards dominate steam survey. And well.. I‚Äôve got bad news Hans..",
      "people like being validated. This sub is one of the best examples i have seen in recent memory . Well this and ps5 sub",
      "Interesting sales figures, I'm interested in watching intel as they are going to increase market share in the next few years.\n\nI would also buy the 7900gre as here it's a similar price to the 7800xt and slightly better performance",
      "The most purchased 7000 series GPU loses out to the RTX 4050 mobile in sales by a factor of 2:1 per the survey, it‚Äôs abysmal.",
      "Thing with Steam survey is it includes all the currently in-use GPUs, not just recent sales. So while AMD may have increased marketshare YoY from 12% to almost 20%, the total number of cards added over that period is still small when compared against the entirety of the current Steam userbase.",
      "The only notable oddity was when it wasn't handling net cafes in Asia right so it was popping repeatedly for the same machines as diff people used them. Also when certain over-zealous fanbases tried to trigger the survey repeatedly to over-inflate their numbers. Both things as far as I'm aware have been fixed.",
      "Random sampling is a valid statistical method.",
      "[According to the IDC](https://www.idc.com/promo/pcdforecast), \"Notebooks\" which I assume is laptops because they don't clarify have outsold desktop by 2.5 times (18.5 million vs 47 million).\n\n\n\nEither way it's actually delusional to think DIY even makes a dent in PC and laptop sales, laptops are now becoming like smartphones while every statistics tracker claims desktops have been declining in sales for a decade before the pandemic.",
      "Another month, another Mindfactory thread. When will people learn? Mindfactory just sells more AMD stuff and it's one retailer in a sea of maybe hundreds of thousands of retailers and distributors across the globe.\n\nOnce you account for laptops, pre-builts, other markets such as Asia where NVIDIA dominates versus maybe Europe which is more AMD friendly, Net Cafes/PC Bangs, OEM Desktops, Small Office Machines, Servers, Professional Industry Computers, University Research Computers etc etc, NVIDIA just wins out the market because they ship more units and they've made an amazing software stack where AMD isn't competitive. \n\nIf you want to use Blender, NVIDIA's better. If you want to use DaVinci Resolve, NVIDIA's better. If you want to do AI, NVIDIA's better. If you want to use Adobe software, NVIDIA's better. If you want to stream, NVIDIA is better. If you want to game with RT, NVIDIA is better. DLSS is better than FSR. If you want to buy a laptop it's 90% going to have an NVIDIA dGPU. If you want to buy a pre-built, it's 70-80% likely to have an NVIDIA GPU.\n\nThe only area where AMD is doing well in pre-builts and the market overall maybe now is APUs (which they pretty much always have) and CPUs. Otherwise, their dGPU stuff is non-existent almost. It's so hard to find an RX 7600S laptop versus a 4060 one for example. I mean what do you expect? They're doing the bare minimum in GPU and sometimes Intel is upstaging them like with XeSS.\n\nTired of seeing these threads... \"Oh wow the 7800 XT sold 1,000 more units at Mindfactory than the 4070, surely AMD is winning!\" /s\n\nI wonder what the next thread will be \"7900 XT outsells the 4080 SUPER at Mindfactory\". Yawn.",
      "nice cope",
      "some of you need help",
      "What kind of question is that ?Should we add switch apus, data center and ai accelerators then too? Who will have more GPUs sold then in your opinion ?",
      "AMD is getting out of a 15 year market share [trough ](https://cdn.mos.cms.futurecdn.net/3sbtBfoms2FNcG8wQCEiBA.png).\n\nUsually AMD has hung around 25-35% of market share. It hitting 10% in Q3 2022 is the lowest its been in 15 years. They're still deep in the hole compared to the late 2010s.",
      "I went from a 1080 to a 7900 GRE a few days ago. It kicks so much ass.",
      "I don't think they are refusing to do Steam survey, like I have my unit for more than 2 years (and had a previous Intel based laptop for 3 years) and only got the Steam hardware survey one time (this month). Previously I even thought that the hardware survey was done automatically to ALL units with Steam installed, guess not. \n\nSo while Steam hardware survey shows stats, it might be selective (especially sometimes when there is a sudden influx of Chinese users being surveyed lmao). I'd at least expect NVidia to at the minimum be 65% market share, probably 70%+."
    ]
  },
  {
    "brand": "amd",
    "generation": "7000",
    "tier": "high",
    "matched_keywords": [
      "7800"
    ],
    "title": "Possibly cheaper RX 7800 outperforms RTX 4070 by 5.2% while RX 7700 beats RTX 4060 Ti by 15% in leaked benchmarks",
    "selftext": "",
    "comments": [
      "Spoiler Alert: They won‚Äôt.",
      "If amd prices these right, it could finally be a W for gamers. Doubt it tho",
      "I mean how many times have we seen this?\n\nNvidia releases a shitty priced GPU -> \"Massive opportunity for AMD to seize market share at a given price point, if only they take it!\" -> AMD releases equally shitty priced GPU, just slightly cheaper  -> Wait for a year of constant price cuts for the said GPU to actually make sense -> New generation comes around -> Nvidia releases a shitty priced GPU",
      "So another way of saying basically within margin of error of the RX 6800 and RX 6800XT?  \nDoesn't sound as great if you put it that way right? lol",
      "Spoiler Alert: You'll probably have to wait 3-4 months",
      "These percentages are gonna mean basically nothing if they're not priced a lot lower then what they're competing with.\n\nThat 7800 especially is gonna have to be a good 100-150 cheaper then the 4070 to make a dent.",
      "RDNA2/RDNA3 cards do better in Timespy compared to their respective NV competition so this means nothing\n\nA 6800 XT for example easily beats a 3080 in FS/TS but they're similar in gaming (raster anyway)\n\nSame for 7900 XTX/4080",
      "It's idiotic that these didn't launch before Starfield. They get the sponsorship for arguably the biggest game of the year and they don't have any new cards in the most mainstream segment.",
      "Sad to see an 800 class competing for dirt with a 70 class. This gen is a giant failure for amd.",
      "Well, for nvidia too, 4090 being the only exception.\n\nThat nvidia's \"70 class\" is a 60 class with a new, fancy name.",
      "I mean 6800 XT performance at current 6800 XT pricing is closer to trolling than sensible imo.",
      "as if timespy scores matter",
      "No they didn't. And it worked with Ryzen. Way better product for cheaper.",
      "That's been the message for 3 years running. However, AMD never has. It's why Radeon doesn't see the success Ryzen did.",
      "it would have to be ¬£500 at the absolute highest to make sense",
      "5% for worse RT, worse upscaling, worse VR, worse power efficiency, generally worse software etc. it better be $100+ cheaper, or the 4070 is a way better buy.\n\nEdit: i agree adrenaline is better, but afterburner and rivatuner is better than adrenaline/geforce. So I dont really think thats all that relevant.",
      "yup! 4060 is actually 4050. dumbsterfire of a GPU gen.",
      "Which, in the end, isn¬¥t THAT long! But yeah, coming with the right price from the start would be so much better PR.",
      "It's definitely better than 6800 sounds like 6800xt performance clone but RT uplift.",
      "4080 bs 7900XTX -tie, AMD cheaper\n\n4070ti vs 7900XT- AMD win, AMD cheaper\n\n4060 vs 7600-  Nvidia win, AMD cheaper\n\nOnly one clear performance winner although AMD is cheaper at each performance tier, however the market adds a premium for Nvidia RTX branded technologies over Radeon RX technologies"
    ]
  },
  {
    "brand": "amd",
    "generation": "7000",
    "tier": "high",
    "matched_keywords": [
      "7800xt"
    ],
    "title": "Bye Nvidia, Hello AMD (1080ti ¬ª 7800xt)",
    "selftext": "My local Canada Computers had 1 nitro + left in stock and I managed to sell my 1080ti for a great price!",
    "comments": [
      "Props to that 1080ti for putting in one hell of a shift. 10/10, best consumer GPU of the last 10 years.",
      "Check your Canada computer receipt for a code to get some free games.¬† I got Warhammer 400k Space Marine 2 with my 7800xt",
      "Definitely. That thing is still a beast to this day!",
      "The 1080 series was just so damn good, I just had someone recycle a 6700XT that I'm getting ready to retire my 1080 for it lol",
      "Yea I saw that offer and got them as well. Super happy with it! Can't wait for Unknown 9 Awakening, it looks really promising. In the meantime, I'll be playing my first ever Warhammer game!",
      "Wonderful card, made similar switch 2 years ago to a 6800XT, had the 3080 in mind but the combination of higher price and actually going down in VRAM from the 1080Ti felt insane so I jumped on the AMD card. \n\n Enjoy!",
      "Been really happy with my 7800xt\n\nRuns cool , all things considered.\n\n\nMy only complaint \nThe 7900 GRE came out a few months later. \nWas supposed to be a china only thing. \n\nOtherwise I would have gotten it probably. \n\n\n\nThere was one driver hiccup. Which AMD admitted to. \nI just had to roll back to previous version and was fine. \n\n\nYa it doesn't have the best Ray Tracing.\nBut there's nothing I play that uses it anyways.\n\nLooking at adding it to my water-cooling loop on my time off over winter.",
      "The 6700/6750 are so great, best bang for the buck at that price range, especially with new games needing VRAM.",
      "1080ti aka the G.O.A.T",
      "AMD will make high end GPUs in the future, don't worry, they just stated they would not for this specific launch.",
      "I have nothing against Nvidia. If it weren't for the price I wouldn't mind going for either brand. I love their GPUs.",
      "i have a 7900xt that‚Äôs tuned pretty aggressively and i haven‚Äôt ever experienced any stability issues personally",
      "I just bought a 7800xt yesterday.   It will be here Wednesday.   It's replacing my 1080ti liquid cooled.",
      "Dude I have had a 7800xt for a year now.\n\nZERO issues.",
      "I got a 6700 XT. It's awesome. Quite a night and day difference from my old RX 480.",
      "I wish Iv got WH40k. When I bought my 7800 XT new Avatar was gifted and this game is trash ngl üòÇüòÇ",
      "Those Sapphire Nitro's are such beautiful GPUs",
      "Why?",
      "According to several benchmarks (I've been looking at Tom's Hardware in particular) the basic 4070 performs slightly worse at 1440p max setting compared to the 7800xt. It would be a downgrade. \n\nThe closest equivalent would be a 3090, 3080ti, or a 3080 12gb. The 4070 Super is a slightly better gpu than the 7800xt, but still closer in comparison than the basic 4070.\n\nNonetheless, any of those Nvidia equivalent GPUs are more expensive where I live, by at least $100. Definitely not a $70 difference lmao. At least not where I live.\n\nI already over stepped in my budget getting this variant of the 7800xt (originally I didn't want to go past $700). Where I live (Canada), the cheapest 4070 super is $799 (as of now). Paying $100 more for a <10% boost in performance and less vram is not worth it imo.\n\nYou also haven't mentioned why this card would be less stable down the road compared to an Nvidia card. You're just trolling atp.",
      "Could your 5800x3d stand a cooler upgrade? How are temps?"
    ]
  },
  {
    "brand": "amd",
    "generation": "7000",
    "tier": "high",
    "matched_keywords": [
      "7800xt"
    ],
    "title": "AMD Radeon RX 7900 XTX now available for $849, Radeon RX 7800XT drops to $449",
    "selftext": "",
    "comments": [
      "Still not cheap enough.",
      "7800 XT is well priced, though would've been great if it had been that at launch, when fewer people cared about RT",
      "Not in EU lol\n\nIts still 1100$ and 4080S 1200$.....",
      "Meh, the 6800 XT was already sub-$500 when the 7800 XT launched. For minimal performance gain and a 3-year release gap, being the same price was crap. 10% off a year later also sucks.",
      "Another week another AMD consumer end price cut, luckily the economy is doing great and they're a data center company now...\n\nRight ?",
      "Oh look, the Nvidia fanboys are here already claiming the cards are still too expensive.\n\nWeird that I don't see that for the 4080 selling at 1050-1200 still and the 4090 going above 2000 again.\n\nI wonder how much Nvidia pays in marketing lol",
      "Always the same, US prices are without tax.",
      "I use two 7800xt in my ai home labs and they‚Äôre so, so good. \n\nWorth every penny.",
      "I think it‚Äôs odd that there was a brief window to preorder a Sapphire 7900xtx for around $830 soon after launch (with rebate) when the 4080 was going for $1300.  And the 7800X3D cpus were everywhere at list price (or cheaper at Microcenter). \n\nNow after all this time the price -just- drops to $850? And the X3D is sold out selling for higher? This has been such a weird cycle. The only time when the smart value move was to buy a video card and CPU at launch instead of waiting. This is so messed up.",
      "Amd is just being too stingy with their price cuts. It's absurd to me that they would rather price drop the 7900 xt to 660 one day, then the next day they drop it to 650. They need to stop playing games and just give them reasonable price cuts instead of just moving the needle slightly every day. It doesn't surprise me that nobody wants to buy amd gpus at this price, just give us reasonable prices and people would be interested.",
      "These prices are still pretty ass ngl. We're at the end of a product cycle for amd gpus. Nobody is really gonna want a mid level previous gen card when they can just wait a few months to buy current gen and the 7900 xtx is way too overpriced. Realistically it needs to hit at least 750 if not around the 700 for people to consider.",
      "AMD shot themself in the foot in a way that not even Nvidia did by having the 6800 XT available at essentially the same price and performance of the 7800 XT new. The 4060 Ti was marginally worse than the 3070 but about $100 (20%) cheaper. Both suck because they‚Äôre not offering what‚Äôs worth an upgrade Gen over Gen but AMD was particularly shitty with the 7800 XT.",
      "how much do you people think taxes are like srsly 849 x 1.2 is not $1100 and that's on the higher side of sales taxes üíÄ",
      "Exactly this.... Just that they are missing that Nvidia is restricting supplies to hike prices again üòÇüòÇüòÇ\n\nNvidia and discounts dont exist lol",
      "6800 XT is not available in most markets, it's been a clearance product for 2 years now",
      "Nvidia's bullshit isn't justification for AMD's. They can both eat crap for this generation.",
      "People have been calling Nvidia cards overpriced since they launched. The 4090 at $2000 is just atrocious but at least it has value in ML applications. The 4080 super being $1200 is just shocking. \n\nThat doesn't stop the AMD cards also being overpriced also",
      "I'm not surprised that we got another price cut tbh. This is like the 3rd or 4th price cut this week. They have a lot of old inventory just sitting on the shelves that no one is buying. On top of zen 5 flop amd is desperate to sell people anything. Their 3rd and 4th quarter earnings for 2024 are gonna be horrendous.",
      "Well idk what they mean with not in the EU, because you can get a XTX for 880 euro in the Netherlands, which is 966 dollars, and that's with much higher taxes than in every US state.",
      "EOL is end of life - no more support. They will be supported for years. The term that you‚Äôre looking for is EOS - end of sale. Like the 6900 XT before it discounts will come until stock is gone. Time to make room for next gen."
    ]
  },
  {
    "brand": "amd",
    "generation": "7000",
    "tier": "high",
    "matched_keywords": [
      "7900 gre"
    ],
    "title": "AMD reportedly discontinues Radeon RX 7900 GRE",
    "selftext": "",
    "comments": [
      "RIP sweet prince. While the 7800xt was better value, at $519 the GRE was an incredible proposition for 1440p high refresh",
      "8800XT probably uses a smaller die than *just* the N31 GCD and doesn't need any special packaging and almost certainly dumpsters GRE in performance and efficiency. Hell, N48 probably costs less than 7800XT to make lol. The cutdown 8800/8700XT is probably the new value champ without even seeing it",
      ">AMD won't fuck up on this gen and will launch at a very competitive price.\n\nAMD: *hold my beer*",
      "Must mean that Navi 31 has ceased production a while back. Surprising then how many 7900 XT and XTX cards not yet sold.\n\nImagine the pressure a 499-599$ 8800XT perf \\~4080 puts on existing stack,",
      "> Hell, N48 probably costs less than 7800XT to make lol. \n\n  This is the major source of my hope that AMD won't fuck up on this gen and will launch at a very competitive price.",
      "Nvidia mind share is way too strong.",
      "Yep that was a good card.\n\nAnd I'm very happy with my 7900xt deal: I bought a used 6800xt for 450‚Ç¨ 2 years ago, and switched that for the 7900xt with a 300‚Ç¨ on top(private seller but new card)\n\nEssentially paid 150‚Ç¨ for renting the 6800xt for 2 years.\n\nI guess I'll do the same with the 7900xt - who can justify paying 600+ on a GPU? I certainly can't, hence the used GPU deals.",
      "Depends on game but at 1440p, seems  to be anywhere from 10-15 percent fps gap, stock. Based on GamersNexus testing",
      "My prediction is that they're going to look at the 5080/70ti or whatever Nvidia card it's closest to in raster, subtract $50-100, and call it good. \n\nThen in 2 months when the price drops by another 10% or whatever it actually becomes a good deal.",
      "This just means it‚Äôs no longer being manufactured. It‚Äôll still get driver updates as usual.",
      "If people go for a 12GB 5070 then their mind sure needs checking.",
      "Wow I just got it in October lol",
      "SO THIS IS WHY I HAVEN'T BEEN ABLE TO FIND ONE?!",
      "XT more likely",
      "Yeah, it‚Äôs getting ridiculous now. Should be 16gb for sure.",
      "While it helps that, I think they just ran out of bins for it, and Navi 31 is OOP.",
      "They did this months ago without saying anything until now",
      "https://www.techspot.com/articles-info/2812/bench/1440p.png\n\n\n1% lows is what I'm looking at.¬† But yeah, had the chance to get either and I ended up getting the Rx 7800xt instead (was on sale for a great price. 670$CAD).",
      "Navi 31 is terrible for AMD. The cost and complexity is just not good from a business point of view. It's done.\n\nExpect AMD to abandon it ASAP like Radeon VII and replace it with something slightly lower in performance like Navi 5700XT.",
      "Yeah, no way its going to match the 7900XTX.     \n96cu vs 64cu.     \n384bit memory bus vs 256.    Both using GDDR6 so cant really compensate with much faster ram. \n\nHopefully it matches 7900XT, but imho a more realisticly place would be somewhere between 7900GRE and 7900XT."
    ]
  },
  {
    "brand": "amd",
    "generation": "7000",
    "tier": "high",
    "matched_keywords": [
      "7800"
    ],
    "title": "Leaked Radeon RX 7800 16GB TimeSpy Score Shows 17% Improvement Over Last Generation's RX 6800",
    "selftext": "",
    "comments": [
      "The 6800 feels like the forgotten GPU in the 6000 series lineup. Everyone talks about the 6750XT, 6800XT and 6950XT but never the 6800.",
      "I think you forgot the long lost 6700 10GB",
      "So weaker than my 6800xt",
      "I have the 6700. It really is the forgotten child of amd. Runs great at 1440p and has 10gb too. It basically the 7600 but with a bit more power and more vram",
      "This whole gen has been incredibly mediocre for AMD. Between the bad efficiency (especially compared to RTX 40), underwhelming uplifts in raster and RT, and major driver issues with power draw and VR I don't know how anyone could go for an RDNA3 card until they're heavily discounted.",
      "It's rarely worth upgrading just one generation anyway, unless you consciously bought the bottom of the stack of one generation with the specific intent of buying the top of the next.\n\nRX6800 is a fine 16GB card and will last you a while yet.",
      "$549 is way too much for this when there is a 4070 which is regularly cheaper with bundles. Given how atrocious upscaling and drivers have been this series, this should be considerably cheaper for it to be viable‚Ä¶ but hey, literally every new gpu from any manufacturer is shit value.",
      "Yeap, that's the reason they'll market it as \"7800\" not \"7800 XT\"  \nPeople would riot otherwise",
      "Think I'll just hold onto my RX 6800 for a while longer. I really don't see a huge reason to upgrade this generation from either Nvidia or AMD at this point.",
      "Fellow 6700 user. Got it 260 brand new and it‚Äôs great! Can even do 4k on older titles with a little settings tweaking or fsr",
      "That's because for a while the 6800 was going for 480$ with the XT at just 30$ more",
      "The 6700 is what the 7600 should've been. A 10 GB 1080p high performer that can dabble and dance in 1440p pretty decently\n\nEdit: accidentally typed 4k instead of 1440p initially",
      "The worst part? It's hardly more efficient and just not worth the extra cost when compared to cheaper Navi21 options.",
      "You'd hope so. If it's anywhere near $600 then it would make 0 sense to get one over a 6950xt",
      "They did that with the 7600, and people still rioted.",
      "Yes, while consuming ~30-40W less power.",
      "The 6800 XT is a pretty big step up and isn‚Äôt that much more. It‚Äôs not as good of a value proposition as the others.",
      "the really ugly one is going to be 7700, where you're using almost as much N6 wafer area as a 7600 and then adding 200mm2 of N5P.  The MCM area overhead is atrocious.\n\nSo basically take a 7600 and then add three Zen4 chiplets worth of area, to slide performance upwards from 4060 to 4060 Ti performance.  Which it should edge past pretty easily ofc (4060 ti + 5-10%?) but it's gonna be a godawful deal for AMD.  Like I guess if it's 10% faster than 4060 Ti 8GB they do $429?  What an absolute waste of silicon from their perspective.  \n\nThere literally is not a number where that product is worthwhile - even at $499 it would be a waste of silicon for AMD compared to Zen chiplets.  And 7800 really needed to be sold for at least $600.  But the product performance just can't justify that.  This is Vega 2.0 where AMD is getting pinched by how poorly their silicon is performing relative to the established performance levels of the competition, and even AMD can't pretend it's an awesome deal at MSRP, but neither can they afford to go any lower on pricing.\n\nThat was when we saw the bundle deals (\"buy a GPU for $100 more than MSRP and get a coupon for $100 off a specific monitor nobody wants absolutely free, coupon expires in 30 days!\") and other crap kick in to shift ASPs upwards.  And even still, standalone MSRP was so low that partners couldn't actually make a profit on the cards they were ordering from AMD (\"made by AMD\" reference cards).  Everyone got real mad about that with NVIDIA a year ago, I think everyone forgot that was an AMD thing with Vega too lmao.\n\nI think the numbers have to be $499 for 7800 and $399 for 7700, *maybe* they will try for $529/$429 to squeeze a couple more bucks but at $450/$550 they are DOA.  DLSS alone is worth 10% to me.",
      "Cheapest 4080 I see right now is $1140. Cheapest XTX is $960 looking on Amazon and Newegg. So for $180 more I get a significantly more efficient card with better RT, DLSS3, and CUDA. Wouldn't be a hard decision for me to go for the 4080 if I was deciding between the two.\n\nAMD is delusional with their pricing this gen or maybe they just don't care and know they won't sell much at their current prices and are ok with it as long as the profit margins are high.\n\nNvidia is also delusional with their pricing this gen but at least they have a good line of cards and people justify paying more for the better features.",
      "AMD didn't charge $400 for a 8GB card, which is what they taunted Nvidia for."
    ]
  },
  {
    "brand": "amd",
    "generation": "7000",
    "tier": "high",
    "matched_keywords": [
      "7800"
    ],
    "title": "AMD Radeon RX 7800 XT GPU Review & Benchmarks vs. RX 6800 XT, RTX 4070, & More",
    "selftext": "",
    "comments": [
      "Happy with my recent 6950xt purchase",
      "My decision to buy the 6800XT last year is looking better and better.  This is no doubt the best price/performance AMD has released this generation, but the lack of generational uplift is disappointing.",
      "Guess I‚Äôll be sticking to my RX 5700 XT or finding a 6000 series replacement.",
      "People calling it Trash are mostly correct. Its not a great card for its price. \n\nWhen compared to its Nivida equivalent? Its ALOT better. Can't wait to see nvidia sell 4 for every 1 AMD sells",
      "So mostly the same performance to last gen but costs slightly less and consumes less power",
      "It seems like it should have been the 7700xt, with the 7900xt being a 7800xt, and 7900xtx being a 7900xt.",
      "Just bought a 6950XT as well, working wonders in Starfield",
      "I'm guessing most people expected a better generational uplift over the 6800XT.",
      "I know the price is okay in the USA, but here in Australia, it's not that great. \n\nA 7800 XT the cheapest I can find as of writing is $879 AUD, that's converted to USD with tax included ~$561 USD which is about right once you add 10% GST/VAT and maybe some extra fees for being shipped to a penal colony. \n\nThe cheapest 4070 is like $889 AUD. So yeah the 4GB of VRAM extra is nice, but the RT performance, DLSS and other features like NVIDIA Broadcast and just general driver stability or rendering performance keep the RTX 4070 lingering around as an option. The $100 pricing gap between the 7800 XT and the 4070 in the USA is basically not really a thing here.\n\nThe 7800 XT desperately needs a price drop here in Australia to be a relevant purchase. A good $80 AUD price drop puts the 7800 XT into a spot of consideration. But then I remember that a used 6800 XT goes for around $650 AUD, so unless you really use RT or want AV1 can't see a reason to buy a 7800 XT.\n\nAnother AMD graphics card release, another dead on arrival product here in Australia.",
      "and improved RT performance, and AI Accelerators, and AV1 encoding.",
      "Spoiler: he wasn't that happy.",
      "Forgot about the 4060 Ti already? It didn't even have cheaper MSRP",
      "I had been looking at buying a 6800xt but now with the 7800xt out, I might just do that. Sure, they're comparable in performance, but the 7800xt seems to win in the power consumption category. Maybe I'm in the minority here but that actually matters to me.",
      "Nvidia is our best friend. We dont talk about issues, because they dont have any and never make mistakes.\nAlways the best choice for gamers!",
      "Hubs video too. No significant change in performance. Thanks amd for blessing us with this massive W today. Same performance as last gens card something I have not seen on either nvidia or amds side in so long but hey. It's just $15 more expensive than last gens card so that's good ? Maybe...? I'm so fucking upset how did we get to this? Maybe by the time we get a 9800xt it might be a slight improvement who knows",
      ">it's $499 and runs as fast as a 4070\n\nSure, that's one way to look at it.  The other way is that it runs like a 6800XT for the price of a 6800XT.  Not saying that's bad (at least compared to the competition), just not very exciting.  People want generational uplift and this has essentially none.  If you have a mid-range or better card from last generation, there is nothing for you here.",
      "I just bought one after looking at the reviews. Also an important point is that 6800xt performance uplift via drivers is likely not going to happen anymore but 7800xt is likely going to get quite a few driver updates that improve performance. \n\nPlus I have seen reviews from 3 different sources running sometimes the same games and where Steve was getting better performance on the 6800xt the other two were getting equal or better performance on 7800xt. \n\nImportant thing to note, Steve was running the stock version of 7800xt vs sapphire nitro+ version of 6800xt. Jayztwocents was running the same version of two cards(red devil powercolor) and 7800xt was showing better results vs 6800xt. \n\nAnd I was hoping for exactly this, similar performance for less power draw and same price or cheaper. And it is in UK same price or cheaper.",
      "In theory, yes. But honestly modern cards tend to really struggle with OC's compared to older cards. The way they boost is just pretty aggressive out of the box. I think very few people get meaningful OC's on any 5000/6000/7000 series cards.",
      "AMD has no shame anymore.",
      "5700 XT ain‚Äôt enough for 1440p in modern titles without FSR or cutting back significantly on settings."
    ]
  },
  {
    "brand": "amd",
    "generation": "7000",
    "tier": "high",
    "matched_keywords": [
      "7800"
    ],
    "title": "AMD announces Radeon RX 7800 XT 16GB and RX 7700 XT 12GB graphics cards - VideoCardz.com",
    "selftext": "",
    "comments": [
      "The RX 7700XT has a much higher CU count than anticipated. A lot of people were expecting 48CU.\n\nIt will all come to the price now. Those cards are not bad on paper but the price will decide everything.\n\nIf priced between 399 and 429 USD, the 7700XT could be a killer. There is a performance gap with the 4060Ti so they could charge it higher, but with the memory deficit it would be hard to justify.\n\nThe 7800XT is really in a weird place though. 499 USD could be really good. 549 would be meh.",
      "Specs on the 7700 XT look better than expected. The fact that they are positioning it against the 16GB 4060 Ti, a $500 card, doesn't bode well for the price though.",
      ">If priced between 399 and 429 USD, the 7700XT could be a killer.\n\nTo be honest I don't see that happening based on the slides in that news article. They are comparing the 7700XT to the 4060Ti 16GB, so $449 for 7700XT is more in line with that.\n\nEDIT after the prices were announced:  \n$499 for the 7800XT seems OKish, but $449 for the 7700XT is ROFL pricing. It says in EU the prices will be 549 es 489 respectively and right now you can still get the 6800 for 459 and 489EUR which seems like a significantly better option than the 7700XT.",
      "Its gonna be ~450 and ~550\n\nThere is a reason why they compared it to a $500 and $600 card.\n\nIf it was $500 for the 7800xt they would have compared it to the 4060ti 16 directly .",
      "AMDs marketing department is unhinged. I'm guessing $479 and $579 right now.",
      "Disappointing that 7800XT=6800XT in terms of performance. Pricing at 449 to 499 dollars would be ideal but knowing AMD they will price it at 549 or similar which is terrible compared to a 599 dollar 4070. The 4070 has all those extra features.\n\nFinally some generational per CU performance improvement.\nThe 60 CU 7800XT is matching 72 CU 6800XT. Not much but it's there.",
      "That's actually fine if you suitably reduce the prices across the board\n\nFor eg. A 7700xt at 429 or something with 6800XT level of performance.\n\n7600XT at 299 with 6700xt level of performance. That way even if there is no performance improvement you reduce the prices low enough that lower tier cards can enjoy higher tier of performance for the same cost.",
      "7700 XT actually seems interesting, if it really is 12% faster than a 4060 Ti that puts it around 20% ahead of 6700 XT, not an impressive gen to gen performance gain but way better than 7800 XT's literal similar exact performance compared to it's predecessor 6800 XT which is an oof 4060 moment for AMD.\n\nNow, it just depends on the pricing, if 7700 XT is priced at over $400 then it is disappointing, same can be said with 7800XT if it is priced over $500.\n\nIdeal pricing should be:\n\n**7700 XT:  $400 or less**\n\n**7800 XT:  $500 or less**",
      "AMD will *technically* undercut, just not enough to matter.",
      "All cards this generation are worse value than previous generation honestly. But at 399, it might be equal value (in terms of FPS) depending on how much more performant it is than the 6700 XT. At the very least, 6700 XT is better value because AMD themselves made it so by reducing it up to 25% from what it was in January.",
      "At 399 it's just... worse value than the 6700xt? Same amount of vram, uses slightly more power, bit better performance, but it costs way more?",
      "It is the same though. Sure no one with a 6800XT would ‚Äúupgrade‚Äù to a 7800XT, but if they price it exactly at or above what the 6800XT is available at right now, then why did those ‚Äúnew people‚Äù wait? \n\nThe answer is they were waiting for 6800XT performance for 6700XT price or less, because that‚Äôs the precedent for the past decade or more. Improving energy efficiency and keeping the price the same while shouting ‚ÄúINFLATION!‚Äù isn‚Äôt good enough to justify these cards‚Äô existence - especially not when RAM chip prices are way down, AMD is building these on a mature previous gen node, and while they‚Äôre not breaking record profits, they‚Äôre still more than profitable and being down 18-20% from the COVID spike is misleading at best. \n\nIf the XTX had simply been the 7900 XT and everything else got bumped down a tier, this lineup would look great. A 7700XT (current 7800XT) with the performance of a 3080 12GB or 6800 XT for $450? Awesome! Positive momentum and genuine reason to justify a purchase or recommend. \n\nInstead we got the ‚ÄúBiff is King‚Äù timeline, but without real hoverboards.",
      "If it‚Äôs true that the 7800 XT more or less matches the 6800 XT in performance, I genuinely wonder what AMD plans to do to fill the gap between that and the 7900 XT. There‚Äôs quite a big performance delta between the two. I know the 7900 GRE exists, but are they planning on giving it a wider release?",
      "my heart hopes you are wrong, but my brain says he is right....",
      "The radeon playbook",
      "No FSR 3.0 info in the slides so probably a no show. AMD must move on to next gen sooner rather than later if they hope to stay relevant in the gpu market. Nvidia has pushed ahead in RT and AI and AMD seriously needs to catch up.",
      "No, but if you were AMD, it would be wise to compare it to the 16gb card, because its priced so ridiculous. Here's hoping for $399 still.",
      "For new people? It's not \"the same\", it has similar performance but greater power efficiency and new feature sets.\n\nThis isn't really for people who bought the 6800xt to \"upgrade\", its for people buying a card today to get something better overall.\n\nIt's not a far out idea, its what most companies do and have always done.",
      "I predict:\n\n$579 for 7800XT\n\n$499 for 7700XT",
      "Now watch AMD burn their market share by pricing themselves out of the market, get horrible reviews, only to go back to reasonable price 3-6 months after damage is done.\n\nEdit: Well, color me surprised for 7800xt. \nThey still pulled that shit for 7700xt, though."
    ]
  },
  {
    "brand": "amd",
    "generation": "7000",
    "tier": "high",
    "matched_keywords": [
      "7900 gre"
    ],
    "title": "AMD launches Radeon RX 9070 GRE in China, officially 6% faster than RX 7900 GRE",
    "selftext": "",
    "comments": [
      "RX 9070 -6% performance for RX 9070 - 2% price. With 4GB less VRAM. Meeeeh.",
      "Its for AMD to get rid of bad yield i guess",
      "Yeah I dont see who this is for.",
      "no clue what demographic this card is caters towards to but this card just seems meh in general",
      "Definitely Garbage Radeon Edition for that price",
      "Should they launch this global it will probably be $500.  Back to the Nvidia -$50 strategy it seems ü•≤",
      "This is pretty much it, 9070 doesn't help AMD sell any GPUs with defective memory/cache. 9070 GRE makes more sense from a manufacturing standpoint for a cut down model.",
      "> I made a long list of games with performance problems and they didn't even approve the post...I think that's extremely negative.\n\nPost it again here. People at AMD do read this sub. I have watched the sub say \"mountain be over there\" and lo it moves.",
      "https://i.redd.it/eg69fkzh2lxe1.gif\n\nUnfortunately, my experience was similar. Despite having good intentions, my post was blocked. AMD needs to get serious about software issues, especially now that Nvidia is slipping...\n\n[List of games with abnormally bad performance on AMD to be fixed. : r/Amd](https://www.reddit.com/r/Amd/comments/1j5oskh/list_of_games_with_abnormally_bad_performance_on/)",
      "Waste not, want not! - AMD",
      "They should simply focus on optimizing more games for RDNA4, pushing the 9070XT to 5080 level in more titles.\n\n\nCS2, Wukong, Indiana, Silent Hill are just a few titles that have obvious software problems and need AMD's focus. I made a long list of games with performance problems and they didn't even approve the post...I think that's extremely negative.",
      "Probably for people who can only afford sub $500 GPUs, and want a next gen card. If this is priced well, let's say 400-450, that would be a 5060ti competitor price wise, but absolutely destroys it in raster. The 5060ti doesn't even beat a 7700xt convincingly.\nSo a 9070 gre 6% faster than the 7900gre is something similar to a 5070 lool, and with also overclock potential could be crazy value for money. Even with just 12gb, this would sell like hot cakes at 400-450.",
      "The reason its China only is propably because they dont have as many defective dies to launch it worldwide.  Selling fully functional 9070xt dies as this would make no sense considering there is shortage of 9070 anyway.\n\n So nah 9060 xt is a different chip.",
      "It's not 400-450 tho. It's essentially 540.",
      "Folks love Nvidia -$50 strategy.",
      "China",
      "Chinese internet cafes and pre-builts? Those usually put the 60 tier Nvidia cards at the top of the Steam hardware survey.",
      "Just let hope it drops down to 400 like the 7700 XT does",
      "This isnt 7900gre replacement. Its more like 7700xt replacement.",
      "This is why we can't be happy for Nvidia fucking up too much, all it does is make AMD get greedy. There should be a balance. Thanos was right üíÄ"
    ]
  },
  {
    "brand": "amd",
    "generation": "7000",
    "tier": "high",
    "matched_keywords": [
      "7800xt"
    ],
    "title": "With nvidia dropping the price of the 4070 to $549, I think AMD needs to drop the price of the 7800xt to $469 in order to stay competitive.",
    "selftext": "Looking at the advantages, the 7800xt has:\n\n1. 10% lower price\n\n2. 4 more gigs of vram\n\n3. 6% better raster performance.\n\nThe 4070 has:\n\n1. Better frame gen\n\n2. Better upscaling via dlss\n\n3. Better drivers\n\n4. Better rt performance\n\n5. CUDA for the few people that actually need it.\n\n6. Better power efficiency.\n\n7. The ability to use both dlss and fsr. If a game just has dlss, amd users are screwed.\n\nAll in all I think the AMD card is still the underdog based in advantages and needs to be at least 15% cheaper in order to sway buyers to team red. For just a $50 price difference, the team green advantages are too stacked imo.\n\nEdit: this is of course in the US market. Every market is different.",
    "comments": [
      "The FSR 3 situation is absolutely crippling what would be very competitive cards, because game devs are building games with upscaling included to achieve minimum performance, which is death for AMD cards. AMD needs to get FSR 3.x WORKING in games asap with VRR and Antilag+ to compete.",
      "If the 7800 XT is already selling well as expected, I don't see why AMD should feel pressured by the price drop.\n\nIt is good to see 2 decent cards being extremely competitive atm, unlike the 6700 XT which literally wiped the floor at $320/330 against the likes of RTX 3060/Ti and even 3070.",
      "That's not how business works. Margin matters, too, not just volume.\n\nAMD is a company, not a sports team. They are in this to turn a profit. Investors don't care if they chip away at Nvidia's install base. They care if they make money.",
      "In my opinion AMD should drop the price of every RDNA3 GPU except the 7800XT.",
      "It's selling well.\nIt's literally fire in new games.\nIt's already a good price for the performance.\n\n\nI can see why they won't stop the price. Nvidia may make them, but I doubt it",
      "i don't think you need to feel sorry for the billion dollar corporation. they have far more data to make their decision.",
      "The problem is even then the upscaler is much worse than dlss. Amd really has to improve the fsr upscaling, because they already are far behind. The quality of the generated frames of the fluid motion fsr 3 thing seems to be decent, but yeah with all the VRR and other features not working with it there is no point in using fsr 3. The main problem they seem to can't solve is the upscaling quality like I said.",
      "4070 should've never been a $600 card. 192-bit, 12GB, 200W TDP, cut-down AD104 die, performs similarly to the previous generation 80-series card - it's a 4060. Not even a 4060Ti, but a 4060. People are suckers for paying $600 for this overpriced piece of trash, and AMD is equally as bad for pricing their cards in accordance to Nvidia's.\n\nEven adjusting for inflation, taking the $300 1060 6GB from the 2016 as reference, this card should've been $380 at launch.",
      "There is no universe where the 7800XT outsells the 4070 and AMD still makes a profit on the card. It could be $400 with the 4070 still at its original price of $600 and the 4070 would still sell several times as much. Nvidia simply has much higher brand power and better OEM connections, and even in cases where AMD has the overall better card for cheaper (see: RX 400/500 series vs GTX 1000 series) Nvidia still sells far more.",
      "I wouldn't call the GPU market an example of healthy competition.",
      "AMD (and every other GPU/CPU chip designer/publically traded company for that matter) listens to people that vote with their wallets; aka free market forces.",
      "It‚Äôs crazy to hear that the 6800xt/3080 performance level is still ‚Äòfire.‚Äô Such a disappointing generation..",
      "Yeah, you know the 7700XT is gonna come down‚Ä¶ but when?!",
      "DLSS quality looks absolutely fine in most games at 1080p.",
      "The resale value isn't the biggest factor for why it sells more units. Nvidia just has a more refined software stack compared to AMD and more regular people, outside of Reddit and tech review channels/sites, recognise Geforce as the go-to brand. It's the name on the product, not how much they can sell it for once they're done with it.",
      "\"better driver\"\n\nYeah nope about that one, if anything their software suite is a disaster",
      "And the people are voting. After the price drop the 4070s have been killing the 7800xt at least on Amazon",
      "Love healthy competition, the consumers win",
      "It is not about the looks only, and amd drivers are no worse than nvidias for a long time already, they do work",
      "a more recent example: 6600 (XT) and 3050"
    ]
  },
  {
    "brand": "amd",
    "generation": "7000",
    "tier": "high",
    "matched_keywords": [
      "7800"
    ],
    "title": "[VideoCardz] PowerColor leaks Radeon RX 7800 XT Red Devil, Navi 32 with 3840 cores and 16GB confirmed",
    "selftext": "",
    "comments": [
      "According to the specs, RX 7800XT should sit between RX 6800 and RX 6800XT.\nIs this the first time when new generation's card is slower than it's predecessor?",
      "What the fuck? Why is this named the XT??? This makes absolutely zero sense, if it‚Äôs worst than the previous gen 6800XT, why not just remove the XT so the direct comparison is the 6800 which it will beat",
      "if we go by name, the HD 6870 back in 2010 was just a smidge slower than the HD 5870. it came in way cheaper as a midrange card though, around the $250 mark compared to $380",
      "Amd can't be this stupid right?\n\nThe 7800xt has 60 CUs which means it will be at best 10% faster then 60 CU 6800 putting on par or even slower than the 6800xt.",
      "Maybe it will be an Ada moment, and they'll announce FSR3 with a few games supported, and then announce it's only available on RDNA3 cards ![gif](emote|free_emotes_pack|poop)",
      "5500xt vs 6500xt ;)",
      "This card has no purpose above 499$  \n\n\nBest case scenario is that it narrowly beats the 6800XT, and that card is already around 500$. Seems like it has very little efficiency gain over that card either.",
      "Reminds me of the time when i bought the Sapphire 5850 Xtreme for 110‚Ç¨ in 2011.  \nGood times...",
      "Well I‚Äôm certainly not optimistic, because it‚Äôs already been proven that the improvement from RDNA 2-3 is not that good CU for CU. It better be like $500 maximum. But i still just don‚Äôt get why they named it the XT",
      "They named it the XT so they can charge XT prices.",
      "I remember when new cards of the same class used to be faster than the card it replaced.",
      "I'm so glad I finally buckled down and just bought a 6800xt. It's just a saphire pulse but its worlds ahead of my 1660ti I used for almost 6 years. All these new cards are either very disappointing or very expensive.",
      "And they gave Assassins creed II for free with my 5850. Great times",
      "We need to wait for benchmarks and price first",
      "This what people don't get about Ada.\n\nThe ada cards spec for spec vs Ampere are excellent. Great gen on gen performance improvements, way more power efficient, new features. Its the prices that sours it.\n\nMeanwhile amd has barely anything improved spec for spec. And they still have the audacity to price it near Ada cards.",
      "The chiplet thing is a huge issue for them. Every time the GCD needs to go to any of the MCDs for things like LLC or memory access, it incurs a latency penalty and loses some power vs a monolithic design. It has its advantages as well, but we don't see those leveraged nearly enough to compensate.\n\nBy moving the memory controllers and such off the GCD, they free up die area for more CUs and being a chiplet design means they aren't as constrained by the reticle limit. A big GCD taking the wide-and-slow approach is more efficient than running less CUs faster, but more costly. My Radeon counterparts aren't stupid, so I expect they are learning a lot from this to tune rdna4 and as design input for 5/6.",
      "GCN had significant, forward-thinking computational architectural advantages over GTX cards.  \n\n\nWith RTX, Nvidia managed to easily pull ahead. The problem with Nvidia right now is they kneecapped themselves with low RAM quantities, so the 6800XT is pulling ahead in new RT over the 3080 10GB despite it's architectural disadvantages",
      "RX 7800XT and the RX 6800 has the same number of Stream Processors and CUs (3840 Stream Processors and 60 CUs)\n\nRX 7800XT Specifications according to this leak :\n\nUses Navi 32 \n\nStream Processors - 3840\n\nMemory - 16GB GDDR6 (18Gbps)\n\nBus Width - 256-bit",
      "7800XT with 60CUs will perform like 6800XT, may be slightly faster. It should be significantly slower than 6950xt",
      "It is truly as simple as this. It‚Äôs why the cards are 7900XTX‚Äî>7900XT‚Äî>7900 GRE‚Äî>7800XT\n\nInstead of 7900XT‚Äî>7800XT‚Äî>7800‚Äì>7700XT"
    ]
  },
  {
    "brand": "amd",
    "generation": "7000",
    "tier": "high",
    "matched_keywords": [
      "7800"
    ],
    "title": "From a 2060 6GB to 7800 xt :) so happy",
    "selftext": "Got it at microcenter for 489 best price i could find ",
    "comments": [
      "An absolute beast of a GPU. You're going to love it",
      "Nice! I just over clocked the crap out of mine and I was already happy with it to begin with\n\nThe thing takes everything I throw at it except LIGHT ray tracing",
      "hell yeah thats awesome! I just built a rig for a friend with xfx 7700xt and the performance is pretty awesome",
      "he didnt have a 6800xt",
      "I have that same one, I came as a die hard nvidia guy, it is fantastic!!",
      "Same hereeee, from rtx 2060 to exactly this model of rx 7800 xt!",
      "Congratulations on the huge upgrade!",
      "I was so surprised what it could handle even after researching which gpu get for months :)",
      "yeah i don't want to use Ray tracing right now anyways and nvidia is too expensive for me right now \nI've done some light oc but its already hitting my max refresh rate so I'm like hmmm",
      "so good im glad you switch as it took nvidia messing up this launch for me to say enough is enough I'm going red",
      "Compared to 2060 it's a beast",
      "Enjoy it!",
      "I‚Äôm in the same boat of having a 2060 Super 6 GB but I‚Äôm just waiting for the new cards. I can still do most games on medium to low settings. Idk if you tried Marvel Rivals with it though because at lowest settings on 1440p my GPU runs at 89-97% capacity and has crashed my game at least 5 times",
      "can i have your old one? mine in 1060 3gb.",
      "I went from a 2060 to a 4080super and my god, its so nice",
      "Ayyy. I upgraded to a 7800xt from a 2060 as well. It was pretty eye-opening. Enjoy the power!",
      "Enjoy! I'm jealous! üò≠üòÇ",
      "recently went from a 3070 to this GPU as well. first time I ever had to limit fps on a graphics card because otherwise this thing pumps out hundreds of unnecessary frames, when I tested it in Doom Eternal (with raytracing enabled by the way) I literally went \"whoa, slow down there buddy\" lmao",
      "I'm so happy for you OP. I was thinking about getting a 7800 xt as well. My 2060 is starting to show its age. I'll reevaluate once the 9070 XT official benchmark comes out. Congrats on your new 1440p era.",
      "Grats. I have the exact model. It's a beast at 1440p high settings 100+ fps in many games"
    ]
  },
  {
    "brand": "amd",
    "generation": "7000",
    "tier": "high",
    "matched_keywords": [
      "7800xt",
      "7800"
    ],
    "title": "Upgraded to 7800xt from A770. What a beast!",
    "selftext": "I'm so happy now, ale games are working like a dream on Fedora42 ! Even raytracing is working fine.\n\n\nXFX Speedster MERC 319 Radeon RX 7800 XT\n\n\nPosted to show sizes comparison ",
    "comments": [
      "I just got a 7800xt recently too.  Playing mostly wow classic on it tho :/ lol",
      "Congratulations! Its a fantastic card. Enjoy!",
      "Im playing wc3 reforged lol.",
      "Nice. Just got one for my kids and had to make some ‚Äúmodifications‚Äù to the old HAF master cooler case I had just to fit the damn thing. And by modifications I mean a hammer.",
      "Is that a HoMM3 mat? Where does one get one?",
      "Nice upgrade! I upgraded from GTX 770 to 7800XT as well last September and I can play everything on 1080p Ultra now haha.",
      "Congrats and enjoy! Upgraded 2 weeks ago from a 6600xt to a 7800xt, massive upgrade üëç",
      "Fenomenal cosmic power!  \nItty bitty living space.",
      "AliExpress¬†\n\n\nSadly it comes with Russian text",
      "My 7900xtx card with the z bar barely cleared the front intake fans on my case.",
      "![gif](giphy|uIWTuwraEnRfblk36e)",
      "Heroes 3 in my case",
      "All dx9 games worked for me, problem is only with dx12 games performance compared to Windows",
      "That was a problem initially, but I haven't found any older games that don't work well recently. They have done an amazing job with drivers since launch.\n\nI personally bought an A750 because I could afford to have one in a second system, and I want to see more competition in the space. I like AMD, but they're no saint. Personally, I am rooting for Intel here.",
      "Peak 2010s design. I really loved cooler master cases in that time and built like 40% of builds using them.",
      "Congrats!¬† Mine is an xfx rx7800xt qick, good times @1440p.",
      "I'm upgrading from a 6600 and that's the exact card I have coming in next week. Wow that thing is massive, thank god I have a anti-sag bracket coming in a day before the card is set to arrive. üòÖ",
      "Glad to see the upgrade is working great, I'm about to make the same swap (just with a PowerColor card instead of an XFX).\n\nFor what I paid ($225 for a Micro Center open box twoish years ago), the A770 was alright, but sadly the Linux performance gains never really came and I don't want to be stuck on Windows on my desktop. (The laptop is because of some software for work) I was hoping Intel would become a good second option for dGPUs on Linux, but that seems to be solely for future gens.\n\nPlus, even with all the game's issues, I'd like to actually be able to play Civ VII on Linux without it crashing in 30 turns.",
      "Fellow merc 319 owner. Picked mine up recently to upgrade mo old 2070",
      "It's an amazing card. People are mostly using it for 1440p these days, but I have had much success with 4k 60fps for the games that I play. Enjoy!"
    ]
  },
  {
    "brand": "amd",
    "generation": "7000",
    "tier": "high",
    "matched_keywords": [
      "7800"
    ],
    "title": "RX 7900 XTX and 7800 XT have dropped to their lowest-ever prices on Amazon just ahead of Prime Day",
    "selftext": "",
    "comments": [
      "And now wait for it to rise then drop again and watch people flip shit‚Ä¶ again",
      "Not in Europe, as always. We have smaller salaries than the US, but sales tax are higher and they make a 1:1 conversion on the eur/usd, even when the eur is considerably higher.",
      "Especially if you're say from somewhere in Eastern Europe where salaries are considerably lower than western Europe and gpus cost ~150‚Ç¨ or more compared to the west",
      "Not a surprise nvidia has all the gpu market share when the average person believes in nonsense like this",
      "People saying AMD drivers are horrible are no different than console people saying pc is to complex",
      "I have not had any issues with my 7900 xtx since launch",
      "Slower card in all but the most intensive Ray Tracing and as a 7900XTX owner since last July I have had one single driver issue which was rectified the next month.",
      "There were a couple of items that I have saved under my cart.  And some of the items since their last \"sale\" are more this time around then the last time.  \"Oh look at those savings!\"  Yeah right.  It's still $100 more this time around than for Labor Day sale.  pft.",
      "In US****",
      "So you had one card 10 years ago, therefore the brand is always that way? Not just a bad experience or potential issues with an experimental design like the Fury was, with HBM and all. Nope, all AMD will ever do will suck forever more.",
      "Its just reddit. Everyone here has some type of mental disability especially people coming to a AMD subreddit praising Nvidia when they have the most absurdly overpriced gpu's. Everyone here complaining about AMD gpu's prices would never buy a AMD gpu anyways. Got people claiming their 4070 super is better than a 7900XTX is just another level of delusional Nvidia Fanboyism. Lmao.",
      "The 7900XTX (which I've had for a year) has been pretty solid driver wise. I switched from NVIDIA with the same fears.\n\n\n\nIf 4070 Super doss the job and is cheaper, then feel free to go for it :)",
      "You have absolutely no clue what you are talking about my guy",
      "There are a few good reasons why:\n\n1) VAT is included in MSRP by law in europe, while sales tax is not in the US (VAT is higher than US sales tax to boot)\n\n2) EU law requires an extremely permissive 2 year full money back warranty serviced by the retailer. It is abused heavily, with people using products for a couple years then returning them no questions asked.\n\n3) EU logistics are far more expensive than US due to astronomically higher fuel prices and much worse infrastructure for freight causing longer lead times and higher cost warehousing.\n\nhttps://europa.eu/youreurope/business/dealing-with-customers/consumer-contracts-guarantees/consumer-guarantees/index_en.htm",
      "Amazon doesn‚Äôt price match, you‚Äôll have to return the item and order it again.",
      "Yep, and none of those features matter at the moment.  Physx is dead.  FSR works fine, and RT is only really worthwhile on 4080/90 and 7900xtx.  RT is still a tacked on feature and bot useful for 99% of games.  Wont be used until PS6 in 2027/2028 and the RT will ALL be built for AMD GPU hardware as baseline.",
      "As someone who has an Nvidia card even i agree, there are really only 2 decently priced 40 series cards worth buying",
      "I know but your average sales tax is what 2 to 7%? Our sales tax is 23% fixed,",
      "Oh boy, another link to a post about unimpressive sales we just had posted a couple of days ago!",
      "That's not a good comeback, if you're trying to refute the claim. Compared to consoles, PC gaming is often a lot more complex. It's not something that can't be understood, but balancing things like types off AA, deciding between changing visual settings or render scale or a bunch of other settings is well beyond what consoles expect/let you do."
    ]
  },
  {
    "brand": "amd",
    "generation": "7000",
    "tier": "high",
    "matched_keywords": [
      "7800"
    ],
    "title": "I've finally had the financial means to upgrade to a 5800X3D and Rx 7800 XT",
    "selftext": "After 6 years of amazing service from my R5 2600 with 16GB of ram and a Rx 480, I've finally upgraded to a 5800X3D with 32GB of ram and a Rx 7800 XT.  \nI've changed the case, I love this TUF GT301s\n\no7 to my old components",
    "comments": [
      "Congrats! The 7800XT is a beast of a card in the 1440p department.",
      "Yes, my next step is to make my 1080p60Hz monitor my secondary monitor and buy a new 1440p144Hz one to use as my primary screen",
      "Yeah that's when it's going to blow your mind.",
      "I can't wait man",
      "I remember making the jump from my R5 2600 to the R7 5700X. Recently I made the jump from the 5700X to the 5800X3D and realized I should have just skipped the 5700X. On paper the performance was just slightly worse than the 5800X and that was \"slightly\" worse than the 5800X3D. In reality I saw a 100FPS increase in some games. In others the over all gameplay was just smoother.  \n\n\nExample: The Callisto Protocol is supposed to be GPU intensive. In the benchmarks I rarely saw above 65FPS at 1440P with the 5700X CPU. I made the switch and Now I'm around 212 in the benchmark. Either they did some heavy optimizations to the game since I last played it or there was something wrong with that CPU.",
      "I love paying extra for a GPU so I can play the three games with RT that are worth playing.",
      "Big upgrade!\n\nEnjoy!",
      "I don't have the financial means but I'm still doing the same upgrade! :D",
      ">In reality I saw a 100FPS increase in some games\n\nThat's just amazing, I think the 5800X3D will become as legendary as the likes of the 4790k",
      "Lmao, go mate",
      "Dude has never had RT on. Just going to 1440p smooth with 144hz native will blow his mind.",
      "Went from a 10700 to 5800x3d (used eBay to swap in and out) and games are so much smoother. The FPS boost wasn't amazing but the boost to the 1% lows was.",
      "> I also used to think RT was a gimmick, but after using it in TW3, it completely changed my mind.\n\nI never even said RT was a gimmick, I'm not even sure how you came to that conclusion with my comment. I simply said I don't think it's worth the extra money to pay for a card just to perhaps play the three games that are worth switching RT on for.",
      "You do realize that RT is actually making the problem of lack of VRAM/bad optimisation/higher detail in modern games (whichever the reason, any or all of them) worse, right? And you say: \n\n>Upscalers are starting to become requirements with all the badly optimised/ported games, and DLSS is vastly superior to the blurry, flickering mess that's FSR, especially at 1440p.\n\nWhich is in fact saying \"I support a line/family of cards that do not have the computing power, nor do they have the memory required to run their most advertised feature at native resolution. However there's this amazing technology that will make them run not at QHD or 4K, but at Full HD or even lower resolution and then it will lie to me better than the competition's technology.\" And, it's worth paying  the extra money to get less VRAM and Computing capability. Priceless!\n\nIf anyone buys a card advertised as a 1440p capable in 2023, it either runs 2023 games @1440p or it's a lie and a fraud. A company's new graphics technology can't be a selling point and a pig to run at the same time, 5 years and 3 generations after its release!",
      "That‚Äôs pretty much the build I‚Äôm going for I‚Äôve ryzem 5 7600 which afaik is similar in performance to 5800x3d and rn I‚Äôm hunting for a good 7800xt deal",
      "Thanks!",
      "This is the way. Enjoy in good health my man.",
      "This is making me jealous. I have the sapphire nitro 7800 XT. But really wanna try the 5800X3D, seems like it would be a nice bump over the 3800X. Even without the cache benefit.",
      "I will say while my AIO does just fine. There is still something sexy about a good air cooler. I do miss having one.",
      "Fantastic upgrade, the 7800XT is the best all round graphics card out there"
    ]
  },
  {
    "brand": "amd",
    "generation": "7000",
    "tier": "high",
    "matched_keywords": [
      "7800"
    ],
    "title": "AMD embarrasses Nvidia's midrange- 4060 Ti 16GB vs RX 7800 XT in 2024: The Ultimate Comparison!!!",
    "selftext": "",
    "comments": [
      "Let's be honest, NVIDIA embarrassed itself with any GPU below 4070 ...",
      "AMD's Reddit is overrun with Nvidia fanboys; they'll downvote your thread to death, it doesn't matter if it's true or not.",
      "I guess it depends on location? Here, the 4060ti is roughly $515 USD whereas the $600 USD. A closer comparison is the 7700XT for our location.",
      "There are people who are fanatical enough to say that the 4060ti is much better. \"Muh RT\"",
      "AMD GPU's offer much better value in the low and mid range, it is in the high end where Nvidia starts making more sense with a better upscaler, better RT, better AI capabilities... But on lower tiers, the bang for the buck should be the buying decision",
      "nVidia customers aren't ones that listen to logic pe common sense but rather warp reality to fit their narrative. They have become the Apple fanbois and fangals of PC community claiming things that are false. Its a mute point to even argue with them at this point.\n\nAnd I see lots of builds in PCMR community that are just Intel CPU + 4060/4060ti and they claim that they got a bargain/good PC. Thats the level of tech knowledge they have. Either You praise their stupidity and help them feel good with their awesome choice or do not, cause they aint listening to reason or logic.\n\nRant over. Have a blessed day.\n\nEdit: typo (good)",
      "And yet AMD cannot seem to move these and needs to bundle two games in order to build interest.",
      "In my country the 16G 4060 Ti is almost costing the same as a 4070 (even reaching the price of the cheapest 4070 SUPER), and is more expensive than 7800 XT, doesn't matter how i see it, it's definitely a bad deal, DLSS and Frame Gen simply don't justify the price.\n\nI think both AMD and NVIDIA embarrassed themselves in the lower end market, anything below 70-class or 700-class simply isn't worth it.",
      "This example makes it clear that Nvidia profits from their status and raise the prices. Those two cards should be in a different price range based on their relative performance. Here in Canada, I guess the prices are not the same as in US, because the 4060Ti 16GB is priced the same as a 7700xt. I know it's similar in Europe and other places around the world so it explains a bit why even if this gen is technically great for AMD, they still loss market shares.\n\nI also can't help but notice how good DLSS is. At 3:04, and even later in other games, if you look closely at the edge of every thing it's so much smoother on the 4060Ti even though it's upscaled (not taking into account the tearing on the 7800xt side).",
      "I was hoping for some nuanced discussion on comparative performance in this thread, or maybe some pushback on the *obvious* sensationalist video title.\n\nInstead it's just a thread full of \"haha Nvidia buyers are literally the worst of humanity, Nvidia more like nshittia, Jensen should be ashamed, this sub is infested with Nvidia bots, Radeon superior race!\"\n\nLike damn dude, y'all acting like you're being oppressed or something, but the only ones stepping on you are *yourselves.*",
      "nvidia also embarrassed themselves with the fk gamers attitude cause AI and them stupid high scalper prices.",
      "I almost bought a 4060ti 16 gb, but after researching benchmarks I cancelled the order and bought a 7800xt instead. If you don‚Äôt do content cration or something else that benefits the cuda cores there‚Äôs really no point in paying more for less. The price to perfomance on the 4060 /ti/16gb is absurd, but it seems like the market have catched that since the prices has plunged the last months.",
      "What about stuttering? Especially in FPS games.",
      "yes",
      "how tf 4060ti have 16gb and 4070 super only have 12gb? what a joke",
      "How is comparing a 7800 xt to a 4060 ti, 'the ultimate comparison'. \n\nThe 7800 xt is the equivalent of a 4070 ti. \n\nShill fest.",
      "Meanwhile, I am thinking about getting a Rx 7600 to replace my ancient Rx 5700xt in a new sff PC I am thinking about building",
      "Gaming ain't everything broüôÇ",
      "Nu uh. What about betur drivurs, dllsss, cuder and muh ray trasung /s",
      "i dont need RT, frame gen and DLSS i only care abr raw performance and power consumption..\n\n\ni would buy a radeon card if they were a little less power hungry.. 300 watt for the same perfomance that nvidia offers for 200 watt? is a lil rough"
    ]
  },
  {
    "brand": "amd",
    "generation": "7000",
    "tier": "high",
    "matched_keywords": [
      "7800xt"
    ],
    "title": "Out with the old and in with the new! Sapphire Nitro+ R9 390 to 7800XT",
    "selftext": "The new GPU for my build compared to the old one. Both Sapphire Nitros'",
    "comments": [
      "That's gonna be a massive upgrade. I am surprised you were able to keep using a 390 that long.",
      "For the last two years it was more surviving then using üòÖ",
      "Crazy how the cooler design on that R9 380 still looks modern today. Everyone else was too busy making their GPUs look gamery.",
      "The fact it had 8gb of vram I think helped in keeping it going for a long time",
      "I believe it. I had to use an r9 290 last year with a 1440p monitor and it was barely playable",
      "I was still on 1080p, got this gpu for a full new build and last thing to upgrade is my monitor to 1440p one.",
      "R9 390 is really close to GTX1060/RX580 perf, many people still use such cards for 1080p low-medium\\~ (on lighter games even high settings)",
      "Wow.. I came from a 2080 and thought my upgrade was huge! You must be in heaven right now! That‚Äôs a monumental upgrade!",
      "Which one is which ?",
      "Also upgraded from a R9 390, night and day performance upgrade! \n\nEnjoy it to the max!",
      "I got my daughter that same card for Christmas as an upgrade for her 1080 non Ti.  I've had good luck with Sapphire Nitro+ cards. \n\nHow do you like it so far?",
      "Happy for you my dude, I got the same GPU 2 weeks ago. I love it.",
      "I mean‚Ä¶ I still have a rx 480 lol",
      "Pretty sure the one stood up is the 7800XT, it looks a lot cleaner and shinier.\n\nThe laid down one looks to have some dust on the front face.",
      "2080 is still relevant",
      "The 390 was still pushing 60-120 fps for me @ 1440p last week (with Amernime drivers and a Ryzen 2600 + <3000MHz RAM) with reasonably modest games on a mix of Medium to Very High settings.",
      "Personal preference, and I think if you don't want features like RT, streaming, encoding or 3D rendering capabilities for like Blender and stuff you're getting much better value out of AMD cards",
      "It's good, no issues with it and the Sapphire Nitros' are binned GPUs so I am not worried.",
      "That's just one game, if you turn RT off, the 7800XT easily beats a 4070 and is also cheaper.",
      "I had the same 390 model. What a beastly card at the time, and a very nice design from sapphire. :-) \n\nThen came VR to destroy my dreams of gpu performance. :-("
    ]
  },
  {
    "brand": "amd",
    "generation": "7000",
    "tier": "high",
    "matched_keywords": [
      "7800"
    ],
    "title": "AMD teases upcoming Radeon RX 7800/7700 XT GPUs to be unveiled at Gamescom this week - VideoCardz.com",
    "selftext": "",
    "comments": [
      "The only way this will be a good unveiling is if the 7800XT launches at $499 and the 7700XT launches at $399.",
      "Can't wait to see AMD release a card with worse value than the current 6800 XT at 520$ - which one could buy 6 months ago now - it's going to be great, especially after DLSS3.5 and 4070 being already 6 months old, and probably still offering better value overall.",
      "They will just wait until the 500$ 6800xt's run out and release a 600$ 7800xt with 7% better performance.",
      "If they give 6800xt performance for 6800xt price i won't be surprised.",
      "Its not a case of 'giving up', just evaluate each one as it comes out.",
      "And for 50$ more!\n\nWhat a bargain haha",
      "7900 GRE is already cutting it close to the 6800 xt in performance. 7800 xt matching 6800 xt is the best possible outcome now.",
      "And the crowd goes mild haha.  It's just disappointing at this point how AMD is terrible at generating interest in their GPUs.",
      "GRE - aka \"Greatly Reduce your Expectations\"",
      "Yeah I think I've given up on AMD GPUs now.",
      "Crypto days are over and you cannot do much AI work on AMD cards. They just for gaming.",
      "No.\n\nRumour source is \"Moore's Law Is Dead\" and he doesn't have a good track of legit leaks.",
      "...IF it has better performance.  It may not.  It may end up being a mere 7800 that beats the 6800 but lags the 6800 XT.",
      "i saw someone else say that GRE meant \"Gimped Radeon Edition\" lmao",
      "HD 5870 to HD 6870 vibes. The 6870 was slower...",
      "GRE = GREED, but they were so greedy that they cheaped out on the remaining letters ED.",
      ">*Yes I do take advantage of those features.\n\nWith your 5700xt?",
      "Is there any hint of FSR 3 being unveiled at Gamescom officially from AMD themselves?",
      "> $399 vs $269.\n\nJesus, I know this is beating a dead horse, but god damn those GPU prices.",
      "At some point AMD HAS to realize that they're not on an even playing field with Nvidia, right? They can't keep releasing cards with nearly the same price to performance, but worse features and power consumption, and expecting them to sell right?"
    ]
  },
  {
    "brand": "amd",
    "generation": "7000",
    "tier": "high",
    "matched_keywords": [
      "7800"
    ],
    "title": "AMD Radeon RX 7800 XT alleged scores \"19K\" points in TimeSpy matching RX 6800XT - VideoCardz.com",
    "selftext": "",
    "comments": [
      "New gen is equal to last gen? Some fancy joke?",
      "Inflation hit their naming scheme this time, I guess",
      "Wasn't this obvious?\n\n7800xt vs 6800xt\n\n60 CUs vs 72 CUs\n\n2.4ghz vs 2.2 ghz\n\nSo 83% of the cores boosted by 10% more clocks and add in a little IPCs.\n\nThen you get 7800xt = 6800xt",
      "Not like this is three years later with the same performance ü§¶‚Äç‚ôÇÔ∏èü§∑‚Äç‚ôÇÔ∏è",
      "Can't wait for 2030 when we won't be deciding between 9700, 9800 and 9900, but between 9990xtx, 9990xxxtx and 9999xxxx",
      "how dare you use math to predict things that are based on basic math!\n\n*obligatory /s*",
      "The names mean nothing it's all about the price.\n\n7900XT is the replacement to the 6800XT.",
      "So 6950xt that i bought yesterday was a good deal :)",
      "This generation sucks. This is not a generational uplift, this is a product replacement.",
      "Why is an expectation of IPC from a new architecture \"out of nowhere\"?",
      "It‚Äôs really just the same price they were clearing out the last generation for. While it‚Äôs better than last Gen launch price it‚Äôs not as good as if they had launched in say March. It‚Äôs also a disappointing generational uplift.",
      "Don't be silly. Elon successfully trademarks the letter X in 2028 forcing GPU manufactures to replace them with exclamation points.",
      "Gonna be curious to see how reviewers treat this if it really only matches the 6800XT. 4060Ti got universally shit on and it at least beats out 3060Ti at 1080p and 1440p for the most part.\n\nAs everyone has said this really should've been a 7700XT at $450.",
      "No reason, this is just a replacement as 6800 XT stock is drying out. For newcomers, it's more power efficient and has the latest tech, better RT performance, and has AI cores.\n\nEdit: also AV1 hardware encoder/decoder - thanks hj17 for pointing it out.",
      "Whats the price uplift and performance uplift of such replacement respectively?",
      "Around %33 performance uplift for 38% price increase at launch.",
      "Cause we already had Navi31 reviews including deep dives and micro-benchmarks so the performance of Navi32 is absolutely trivially easy to preduct.",
      "AV1 encoding, longer-lasting driver support, slightly lower power usage, and I guess that tech they announced at gamescom that's exclusive to 7000 series cards (Anti-Lag+? Or driver-level frame generation? Maybe both, I can't remember)\n\nNot really a compelling reason to upgrade if you already have a 6800XT in my opinion, it's probably more for the people who haven't upgraded their card in more than 3 years. I probably would have gone for a 7800XT if I hadn't just bought a new 6800 a month ago.",
      "that's total uplift including things like the increased memory bandwidth and clock speed. actual IPC increase is significantly lower than that, like single digit level low.",
      "Not great. I thought it would be closer to the 6900XT."
    ]
  },
  {
    "brand": "amd",
    "generation": "7000",
    "tier": "high",
    "matched_keywords": [
      "7800"
    ],
    "title": "Official AMD Radeon RX 7800 XT & RX 7700 XT gaming and synthetic benchmark leaked ahead of launch - VideoCardz.com",
    "selftext": "",
    "comments": [
      "So the 7800 XT has 39% better value than the 6800 XT did at launch (1.07/0.77). That's pretty decent (about the price to performance uplift as the 3060 TI was to the 2060 Super), but I'm sure the goalposts will migrate soon enough.\n\n(For the record I think 7800 XT was a stupid name and it should've been called a 7800, but the price is perfectly fine. And relative to Nvidia it's quite excellent.)",
      "tl;dr (based on leaked gaming benchmarks)\n\nRadeon RX 7800 XT 16GB vs. RTX 4070 12GB\n\nRASTER:¬†+6.9%\n\nRT:¬†-11.6%\n\nAVG:¬†+0.5%\n\nRadeon RX 7700 XT 12G vs. RTX 4060 Ti 16GB\n\nRASTER:¬†+15.9%\n\nRT:¬†-5.4%\n\nAVG: +8.5%",
      "planning on getting a 7800xt. upgrading from a 1060 6gb.\n\nwas already loooong overdue for an upgrade and it seems like good value.\n\nedit: although I am eyeing the 4070",
      "It's better to wait 1-2 days for HUB and GN reviews. \n\nAs usual, \"official benchmarks\" and leaks are not very trustworthy.",
      "The 7800XT would be like a 6900XT but slightly more efficient if those numbers are accurate.\n\nI'm more puzzled by the 7700XT, which would be like a 6800 non-XT, with similar power consumption but less VRAM?",
      "direction yoke nutty dinosaurs melodic silky jar merciful cheerful fuzzy\n\n *This post was mass deleted and anonymized with [Redact](https://redact.dev)*",
      "Rational posts like this are a breath of fresh air in this sub lately. Nice stuff. Agreed, the naming is bad, but at least the price is right.",
      "People speculate the 7700xt is overpriced on purpose to push people into buying the 7800xt. Also supposedly the fabrication process has an 85% yield rate, so in theory only 15% of all cards should be 7700xts, but at launch it's 50/50, so they are pushing people into buying all the 7809xt stock. They e been accumulating the chips for many months, not selling the cards yet to get rid of 6000 series stock, then they play this game to push out more 7800xt stick, then will drop the price of 7700xt in a month or two to sell those 15% yields. Assuming I understood the YouTubers correctly, who spread unverified rumors with nameless sources.",
      "Basically, the 7800 XT is a win, but only because nVIDIA didn't release the 4070 as a 4060 Ti for 499$, which I'm pretty sure they could have - but of course, no point where ***cough*** AI ***cough***.",
      "Note the RT data is quite skewed towards Cyberpunk. They even included RT overdrive benchmarks for w/e reason which was never meant to run on Radeon lmao... even with Cyberpunk benchmarked **4 times** out of the 9 results, the RDNA3 GPUs are still holding up against their counterpart in RT. If you ignore Cyberpunk overdrive, 7700xt is 1.875% faster than 4060ti on average in RT (with Cyberpunk being benched 3 times). The 7800xt would be 4.375% slower than the 4070 in RT as well.\n\nThat brings me to conclude that the 7700xt is actually decent value vs 4060ti 16 GB on paper even if they are both \\~$450. With the 4060ti, you mainly gain DLSS 2 and 3, which isn't always present in all games (or you can pay for it lol ...), and 4GB more VRAM. The 7700xt has roughly equal RT and 15% better Raster on the other hand.",
      "Well, that's because the 4060 is objectively bad value though?",
      "The 7800XT....if the leaked performance is true, you get 4070-level performance (high fps 1440p ultra) for 15-20% cheaper. That's solid value (yes not amazing, but reasonable). 500$ is a price many people can afford for a GPU, and now you can get a solid 1440p experience or even 4K for that price.",
      "Yeah, it‚Äôs decent in isolation. I‚Äôm still kind of annoyed that this particular generational uplift took nearly *three years*, but at least it is one. That hasn‚Äôt happened since the 3060 Ti, maybe the 7600 if we‚Äôre being generous.",
      "The same people defending the 4060 will be screaming the 7800xt is bad value.",
      "AVG isn't useful because it's dependent on the ratio of RT vs non-RT games tested. Ie if you just picked cyberpunk path tracing and one non RT game, the 4070 would be \"AVG 60% faster\" than the AMD card.\nLikewise, they could leave CP2077 PT out and avg RT performance suddenly looks a lot better for AMD.\n\nNevertheless they look like competitive options (though I don't understand why anyone would buy the 7700xt for $50 less).",
      "The main reason that happened was oversupply of last gen stock, so AMD fronted the generational value uplift via discounts, then slotted in these two more or less based on that.\n\nPersonally, even if it makes reviews boring, this strategy is **far** more customer friendly than the typical one. These GPU's are designed, and prototypes are made WAY ahead of time, so selling you reheated leftovers for full price one day and then immediately launching something that makes that price look silly is kind of entrapment...\n\nThey would have came out earlier, but people were incensed that last gen clearance pricing was better value than the 7600 (since last gen is more expensive to make for a given tier of performance so selling through it is top priority).\n\nSo since everyone told AMD that launching the 7600 when they did was an unwinnable situation, they held off releasing these two until last gen products were almost out of stock.",
      "7700XT is a bad value at 449.\n\n&#x200B;\n\n7800XT at 499 is OK",
      "They're both completely fine nowadays. Both have AV1 for streaming and content creation, and AMD's RT is perfectly fine as well, just slower than Nvidia on matching tiers. It really comes down to personal preference.",
      "fwiw, the average RT scores (which tbf, are not in the original data, but videocardz's summary) are unfairly biased by cyberpunk being included 4 times in the overall averages (i mean, all these games are cherry picked to a certain degree, but having the worst AMD performing game included multiple times is particularly egregious)   \n  \nIf only RT ultra is included, which seems reasonable since the 4070 only manages 18fps in overdrive, the 7800xt vs  4070 changes to -4.3% in RT, and overall to +3%. \n  \nNot a big practical difference either way - I just don't like seeing averages just being applied blindly!",
      "Yeah just look at the 7900 xt\n\nAt launch, utterly stupid value. \n\nNow? Probably best card you can buy for the money."
    ]
  },
  {
    "brand": "amd",
    "generation": "7000",
    "tier": "high",
    "matched_keywords": [
      "7800xt"
    ],
    "title": "From RX 580 to RX 7800XT",
    "selftext": "",
    "comments": [
      "Eyy rx7800xt gang",
      "580 to 7800XT ? \n\nits like riding a bicycle to driving a corvette..",
      "Congrats! 7800xt is an excellent choice!",
      "Imagine paying $1200 more for a GPU with the same specs",
      "Imagine not allowing yourself to enjoy something fun because something slightly more fun might be available in the future.",
      "Yeah I did the similar rx580 to 6900 xt and jeez it's fast",
      "HECK YEAH!",
      "Curious why you would get a 7800XT with the 9070 going on sale next week?",
      "hey that‚Äôs gonna me me in a few weeks! goin from a 570 to the gigabyte 7800xt soon, how does it feel?",
      "NO MORE SUPER LOW SETTINGS (QuQ)",
      "9070 is going to be roughly 25-30% faster (and much more than that in RT) than a 7800 XT, and otherwise be the better card in every way.",
      "I just went from a 480x to a 7700xt! It‚Äôs wild how good it is. No more running newer games on low 1080p. \n\nMy 480x is a rockstar though. Still kickin and I‚Äôll probably throw it in my office computer build when I get to it. \n\nI still have my 280x as well but not sure what to do with it anymore.",
      "I upgraded from a 580 to 6700XT. 7800XT is a solid choice. I'm looking forward to seeing how it stacks up against the 9070 - on paper 7800XT looks better but we'll see.",
      "I am going to try to keep my next GPU for long enough to have a substantial upgrade. The 2-year cycle is for maniacs now, I gotta adjust to at least 4 to 5 years.\n\nNice rig. Love the UFO lighting.",
      "5 year upgrade cycle is where it's at. Thanksgiving week this last year I went from a 1800x and a 5700xt to what I have now and it's like hitting the NOS button in Fast and Furious.",
      "üëçüèº",
      "7-8 years has been my cycle since I'm 3rd worlding it.",
      "Also if you upgrade every 5 years you have more time to save up money and therefore can afford a higher tier of card. Meaning even an even bigger upgrade",
      "That's an upgrade you should feel!",
      "Been looking to make the same jump. Waiting for 9070xt listings to go up, as I might go for that instead, if it is close enough to MSRP, or otherwise to see if it causes the price of the 7800xt to drop. Also not sure yet whether to pair it with the 7600x3d or the 9800x3d"
    ]
  },
  {
    "brand": "amd",
    "generation": "7000",
    "tier": "high",
    "matched_keywords": [
      "7800"
    ],
    "title": "Simulated Radeon RX 7800 XT GPU ends up 4% to 13% faster than RX 6800 XT - VideoCardz.com",
    "selftext": "",
    "comments": [
      "Yeah... both nvidia and amd seem to have a hard time beating the 6000 amd's series deals for low/med/high-end, unless you want to get the top of both current generations the rest looks like a waste of time. Even if this is still a rumor I doubt it'll end up any different. Probably gonna end up getting an rx 6950 xt like any sane person.",
      "If it doesn't have some crazy power efficiency, it's better for them not to even release it.",
      "Not even a good simulation lol. This is based on the assumption the Navi 31 70cu card will be 7800XT, when the leaked rumours indicate 7800XT will be 60CU N32 card.\n\nDoesn't make sense to equate the GPU to 7800XT. It's not like 7800X3D simulated graphs where we got near accurate simulations.",
      "Power consumption difference will likely be pretty large. The 6950 XT also went up in price recently.",
      "Its not just about the value. If your sucessor (with almost same CU count of 70 vs 72) is only a single digits faster than the previous gen, \n\nThen you fucked up. Its the same with the 7600 vs 6600xt (both 32CUs). Its just sad at this point. Almost as sad as NVs milking of consumers this gen.",
      "Has anything from this gen of AMD so far had impressive efficiency? It seems like they really walked away from efficiency this round.",
      "4 to 13%, like the 7600 was going to be 11% better than the 6650 xt? :(",
      "Same deal here for 3+ months and actually it went down by 20EUR, once you do some UV you'll have a much more efficient card and lose 5% perf. in the worst case. Unless the 7800 xt isn't 50/100 cheaper than the rx 6950 xt there is no reason to wait for anyone that has been eyeing the rx 6950 xt.",
      "I worry more about the price than the performance for cards these days. The problem is not the performance, they could call it a 7800 XT and it could be the same speed as the 6800 XT, but if it's $399 or $349 then it's a decent product. But if it's $599 or something, then it's DOA. There's no bad product, just bad pricing. Yes, even the horrible \"4060 Ti\" wouldn't of been canned it they named it appropriately, say the RTX 4050 Ti and sold it at $199 or $249.",
      "RDNA 3 is a disappointment.\nHopefully, discounted 7900 XT down to $699 would fix this generation.",
      "tldr; if you're waiting for 7700/7800, don't. just buy a 6800 XT or 6900 XT",
      "6950 XT is the goal, haha. If that's it but maybe 20 to 40% better on power, then we're good. There isn't much room between the 7900 XT to the 69\\*\\* series for a 7800 XT.",
      "They're still efficient, but they're tuned in the other direction at stock. I took 35 watts off the top of stock 7950X settings and get higher Cinebench R23 scores, lower thermals, and better gaming performance. I'm running -24 all-core PBO and haven't even tested higher undervolts on the cheapest X670E board available.",
      "It's just more proof that the \"7900\" products should have been named \"7800\". If anything, it is strange that AMD decided to play the \"one-up in naming\" game with the 4080 / 7900XTX and will probably do the same with 4070 / 7800, but *didn't* do the same with the 4060 / 7600.",
      "The 60CU N32 performance means it cannot be more expensive than a 4070, which means it'll be branded as a 7800 non-XT.\n\nSimilar scenario to the 7600.\n\nThe 7800 XT will either be this GPU or will not exist at all.",
      "Yuss :3  \nAlso the same hype predictions for 7900XTX and 7900 XT before they were even out.",
      "That argument has always been bizarre to me. \n\n\"Hey, if you wait a year or two, they'll sort the drivers out to the point that they should have released with!\" lol\n\nNvidia also does driver improvements over time, but tend to get most of the performance right out of the gate.\n\nSaying it's like \"fine wine\" is a weird take on unoptimized drivers that take years to fix.",
      "I mean, it's fine as long as the prices come down.",
      "I was about to suggest power consumption might be a factor... but it's only about 10 watts of power difference... and for those 10 watts you get another 2 gigabytes of VRAM and 4% more overall performance... and you can undervolt...\n\nI'm actually curious as to why people are buying the 7600 when the 6700 has an identical price...",
      ">  7800 N32 will likely be in the 550-580 range.\n\nThe 6800xt had an MSRP of 649. Why would the 7800xt be lower?"
    ]
  },
  {
    "brand": "amd",
    "generation": "7000",
    "tier": "high",
    "matched_keywords": [
      "7900 gre"
    ],
    "title": "GeForce RTX 4070 Super vs. Radeon RX 7900 GRE, GeForce Premium Worth It?",
    "selftext": "",
    "comments": [
      "Hot prediction for these comments:\n1. DLSS is trash\n2. DLSS makes up the difference for 4gb vram\n3. Frame gen is just fake frames\n4. Frame gen is incredible and will change everything forever\n5. FSR will never be good\n6. FSR is just one release away from being just as good as DLSS\n7. AI is the future\n8. Nvidia are greedy\n9. AMD can‚Äôt compete",
      "You pretty much summarized every GPU comment section for the last year+ lol",
      "I'm a simple man, I see an Nvidia vs Amd video, I grab some popcorn and scroll through the comments. Bonus popcorn if I see comments mentioning Intel arc gpus",
      "You forgot:\n10. Upscaling looks better than native\n11. AMD bad drivers",
      "After ten years with Nvidia I‚Äôm not convinced driver stability is actually any better than amd. Amd adrenaline is certainly better than GeForce expensive imho .",
      "There's really only 2 reasons to buy the GRE over the 4070 Super. 1 is if the price difference is astronomical. The other is if you desperately need 16GB of VRAM to the point where it would make a substantial difference in a wide case of scenarios.\n\nOtherwise the 4070 Super is a no brainer. Pretty much just as fast in raster performance. Much faster in RT. Especialy heavy RT. Lower power consumption and brings all the software advantages that AMD doesn't offer or offers in an inferior fashion. RTX HDR, DLSS, More mature Frame Gen, Reflex and many more.",
      "I will get the GRE solely because of linux and VRAM",
      "Either card is fine. I would pick the 4070 if I'm upgrading within 3 years and the 7900 if I'm keeping it for 5 years or more.\n\nBoth cards are decent enough so there is no need for animosity.",
      "Grabbed a 7800 XT and it works perfectly fine. Handles pretty much everything I throw at it minus Cyberpunk where performance is iffy but that‚Äôs just a beast of a game even on a 4090.",
      "In the UK, the difference is about ¬£80 for a GRE to a 4070 Super. Pretty big gap, in the US it‚Äôs much closer.",
      "I know it's quite a niche case, but the 7900 GPU on Linux with ROCm 6.0 is incredibly powerful for machine learning, it's amazing if you can find it for a good price!",
      "Both are okay for the price. I rather stick with something with 16gb VRAM. Screw you Nvidia. Spending 600+ for a card that probably won't age past 3 yrs is heartbreaking. I hope the 5000 or 6000series have more VRAM with ddr7...",
      "This is 5700xt vs 2070super all over again, both were forgotten within a couple of months and nobody expect miners have mentioned them ever since. This will be no different imo aka don‚Äôt fall for this trap when new everything is around the corner",
      "omg #10 drives me up a wall hahaha. \n\nThanks for irritating me lol",
      "As a Linux user, AMD's drivers are also worlds better than nVidia's. So, perhaps a niche case, but it's important for me.",
      "it can happen\n\nif only because we literally have not had good AA options for a decade but the upscale is simulating having that AA.",
      "For those who want a more diverse sample size just go to tomshardware it'll be a more accurate overall test.\n\n[https://www.tomshardware.com/reviews/gpu-hierarchy,4388.html](https://www.tomshardware.com/reviews/gpu-hierarchy,4388.html)",
      "Intel Arcs look cooler than every other gpu. That's pretty much all I know about them.",
      "Intel taking the fight to Nvidia at the high end is a pipe dream really, they haven't produced a true mid range GPU yet. A770 is being matched and even beaten by the RX7600 which is half its die size on the same node.",
      "You want us to believe you changed from 4070s to 7900gre? What possibly can be your reason?"
    ]
  },
  {
    "brand": "amd",
    "generation": "7000",
    "tier": "high",
    "matched_keywords": [
      "7800"
    ],
    "title": "[HUB] Radeon RX 7800 XT vs. GeForce RTX 4070, 45 Game Benchmark @ 1080p, 1440p & 4K",
    "selftext": "",
    "comments": [
      "td,dw:\n\nRadeon RX 7800XT is:\n\n* 3% faster on average @ 1080p (mixed), 5% faster on average @ 1080p (rasterization), 4% slower on average at 1080p (Ray-Tracing)\n* 5% faster on average @ 1440p (mixed), 7% faster on average @ 1440p (rasterization), 2% slower on average at 1440p (Ray-Tracing)\n* 8% faster on average @ 4K (mixed), 8% faster on average @ 4K (rasterization), 6% faster on average at 4K (Ray-Tracing)",
      "And cheaper.",
      "Everyone arguing which one is best, meanwhile I'm here sitting thinking the perf/‚Ç¨ hasn't budged in 3 years and nobody bats an eye. Even the mighty 4090 at the current price is double the perf of a 3080/6800xt for triple the price. Can we stop validating these shitty anti-consumer practices or what?",
      "Raytracing performance on RDNA3 is great when the RT effects are on the less \"heavy \"type. In Cyberpunk 2077 for example, 7800XT beats 4070 easily when using RT low or medium. It's when you push the setting to RT ultra and psycho (RT Overdrive is unplayable on 7800XT) the 4070 pulls a massive lead.",
      "Huh, it even is comparable in raytracing. That's surprising.",
      "70USD cheaper currently where I'm at (Sweden) (looking at items in stock)",
      "I said in r/hardware and i should also mention it here. That Control RT result is 100% wrong.\r\r\n\nFor Eurogamer [https://www.eurogamer.net/digitalfoundry-2023-amd-rx-7800-xt-7700-xt-review?page=2](https://www.eurogamer.net/digitalfoundry-2023-amd-rx-7800-xt-7700-xt-review?page=2) \r\n\n7800xt - 49.64 fps vs 4070 - 57.18 (1440p)\r  \n\r  \nFrom Kitguru\r [https://www.kitguru.net/components/graphic-cards/dominic-moass/amd-rx-7800-xt-review/all/1/](https://www.kitguru.net/components/graphic-cards/dominic-moass/amd-rx-7800-xt-review/all/1/) \r\n\n7800xt - 44.3 fps vs 4070 - 52.8 (1440p)\n\nFrom Tom's Hardware\r\n\n[https://www.tomshardware.com/reviews/amd-radeon-rx-7800-xt-review/3](https://www.tomshardware.com/reviews/amd-radeon-rx-7800-xt-review/3) \r\n\n7800xt - 49 fps vs 4070 - 59.4 fps (1440p)\r\n\nNo way these two perform the same in Control RT. The 4070 should be about 20% faster",
      "> perf/‚Ç¨ hasn't budged in 3 years\n  \nThis is objectively false. \nWhat could you get for $500 3 years ago, and what can you get now? (And im not even talking about crypto prices.)  \nHow much did a 6800xt cost 3 years ago, how much does a 7800xt cost now?  \nIts not amazing, but that's a >30% improvement in perf per dollar.",
      "Damn,not bad.\nThe only bad thing about it is fsr image quality at 1440p. Reason I'd probably still buy 4070 over 7800xt.\nAMD needs to step it up.",
      "Not everywhere. For malaysia,[ the cheapest 7800XT converted price at 577.32 USD](https://shopee.com.my/Sapphire-PULSE-AMD-Radeon-RX-7800-XT-16GB-GDDR6-i.17919052.22479419959). which is the same price as a rtx 4070.",
      "I am not quite sure you really understand the way raytracing and especially pathtracing appear to be evolving right now.\n\nFor example, with DLSS 3.5 Nvidia is enhancing the denoising step by combining it with upscaling step and leveraging Tensor cores to make it better.\n\nNvidia has a whole slew of new optimizations that most games do not use (for now) baked into Ada Lovelace architecture: Shader Execution Reordering, Opacity Micro Maps, and even a new primitive (admittedly the least likely to ever come into play) - Displaced Micro Mesh.\n\nNvidia is evolving their approach to raytracing all the time, especially whenever new architecture is introduced, while maintaining solid support for techniques that came before, at least for the time being.",
      "AMD pricing in Malaysia has always been so bad.",
      "I don't know what HU does but I swear sometimes they have super weird results that isn't even comparable to other reviewers",
      "At 1080p FSR looks bad to me\n\n1440p, it's better, but still below DLSS\n\nAt 4k, I can't tell the difference (unless it's slo mo side by side)",
      "3 different reviewers got the near same delta. Chances that all 3 did the same teat at the same place the same way is very slim.",
      "Not everywhere",
      "As much as I ragged on the naming scheme and previous gen performance compared to the 6800xt, this shows NVIDIA released absolute garbage this time except for the 4090",
      "What? All the results are in the video. Just that notable games have been given their own slides, but it's easy to know the numbers from the given results without the slides.",
      "It really depends which games you pick, [this](https://www.reddit.com/r/hardware/comments/16guxrk/amd_radeon_rx_7700_xt_7800_xt_meta_review/) meta review claims 4070 is 18% faster in RT",
      "Yeah RT is not bad on 7800xt but the gap is bigger than what they showed"
    ]
  },
  {
    "brand": "amd",
    "generation": "7000",
    "tier": "high",
    "matched_keywords": [
      "7800"
    ],
    "title": "People waiting for the 7800/7700 cards: is it getting hard to justify the wait?",
    "selftext": "I am on this boat. But every week that goes by, I see myself close to jumping off from it.   \n\n\nI will give some thoughts and I would be happy to be proven wrong, and that the 7700/7800 are worth the wait, but I am finding it hard to justify. Here we go:  \n\n\n1. The upper tier of RX 6000 cards are being priced very aggressively as of lately. Namely the 6800XT and the 6950XT. Besides, we pretty much know that whatever price/performance ratio the 7700 and 7800 offer at launch, it is unlikely the beat the discounted 6000 cards. The 7600 vs 6600XT/6650XT was a good example of that.  \n\n2. Free Premium Starfield. That is a $100 game being offered with upper tier RX 6000 cards and we can't tell for sure whether it will be offered with the 7700/7800 cards. These cards are unlikely to be released before Starfield is (which is just 7 weeks away). Moreover, 2023 has been an incredible year for gaming - arguably the best year out of the last 5 years, if not longer. Some are suggesting it is the best year for gaming ever. That might be a stretch. Regardless, each month of this year that goes by without a GPU upgrade, well, it kinda sucks.  \n\n3. RDNA3 offers no significant technological improvement over RDNA2, other than a small performance/watt gain. FSR3 will work for both. Memory (a strong selling point for AMD) won't improve either: the 7800/XT will offer the same memory capacity as the 6800/XT.  \n\n4. AMD is not necessarily under pressure. Their stocks are doing pretty well - the only time in history they were higher was during the peak of the mining boom. Nowadays AI is where the money is. GPUs for gaming is not AMD's top priority, whether we like it or not.",
    "comments": [
      "Your point 4 is incorrect.\n\nThey are under pressure. IP that has been developed and productized needs to make a ROI. Every month it waits, is another month that AMD is losing out on revenue.\n\nIt is likely that AMD is trying to get rid of its 6xxx stock.\n\nBut yeah, I wouldnt wait. The deals are too good right now.",
      "Is the cheapest, on sale RX 7900xtx still $900+?\n\nThen I have no trouble waiting.",
      "I was considering waiting, but looking their product stack and their pricing, there's literally nothing they could release that would be better then a 4070 for me.\n\nI would pretty much need to get a 7900xt performance wise, but using less power, for the price of a 4070, to want to give up the ray tracing performance, DLSS, cuda, reflex, and other nice Nvidia features. Those features really put in work and I'm tired of getting second class support all in the effort of raster performance. We're well past the point of raster being the only thing that matters, I'd happily give up 10-15% or more of my performance if it meant the card was better in all other aspects, and unfortunately that's the position I'm in with Nvidia and AMD.\n\nThis coming from someone currently on a 5700XT. When I bought that card over a 2070 super, ray tracing and DLSS were jokes. But if I could know how much better they were gonna get in the future I would have happily spent more on the 2070s.\n\nThat, and AMD's pricing here in Canada sucks right now anyways and I couldn't get a 6950XT for anywhere close to the price of a 4070 even if I did want that card, which I don't.",
      "What are you even talking about?\n\n> *nothing* is standard except the VRAM config\n\nThey are literally all the exact same card and will perform within 5% of each other, the only difference is the coolers and the warranty. \n\nPaying extra for better overbuilt coolers is stupid, you won‚Äôt get any better performance.",
      "I can understand someone not wanting the 6950xt due to the high power consumption, but the 6800xt is much more reasonable, and is appearing at or below $500 right now. Not much point in waiting. I got mine for $479 a couple months ago.",
      ">Moreover, 2023 has been an incredible year for gaming - arguably the best year out of the last 5 years, if not longer. Some are suggesting it is the best year for gaming ever. \n\nWait, what? Did I miss something? What games are you talking about to call it \"best year for gaming ever\"?",
      "Agreed, I think they're really missing out a chance to grab the 2023 mid-range GPU market by the balls. I'm in a similar boat as OP's except I'm waiting on a bit of money to come in which I will use to make a purchase and I've been crossing my fingers for a 7700xt release. Really didn't want to buy 2+ year old hardware. Sigh",
      "> Really didn't want to buy 2+ year old hardware. Sigh\n\nTheres always pros and cons to buying brand new hardware. 7000 drivers were a mess at launch and it took months to fix them. Meanwhile, 6000 series drivers have been stable for well over a year. Another example, when I got my 5900x and x570 mobo in late 2020 (when 5000 series cpus launched), my ram wouldnt run at the frequency advertised (3600 mhz) without my system crashing like crazy. I had to run it at 3200 for over 6 months until there was a bios update that fixed it. So I ended up losing performance and paid for something I couldnt fully use for 6+ months. New tech is almost always overpriced at and around launch too.\n\nI get the allure of buying the brand new, shiny thing, but is it really that big of a deal to buy 2+ year old hardware? When you go car shopping, do you only look at the 2023 models and ignore everything 2021 and earlier? Even if you get most of the performance/features for a lot less money? What about TVs or monitors? The latest lg c3 is 25% more money than a c2 and has marginal performance increases at best. Most would say it's a waste of money to buy the c3 over the c2. \n\nI just think we need to change our mentality when it comes to these things. You shouldnt feel bad because youre buying something thats a couple years old. Especially when that thing thats a couple years old is priced well and is a big performance increase to whatever youre currently using.",
      "I just bought a 6800xt and not feeling bad at all. Couldn't wait for a release that no one even heard rumours about the date.",
      "> ‚Ä¶an MMO without class system as everyone is a DPS, with no economy‚Ä¶\n\nIts an ARPG. It‚Äôs not an MMO. You literally described any character in an ARPG. Maybe next time check out the genre of the game before jumping into it?\n\nNot disagreeing that its a disappointment still tho. But it‚Äôs certainly for others reasons than the ‚ÄúMMO‚Äù reasons you‚Äôve stated.",
      "Newegg has a couple that are *technically* under $900 pretax right now:\n\n[Asrock Phantom](https://www.newegg.com/asrock-radeon-rx-7900-xtx-rx7900xtx-pg-24go/p/N82E16814930081?Item=N82E16814930081&nm_mc=AFC-RAN-COM&cm_mmc=afc-ran-com-_-PCPartPicker&utm_medium=affiliate&utm_campaign=afc-ran-com-_-PCPartPicker&utm_source=afc-PCPartPicker&AFFID=2558510&AFFNAME=PCPartPicker&ACRID=1&ASID=https%3a%2f%2fpcpartpicker.com%2f&ranMID=44583&ranEAID=2558510&ranSiteID=8BacdVP0GFs-QepXz8tfA44LmkS17.zQrg)\n\n[MSI Trio](https://www.newegg.com/msi-radeon-rx-7900-xtx-rx-7900-xtx-gaming-trio-classic-24g/p/N82E16814137781?Item=N82E16814137781&nm_mc=AFC-RAN-COM&cm_mmc=afc-ran-com-_-PCPartPicker&utm_medium=affiliate&utm_campaign=afc-ran-com-_-PCPartPicker&utm_source=afc-PCPartPicker&AFFID=2558510&AFFNAME=PCPartPicker&ACRID=1&ASID=https%3a%2f%2fpcpartpicker.com%2f&ranMID=44583&ranEAID=2558510&ranSiteID=8BacdVP0GFs-3gx3XaUBtMGT4Iiwc0EqnA)\n\nWhich I know is probably close enough to not really change your point, but there's a few more which are getting close to $900; it wouldn't surprise me to continue to see price drops.",
      "What‚Äôs wrong with asus, msi, and lower end asrock cards? they perform the same as other brands since they are the exact same PCB under the hood.",
      "I jumped off and bought a 6950xt for $570 USD brand new lol",
      "I gave up 7-8 months ago. Not as in i gave up and bought another card, i gave up on this entire generation. Currently I'm waiting till next gen.\n\nAt first i was targeting a 7800 this gen....but then we found out it was not navi31 based and thus not released with the first wave; so then i was begrudging considering tiering up to a 7900xtx...but its value just was not good enough for me once the benchmarks came out....if it was $850 7 months ago i would have bought one, but not anymore, too late for amd/nvidia...do better next gen....\n\nMy desire for a new card is building again....the 8gb card i have now is not enough even at 1080p. To clarify its enough to play every game on the market at 1080p....but its not enough for me, i have had to lower settings a few times already this year because of the 8gb vram limit, which is becoming more and more undesirable.",
      "And even when 7800 comes out, it won't be officially able to run ROCm, unlike all nVidia GPU's.\n\n[ROCm supported GPUs](https://rocm.docs.amd.com/en/latest/release/gpu_os_support.html#supported-gpus)  \nvs  \n[CUDA supported GPUS.](https://developer.nvidia.com/cuda-gpus)",
      "It's incredible year for gaming, just maybe not that good for PC gaming due to horrible ports, but we got Hogwarts Legacy, Atomic Heart, Everspace 2, Dead Island 2, Jedi Survivor, Diablo 4,  Street Fighter 6, FF16 and more on consoles like new Zelda. There are also many potentialy good games coming like Starfield, Baldurs Gate 3, Mortal Kombat 1, Lies of P, Alan Wake 2 and thats mostly big names there are more that I'm forgeting",
      "Yeah AMD really dropped the ball on productivity. I learned that the hard way when AI upscaling first started taking off and I really wanted to try it out and learned all the popular upscalers people were recommending all uses cuda and pytorch.",
      "I've had enough and went with Intel.\n\nI got an A380 and all AI and deep learning tools just work.\n\nIntel even integrated AI image generation into GIMP.\n\nhttps://github.com/intel/openvino-ai-plugins-gimp",
      "Typically most cards use the reference PCB design. Which means the VRMs, traces, power delivery capability, all of that is exactly the same. The only difference being the cooler.\n\nMaybe you're overestimating how many cards bother going off reference design? Usually it's much more expensive cards and at the top end, stuff like what EVGA did with their Kingpin variant of cards, but not their more standard lineup.",
      "Most of those games aren't even that good."
    ]
  },
  {
    "brand": "amd",
    "generation": "7000",
    "tier": "high",
    "matched_keywords": [
      "7800xt",
      "7800"
    ],
    "title": "From gtx 970 to 7800 xt",
    "selftext": "Finally retired my Gtx 970 after 7 years of service. She took me all the way from 1080p to 1440p. But i wanted to finish my full upgrade. 7800xt Nitro+ . Worth every Euro.",
    "comments": [
      "On one hand, pretty big upgrade. On the other, homie where did your fans go",
      "Finally someone who upgrades reasonably. I am so tired of these people complaining they have to upgrade from a RTX3090ti to a 4090ti.",
      "Over the years they stopped working. And I removed them.",
      "That 970 has seen some shit",
      "...and you didn't bother to replace them? Bruh.\n\nJust Google the part number on the back of the fan, and buy a replacement online for like ¬£3.83.\n\nEDIT: https://www.aliexpress.com/item/1005004056607498.html",
      "Oh boy that‚Äôs escalated quickly!",
      "7800xt is the best value new card you can get for max 1440p/mid 4k high refresh gaming. \n\nabsolutely a winner",
      "Apart from getting pretty hot during the summer it did alright.",
      "Best gpu during shit generation. Good choice",
      "How did the 970 do with only one of them?  \nI also had a 970 a while ago, and it worked just fine with one out of two. The 900 series was damn energy efficient back in the day.",
      "Agreed. I had a GTX 760 for way too long, got a free R9 290X that died after a few months, (probably PCB breakage because of sag, it was the Powercolor PCS+ which was by far the heaviest variant) so I went back to the GTX 760. Bought a suspiciously cheap used Sapphire RX 580 8GB eventually that was black screening when idle because the lowest voltage step was unstable and also the only one you weren't allowed to change (tried on 3 different PSUs one of which 1000+W single rail) \n\nThen got a GTX 1080 which gave me flickering with Freesync unless I hunted down a sweet spot max refresh rate with trial and error... Then a 3060 Ti that did the same thing.\n\nGood thing is I broke even on every single one of those except the RX 580 but that was so cheap anyway.\n\nThe 6950 XT is literally the first GPU in 12 years that has been problem free. (Not counting a 980 Ti I borrowed for a couple of months while its owner had a broken motherboard)\n\nEdit: And for the record, I'm \"cheap\" because most of my money goes towards photography equipment. The 4090 could be infinitely powerful but as long as it's a toy that costs almost the same as the *tools* I use to *make* money it will never be prioritized. Not to mention Warhammer 40K and music production are equally expensive hobbies.",
      "Celeron iGPU -> ATI 4770 -> R9 280X -> 3080. Every upgrade is massive to me.",
      "I think they meant the 7800xt",
      "900P to 4k upgrade path",
      "I went from a 1080 to the same Nitro+ 7800XT. Its felt like a giant leap forward, I'll replay some games I thought my old 1080 was a bit weak at 1440p to fully enjoy just to see things again without any graphical compromises. (Hogwarts Legacy, CP2077, RDR2 etc)",
      "Thanks for the info. I will refurbish my card then and use it for another pc",
      "That old girl was fighting for its life",
      "tf happened to the poor 970",
      "I had an ATI 5950 that did that to me. I left the side of the case open and stuck a house fan on it. It would get toasty but it hung in there lol",
      "I upgraded from an rx 590 to an RX 6700 non-xt because the 590 was unstable as heck and the upgrade doubled my effective performance\n\n3090 to 4090 is wild"
    ]
  },
  {
    "brand": "amd",
    "generation": "7000",
    "tier": "high",
    "matched_keywords": [
      "7900 gre"
    ],
    "title": "AMD Radeon RX 7900 GRE officially launches with 5120 cores, 16GB memory and 260W TBP, costs $649 - VideoCardz.com",
    "selftext": "",
    "comments": [
      ">AMD advertises it as the successor to the RX 6800 XT.\n\nwell name it RX 7800 XT then???",
      "80cu, like 6900XT\n\n2250mhz, like 6900XT\n\n16gb, like 6900XT\n\nperf, like 6900XT\n\nprice, like 6950XT now\n\nsame features (only FSR2 now)\n\nthis should be named 6950XTX",
      "Only on launch to make sure it has all the bad publicity to make people spend more for Nvidia, then they drop to the prices they should've started that and every influencer starts recommending it as they wonder why nobody buys AMD cards",
      "Theres an inner voice saying this naming scheme is to scam customers but i've seen allot of retailers here misprice the 7900xtx the XT price especially in the last 2 months.\n\nProbably not helping sales when retailer has to cancel orders because of those pricing errors.",
      "So, we're getting 550$ rx7800 and 450$ rx7700. Classic radeon \"meh\" pricing.",
      "Checkout the RX 5000 series\n\nThe top card was a 5700 XT\n\n&nbsp;\n\nThen for the RX 6000 series, they lined the names closer to Nvidia\n\n&nbsp;\n\nNow I have no idea what they are doing",
      "V2 at the end :)",
      "Can we all collectively give AMD the same backlash we did to Nvidia for trying name the rtx 4070ti 4080? If we don't, we are hypocrites",
      "AMD naming 7000 series reasonably challenge: Impossible\n\n7900 XT should‚Äôve been the 7800 XT but they want to price it above the discounted Navi 21 cards since those are/were still in supply. \n\nThis ‚ÄúGRE‚Äù could‚Äôve been just 7800 non-XT. \n\nNaming does affect price on release, I guess.",
      "Next gen top card: RX 8999 XTXX\n\nFind a way to make a better card within that generation? Add some X's it'll work!",
      "The names of the new generation cards are weird overall, the 7900 XTX should be the 7900 XT, the current 7900 XT should be the 7900 non XT (or 7800 XT) and the 7900 GRE should be the 7800 XT (or 7800 non XT, depending on the other names).\nI don‚Äòt understand why they are not keeping it consistent between generations (which would actually help the people who are not very familiar with the GPU market).",
      "100% AMD trying to be confusing. This and the extremely slow GPU launches, non-existent features (FSR 3) all add up for the perfect disappointment.\nNo wonder people buy Nvidia. Even though it's overpriced to hell, they have actual products and features.",
      "Oh okay then . I guess we are fine with Chinese customers getting misled.",
      "I actually think that the 7900XTX should have been named **7800**XTX, and there should have been no 900-tier card this gen whatsoever. Last gen 900-tier cards competed against the 3090, while this gen AMD has nothing against the 4090.  \n\n\nWhich is a similar case going back to the 5700XT. It was meant to compete against the 2070/2070 Super, so it get a 700-tier name. It would have been silly to name it 5900XT.",
      "*super*",
      "RDNA 3 has double L0,L1, and more L2 cache",
      "As is tradition",
      "They just straight up lied about the FSR3 stuff. Long deadline, didn't hit it, i don't think i even saw them say anything about it?",
      "I'd say the naming of the 5700XT was wrong and now it is correct. AMD should not be required to name their products against the naming scheme of Nvidia, that just gives up their own initiative.",
      "*Tie*"
    ]
  },
  {
    "brand": "amd",
    "generation": "7000",
    "tier": "high",
    "matched_keywords": [
      "7900 gre"
    ],
    "title": "AMD Radeon RX 7900 GRE now available for $519",
    "selftext": "",
    "comments": [
      "Well you paid the ASUS tax, that thing is still probably $100 over MSRP.",
      "I mean, I could've potentially saved 31 whole dollars, but I'm still happy with my purchase in May.",
      "The best option in that price bracket. Great undervolt/overclocker too, reasonable amount of VRAM and even performant at RT gimmick, for those who care about it.",
      "Mfs rather wait a year to save 20",
      "That 4070 super did a lot of damage on the AMD price scheme lol. Good for consumers.",
      "Yeah. I'd sell it and get a RX 580 8GB. That beast outperforms a 1060.",
      "> at RT gimmick\n\nLol.",
      "Fuck. I just bought this but asus for $150 dollars more last Sunday from my local computer storeüò°",
      "Goes for the brand notorious for being expensive and overpiced, gets pissed because it was expensive.",
      "So you're saying I should upgrade from my RX 580 4GB?",
      "4070 super is 200 euros more expensive then the GRE for no raster performance improvement. No tx.",
      "Can confirm its a beefy card. Runs cybperunk at max rt without path tracing and games runs smooth idk what the fps is tho but its smooth on 1440p. Once you add path tracing.... good luck unless you downscale to like 1080p and 900p then upscale it,  itll be somewhat playable but bad visuals",
      "Is 20 bucks that much of a deal breaker? Lmao",
      "/r/buildapcsales energy",
      "Definitely not a gimmick. Nobody would say this of amd was on par with their hardware rt performance. \n\nRt features does matter to many looking for a card to last them years into the future. Calling it a gimmick is being facetious",
      "It's slotted in-between the 7800xt and 7900xt. The 7900 golden rabbit edition was originally a china only year of the dragon special release and got launched worldwide later on",
      "12GB of VRAM is a huge turnoff.",
      "I will buy it when it drops under 500‚Ç¨ so my 6600xt can go to my media PC",
      "> The Filthy Green\n\nYeah I'm just gonna block this nonsense.",
      "Y‚Äôall think DLSS and Ray Tracing are worth going NVID? 4070 super prices dropping here in Canada"
    ]
  },
  {
    "brand": "amd",
    "generation": "7000",
    "tier": "high",
    "matched_keywords": [
      "7800"
    ],
    "title": "AMD Navi 32-based Radeon RX 7800/7700 series reportedly targeting September launch - VideoCardz.com",
    "selftext": "",
    "comments": [
      "Just in time for the 6700/6800xt stock to finally dry up probably",
      "Really wondering how these will be positioned. With the 'low' price of the 7600 there is plenty of room to price these competitively - but I somehow have very low hopes.\n\nAMD can only really go for value with either card, since their price to performance is capped by the generationally rather mediocre 7900XT(X).\n\nMy guess is it'll be another very underwhelming release that's not going to excite anybody for AMD who isn't already, and disappoint those who already are. :D",
      "Yeah prices are already going up again due to lack of stock here in europe",
      "If the 7800XT is $600, then it's DOA. (Like the rest of RDNA3 has been)\n\nThe 4070 is already $600 and it isn't selling all that well.",
      "I can already see titles ‚Äúto little too late‚Äù",
      "Calling it now, 7800 is going to slot somewhere in between the 6800xt and 6950xt performance wise and they‚Äôre going to charge 600 for it. DOA",
      "got a xfx 6900XT for 250‚Ç¨ (pre-owned)",
      "A month ago I'd say you'd be spot on butttt the 7900xt and xtx have drifted down quite a lot.",
      "Narrator from the future: it did not make sense.",
      "The 7800 XT really needs to be no more than $600",
      "They have which is why the 7700 and 7800 will have to be priced even lower to make any sense. :)",
      "They'll target 549 with similar performance to a 4070 and 16GB of VRAM, because that's a \"good deal\" from AMD's point of view.",
      "I hope they don't do their usual idiocy where they overprice product on launch, collect negative reviews from most reviewers and then silently drop prices to competitive levels anyway a month later, a masterclass in failed marketing. Just go for a good price upfront",
      "AMD is currently sitting at 17% more fps per dollar on a GPU with equal raster performance, with EQUAL VRAM. 7600 vs 4060. \n\nAnd with the 7900xt they are offering 5-10% more fps per dollar compared to a 4070 ti with 66% more VRAM.\n\nThe next gen cards should slot right in the middle then to not look embarrassing. \n\nIf you drew a \"line of best fit\" through the middle it should look like this:\n\n7700 should have 10% more fps per dollar with 50% more VRAM than a 4060ti. So I'd guess $399 at 10% faster.\n\n7800 at 10-15% more fps per dollar than a regular 4070 with 33% more VRAM. $529-$579 depending on if it's equal to or 10% faster.",
      "They gotta to do what they gotta do to get those sweet poor reviews they love so much on the launch day and then drop the prices in a couple of weeks to reasonable levels.",
      "Because it is a bit to late.     \nI know that companies don't want to acknowledge this but crypto times are over, hopefully with some extra regulations crypto will also die out.",
      "And then I woke up, realising it was only a dream",
      "Wat how.",
      "You're not excited for the 50$ cheaper than Nvidia and 5% slower?",
      "7700 350-450, 7800 450-550     \nAnything higher DOA."
    ]
  },
  {
    "brand": "amd",
    "generation": "7000",
    "tier": "high",
    "matched_keywords": [
      "7800"
    ],
    "title": "HUB - Radeon RX 7800 XT Review, AMD Finally Worked It Out!",
    "selftext": "",
    "comments": [
      "Almost zero difference from a 6800xt even in ray tracing.",
      "AMD saw the horrible naming for the 4060 Ti and decided to copy NVIDIA's homework.",
      "6800 xt/7800 xt spiderman pointing at spiderman gif",
      "Is this a joke? Am I missing something?\n\nSame performance as last gens card? When was the last time that happened? The 6800xt is cheaper and has the same performance and vram? What an amazing launch. There has to be something I'm missing here what is it",
      "Why not name it 7800 without the XT?",
      "It is, it's just the naming is stupid.",
      "It's an x700 class card, not x800. It should have been called the 7700 XT and that card the 7700. It has 12 fewer compute units, 768 fewer shaders, fewer ROP's and TMU's than the 6800 XT while running on a lower TDP.\n\nIt's actually a decent generational uplift. They just decided to call it the 7800 XT for whatever reason.",
      "AMD finally worked out how to offer a 33% performance per dollar increase in 3 years?",
      "XT makes it sound more powerful lol",
      "69 vs 66 fps 1440p ray tracing and 38 vs 36 fps in 4K, no notable difference imo.",
      "Basically, the 7800 XT is a definite win in the current market, but only because nVIDIA didn't release the 4070 as a 4060 Ti for 499$, which I'm pretty sure they could have - but of course, why do that when AI balloons those margins anyway.\n\n7700 XT needs to drop to 399$ yesterday, however.\n\nBy the way, the 7800 XT does really well in Starfield.",
      "The last gen the x800 had the same die as the x900 GPU's.\n\nNow the x900 GPU's have their own die, while the x800 moved one die down in the stack.\n\nAnd they also moved down in price. at least relative to the previous gen at launch (500 now vs 650 then).",
      "So MSRP wise a $100 dicount 3 years later. How sad is that...\n\nEdit: $150\\*.",
      "Worked what out?",
      "It's 45% faster than a 6700XT, that's a good generational upgrade for once. Twice as fast a 5700XT. I think for once, it's a good product.",
      "This should‚Äôve been the 7800 not the 7800XT. As a 5700XT owner this looks like a good upgrade for the price, but like you said the naming is stupid.",
      "At least AMD dropped the MSRP VS what the 6800xt was, by $150. The 4060ti is more expensive than what the 3060ti launched at.",
      "7800xt is not successor to 6800xt. It's just a name. It's basically the successor to 6700xt. AMD, just like NVIDIA (except 4090), shifted all gpu naming to 1 tier up.This is like what happened to the old Radeon 6870 last 2010.\n\nSo compared to previous gen 6700xt, this is still good. Performance increase for almost the same MSRP, +4gb RAM and better ray tracing performance.\n\nIf I didn't buy 4070 TI last January (coming from 5700xt), the 7800xt price/perf ratio is very appealing to me.",
      "At least the 4060Ti dropped power a bunch and includes new features",
      "> It's $100 less than the 6800 XT's MSRP.\n\n$150 actually.\n\nFor reference, the 6700XT was $479."
    ]
  },
  {
    "brand": "amd",
    "generation": "7000",
    "tier": "high",
    "matched_keywords": [
      "7800"
    ],
    "title": "Undervolted AMD Radeon RX 7800 XT with 200W power limit matches average performance of GeForce RTX 4070 - VideoCardz.com",
    "selftext": "",
    "comments": [
      "\"And if my grandma had wheels she would be a bicycle\"",
      "Its like most of the latest tech products are clocked to high, resulting in much higher power consumption, heat and noise.\n\nOf course its not a secret that you can do it with any other product, be it the AMD or Intel processors, or NV cards, but it rather shows how much energy is wasted for a small bump in performance.\n\nI let my 7900XT run at -10%, with 87% max core and 95% voltage, resulting in way lower temps and power, while still enough performance for 4K gaming.",
      "The point is to match the ~200w level that 4070 consumes. Also the article hurts my head why can't they just say it's better already but consumes more power to do so. Now with drawing down it's power it only sacrifices 9% while being at level with 4070 this means consuming %40 less wattage. So the rdna3 is not efficient blah blah can be put to rest.",
      "Wouldn't a fair comparison be vs an undervolted 4070 as well?",
      "Yeah, just knocking down the max clock speed on my 6900xt by 100mhz and undervolting it by about 3% reduces my performance by about 1% on average (literally just a 2 FPS difference on average in games I had 200 FPS in) , but reduces power consumption by 100w on average. I don't even have to reduce power limit, the last 100mhz on clock is burning a hole through the card for almost no performance gain.",
      "Tell that to her pacemaker",
      "It is generally more efficient to run a bigger chip slow than a smaller chip fast. A 4090 at 50% power still retains 77% of the performance, which will probably still match or even beat the 7900XTX and 4080 while consuming only 225W. \n\nSource: https://www.tomshardware.com/news/improving-nvidia-rtx-4090-efficiency-through-power-limiting",
      "Not like you can undervolt your grandma with a couple of clicks though.",
      "The problem is, it's not a fair comparison\n\nThe 4070 also benefits from undervolting, you can cut it's power draw down to 140-160W with stock performance\n\nMy 4070TI undervolted (900mV at 2550MHz, +1500 memory) draws 150-170W with a 5% drop in performance from stock\n\nSo ~20% faster than the 7800xt while drawing less power",
      "Undervolting seems to be a smart idea if you plan on keeping your card for a long time. I saw more than a 100w reduction just using my monitors refresh cap over letting the frames run free.",
      "An undervolted, tuned card VS a stock card? Interesting, but not exactly academic. Let's put them both through the same undervotling and see how it all goes.",
      "I'd ride that",
      "In my experience running a capped framerate makes games look smoother too, running a game at a solid 90 fps feels better than swinging around between 100 and 200 fps. I also like the fans to run at a mostly constant speed, I usually play with a headset so I don't really notice the noise unless they are jumping around the fan curves like crazy",
      "That's because the article kinda forgot you can also undervolt the 4070.\n\n\n\n\nEdit: and not every 7800XT can be undervolted the same way, it's a hit or miss.",
      "And other one is Cyberpunk and Baldur's gate 3, which are Huang's tech demos.",
      "I under volted grandma pacemaker and she's much more chill now..",
      "Did you understand the point of the video ? watch the start again.",
      "Cyberpunk with RT off runs very good on AMD hardware, and she didn't turn RT on, so...",
      "Monolithic design are more effecient. To match 4090 level efficiency and performance, AMD would need to undervolt a seriously powerful multichip design",
      "7800XT is 346mm2, you have to add the MCDs too"
    ]
  },
  {
    "brand": "amd",
    "generation": "7000",
    "tier": "high",
    "matched_keywords": [
      "7900 gre"
    ],
    "title": "GeForce RTX 4070 drops to $499, Radeon RX 7900 GRE now at $509",
    "selftext": "",
    "comments": [
      "Love how on an AMD sub the primary discussion is NVidia and VRam, a tale as old as time.",
      "Mid range cards having to drop to 500 is a sad state.",
      "I hate the term future proof. Like back in the day if I could've got an 8800ultra with 8gb of vram, would it have held up for ten years? No of course not. One aspect means jack shit in terms of longevity.",
      "Peak AMD GPUs was the r9 390 > GTX 970 meme and then releasing the $200 480 next. It's been a bit downhill since then.",
      "Remember launch day 4GB RX 480s being rebadged 8GB ones that you can unlock with a bios flash?",
      "That's absolutely not true. It's raw raster performance is better per currency",
      "The 7900 GRE has been a fantastic GPU for me.\n\nIt actually runs surprisingly cool and quiet, it handles most games, even fairly demanding ones, at 4k fairly smoothly. As a Linux user, it runs basically flawlessly with no hassle whatsoever.\n\nI'm not going to argue the machine learning stuff, I don't use it. I just play games, at native resolution, and the 7900 GRE does that beautifully for me. The seamless operation, size, power profile, and overall great performance made it just the right card for the price.",
      "That doesn't sound like \"VRAM is the only thing AMD can compete on\" to me. Nice backpedal.",
      "4070 had just 12 gb of VRAM that isn't future proof imho",
      "Neither is 4070s or 4070ti. Yet people buy them.\n\nAlthough, right now 4070s is objectively the best. For right now.",
      "You WILL pay ¬£800 for a 4070ti and you WILL be happy",
      "Who buys a GPU to be future proof? They are like the item least possible to future proof. It's so, so, so much better value to buy mid range every few years. Plus by the time the 12Gb will be an issue, the card will be too slow to run at ultra anyway",
      "Not really, as on the whole AMD rasterization performance is significantly better even in the same price segment -- take the two cards in this headline, for example.\n\nI mean, at this moment I wouldn't pick AMD for my next GPU but either way I'm not going to sit here and fanboy over a corporation by making inaccurate, sweeping generalizations.",
      "Wait wasn't the 4070 already 500$ on launch or at least the unscalped price for the FE!?",
      "> Before that Nvidia and AMD used to mostly have VRAM parity across price points.\n\nNo? 970 with 3.5Gb, 1060 with 3Gb and 6Gb when the 480 had 4 and 8, etc.",
      "it's unfortunate we probably won't see mistakes like that again though. I remember some R9 390 owners could flash the 390x bios and also got a free upgrade.",
      "ok Klaus Schwab lol",
      "Good ol' Should've gotten a 390 meme. Good times.",
      "8/3.5 meme",
      "Ratchet and clank with RTX  uses over 13 GB OF VRAM.at 1440p so do many other games"
    ]
  },
  {
    "brand": "amd",
    "generation": "7000",
    "tier": "high",
    "matched_keywords": [
      "7800"
    ],
    "title": "AMD Radeon RX 7800 XT is now available for $489",
    "selftext": "",
    "comments": [
      "What is this, a $10 discount? Lol",
      "Competition is nice. :)",
      "LMAO. Let's make an article asap.",
      "As much as I want this to be true, I've heard this before. Fingers crossed.",
      "Yes\n\n  But first time they've dropped below $500 I believe.",
      "24/7 news cycles are a disease.",
      "489 is a good price. That‚Äôs only a 100 more than what I paid for my 6750 xt 2 weeks ago.",
      "I cant wait for rdna4 .... If the rumors are true its gonna be a great time for upgrade late 2024...",
      "$10? lol",
      "Isn't it literally a 6800 XT in almost all ways? And we're happy now it's $150 off after all this time?\n$400 as MSRP would have been a good milestone.",
      "why even make an article and why are so many people upvoting this?\n\nthis is the most non-news I have ever seen on this sub, seems odd",
      "Yes it is. It should be $450 or cheaper in my opinion.",
      "It wasn't priced right to begin with and it isn't priced right now. \n\nYour job as a consumer is to expect and demand better. Your job is **not** to cheerlead publicly-traded megacorps. There's no benefit in doing that.",
      "Oh god don‚Äôt get me started. And we wonder why our society lives in a state of pure ADHD-riddled anxiety.",
      "should have got a 6800 for 400",
      "True we can only hope...\n\nall i want is a rdna 4 gpu around 7900xtx raster performance plus 5-10% improvements and 20-25% better ray tracing performance with some improvements in power consumption for 600-650‚Ç¨ .. so i can upgrade my 6950XT.\n\nWe can dream cant we? :D",
      "I checked for this upgrade some day ago and if your cpu is good enough it's double the fps in some game (and without the new fluid motion frame).",
      "> This entire sub was up in arms for months leading up to the release demanding a 550 msrp\n\nNot me.\n\nThat's incredibly little progress gen-gen for what is really a 7700 XT with a new name. Heck, that was a price increase! Why would you tolerate such a high price increase?",
      "Come to 440 fast i want one toooo",
      "Did you get a stroke?"
    ]
  },
  {
    "brand": "amd",
    "generation": "7000",
    "tier": "high",
    "matched_keywords": [
      "7900 gre"
    ],
    "title": "Best $550 GPU in 2024? RTX 4070 vs RX 7900 GRE: The Ultimate Comparison!!! [Spoiler: 7900 GRE wins, even in RT games]",
    "selftext": "",
    "comments": [
      "Surely the card to beat would be the slightly more expensive $600 4070super, no?\n\nThe [Techpowerup RT benchmarks](https://www.techpowerup.com/review/sapphire-radeon-rx-7900-gre-pulse/35.html) has the 4070super coming out significantly ahead at 1080p and 1440p RT. The 4k ones are close, but both cards are eating shit and dying at 4k RT (FPS in the 15-30 range), so not really relevant as no one would be running those settings.\n\nIt should also be noted that while the GRE is a faster card, it takes a bigger hit to FPS when using RT. This allows the slower 4070super to, generally, pull a pretty decent lead in RT.\n\nEither card would be a solid buy. It'd depend on the games you play, the settings you like, and how long you hold a card.",
      "It's crazy how people talk because in the latest generation while Nvidia definitely still maintains a lead it's not as big as it used to be.\n\nI find none of the games I play even use RT.",
      "Loved that he pulled up Ratchet and showed that despite having architectural advantages for RT, and hardware advantages for Frame Gen, they amount to nothing because NV shortchanged the framebuffer. \n\nIt's a 2023 game, at that. That should give anyone buying a 12GB NV card for RT and FG in year of our Lord 2024 some serious pause.",
      "Bu bu bu but AMD is 19 generations behind Nvidia in RT performance?",
      "Or even better, I was able to get a card like the 7800xt for around the same price as the 4060ti. It beats the hell out of it pretty much in everything. Even RT, or at least close\n\nSo what's the big deal? It evens out, and when you don't need RT, it has a massive gain\n\nNo DLSS? I don't even need to use upscaling because I was able to get more AMD card for the same price. \n\nAnd since I've moved to Linux it's a moot point anyway. Nvidia is garbage there (first hand experience)",
      "I don't really get this card. If you upsell to the 4070s for $50 more, you get better efficiency, a better feature set, the same raster performance and better rt performance. I can't really see a world where that's not a better deal.",
      "I don't know how anyone justifies buying this over a 4070S for $50 more tbh.",
      "Maybe I‚Äôm dumb, but wouldn‚Äôt buying either of these cards for RT purposes be a poor idea? It seems like you really need to jump up to the elite tier to get consistently decent FPS with higher resolutions while using RT.",
      "Man, people are just weird. \n\nWhen the rtx 30 series came out, people said finally RT is usable. Even at the 3060ti\n\nNow suddenly cards that destroy it, and ones 2-3 tiers above, are called too weak",
      "The 12 GB VRAM is the biggest problem with the 4070 and 4070S. I wouldnt buy either for this very reason.",
      "A cut down N31 barely beating a glorified midrange GPU while using 60% more power is not exactly something to be happy about.",
      "Yep for $50 extra you get significantly better efficiency, better raster performance in most titles, better RT all around, and DLSS. Probably a no brainer for most people.",
      "Yet there are so many ppl defending it.",
      "Spoilers: Title is editorialized version of a very editorial title. \n\nThis guy has no problems with comparing frame rates with unequal image quality. Why doesn't test the high settings with RT in Ratchet and Clank? Why doesn't he move down to balanced DLSS that still looks better than quality FSR? If he says that 76 fps is \"borderline\" playable with frame gen due to latency, how come he doesn't show the latency on the 7900GRE without Nvidia's Reflex technology. \n\nThe thing with this channel, and most techtubers, is that they tend to downplay Nvidia's advantages, and oversell AMD's. This is not surprising, they must present things as more of an equal footing for their audience. For narrative reasons, if there is an underdog, it must be plucky one.",
      "16 vs 12 GB of VRAM. That should make the AMD cards usable for one or two more years. 290/390/4x0/5x0 are still usable today if they are the 8GB variant. Those are up to a decade old now.",
      "Epic sent a love letter to AMD with SW Lumen. \n\nApparently it hammers compute, which is why AMD cards bench beyond their weight in games like Immortals of Aveum despite the entire game being designed around RT and not having any option to turn RT off.",
      "Impressive, very nice.\n\nNow let‚Äôs check the Productivity benchmarks:\n\nOh wait-",
      "> It's crazy how people talk because in the latest generation while Nvidia definitely still maintains a lead it's not as big as it used to be.\n\nThe advantage is still there just not as visible when you test it in \"we have RT at home\" games like F1, Far Cry or Spiderman. In Alan Wake 2 or cp77 rtx was 50% faster. Other than that, 7900 GRE have 33% more RT cores than 7800xt, the card which is a closer competitor in raster to 4070.",
      "Pretty much this.  They were definitely comparing the GRE to the wrong card.",
      "Part of it might be more people have shifted to 1440p 144hz+."
    ]
  },
  {
    "brand": "amd",
    "generation": "7000",
    "tier": "high",
    "matched_keywords": [
      "7900 gre"
    ],
    "title": "Radeon RX 7900 GRE: The Best RDNA 3 GPU & You Can‚Äôt Really Buy It!",
    "selftext": "",
    "comments": [
      "Yeah at this point we‚Äôll be lucky if the 7800xt beats the 6800xt, at least consistently.\n\nSad sad generation from both vendors (apart from 7900xtx, 4080/4090)",
      "Barely faster (\\~8%) than the 6800XT, while featuring 80 CU.  \n\n\nThe 7800XT will feature 60 CU - that is a 25% reduction - While its clocks should be \\~12% faster. The 7800XT will no doubt be slower than the 6800XT.",
      "8% faster than 6800 XT at 1440p...\nThis pretty much confirms the 7800 XT will be slower than the 6800 XT",
      "\\>gets beat by the 6950xt that goes on sale for under $600 every couple of days",
      "Becoming more satisfied with my purchase of the 6800xt for $480 day by day by day.",
      "What 7800xt performance will look like if it has even lower spec than 7900gre?",
      "Agreed.\n\nMy hope is that Intel Battlemage will turn out decently and put pressure on AMD and Nvidia. Nvidia might give up on the midrange gaming segment and cater more towards AI, but if the rumors about RDNA 4 ditching the high-end gaming segment turn out to be true, we might see AMD and Intel battling for marketshare and mindshare in the midrange in the next years.",
      "I guess AMD signed up for the green team's \"The way you're meant to be milked\" sales program.\n\nWhat a joke. What should've been legitimately called a 7700XT and sold for 399USD is rebranded as a 7900 series and sold for 50% more. ![gif](emote|free_emotes_pack|facepalm)",
      "another bad joke from AMD. this 7900 card doesn't even beat the 6950xt!",
      "Some people have a hard time justifying spending $450 used $520 new for a three year old card (which the price has remained the same for the past year). Data from pcpartpicker and eBay sold.",
      "I just gave up and bought a 6700xt and decided to wait this generation out. Can't even properly RT without DLSS 3 unless you buy 4070ti.",
      "The 4090 isn't the new 1080 Ti due to the price alone, it had to cost 1200$ max to have a discussion here.\n\n1080 Ti wasn't great only due to its performance, but it was offered at a somewhat affordable price point - for an enthusiast card, that is.",
      "If it's faster than a 6800 and costs $400 I'd be fine with that. So I won't be fine with it because it will be $550. 10% more at current market prices for 10% less performance. Yay.",
      "Yeah, I don't care how many people use Nvidia's garbage pricing to excuse AMD's garbage pricing. The 7900 XTX's most direct competitor was already the 4080. It should have been called a 7800 XT, but calling it the 7900 XTX was their justification for saying \"the generational pricing is the same,\" even though their 80 series competitor moved from $650 to $1,000.\n\nThe 7900 XT should have been the 7700 XT, and this should be the 7700. The 7600 should be a 7500. The whole generation is a series of half-truths and nonsense backed by leveraging Nvidia's greed to fuel AMD's.",
      "I think this is what they call a Duopoly",
      "Why isn‚Äôt HUB throwing a fit about the naming shenanigans like they did with the two 4080 SKUs?",
      "Then buy 6800 XT :>",
      "at much lower power consumption. If they had released it for sale not just for prebuilts then the bigger problem would have been 7900xt which I have seen dip down to 700. \n\nBut since it's only being sold in prebuilts I imagine they intentionally lowered the performance by lowering the power limits because prebuilts are notoriously hot.",
      "So 4080 16GB and 4080 12GB is misleading too confusing for consumers but 7900 XTX, 7900 XT, and 7900 GRE isn‚Äôt? \n\nI‚Äôm not even defending nvidia here just wondering where the same logic is. \n\nAnd yes this card is woefully underpowered to be a 7900 SKU. Realistically there should only be one",
      "Yet hub calls it \"the best RDNA3 card\""
    ]
  },
  {
    "brand": "amd",
    "generation": "7000",
    "tier": "high",
    "matched_keywords": [
      "7900 gre"
    ],
    "title": "Bye bye 2070s hello RX 7900 GRE",
    "selftext": "I have joined team red! ",
    "comments": [
      "Welcome aboard to team red! I guess I would have bought RX 7900GRE, but it was released later and I already had RX 7900XT.\n\nBtw I still have RTX 2070S in my secondary PC and it¬¥s still doing a good job.",
      "Say 3090 cause it sound better üòéüòéüòé",
      "I have been toying with the same idea but I have a 2070 non super.. how are you finding the performance difference?",
      "Yeah a massive jump in fps, for example on far cry. 6 at high settings on 2070s was like dropping to around 50, I can now get around 100 on ultra with 7900 gre.\n\nEdit: this was at 1440p btw",
      "Tonight on things that didnt happen.",
      "The GRE is also right between the 7800XT and 7900XT (some say the GRE is like the real 7800XT and the 7800XT is more like a 7800 in terms of the upgrade from 6800/6800XT and what not. Unnecessary info but hey).",
      "Excellent choice! And with a good little OC/UV well done and VRAM OC, this card can claim to have the performance of its big sister the Radeon RX 7900XT (at stock settings). Hoping for a long life of rasterization to your map, greetings!",
      "about double fps in 1440p in most games",
      "Same cannot be said for 2070 mobile.\n\nAlthough that card will work, you're basically stuck with 1070ti performance but with added ray-tracing.\n\nWhich is really weird cause RT performance is better than raster performance in some cases, and in other cases turning on RT will turn 240fps into 30fps, but at the same time you can overclock it to the moon on basically any Vulkan game and gain absolute massive performance seemingly out of nowhere, like stock OC and max OC brought BeamNG from 50fps to 90fps but only on Vulkan.\n\nIt's honestly kinda weird having a card with such massive gains and relatively simple overclocking, and then moving to a modern AMD GPU where manually overclocking might loose performance in some cases so it's best to just leave it as is with how advanced modern boost logic has become.",
      "I went from a 3060ti (2080super equivalent) to a 7800xt and went from about 100fps medium-high  in the games I play at 1440p to 150-180fps ultra 1440p.\n\nWell worth it, especially because I sold my 3060ti for $300 USD equivalent and bought my 7800xt for $500 USD. Best $200 upgrade I ever made",
      "Roughly in between the 4070 super and 4070 ti",
      "Yeah I dont get why Nvidia fanboys come to AMD sub reddit just to lie. I got a 7900XTX and never had a single problem once. They don't realize people that actually own these gpu's know they're full of it. Even if he happened to have a defective GPU its messed up you sold it to somebody and told them it works im sure... I dont trust scammers.",
      "Is it worth it to upgrade from a 6700XT to the 7900 GRE or should I wait for RDNA 4?",
      "Around 60-70% uplift from a 6700xt. Personally, it‚Äôs a pretty decent upgrade especially with the overclocking potential, but if you don‚Äôt need it right now, I would say wait for rdna 4s midrange to drop around end of this year. Should be around 7900xt-7900xtx in raster, but apparently rt is getting a big boost over rdna 3.",
      "Where does the GRE fall performance wise?",
      "Nvidia users must be the saltiest people. They need to validate their purchases by bashing anyone enjoying AMD cards. I swear, daily hateful posts on their sub.",
      "![gif](giphy|B6Jr28VwfxUFa)",
      "I moved from nvidia to amd (4070 to a 7900xt), and I have been super impressed with it. I tried amd before and had a lot if issues, but this time I've had better luck with amd than nvidia. Just saying...",
      "Depends on what your expectations are.",
      "I got the 7900 GRE two weeks ago and have been loving it so far. XFX tri fan model, it‚Äôs quiet and is massively faster than my old Radeon VII (which I believe was a smidge under the 2070S in performance but in the same ballpark.)\n\nTripled my framerates in Star Citizen, and I‚Äôm getting ~50% better frames in Cyberpunk even with v. high raytracing and all settings maxed (was on a mix of med-high before). \n\nHaven‚Äôt tried frame gen yet though, what‚Äôs a good title to test?"
    ]
  },
  {
    "brand": "amd",
    "generation": "7000",
    "tier": "high",
    "matched_keywords": [
      "7800"
    ],
    "title": "No frills 7800X3D + 7800 XT (opinions?)",
    "selftext": "",
    "comments": [
      "![gif](giphy|eKNrUbDJuFuaQ1A37p|downsized)",
      "Yep, that‚Äôs a box that plays games.",
      "Vertical mount is a frill, isn't it?",
      "Let‚Äôs see Paul Allen‚Äôs PC",
      "Just put the monitor in vertical mode also and you're all set.",
      "Nice and clean. Enjoy, m8 üëç",
      "My only nitpick is that you have 2 fans intake and 4 fans exhaust. In fact, since you have an air cooler for the cpu, my best recommendation is to remove all fans from the top and put one of the fans on the front if you can (it looks like there‚Äôs room for one more fan on the bottom front if you move the front fans closer together, but I could be wrong). The front to back push-pull air configuration works best for air coolers, and maintains positive pressure.\n\nEdit: nvm about the negative pressure, didn‚Äôt realize it was the Lancool 216, but it would still be a good idea to drop at least two of those top fans, if not all three, going with an air cooler",
      "Look at that subtle of black XTX. A Tasteful thiccness of it. Oh my god, it even has a Radeon logo.",
      "When 5800X3D came out in ‚Äô22, I think they really came into their own, commercially and practically.",
      "Digital computers are a frill. I do all my gaming on a monochromatic abacus.",
      "Source: https://www.tomshardware.com/how-to/set-up-pc-case-fans-for-airflow-and-performance\n\nThe issue with having 3 exhausts on the top and 1 exhaust on the rear is that the air will be pulled vertically more than horizontally, leading to heated air from the GPU interfering with the cooling of the CPU. Straight horizontal push-pull setup, assuming you have a positive pressure system, means that most of the hot air will exit through the back of the case and not interfere with the CPU cooler.\n\nAnd on top of that, having a negative pressure case will lead to the issue of heat recycling, since the case will naturally suck in air through cracks and crevices, and some of that air will be freshly exhausted, heated air. You always want to make sure you have more intake than exhaust, but not too much more.",
      "He might be ok. That's a LianLi 216 case so those 2 front fans are 160mm and they move a shit ton of air.",
      "Beautiful! I love blacked out builds",
      "dat reference design üò©",
      "How loud is that 7800 XT?",
      "Nah, you should've bought the gpu 7800 XT3D",
      "Earned my upvote üòÇ",
      "Don‚Äôt know why you‚Äôre down voted, it‚Äôs definitely not an optimal combo",
      "‚ÄúIt even has the white Taichi OC edition, oh my God‚Ä¶‚Äù",
      "HEY PAUL!"
    ]
  },
  {
    "brand": "amd",
    "generation": "7000",
    "tier": "high",
    "matched_keywords": [
      "7800"
    ],
    "title": "Alleged Prices of AMD's RX 7700 and RX 7800 Leak",
    "selftext": "",
    "comments": [
      "TLDR: AMD is thinking about pricing the RX 7700 for $449 and the RX 7800 for $549.",
      "Oof",
      "If they lowered both by 50 bucks to 400 / 500 it still wouldn't be the great generational uplift people want but the reviews would be much better.\n\nSeems like they need to squeeze every dollar tho before prices inevitably fall.",
      "Whales don't buy 450 and 550 GPUs...",
      "Eh I'll skip this generation absurd pricing üòî",
      "Genuine question, is anyone here getting GPU upgrades every generation? I just upgraded from my 1070ti and I don't plan on getting a new one for atleast 5 years.",
      "At this point if someone wants better RT they might as well be shopping green though.",
      "No great. Not terrible. Everyone will just wait for the inevitable price drops. Or AMD will change the price last minute anyway.\n\nDrop $50 and it‚Äôs probably a good deal.",
      "Normal people don't upgrade every gen. \n\nBut reddit is a small town, so most intense people are very vocal in here.\n\nIf you come from old gens is fine to upgrade",
      "The 6800xt goes for $480-520 now, has a higher timespy score according to leaks, and they're trying to sell the 7800 at $550 with no significant extra features, atleast Nvidia's new cards have DLSS 3. This is DOA until price drops like the 7600.",
      "They need to sell some to the \"whales\" first.  Then when they're had their fill and stop buying, AMD will have to drop the prices.  By the time that happens the free Starfield deal will probably be long over, but maybe Fall Zipfest will come around again.",
      "AMD and nVidia have effectively set up a duopoly. It seems like AMD isn't willing to compete for market share.",
      "The name isn‚Äôt important. The price and performance is what matters. If a 7800 is the same or slightly better than a 6800xt for $499, with some newer features and more efficiency, then that‚Äôs a pretty good offering, and a good improvement over previous gen price to performance.\n\nAt $549 it‚Äôs not BAD, it‚Äôs just not that exciting.",
      "So the 7800 is a slightly more expensive 6800XT. A whole new process node and R&D for...AV1 encoding I guess?",
      "you are comparing the wrong product and the wrong time. \n\n6800XT launched at $649 while 6800 was $580.\n\nthis 7800 non-XT will be lower than both at launch for $550.",
      "Neither of these prices are competitive enough, AMD just seems to be following the same trend again, price just close just to Nvidia to ‚Äúseem‚Äù better. \n\nIMO they need to be way more aggressive if they have any intention to capture market share. But even 400 for 7700 isn‚Äôt looking exactly great when the leaked/rumored benches say 15% better than 4060Ti and having 12GB VRAM, while the public sees DLSS, Frame Generation and RT as better on Nvidia. And that‚Äôs ignoring the previous gen market prices.",
      "The issue is price drops generally only happen in USA, in other places prices can be quite sticky. Which is quite sad, Nvidia on the hand is just giving an even larger FU to consumers making AMDs dirt bag money squeezing look like a good deed.",
      "Well not exactly whales, but if there‚Äôs just some fraction of people out there willing to buy at 550, selling at 500 at launch could mean fewer profits.",
      "We need a better competitor than AMD in the GPU market. AMD just doesn't care.",
      "Irrelevant. 6800 XT is cheaper now than the 7800 will be. Anyone buying in the near future should only buy a 7800 if all 6800 XTs are gone."
    ]
  },
  {
    "brand": "amd",
    "generation": "7000",
    "tier": "high",
    "matched_keywords": [
      "7800"
    ],
    "title": "ASRock Radeon RX 7800 XT graphics card with 16GB VRAM spotted at EEC - VideoCardz.com",
    "selftext": "",
    "comments": [
      "Probably. And priced $600-650. So basically the same 6950xt you can buy now with more power efficiency. The rumored 7800 will compare the same way to the 6800xt.",
      "Any predictions as to where this will be in perf? 6950 xt?",
      "That's how it has always been, newer cards at the same street price as older cards at similar prices but better efficiency and more features. \n\nThe problem is 2020-2022 shortages inflated street prices. On top of that, Nvidia also adopted shrinkflation by using much smaller dies and buswidth than previous generations, plus stagnant VRAM sizes.\n\nRTX 4090 being seen as \"good value\" by some is just insane. It's a great card and a good purchase for enthusiasts with money, just not good value.",
      "No, cards like 1080/1080 Ti/3080 genuinely moved the price/performance needle forward at their release. They were a no-brainer if you could get them.",
      "Once again it's,  7900xt, 7900xtx, 4080, or 4090 and nothing else.  If you have a 6700xt or a 3060ti or higher either get one of those 4 or skip this generation.  Everything else is mid and won't make a big enough difference to warrant the money spent",
      "RDNA3 as a whole is just doing terrible. It's a somewhat decent iteration of their GPU tech being absolutely killed by how out of touch AMD is.\n\n7 months after launch and RDNA3 is still not on the steam hardware survey, even though it has been widely available; RDNA2 was comparatively impossible to acquire (partly due to GPU apocalypse and partly due to reduced production quantities in favor or Zen 3 and Console APUs), but it still manage to break into the steam gardware survey within the same time frame under multiple entries.\n\nIf AMD still believes that they can do Nvidia pricing*0.90 and manage to get sales after this, then there's no saving how out of touch the leadership of the Radeon Group is, especially with how much wider the feature set chasm keeps growing between Nvidia and AMD.",
      "4070 is a solid card. I wouldn‚Äôt worry too much about it. We have no release date on this card yet anyway. Or actual reviews.",
      "It‚Äôs not that 4090 is a good value as much as all the other offerings from them are bad value. It‚Äôs simply the best of them all. Jensen realllllllly wanted his ‚Äúthe more you buy the more you save‚Äù to be true I guess.",
      "I mean yeah it‚Äôs pretty good, but you can already buy a 6950xt for that price and performance right now. So not very exciting.",
      "Yea, at MSRP. then Nvidia saw the scalpers making huge profits and said \"that's a good idea.\"\n\nNvidia decided to slam that needle backwards with the 40 series",
      "calmly AMD,  calmly, you have time",
      "Well unless you are swimming in cash and can afford to buy RTX 4090, then you best not ugprade at all. \n\nBut of course it is only you who knows what is the performance you really need.",
      "85 - 90% of nvidia's pricing, especially at the high end, just isn't gonna cut it. The 4080 might be insanely overpriced, but in comparison to the 7900 XTX, it's good value. \n\nI'd rather spend ¬£1200 for something that feels a bit more complete overall, compared to a ¬£1000 card that has outdated tech.",
      "damn i just bought the 4070 thinking the 7800xt is never coming. I waited for so long with my 1060 for AMD to release their lineup.",
      "You didn't lose anything by doing that. Except maybe 4gb extra VRAM. But you got a version of frame generation that actually exists, and better upscaling and RT performance.",
      "7900xt only needs 2, so I would think only 2.",
      "Inaccurate 1070 = 980ti and 3070 = 2080ti",
      "I see a lot of folks saying it's gonna perform like a 6950XT. I'm not saying I know that, this wont be the case. All I'm saying is the rumored N32 would have at least 25% less cores than the 7900XT, while the 7900XT is 10-15% faster than the 6950XT. \n\nSo basically, unless N32 is seriously impressively clocked i struggle to see how that adds up. I think N32 would have to be closer to 72CU's to compete just based on the performance we know from N31. At 60-64CU's it'll perhaps compete with the 6900XT.",
      "I don't see this card being as expensive, let alone more expensive than the 4070 even if it is faster. Unless, as usual, AMD just could not care less about being competitive.",
      "This gpu is going to flop hard"
    ]
  },
  {
    "brand": "amd",
    "generation": "7000",
    "tier": "high",
    "matched_keywords": [
      "7800"
    ],
    "title": "Graphics Cards Retail Sales Week 36 2023 (mindfactory.de) - RX 7700XT/RX 7800 XT Launch",
    "selftext": "",
    "comments": [
      "People with less than 300eur who want DLSS2 and/or 12GB VRAM",
      "No matter what anyone says, 7800 XT is one of the greatest value cards launched in the last few years.",
      "Who is still buying the 3060",
      "If you depend on CUDA and tensor Cores for productivity, you wouldnt be looking at a 3060.",
      "It's one of the best if you're down like 2 gens+ (I'm one of those people and am now the proud owner of a PC Hellhound 7800XT for a fresh build). Slightly improved 6800XT power for less than it, yeah that's a good deal! Plus a guaranteed fresh card. But other than that, I get why people aren't awfully pleased. I can see it from both sides.",
      "Maaan, you can get a 6700xt that smacks tf out of a 3060 for that and it's only missing DLSS lol.",
      "Some absolutely insane takes in this thread. From everything I've seen:\n\n\\-7800XT offering 6800XT performance for $100 cheaper is apparently a great deal but 4070 offering 3080 performance for $100 cheaper is a ripoff.\n\n\\-RT is still a gimmick only worth using in several games and no one actually cares about it\n\n\\-Frame gen is trash and no one cares about it\n\n\\-FSR is \"good enough\" therefore you don't need DLSS\n\n\\-12GB VRAM is only good for 1080p. If you have an 8GB card you miles well use it as a doorstop at this point.\n\nIf all of that was true AMD would have a 50%+ market share in the GPU space right now. Then you go look at the real world and realize that the PC gaming market is generally pretty enthusiast skewed where people do care about new features like RT, good upscaling, and frame gen and Nvidia happens to dominate in all of those aspects atm.",
      "The 3060 is way better value than the 4060 and often beats it when memory limitations happen.\n\n\nBetter question is who the fuck bought a GT 1030",
      "15 Intel employees keeping those stats up.üëç",
      "> AMD outsold Nvidia in this week's sales\n\nOnly in a single store in Germany (called mindfactory). In reality, it's getting worse for AMD. 4090 alone outsold all of Radeon 7000 series.",
      "So you pay more to get less performance just to compensate it with DLSS instead of paying less to get way better performance natively. Wow..nvidia buyers are different.",
      "am i the only one that thinks that people are being too soft on the 7800xt ?\n\nyes its half decent for the current market\n\nits not good\n\nno wonder they keep pushing these ridiculous prices when the customer base acts like this for a card with the same performance of a card released three years ago",
      "opinions like yours are exactly why companies like nvidia use and abuse their customer base\n\nyou may think im wrong and disagree with me but at the end of the day look at how much more you are paying for a midrange gpu compared to a few years ago\n\nand lets not go to the high end\n\nthese new generations are too soft and that reflects directly on the prices",
      "But the 4070Ti is still 18-20% faster",
      "Yes that's unfortunately the gap between these performance tiers now, it's not like AMD is doing much better, the 7900XT is around 28% faster also for 60% more money.",
      "4070 is a decent card, the main problem with it is the price",
      "It‚Äôs probably people wanting the performance of a 3090/3090 Ti at half the price.",
      "Same perf for 20% less msrp.\n\nIf someone needs to buy a GPU for gaming only, what would you recommend then?",
      "(Germany has only 1% of the world's population)\n\nSteam charts are international, and they show that 4090 outsold entire Radeon 7000 series. So that is why you see so many people on reddit with 4090s - people are actually buying them.",
      "i recommend this gpu 100%\n\nbut i wouldnt call it a good deal or amd¬¥s gift to gamers ...\n\nthis is still a greedy inflated price"
    ]
  },
  {
    "brand": "amd",
    "generation": "7000",
    "tier": "high",
    "matched_keywords": [
      "7800"
    ],
    "title": "RX 7800 XT: Optimizing efficiency (huge effect)",
    "selftext": "Hi guys,\n\nI was trying to optimize the efficiency of my AMD card and wondered why I can't set a lower power target than -10%. So I started benchmarking with different max clock speeds. I don't know if this is good in \"real life gaming\" performance, but I did it on the fly and just thought I could post it on reddit as well. (Spoiler: Yes, it's amazing!)\n\nKeep in mind that the specified clock rates are those that I have set in the software and that the real clock rates are somewhat higher. I also only ran the tests in a 3DMark test, as it is pleasantly short.\n\n&#x200B;\n\n* **Model:** ASRock Radeon RX 7800 XT Steel Legend 16GB OC (90-GA4RZZ-00UANF)\n* **Driver:** 24.1.1\n* **Benchmark:** 3DMark - Solar Bay Custom 1440p, Fullscreen (no Async/Vsync)\n* **Tool:** AMD Adrenalin Software\n* **Default Card Settings:** Power Target: -10%; Voltage: 1.070V\n* **Watt:** average consumption in GPU-Z (by eye)\n* **ppw:** points per watt\n* **clock speed:** corresponds to what I have set in the program; real clock frequency was 100-120 MHz higher due to the lower GPU voltage.\n\n# Scores:\n\n**Stock:** 74 125 - 276W - 268,6 ppw\n\n**Default:** 77 211 - 250W - 308,8 ppw\n\n**1700 MHz\\*:** 44 898 - 130W - 345,4 ppw\n\n**1750 MHz:** 61 222 - 167W - 366,6 ppw\n\n**1800 MHz:** 62 337 - 170W - 366,7 ppw\n\n**1900 MHz:** 65 702 - 177W - **371,2 ppw**\n\n**2000 MHz:** 68 388 - 185W - 369,7 ppw\n\n**2100 MHz:** 70 397 - 195W - 361,0 ppw\n\n**2200 MHz:** 72 539 - 205W - 353,8 ppw\n\n**2300 MHz:** 74 704 - 220W - 339,6 ppw\n\n*\\*real clock was just 1275 MHz*\n\n&#x200B;\n\nIn its original state, the RX 7800 XT only achieves an efficiency of 268.6 points per watt. My best result at 1900 MHz is 371.2 points per watt (+38%). Comparing the relative power consumption with the stock settings, the card would consumes only 200W instead of 276W (stock score divided by best points per watt value).\n\nThe reduction of the relative power consumption to 72.5% is in my opinion extreme potential. The card is at least as good as Nvidia's RTX 40 cards whose power target would be set to \"70%\". In absolute numbers, this means: With 1900 MHz, 1.070v and \"-10%\" power target, the **FPS loss is 11.4%** while the **power consumption is only 64.1%.**\n\n# Screenshots from Starfield:\n\nhttps://preview.redd.it/zmmh18byrufc1.png?width=2560&format=png&auto=webp&s=b4bb30ebaa7ab17d2ece426747f141facdf45cca\n\nhttps://preview.redd.it/ku1w4abyrufc1.png?width=2560&format=png&auto=webp&s=9f6599acf16b77213a0f85aaa021aec7d2d53541",
    "comments": [
      "Lol, If I UnderVolt my 7900XT it does NOTHING for me if I don‚Äôt reduce my already EXTREMELY high Boost clocks from ‚Äústock‚Äù approx 2860 down to about 2700 or 2600 is then where I see a reduction in power with minimal fps loss maybe 2-4fps",
      "Thank you! But that's nothing special imho. From what I've heard, many people already undervolt their GPUs with lower power target, so oddly this doesn't really seem to be a thing. But I haven't really bothered with overclocking for 10 years because the benefits have always been quite small these days.\n\nMaybe I'm just oldschool and there aren't that many people who care about efficiency anymore. Don't get me wrong, I'm the typical OC guy from 2006-2012 when hardware in general had much worse efficiency. But nowadays all manufacturers overdo it and mid-range products already consume 200-300W. And entry-level models consume less, but in some cases there is no trace of efficiency anymore... Yes i look at you, RX 7600 XT with 190W!\n\nAMD may not have optimized the cards well, but I am very happy that RDNA3 itself is great.",
      "I was able to reduce my overall power consumption and increase my max core clocks on my 6800 XT by doing an undervolt. I don't think setting a power target would be nearly as good as a proper undervolt for AMD GPUs. Taking some voltage away allows the core to boost higher and use less power so a power limit shouldn't be necessary. I think I knocked off like 30-60w on my 6800 XT and got \\~10% more performance with the undervolt. I also went through this with my 4090. Yes, I know the architecture is different but I got the same results as my 6800 XT in terms of doing a proper undervolt rather than power limiting which knocked off about 50-100w depending on the situation and I gained \\~3% performance. Undervolting should always be better than power limiting from my experience and I have been overclocking GPUs since the 3DFX VooDoo 2. AMD in particular is really damn good with undervolting - both their GPUs and CPUs.",
      ">Everybody is going to hate this analogy, but AMD factory tunes their GPUs to be muscle cars, they don't have Tensor Cores or CUDA Cores or PhysX chips or what have you, so they make up for the difference with software optimizations and raw horsepower.\n\nWell I don't really think that's quite accurate, it's more like a base model or mid spec car vs fully loaded/top trim, you get the same on-road performance, without all of the bells and whistles and maybe flashy coat of paint that the  Nvidia cards come with.\n\nI also don't understand where this notion that AMD cards have more 'raw horsepower' comes from or what it's founded in. They're just more basic/less frills gaming focused cards, which if anything, simply have a larger fuel tank (more VRAM). I'll note you didn't say more, you just said raw horsepower, but I've seen that term used (often with the word more) since RDNA2.",
      "Same with my xtx at stock it tries to boost to 3gz and consumes an ungodly amount of power. I limit it to 2650 and see a reduction of about 50-70 w with no real loss in performance",
      "You can of course do both, underclock for efficiency or to increase/hold performance, but since the cards are so far from the sweet spot, it's more profitable for me to limit the performance.\n\n// Btw:  Lowering the voltage in AMD Adrenaline actually is like an offset and i guess it works as a percentage. In other words, lowering the voltage from 1.150v to 1.070v (93%) also reduces the voltage in games from e.g. 0.900v to 0.837v. That's why it's so rewarding to explore the sweet spot.\n\n// 1. feb 24 // It seems under a specific threshhold it is not like an offset. I testet it now with 1.000v and 1.070v. The real life voltage was in both settings 0,783v in FireStrike with 100% GPU Load. Imho the typical weird AMD OC/UV behavior, sadly it is kinda restricted. But the results are still very nice.",
      "Intel is on-par to cheaper than AMD now. (K vs. X parts, X3D parts are another price level above)\n\nGolden Cove/Raptor Cove cores (P cores) are, when properly tuned, better clock for clock and watt for watt than Zen4 - except for cases where AVX512 comes into play.\n\nHowever the E cores, despite being labelled 'efficient' are really only efficient on die area, they're far less power efficient than the P cores. \n\nZen3 was already more area efficient than Golden Cove, Zen4 just makes that worse for Intel - so to keep performance parity without making massive dies that cost too much to sell, they're pumping more E cores which hurt overall power efficiency.",
      "Yeah, RDNA3 sort of missed the mark on improving efficiency over RDNA2, even with the move to N5 (though chiplets aren't helping either). 1900-2000MHz is also where my 6950XT consumes less power, but still offers good performance. 2400-2600MHz is where it will eat power like crazy and use the entire +20% power budget even with undervolting.\n\nThere are cases, though, where the lower clocks may cause slight microstuttering (2160p) in RDNA2 (not sure if RDNA3 has this) that completely goes away once clocks are raised again. There may be architectural design reasons for that where timing targets (in clock cycles) were relaxed for certain pipelines or pipeline stages were added to improve high clock tolerance (common design decisions). Performance critical pipelines likely retain tight timing, short wire lengths, and no increase in pipeline stages to keep ALU throughputs and performance per watt competitive. However, architecture is always limited by the weakest link in the chain.\n\nEDIT: One interesting thing I've noticed in both AMD and Nvidia architectures is that large opaque textures/objects (like a body of water with high pixel coverage or a running river with moving translucent pixels) cause increased power consumption even if overall scene/geometry/object load hasn't increased. Alpha blending has been a power virus since the beginning of 3D acceleration and I wonder if anything can be done to fix that in future architectures. I mean, deferred rendering breaks this entirely, but I wonder if there's a way to make (forward rendered) alpha heavy pixels more efficient, maybe through hardware in an adjacent pixel interpolation pass? Basically trying to cut the amount of alpha blended pixels rendered through inferencing/interpolation.",
      "Yeah. These cards try to hit high boost clocks at all costs. Limiting how far they can clock pays dividends while only costing a couple of frames. I had my 7900 XT undervolted and limited to 2400MHz and those power savings were rather absurd in a lot of cases. I‚Äôd slash around 60-100 watts of power (and I‚Äôd get a much cooler running card) while still getting the performance I want.",
      ">Everybody is going to hate this analogy, but AMD factory tunes their GPUs to be muscle cars,\n\nApparently though, it's not OK when Intel does the same thing.",
      "Because on heavy tessellation workloads the 400 series ran circles around anything AMD offered back then and for the next gen too.\n\n\nAt the end of the day people only cares about performance and totally ignore efficiency, who could imagine that? *Looks out of the windows to thousands of cars with a single driver moving slowly than walking people*",
      "My Pulse 7800XT crashes (black screens) infrequently but often enough to be annoying when I play games like Hell Let Loose or run compute tasks like Einstein@Home. I have a 660W Platinum PSU from Fractal and a 5950X. 23.11.1 driver. Any ideas?",
      "Yeah same here, however power is cheap where I live, so we send it. After that brutal cold snap last month with heater going, 2 gaming PCs, 2 tvs and electric stove my power bill was only 120 bucks.",
      ">I think that says something about AMD‚Äôs out of the box settings\n\nNot necessarily - it could also be saying that OP‚Äôs 7800XT has much better performance than the minimum bin AMD chose for that SKU. Without a large scale investigation, it‚Äôd be very difficult to figure out. In general I do think AMD cards are usually released with power levels that are too high, but 27% may not be what you‚Äôd typically gain.",
      "memory lip quaint obtainable depend wise numerous vanish air childlike\n\n *This post was mass deleted and anonymized with [Redact](https://redact.dev/home)*",
      "You will probably go WAY lower than 1900MHz@1.070V.\n\nMy 6800XT is on 2255MHz core clock at 1.007V or 2170MHz@0.963V stable. You will probably be fine at 0.9V or around that.\n\nRemember, what **really** saves energy is voltage, not frequency. P = U^2 / R, as per school physics program. It's a quadratic relation. So, by increasing voltage by 10%, you increase power consumption by 21%. By lowering it by 20%, you lower core power consumption by 36%.\n\nThus, you need to measure it in a different way. You lower BOTH frequency and voltage, define if it's stable, THEN you measure efficiency. This is really a correct way to conduct this  test.",
      "Unlike in this case, however, you usually have to be very clever.",
      "I see what you mean, I have issues with the analogy still but it makes more sense this way. \n\nFWIW I've found many Nvidia GPU's to be the same, stock tuning is right at the tip of performance using more power than it needs, seems like any contemporary GPU from either camp benefits from tuning, but perhaps AMD more so.",
      "If undervolting help with preventing crashes, like you don‚Äôt have any crashes at all, then you identified the problem - your power supply",
      "u/BigBashBoon Which overlay do you use to display metrics of your FPS, power usage, etc?"
    ]
  },
  {
    "brand": "amd",
    "generation": "7000",
    "tier": "high",
    "matched_keywords": [
      "7800"
    ],
    "title": "Premilinary RX 7800 XT and RX 7700 XT performance and specifications leak alongside possibly-doomed RX 7800 XTX",
    "selftext": "",
    "comments": [
      "The leak cycle:\n\nMLID->Videcardz-> Wcctech->Tom's hardware-> Redgamingtech->notebookcheck.net->Twitter->MLID\n\nand so on and so forth",
      "This whole gen has just been so blah. The only amazing card is the 4090 and you have to sell a kidney to afford it.",
      "Too much.",
      "The real question is, what is the price going to be of these cards.",
      "As someone with zero industry connections, I feel like I could pull out of my ass that the 7800 xt competes with RTX 4070 and the 7700xt competes with 4060 ti and be 100% correct.",
      "It's really the only card worth getting if you already have a 30 series or 6000 card. The high end of last generation is still excellent",
      "Using the 7800XT as an example, if it has 6950XT performance I would expect it to be about $20 more than the 3-4th cheapest 6950XT.  If it came put right now, Newegg had a $579 6950XT, but $600 is where the next cheapest ones land, so a 7800XT would be $629. If it is a little slower than a 6950XT expect the same price.\n\nPut another way, there will be a lot of posts on reddit asking \"should I get a 7800XT or a 6950XT\" with no clear right answer until 6950XT inventory runs out.",
      "It's not MLID, though. It's RedGamingTech, who has an even worse track record, but is just way less egotistical about it.\n\nAlso, these RAM specs make no sense. It's 21gbps? N31 is only 20gbps. Lonely trolls desperate for attention just making shit up to send him. I remember he had specs like a year ago of the 7900xt and the whole lineup, which all ended up being wrong.",
      "Woah, Nostradamus over here.",
      "If true seems like a pretty disappointing gen all around both AMD and Nvidia. The 7900 cards might be the only real outlier. If you can get a 4080 for $1k or so not bad if you really like RTX but I think the 16gb VRAM will hamstring it a few years from now. 4090 is obviously awesome but yeah it's just too much $$$",
      "Considering they have to compete with a $600 6950xt they should be pretty well no?",
      "one with more vram",
      "3080 12GB and above will last for a while still IMO. The 10GB 3080 and below have a much shorter shelf life for AAA gaming on high settings.",
      "MLID also claims that 7600 XT is only 11% faster than 6650 XT at 175W",
      "Imaginary Sources->MLID->Videcardz-> Wcctech->Tom's hardware-> Redgamingtech->notebookcheck.net->Twitter->MLID.\n\nFTFY.",
      "I really wish MLID and Redgamingtech would be barred from Reddit as 'sources', the way UserBenchmark is.",
      "Yeah it's an easy pass on every card from both of them at this point unless MSRP dumps for all of them. Which to be fair, the 7900 XT/x has been falling and the market seems to be forcing the 40 series to dip as well as much as Im sure it riles Black Jacket's feathers lol\n\nIt's looking very likely I hold onto my 2080 for like, 7 years at this point, which is kind of crazy to think about because even when I bought it at the time I kind of grumbled about it not being enough of an upgrade but it was the option I had at a time I needed to upgrade. Now it's looking like the thing will be by far the longest I've ever held onto a GPU ü§∑‚Äç‚ôÇÔ∏è\n\nHindsight can be funny sometimes lol ...",
      "8800 XT is looking more and more promising",
      "Why wait? Go nvidia 8800 GTX or Ultra. It supports CUDA!",
      "The 7900 XT is not that much faster than the 6950 XT, so I tend to doubt the 7800 XT will match the 6950 XT."
    ]
  },
  {
    "brand": "amd",
    "generation": "7000",
    "tier": "high",
    "matched_keywords": [
      "7800"
    ],
    "title": "Regulatory filing hints Radeon RX 7600 XT, RX 7700 and RX 7800 cards might be coming - VideoCardz.com",
    "selftext": "",
    "comments": [
      "For what? To fill 5 fps gaps? I don't get it, their current lineup doesn't habe big enough gaps for shit like this IMHO",
      "There really isn't much space to squeeze another SKU between a 7700XT and a 7800XT IMO.  54 to 60 CUs and 12 to 16GB VRAM.  What would a 7800 non-XT look like?  60CUs but only 3 MCDs/12GB?",
      "imho that's an EEC typo",
      "The lineup has one gap: between 7600 and 7700XT. $269 to $449 is much too large of a gap. There is also 7900XT to 7800XT, $499 to $899, but there is at least 7900 GRE in that gap even if it isn‚Äôt widely available. I‚Äôm sure AMD WANTS to put something in that lower gap, but I‚Äôm not sure what that card is. A third tier Navi 32 is of course an option, but the confusing pricing of the 7700XT (and quite frankly, the stupid naming of the entire lineup) makes me think that they don‚Äôt want to price any of their chiplet designs any lower for whatever reason - more likely capacity than cost, but it could be either.\n\nFaster Navi 33 seems unlikely as the boost clock is already the highest in the lineup. Of course they could upgrade the VRAM clock to 20GHz effective, but that‚Äôs about it, and I don‚Äôt think Navi 33 is bottlenecking that hard on memory bandwidth anyway.",
      "How I've always seen it:\n\nWhat it's called --> What it actually is\n\n7900XTX --> 7900XT\n\n7900XT --> 7800XT\n\n7800XT --> 7700XT\n\n7700XT --> 7600 XT\n\n7600 --> 7500 XT\n\n\nAnd it's ridiculous that the inflation adjusted price of a 8GB card is the same in 2023 as it was in 2016. Price range for the listed models should be something like $150-$750.",
      "lower clocks, less W",
      "I respectfully disagree. There is a gaping hole in both performance and price between the 7600 and 7700XT.",
      "I couldn't care less about these. My sticking to the 5700 XT is solely about the absurd pricing of the existing lineup. Releasing more overpriced cards won't make me upgrade or recommend an upgrade to anyone else. Just bring down prices to sensible levels. The $7900 XTX barely hitting a 10% discount after a year is crap. Holding the 7800 XT back a year (3 years after the 6800 XT that performs the same) doesn't make the $500 price tag look good.",
      "And what MSRP difference?  It would cost virtually the same to make and there's only a $50 gap to squeeze it into and that's less than the existing difference between AIB 7800XTs.  IDK maybe AMD plan to cut the 7700XT MSPR?",
      "> \"Super\" is never\n\nThe 2070 Super was the same price as the 2070. Same with the 2080 Super.",
      "IMO 40% is not enough of a jump to upgrade at similar pricing, let alone higher pricing. You would think that 2 gens later, you should be getting at least 2x performance for the same price. Sadly this reflects the trend of diminishing performance gains every gen thanks to inflation and physics. I don't expect to have to upgrade my 6700xt for atleast another 5 years given how slow GPU hardware is improving.\n\nVRAM can be a reason to upgrade if certain games can't run or can only display a blurry mess which is the case with a number of new games on 8gb cards.",
      "If enough people are smart like the poster you replied to the prices will fall before that. I‚Äôll also sit on my 3060TI for another few years if I can‚Äôt get a true midrange card again for less than ‚Ç¨400.",
      "For real, price difference between 7700XT and 7800XT is already so low that it makes no sense to even consider 7700XT and just go for 7800XT. If they significantly drop the price on 7700XT then it would make sense but then the 7800 non XT would become pointless to consider.",
      "The 4070 Super will probably be more expensive than the 7900 XT.\n\nI don't know why people are in denial about Nvidia's pricing. \"Super\" is never a price cut or even price stabilisation; it's something like 8% more performance for 15% more money...",
      "1650, 1660, 2060 Super were more for more.\n\n2070, 2080 Super were more for the same.\n\nAlthough the 2080 Super was only like 5% more perf.",
      "7850XT would make more sense to compete with 4070 Super.",
      "....\"Rumors state a company that releases updated lineups is going to be creating an updated lineup.\"\n\nIs this really all they have to write about.",
      "It‚Äôs completed in the sense that they have released an SKU for each die. Doesn‚Äôt mean they won‚Äôt release a different variation for each die.",
      "They could always buy an used card for a more reasonable price a few years down the line if it comes to a point where the RX 5700 XT is too outdated.",
      "No, there's two possible reasons for the 7800.\n\n1. Vram prices crashed hard just before the launch of the 7700xt. You can get 8gb of gddr6 for $25 pretty much and this happened around June 2023. With the lead time to a product launch, the August release of the 7700xt was likely planned prior to these prices collapsing.\n\n2. Yields of the dies are good enough AMD wants to up the CUs. It could also be AMD found 60 CUs at lower clocks is perfectly stable, so there's no need to cut down to 54 when they could sell 60 just at a lower clock speed.\n\nSo, there are at least two reasons I see for this that make sense."
    ]
  },
  {
    "brand": "amd",
    "generation": "7000",
    "tier": "high",
    "matched_keywords": [
      "7900 gre"
    ],
    "title": "AMD Radeon RX 7900 GRE to launch globally on February 27th at $549 - VideoCardz.com",
    "selftext": "",
    "comments": [
      "12% more expensive than the 7800 XT for 5-7% better performance and \\~10-15% better efficiency.\n\nI mean, it's not terrible but it's not exactly exciting either.\n\nEdit: In the just released TPU review, the GRE is 10-12% faster than the 7800 XT. Now that is a noticeable difference. I wonder if they optimized drivers or why the GRE seems to be about 5% faster than last year in the HUB and computerbase reviews.",
      "Slower DDR6 RAM, hmmmmm, I need benchmarks.",
      "5% better performance is probably not even noticable - its diifference between 60 and 63fps. Definitely not something one woukd expect from upgrade 7800 -> 7900",
      "So... A 7800 XTX",
      "kinda as fast as a RX 6950 XT, but 25% less energy (250 watts)",
      "A more accurate comparison is calling it a 7800 XT with 5% better performance and very slightly lower power draw.",
      "True but for those looking for a card like that the efficiency might do it.\n\nPeople are replacing lightbulbs with ledbulbs. If the difference is a lightbulb it's already worth ‚Ç¨50 over here in Belgium. Let's say it saves you 0.03kW/h x50h of gaming a month >>15kW/h a year x 4 years is around 60kW/h x‚Ç¨ .35= ‚Ç¨21 \n\nI would definitely buy it over a 7800xt, that's just another 6800xt basically.",
      "It‚Äôs pretty unimpressive for an 80CU part. Though that seems to be consistently the case for Navi 31/32 apart from the SKUs with fully populated MCDs.",
      "> DDR6\n\nGDDR6",
      "10% better than a 7800xt at best for 10% more. It's.. Eh",
      "I wouldn't unless you wish you got a 7900 XT or XTX instead. The 7900 GRE is nothing to write home about",
      "I‚Äôm starting to regret just getting a 7800xt‚Ä¶ I meant it‚Äôs nitro+ so basically the same price as 7900GRE anyway.",
      "4070 Super for only $40 more\n\nGRE is underwhelming",
      "I thought so too at first, but honestly having a better look at it i don‚Äôt anymore, but granted i might just be coping.\n\nThe 7900GRE appears to be barely offering 10% more performance for also about 10% more in terms of the price for what appears to be an inferior quality build compared to my Nitro+ 7800 XT, which i know has (imo) awesome cooling capabilities as well as it handles undervolting and overclocking like a champ so ultimately that difference in raw performance may very well be much smaller than 10%, and while i have no idea regarding the OC capabilities of the GRE overall I remain content with my purchase for the time being.",
      "it's similar to a 7800xt",
      "So finally the true 7800 XT is going on sale worldwide.\n\nAMD really messed up with their naming scheme this generation by creating the unecessary XTX SKU...",
      "One thing to watch out for with this one is overclocking potential.  They stated the power limit will be limited to 260W.  If that's the case and there's no easy way to get around it even on custom AIB cards that's gonna limit it severely because of how overclocking works on RDNA 3.  \n\nIf not for bullshit artificial limits, these would probably be really good overclockers given the low stock clocks.  OC vs OC you'd probably be looking at more like a 15-20% performance advantage for the 7900 GRE vs the 7800 XT if you can OC the memory on the 7900 GRE a fair bit, and it would significantly close the gap to the stock 7900 XT which is what makes me think AMD will be assholes and artificially limit OC via firmware on these.\n\nFully expect that availability on these will be low as well, just as it was for the RX 6800.  The reason is that this is a die that's already been cut down to make the 7900 XT, in similar fashion to how Navi 21 was cut down to make the 6800 XT and even more cut down to make the RX 6800.",
      "the naming scheme this gen has been abysmal, they had it almost right with the 6000 series but i guess if you can't compete confuse the end users.",
      "germany.jpeg \n\nWhen you pay 300% tax on electricity to fund green energy. Aka shutting down nuclear to power up coal and natural gas, and even more coal after russia cuts off the gas. All while taking down the rest of EU with their bullshit.",
      "Same, I'm tempted to replace my 6800 in my SFFPC with this GRE offering depending on power usage results in reviews."
    ]
  },
  {
    "brand": "amd",
    "generation": "7000",
    "tier": "high",
    "matched_keywords": [
      "7800",
      "rx7800"
    ],
    "title": "ASUS TUF Gaming RX 7800 XT and RX 7700 XT Launch - Official Q&A",
    "selftext": "Hi everyone! I'm Jake, a new community manager for the ASUS NA team. Going forward, I'll be around to bring you all some news, answer questions, and (hopefully) be of some help to you all :)\n\n&#x200B;\n\nTo kick things off, I'd like to open discussion about our recent launch of the TUF Gaming RX 7800 XT and RX 7700 XT cards.\n\n&#x200B;\n\n[TUF Gaming RX7800 XT Black](https://preview.redd.it/v5lmto2c6tkb1.png?width=2092&format=png&auto=webp&s=f2a7cb82af226b302135a7f4798a607467a962eb)\n\nhttps://preview.redd.it/utfbow6g6tkb1.png?width=2400&format=png&auto=webp&s=97644a287bcca9257c9f701cde35245165441f86\n\nhttps://preview.redd.it/neggxkql6tkb1.png?width=2400&format=png&auto=webp&s=db2e2d1d5e4625e3bba758da8d07e5ace3e65f7a\n\n[TUF Gaming RX 7800 XT White](https://preview.redd.it/pc55uel45tkb1.png?width=2400&format=png&auto=webp&s=caf0a6a1547dd946dd2ec8e0814fd17c2ab4e813)\n\nhttps://preview.redd.it/1g6xiel45tkb1.png?width=2400&format=png&auto=webp&s=e3895a95ce32454368246ebcded1ef410d45a487\n\nhttps://preview.redd.it/y8o4qfl45tkb1.png?width=2400&format=png&auto=webp&s=2f5d0fc9e88d4f6d1ae8b1d0d11aeac4bafc728c\n\n[Accessories pack included with cards; phone holder, screwdriver\\/gpu support brace, collector's card](https://preview.redd.it/2bz0mhl45tkb1.png?width=2400&format=png&auto=webp&s=3981a1be6869334d5aeb2a8a72820c050b13ef4c)\n\n&#x200B;\n\n&#x200B;\n\n&#x200B;\n\n&#x200B;\n\n&#x200B;\n\n[TUF Gaming X670E-PLUS for design comparison](https://preview.redd.it/k2ngbxvn5tkb1.png?width=2400&format=png&auto=webp&s=949e3c548f3137fb85a968e2efe276b51f0fc6a8)\n\n[TUF Gaming B650-PLUS for design comparison](https://preview.redd.it/d1jygqho5tkb1.png?width=2400&format=png&auto=webp&s=24fe9afa957a2f50c7756c3ff6b133669bc70fc7)\n\n&#x200B;\n\nThe main things to note are the continued use of the same cooling design from the TUF Gaming RX 7900 XT that features the triple Axial-tech fans, full aluminum shroud and backplate, and the subtle bit of RGB lighting. New to this launch is the white version.\n\nSize:319.8 x 150.9 x 59.2 mm12.6 x 5.94 x 2.33 inch\n\nAvailable now\n\nTUF Gaming RX 7800 XT Black - $529.99\n\nTUF Gaming RX 7800 XT White - $539.99\n\nTUF Gaming RX 7700 XT Black - $469.99\n\nMore info on the TUF Gaming RX 7000 Series: [https://edgeup.asus.com/2023/tuf-gaming-radeon-rx-7800-xt-and-tuf-gaming-rx-radeon-7700-xt-intro/](https://edgeup.asus.com/2023/tuf-gaming-radeon-rx-7800-xt-and-tuf-gaming-rx-radeon-7700-xt-intro/)\n\nMore info on the RX 7800 XT Black: [https://www.asus.com/us/motherboards-components/graphics-cards/tuf-gaming/tuf-rx7800xt-o16g-gaming/](https://www.asus.com/us/motherboards-components/graphics-cards/tuf-gaming/tuf-rx7800xt-o16g-gaming/)\n\nMore info on the RX 7800 XT White: [https://www.asus.com/us/motherboards-components/graphics-cards/tuf-gaming/tuf-rx7800xt-o16g-white-gaming/](https://www.asus.com/us/motherboards-components/graphics-cards/tuf-gaming/tuf-rx7800xt-o16g-white-gaming/)\n\n&#x200B;\n\nNow for the questions! :)\n\n1. How do you feel about the current TUF Gaming design language?\n2. Is the focus on the TUF models preferred or regrettable to you?\n3. Do you prefer the black or white variant or would you prefer a different color?\n4. Are you excited for Starfield? :D\n\n&#x200B;\n\nPlease also feel free to ask anything or provide additional feedback!",
    "comments": [
      "MSRP + $100 incoming...",
      "Just please keep them as close to MSRP as possible. Especially the white because we all know there is usually a ridiculous added charge on white gpus",
      "Jake,\n\nA 850W PSU is recommended for the 7800XT...is that a mistake?\n\nWhen will the clock speeds be announced?\n\nThanks.",
      "1. The cards look great,  but tbh they need to stay as close to MSRP as possible,  or else they're DOA.   \n2. The white model looks the best in my opinion, but I don't like the yellowish logos.   \n3. A giveaway would be a good way to connect with consumers and give back to the community.  Just saying ;)",
      "Considering that the Suggested PSU for 7900 XT is 700W (750W in the ASUS PSU Table), that should be a huge overestimation.",
      "If they cost 10% more than MSRP then they're not worth it",
      "This, unfortunately. White is a real pain and challenge to get the color matching perfectly. Black blends better but white shows everything and even a slightly different hue can be apparent.",
      "That seems like an oversight to me OR that the article was written prior to actually receiving confirmed numbers, which is likely. I‚Äôll pass this along. Like u/poppoo143 mentioned, the higher tier card already states a lower wattage psu.",
      "Personally I feel like the TUF Gaming line as a whole is missing on an opportunity to distance itself from \"gaming\" and be a sleeker more minimalist brand (as it is your cheaper option). I think at this point the whole \"gaming\" marketing in the computer component world is very oversaturated and as of today you could go as far as calling it \"gimicky.\" I'm a gamer, I don't need my components to say it on them. I'm aware I can game on my GPU and Mobo, that is what I bought it for after all. You already have the ROG brand, the TUF Gaming brand is starting to = cheaper asus brand, more than just gaming computer components which I think was the original intention when TUF Gaming launched.\n\nSimply put, if I were the VP of marketing I'd drop \"Gaming\" from \"TUF\" and try to capitalize on the anti-rgb movement and have it be a minimalist, sleek line and pivot from the \"cheap, downgraded ROG\" line that it has become synonymous with. Kind of like pro-art, but again not targeting any specific group. Let's be real, it's not like the consumer hardware itself would physically change if gaming was the focus or not. No board partner made \"mining\" focused hardware brands for example. Your Pro-art GPU dies aren't any different from your TUF or ROG brands.\n\nI would never buy Asus TUF Gaming branded products new unless they were steeply discounted, which is almost never the case, because I assume they're just intentionally built worse than they could be and usually they're not priced as such. And conversely I'd never buy your Strix brand new because I assume that the relative performance increase doesn't align with the price increase. Maybe what I'm asking for is to merge TUF and Pro-art into an economy brand, that is a general economy brand, priced at the bottom of the stack that doesn't feel \"gimicky and intentionally cheaper.\" Like a brand I'd buy for myself and not my 8 year old nephew because he can't have nice things yet. A big part of the problem is the Strix line is infamously overpriced at this point so it makes the TUF Gaming line seem way worse than it is.\n\nYour competitors do a much better job of differentiating and blending their brand tiers in my opinion. Take MSI for example, they have the ventus, Gaming trio & Suprim cards. When I think of the two Asus brands I think of intentionally worse thus overpriced gaming, and very overpriced, high quality gaming. MSI? Ventus is cheap and crappy, gaming trio is more expensive but performs to that bump while establishing a middle ground and then suprim is splurge. Not to say Strix doesn't compete with Suprim, but there's no middle ground for Asus and the juxtaposition between TUF and ROG is too big and obvious. MSI boards? I couldn't even tell you how that branding works, but all I know is they're not clearly pitted against each other as cheap vs overpriced. And Asus mobos still aren't out of the woods from voltage-gate from a public perception standpoint. ASRock? Same story as MSI, unique branding, no \"gaming\" overkill and sensible tiering.",
      "We should have pricing soon and I‚Äôll update when we do. Part of why we‚Äôve targeted the TUF series was to help keep prices a bit more reasonable compared to some other options.",
      "Recommended means nothing dude. I have a 850w psu for my 7900xtx. You're 750w psu is more than enough.",
      "It‚Äôs actually not ridiculous for white to be a more expensive color. It is harder to get good yields on white injection molded parts and painted parts. Which means either parts are rejected and then scrapped or reworked. In either case that leads to more money be necessary to make a unit. The auto industry does similar. The white colors tend to be an up charge color.",
      "Haha giveaways aren‚Äôt off the table though my personal preference is to first have some open and honest dialogue. Giveaways can muddy the waters on feedback and honest discussion.\n\nThanks for the feedback on the cards!",
      "I would like to know whether the coolers are repurposed nvidia ones or not. Some ASUS radeon cards have coolers designed for nvidia models, probably to save cost of development idk.",
      "Bro 3080 10GB is arguably the worst to get right now, the 7800xt will probably match its performance or slightly supersede with 6GB more vram for proper 2k or 4k textures in the near future. \n\nThese recommendations are really meant for typical buyers who usually have shitty Psu ... for example a noname 850w psu (such as that infamous series from Gigabyte) cannot match a solid 650w from FSP. Hence, they have to inflate these recommendation numbers in case some dumb ass uses these no name psus\n\nJust have a solid 650-700w and you should be fine with these mid range gpu",
      "Car paint =/= plastic parts for GPU.\n\nAlso white color isn't always the cheapest for cars, sometimes you need to pay extra for white.",
      "I like the rgb, it's not over the top. Looking at an 7800xt for a friend just waiting on availability and price in NZ, really happy with my tuf xtx",
      "I could probably find some info and other bits to sell you on a snazzy new gen card, BUT I think you‚Äôve actually answered this yourself. The RX 6800 is cheaper and does the job you need, it sounds like? If so, that‚Äôs likely the best option for you. I‚Äôll usually advocate a little bit for new versus used because of warranties, but when it comes to the generation and tier level, I‚Äôll always suggest to choose what fits your needs and wants. \n\nIf you need to play X game at Y resolution, then base the purchase on that. \n\nIf you want a shiny new toy, then buy what you‚Äôll have fun with within your budget. No need to justify your own expenses for fun.",
      "Your 750 should be perfectly fine I run a 7900 xt with a 750",
      "I liked the older TUF Sabertooth(X99/Z87/990FX etc.) aesthetic more than the more recent yellow TUF design. Seems like a massive downgrade.   \nROG/Strix lines seem super upcharged while being hit-or-miss quality wise."
    ]
  },
  {
    "brand": "amd",
    "generation": "7000",
    "tier": "high",
    "matched_keywords": [
      "7800"
    ],
    "title": "I get the controversy behind the mislabeling of the 7900/7800 series but why is the 7700 XT getting the same hate?",
    "selftext": "I'm seeing numerous posts on here saying that the 7700 XT is really just a 7700 or even a 7600 XT class card. Heck, even the 7600 is not spared although I think it performs fine as a 6600 successor. Are people just parroting what others online are saying?\n\nLet me break it down for you:\n\n* Architecture: They are both Nx2 classes (N32 vs N22)\n* Memory Capacity: Both 12GB\n* Memory Bus Width: 192 bit\n\nBut that's where the similarities end. It is much closer to a 6800 non-XT than it is to the 6700 XT\n\n||RX 7700 XT|RX 6700 XT|\n|:-|:-|:-|\n|Core Count|54 CU|40 CU|\n|Boost Clock Speed|2544 MHz|2424 MHz|\n|TDP|245W|230W|\n|MSRP|$449|$479|\n\nIMO, it a worthy successor to the 6700 XT and at a $30 discount, bringing much more features and significant performance uplift.\n\nIf anything that the 7700 XT should be guilty of is that it is priced too high or too close to the 7800 XT.\n\n**EDIT:** Again I want to clarify, not spotlighting the price (that is a separate debate), it's that people won't stop labeling it as a 7700/7600 XT. Even if they do label it as a 7700, people will complain the price is too high, but the performance would be greatly above its predecessor (6700).",
    "comments": [
      "Yeah it seems good but people are pissed it's priced so close to the 7800 XT. I think a $70-80 difference would set them apart better (either increasing one or decreasing the other).",
      "GN nailed it - at $50 gap it's not worthwhile, at $100 it's extremely compelling.",
      "You can't really compare release MSRPs because the 6700XT is now selling for $330.   \nPeople are disappointed that the 7700Xt is priced at $450 because the 7800XT is \\~20% better and 11% more expensive, essentially funneling everyone toward a higher price bracket.   \n\n\nThe 7700XT doesn't really fill a meaningful position in AMD's GPU lineup right now, at the $450 price point.",
      "Because if they released it at $400 they'd have the $330 6700xt and $350 3750xt collecting dust. Inevitably the 6000 GPUs will sell out and the 7700xt price will drop to $400 or less. Sucks but if they got stock to move they're going to price it around making it move. \n\nBasically where it sits now pushes people up to 7800XT or pushes them down to a 6750 or 6700. Once the bottom of this tier falls out (6000 series sold out and done), the price of the 7700Xt falls in response. Its pretty basic business and is done with almost every product you buy that has recurring releases.",
      "I live in Europe, and the price gap is actually roughly ‚Ç¨100 here. The 7700 XT retails for around ‚Ç¨520-550 and the 7800 XT is around ‚Ç¨620-650, depending on XFX/Sapphire/Asus etc. (including all taxes and stuff).",
      "Yeah, people easily forgot what happened just a generation ago. if 7800XT is really priced that good then keep saying that 7700 should drop in price, can't the opposite also happen in which the 7800xt might actually increase in price? \n\ni am in a region where GPU prices tend to stick to what is release price and dont decrese BUT will actually increase in price if its always sold",
      "So AMD should just raise 7800xt prices! \n/s",
      ">Are people just parroting what others online are saying?\n\nthey're all saying the same thing because it's true, why would you buy the 7700 XT when you could get the bigger 7800 XT for just $80 more?\n\n$80 is a small gap for the current GPU economy today, and it's certainly better than the $170 difference between the 6700 XT vs 6800 XT.\n\nthe 7800 XT is not only faster, it also has 16GB of VRAM, quite a few RT cores and should only draw like 50-60watts more.\n\nthe 7700 XT is not a bad card, I've not seen anyone say that anywhere. it's position in the market is just weird.\nhere's hoping for a price cut for the 7700 XT.",
      "Then why would you ever buy a 7800xt or 7700xt when 6800xt is 500 brand new.",
      "Mindfactory sold many 7800 xt units for 559‚Ç¨, sadly other countries tend to get screwed with pricing.",
      "What a level-headed take",
      "If 7800xt rises more in price, then there is less actual incentive to chooce 7800xt over 4070 so i doubt it will go that way if amd is smart.",
      "It's even more pointless to compare it to heavily discounted 6800xt cards, that will disappear from the market in a few weeks. \nThe 7600 was compared to the 6700 10GB discounted to sub $300, which never had many cards on sale to begin with.",
      "So AMD should raise 6800xt prices too!!",
      "You can't really compare \"is now selling for\" prices either.\n\nA 6700 XT here (Philippines) is still $460. However, a 6750 XT is $440 - because the retailers got newer stock for it at a lower price. It used to be $540. It's also why a 6950 XT is cheaper than a 6800 XT.",
      "I'm so fuckin confused why every outlet insists on basing their review on MSRP and not *performance*. In 6 months none of their conclusions will make sense because the prices have shifted. \n\nI mean go watch everyone's reviews of 6700 XT or 6800 XT etc from last year. They all shit on it for being too expensive, and some even *re-reviewed* it after prices normalized. \n\nPeople use your recommendations well after launch. Like years later even. Including MSRP as a consideration is absolutely pointless beyond mentioning its current price. Because when you watch it a year later for a recommendation, suddenly the videos telling you to not buy a perfectly good card because they think it's not a good deal.",
      "Not everyone makes purchasing decisions from the mindset of \"what is the absolute maximum amount of money I can possibly spend?\"\n\nI could afford a 4090, but there's no chance Nvidia is getting $1,600 out of me. I could afford a 7950X3D, but it would be a waste. If the price:performance is close, yeah, I'll eat a bit of value for more performance (say, 30% more performance for 40% more money). However, with stuff like the 7700 XT and 7800 XT, it's easy to fit another $50 in the budget.\n\nHeck, there are times I'm debating between going all-out for a top-tier product to keep for a long time or getting something with much better value and upgrading more frequently.\n\nThat said, neither of these cards really does it for me. If the 7800 XT were $50 cheaper, I'd maybe get it. The 7700 XT needs to be more like $80-100 cheaper, IMO. If the 7800 XT comes down a bit for Black Friday, I might pick it up, but the 7700 XT has to be stupidly good value to convince me it's enough of an upgrade from my 5700 XT AND that I shouldn't just buy a 7800 XT for a little more.",
      "All that matters is current relative prices. Why would you buy a 6700xt when 6750xt is cheaper or 6800xt when 6950xt is cheaper. \n\nJust like why would we buy a 7800xt when 6800xt is cheaper. \n\nMsrp doesnt matter what matters is new avaliablity prices.  \n\nJust look back at 30 series and 6000 series releases. Msrp didnt mean a thing.",
      "[You can get a brand new rx 6800 for less and it has 16gb of vram.](https://www.amazon.com/XFX-Speedster-SWFT319-Graphics-RX-68XLAQFD9/dp/B09KW68M2G/ref=sr_1_2?keywords=rx+6800&qid=1694135468&sr=8-2) Or you can go the used market and save even mroe. These cards are way overpriced for what performance they offer.",
      "Higher? The 7800xt is at the highest price to make sense at all, any higher price and the 6800xt gets a far better alternative...\nIt should be named the 7800 and the 7700xt should be a bit less. I'm sure prices will go down a bit soon, but for now Amd again somewhat fuck up the lunch with the naming and will get hate again."
    ]
  },
  {
    "brand": "amd",
    "generation": "7000",
    "tier": "high",
    "matched_keywords": [
      "7800xt"
    ],
    "title": "RTX 5060 TI 16GB or RX 7800xt 16GB for similar price",
    "selftext": "Its been already asked since launch of 5060 ti but every case is a little different.\n\nI want (in fact I need to) change my GPU\n\nNow i have old excellent  GTX 1080TI. Its holding up fine but recent games seems to struggle to much.\n\nAnd i have kind fixed budget. And I need to buy something.\n\nBest i can afford is RTX 5060 TI 16GB  or RX 7800xt (previously i have considered Intel B580 so its already a huge price increase.) So RX 9070 or RTX 4070 or 5070 is not an option)\n\nIt has to be one of those two.\n\nIn theory 7800xt destroys 5060 TI. In every gameplay i saw like 10 to 30 fps more with RX 7800xt\n\nSo its seems that choice is simple. But, (there is always but) its not that simple.\n\nA small background.\n\nI play at 1080p 60hz LCD screen or 4K 60hz TV screen (only older games - 1080ti is too weak for 4K)\n\nI have rather weak CPU i7 11600H with DDR4 3200 memory.\n\nI would not change that in near future.\n\nAnd here comes upscaling and frame generation\n\nNvidia DLSS an FG is far more superior and common than FSR3.1.\n\nAnd i think for 4K gaming even RX 7800xt will struggle to to get 60FPS without upscaling.\n\nFor newer games (GTA 6 ???) even at 1080p i guess\n\nSo card with bad upscaling is not good choice for next few years....\n\nSo although im impressed with raw performance of RX 7800xt I still consider waiting for price of 5060 TI 16GB decrease, so it will be cheaper than RX 7800xt\n\nBut choice has to be made.\n\nWhich one would you buy?",
    "comments": [
      "the 5060 ti barely hits the 7700xt in raster if that, and I think you may be overestimating what DLSS can do.",
      "I have never heard anyone else having that issue",
      "7800xt, then if you can keep the 1080ti for lsfg.",
      "I own a 7700 XT and I never experienced that.",
      "I would personally buy the 5060 ti. The 7800 xt is stuck with FSR 3.1 (which is abysmal), is less efficient, and performs worse with RT on (unless it's a super light, and therefore pointless rt implementation). The 5060 ti should overclock quite easily to just about match a 4070 in raw performance (not that far off of the 7800xt).\n\nEdit: It may also be worth sticking with your 1080 ti for just a bit longer and saving enough to get a 9070, 9070 xt, or 5070 ti",
      "Tbh the 5060ti 16gb makes more sense to me, yes the 7800xt is a bit faster, but i think the current version of DLSS grants a bigger advantage. FSR 3 is pretty meh and falls really short compared to DLSS 4, only the 9000 series with FSR 4 comes close but obviously you'll be spending more for a 9070/xt.",
      "I just bought rtx 5060ti :) not the greatest model MSI ventus 2x oc plus but it will do the job.\nI found it at mrsp so it turned out to be 50$ cheeper than the cheapest Rx 7800 that I could find.\nI would get it on Wednesday. I will let you know how it works:)\nWas it good choice? Time will tell...",
      "I dont agree, dlss quality is like 30% performance increase, and basically all games where you will struggle with fps will have it.",
      "In truth, you‚Äôre asking if you should buy the midrange card (7800XT) or the budget option from the newest series (5060TI) which is purely up to you. Me though, I wouldn‚Äôt spend an equivalent amount on the budget option when you have a midrange card capable of some great raster performance available to you. Your cpu isn‚Äôt all that weak, and there‚Äôs nothing wrong with ddr4 memory, your cpu gets some pretty decent price to performance and in truth I don‚Äôt understand why you think you‚Äôll need any kind of frame gen. If you want frames and raw performance, the 7800XT is your choice, if you *want* to use frame gen and have slightly less frames without using that feature then you should get the 5060TI. My choice would be the 7800XT though. I use it right now with a 9600x and I‚Äôm pushing the last of us part one with the settings cranked as high as they‚Äôll go in 1080p well over 90-120 frames. Keep in mind ray tracing isn‚Äôt available in every game and that‚Äôs the reason (outside of greed) why nvidia costs so much.",
      "I DO have a7800xt and ive never seen anything that makes videos, even 4k video look any different than when i watch on another device",
      "It helps a lot and it's doing it with much better results than fsr3.1. if fsr 4 was available for rx 7800 than it will be much simpler choice. But we don't when  it will be (and if it will be because it's not clear)\nFor recent games it's seems like Rx will better choice, but for future releases? Not so sure",
      "As you can see it's hard choice :) \nAbout budget. It's not that I can't afford more expensive card. If I want to I can go and buy 5090 out of the shelf. It's that I think it's not worth it. I'm not heavy player. But I do like to play occasionally. To buy better card I will have to replace screen, cpu ,motherboard, memory and psu to make it sense. So it's pointless to buy better card ither than those two mentioned in my opinion.\nAbout DLLs and performance. My nephew has a rtx 4060 paired with Ryzen 5600.\nI was amazed what this setup can do with dlss on cyberpunk or last of us compared to what I was getting with my 1080ti\nThat the performance that I was looking for.\nAnd I almost bought 4060.\nBut then Intel b580 came out.\nI almost bought it :) . But It was little overpriced at the beginning. So I decided to wait. And then came Nvidia 50xx card release with 5060 announcement.\nI thought I will wait a little bit longer.\nAnd now when it's released I almost bought it :)\nBut I watched YouTube video with comparsion to rx 7800, where red team destroys green:)\nBut it was with very strong processor of course, without using DLLs or fsr , no RT.\nSo after all this digging in internet I still don't know ... Heart goes red, mind goes green...",
      "7800xt is a pretty good OC card too. I‚Äôm up to 2690 core and undervolted.",
      "7800XT or wait around for a 9070 at MSRP",
      "7800xt.\n\nA card that does the job without relying on dlss or far is always the smarter option - you're not putting up with artifacting, perceived input lag from FG, etc.\n\nNeither will be great for 4k and you'll be making comprises one way or the other.",
      "I have used both and really only started getting fed up with Nvidia with extreme prices and planned obsolescence because they use a smaller amount of memory. This is on purpose as its not a huge cost. So use what you want. Nobody will be able to afford upgrades soon. Get a card with the most ram.",
      "If you don't want to wait 7800xt.\nAt 4k FSR3.1 is not bad. Yes DLSS is more available but you can always optiscaler to try to inject FSR.\nNewer game that still lack any info can be as bad as optimized as it can be that 5060ti struggle alot even with DLSS and the excess performance of 7800XT might help especially in 4k.\nFor a rather old title, your best bet is using Lossless scaling in my opinion anyway.\nBut since AMD haven't yet release it's 9060xt, there is also option to wait for a bit to see how it's performance and hopefully at that point 5060ti/7800xt price also going down.\nSo more options as well.\n\nFor for now, my pick would be 7800xt.\nUnless you care about RT or efficiency (5060ti is a very efficient card) but probably wait is also a better choice.",
      "I have both. 5060ti in my main rig, and a 7800xt in our lounge gaming PC. I play at 1440p on the main PC, and the 7800xt at 4K in the lounge PC.\n\nThe 7800xt plays games like dragon age Veilguard and AC shadows at 60fps with some settings tweaks or frame gen. I generally steer clear of upscaling as I don‚Äôt like the artifacts it creates and FSR3 is pretty mid, however XeSS can be used by any card just like FSR3, and it looks a lot better imo especially at 4K.\n\nI think the 7800xt is a better option for 4K as it has more brute strength in terms of rasterisation. I‚Äôm happy with what I use it for. \n\nHowever, DLSS4 is very impressive, the best upscaling I‚Äôve seen so far. It‚Äôs not perfect though, there are still artifacts etc, just a lot less than DLSS3. \n\nI personally use the 5060ti for high fps at 1440p, as it has more dials to turn as DLSS is more viable to use. I really don‚Äôt like upscaling in general, but especially at lower resolutions and DLSS is better at lower resolutions. I also chose it as it‚Äôs my main PC and it runs a fair bit more efficiently, and my main PC gets used a lot more than the lounge PC. The 5060ti sits at anywhere between 150-190w whereas the 7800xt is more like 190-250w.\n\nPersonally since you don‚Äôt utilise high fps in either situation, the 7800xt is a better option for you as it‚Äôs more capable at 4K. If DLSS or power efficiency is a major point of contention for you then maybe consider the 5060ti.",
      "I just purchased the new rtx 5060 ti 16gb to replace my AMD graphics card and amd all together and wanted to go back to something that is familiar which intel and nividia. So should be here in may.",
      "so it came today. And it's not working in my setup (it is working on another setup in the shop).\nI don't know why but it's not detected, no image only fans spins.\nAnd now I don't know what to do. Return it (if I can) or spend another 500$ or more on mobo,CPU and possibly memory(if CPU will be Ryzen) and maybe psu"
    ]
  },
  {
    "brand": "amd",
    "generation": "7000",
    "tier": "high",
    "matched_keywords": [
      "7900 gre"
    ],
    "title": "\"New\" $550 RDNA 3 GPU, AMD Radeon RX 7900 GRE Review",
    "selftext": "",
    "comments": [
      "XTX, GRE, Ti SUPER...\n\nI want whatever Nvidia and Amd are smoking.\n\nJoking aside, it looks like a decent gpu for the price",
      "Basically **RX 7800XTX**",
      "7900 XTX -> 7900 XT  \n7900 XT -> 7800 XT  \n7900 GRE -> 7800  \n7800 XT -> 7700XT  \n7700 XT -> 7700  \n+ 7600 XT and 7600\n\nHey look, it's a whole product lineup like we had before with differing names.",
      "or 7850XT but definitively not 7900",
      "Actual 7800 XT. The one we got is a 7800 cosplaying with its brother‚Äôs name tag",
      "yea, Ti SUPER and XTX are weird as hell, but GRE is fine in my book. afaik GRE means \"golden rabbit edition\", and makes sense given it originally released as a china-only market card.",
      "Naming is irrelevant anymore. Just buy the best you can within your budget.",
      "Personally, I'm waiting until 2029 for the Golden Cock Edition",
      "Literally the bike stick meme. They created a problem from nothing",
      "The problem is if you try to but the same price as you paid for your 2019 card.... You get the same performance anyway.",
      "TLDR: Decent card for the money, about 6% faster than 7800XT and 3% slower than 4070 Super.   \nFrom all AMD cards tested (Sapphire Nitro+ , PowerColor Hellhound, Gigabyte , Asrock Steel Legend)  The  PowerColor Hellhound is the most impressive, running cooler and quieter.",
      "In 2019 you got an RX 5700 XT 8GB for $400.  \nToday you get an RX 6800 16GB for $400 with 70% better performance.\n\nIn 2019 you got an RTX 2080 8GB for $700-800.  \nToday you get an RTX 4070 Ti Super 16GB for $800 with 120% better performance.\n\nHow is your comment even remotely true? I get that hating is fun and always gets lots of upvotes, but you're just making things up, lol.",
      "it's based where you live. I don't see reason to buy 4070super, because here 7800XT 150$+ cost less, but avg is 180$+ difference",
      "You‚Äôre not missing anything",
      "Only thing this is good for is pushing the 7800xt price down to $450",
      "the argument is that by using the name ‚Äú7900xtx‚Äù and creating a whole new segment (last gen topped out at 6900xt/6950xt not xtx) that it screwed up the whole alignment of the stack with respect to the actual performance of the products. The 7900XTX was not a 4090 competitor, they said that from day 1, so *creating a whole new segment on the top of the existing 6000 series for it* probably was not justified... and once you're committed to the XTX branding, it drags the whole rest of the line around, otherwise you get weird gaps.  \n\n7800xt for example barely outperforms 6800XT, and you can view that as a result of the top of the stack being too high and everything having to slide upward to fit. That 7800xt could have been called a 7700xt and then it‚Äôd have a sensible generational gain.\n\nOn the other hand I think this downplays the fact that AMD probably didn‚Äôt want to charge 7700xt prices for it at launch etc.  If it doesn‚Äôt use significantly less/cheaper silicon than the 6800xt, AMD can‚Äôt really reduce prices all that much. And remember they still knocked $150 off the original msrp of the 6800xt already‚Ä¶ and 6800xt was not really inflated at all.  The 7800XT already launched at \"almost\" 6700XT pricing.  The naming isn't what matters, at the end of the day it's pricing that matters, and unless the lower names came with lower prices it wouldn't really change anything.\n\nPricing and naming has become this Rorschach blot though, everyone knows its ‚Äútoo high because of the pandemic/mining‚Äù but this allows people to impose whatever number *they think it should have been* and the reality is most SKUs aren‚Äôt gouged as much as people wanted them to be. 6700xt launched at $480 but probably never would have been less than $420 or $399 even without gouging‚Ä¶ but people imagine that it would have launched at the current (clearance) pricing or something.  It would absolutely never have launched at $330 or $299.\n\nAnd I think that's the unacknowledged problem with this theory... if you call cutdown N31 as \"7800XT\" then you have that product segment going from $649 MSRP with 6800XT to $900 MSRP with 7800XT and that's bad optics for AMD too.  Even if you assume it launched at the \"real price\" of $749, that's still a $100 price increase over RDNA2.  7700XT (full-die N32) at $499 would have been a $20 increase over \"already gouged\" 6700XT pricing.  Etc. \n\nAMD is not immune to the price increases taking place either, they just went with \"shrinkflation\" (smaller generational performance increases) instead of outright price increases.  Basically instead of increasing prices they slid everything down a tier and then cut prices a bit so people would \"feel like\" prices went down after mining, despite a lot of that actually being the shrinkflation...",
      "Got enough bad yields of Navi 31 in their inventory to be sold internationally. Still hate how memory bandwidth starved those cores are.\n\n$550 is a good deal if someone makes a modded BIOS and overclock those weak and cheap GDDR6 memories (if possible at all). Probably halfway to 7900XT performance at most.",
      "They are just doing a collab with the USB Implementer Forum",
      "Waiting for this sub to tell.me it should be under 500 dollars or else they won't buy it. With am nivida gpu in their flair.",
      "ATI used to have a model called Radeon X1950 XTX"
    ]
  },
  {
    "brand": "amd",
    "generation": "7000",
    "tier": "high",
    "matched_keywords": [
      "7800xt"
    ],
    "title": "Anyone go for the 7800xt nitro?",
    "selftext": "Pretty much set my eyes on it as soon as i saw the big light bar. Past reviews for the 6800 series and latest ones for the 7900xt were positive. Better thermals than other brands.\n\nStays below 50c while playing Starfield.",
    "comments": [
      "Sapphire cards have always been top notch.",
      "i have got the MERC",
      "I've got it not too long ago! I could barely fit the thing into my pc case, it's huge but thankfully it's cooling capabilities proved to be just as impressive as it's size. It feels like a much higher quality build card than anything i've ever had before.\n\nFirst AMD/Sapphire card i had since the R9 270X. What can i say? I'm very happy with it and I'm glad i decided to get it instead of a 4070, i get great performance with it in 4k.",
      "I purchased the Sapphire Pulse RX 7900XT which arrived yesterday üòÅ",
      "First saphire card, and I'm completely in love with it",
      "40 degrees is pretty hot for a person but not a GPU so it makes sense.",
      "7900xtx nitro+ here.\n\nFans at 15% or so most of the time during gaming. Up to 50% in Furmark.\n\nConsumes down to 3W when idle and up to 480W when overclocked.\n\nDefinitely recommend, especially since it is only CA$100 more expensive than the cheapest 7900 xtx. Of course depends on price in your region.",
      "Got it 2 weeks ago, coming from a 1070. FIDELITYYYYYYY üòÅ",
      "Got mine yesterday and did some adrenaline settings tweaking. For someone who came from a GTX 1080 all these settings were a bit overwhelming lol. Got 50-60c on the highest settings in Cyberpunk that allows me stable 60 fps and I don't hear any fan. Though it seems I somehow can't change the RGBs with my motherboard RGB header where it's plugged in... not important though.\n\nMy 1080 was still enough for high settings BD3 but with the 7800 xt it's a big difference.\n\nQuite satisfied ngl.",
      "I came from the 970 so big leap and ray tracing",
      "Sapphire Nitro 5700 (+XT) had worse PCBs than reference cards:\n\nhttps://www.youtube.com/watch?v=9Nve6XruPgw (Buildzoid)",
      "Ordered 1 last week",
      "Got the 7900xtx nitro+ thermals in crazy good even at oced 465w limit. Only using 50% fanspeed and temps Max reach 64c and 82 hotspot. If i run Stock 404w limit i Can pull fans Down to Max 38% (1450rpm) barely audible and keep temps at 54c and 69 hotspot",
      "I have one, I will finish build today hopefully. I‚Äôm just worried about the coil whine, I still didn‚Äôt had card without a whine",
      "I did as well. It‚Äôs coming today. How do you like yours?",
      "If you can afford the xtx, why not.",
      "I like nitro cards. Currently have 5700xt nitro.\n\nI shall get the 7800xt one when it goes down in price.\n\n700‚Ç¨ is just too much for me to spend on gpu.",
      "Ive took 7900xt last month ago. Waiting for update to improve ai performance specially for pytorch. Ive go some blue screen sadly üò•",
      "I was super tempted but ordered the red devil in the end last night.",
      "My thermals on my asrock challenger 6750xt are starting to worry me. Been getting hotspot temps near 98 and overall temps around 65. It's only a 7 month old card. Was thinking about getting a cooler running new gpu. Might just get this one since you're saying it runs cool. Gratz man."
    ]
  },
  {
    "brand": "amd",
    "generation": "7000",
    "tier": "high",
    "matched_keywords": [
      "7800"
    ],
    "title": "AMD Radeon RX 7800 and RX 7700 graphics likely to rely on high clocks for performance",
    "selftext": "",
    "comments": [
      "and I need oxygen to live",
      "I just got the 6800XT Red Devil, don't think ill change for a few years to come, i'm not missing much am i?",
      "I don‚Äôt think you‚Äôre missing a whole lot. The 7800xt will likely be at best on par with the 6950xt, which while faster than a 6800xt, it‚Äôs not 300 dollars faster",
      "Yeah AMD renamed 6800XT successor to 7900XT and charge 900USD for it.Literally same shit as Nvidia tried with RTX4080 12GB/RTX4070.But they didnt get away with that.Looks like no one cares AMD doing same thing.I dont know how/why, but because of this we will get very underwhelming 7800XT.\n\nInstead +50% performance uplift at +- same cost(7900XT alias 7800XT at 650-700USD) we will probably get samall die as 7800XT barelly faster than 6800XT/6900XT(like 15-20% faster instead of 50%)\n\n&#x200B;\n\nEdit:to be honest GPU market looks like both AMD/NV just price fixing.Nv do some crap like RTX4080 12GB and AMD do same crap.They dont even try compete.They could realease 7900XT as 7800XT for 700 and gain market share.But Noooooo lets just do same shit as nvidia and lets continue price fixing.Someone should take them to the court.",
      "It won't be on N33. 8GB 128bit 32MB cache just does not cut it for 1440p and entry 4K.\n\n7700XT will be a cut N32 die with 3MCDs, 192bit bus and 12GB ram.",
      "bust me tro",
      "Well it's obvious that 3Ghz boost is becoming standard, question is how high can we go in next few years?",
      "I doubt they would gain marketshare. In usa 6800xt is like 300 dollars cheaper than 3080, same price as 3070. But still people buy 3080 and 3070. 6600 is 50% better than 3050, ans costs 80-100 dollars less yet people are buying 3050.",
      "Source",
      "> They could realease 7900XT as 7800XT for 700 and gain market share\n\nWhy do you think this? AMD has been offering the better value product at every price point for years and people still choose Nvidia.",
      "ITS OVER 9000",
      "I hate this. I would like graphics cards to be on the best performance per watt curve. Pushing an extra 10% performance for significantly higher power draw i dont like..",
      "Clocks have a major impact on performance??\n\nHOLY SHIT GUYS",
      "7700XT on navi 33 would be a real dick move",
      "Only slower in ray tracing, faster in practically every other way while using less power and costing considerably less.",
      "My room temp cares. 900 watts of the heat pump in my room is still 900 watts. A PC is not like a console we have them closer to us.\n\nI remember buying my 5700xt on December 3 years ago, the heat was welcomed at that moment, but later in the year became unbearable had to resort to uv.",
      "Breaking News: AMD reduces GPU IPC to enable super high clocks up to 10GHz!",
      "Same as N22 then to make up for the difference in CU count",
      "It would be insane, for AMD\n\nNot only do they still have 6000 series to sell (but not as many as nvidia has 30 series), they also don't have the wafers to supply the demand a half priced 4080 beater would generate.\n\nThey are already undercutting nvidia by 25%, while offering what looks to be better performance.",
      "Source?"
    ]
  },
  {
    "brand": "amd",
    "generation": "7000",
    "tier": "high",
    "matched_keywords": [
      "7800xt"
    ],
    "title": "First PC build 7700X & 7800XT",
    "selftext": "",
    "comments": [
      "A little support for that GPU wouldn't hurt",
      "Bro that 7800XT is sagging, get a support for it for the love of God",
      "The crack on the PCB board will look worse üòè",
      "there's one in the box too",
      "Super nice and clean, I love the white AMD cards! \n\nIf I didin't own a reference XTX I would no doubt have a white one too in my Corsair 4000 Airflow build.",
      "Get a support bracket for that GPU. Even if it's just a simple metal prop rod.",
      "You can also get a cheap $10 support which could hold it up from the other end, either way I wouldn't gamble with pins on my PCIE like that (and not level looks narsty anyway c'mon)",
      "I bought a used 6800xt that bricked after a couple years being almost 4 years old. I took it in for repairs and the guy fixed it saying it's because of not having enough support.\nThe pcb basically separated from the cooler cause it's so heavy. It could have been a bullshit story but I've got my 6800xt back and it's working like new all for less than 50usd",
      "Yes, the unit is the frozen notte 360mm. It has been good for me aside from the pump hissing above 80% speed(easy fix). The aio allows the 7700X to boost up to 5.1-5.2ghz, 85-95 degrees, at 100-105 watts under sustained loads (based on adrenaline software readings). \n\nAlso just put the sag bracket on after reading the horror stories .",
      "If you‚Äôre referring to the case, it‚Äôs Montech",
      "It will look way more off once it comes off your PCIE slot.",
      "I know it‚Äôs on the nitro+, did they include one in the ~~pulse~~?\n\nEdit: Realized it‚Äôs a pure not a pulse.",
      "This the micro center bundle on Amazon? I just built a new PC with the 7700X and what looks like the same MSI board. I'm super happy with mine.",
      "Yes it is. Great bundle for the price .",
      "7800x3d and 7800XT just seems so right lol",
      "Yea same for me, so i put lego there",
      "I just went into the bios and lowered the pump speed until it stopped making the noise(around 80-88%). I have it at a constant speed at all times \n\nAnother commenter said they had the same pump without hissing. Each unit is different.",
      "The notte has been great for me. Only thing that has come up is a buzzing sound above 88% pump speed. Another person said they don‚Äôt have any buzzing. Every unit is different .\n\nI couldn‚Äôt tell you the difference between the prism and the notte .",
      "Just built the same rig with the Micro Center bundle.  Got an XFX Speedster Merc 7800xt though.",
      "Why people put watercooling on CPUs below 200w is beyond me. Watercooling 7700x costs more than 7800x3d with cheap-ass air cooler"
    ]
  },
  {
    "brand": "amd",
    "generation": "7000",
    "tier": "high",
    "matched_keywords": [
      "7800"
    ],
    "title": "AMD Radeon RX 7800 XT Features up to 60 CUs (3,840 Cores), RX 7700 XT with 32 CUs (2,048 Cores): Rumor | Hardware Times",
    "selftext": "",
    "comments": [
      "So much for 7700xt that will be as fast as 6950xt rumors",
      "Should really be called speculation, as the SKU stuff is just *guesswork* by the writer. They even said that in the article.\n\nThe actual info only concerns the GPU, not what it's being used in.",
      "Those were pretty much dead the moment AMD revealed N31 performance.",
      "No. 7700XT will be cut N32. Maybe 2SEs so 40CUs or maybe 16 CUs per SE so 48CUs.\n\n7600XT will be 32CUs and it will use N33.",
      "7800xt will have 12gb vs the 6800xt which has 16, and it's not even GDDR6X.\n\nSounds like AMD is following nvidia's footsteps in card naming and has turned the real 7800xt into the 7900xt and then its all downwards from there.",
      ">as the SKU stuff is just guesswork by the writer.\n\nThey do this every fucking time!  And every time, everybody in the comments just eats it up unquestioningly.  So frustrating. \n\nThe actual GPU die specs are correct, we basically know this by now.  But how AMD decides to segment out the rest of the lineup is very much up in the air.  There's several different ways they could go about it.",
      "They were dead as soon as we saw the very credible Angstronomics article about the specs of Navi 31/32/33 and saw that not only was Navi 33 still gonna be using a 7nm-family process node, but it would only be 200mm¬≤ in size, rather than the \\~350mm¬≤ or so many were predicting(though even that might still not have been enough).  \n\nIt was immediately obvious that there was no way such a small GPU was gonna punch that high.  RDNA3 architecture(minus TSMC 5nm) would have needed to have been a *miraculous* leap in performance efficiency to achieve that.",
      "ITT: people who don't know how segmentation by die size works",
      "As long as it eclipses the 6800XT by a decent amount, uses less power, and costs less.\n\nAlso, drivers need to be solid on release.",
      "There's no way the 7700 XT is gonna be on navi33 with 32 CUs as the article suggests. Angstronomics said that navi33 is mobile first and only outperforms the A770 which means it's gonna be at the level of a 6650 XT. Plus your average consumer is gonna look at the 8 GB VRAM of the \"7700 XT\" and compare to the 6700 XT and see the card as a downgrade.\n\nAnd even if you ignore all the above and just do the math, navi33 with 1/3 the CUs of a 7900 XTX is never gonna outperform the 6800 XT even if it throws power efficiency out the window",
      "if you think 15% improvement in 2 years at the same price it's good, well that's a problem.\n\nmaybe because there is a lot of people like you out there the companies letting themselves keep raising prices like crazy and give us poor value for money",
      "Higher clockspeed so 20% off the 7900xt performance.  \nif priced right it can be a new golden age for radeon cards",
      ">coincidentally the 7900xt & 7900xtx also has an 8 CU difference\n\nThat's not the case. XTX has 96 CU and XT is 84.",
      "With the same clocks as 7900xtx a potential 7800xt would hit just 11% above rx 6950xt raster ( which is 7% more than rx 6900 xt)  with possibility  of TBP 235W.  Key idea is to not price it higher than 6800xt official launch MSRP.",
      "Yeah, what's worse is that  7900XT is cut even further from the full die than 6800XT was but priced $250 higher.",
      "Yup. This is exactly what they‚Äôre up to. A shame that nvidia has gotten so out of control that AMD thinks they can do the same with their pricing.",
      "In what world is 15-20% not a whole lot? You must be confusing the 6900xt with the 6950xt.",
      "The leaks is about navi32 and 33. But not their position.\nSome leaks sugested n32 will be in both 7800 series and 7700 series. N33 for 7600 series.",
      "It isn't their first time, the 5500XT 8GB is faster sometimes than the 6500XT",
      "It has a 256-bit bus, so 8 or 16 GB, according to Angstronomics / SkyJuice. There might be lower end variants with fewer MCDs, but no reason to assume the top model would have.\n\nedit: Angstronomics was 100% accurate with N31, so no reason to assume they aren't accurate with N32"
    ]
  },
  {
    "brand": "amd",
    "generation": "7000",
    "tier": "high",
    "matched_keywords": [
      "7800"
    ],
    "title": "7800 Xt vs 7700 XT vs 4060 Ti 8GB and 16GB- Tested in the newest games!!! (Starfield, UE5, RT, DLSS)",
    "selftext": "",
    "comments": [
      "4060ti is such a bad card",
      "AMD kinda just shit all over Nvidia in most of these tests. You basically have to use dlss to even be competitive if your using a comparable rtx card.",
      "Yeah the 4060 Ti has been an insult from day 1. NVIDIA taking $50 off their insanely priced 16GB version doesn't save those duds.",
      "It's a 4050 and everyone knows it",
      "AMD didn't even have to upgrade their cards to compete lolol",
      "4060ti is an example of how Nvidia loves to fuck their customers.",
      "Even with a bad value the 7700 XT still manages to absolutely murder both 4060 Tis, and the Nvidia fanboys and dumbasses who don't do research will still buy it in masse lmfao.",
      "I knew I made the right decision months ago with 6800xt. The performance is good for the price and the 7800xt is just that mild bump and lower power. Go get em if you haven't already.",
      "when (not if) the 7700XT drops to 400 bucks there really will be no rational reason to buy a 4060ti",
      "It could be 'good' at 250$ for 1080p, but that memory bus has a lot of *massive* situational performance issues.\n\nAnywhere the 3060 outperforms a 4060, it will likely outperform a 4060 ti 16GB by a similar margin due to the bus bottleneck.",
      "People were buying garbage tier GTX 1050 Ti for a HIGHER price than the RX 470.",
      "Don't forget \"RT performance beats Radeons in most cases! Cyberpunk RT shows Radeon sucks! If you want RT, NEVER BUY AMD!\"\n\nSure, 7000 series RT might not be as good as 4000 series, but it's not that trash now. 7900 XTX is roughly equal to 3090 Ti RT performance and nobody said 3090 Ti had shit RT performance...",
      "Even at $350 most of the market won't consider AMD",
      "It's just a matter of price and performance and NVIDIA has done a horrible job with the mid-range. They like to pretend that DLSS3 numbers should be counted the same as raw performance. Let's not forget AMDs 7**8**00**XT** faces off against a plain old 40**7**0 and their 7**9**00**XTX** can lose badly to the 40**8**0 depending on the scenario.",
      "Nowadays I've seen people who insisted on getting the RTX 3050 over RX 6600 / 6600 XT. \"because it's Nvidia\"",
      "the thing people who talk about dlss vs fsr always ignore is that most of the time, amd cards have better fps without upscale vs nvidia with dlss",
      "I don't know about you but a 4080 will cost roughly 300-400 euro more than 7900xtx where I live and that is comparing low tier aib models for 4080 vs high tier aib models 7900xtx. If 7900xtx can beat 4080 in most cases then it's a fantastic card and as far as I am concerned 4080 is in a different price bracket. Only 4090 does not have proper competition right now which I believe everyone can agree with it.",
      "6950xt for me and fuck yes",
      "And even then, in a lot of newer games it seems like AMD wins in ray tracing at equal price points now too. Literally the only argument I can see anyone making for Nvidia cards for purely gaming at this point is DLSS or if you're willing to spend $1500+ on a 4090 and imo DLSS isn't strong enough to justify it.",
      "Well like most people I didn't drop $2000 just to play Cyberpunk with RT enabled. I could care less about RT performance because personally I can't really tell that much of a difference and the majority of games don't even have RT options."
    ]
  },
  {
    "brand": "amd",
    "generation": "7000",
    "tier": "high",
    "matched_keywords": [
      "7800xt",
      "7800"
    ],
    "title": "From 5700 to 7800 xt . it's crazy stupid fast . ( Gigabyte Rx 5700 vs Rx 7800xt nitro+)",
    "selftext": "The 7800 don't even go above 65C' . That cooler is fucking massive.",
    "comments": [
      "its also crazy stupid big too",
      "Is it weird that I prefer the bigger cards? More mass makes for a quieter cooler most of the time.",
      "Yooo I upgraded from the 5700 to 7800 as well (not 7800xt amd fcked up names in my opinion the 7900gre is the xt version)",
      "Upgraded from a NITRO+ RX 5700 XT to a Hellhound RX 7800 XT. Loving it so far.",
      "Upgraded from an RX580 4GB a week ago to a RX6600 (non-XT), it‚Äôs amazing the difference.",
      "So I kid you not, I got up at 7am day of release and had 5 websites loaded, I ended up getting the power color hellhound off of Newegg. The main reason was it was on sale for 500 instead of 520.",
      "Yup, the difference between my 5700XT and 7900XTX is fucking insane and I didn't even get the beefier 7900XTX, I got a hellhound, which is a \"smaller\" one compared to the likes of Red Devil and what not.",
      "Nice . Wich 7800xt you get ?",
      "Similar upgrade path to you, I went from the 6700XT to 7900XTX. \n\nSome games weren't optimized that well, so I saw 50-80% more fps. \n\nBut on many graphically intensive and well optimized games I saw as much as triple the fps.",
      "7900X, I came from a Ryzen 3600. \n\nI made an absolutely massive performance jump. (I got the CPU first), but combined you're probably talking quadruple performance.",
      "Bigger doesn't mean more mass (that would depend on heatsink material mostly). Bigger cooler may offer the same temperatures as smaller one depending on many variables (heatsink material, number and speed of fans, number of heatpipes if applicable, type of cooler etc etc)",
      "Most definitely, your 5800X3D is actually faster than my 7900X in certain games, some games really love the massive cache the X3D CPUs offer. \n\nI would've got a X3D CPU but microcenter had the 7900X, Asus rog strix B650 MB, and 32gb of 6ghz RAM for $500 so i couldn't pass it up. I built a 2nd PC out of my old parts. I wanted to get the 5800X3D but for $150 more I jumped to a much nicer platform, because my old motherboard was a budget MSI tomahawk b450 and lacked features.",
      "those sapphire cards really are chonky",
      "Nice man .",
      "Good upgrade. \n\nYeah I definitely spent too much on my PC but I got tired of buying mid range parts that quickly started to struggle within a few years, at least with a high end computer you can stretch the life of the computer so much longer, so I would argue it costs less. \n\nI think my next upgrade will be a OLED 1440p 240hz or 360hz monitor once prices come down. Right now I'm running 1440p 165hz mini-LED IPS so I need a big upgrade to be worth it.\n\nAMD ages like fine wine, when benchmarks first came out for the 7900XT and 7900XTX both GPUs did not perform that well to Nvidia, now the 7900XTX beats the 4080 in many games while costing $200-$300 less. (I paid $930 for my 7900XTX after taxes and fees).",
      "I never said they were cooler and since they're generally made of copper, bigger=more mass but also bigger coolers mean bigger fans. Fans exponentially increase airflow with size and are more efficient as they get bigger. This is why 200mm fans can spin incredibly slow but still produce a lot of airflow.",
      "I went from 3600 to 5800x3d . Didn't upgraded my MB . I hope this cpu will be fine for the next 4 year's",
      "recently upgraded to a 7800xt from a gtx 1080, loving it",
      "I like to see such upgrades",
      "That card is so beautiful üòç"
    ]
  },
  {
    "brand": "amd",
    "generation": "7000",
    "tier": "high",
    "matched_keywords": [
      "7800xt"
    ],
    "title": "Since 6950XT is now $600, what will the 7800XT be?",
    "selftext": "The 7900XT cost $780.  \nThe 6950XT cost $600.  \nThe 7900XT is 30% more expensive than the 6950XT with current pricing.  \nThe 7900XT must be faster than the 7800XT obviously, but the 6950XT is already pretty close to the 7900XT in raster, so where will the 7800XT be compared to the 6950XT? Will it be slower in raster? For what MSRP, when the 6950XT is $600?",
    "comments": [
      "$499 with 6950xt levels of performance, with less power, and they have a home run on their hands.",
      ">\"6950XT is already pretty close to the 7900XT in raster, so where will the 7800XT be compared to the 6950XT?\"\n\nRelatively might be a bit pushing it a bit. \n\nIts about 15% faster at 1080p and the grap grows as the resolution increses to about 20% at 1440p and over 20% at 4K.\n\nI think its gonna land around 6900-6950XT raster performance so slightly faster than a 4070 but with worse RT. As for the price. Expect the usual Nvidia's price and subtrackt $50-$100. I'd bet on $550",
      "Keep dreaming, and let me dream with you for a while.",
      "My guess is it will match the 6950xt in raster while being far more power efficient and better RT performance.  \n\nI'm hoping this means 600-650 price tag but it will probably be $700 cuz reasons.\n\nI'd love to get a 6950 right now but worried about my PSU being a bit short.",
      "One does not simply leave money on the table.\n\nThat price is to get rid of the 6950XT stock so it will not be available by the time they release a new card with similar performance.",
      "I feel like the 6950 pricing is to clear out inventory before they are left with a lot of stock once faster stuff comes along. \n\nBecause the prices are great, but the power requirements, not so much.\n\nif you can give me card that costs the same or a tiny bit more, but i don't have to swap out my PSU, I'm way more inclined to buy it. \n\nThe 6950's audience are people with really big PSUs in their computer.",
      "Plot twist the 6950XT is the 7800XT because AMD doesn't actually have a 7800XT to release.",
      "Honestly history has shown that many people will buy Nvidia even if AMD is better at the same price point. What they need is mindshare.",
      "6800xt was 16 vs 3080 10 and look how that went",
      "More important, when will it be released?",
      "It doesn't need to be faster than the 6950. It just needs to be cheaper.",
      "Pointless, that's what it'll be, pointless.\n\nThere's not enough room between a 6950xt and 7900xt for a model.",
      "I have a 6950xt with a cosair rm750x psu. Everything runs great and I OC my 5800x too.",
      "As soon as the 6950 XT stock dries up. Probably in a few months from now.",
      "A 7800 XT performing the same as a 6800 XT would be a shambles of a product. There are generational and architectural improvements that go with such a new card that would mean something would have to have gone very wrong for them to release the next in the series at the exact same performance, whether it runs more efficiently or not.\n\nThankfully, all indications are that it'll run faster at somewhere around the 6900 XT with lower power consumption, better ray tracing performance and the bonus of AV1.",
      "6950xt performance for $550 would be fine, for $500 would be amazing, for $600 would be boring, and for $650 would be awful/expected.",
      "700$ would make it horrible, literally worse value than 4070.\n\nIt needs to be a more efficient 6950 XT for 599$ tops - and that's what I think it will end up - otherwise it's useless.\n\nBasically, you will get about 15% better raster and more vRAM but without \"nVIDIA\" and the better software stack. This should even things up nicely.",
      "This exactly. I don't wanna swap the PSU. Because if we did a 6950 + PSU we are in a 7900xt price range where we wouldn't need a new PSU.",
      "That's my point, it needs to be significantly better of a buy to start getting attention.  Like the 6600-6750 were way better price to performance vs NVIDIA and started to pick up momentum.  Still nowhere close to what it could be though. But honestly if it's $700 7800xt that is 10% better than 4070 it's got no chance.  90% of people will go to to 4070 ti or down to 4070, a lot of the rest will go up to 7900xt.",
      "It doesn't need to be cheaper either.  It just needs to be released after 6950xt stock is gone."
    ]
  },
  {
    "brand": "amd",
    "generation": "7000",
    "tier": "high",
    "matched_keywords": [
      "7800"
    ],
    "title": "RX 7800 XT Review | Is it really this good?",
    "selftext": "",
    "comments": [
      "Best card of this shitty generation that is cursed by Nvidia. Also comes with starfield Premium. Currently, it is the best option for anyone buying new midrange. And you can undervolt it for lower power consumption, win win situation.",
      "270W isn't low power.",
      "When efficiency was better on RX 6000 than RTX 3000 no one seemed to care. Now that it's the other way around suddenly power consumption is mega crucial.",
      "Because they started this whole \"charge way more for way less\" stuff we see going on. The company is making endless billions at a rate you can't keep up with yet are trying to nickle and dime.",
      "2024 game devs will find a way to use 20gb of vram on Minecraft looking graphics.",
      "RX 7800 XT really is the best value 1440p GPU it seems.",
      "It's weird that people benchmark hogwarts.. the game only works if you set your pc to 60hz to get no stutters. Anything more and it just stutters... freesync/G-Sync do not work. I've tested it with both a 4070 and 7800xt.",
      "I think you meant the Powercolor Hellhound.",
      "The 16GB VRAM should also offer excellent longevity",
      "how many user have/had the RTX 3080+ with 320W-350W and more? And nobody cares.\ni dont care about ~50W \ni search the best Price/Performance",
      "4070",
      "8K texture pack dlc - $19.99",
      "AMD changed their naming scheme, they didn't add anything on top. Whoever was responsible for the naming at AMD should open a circus. The 7900xtx was the 6900xt, the 7900xt was the rx6900 if they made one. Hence the pricing was the same $999. They offered a 50% uplift in performance for the same money.",
      "How so? \n\nIn this same review, it says 7800XT is 2.12w per frame, 6800XT is 2.48w per frame. Is this review wrong?",
      "I got a 7800xt for my new build and I stick do 1080p gaming and it‚Äôs an absolute beast I get 400 frames easily",
      "Unless you need the reference to fit in the case, the Sapphire Hellhound has much better noise and thermals (in addition to higher clock speed) for $20 over MSRP (at least in the US) of the reference",
      "I have a 6800xt and it's great, but if i were you i'd go with the 7800xt tbh, newest tech, supports all the new features and less power consumption. Can't go wrong with that and it'll last you for a few years probably.",
      "We were only including things people should buy.",
      "Relative to what other card that provide similar performance...?",
      "Really? It outperforms a 4070 in pure frame vs frame case, has 16gb vram vs 12, 256 bit bus vs 192, can be undervolted to 200w avg, and costs $50-$100 less than the 4070. Also comes with Starfield for the next few days. The sales and constant sold-out shows for it. FSR 3 is icing on the cake."
    ]
  },
  {
    "brand": "amd",
    "generation": "7000",
    "tier": "high",
    "matched_keywords": [
      "7800xt",
      "7800"
    ],
    "title": "Simple solution for the 7800XT",
    "selftext": "After watching multiple reviews on the 7800XT it's clear that the card is decent value for money given the current GPU climate and it's nice to see AMD pricing a cards like this compared to the competition.\n\nSaying that, the should have named they 7800XT just 7800.  it just makes SO much more sense given that the card is supposed to be an upgrade to the 6800 which is evident given that A) AMD said themselves that this is the previous gen card it's following and B) they both have the same amount of GPU and raytracing cores.\n\nGiven the performance increase from the 6800 to the 7800XT as well, it would make the card look MUCH better calling it the 7800 AND would make the fact that it's close with the 6800XT in performance quite impressive.\n\nAfter seeing the reviews I thought that AMD only called it the 7800XT to price the card higher, which may in part be true BUT you can find and purchase the 7800XT for LESS than the MSRP of the 6800 when it launched!\n\nIDK maybe it's just me rambling, but I really think that the card would've been received a bit better (not to say that it hasn't) if it had been called the 7800 and would've just made the card look like a TRUE generational increase at a lower cost than the previous generation.",
    "comments": [
      "7600* = 7500 XT\n\n7700 XT = 7600 XT\n\n7800 XT = 7700 XT\n\n7900 XT = 7800 XT\n\n7900 XTX = 7900 XT\n\n&nbsp;\n\nIt's only 5 cards lineup (ignoring Chinese GRE) \n\nThe above makes it feel like they had big generational increases",
      "They probably were thinking that It would have sold less without the \"XT\".\n\nIf they had stuck to the names from las gen there would have been no problem.",
      "I'm glad all the people upset about the inconsistent naming were not around when the HD 7990, R9 390, R9 Fury, RX 480 AKA RX 580 AKA RX 590, Vega 56/64, Radeon VII, or RX 5700 XT launched caused they might have died from whiplash.",
      "> 7900 XT = 7800 XT\n\nWhich would make people wonder why the hell did the price increase by $250.",
      "More like...\n\nLeave 7600 name as is. They named this correctly.\r  \n\r  \nLeave 7700 XT name as is. This is also fine. Price it at $429.\r  \n\r  \n7800 XT = 7800. This is inline with last gen's dies. Pricing is fine.\r  \n\r  \n7900 XT = 7800 XT. Launch it at $699 and it wouldn't be in stock anywhere, still.\r  \n\r  \n7900 XTX = 7900 XT. Price is the same. Halo product at $1000.",
      "Don't forget the RX 580 2048sp (even if it was China exclusive), which is actually just an overclocked RX 570.",
      "I'm not. There is a $250 increase between the 6800xt's and 7900xt's msrp.",
      "It's just AMD doing its AMD things, it happened already in the near and far past (68x0 was equivalent in performance to 58x0 cards while 6950 and 6970 were technically slower than dual-chip 5950/70, x700 was close in performance to 9700 etc), nothing new.",
      "I don't get why people are so obsessed with the naming..\n\nIf they called it the 7800 it would have made any difference? You're getting X performance for Y price.",
      "When the 7900 XT and XTX were launched\n\nI expected they would have a lot of cards in the lineup, since they brought the XTX back\n\n&nbsp;\n\n*nope*",
      "I liked the old HD naming, less wasted number spaces. \n\nHD 7850 \\~ RX 7800\n\nHD 7870 \\~ RX 7800 XT\n\nHD 7730 \\~ RX 7600 or 7600 XT, maybe?\n\nHD 7770 \\~ RX 7700 XT\n\nWe've got these two dead zeros at the end and they're tacking on XT or XTX (no LE cards, though).\n\nIn the end, it's all marketing. They wouldn't be naming cards like this if it didn't work. I'm sure the vast majority of their customers don't know too much about card hierarchies. They just know that bigger numbers are better and Xs at the end are even more betterer.",
      "Also the outrage is really western centric. Previous generation AMD had massive discounts through the year over there. Meanwhile in the Philippines, 6800 XT is still $680 and 6700 XT is at $390. 4060 TI 16GB is at $550 now, so if 7800 XT releases at $550 here, that's massive value over previous generation.",
      "This whole naming problem just goes back to the XTX and XT. They tried to copy NVIDIA's homework, by copying the idea of naming a card higher than it should be and it's come back to bite them.\n\nIt should have been: \n\n* 7900 XT (instead of XTX)\n* 7800 XT (instead of 7900 XT)\n* 7800 (instead of 7800 XT)\n* 7700 XT (It can stay, it's probably the most appropriate name so far, but its overpriced. It needs to be $399 to be worthwhile.)\n* 7600 (another decent name, but it should've launched at $229 to save face on the reviews at launch, it sells for around that now anyway...)\n\nBecause they named the 7900 XTX and more importantly the 7900 XT what they did it's made the rest of their naming in the lineup pretty poor. They got greedy and decided to upcharge by naming the 7900 XT what they did to reap more profit, they get what they deserve really. A \"poor\" generational uplift in terms of performance when comparing the 7800 XT to the 6800 XT in reviews because of a dumb naming scheme.",
      "I believe the simple answer is that they actually wanted to get rid of the non xt versions. I really think the non xt's were a \"necessary\" evil during the GPU shortage simply because it allowed more product segmentation and allowed them to increase profits(6800's are just 6800xt's that were underperforming) so they didnt have to sell them as 6700xt's. \n\nNow we are over the shortage issues they want to get rid of non xt's for branding and simplifcation which i think is fine. The fact that the 7800xt looks \"bad\" compared to the 6800xt is just a reality and its a fair critisism but its a minor one as 6800xt was already a really good gpu at the price so a modernized version isnt bad per se, but from a consumer standpoint every GPU should have been a notch, in nvidia's case sometimes 2 notches, below what they actually are. Its just a reality of current gen GPU's. In the end price to performance is king and 7800xt is a good GPU.",
      "To be fair too, they still sell a lot from first day sales numbers from multiple outlets. Having the 6800 XT at great value doesn't make the 7800 XT a bad card at all. Especially since some countries never dropped the price of 6800 XT (still $680+ in the Philippines). The 4060 TI 16GB is at $550 now, so the 7800 XT releasing at same price is MASSIVE value over the 6800 XT.",
      "You don't get the point, the name doesn't change the performance of the card but it is used for deceptive marketing and as excuse to inflate prices.",
      ">(ignoring Chinese GRE) \n\nCan't, Chinese GRE haunts my dreams. Should have called it Freddy Kruger",
      "Actually no, the 7800XT is Navi 32, so it should have been named a 7700XT if they were in-line with last gen, the 7700XT would be the 7700",
      "In olden times there was a lineup of Radeon 9000, 9200, 9500, 9550, 9600, 9700, 9800, some of which were dx8 gpus from r2xx generation, the others were first-gen r300, then the next were 2nd-gen r300 (with two variances in the same SKU line like 9600pro/xt and 9800pro/xt) and so on and so forth. 9550 was slower than both 9500 and 9600 (and 9500 was faster than both especially if you unlocked it to ghetto 9700pro). No one was really complaining then for some weird reason, people just read the specs and checked prices instead of expecting that number 6 or number 9 provides whatever they want.",
      "6800 XT and 6700 XT use different dies. The real reason for the non-XT's was defective dies, as without a lower binned SKU, those dies would go in the trash."
    ]
  },
  {
    "brand": "amd",
    "generation": "7000",
    "tier": "high",
    "matched_keywords": [
      "7800"
    ],
    "title": "AMD Radeon RX 7800, RX 7700, and RX 7600 tipped for a June 2023 launch",
    "selftext": "",
    "comments": [
      "Waiting for Nvidia to release so they can price it at the same outrageous prices with little backlash",
      "This makes the most sense honestly considering the cadence thus far.",
      "I'm still waiting for the prices to drop; everything is overpriced now.  \n\nIt's 2023 and prices are still affected by the pandemic from 2020 and mining, which is very bad.",
      "Probably to try and squeeze out a few more 7900‚Äôs before they release the series of cards that most consumers want‚Äîlow end to mid-range. \n\nAMD‚Äôs problem this gen is going to be DLSS 3.0. By the time FSR 3 comes out DLSS 3.0 will have matured and have made its way into games, basically meaning FSR 3.0 is probably going to have the same issue as previous iterations‚Äîadoption rate. Next problem will be RT performance, power consumption, content creation, and probably pricing to compete. \n\nAs seen with the comparison between the 4070Ti and 7900XT, rasterization performance alone isn‚Äôt going to sell a lot of cards, feature sets are going to dictate what card has better value. \n\nI had high hopes for AMD with the 7xxx series, but when I see basically normal generational steps up with their lineup while not pushing the envelop and charging high prices, it really disheartened me. \n\nNvidia, while still expensive, saw some nice gains, especially in the 4070Ti, while also bringing out a much more robust feature set at launch, and nailing the power consumption, unlike AMD that just keeps promising, is why I chose Nvidia this time around. \n\nC‚Äômon AMD, innovate! Quit copying Nvidia while being late to the party. You only get one first impression and they seriously need to up their game in that department.",
      "Yeah. I feel like there's WAAAAY too much gaslighting on hardware subs on this site over high GPU prices. \n\nI mean, if they sell, you got the free market bootlickers going \"well ackshuilly they're selling so that means the prices are justified\", but if you point out low demand and them cutting back stock to keep prices high, people just find another nonsense argument to push.\n\nIt's like way too many people are trying to contort themselves into pretzels to justify these crap prices.\n\nAnd then they're like \"well ackshully its just out of your budget\", YEAH NO CRAP! The current prices are insane, and the lowest RDNA 2 discounted cards are the only ones that remotely approach what i consider a fair pricing. \n\nSeriously, it wasn't long ago when the top end GPU was like $500. Then suddenly it was $700. And then it was $1000. And then $1200. And then $1600. \n\nIt's insane. \n\nHeck, I remember in the late 2000s you could get like a 9800 GTX for like $250 or something. \n\nI remember my first GPU being a $80 3650 and my first \"REAL\" GPU being a 5850 for like $300 or something.\n\nAnd that was like the fourth strongest single card on the market at the time, only below the 5870, 470, and 480. \n\nI mean I remember when the market had like several tiers of products in the $100-200 price range alone. And anything from $100 on up was fairly \"gaming capable\". \n\nReally, this current market is broken.",
      "and added some new cringe presentation to mock ur competitor but cant deliver performance you promised",
      "That's not what price fixing means",
      "Aren't sales at an all time low?\n\nThen there is the \"overpriced for the market\", and \"overpriced compared to previous gens\" distinction.",
      "JUNE?",
      "As a survivor of Fury and Vega...\n\n... don't buy based on promises of future driver improvements. They don't come, are less than you hoped for, and you will never get over the feeling that you're leaving a lot of performance on the table. Those fixes won't actually come without hardware revisions, even when it'd technically be possible to do in software.",
      "Hello, it looks like you've made a mistake.\n\nIt's supposed to be could've, should've, would've (short for could have, would have, should have), never could of, would of, should of.\n\nOr you misspelled something, I ain't checking everything.\n\nBeep boop -¬†yes,¬†I¬†am¬†a¬†bot, don't botcriminate me.",
      "That is not needed, navi31 is on the market for a long time already, and the drivers are ok.",
      "Where is the fire extinguisher?",
      "New foundries which were start building in 2020-2021 coming online somewhere in 2024-2025. 2025 was my guess two years ago on when chip shortage would become more like chip abundance again. So still quite a while before chips isn't a limiting factor.",
      "> everything is overpriced now.\n\nCounter-point: They're still selling so it's not over-priced; just out of your budget.",
      "Well said, I would of been fine with the minimal raster up lift with the gen if AMD really hammered down on the other core features like content creation, power consumption, RT performance and competitive pricing. \n\nInstead AMD said sprinkle a little more raster, forget about anything other than raster and let's hike prices.",
      "Clearing RDNA2 supply, which is taking much longer since almost no one is buying any GPUs.",
      "It'll be interesting, \nIf budget allows, looking forward to a rx7700 later this year. And then probably no upgrades for years....",
      "All overpriced shit, skip this generation.",
      "The 4090 owners have bought them."
    ]
  },
  {
    "brand": "amd",
    "generation": "7000",
    "tier": "high",
    "matched_keywords": [
      "7800"
    ],
    "title": "XFX Radeon RX 7800 XT launches at $539 on Amazon, RX 7700 XT available for $459 - VideoCardz.com",
    "selftext": "",
    "comments": [
      "Let see how the EU pricing will look like        \n\n-------------------------\nedit: at least here are decent  aka at MSRP or 20-30euro more for higher version                \nhttps://www.mindfactory.de/search_result.php?search_query=7800+xt     \n\nedit 2: managed to get Shaphire Nitro+ for 630 euro in my local store so like 11 euro more than in mind factory, less if you consider shipping & stuff - it will be also delivered tomorrow.   \n\nedit 3 : today supplier called that they need to move my order by 2 weeks as \"they had less in warehouse than they assumed\" .... well canceled order looking for other supplier             \nI wonder how good supply will be.",
      "Well I am sure the price in Finland for me will be something like ‚Ç¨900 lol ^/S\n\nedit: Just checked, the most expensive one is the powercolor red devil and it's ‚Ç¨700",
      "Snagged one.\n\nThank you for sharing! Because of you I have my first new GPU on the way in almost 10 years :)",
      "AMD promused 550 euros including vat in the eu.",
      "litterally anything would be a uprgade at that point",
      "EVGA ACX 2.0+ GeForce GTX 960 4 GB (https://pcpartpicker.com/product/cBjWGX/evga-video-card-04gp43965kr)\n\nI was really starting to struggle with modern games and had to buy a subscription to GEForce Now to be able to play Darktide with my friends when it came out.\n\nBig upgrade. Quadrupling my VRAM xD",
      "I wish it was eligible for the Starfield promo :(",
      "it is, just wait for official release in an hour",
      "6800 XT performance at 6800 XT price. What a time to be alive. üòÇüòÇ",
      "The official release time is in 1.5 hours I think.",
      "You are missing the fact about what is EU.",
      "> litterally anything would be a uprgade at that point\n\nik ik poverty gaming",
      "You can get a new 6950xt for 520?  Lowest i see is 620 or are you including the starfield promo?  And im assuming the rest of the world its more.",
      "Ayo, where reviews at?",
      "Yeah. For their shop offer. It's a different story for other models.",
      "Well you can order from anywhere in EU.             \nI assume that quite probably i will order from mindfactory and use some shipping service ... but who knows maybe one of the local sellers will actually surprise me (i would be honestly surprised).",
      "In my country you mostly rma to the shop you got it from and they deal with it. If the manufacturer has a repair center in the county, you can send it to them.\n\nIf I buy a Samsung SSD from Germany and send it to them from my country with a German receipt, they will instantly reject it. At least that's my experience.",
      "In your post you said \"its 14:30 now\" while it was 13:30 in the timezone that was used for the review embargo.\n\nSo you _don't_ live in that timezone. Also the GN review went live exactly at 14:00, or 15:00 your timezone. Funny how that works.\n\nMaybe you should go back to America.",
      "Amazon Spain still waiting......",
      "It‚Äôs not? That was one of the reasons I waited for this.\n\nEdit: It is"
    ]
  },
  {
    "brand": "amd",
    "generation": "7000",
    "tier": "high",
    "matched_keywords": [
      "7800"
    ],
    "title": "RTX 4070-beating RX 7800 could cost US$549 as RX 7700 and RX 7900 MSRPs allegedly fall under US$700 and US$500 respectively - NotebookCheck.net News",
    "selftext": "",
    "comments": [
      "Ah can't wait for the 7800 to beat the 4070 by 5% in some cases, lose in others, cost 50 dollars less, use 50-100w more power, and sell approximately zero units due to the bad reviews.\n\nYou know a gen is terrible when even the *rumours* about the upcoming cards suck.",
      "Don't forget the part where AMD ends up slashing the MSRP to where it should have been to begin with after a month or two.",
      "DOA. \n\nI can already grab a 4070 for 560 where I live. \n\nTo be even worth considering AMD need to be at LEAST 20% cheaper at around the same raster performance especially if they have worse efficiency. \n\n7800 is pointless at anything over 450. Just get a 4070 or buy second hand.",
      "So they aren't worth buying until 2024.",
      "And don‚Äôt forget that it will badly lose in RT, and it doesn‚Äôt even carry new unique technologies over RDNA2",
      "Those TDP numbers MLID leaked made no sense. At least that's where I'm assuming you're getting your 7700 power numbers from. More likely the 260w and 245w is for the 7900 GRE and 7800 rather than 7800 and 7700.\n\n245w that he claimed for a card that is 3/4 of the full die in almost every way would be insane for a cut down die. 15w for disabling 1/4 of the die and memory? That would mean they are pushing the frequency target for the 7700 way higher than the 7800, which is the opposite that usually happens on cut down cards. Often they are also sold as lower chips because they can't hit frequency targets.\n\nThe 260w lines up more with the 7900 GRE,  and 245W with a full 60 cu 7800 with a N32 die pushed to it's limit. I don't think anyone knows the 7700 TDP. Either one of his contacts is confused, or it's all made up.",
      "source mlid  \nThen we turn off the tv",
      "The 7700 uses 50W more already than the 4070, what makes you think the 7800 will have the same TDP as the 7700?",
      "Personally for my next build, a second hand (or even brand new) rx6800 non-xt starts to make more and more sense around this performance level both for the budget and for the efficiency. Card has been a sleeper beast, undervolts well, smashing the 3070 and closing in on the 3080 and 4070 in many titles. Its existence is making the 3060,3070,3080,7600,7700,7800 and even 4070 kind of redundant unless you care for RT performance. Current amd gpu gen is looking so pointless, at these prices, unless you are going for a 7900xt or 7900xtx. Makes the 4070 look like a decent deal when it is oh so very far from that. 6000 series were killer gen and aged so well.",
      "Recently it's been down to a day or two\n\nBefore launch",
      "It's really hard to believe just how badly AMD have dropped the ball on this generation, especially when compared to the RX 6000 series that seemed like a solid alternative to the RTX 3000 series (although I'm sure the pressure of availability helped).\n\nWith equal core configurations, RDNA3 products have measly performance improvements over their previous gen counterparts. AMD no longer has a **90 competitor, yet they've reintroduced the XTX SKU for some reason. RX 7000 GPUs have all the downsides of being MCM products with none of the benefits. They don't even have a dual GCD product to show for it. I really hope it pays off, because this generation seems like a flop architecturally.",
      "What's interesting is that the 4070 is more like a 60ti class card this generation and AMD is releasing an X800 class card that seems to be it's competitor if rumors or true.",
      "The 7900 GRE uses a cut-down version of the Navi 31 GPU, has uncertain global availability and possibly quite limited supply.\n\n7800 is expected to be based on the Navi 32 GPU, meant for mass production.",
      "I don't necessarily believe this is exactly how it will play out but it's just disappointing and confusing to see AMD be so strong in cpus and then screw the GPU division up so bad that they can't capitalize at all  while Nvidia is weak in the consumer market.",
      "7700 at $300 and 7800 at $400? Keep dreaming lmfao.",
      "You're dreaming. AMD would need to sell the dies to AIBs at the cost they buy them from TSMC and make no profit in order for that to happen. Or at least they'd be making no more than 10% margin on the dies. Maybe when RDNA4 gets announced, and they try to liquidate old GPUs you'll see those prices.",
      "They had a large boost when you compare the area/die version.\n\n4070 is using what would be the 4060 die in another generation. \nCompare the 4070 and the 3060 and you are going to see a major boost in performance. \n\n4090 had a massive boost because it's not using a lower spec die.",
      "Dude have another fantasy about amd, then state it as a leak. Probably true for his pants.",
      "Yeah that's why Nvidia was able to pull this. They got such a large boost in performance in this archicteture that they can rebadge their cards with no problem.",
      "What the fuck is this title, just speak normal english holy fuck."
    ]
  },
  {
    "brand": "amd",
    "generation": "7000",
    "tier": "high",
    "matched_keywords": [
      "7800"
    ],
    "title": "‚ö°Ô∏èGPU Retail Sales Week 40 (mindfactory) - RX 7800 XT top, Intel a non-seller",
    "selftext": "",
    "comments": [
      "The Intel cards sold went solely to that dude posting his dual A750 build lol.",
      "I was surprised to see the 7800xt selling more than the 4070 given prices here in Europe are completely stupid where I see a lot 7800xts more expensive than 4070's.\nThen I went to the mindfactory website only to realize that they aren't being greedy and the prices actually make  sense there. Do they ship internationally? Within Europe?",
      "I was a long time Intel and Nvidia guy. \n\nWhen Ryzen came out I was skeptical but eventually hopped on the 3700x after seeing the benchmarks. The bang for buck, upgradability, and value was pretty enticing. I'm glad I went with my 3700x because it just plows through without a sweat. And I was coming from a I7 2600k. I have no regrets with my 3700x and I have no plans on getting rid of it anytime soon.\n\nHowever I'm still with my 1080TI. It's a great card however it starting to show its age and want to upgrade. I looked the 4070ti, but I can't get over the stupid 12 GB of ram. My old 1080ti has 11GB. I did some research, watched some videos, looks like AMD has made some real advancements in software (Adrenalin) and features. I think my next card will be AMD too. I'm not coughing up 1k+ for a gpu. Fuck all that.\n\nI'm at a point where I don't care about the max performance I can buy, I just wanna be able to game with my friends at a reasonable price to performance ratio.",
      "1. Because I expect a newer card to have more VRAM.\n2. It's future proofing, I'm playing on a Ultrawide which sits between 1440 and 4k, but I want to go to 4k soon.\n3. Because I want more VRAM.",
      "de only, but you can use mailbox.de",
      "Why this one retailer has to be so much different with rest of the market?",
      ">4070 is in no way \"premium level\"\n\nTell that to Nvidia trying to sell it at a premium price lmao",
      "Mindfactory doesn‚Äôt represent shit. Pccomponentes is a Spanish retailer that is bigger than them and there the most sold cards are the 3060, 6700XT, 6800 and 4070.\n\nAnd other retailers might have different order.",
      "It's playing most games I play without issue. Sure, it's not on ultra, but I'm perfectly fine with medium settings because I really don't care about turning on every setting to the max. Also I don't swtich out hardware frequently. As I mentioned I went from a i7 2600k to a 3700x so I'm fine with waiting several generations and then leaping forward when it's time I feel I need to upgrade.\n\nSo far the only game the 1080ti has struggled with is Starfield and even then it's been playable, but also they did a crappy job of optimization.",
      "Looking at the price .... it is",
      "Last time these were posted (week 39?), people were mentioning how 7800xt wasn't on the list at all even though they been available. Seems like this is more than \"one week\" of sales for 7800XT?\n\nDoesn't really matter though, makes it even more pointless set of data. I really don't get the point of even posting it but to all their own.",
      ">how are 8gig R9 390 and RX580 doing these days?\n\nBelieve it or not, pretty good actually, like sure you'll have issues playing the latest AAA releases, but AA games, indies and competitives? no issue.",
      ">You trying to justify otherwise is just covering for being a cheap ass.\n\nPeople who say this sort of stuff tend to be the most broke. I'll spend my money how I want. Shelling 1700+ USD for a GPU isn't really high on my list of priorities. I have other things and responsibilities that come before generating pixels on a screen.",
      "I think you are missing the point.           \nHe have a card from 2017? that have 11GB ram.       \nFact that in 2023, so 6 years later \"premium level\" card have 12GB ... well i agree with him.",
      "It isn't scam, it is about getting desired features and performance at desired pricepoint. If AMD card can satisfy you whie costing less and you understand what you get - then why pay more?",
      "One retailer is completely pointless and shows nothing. AMD is still getting absolutely slaughtered in the GPU market.",
      "hmm i wonder why\n\nthe 7800 xt hellhound is at the moment almost 200 euros more expensive than mindfactory\n\nGREED",
      "Scammed? Hard to get scammed when the benchmarks and reviews have been done over and over by many reputable reviewers.\n\nThe real scam is 12 GB of VRAM on a card in 2023 when my 1080ti still have 11GB.  Is AMD's option perfect? No. But it's better then what Nvidia is pumping out.",
      "What card have you owned that was better than a 7900xtx?",
      "bs, 7800xt is faster, please don't compare apples to oranges"
    ]
  },
  {
    "brand": "amd",
    "generation": "7000",
    "tier": "high",
    "matched_keywords": [
      "7800"
    ],
    "title": "AMD Announces \"This is Why We Game\" Game Bundle with Radeon RX 7800 XT and RX 7700 XT Graphics Cards",
    "selftext": "",
    "comments": [
      "If someone hasn't gotten an RDNA3 card by now I don't think this is what's going to move the needle to convince them. The entire line needs price drops to clear space for RDNA4 tbh.",
      "Good to see the 7800 XT and 7700 XT bundled together. If someone asks me why I have both, I'll tell them this is why we game.",
      "Yes, i got myself a 6750xt and is enough for my daily use on 1080p, would only make Sense going to 7800xt which IS close 4070 super and not such a big price Gap to TI version, what makes 7800xt/7900gre useless at this point\n\nVery little reasons to move to 7000,",
      "\"this is why we game\"\n\n\\*starfield\\*\n\nIs this backhanded insult?",
      "Honestly even for 1080p, a 6750XT is still bordering on overkill. Given that a lot of gaming lately seems to be marketing 1440p and 4K, 1080p gaming has kind of seen diminishing returns as these GPUs get faster and faster. Most of the time you're gonna get capped by the CPU at that resolution. \n\nSo unless you are planning to go 4K any time soon, that 6750 is gonna carry you a *long* way.",
      "You misunderstand my point, which had nothing to do with Nvidia, but just to point out that a blanket statement of declaring the 6750xt overkill for 1080p would serve someone wanting to enjoy rt/pt games very, very poorly.",
      "2023 titles, most of which can be found in a subscription(gamepass/Ubisoft+) and only for 2 gpus.\n\nPretty disappointing ngl.",
      "Probably because they're the ones whose unit sales are the most below AMD's projections.",
      "Hmm, sounds to me like a move to clean up the stock and make room for successors",
      "Well that depends on what games you play. With all the graphical ray & path tracing, something like Alan Wake 2 / Cyberpunk would absolutely annihilate a 6750xt even on 1080p, and upscaling+fg at such a low res and baseline framerate just isn't good.  \n\n\nIt always depends.",
      "Why the specific 7700 XT and 7800 XT GPUS only?",
      "7700xt struggled in sales because it doesn't differentiate itself enough from previous-gen 6700xt and 6800.\n\n\nThe 7800xt was selling okay, but with the 7900 gre releas e (and the 4070 super), unless your budget is absolutely hard capped at $500, you can now spend just a little more to get a significant performance boost with other options.\n\n\nThis is likely an attempt to move stock for both.",
      "It clearly says that the promo is for 7700XT and 7800XT...",
      "lies of p is best pick.",
      "Aren't these just the same rotating games that come with a GPU purchase on Newegg anyway? How about you finally slash the price of the 7900 XTX instead?",
      "its called scraping the bottom of the barrel.  Starfield a dead game that tries to sell you a quest line for 7$.",
      "I‚Äôd wait at least another generation. The upgrades are (mostly) slowing down, and the 3070‚Äôs still a fantastic card.",
      "I upgraded from my 1080 this weekend to the 7800xt. Found a local guy on fb marketplace selling it for $375. This was still a better deal",
      "more like \"this is why we pay 500$ for 5% performance 3 years later\"",
      "I wouldn't suggest Avatar nor Starfield to use as advertisement, associating mediocrity to their brand sound like a bad move."
    ]
  },
  {
    "brand": "amd",
    "generation": "7000",
    "tier": "high",
    "matched_keywords": [
      "7800"
    ],
    "title": "AMD 6800 XT vs AMD 7800 XT",
    "selftext": "* Compute Units: 6800 XT: 70 , 7800 XT: 60\n* Stream Processors: 6800 XT: 4608 7800 XT: 3840\n* Boost Clock: 6800 XT: 2.25 Ghz 7800 XT: 2.4 Ghz\n* Memory: 6800 XT: 16 GB 7800 XT: 16 GB\n* Memory Bus: 6800 XT: 256 7800 XT: 256\n* Memory Speed: 6800 XT: 16 Gbps 7800 XT: 19.5 Gbps\n* Memory Bandwidth: 6800 XT: 512 GB/s 7800 XT: 624 GB/s\n* Power: 6800 XT: 300 W 7800 XT: 263 Watt",
    "comments": [
      "6800XT has 72 CU's, not 70.",
      "These new cards only make sense for people coming from older card generations, not previous gen.",
      "Why would you even consider upgrading a 6800xt anyway",
      "Makes me love my 6800xt all the more. Can't wait for FSR3!",
      "Rasterization performance will be similar between the two cards. Though I imagine the the 7800 XT will pull ahead in ray tracing. Biggest wild card is if cache makes much of a difference as the 7800 XT only has 64mb vs the 128mb in the 6800 XT.",
      "The only reason I‚Äôll make my next upgrade is if ray tracing is both impressive and achievable with a mid range gpu. Until then, I‚Äôm just chilling.",
      "7900 XT is the first step up, barely. Literally only option I would consider is 7900 XTX but its freaking 1200‚Ç¨.",
      "I think there isn't much reason to upgrade until the next generation of consoles are out (I reckon \\~4 years from now). If you have a card that is on par with the current-gen consoles, then it should easily play games for as long as this gen lasts.  \n\n\nThe watershed moment in gaming in terms of specs and requirements is the launch of new consoles. Every GPU launched in between is just a stepping stone.",
      "As usual it depends on the specific game but overall the 7900xt is much faster. 27% in God of War, 40% in Cyberpunk, 30% in AC Valhalla, 35% in RDR2. Also 26% higher in Port Royale and 28% higher in Speedway.",
      "It is already confirmed by AMD, it can be used from RX590 onwards",
      "I'm so glad I got a 6800xt half a year ago tbh",
      "Yes, but the feature that reduces latency is exclusive to RDNA3, the plus version. Also, they recommend 60 fps as a baseline.\n\nOverall, this is still better than nothing, hopefully it will infuse some life into old gen cards.",
      "It's a slight regression, but not as a big regression as what happened with Nvidia and their total restacking of the 4000 series.\n\nI mean this 7800xt could have been the 7700xt, or simply a 7800 without the XT.\n\nNvidia went as far as upgrading a 3050 to a 4060 Ti..",
      "Specs are the same as the RX 6800 but it's labeled as an XT. It *might* have performance parity with the 6800XT but I don't expect it to perform any better, if at all, based on the 7900 GRE. Seems like the larger lower level caches help alleviate the need for more Infinity Cache. 128MB Infinity Cache on the RX 6800 is overkill as you'll never clock high enough (2.6 Ghz max) to introduce notable bandwidth bottlenecks in most titles.",
      "If you want raytracing in the mid range go buy an Nvidia card. Waiting for AMD to catch up is just going to leave you disappointed.\n\n3080tis and 3090s are like $500/600 used, that will get you the RT perf of a 7900XTX, and you‚Äôll get DLSS to assist with running the heavier RT games.",
      "But, do you guys really upgrade your GPUs with every new Gen...?",
      "RX 6800 XT has 72 CUs, not 70.",
      "You missed a key feature: Infinity Cache.  \n\n\nThe 6800XT has 128mb while the 7800XT has 64mb.",
      "well, the 5090 is rumored to have 512-bit bus. don't expect 512-bit bus from AMD any time soon, especially if the rumors of them dropping Navi 41 and 42 end up true.",
      "At how many watts?"
    ]
  },
  {
    "brand": "amd",
    "generation": "7000",
    "tier": "high",
    "matched_keywords": [
      "7800"
    ],
    "title": "Alleged AMD RX 7700 and RX 7800 GPU Performance Leaked",
    "selftext": "",
    "comments": [
      "It's sad how predictable it is that AMD will try and release these at way too high a price point, get absolutely panned in the reviews, have terrible sales and then slink away to drop prices to a more reasonable level after everyone has already decided to buy something else.\n\nIf the 7800xt come out under 500 dollars it'll be a good launch.  But you just *know* AMD are going to try for 600-650",
      "I mean we already had an upper bound with the 7900xt's performance, what could people have reasonably expected? Anything genuinely good? no way. All those rumors about some purported hardware defect that's fixed in navi 22 were clearly hogwash in the first place.",
      "Unlikely 600.\nRTX 4070 (non Ti) had a $599.99 MSRP on release and I'm pretty sure they'll try to price it less.",
      "The problem are the powerspikes, not the average load.",
      "> Anything genuinely good?\n\nBefore rumors speculating on the disappointing performance of the 7700 and 7800 started to leak out, I had been hoping for a 16 GB 7800 XT = 6950 XT with lower power consumption and a 16 GB 7700 XT = 6800 XT with lower power consumption on the level of the 4070 allowing for some short cards.",
      "6950 XT has some disadvantages, namely power and size.\n\nYou're gonna need an 850W+ PSU for one, and many people buying a 500-600 dollar GPU won't have one.",
      "No, 7900 XTX competes with 4080.\nAlready priced lower and have matching performance in raster (see reviews)\n\n7900 XT vs 4070Ti and 7800 (XT?) vs 4070.\n\nNo competitor for 4090.",
      "Yet the 6950 XT is still in widespread stock everywhere and is markedly better than the 4070 and I suspect at the best-case scenario price of ‚Ç¨530 they're near breakeven.",
      "Without watching the leak i can tell you also my \"leak\" or my guess. It would be same as from rx 6700xt to rx 6750xt improvement (for 7700 over 6750). This AMD gen is failure. The only way they \"win\" is more vram lower prices.",
      "Wouldn't expect a 7700xt to have 4070 power use when nothing else in the stack has been that efficient",
      "Unfortunately, it is not. It is more like 4-5%.\n\nHave you seen the 7600 reviews? See how it compares against the 6650XT, both cards feature 32 CUs, one is RDNA2 and the other is RDNA3. This is the best CU to CU comparison and the difference is 4% (source: [techpowerup](https://www.techpowerup.com/review/amd-radeon-rx-7600/32.html)).",
      "That's kind of cheating, given the 5700xt was only 251mm¬≤ chip.",
      "It's hard to say exactly how the 7700 and 7800 will compare to the 6700 XT and 6800 XT based on what was leaked, but as anticipated it does not look very encouraging.  If the 7800 has the same performance as a 6800 XT, it might be difficult to choose a 7800 over a 4070 unless the 7800 is at least $100 less.",
      "The 4090 jump isn't that much smaller than the 1080Ti jump. The 4090 is like 70% faster than the 3090 at 4K.",
      "6950XT reasonable expectation? For the 7800(XT)? I wish.  \n\n\nThe 6950XT is \\~10% slower than the 7900XT ([HUB](https://youtu.be/NFu7fhsGymY?t=585) shows a \\~9% gap at 1440p). And it features 80 CU. Unfortunately there is no chance the 7800 with just 60 CU will come close to the 6950XT.",
      "Why would you even consider upgrading after just one generation",
      "I had higher expectations as well, but after learning that CU per CU, there has been almost no generational improvement, it became clear that the 60 CU RX 7800 (XT) wasn't going to be much faster than the 6800 non-XT.",
      "Except many can't, because the power spikes on some cards went well beyond anything reasonable. There was, and still is, a lot of back and forth between the gpu and psu makers over this.\n\n\nEdit: there was even an update to the atx standard over this.",
      "Have you seen GPU releases the past 6 months? that defines this entire gen.",
      ">Meh, people also said AMD would price 32CU N33 at 350 dollars, yet it ended up at 270 and on sale for cheaper than that and/or bundled with a game.\n\nBecause people thought it would be more competitive? Once we knew that 32CU N33 is such disaster - people expected 249$ or less"
    ]
  },
  {
    "brand": "amd",
    "generation": "7000",
    "tier": "high",
    "matched_keywords": [
      "7800"
    ],
    "title": "‚ö°Ô∏èGPU Retail Sales Week 44 (mindfactory.de) - Demand still rising, 7800 XT doing very well",
    "selftext": "",
    "comments": [
      "I just recently got my 7800XT. it is an absolutely amazing 1440p card. I can‚Äôt wait to hold onto it for years to come.",
      "I want what you're smoking",
      "Imagine buying 4060 or 4060 ti. Mind boggling",
      "If you honestly think AMD is outselling Nvidia in any meaningful context you're delusional.",
      "Next Week, and 7800XT still best selling GPU. My 6800XT looks at it with pride.",
      "And performance.",
      "Couple hundred sold in a small market is nothing ü§£ amd fans getting off to these post is hilarious",
      "OEMs and prebuilds love the 4060/ti",
      "What's the alternative if you have $300 and need the features that Nvidia provides? the 3060?\n\nThe 4060 and 4060 ti are bad cards but for the price, if you need Nvidia there's no alternative aside from old-gen cards if you can still find them for sale.",
      "Me too, great card. AMD just need to concentrate now on FSR 3 for better quality picture. Year has passed and it needs to deliver. Intel upgraded its XeSS twice now in a year and its producing better pic then FSR2. All cards on FSR3, but not that beta one released month ago.",
      "Damn, talk about a reddit moment. \n\nThe person you responded to never claimed the data included prebuilts, they just pointed out how 4060's are easily sold to people who don't know any better through prebuilts. \n\nThis is backed up by 4060/4060ti numbers on steam being shown when they don't sell very well to DIY'ers like in the data you're whatabout-ing.\n\nYou're so desperate to argue about shit that you didn't even consider you might be interpreting something differently than it was intended.",
      "Well of course it looks with pride, its the twin brother lol.",
      "Why would i buy a 7600 for just $30 less?",
      "what is the problem with the 4060? It is better than the 7600 and there are not other options at that price point",
      "All 40 series cards (6 of them) are amongst the top 12 most sold which is quite remarkable.",
      "Your reality*",
      "Too many prebuilts with them unfortunately",
      "Keep up the cope. \n\nWhile the 7800xt has been BOOMING, amd‚Äôs market share can‚Äôt even hold a candle to nvidia‚Äôs. No need for fanboyism",
      "I work with b2b sales and always thought Mindfactory numbers are off by a huge margin compared to every other store and my own experience + Steam Hardware Survey.\n\nI don't believe their numbers really. AMD is loosing GPU marketshare not gaining. 9 out of 10 people I ask or talk to uses Nvidia as well. We ship like 80/20 in Nvidias favor if not more (Enterprise/AI is more like 90-95/10-5 really.\n\nI hope RDNA4 can turn things around for AMD.\n\nAnd no I am not a fanboy. I just want comptetition again but if you think AMDs sells just as many GPUs as Nvidia - or even outsells them - you need to wake up from that dream.\n\nI think many AMD users just buys from Mindfactory. They are very AMD and always released their CPU/GPU sales with the public. If you look at [Caseking.de](https://Caseking.de), one of the biggest German retailers, and check their GPU popularity (most sold) it does not reflect Mindfactory at all either.",
      "This isn‚Äôt indicative of the rest of the world. Germany has more of a Radeon culture than the rest of the world because ATI/AMD have/had a bunch of major offices there iirc.\n\nI do find it interesting they‚Äôre still going for Radeon after the major increase in energy prices though. I‚Äôd have thought they‚Äôd go for either a 4060ti or a 4070 because of how much more energy efficient they are. The 4060ti in particular just sips power, I wish an AIB would come out with a half height or single slot version already."
    ]
  },
  {
    "brand": "amd",
    "generation": "7000",
    "tier": "high",
    "matched_keywords": [
      "7800"
    ],
    "title": "MSI not listed as launch partner for AMD Radeon RX 7800/7700 XT graphics cards",
    "selftext": "",
    "comments": [
      "same for 7900xt/7900xtx. Busy selling SUPRIM for Nvidia. Also no Lightning models for years",
      "https://videocardz.com/newz/msi-preparing-twenty-geforce-rtx-40-gaming-slim-graphics-cards\n\nlol maybe this is why.",
      "Thats fine. Get a sapphire.",
      "Looks like xfx will be making a 7800xt.  I'll more than likely go with them, I 've had really good luck with their gpus.",
      "MSI has never made good AMD cards anyway. They put all their efforts into Nvidia designs.",
      "They follow suit with asus to save production costs since the 40 series coolers were overdesigned for a tdp that will never be reached under gaming loads so they make \"slim\" aka cost cut version coolers now",
      "They have a gaming trio classic model for the 7900 xtx no?",
      "It was the same when the 7900 series launched: https://videocardz.com/newz/msi-to-launch-custom-amd-radeon-rx-7900-graphics-cards-in-q1-2023",
      "Shit temps, crappy quality and lower PL than a reference model.\n\n\nMSI should just stop making AMD GPUs.",
      "7800 xt meh?! Beats a 4070 and is 500$.  Not a rich guy and am actually pretty broke but am still picking one up because of how good a deal it is. I think your just delusional. Unless you mixed up 7700 xt and 7800 xt. Cause 7700 xt isn‚Äôt a good deal.",
      "I don't think they were complaining. \n\nIt's well known in the industry that Nvidia withholds details about their power limits from manufacturers until the last minute, and in the meantime the AIB's are stuck designing coolers for the absolute maximum TDP they think a generation can ever reasonably expect to hit. That's why the 4080s and 4090s were pretty much universally overbuilt, everyone built them to be able to reasonably dissipate the heat from a 600w load. \n\nRealistically, the 30-series coolers would have been adequate for the 40 series. \n\nThe size bloat is Nvidia's fault. They determined power limits too late in the development cycle, even their own FE cooler is overkill for what these GPUs can be expected to do.\n\nNone of this is a slam on any of the AIB's or even Nvidia, it's just the way it is, and it bloated both size and production costs. We would hope that Nvidia would learn from this and finalize their engineering earlier in the development but the 4090 was an unprecedented success and all their efforts are going into AI now so we consumers will just get what we get going forward.",
      "And the 7900 xt that i have.  Superb no issue at all.",
      "For AMD Asus is just utter shit.",
      "Sapphire and PowerColor are sitting together quietly snickering about MSI during lunch in the cafeteria.",
      "MSI AMD GPU just get released a bit later. My MSI Gaming Classic Trio 7900 XT  was release about 3 months after the MBA one.",
      "what ? i buy MSI since my HD 7950, R9 390,  RX 5700 XT and now 7900 xt and all these card worked well and still work well,  i upgrade each 3-4 years.\n\nMy MSI Gaming R9 390 still working perfectly after 8 years. >\\_>\n\nSome model had a bit of a failure design a launch like the MSI 5700 XT Evoke, but the cooler and thermal pad issue was fix after the launch batch, and it's not complicate to RMA with MSI when these thing happen.  \n\n\nBref I never got a bad AMD GPU from MSI.",
      "You mean RTX3090 cooler for AMD?",
      "Which they discontinued, offering replacements to all \"affected\" customers not long after launch:\n\n[https://www.techpowerup.com/260696/xfx-revises-rx-5700-xt-thicc-ii-cooler-offers-replacements-to-current-owners](https://www.techpowerup.com/260696/xfx-revises-rx-5700-xt-thicc-ii-cooler-offers-replacements-to-current-owners)\n\nNot relevant information at all honestly... One bad release does not make them a bad option. They've been perfectly good cards for many, many years.\n\nI'd still go with something like a hellhound though since they're much nicer looking imo.",
      "What ![gif](emote|free_emotes_pack|dizzy_face)",
      "At least we got Biostar! lol."
    ]
  },
  {
    "brand": "amd",
    "generation": "7000",
    "tier": "high",
    "matched_keywords": [
      "7800xt"
    ],
    "title": "ASUS launches Radeon RX 7700XT/7800XT DUAL graphics cards - VideoCardz.com",
    "selftext": "",
    "comments": [
      "Guess they took notice how many ppl actually buy these GPUs and want a piece of the cake aswell.\n\nLet's just hope they actually do a proper design and not just reuse the nvidia components and kind of make them fit like MSI did with the 6XXX series 'custom' designs.\n\nKind of sad we don't have anyone doing full two slot only variants of these cards by now.",
      "It's actually funny how TUF was supposed to be the budget option in the beginning and as soon as people started actually buying it they cranked up the prices to Premium and charged even more premium for ROG.",
      "More like their TUF cards were way too expensive and they realised they had to find a way to make a cheaper card without affecting the reputation of ASUS cards (that being more expensive=better)",
      "Still a flipping 3 slot design :(",
      "Can someone ELI5 what a dual card is? Are they combining two GPUs into one?",
      "I thought the same thing, but if you read the article, ‚ÄúDual‚Äù is just the name of the two fan card design. It's an ‚Äúupdated‚Äù design specifically for the 7700,800XT with a $100 premium over the TUF models. TUF models have higher clocks so it's dumb.",
      "Dual fan",
      "Okay, just another model to skip. Sapphire, powercolor, xfx, or bust",
      "if you are in budget then 100% sapphire pulse, not this thing",
      "No it's not. Powercolor Hellhound Spectral, Asrock Steel Legend, Sapphire Pure all exist and usually aren't that much more than MSRP. Even ASUS has a white TUF",
      "everytime i read dual i expect a 2 graphics core crossfire design but then i realized companies arent fun anymore so meh",
      "TUF was initially introduced with the Sabertooth Z87 motherboard and even then it was meant to be a semi-premium model.\n\nOn GPUs TUF basically replaced the \"GAMING\" line which sat just below STRIX and above the base model cards.",
      "Well that‚Äôs good, cos the ASUS TUF Gaming 5700 XT had terrible cooling",
      "Dual was always ASUS budget branding for GPU?",
      "It's down to 399$ now , i say that's pretty good unless you wanna buy used cards",
      "It has two fans.",
      "TUF was competing with MSI Military branding. It was meant to be the \"Middle-tier, high durability/better warranty\" bracket.",
      "After [ASUS blamed AMD for their trash design](https://www.youtube.com/watch?v=H7lnBCFnBok), they can shove these cards up their a\\*\\*.\n\nASUS is not the legendary 90's company they once were.",
      "Don't buy AMD Gpu's from ASUS they just use the leftovers coolers from Nvidia\n\nBuy Sapphire, PowerColor or XFX they are much better and cheaper",
      "Yeah if that's in stock"
    ]
  },
  {
    "brand": "amd",
    "generation": "7000",
    "tier": "high",
    "matched_keywords": [
      "7800xt"
    ],
    "title": "Should I buy 4060ti or rx 7800xt ?",
    "selftext": "So I'm finally planning to upgrade from my 1060 3gb to either of these.\n\nI know 4060ti is equivalent to 7700xt and I should rather consider 4070s BUT \n\nIT IS ( 4070) $100 MORE THAN 7800xt.\n\nSo Recommend accordingly please.\n\nI plan to use the pc for : \n\n- Content creation, edits and Projects ( Softwares like After Effects, Premiere, Blender, etc). So will be rendering stuff frequently.\n\n- Gaming on max 1080p 75hz, don't care about 2k , it's fine if it's just playable on that resolution ahahaha. Only Care about actually playing the game to be up to date. That's it!\n\nBudget is $500\n\nThanx all.",
    "comments": [
      "The 7800XT is over 35% faster in games, if the apps you use need cuda then Nvidia, but anything else, amd.",
      "Bruh the 7800xt it‚Äôs stronger and better Nivida is just there to gank yo money. I‚Äôm a video editor and have a 7800xt and a R9 paried together it‚Äôs smooth as butter",
      "Can you wait less than a month? Nvidia is expected to release the RTX 5060 and RTX 5060ti within the month of April 2025. I do not know the price range, but I expect the pricing for both would be between 330 and 500 dollars and the trend for the RTX 5060ti 16 GB would likely move toward the 600 price point immediately after release.",
      "There is no question.¬†¬†\n\n\nIf you just Gane 7800xt\n\n\nIf you need to do work, 4070 or 4060ti.",
      "7800xt no doubt is better in games",
      "So a 7800xt shouldn't be a problem, but it's pretty overkill for 1080p 75hz, save some money and get a 7700xt",
      "This is a wild take. 5080 is the 3rd fastest GPU in the world right now. 5080 or faster ? Seriously?",
      "What power supply?",
      "Who said 4060 ti is equal to 7700xt? 7700xt is 30% faster than 8 gb 4060 ti, go see benchmarks",
      "I feel like if you're looking at a 4060ti and have a newer CPU then the Intel b580 is way better value than a 4060ti lol. \n\nIt's not the strongest card, but has very good overclocking room, is cheap and has 12gb of VRAM. 4060ti just seems nonsencial at the price range mentioned",
      "You can't afford a decent Rendering Gpu, but you can afford it to wait a few minutes longer with an Amd gpu, and you get more value for your money",
      "Nice take, true tho",
      "7800XT will do the job just fine.\n\nPaying more than 250 bucks for a shitty nerfed 3060Ti makes no sense. Might as well buy a used 3060Ti/70 then.",
      "I love my 7800xt, its huge tho but every modern game you get 2k60fps",
      "Both cards will easily handle any game at 1080",
      "Browse around on subreddits for the applications you're going to use or might use in the future. Read recommendations from the software itself, and look for experiences others are having with AMD and which cards they're using. AMD GPU's have issues or simply perform poorly with SOME productivity applications, and other times they're perfectly fine.\n\nAsking in mostly gaming enthusiast subs aren't going to get the answers you're looking for.",
      "OP look into how nvenc/nvdec will help you in content creation.\n\nPrices are coming down fast atm for the 50 series. Just get a 5070 at this point.",
      "7800xt no question",
      "7800 XT it's not even close",
      "Can future proof yourself with a 9070xt"
    ]
  },
  {
    "brand": "amd",
    "generation": "7000",
    "tier": "high",
    "matched_keywords": [
      "7800"
    ],
    "title": "Amazon Deal: AMD RX 7800 XT 16GB, 6750 XT 12GB prices puts Nvidia RTX 4070, 4060 to shame",
    "selftext": "",
    "comments": [
      "They're talking about the 4070 non super...Did you even read the article?",
      "So where in the UK is this price updated?",
      "Here is the breakdown if you compare a $480 7800XT against a $600 4070 Super:\n\n* 4070 Super +25% more expensive\n* 4070 Super [+14-38% faster in RT](https://www.techpowerup.com/review/nvidia-geforce-rtx-4070-super-founders-edition/35.html)\n* 4070 Super [+8% faster in aggregate gaming benchmarks](https://www.techpowerup.com/review/nvidia-geforce-rtx-4070-super-founders-edition/32.html)\n* 4070 Super [significantly faster in these common compute tasks](https://www.techpowerup.com/review/nvidia-geforce-rtx-4070-super-founders-edition/37.html)\n\n\n\nI guess it's not that clear cut. One is a better product, and there is a 25% premium for it.",
      "Should be comparing the 7900 GRE for $550, most people forget it exists lol",
      "If you don't care about upscaling, yeah. I love the 7800xt and if DLSS isn't a factor for you it blows the 4070 super out of the water in value but it needs to be mentioned.",
      "The 6800/6800XT late adopters were the real winners if you have to make a fuss about a $480 7800XT years later.",
      "It depends, to be fair. If it's a cheap 2 vent card, then the heat and noise will destroy any positives. I know that.\n\n\n7900 gre has pretty cool stuff with not much price that is very efficient. And that makes them more attractive.\n\n\nRT stuff isn't a clear winner here, btw. 12gb hurts 4070s a lot, since you have to sacrifice something to get a decent performance.¬†\n\n\nIn short. The only clear advantage is production in CUDA specific apps (there are lots of them though). If that's important - 4070s is better. Everything else is not worth the premium here",
      "> So even if I believe you (I dont)\n\nNobody cares, you literally have a nonexistent CPU in your flair, touch grass",
      "That one compares less favorably. The 4070 Super is clearly the better buy there IMO. [Deadheat in aggregate gaming](https://www.techpowerup.com/review/sapphire-radeon-rx-7900-gre-pulse/32.html), 4070S retains its clear RT/compute/feature advantage while drawing 40-60w less at just $40-50 more.",
      "Yeah, sure, but your post isn't relative to what they're discussing...So yeah.",
      "True gAmErS render at native resolutions",
      "Calling it an article is a reach. They're generating revenue from what is essentially an ad. I was providing more context/performance figures.  Though TIL the non super is still being sold, I thought it was discontinued.",
      "You turn DLSS off now? With your 6900XT?",
      "Shame? This \"article\" is a joke. It's just a click-through affiliate ad for $15-20 of a 9-month-old GPU that wasn't even a meaningful upgrade from its predecessor. The laziness of using Nvidia's poor pricing to excuse AMD's poor pricing is so tiresome.",
      "The 4070S will shortly become the new 3070. Limited by its VRAM. There are currently plenty of games that use over 12Gb at 1440P. Give it another year or two and people will be saying 12GB isn‚Äôt enough for 1440P.",
      "my whole household runs AMD (Vega 56, RX 5700XT, RX 6700, plus a few laptop APUs and my Steam deck) and there are no issues or complaints.\n\nThe only thing that I will give you is cutting edge architectures can have some bugs, but that's normal for early adopters and not exclusive to AMD.",
      "Hows your 9800x3d running? xD",
      "XeSS is pretty good tbh. Better than FSR2.1 (or whatever it's at now) anyways. It'd be nice if FSR 3.1 would make it into more games already.",
      "The driver thing is a red herring.  I honestly don't know why Nvidia has been given a pass on driver issues when they've had plenty over the years. I can name quite a few I've personally experienced, even up to today. AMD drivers have been fine for a while. *Shrug*",
      "Its only my personal experience, but this has not been the case at all for me."
    ]
  },
  {
    "brand": "amd",
    "generation": "7000",
    "tier": "high",
    "matched_keywords": [
      "7900 gre"
    ],
    "title": "Radeon RX 7900 GRE, Now With Memory Overclocking!",
    "selftext": "",
    "comments": [
      "I hope retailer won't try to advertise these potential overclocking performance and price them higher.\n\nOverclocking is always a lottery, just because this gpu have more than usual potential upside, doesn't mean it is a guaranteed result, you could have bought one and a mere 50hz will push it over the edge.",
      "I fear people will OC their card to be unstable then continue to blame bad drivers when infact it's user error flamed by inflated expectations.",
      "Not necessarily. 10fps from 10 to 20 is double (~~200%~~ 100% increase). 10 fps from 50 to 60 is a 20% increase. Using fps as a metric for performance improvement is terrible. Edit: corrected a snafu",
      "The GDDR6 ICs on 7900 GRE cards are rated for 20Gbps, regardless if provided by Samsung or SKHynix.",
      "I'm not sure I like this kind of messaging. Memory¬†overclocking is much trickier to get right and the chips on the card are rated for 18gbps, not 20 like with the other 7900 cards. the fact that they managed to get it to around 20gbps should not be taken for granted.\n\n\n\nI feel like a good amount of people are going to try and replicate other people's results and when those fail at some point, blame the card or the drivers.¬†\n\n\nWe probably see that happening already with so many recommending undervolting the cards expecting to replicate others' results without first realizing that just because the value sets and it doesn't crash immediately, you won't get some sort of issue later on.¬†\n\n\nRunning a card out of spec can have many different ways to fail, you could see more issues with frame pacing, you could see driver resets, you could see texture or polygon flicker, you could see artifacts, sudden crashes to the desktop without an error message and all of them could be random at a random time. It doesn't even need to be at load to manifest itself.¬†\n\n\nPeople used to be way more aware of the consequences of overclocking and undervolting. I don't know if it's just me getting older and crankier or if it is actually an issue.",
      "A cool feature Adrenaline comes with is that 1 click overclock button. You just go intro adrenalin, find the gpu and click overclock, and it sets by itself. This gpu was already good enough, you get 10% on average more performance for 10% more money, than the 7800xt. Now.. if you are able to overclock it and get let's say 15% not 10%, it's even better value, let alone 20%. IDK how to translate +10 fps into % performance, but i guess it's somewhere between 0% and 10%? Anyway, if it's true, this is a good value gpu right now.",
      "Have a Sapphire Pulse model. Techpowerup says that it has hynix VRAM than can go up to 2500MHz (20 Gbps), sadly anything above 2400MHz on \"fast timing\" almost instantly crashes either the driver or PC itself. The GPU itself can haull ass at 2830 ish MHz sustained at 0.95V and 280W TBP. Stays cool and quiet at 71¬∞C",
      "Interesting conclusion. I checked my local microcenter and they have these for $550, and new 7900 XT for $719 to $749, however, you can get a refurbed one w/ warranty for $650. So for $100 more, you're getting better performance and 4 GB of ram.",
      "yes, that's why i said i don't know how to translate into % performance, but also i didn't watch the video, maybe he translates it. Overall a good card for the price, now it's further away from the 7800xt and closer to 7900xt in performance, which is nice.",
      "Sadly, all GPUs locally sold get priced according to benchmarks. If a 4080 does better than a 4090, the 4080 gets a price bump.\n\nEssentially, bang for buck has disappeared completely. \n\nYou either manage to get a promotion code or some kind of sale, or you are fucked paying benchmark prices and not MSRP",
      "I stand corrected, then. Maybe I misunderstood what the video said then.",
      ">  blame bad drivers\n\nAMD when 7900 xtx stutters on a 3770k: Bad Drivers\n\nNvidia when it black screens on DSC, has gamma issues on YouTube, and artifacting on chromium/hardware acceleration:  Zzz",
      "thats my problem, literally all the youtubers this week on 7900 GRE mindlessy drag the power limit to 15% FOR NO REASON!!. \n\nA stock setting is 19k points in timespy. 15K points Horizon Zero benchmark\n\nA 100mv undervolt, 2550 mhz memory, 2600 core clock, 15 power limit is 24.9k points in timespy, but with fans at 3100 RPM (lol) to maintain 72-75Celsius, 308W - This is what youtube shows everybody. 18k points Hoirzon Zero\n\nA simple -100mv, memory to 2500, NO POWER LIMIT adjustment from stock, no GPU core adjustment, is 23.8k points in Timespy, and 17k points in Horizon, with fans needing only 1900-2000 RPM to keep it at 71Celsius. This baffles me  as this is obviously what youtubers should show, The card beeing at 260-270W cool and quiet for almost MAX results everywhere, instead of a fans blowing 308W loud card with just a bit of extra thats not worth it..\n\nHence my question, was i safe to just use the third option i listed, with just undervolt..\n\nThanks for replying.",
      "I think Steve was rather unclear in the video. He did say the memory was rated at 18.5. \n\nBut at least for Samsung they've already discontinued their slower GDDR6 and 20/24Gbps is the only stuff available now.\n\nSamsung 18Gbps SKU marked as discontinued: https://semiconductor.samsung.com/dram/gddr/gddr6/k4zaf325bm-hc18/",
      "I had something similar with my Powercolor Hellhound 7900 GRE. Fast timing limited the memory OC to 2375MHz, but I can do 2625MHz with default timings.\n\nThis is very different from my experience with the 7900 XTX. That card only lost ~50MHz of max memory clock by enabling fast timings.\n\nTry with default timings and see if that helps. The fast timing option is only worth using if the clockspeed hit is small. Small being ~50-100MHz.",
      "If I recall you can't really have both Fast Timings **and** SAM working well together at the same time. It's too unstable.\n\nI think it was : if you really want to use Fast Timings you should de-activate Above-4G decoding first (therefore goodbye SAM)\n\nBut it seems SAM is more beneficial to have, so just forget about Fast Timings and when you go overclock your VRAM, do it with the default timings as u/jedi95 recommends.\n\nThis way you should be able to push that VRAM overclock enjoying greater stablility.\n\nSource : a random UV+OC video guide on YT, but I can't find the link anymore, sorry lol. \\^\\^",
      "They're widely available in Europe, at least. Many models in stock at various sellers. https://geizhals.eu/?fs=7900+GRE\nI just ordered and built a PC with a Sapphire Pulse model for a friend two weeks ago.",
      "Yes, but¬†since you provided a guess I provided more info for any potential reader.",
      "yep, thank you kind stranger. Let's just say hardware unboxed uses the 7800x3d on all resolutions for testing, and the 10% fps is the average, from which 4k resolution massively cuts it down i suppose? In that case this could mean a lot more % fps in 1440p.. don't mind me i'll just watch the video tonight and make some sense out of it lmao",
      "Anytime i try to oc the vram i always get artifact or it will black screen. Gpu cores i can oc easily vram is a different story. I got the asrock steel legend 7900gre yesterday"
    ]
  },
  {
    "brand": "amd",
    "generation": "7000",
    "tier": "high",
    "matched_keywords": [
      "7800xt"
    ],
    "title": "First PC Build. Full AMD 7700X | 7800XT",
    "selftext": "",
    "comments": [
      "I like those fans",
      "Love the look.  Nice and clean!  Reminds me of Tron: Legacy.  Batman?  Oh!  He got In!",
      "Case?",
      "Straight bussines.",
      "Looks good and the hardware is really well balanced. It'll play high fps 1080p and 1440p for years to come. Montech cases are also great for the money. \n\nWhat fans are those?",
      "Montech Sky Two",
      "Being able to pick up a 7700X, motherboard, and 32gb ram for $400 is insane value. I still love the deal I got a year ago for $500.",
      "Imo, the 7700X is the most underrated CPU of all time. That is if Microcenter is available to you. Mine is 5 min away. It is literally a 13900k without the E cores, which are not needed for gaming for 1/3 of the price.",
      "Very far away for gaming? Nope. 13600k chokes in BF2042 due to only 6 cores that are used for gaming and struggles in most online gamesü§£  \n\ndon't get too glued to CPU benchmarks with nothing going on that are meant for GPU testing. Online multi-player is a whole different animal, and the 13600k with just 6 gaming cores is a disaster. Heck, even ps5 and the new Xbox use 8 cpu cores for gaming.",
      ">They are on a lot of r/buildmeapc builds and\n\nThis cliffhanger is killing me.",
      "Whay type of games u playing with that setup??",
      ">What fans are those?\n\nNot OP, but [Montech](https://www.montechpc.com/en/products_item.php?cid3=64#link2-64)\n                \n[Stock case fans](https://www.montechpc.com/en/products_detail.php?nid=314&s_ok2=)",
      "$400 Microcenter bundle. Basically got a cpu/mobo/ram for just over the price of the 7800x3d alone. Can always pop the last x3d AM5 chip that comes out in later and boom, another several years of gaming ahead.",
      "All fans came with the case (Montech Sky Two). Front and rear are preinstalled. Front and bottom are reverse fans and function as intake.",
      "Yes. And then put the money you saved from that combo for a better GPU.",
      "Really nice build! My only comment would be that i would have got a different model of the 7800XT (not the biggest fan of Gigabyte GPUs) but a really solid build regardless.",
      "looks amazing",
      "Gorgeous",
      "Hot",
      "Just built in the same case. All my reverse fans were grey which i don‚Äôt love. I ordered another one from newegg and it showed it was a grey reverse fan but it ended up being black. Not sure why they have a mix of these but they should leave them all black."
    ]
  },
  {
    "brand": "amd",
    "generation": "7000",
    "tier": "high",
    "matched_keywords": [
      "7800xt"
    ],
    "title": "Team Red build: 9800X3D + 7800XT Red Devil",
    "selftext": "",
    "comments": [
      "If you're playing CPU heavy games it's not overkill",
      "youve so many insanely expensive parts and gpu that seems totally out of place, are you planning on upgrading it? is this a new build thats temporarily using old gpu youve already had?",
      "It's really a Ship of Theseus build I've been piecing together for about a year and a half now. It started as a pre-built and I've saved up for fancy pieces here and there but the pre-build I started with didn't have a discrete card, so the GPU was the first thing I bought. Then the power supply, then the case, and finally bit the bullet on the CPU, mobo and RAM during some cyber Monday deals and using the hotstock app to find the 9800X3D.\n\nI do plan to upgrade the GPU to a 9070XT that is white in the future, it was just at the time I needed a graphics card and the 7800XT fit my budget at the time.\n\nI was able to use my leftover parts to build a nice little secondary gaming PC for my teenager so all in all nothing really went to waste except for some uneducated purchases I made for my build (RAM and Mobo)",
      "Because they probably had the gpu already and just upgraded the cpu?\nNot everyone just buys everything in one go all the time.",
      "Powercolor make the prettiest GPUs. Love their designs",
      "Hate to be that guy to nit-pick what is a lovely build but it looks like you got your ram in the wrong slots for dual channel. The left stick should be moved 1 dimm to the left so there is a 1 dimm gap between them. You're running in single channel mode atm and losing performance. [https://dlcdnets.asus.com/pub/ASUS/mb/SocketAM5/ROG\\_STRIX\\_X870-A\\_GAMING\\_WIFI/E25346\\_ROG\\_STRIX\\_X870-A\\_GAMING\\_WIFI\\_EM\\_V2\\_WEB.pdf?model=ROG%20STRIX%20X870-A%20GAMING%20WIFI](https://dlcdnets.asus.com/pub/ASUS/mb/SocketAM5/ROG_STRIX_X870-A_GAMING_WIFI/E25346_ROG_STRIX_X870-A_GAMING_WIFI_EM_V2_WEB.pdf?model=ROG%20STRIX%20X870-A%20GAMING%20WIFI) page 18",
      "What is your full spec?",
      "Case: Hyte Y70\n\nMotherboard: Asus ROG X870-A\n\nCPU: Ryzen 7 9800X3D\n\nGPU: Powercolor 7800XT Red Devil\n\nPSU: EVGA 850W\n\nRAM: Corsair Dominator 2x16gb 7200mhz\n\nCPU Cooler: Asus ROG Strix LCII 360\n\nFans: A combination of Corsair QX 140mm for the rear exhaust and 3 120mm for the front intake, and 3 Arctic 120mm fans in the bottom feeding the GPU\n\n\nAfter putting things together I wish I would have done more research on the RAM, since it only supports XMP and not DOCP.\n\nAlso regret investing in the Corsair QX fans as well. The iCue software is messy and the proprietary fan hub takes up one of my USB headers on the board, which I needed for the Liquid Cooler RGB.",
      "Yeah it's actually a cpu that can run tarkov. Which is surprising (considering it's tarkov)",
      "Thank you so much for this! I wasn't aware of the separate channels and seeing the page in your link it makes total sense now. I'll be swapping that around! I appreciate the tip.",
      "I hate this argument for simulation/grand strategy games this CPU is more important than any GPU, hell give me a bad video card over a bad CPU, I can tolerate bad graphics.",
      "I bought them a little over a year apart so that would have been a little difficult.",
      "This. Can confirm staggered upgrades are a thing.",
      "most x3d chips do fine in tarkov, even the old 5700x3d\n\nplaying SPT, which is way more CPU intensive than regular Tarkov, on my 7600x3d gets me consistent 100-140 fps on any map that isnt streets",
      "Lovely!",
      "Thank you for taking the time to do this. If your first photo is with fsr off I‚Äôm already seeing a large difference but I have to update my driver to the same as yours and do it again. Big thanks again!",
      "Got the Hellhound Sakura version of this card for a while build, but pretty sure they're out of production and the Devil one is one of the best alternatives for sure :)\n\nHave fun eith the system, especially with such a great processor, my budget only allowed for a r7 7700 after the card...",
      "OP please run the free Monster Hunter Wilds benchmark and post your results; I am dying to find out how a powerful CPU will benefit from Capcom‚Äôs cpu intensive graphics engine. I have the same GPU but have a 7600x.",
      "You could've get a better GPU, 9800x3d is above that GPU",
      "Hey OP ‚Äî /r/AMD is in manual approval mode, this means **all submissions are automatically removed and must first be approved before they are visible to others**. This is done to prevent spam, scams, excessive self-promotion and other rule-breaking posts.\n\nYour post will be approved, provided it follows the subreddit [rules](https://www.reddit.com/r/Amd/about/rules/).\n\n**Posts regarding purchase advice, PC build questions or technical support will not be approved.** If you are looking for purchasing advice, have a PC build question or technical support problem, please visit the [Q1 2025, PC Build Questions, Purchase Advice and Technical Support Megathread](https://www.reddit.com/r/Amd/comments/1hqs820/pc_build_questions_purchase_advice_and_technical/).\n\n\n*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/Amd) if you have any questions or concerns.*"
    ]
  },
  {
    "brand": "amd",
    "generation": "7000",
    "tier": "high",
    "matched_keywords": [
      "7800xt"
    ],
    "title": "7800xt is out of stock everywhere I've looked. Any guess on how long it'll take for stock to come back?",
    "selftext": "I've never bought a GPU at launch before so just wondering if this is a normal thing that takes a few days or weeks or months to resolve.\n\nI'm in Canada, every vendor on PCPartPicker says it's out of stock, and I've manually checked:\n\n* Newegg\n* Canada Computers\n* Vuugo\n* Amazon.ca",
    "comments": [
      "next week man dont worry, it was just like the 7900 XTX situation, restocks weekly",
      "That's a good choice buddy, sapphire nitro us top quality.",
      "I've ordered mine in France yesterday (7800 XT Nitro+), the shop says it's still in stock, but it hasn't been shipped.\n\nKinda weird.",
      "It took them like 3\\~4 hours to sell out, so I'd say it wasn't a paper launch at all. A paper launch would mean the cards sell out in 5 seconds from bots.",
      "Not really when the 6000 series is pretty much gone.",
      "Yes, it's quite normal in my expirience here in Canada. If you want, you can check also on AMD site : [https://shop-ca-en.amd.com/graphics-cards/](https://shop-ca-en.amd.com/graphics-cards/)",
      "No it is not, all big reviewers (aka not tech Jesus cause he only did like 7 games) put it squarely in between the 6900xt and 6800xt in terms of performance.\n\nhttps://www.techpowerup.com/review/amd-radeon-rx-7800-xt/32.html",
      "Yeah, I'm taking their models everytime when I can, since the HD5870 Vapor-X OC !\n\nPrevious card was a 6700XT Pulse, it was ok.",
      "It‚Äôs has to cross through the forest.",
      "At first yes, but i dont think the momentum will continue, people who were waiting and didnt grab the 6700 XT/6800 XT are the ones who are grabbing those, after all the wait, they got similar products at the same discounted 6000 prices.",
      "Literally cheaper for most models everywhere outside of the US. UK is basically the same price and the 7800 is lower power draw and far more likely to have longer legs being rdna3",
      "Yep, as usual the US got most of them and everyone bought it.",
      "Would be a long ride from Vancouver",
      "I bought my card 20 minutes after they went live at 6am yesterday. By noon, newegg canada was sold out. It's out for delivery already, def not a paper launch.",
      "6950XT is 629 euro here üò´\n\nGood deal?",
      "I was honestly disappointed with GN‚Äôs review. Thought it felt rushed and less meticulous as previous reviews. Hell, even Daniel Owen tested it in more games than GN.",
      "It's the other way around. Some review outlets tested overclocked AIB 6800 XT's, which is leading to the discrepancy.\n\nTechpowerup had the 7800 XT faster in pretty mucb everything except Dying Light 2.",
      "He is telling him to biu the older, less power efficient gpu when the op is asking when he can get the 7800 xt. That's like me asking people when will the 4070 be in stock and someone answering me to get the 3070.",
      "Croatia just ASRock cards from 650‚Ç¨ 7800, Sapphire, xfx 0.. day 1 ü§£",
      "and no where to be found after months of wait similar to what happened during the mining craze."
    ]
  },
  {
    "brand": "amd",
    "generation": "7000",
    "tier": "high",
    "matched_keywords": [
      "7800"
    ],
    "title": "AMD Announces Radeon RX 7800 XT & Radeon RX 7700 XT: Enthusiast-Class RDNA3 For 1440p Gaming",
    "selftext": "",
    "comments": [
      "Everything is \"enthusiast\" nowadays.",
      "$500 flat for the 7800 XT is pretty good, that's a 9% discount on the 6800 XT's current price along with some RDNA3 improvements and lower power consumption.\n\n$450 for the 7700 XT is bad. That's around the price of a 6800, but with less VRAM. Plus you can find 6800s for $430, which is the maximum this card should have been. AMD probably saw how bad the 4060s were and got a little too confident.",
      "On AMD's own slides the 7800XT is 20% faster than a 7700XT for 11% more. There is definitely something weird going on like yields are really good, so they are making many more 7800XT and don't really want to sell 7700XT???",
      "Its probably both cards cost a similar amt to make, like the 7900xt/xtx, and they want to push folks into the more expensive SKU. In a few months, the 7700xt will be down to 399.",
      "Honestly? Wait for benchmarks, you stand to benefit by waiting until Sept 6th and seeing how the 7800xt stacks up against your current card and the existing lineup.",
      "Glad I jumped on a 6700XT + Starfield Premium for $255 (open box from MC).",
      "7700xt = DOA, just like 7900xt at launch",
      "I would wait for the 7800XT same performance, lower power more features, and the same price",
      "Or they want to finish selling 6000 series stock.",
      "There seems a very large gap in price between 7800xt and 7900xt. Any chance 7900xt will drop a little in price?",
      "Lol enthusiast 70 class card for $450 that competes in the 60 class segment that's really a 50 class segment.\n\nIt's 2023 and you get to pay $450 for a \"7700xt\" that competes against a \"4060ti\" which is really a 4050ti but Nvidia *also* shifted their product stack.\n\nPeople really do fall for this shit.",
      "People have been brainwashed to consider mediocre products good after travesties such as 7900 XT or even worse, the absolute potato 4060 Ti.\n\nIf 4070 was a 4060 Ti sold at 499$ - which it should have been - anything more than 449$ would have been outrageous for this 7800 XT which should have been 7700 XT or at most 7800 to begin with.\n\nBut with Ada being mildly (4070) to very underwhelming (4060 Ti), 6800 XT performance for 499$ and newer tech sounds very compelling out of nothing - **because in the current market, it is.**\n\nBesides, AMD has a (recent) history of not actually competing with nVIDIA at launch in terms of MSRP, so the fact that they have at least read the room this time makes this launch better than it actually is.",
      ">$450 for the 7700 XT is bad.\n\n7700xt is clearly there to upsell 7800xt and would likely be disounted later like 7900xt was.\n\nHonestly 7800xt seems like an amazing 1440p card  after their FSR3 presentation that will last years. Both need independant testing though.",
      "The whole point is to upsell 7800xt, yes, to be discounted later. Atleast 7800xt looks amazing unlike 7900xtx for its price as long as FSR3 lives up to DF expectations.",
      "I don't think it's \"falling for\" anything as much as it is making the best out of a shit sandwich.",
      "I can see it continuing to come down just like were seeing for other higher end cards. But not by big leaps. I bet we see a few $699 deals pop up around black Friday.",
      "I do wish there was a way for Steam to seperate desktops and laptops, I suspect a good number if not the majority of those 1650s are laptops.",
      "Because 7000 series supports Anti-lag+ and driver-level Frame Generation. It has AI cores that would be needed for future iterations of FSR and therefore those cards would last longer than 6000 series despite their similar raster performance right now.\n\nThat's objective. 'Upscaling looks horrible' and 'Fake Frames are not real frames' are subjective.",
      "sucks for the countries that don't get AMD discounts though.",
      "It's terrible.  Why is the 7700XT so expensiveüò≠ I hope half a month goes by and the price drops to at least 400‚Ç¨... My RX580 is about to die, I can't wait anymore, I want to play starfield..."
    ]
  },
  {
    "brand": "amd",
    "generation": "7000",
    "tier": "high",
    "matched_keywords": [
      "7800"
    ],
    "title": "Sapphire Nitro+ RX 7800 XT INITIAL REVIEW",
    "selftext": "The big boy is finally in. Upgraded from the MSI Mech RX 6500 XT and let me tell you‚Ä¶ it‚Äôs not even funny how powerful this thing is in comparison. I mainly play MW2 and wanted to upgrade the whole system for the new COD this year. This card has tackled every graphical setting I could try while maintaining 200+ FPS. (1080p) CAM software doesn‚Äôt show GPU stats anymore but with the dual bios that‚Äôs not necessary anyway. Stress tests all maxed out at 65 degrees on silent bios. Noise was fairly loud on the performance bios preset and adrenalin fan tuning doesn‚Äôt seem to make a difference so I went with the silent bios preset, haven‚Äôt had any issues so far. Exactly what I was looking for and I only imagine performance improves from here with FSR 3 and the advance of RDNA 3 drivers. Have high hopes for this card!! (yes that‚Äôs a deodorant cap being used as gpu support LOL)\n\nSystem Specs :\ni5-13600KF\nGigabyte B760M DS3H AX (MATX)\nRX 7800 XT Nitro+\n32GB G-Skill Ripjaws DDR5 6400\nSamsung 980 Pro 1TB + 500GB Hard Drive + 128GB Sata Drive\nThermalright Peerless Assassin + same fans in case\nToughpower GF3 1000W ATX 3.0\nDLM22 MATX Case",
    "comments": [
      "I have the same card, it's a beast.\n\nLest us know if you get Green Screen of Death",
      "I went from the Ryzen 3600 and Radeon 6700XT to Ryzen 7900X and Radeon 7900XTX. \n\nFeels like a whole new world, it's nice appreciating games the way the developers wanted me to see them.",
      "You need more than one power cable attached to that graphics card.",
      "green screen of death?",
      "Green screens are just black screens but on monitors running YCbCr instead of RGB.\n\nMystery solved lol",
      "Computer crashes and display a green screen.\n\nOwners don't know the solution to this issue yet. You can get a look by looking for green screen and AMD cards on Google, or get to /r/AMDHelp/",
      "YES",
      "I went from Ryzen 1600 and GeForce 970 to 7800X3D and a 7900 XTX. So good",
      "i7 965 (yes really) and GT 1030 (yes really) to a 7950X and 7900 XTX.\n\nI feel like I went from an abacus to the processing power of Skynet.",
      "Oh so it's a known problem? The Nitro+ I bought at the beginning of the month got one a week ago and I was pretty confused about it since it happened while the GPU was under very light load in Google Chrome. The audio was also stuck in a repeating loop while it happened.\n\nBesides that I had only one driver crash in Snowrunner which was also weird since there hasn't been any prior instability.\n\nOther than these two cases the card has been great.",
      "LMAO, why would you do that?",
      "Easiest way to make performance with one setting is increase power limit to max 15%. That alone got me close to 1000 points for graphics on timespy benchmark. There's about another 1000 easily on the table with lowering your voltages 5% which most if not every 7900xtx can do(my pulse original is 1150mv and I lowered mine to 1100mv) then by tweaking the max and min frequency. What I did was do the auto overclock and I comes up with a mhz it will overclock to. Mine came up at 3105mhz so I set my max to 3100mhz and min 2200mhz. I also overclock the vram to 2664mhz I'm stable higher but don't get the scores ü§∑‚Äç‚ôÇÔ∏è probably memory stretching...",
      "Great card indeed! Smashes everything on my UW with low temps and noise. My only concern is the fiddly support bracket that comes with it. Does not seem to work well with my meshify 2 compact. Might just be me and my sausage fingers though.",
      "To be in compliance with the ATX power specs, you need one harness for each 8 pin connection on your GPU.",
      "KF boosts higher. Overclocking is dead and makes no difference so may as well get a CPU that can both get ample power from the board, while also reaching its full boost clocks. \n\nThe need for Z series motherboards is over, B series has everything you need.",
      "Your answer is... Acceptable",
      "Bet you didn't smash your glass side panel by accident like me after installing a new gpu.",
      "Nice build! Mine is very similar! Got the watercolor 7800XT red devil with ryzen 7700x. I was also surprised about the size of this card ü§£",
      "Wait this is an issue. I‚Äôve had mine since mid-late September and I haven‚Äôt seen it.  Well to be clear I haven‚Äôt seen it on my main rig. I run VMs on my main machine and on the VMs I‚Äôve gotten green screened but I chalked it up to the Windows canary build being buggy not my GPU.",
      "Haven't run into the green screen of death yet, after 1 1/2 month with my nitro rx 7800 xt."
    ]
  },
  {
    "brand": "amd",
    "generation": "7000",
    "tier": "high",
    "matched_keywords": [
      "7800"
    ],
    "title": "Absolutely loving my 40th bday build. 7900 xtx and 7800 x3d. Specs inside!",
    "selftext": "Xfx 7900 xtx\n\n\n7800x3d\n\n\n4tb ssd, 4tb hdd\n\n\n32gb ram 6000 mhz\n\n\n850w gigabyte psu gold",
    "comments": [
      "Happy birthday man, hope you have a great time slaying some games on that beast.",
      "Nice to see some air-cooling, good temp?",
      "Thanks v much!",
      "Yep cpu usually sits about 60 degrees in games. Under stress test I've seen 74c.\n\nGpu sits around 55 to 65 in all games. At 450w it can go up to 70 ish.",
      "Us old timers keep the air cooled market alive.  Also, with age, you learn a full 360 liquid cooling setup is a complete waste of money and epic levels of overkill on 90% of setups. \n\nBut that's what this hobby is about much of the time, right?  Chasing the latest,greatest and often times, unnecessary.",
      "Nah not necessarily. Lots of good games out there. Been playing hell let loose this week. Been a blast!",
      "Happy Birthday OP. And respect for the aircooler (so much less hassle in the long run and more than powerful enough to handle the 7800X 3D).",
      "Nice! \nHappy cake day bro üëçüèª",
      "Thankyou! Yep temps are absolutely fine. I don't like the idea of water inside a pc...but then I'm 40 so I have reason to be old fashioned.",
      "Yeah I'm the same - peace of mind feels like higher FPS. :P\n\nThe Peerless Assassin is a pretty legendary cooler. Thermalright makes some great stuff.\n\nOh, and Happy Cake Day too.",
      "7900xtx and rocking Metroid. Respect it.",
      "Enjoy your bday build, I too have the 7900 xtx and 7800x3d bundle‚Ä¶great choice",
      "I don‚Äôt use AIOs to have the latest and greatest, I use them because I think the giant air towers look dumb.",
      "That's cool too!  To each their own.  I absolutely despise rgb, different strokes.\n\nMy point was, if you get into this as a passion/hobby.....we often buy things we do not necessarily *need*.\n\nI had zero business dropping 900 bucks on a 7900xtx, or real need to, my 3080 was great (rip EVGA).  But I did.\n\nI have ZERO reason to even be thinking about getting a 4090, but I am.\n\nI will literally build fantasy carts on NewEgg, mini itx builds....all AMD or Intel builds, APU console-like builds.\n\nI almost bought an entire all Intel build with a 14600k and an Arc A770 yesterday, FOR NO REASON!  I don't *need* that. \n\nI just think the Arc series are so interesting. \n\nThat's all I was saying, thats the way we enthusiasts are.  We get the hardware bugüòú. I wasn't trying to imply people who buy AIO liquid cooling do so for unsavory reasons",
      "Yeah I just don't see the point anyway because temps are perfectly fine with this ¬£30 peerless assassin cooler. Having an aio would not only cost more but the risk, in my brain, of failure and leaking just would make me uneasy.",
      "Nice",
      "Boys doesnt get older, their toys become more expensive.",
      "5900x / 7900xtx RD here. I upgraded from a 3080 10gb & love it.",
      "Randomly on AMD reddit... I dont have AMD, recommended post thing caught my eye... just wanted to say, nice tower! I just did a rebuild and have the same one!",
      "The real question is, what are you playing? I have a very similar setup"
    ]
  },
  {
    "brand": "amd",
    "generation": "7000",
    "tier": "high",
    "matched_keywords": [
      "7800"
    ],
    "title": "AMD Radeon RX 7700 XT and 7800 XT will go up against Nvidia‚Äôs 4070 and 4060 Ti",
    "selftext": "",
    "comments": [
      "They should have named 7700 and 7800 as per specs .\n\n7900GRE should have been 7800xt .",
      "Yeah, the naming scheme is not helping here",
      "To be fair, who cares what the model numbers are. It's the price/performance comparison that's the real deal.",
      ">The 7700XT is dumpsterfire trash \\[...\\] should have been $399\n\nIf just a 11% discount would make the product acceptable I don't know if we can call it dumpsterfire trash.",
      "The 7800XT is a good enough product if these performance claims hold.\n\nThe 7700XT is dumpsterfire trash though only existing to upsell you to the 7800XT. One would have thought AMD learned their lesson with the 7900XT. The 7700XT Really should have been $399",
      "Well *actually,* the 5700XT was the top RDNA1 card, there the so-called \"6900XT\" was really the 6700XT\n\nOh wait, inter-generational numbering conventions have always been aspirational at best and have never really been very consistent.\n\nJust let it go and talk about the price and the performance.",
      "7900XTX ‚Üí 7900XT\n\n7900XT ‚Üí 7800XT\r  \n7900GRE ‚Üí 7800\r  \n7800XT ‚Üí 7700XT\r  \n7700XT ‚Üí 7700\r  \nThis is better, IMO. Would've been similar to 6000 series then.",
      "Because paying ‚Ç¨35 more for a bit worse raster but much better RT, upscalers, potentially frame gen (though FSR3 does seem potentially almost as good), and ~80W less power draw is honestly a no brainer.",
      ">The 7700XT is dumpsterfire trash \n\nIt's overpriced by about $30-40.  that's all that's wrong with it.  Calm the heck down.",
      "The 6800 XT competed with the 3080 for $650. Its successor is the 7900 XTX, which competes with the 4080 for $1,000. Nvidia's preposterous pricing is what keep's AMD afloat in the \"value\" discussion.\n\nThe 7800 XT is \"only\" $500, but it's realistically replacing the 6700 XT that was $480.",
      "This was always going to happen. The 7900 XTX is a 4080 competitor. AMD liked to tout that they didn't raise prices between generations, but they pushed their product names up a tier and skipped a 6900 XT successor.\n\nIt's why I hate AMD's pricing and naming this generation. On value, AMD loses at every tier. In value, RX 7000 loses to RX 6000 at every tier, since 7000 uses the price and name of a higher tier than it should.",
      "Yeah, that's how generational improvement used to work. You got more at a faster pace than before. You'd expect the 6800 XT's successor to be a higher-powered card for the same money. Instead, it's a similar-powered card for less money.\n\nEven then, it's generous to consider. It's around the same price the 6800 XT is selling for now. Where we'd expect a new GPU roughly a year after launch, the 7800 XT is launching almost 3 years after the 6800 XT. So, it's on-par with a 3-year-old card that's been on sale for about the same price as the 7800 XT.",
      "The only argument for pricing that makes sense is that their costs on the 7700 XT are high",
      "Perhaps they don't have many partially defective Navi32 die for 7700XT.",
      "I am saving to buy me a pretty sapphire 7900 xtx, these lower specs gpu just don't cut it for me",
      "In Germany the rtx 4070 can be had for 585 euro. AMD must drop the 7800 price from its ‚Ç¨550 retail if they want it to succeed.",
      "It makes no sense, the 6800XT was 650$, the 6800 580$ and the 6700XT 480$.\n\nAssuming we go by price the GRE should have been called 7800XT and the 7800XT should have been called either the 7800 or 7700XT.",
      "Im curious to see how well the 7800 xt compares to 6950 xt so I can either cry or laugh üòÉ",
      "What makes it matter is a lot of consumers just don't know enough. They check in every 3-5 years, look at the numbers on the box, then make a choice.\n\nThis lets AMD slide their cards' branding up a tier. People will see \"$1,000 7900 XTX vs. $1,600 4090\" and not realize they're buying a 4080 competitor. They'll see a 7800 XT and not realize it's a 4070 competitor that's not much better than the 6800 XT. They won't realize they're buying a 7700 XT with a different name.",
      "**They don't!** And for the most part, AMD have had naming conventions that were wildly different from Nvidia's. There's nothing wrong with that.\n\nBut AMD ***chose*** to align their product numbers, pricing, and performance (for the most part) to Nvidia's for both the RX 5000 and 6000 series. The problem is that AMD *mostly* did the same for the RX 7000 series, but completely threw it in the bin at the high end. It's a way for AMD to pull the wool over anyone who doesn't pay enough attention. Why else would AMD announce a SKU above the 7900 XT in a generation where they don't hold the lead?\n\nIt's just a matter of setting a precedent then going against it arbitrarily. It confuses uninformed customers. That's all."
    ]
  },
  {
    "brand": "amd",
    "generation": "7000",
    "tier": "top",
    "matched_keywords": [
      "7900 xtx"
    ],
    "title": "RX 7900 XTX is rapidly going out of stock across major retailers following the RTX 50 series launch",
    "selftext": "",
    "comments": [
      "I'm just joking, but sometimes it seems like nothing sells Radeon GPUs like disappointing Nvidia GPUs.\n\nStill hoping AMD can move into Radeon GPUs selling primarily because they are good and an excellent value at launch. Going back through the decades I've owned the ATi 9800 Pro, Radeon 7870 Ghz Edition, and Radeon 390X, because they were great values and excellent performers at the time. Vega 64 was my last Radeon GPU and it was disappointing value compared against the 1080 and 1080 Ti. I would buy Radeon again easily if the performance/price ratio was good *at launch*.",
      "I thought the 7900xtx was decent at launch, I bought when 7800x3d came out and built my PC then.",
      "While I am sure the lackluster launch for the 5xxx series has helped sales, a big part of the stock issues could also be AMD letting stock fall off as they have a new launch coming up.",
      "Prices have jumped I think too. I was looking at a 7900 xtx nitro+ for ¬£800 last month that in the last week jumped to just over ¬£1000",
      "Yeah, the 7900 XTX is a great card, it did have some driver issues at launch in some games that were fixed later, but compared to the $1,200 4080 it was a good choice. \n\nOf course, people wanted it to be cheaper than it was, but I think the main issue was the 7900 XT being too expensive at $900.",
      "It's truly a perfect storm for AMD. And with nvidia being grilled for their paper launch maybe just maybe AMD did the right thing delaying 9000 series launch.",
      "Is it even manufactured anymore? The card is 2+ years old.",
      "Can you guys please try not to buy up all the rx 9070s instantly thanks",
      "I think they had ehtt of 9070 volume. I think they just didn't know how to market the cards in the face of Nvidia just bold face lying about performance.",
      "Probably caused more by DeepSeek? I recall reading that it seems to use the 7900XTX really well and gets within a few percentage points of the 4090, sometimes even above it.",
      "AMD generally manufactures cards for longer right? They don't stop production the way NVIDIA does once a new generation arrives. Most of their sales comes from the increased value of their discounted older cards.",
      "If I remember correctly, VR games ran like absolute dogshit on the 7900 XTX at launch.\n\nNow thats been resolved, I think the 7900 XTX has an edge over the 4080 and 5080 in this category cause DLSS seems to impact image quality too much and 24 GB VRAM > Ray Tracing.",
      "AMD hasn't stopped production of the card. It's been out of stock many times and the stock keeps coming back. \n\nNo news of AMD halting production of the card either. He'll there are still some 6000 series cards being made.",
      "I'm so glad I got my Nitro 7900XTX in December! Especially here in the USA where the cost of all consumer goods is about to go up.\n\nMany argued it was a dumb move with the new cards launching this year, but with supply issues and scalping it could be quite a while before that kind of value is available on a high-end card again.",
      "its a good gpu, launch was a bit of disaster but overall nothing wrong with it.",
      "It was the second best gpu for the entire 40 series betting the 4080 and 4080s while consitently being $200-300 cheaper. I waited for the 7800x3d launch to get a new pc with a 7900xtx aswell cause it was pretty obvious to anyone keeping up with the pc part trends for a while(13 years for me) that the next generation was gonna be lackluster and 40/7000 series was a great time to get a pc.",
      "I have no doubt this played a role. Waiting lets them stabilize stock however, with maturing drivers sounds like a great reason and then add this to the mix.",
      "Ok cool so in 99/100 situations it's the second best cardüëç",
      "Launch day reviews tend to stick around forever.\n\nAMD decided that ironing out major issues before launch is more important than beating NVIDIA out the door.",
      "Not really a positive news tbh\n\nRadeon can't be the product that \"if Nvidia doesn't do that well much in the new gen, might as well buy radeon's best previous gen\"\n\nIt needs to get out of the door day one\n\nWatching the recent Threat Interactive video, and I agree with what the man said, AMD's GPU division lacks vision compared to Nvidia and they are a hardware manufacturer first"
    ]
  },
  {
    "brand": "amd",
    "generation": "7000",
    "tier": "top",
    "matched_keywords": [
      "7900xtx"
    ],
    "title": "I think AMD made a mistake abandoning the very top end for this generation, the XFX 7900XTX Merc 310 is the top selling gaming SKU up in Amazon right now.",
    "selftext": "[https://www.amazon.com/Best-Sellers-Computer-Graphics-Cards/zgbs/pc/284822](https://www.amazon.com/Best-Sellers-Computer-Graphics-Cards/zgbs/pc/284822)\n\nThis happened a LOT in 2024, the US market loved this SKU.\n\nSure there is a 3060 SKU on top but these are stable diffusion cards and not really used for gaming, the 4060 is #5.\n\nEDIT Here is an image timestamp of when I made this post, the Merc line has 13K reviews more than the other Nvidia cards in the top 8 combined.\n\n[https://i.ibb.co/Dg8s6Htc/Screenshot-2025-02-10-at-7-13-09-AM.png](https://i.ibb.co/Dg8s6Htc/Screenshot-2025-02-10-at-7-13-09-AM.png)\n\nand it is #1 right now\n\n[https://i.ibb.co/ZzgzqC10/Screenshot-2025-02-11-at-11-59-32-AM.png](https://i.ibb.co/ZzgzqC10/Screenshot-2025-02-11-at-11-59-32-AM.png)",
    "comments": [
      "It's the best selling gaming SKU because it's one of the cheapest 7900XTXs and the RTX 5080 is both unobtainium and the best advertising for the 7900XTX since it launched.\n\nPeople holding off on an upgrade who waited for the 5080 are sorely disappointed so probably buying the 7900XTX because they can't get 4080s.",
      "There was also people looking to upgrade to latest highest performance AMD GPU. e.g. me\n\nGiven the 9070 won't outperform the XTX, you may as well buy the XTX instead of waiting how long for them to release a 9080/9090",
      "The product didn't perform as expect.\n\nAMD didn't intentionally ceded the top end of the market.",
      "adjoining sheet engine enter like piquant selective cable bag soup\n\n *This post was mass deleted and anonymized with [Redact](https://redact.dev/home)*",
      "I don't think there's a meaningful argument to make about this right now. Much of the RTX 4000 lineup has gone out of production to make the RTX 5000 stuff, which is on the same node. Between that, allocation of silicon to datacenter cards, and the general lack of availability of RTX 5000 right now, there's not a lot of stuff to sell. Even the 7900 XTX can be hard to find.\n\nWe don't even know what it would take for AMD to make a higher-tier card this generation. Would it take 3 times the silicon (like with the 5090 vs. 5080)? Could it match a 5080? 4090? 5090?\n\nMuch of RDNA 3 was, in my opinion, a mediocre bunch of products. Pricing and time to market was a bug part of why. The XTX is selling now because Nvidia has nothing you can buy and it's come down 15% or more from its launch price. It's not like the XTX has been a sales monster for the past 2+ years.",
      "This running into technical issues with the design wasn't them throwing in the towel on purpose. There would be no point launching something that wasn't going to meet performance targets.",
      "sink one humor elderly long theory arrest deer physical direction\n\n *This post was mass deleted and anonymized with [Redact](https://redact.dev/home)*",
      "Can‚Äôt find 4080s or 4090s to buy right now, also 3060s are very much used for gaming lol.",
      "This is exactly me right now, I want to make a new build and I want the best AMD has to offer, on one hand I love the 7900XTX, on the other I can‚Äôt wait to see what RDNA4 has to offer. Problem is if the 9070XT is somewhere in the 7800XT ballpark, then I don‚Äôt know what to do :(",
      "The conspiracy and misinformation mill is churning in full force in these comments man.\n\n\"XTX was the best selling GPU of the generation,\" yeah okay that explains why it's...practically absent from every steam survey since 2023? But sure sure, steam survey is just bought and paid for by Nvidia right",
      "Because obviously you need a 4080 to do all that AI image generation, play nothing but cyberpunk with path tracing, and use heavy CUDA workloads constantly. /s (like every Nvidia user seems to be)",
      "From what little I have heard of RDNA4, it is going to look very alien compared to even RDNA3.\n\nCUs appear to be larger individually based on die size leaks. N48 is \\~30% larger than the N31 GCD for 67% the CUs, and while yeah, GDDR6X PHYs are large, they aren't that big.\n\nComparing to N32, which has the same bus size and only 4 fewer CUs, its GCD is about half the size rumored of N48. N48 is similar in size to GB203, likely a touch larger, so 5080-like silicon costs given both are 4nm.\n\nRDNA2 to RDNA3 by comparison isn't a large jump in the actual CU design from what I can tell after probing around on my 7900XTX and 6700 10GB cards, or my 780M and 680M machines. Most of the changes appear to be in dual-issue support, WMMA support, and some little RT tweaks. Caches also look like they got some changes to handle the extra interconnect delays maybe. RDNA3 looks like RDNA2 on steroids from my perspective, while RDNA4 looks like it may be more like a RDNA1-2 style shift.\n\nIIRC FSR4 relies on FP8, which RDNA3 does not natively do, or at least does not do well. If RDNA4 has dedicated high-throughput low-precision hardware, such as a big block of FP8 hardware in each CU or WGP, then that gets you both die size increases and functionally exclusive FSR4 functionality. Of course brute-force compute is also an option. Maybe there is some threshold amount of BF16 grunt that RDNA3 can put up for at least the halo cards to be technically compatible, (7900 family being a nice cutoff) but maybe not.",
      "It helps that every other relevant GPU is out of stock... :D",
      "There's literally no GPUs for sale.  It's easy to be number 1 in a field where there's nothing else competing.",
      "From leaked info they had no choice as the top SKU was also meant to be MCM and not monolithic but the design failed to work properly and needed a lot of time/resources to solve so they allegedly decided to just refocus on next generation and it MCM.\n\nTrying to salvage it with just larger monolithic design likely would end up Nvidia-like in pricing due to costs of large dies.",
      "Exactly why I pulled the trigger on an XTX as soon as they said no high end. I know it was likely the XTX would stomp whatever came next so I bought it for ¬£700 almost a year ago.",
      "Just take the L dude\n\nYou can‚Äôt buy a 4080, 4090, 5080 or 5090 off Amazon without going to a scam seller\n\nAMD has product available. They‚Äôre going to rank high for sales as they‚Äôre literally the only thing available.",
      "It also *isn't* the best selling of the generation. Idk where y'all are getting that from. Hardware surveys all show RTX 4000 series having a much more prominent userbase across the board.",
      "Piggybacking top comment here..\nThe 7900xt and xtx both have¬†issues running more than one display.¬†\nIdle power goes from 20w to 100w for the card alone.¬†\n\n\nIf love to think this is fixed, buggy can't find any info aside from people discussing the issue still exists.¬†\n\n\nFor my use case and energy cost is an extra $80 per year.\nIf that card is going to be active in my household for 5 years (my use Phys have be down) that's an extra $400.... That I might as well spend on an otherwise over priced NVIDIA card and pick up better RT.\n\n\nIf AMD would fix this I'd be dropping coin on a 7900xt or very very seriously considering a 7900xtx.\n\n\nPeople deserve to know about this.¬†\nLots of us are using a spare old monitor for a second display now.",
      "Knowing AMD and nvidia they eventually give the new tech to the older generations aswell. I highly doubt raytracing will see much improvement on the 7900XTX but I bet it'll see FSR4 eventually.\n\nEdit: read the comments below me!!\n\nTldr: 6000 probably wont see fsr4 and even 7900 might only profit from it slightly more due to the (speculated) fp8 limitations."
    ]
  },
  {
    "brand": "amd",
    "generation": "7000",
    "tier": "top",
    "matched_keywords": [
      "7900 xt"
    ],
    "title": "New first party performance numbers for the 7900 XT",
    "selftext": "",
    "comments": [
      "This makes it clear that the 7900 XT is a full tier down from the XTX and there's no point in saving 10% in price when you lose 20% in performance.",
      "that was clear when you looked at the specs, it confirms it tho. it's gimped af and only exists to upsell the XTX",
      "I don't know a card that doesn't need at least a 100 dollar price drop.",
      "Everyone jumped on the \"XTX\" being \"value\", **forgetting the crappy price bump of the 6800 XT's replacement of literally** ***250$***.\n\nBut it's easy to do so when you look at the abominations called RTX 4080 12GB/16GB.\n\nRemember, names mean nothing, it's all about the specs from a generational comparison point of view and if you look at them, 7900 XT is even more castrated than 6800 XT was compared to the flagship counterpart.\n\nAMD pulled off a much more elegant/less outrageous \"4080 12GB\" with the \"XT\" and \"XTX\" conventions.",
      "RX 7900XTX performance increase to RX 6950XT \n\nRE Village - 53%\n\nCOD MW 2 - 51%\n\nCP2077- 67%\n\nWD Legion - 47%",
      "Can we speculate that the 7800xt will be only as good as a 6950xt, if not worse? Then it is time to get $515 6800xt. No need to wait any more.",
      "I think this is a new chart? Let me know if it's old news.",
      "Agreed it also need a price drop of $100",
      "Geomean: 1.545x (335W 6950XT performance)\n\nFyi, in the footnotes, AMD also clarified that at 300W the 7900XTX was 54% faster than the 6900XT.",
      "AMD doing Nvidia tactic.\n\nMake 7900xtx / 4090 look like the better value option compared to 7900xt and 4080.\n\nPotato potato.",
      "Back in my day! 500$ bought u a nasa quality gpu! :)",
      "7900XT should be $800. AMD is using the classic upselling strategy.",
      "That's practically a given at this point.",
      "If I see strong post release review numbers for performance I‚Äôm buying an 7900XTX for sure. But this graph shows pretty decisively that the 7900XT needs to be cheaper than it is to make it in any way worth buying instead of the XTX.",
      "The 7900XT should really be 7800XT at $799 ideally .\n\nBecause otherwise you will have another 7800XT that is barely faster than 6950XT and that doesn't makes any sense .",
      "This was pretty obvious from the moment the XTX performance was announced.\n\nI'm pretty sure RDNA2 already offers similar value to RDNA3 on the lower-end stack **with the current discounted prices applied**.",
      "Like the 6800 (non XT) this GPU will hardly sell and no one would buy it (and rightly so) at it's price point.\nFortunately AMD will probably drop it's price sooner or later.",
      "And we would have gotten away with it too, if it wasn't for those meddling Nvidias and their 780 Ti",
      "It's to make the 7900 XTX a \"no brainer\" upgrade. It's an upselling tactic. If it's called 7800XT then it doesn't make sense to have that $899.",
      "Why not just call them 7800 XT and 7900 XT. And leave room for a XTX or 7950 XT which uses dual GPU dies?"
    ]
  },
  {
    "brand": "amd",
    "generation": "7000",
    "tier": "top",
    "matched_keywords": [
      "7900 xt"
    ],
    "title": "AMD Radeon RX 9070 XT GPU Review & Benchmarks vs. 5070 Ti, 5070, 7900 XT (Sapphire Pulse)",
    "selftext": "",
    "comments": [
      "HUB swears they'll honour MSRP, after informing with stores. I will get one tomorrow on launch. Finally saying goodbye to my 1070.",
      "Keep in mind that is for the base models. We don't have pricing yet on the majority of the cards. But the $600 reaper isn't going to cost the same as the hellhound.   \nOr for Gamers Nexus, they tested on the Sapphire pulse which is a $600 card. But how many of those will be available versus the Sapphire Nitro or Pure? And will that extra $100-$200 have decent gains? Probably not. Only the MSRP cards are worth the price. The others quickly lose value.",
      "Hilarious to see the 5070 already hitting VRAM limits.  Goes to show that AMD's bet on chiplets for GPU's wasn't that good of a bet on the last gen with the half priced 9070XT hitting 7900XTX speeds.  Hopefully it doesn't get scalped to hell",
      "I wonder what's going on with the numbers for FFXIV. Damn shame too, because that's one of the games I play most of the time.",
      "An XTX version of this would have been real compelling. Im very bummed they ditched the high end. Just not worth it coming from a 3090.",
      "Yes, the 7 fps 5070 got on Indiana jones with RT really is amazing/s",
      "A theoretical 96CU 24GB Radeon RX 9080 XT has a very good ring to it. If they made such a product it would be pretty close to a 4090 I think, and it‚Äôs a shame they did not.",
      "tbh the issue is reviewers for years told people \"VRAM doesn't matter\". Last several years VRAM requirements have jumped a lot and they definitely do matter especially with RT at higher resolutions",
      "You needed a review to see if the 2000$ card is better than the 599$ card?\n\nNo, you didn't but you just had to comment that shit",
      "tbh for that resolution and refresh rate you really need to look at 5090/4090.",
      "That reaper is looking real nice though.\n\nProper SFF capable but still 3 fan. \n\nWish XFX would put out a model like that",
      "4070ti super is one of the best value cards of these years.",
      "I have a GTX 1080\nIf price is right, it might be time.",
      "Eh..I need a 4k/120Hz card, with FSR 4 this seems to come close. Since I can't get a 5090 for $2k I will probably buy a 9070xt this gen and forget about it.",
      "So it looks like I didn't make a bad decision paying $700 for a 7900XT early last year",
      "you shouldn't go from the 4080 to anything unless you hate money lol",
      "I don't see anything \"clearing\" anything.It's a hit and miss.  Good job by amd but RT performance seems to be all over the place.",
      "PSA: you are allowed to turn down settings to hit your framerate targets.... especially these days where the difference between high and ultra is visually imperceptible and sometimes still finds 30% more FPS.",
      "VRAM is a tricky selling point since it matters only if you don't have enough of it, and at release the Nvidia cards have usually had just enough. But certainly we're at the point where 12GB is insufficient for 4K and may run into issues at other resolutions.",
      "Is it weird that I have a 7900XTX and still kinda want this? I won‚Äôt, because that‚Äôs stupid, but still."
    ]
  },
  {
    "brand": "amd",
    "generation": "7000",
    "tier": "top",
    "matched_keywords": [
      "7900xtx"
    ],
    "title": "if you catch the 7900XTX at a certain angle, you can see that the fin stack is painted red on the inside too",
    "selftext": "",
    "comments": [
      "It does look nice. Hopefully its performance doesn't disappoint",
      "As we all know these three painted rims increase performance by at least 30%",
      "3 stripes for *RDNA 3*",
      "I think it's finally time I part ways with Nvidia. This card is just so impressive. After spending 2 years with a 3080 I've come to the conclusion raytracing, cuda and reflex aren't necessary for me. And with a card this powerful, there will be no need for DLSS/FSR. In terms of price to performance, power usage, aesthetics, no stupid PSU cable adapter.. pretty much everything.. AMD wins this time around.",
      "Looking forward to AIB models. Thinking about going team Sapphire Pulse.",
      "As a matter of fact I build a whole new PC every 2 years, and sell my current one to friends at a very discounted price. It's just a hobby of mine, the expense is worth it in my opinion like with many other hobbies.",
      "And I‚Äôm sure your friends fucking love you",
      "No they did it wrong. RGB makes things faster. RRR doesn‚Äôt do shit except making you sound like a seal",
      "I have never had a reference card before but RDNA3 looks kinda cute.",
      "Common misconception. Red = fast, bozo.",
      "Do you really spend a grand on a new graphics card every single generation?",
      "Adidas picking up AMD after dropping Ye:",
      "Yea but it's red and red is hot.",
      "Been on 5600XT Pulse and it's been really great \\^^ Very quiet and good temps for years. If there is a 7600 or 7700 Pulse that'd be amazing.",
      "AMD is pretty damn good at making sexy cards.",
      "I haven't had issues with Radeon drivers since R300...",
      "> And then all board partners will make fat chungus cards and force me to Nvidia again\n\nYes because nvidias cards are so nice and slim",
      "I think a lot of people don't really understand this. For a lot of people building PCs is their hobby, their are plenty of people who spend much more than $3000 every 2 years or so on their hobbies.",
      "Hahaha, probably not! üòà But they are very thankful for the PC's!",
      "Yeah, your 30**60**ti, not your 3080. This is also the 7900xtx we're talking about, not the 7600xt or whatever it will be called."
    ]
  },
  {
    "brand": "amd",
    "generation": "7000",
    "tier": "top",
    "matched_keywords": [
      "7900xtx"
    ],
    "title": "Fixed the 7900xtx reference cooler",
    "selftext": "",
    "comments": [
      "Are you BMW engineer?",
      "Got my first bmw earlier this year and this comment hits so close to home. I‚Äôve never seen so much plastic tubing in my life",
      "I love this and hate this at the same time.",
      "There are 2 days that make a BMW owner happy. The day they buy one and the day they sell it to another sucker.",
      "My guy went crazy on the 7900 xtx's ass.",
      "In a week or 2 im posting results. So far i dry tested it to make sure nothing shorted (it pass)",
      "I elected to change spark plugs and head gasket on an 08 335i I had awhile back. \n\nI don‚Äôt know how those engineers fit all that shit in there but I will never work on a bmw again. Fuck that",
      "What's the difference between a cactus and a BMW? \n\nA cactus has its pricks on the outside.",
      "So how does it perform?",
      "But why not a single longer block instead of like 10 in a straight row with tubes? That really has to whisper l absolutely kill your flow rate.",
      "Flow is like 1ml/h.... Jokes aside why using so many tiny WB?\n\nAlso tubing can be heavily improved (distribution column).",
      "Holy pressure drop ü§£",
      "110$ for cpu block, 5$ each for the mini blocks, 25 blocks in total 125$ for mini‚Äôs",
      "Agreed, but this is the best i could think of. This gpu is extremely sensitive to temps change so im making sure everything gets overkill cooling.",
      "\"Learn how you can spend RTX 4090 money on a 7900 XTX with this one simple trick\"",
      "i would be too stressed out knowing that 1/1000 of those barbed fittings could pop off at any second, at least ziptie them on!",
      "God I hate/love, but mostly hate that N54 engine.",
      "Dude has ALL the chill",
      "Hi. Equipment tech here. This is a really cool thing!\n\nI feel like someone at least ought to remind you to be really vigilant about leaks in this thing. They're absolutely inevitable, and I don't mean that as a slight.\n\nIf they're in series like that the first clog anywhere is going to pop a tube upstream. If it never clogs, that's awesome. You should be aware that the tubing will EVENTUALLY harden and learn the shape of those barbs. At that point nothing short of a full tubing replacement will prevent leaks.\n\nIf I'm you I'm replacing all of this tubing yearly at a minimum. But maybe you're not even here for that long, what do I know.\n\nThis is a really cool thing. Good job.",
      "I had no indication where this joke was going."
    ]
  },
  {
    "brand": "amd",
    "generation": "7000",
    "tier": "top",
    "matched_keywords": [
      "7900xt"
    ],
    "title": "CES AMD billboard on 7900XT vs 4070 Ti",
    "selftext": "",
    "comments": [
      "That price tag is an insult to the gaming community. If we gamers won't stop buying these ridiculously expensive cards, AMD and Nvidia are gonna squeeze our wallets even harder.",
      "such sad marketing - \"under 900 dollars\" - jeeeez",
      "this dick waving over which company is gouging us least is really getting old.\n\nboth these cards should be $500.",
      "That‚Äôs why I look at my 1080ti and I‚Äôm like ‚Äúyou keep on doing a good job there‚Äù /pat /pat",
      "1070 Ti MSRP was $399. 4070Ti's double that.",
      "But our salaries did not double unfortunately",
      "M8 I got Vega 56 for 350 EUR on release day. This is the same tier of card‚Ä¶ 500 bucks was for 64 a god damn halo product, top of the line.",
      "The 4070ti is the fastest card under $800.\n\nGood luck finding one at MSRP though.",
      "Both are still too expensive by a couple hundred so, meh to that. We all know the xt launched to sell the xtx, but using the 4070ti here to sell cuz it‚Äôs bad and worse than the xt rather than lowering the price point like we all know they should is just greedy. I swear it‚Äôs like they planned this together",
      "Well, yeah. Business 101; if people are willing to pay $1,000 for X, listing it for $700 would be stupid.",
      "Inflation goes through the roof while working class salaries stagnate...",
      "GPU sales are at a 20 year low, with a 40% year on year reduction. AMD's market share somehow found another floor to fall through, giving Nvidia their highest control ever.\n\nI don't see how this is good business from AMD. It's so short-sighted. I have more hope for Intel GPUs than AMD at this point.",
      "After 4 years i expect to have a 400$ replacement for my 5700 XT with a least twice more performance. That how thing was since i started DYI PC and PC Gaming in 2002.\n\nNow for getting twice more performance, i need to pay 2.2x time more money today even after 4 years now.\n\nAnd Card at 400$... 4 years after. Still the same performance that my 5700 xt...\n\nI'm really ashamed of people that going to buy these cards.  You are not more worth than Cryptoboy/miner.\n\nGuess i am going to hold my 5700 XT until it die.  AMD really don't want my money.\n\n4 years. 0 Performance gain for 400$.   \n\n\nHello, its regression.",
      "dude same, \"keep chuggin fella\"",
      "Okay. This is literally a cherry picked selection of ‚Äúbest case scenario‚Äù games that RDNA 3 as an architecture performs better in. Once you use a wider selection of games, the numbers don‚Äôt add up, much like their ‚Äúup to 50% faster‚Äù benchmarks for the RX 7900 XTX.",
      "Jesus christ this is pathetic.",
      "Just wait til they go full Apple and start bricking old cards via software and driver updates üôÉ",
      "rtx 7900XTX 7900XT RTX 4090 4080 and 4070ti\n\nall of them cost more than 1000EURO is that normal?\n\ni mean it becomes worse and worse every year and less and less people can afford new GPUs\n\ni really hope karma will hit NVIDIA and AMD someday so hard that they will never recover.\n\nAlso keep buying those and posting your boxes it literally helps mid-end and low end soon we will pay 1000EURO for 5060 and 8700XTX and you gonna downvote everyone who will not agree.",
      "i hear ya mate. we're getting fucked.",
      "Take that dollar and buy a... ummm.... candy bar?"
    ]
  },
  {
    "brand": "amd",
    "generation": "7000",
    "tier": "top",
    "matched_keywords": [
      "7900 xtx"
    ],
    "title": "Alleged AMD Radeon RX 9070 XT nearly matches RX 7900 XTX in leaked Furmark 4K benchmark - VideoCardz.com",
    "selftext": "",
    "comments": [
      "Today's rumors are just all over the place.\n\nIt's a 4070... 7900 GRE... 7900 XTX...\n\nI think we just need to chill out and wait.",
      "Today is rdna4 leaks embargo\n\nAnd all of them range from \"we're so back\" to 'it's joever\"",
      "It has performance ranging from 5090 TI to a TI-84, has between 2 and 2 million shader cores, and costs are in between a used McDonalds wrapper and Bill Gates's Porsche 959. \n\nIt either causes blackouts when on or even generates power for you.\n\nRX 9070 XTXXX.",
      "All these \"it's joever\" leaks are from Geekbench and that's not realiable data, just look at their leaderboards and you'll see that according to them some 7900 XT SKUs are faster than 7900 XTX and 6650 XT is basically the same card as 6700 XT. These Geekbench leaks are really funny because we've got like 3-4 of them today and each one has numbers that are not even close (it's around 20% variance)",
      "I am so glad that you time traveled to tell us.",
      "The RX 9070 XTX can also teleport and exist in two places at the same time. I've seen it both inside and outside Schrodinger's box.",
      "These numbers do seem to lend creedance to the around 7900GRE/7900XT performance claim waaay back.¬† 1440p, where more people are gaming, would be more interesting to see.",
      "307W with literally no efficiency gain would still be 7900XT performance.",
      "please dont copy nvidia 5070ti =4080 =1000SRP",
      "On a single day you got leaks that are saying it's comparable to 7900 GRE and 7800XT, and then this one nearly matching 7900xtx lol, this is gonna be a long week ain't it",
      "you'll get $950 and you'll like it   \n\n\n/s ^^^pleasebe$600orless",
      "AMD needs to make it the 'only' option.\n\nThat means beating NVIDIA performance by 25%+ at the same price.\n\nI don't really like the way that HWU puts it as a 'discount' over just significantly better performance at the same cost.\n\nDoesn't really matter though as the end price is essentially the same.\n\nIf they have 7900XTX/4080/5070Ti performance for $500, it will be the only choice outside of specific work.",
      "What Nvidia cards? They are all out of stock.",
      "How dare you be reasonable and rational about all this!\n\nIn all seriousness I agree, not long to wait now",
      "The 6900 XT was fast as fuck when it came out vs. The 30 series. It isn't universally true.",
      "Yep, I expect it $50 below the 5070ti.\n\nProbably better availability after the launch window, though, and prices won't be so far over MSRP once you get a couple weeks in to March. That's my guess.\n\nIf FSR4 is comparable to CNN DLSS3, and can be plugged-in to FSR3 games via DLL swapping or whatever, it could get *some* traction even at $699.",
      "Counterpoint: Fuck Nvidia.",
      "If you have ever seen a launch ever. AMDs claims are almost always hyper inflated. The 9070 series will be underwhelming at best. You all know it will be. \n\nSincerely, \nA 7900xtx owner",
      "And in another it's basically matches 7800XT.\nWhich at this point means nothing.",
      "If they listen to Hardware Unboxed, they need to price the XT no higher than $500 or it's an immediate failure no matter what the performance is. \n\n(due to AMD needing market share and the mindshare of the average consumer only being flashing neon signs of the Nvidia logo)"
    ]
  },
  {
    "brand": "amd",
    "generation": "7000",
    "tier": "top",
    "matched_keywords": [
      "7900xtx"
    ],
    "title": "My New Rig (7900XTX Nitro +, 7900X3D)",
    "selftext": "Fractal North Mesh Black\nAsus ProArt X670e Creator \n7900X3D\nSapphire 7900XTX Nitro +\nG.Skill Trident Z5 Neo RGB x2 32GB \nLian Li Strimer Plus V2 \nSound BlasterX AE-5 Plus\nSeasonic Prime TX-1000 \nAlpenf√∂hn Gletscherwasser 360 AIO\nAlpenf√∂hn Wing Boost 3",
    "comments": [
      "I really like this, it looks like a cozy fireplace! Looks hot, runs cool (I hope)! When you were choosing motherboard and RAM for this did you go based on QVL or did you just wing it? I am picking parts right now for a 7800X3D build (if I can even get one) and the QVL seems lacking on a lot of motherboards.",
      "Wow...üò≥\n\nI will never get tired of that amazing case",
      "Definetly looked for AM5 compatible ram with EXPO. Did not check the QVL list. since the Ram I choose is a very, very popular one, there were alot of working examples. \nand yeah. it really does feel like a fireplace. temps are usually around 60 both GPU and CPU under full load which is really nice.",
      "Kinda looks like an oven from the side. Is it just me?",
      "I kept thinking how overrated this case was aesthetically... I now... have completly changed my mind LOL!",
      "[Fractal design north](https://www.fractal-design.com/products/cases/north/north/chalk-white/)",
      "I 100% agree",
      "That orange light reminds me of Nixie tubes, i like it !",
      "definetly not. it does have that cozy fireplace feeling haha",
      "Or literally anything that isn't the stupid \"gamer\" aesthetic.",
      "glad to have changed your mind because that case is simply amazing. you could definetly feel a difference how easy it was to assemble compared to other (cheaper) cases.",
      "What is the actual color code for the lights? Or was this a preset golden glow option?",
      "r/pcporn",
      "GSkill has some 6000 cl30 with EXPO. Works out of the box, no fiddling around. Some other brands have some with the same specs so I guess it's the same chips.\n\nBoard-wise I went with the NZXT board, since most good looking boards were expensive anyway. So I went with 650E directly.\n\nPlanted a 7700 non-X. Hope to switch to the final AM5 CPU when the socket's lifetime ends.",
      "It shouldn't become some gimmick but I can definitely see why this case became so popular, it's very well executed and the wood nicely accentuates the rest without becoming too dominant",
      "Many people forget there is five major cooling companies situated in Germany/Austria .\n\nOnly think of Noctua and Be Quiet.\n\n\nWhile there is Alphacool, Watercool and Alpenf√∂hn as well.\nAnd their stuff is just top notch standard and quality.",
      "Fractal has been making great non-gamer cases for ages now. I've been using the Define S since 2015. There are plenty of options from other brands too.",
      "Wouldn't an external USB DAC have been better for this kind of impedance? I went away from a soundcard because I got fan statics on my Yamaha monitors, with the DAC outside, no such issues",
      "mainly because I have 600 Ohm headphones.\nthe sound quality of this mobo is actually pretty decent",
      "funny story: the build was planned with TG panel.\nshop send the wrong case. didn't want to send back because the TG version wouldn't be in stock before June. so I just went with it and with the stuff I already had planned anyways. I am still very happy how it turned out.\n+ the mesh looks less see trough than it actually is in real life"
    ]
  },
  {
    "brand": "amd",
    "generation": "7000",
    "tier": "top",
    "matched_keywords": [
      "7900 xtx"
    ],
    "title": "LTT casually forgetting to benchmark the 7900 XTX",
    "selftext": "",
    "comments": [
      "Relevant content: LLT reviewed the 4080 Super and ignored AMD's direct competitor - 7900 XTX.",
      "They should've never released the video without 7900 XTX in the charts",
      "I usually give them the benefit of the doubt, but they have a team of engineers and spent a lot of time on this video, so not including it has to have been a conscious decision they made. The XTX comparison is, if anything even more relevant now with the Nvidia price cut",
      "Yea...\"forget\"",
      "Not surprised. People on this sub and others have now been going at amd claiming the xtx needs to be at least 800 to be competitive against a part that is still selling for about 200 more. Why? Would they buy the xtx? No probably not, they would just wait for nividia to drop and then purchase an nivida card.",
      "Imagine watching Linus for reviews",
      "LTT is shit? Nooo way.",
      "I don‚Äôt understand why they didn‚Äôt if you watch towards the end of the video they actually use one to briefly show amd‚Äôs ai assist which though Linus language was negative about if you watch the specs and add the fps boost on screen it gets a fairly large boost in fps. The omit was so obvious as they kept mentioning the xtx in the final moments but refused to show stats while pretending to be impartial.",
      "[https://youtu.be/UZ-hwlKmAPc?t=568](https://youtu.be/UZ-hwlKmAPc?t=568)\n\nThey even say it's a direct competitor (9:28 timestamp) so why not include it charts? They obviously tested it as they say it's \\~2% faster in rasterization and 30% slower in Ray Tracing.",
      "They also have multiple people who watch the video for errors and what not, this really isn't acceptable for how massive their team actually is. Like JayzTwoCents and his errors? He has 3 people. LTT has over 200.",
      "He‚Äôs gonna yap for 4 hours on his therapy podcast about why he doesn‚Äôt have to compare it to the xtx",
      "Incompetent? Yes.  \n\n\nNvidia shills? nope, chill the fuck down.  \n\n\nLTT and Nvidia are not on good terms.",
      "LTT is not good quality anymore. It is a money making machine. Like with the engineering sample from that small company that they gave away after completely trashing them in a review because they applied the product incorrectly.\n\nThis is unacceptable.",
      "AMD 7900xtx beats the 4080 super by 9% AND has 24gb of ram to the 4080s 16gb. No reason....?",
      "It would be first in the chart since they didn't include 4090 and we can't have that!\n\nEven though it's cheaper than 4080 Super and by a lot at least where I live, not to mention whole other price bracket than 4090.",
      "Look at the asterisk, it's historical data. I'm assuming they had problems with their 7900 XTX and couldn't get fresh data for the graphs. Of course this doesn't justify not trying to solve the problem and rushing out the video like they did, I'd have thought they had learned their lesson from the backlash last time\n\nEdit: Never mind, according to the WAN show this Saturday Linus and the writer of the video didn't think the XTX was relevant enough to be included in the testingü§¶",
      "Their graphs are so fucking bad, don't they have literal scientists and engineers working there? How hard is it to present data?",
      "Ahh shit, here we go again",
      "And the thing, too, is that Linus has bragged for over a year about how game changing the \"LAB\" is going to be. I have yet to see anything noteworthy from them. \n\nI mean Project Farm produces more meaningful product testing content and he does it from his garage attached to his house. Linus has over a million dollars worth of test equipment and can't even get a chart right. It's kind of embarrassing at this point.",
      "Looked at the Steam hardware survey yesterday (they asked me for my config) and the amount of NVidia Gpus i had to scroll through was insane.   \nThis is just too true."
    ]
  },
  {
    "brand": "amd",
    "generation": "7000",
    "tier": "top",
    "matched_keywords": [
      "7900 xtx"
    ],
    "title": "AMD's RX 7900 XTX is Faster than the RTX 4090 in Call of Duty: MW3 and Costs Half as Much",
    "selftext": "",
    "comments": [
      "If COD is your jam then AMD is your card.",
      "AMD wrecks Nvidia in all CoD games.\n\nAlso the 4090 is barely in stock anywhere with massively inflated prices.",
      "Yeah, that's not news. AMD cards have been faster at CoD games for a while.",
      "Nothing new. Was the same with [MW2](https://www.techspot.com/review/2561-cod-modern-warfare-2-benchmark/)",
      "Actually, even in that article, they show the 4090 is faster at 4k, so the title is inaccurate",
      "It's the same game, same graphic engine, so yes, not really a surprise",
      "DICE used to work close with AMD, not sure how it is now",
      "Also Call of duty mw3 is fucking garbage.",
      "No reason that we know of. My best guess is very specific optimization for AMD, since consoles run AMD hardware. CoD has it's own engine, so they could have done a lot of specific work.",
      "Isn‚Äôt the 4090 really popular with people who do AI?\n\nThe demand makes sense even at that price if people are using it to turn a profit.",
      "Yep, bf1 and bfv perform a lot better on amd, but with 2042, I think nvidia has a small advantage.",
      "How about Battlefield?",
      "Its hilarious how it's actually big news here that the 7900xtx is faster than the 4090 in one game.",
      "All the 4090 were shipped to China to try and beat embargo date, absolute pinnacle leather jacket moment.",
      "And in alan wake 2 4090 is 4 times faster than 7900xtxt . Its all good",
      "Yeah because DLSS is actually carrying in that title. Without upscaler theyre even afaik.",
      "this is like the article with the 4090 being 4x faster in Alan Wake 2 with path tracing. Yep, the cards are very good at the things they do well....",
      "The 7900XTX is not a 4090 competitor, it is a 4080 competitor (and still cheaper). So yes, it beating the 4090 is an interesting thing.",
      "Yes, but those people are also the reason why prices are insane. When your business operates on AI or when your job depends on it, normal price rationale kind of flies out the window.",
      "But the original comment was talking about the title and that is still inaccurate though?"
    ]
  },
  {
    "brand": "amd",
    "generation": "7000",
    "tier": "top",
    "matched_keywords": [
      "7900 xtx"
    ],
    "title": "AMD confirms RX 7900 XTX is RTX 4080 competitor, FSR3 may be supported by pre-RDNA3 architectures - VideoCardz.com",
    "selftext": "",
    "comments": [
      "AMD regarding competing against the 4090:\n\n>\\[Radeon RX 7900 XTX\\] is **designed to go against 4080 and we don‚Äôt have benchmarks numbers on 4080.** That‚Äôs the primary reason why you didnt see any NVIDIA compares. \\[‚Ä¶\\] **$999 card is not a 4090 competitor,** which costs 60% more, this is a 4080 competitor.\n\n‚Äî Frank Azor to PCWorld\n\n&#x200B;\n\nAMD regarding FSR3 :\n\n>\\[AMD FSR3\\] is not a reaction or a quick thing \\[to DLSS3\\], it is absolutely something we have been working on for a while. Why is it taking a little bit longer for it come out, that you‚Äôd probably hoped for? **The key thing to remember about FSR is the FSR philosophy and FSR until now did not just work on RDNA2 or RDNA1 they work on other generations of AMD graphics cards.** They also work on competitors graphics cards. It is exponentioally harder than if we just made it work on RDNA3. \\[‚Ä¶\\] **We really do want to work on more than just RDNA3.**\n\n‚Äî Frank Azor to PCWorld",
      "The price and the fact that they didn't even try to compare it to the 4090 in their presentation made this obvious.",
      "I hope the news regarding FSR3 doesn't get overshadowed because I think it's really exciting stuff. FSR2 has breathed new life to aging Radeon GPUs and strengthened current gen RDNA2's position, so FSR3 could really be a game changer. I wonder how this will affect sales of upcoming 7800 and 7600 tier cards.",
      "Although it was pretty obvious (based on MSRP) that either card wouldn't challenge Nvidia's RTX 4090, it's a bit surprising for AMD to admit (quite strongly) that it's not a competitor. Anyone think this news gives credence to a 3D v-cache iteration currently in the works?",
      "Thats not how marketing works. Do you really think AMD would put up a chart where the 7900 XTX loses every game (including getting trashed in RT)? You just dont do that, cheaper or not, everyone would focus on how \"bad\" the performance is and ignore the price.\n\nThey will definitely give us some new graphs once the 4080 is out and they have something to compare it to where it actually wins a bunch.",
      "Tell that to the goons who keep posting FPS charts showing the 7900XTX is going to be within 10% performance (or even better) than the 4090 for 600 less.",
      "Given their claimed performance vs the 6950 XT that's an accurate comparison, just like how saying it's gonna be 20-30% faster than a 4080 in raster while costing $200 less is also valid.",
      "They literally said it would be ‚Äúthe fastest GPU below $1000‚Äù during the announcement. This was all the confirmation anyone needed.",
      "fly disgusting unique violet hateful crush nippy wasteful pet rhythm -- mass edited with https://redact.dev/",
      "> [Radeon RX 7900 XTX] is designed to go against 4080 and we don‚Äôt have benchmarks numbers on 4080. That‚Äôs the primary reason why you didnt see any NVIDIA compares. [‚Ä¶] $999 card is not a 4090 competitor, which costs 60% more, this is a 4080 competitor.\n\nI'd think this is more a reasoning why they wouldn't show graphics against the 4090, rather than the 4080 really being the main competitor as if they were equals. Of course they aren't going to show graphics of them being beat by the 4090.",
      "I'm guessing most games will be closer to the 1.5x performance claim and very few games will reach 1.7x.",
      "FSR also works on my 1080ti, amazing AMD.\n\n\nI was one of the early adopters of the 5700XT and oh boi I had problems. \n\nBut now I'll get for sure a 7000 series",
      "For $999 I would argue the XTX does not compete with the 4080 or the 4090, same argument that was used for the 6800 not really being a competitor against the 3070.\n\nThe 6800 was just better, but also cost more & the 4080 is better a RT, has a bigger feature set & the 4090 is the best GPU on the market, a halo product of it's time.\n\nBut the 4090 is 60% more expensive.. At that price range if you're just playing games, you're arguably wasting money on a card like the 4090 because it exists to do more than game.\n\n^(EDIT: Although for 4K enthusiast, it is a compelling offer, but the price coupled with Display Port 1.4 support does hurt new 2023 4K monitor support.. Meaning you should probably wait for the 4090ti & buy it on sale or make concessions)\n\nAnd the 4080 costs $1200, probably $1300/1400 when AIBs and scalpers tach on their tax.. Where as AMD will likely do like last year and sell GPUs year round at MSRP.\n\nSo for $2/300-6/700$ more.. You have to ask yourself is Nvidia REALLY worth the extra premium on top?\n\nThis generation will be a defining moment for this community.. If compelling value can move the community to make different purchasing decisions, we will see a better PC market because of it.\n\nI'm still expecting 99% of people to just grab  Nvidia like they've always done since i've been following PC Gaming since the 2011-2012.",
      "Fsr works with nv and Intel already. Fsr 3 they *want* to work with more than just rdna3 but we will have to see if that's possible",
      "I for one couldn't care less about their lack of a 4090 competitor and, am pleased they were honest about it. Sure they'll release a 7950xtx at some point to go up against the 4080 ti/4090 ish, but I'm not in that area of the market.\n\nThe 4090 is absurdly priced. The 4080 is also stupidly priced and, is also a dumb value for money pick given how much better the 4090 is. The 7900xtx is perfect for those who may originally have been in the market for the 4080 but were put off due to obscene price gouging and ridiculous power consumption. \n\nI've always been team Green but they've messed up badly this time around. Sure the 4090 is an absolute behemoth of a card but it's just too frigging massive and power hungry. The pricing is exploitative at best and the 4080 12gb was an absolute farce.\n\nThe plan right now is, wait for the zen 4 3d cache cpus in apr/may 23, pull the trigger on a full amd rig and give the middle finger to nvidia. Fingers crossed they get burned financially and do better next time.",
      "I think showing yourself losing always would look bad regardless of price performance or being within 10%.",
      "There is no need to really position 7900 XTX as 4090's competitor even if eventually it comes close in raster. Simply by positioning the card as a 4080 competitor AMD can argue review outlets to rather make comparisons with the 4080 and hence able to get good wins in comparisons.",
      "different husky hospital nutty continue degree workable weary birds towering -- mass edited with https://redact.dev/",
      "For more educated buyers, showing a $999 card losing to a $1599 card by 10\\~15% margin is a win. I am not sure, however, all potential buyers see it that way, and AMD as most corporations take in mind the lowest common denominator.",
      "As long as it‚Äôs priced properly, who cares about the actual target competitor"
    ]
  },
  {
    "brand": "amd",
    "generation": "7000",
    "tier": "top",
    "matched_keywords": [
      "7900xtx"
    ],
    "title": "3DMark Fire Strike (Graphics) 7900XTX/XT scores",
    "selftext": "",
    "comments": [
      "Why not just put the videocardz link that has timespy scores too?\n\nhttps://videocardz.com/newz/first-amd-radeon-rx-7900-xtx-7900-xt-3dmark-timespy-firestrikes-scores-are-in",
      "Whats worse is if true the 7900XT is within spitting distance or almost the same as the 4080 for $100 cheaper than 7900XTX",
      "According to this the 6900xt beats the 3090ti and the 6800xt beats everything 3090 and lower.",
      "All these \"brackets\" are standing on the trampled bodies of broke ass PC gamers.",
      "Looking at the time spy results, we all know why OP didn't share them lol.\n\nDrivers are probably a mess. It's that or the cards themselves have an issue...",
      "Also with the now confirmed 4070 ti. That gap between the 4080 and 4070ti is so large, the 7900XT is a no brainer for that price bracket.",
      "It's not normal to buy a new GPU/CPU every generation, despite what reddit might make you think. Even every other generation is quite aggressive.",
      "This doesn't look too good if you look at how the old generations squared up in Fire Strike. Looks like the old generation of AMD GPUs had an advantage in this benchmark relative to average gaming performance.",
      "Fire strike has always been like this. I assume it's something about dx11.",
      ">No, firestrike just isn't good",
      "AMD just can't sell a 7900XTX for $1000 if it ends up being basically the same performance as the 4080 in raster but like half the performance with RT and also no DLSS, NVENC, CUDA and worse efficiency (remember, the 4080 is very efficient).\n\nIf the 7900XTX is not at least 15-20% better than the 4080 in raster, it's going to have a hard time even at $200 less than the 4080.",
      "No, firestrike just isn't good for comparison between different architectures",
      "Absolutely not.\" 7900XT\" should be called 7800XT and cost $650-700 because it replaces  6800XT. It's not a no brainer, it's a price gouge from AMD.",
      "I know it's a leak and so not trustworthy, but these results are about where I expected them to be relative to 4080/4090.",
      "So everyone sees the reviews at launch, thinks the cards are shit and never buys them. Then once the drivers are perfect Nvidia releases the next generation to much fanfare and nobody give two ducks about AMD.\n\nThe first impression is what counts",
      "Yup, first gpu's with chiplets as well so I expect a few months to get more performance",
      "This is so true, none of my friends want to upgrade. They spent too much last generation.",
      "I see some people want this to be more impressive than it is, but the 7900xtx is actually looking $100 too expensive. Depending on the game it could basically be slightly above the 4080, and that's with much worse RT and no frame generation. \n\nI'd probably settle on a 7900xt just to save some bucks, unless the 4080 gets under $1000, in which case it's the best option.",
      "Let's hope these results aren't reflective of gaming performance otherwise no one would buy these cards after the inevitable 4080 price drop.",
      "Yeah, while not representative of actual gaming performance, these numbers are a little ooofffff. Let's hope it's down to the changes AMD has made for RDNA3 just not scaling well on 3DMark's tests. \n\nAt this rate the 7800xt wouldn't even be faster than a 6800xt."
    ]
  },
  {
    "brand": "amd",
    "generation": "7000",
    "tier": "top",
    "matched_keywords": [
      "7900xtx",
      "7900xt"
    ],
    "title": "After 9070 series specs leaks, here is a quick comparison between 9070XT and 7900 series.",
    "selftext": "[7900XTX\\/XT\\/GRE \\(Official\\) vs 9070XT \\(Leaked\\)](https://preview.redd.it/zzkyaed2akde1.png?width=1856&format=png&auto=webp&s=27ea1619fbf4fe055753420f5e8726de1698bcd0)\n\nOverall it remains to be seen how much architectural changes, node jump and clocks will balance the lack of CU and SP. \n\nPersonal guess is somewhere between 7900GRE and 7900XT, maybe a tad better than 7900XT in some scenarios. Despite the spec sheet for 7900, they could reached close to 2.9Ghz as well in gaming.",
    "comments": [
      "Interesting, still waiting to replace my 1070ti for 1440p gaming. Undecided between 9070 XT or 5070 TI, definitely need at least the 16GB of ram for some future proofing. The 5070 regular sucks.",
      "All the missing compute units agains the 7900XT are replaced with clocks. So that is the bottom line. Now it remains to be seen how the architectural improvements impacts performance.",
      "keep in mind that historically the higher CU count does not scale very well with AMD. If you compare 7800XT with 7900XTX thats 60% more CU but results only in 44% higher performance. 7900XT has 40% more CU and 28% more performance. The sweetspot always seems to be around 64 CU (Scaling from 7700XT to 7800XT is way more linear).\n\nAlso RDNA3 used Chiplets while RDNA4 is monolithic. Performance might be 5-10% shy of an XTX. It comes down to architectural changes and if the chip is not memory starved.",
      "I'm also waiting to decide between these two cards, my focus is raster performance in 1440p gaming.",
      "I bet AMD did something to make these additional ALUs more useful. Something like adding more register space and extending the types of instructions the second set can perform to allow for single-cycle Wave64 execution more often.\n\nHaving less CUs also means having less scheduling overhead btw. I believe one of the reasons the command processor in flagship RDNA3 clocked higher than the shaders was because of such overhead.\n\nAnyways, the rumored 390mm¬≤ seem considerably large for a die with just 64CUs and a 256bit memory interface. Something in that chip is needing tons of space and I don't think it's the fixed-function units or shaders (although the latter are probably less dense than usual to allow for higher clock speeds).\n\nI can't wait to see the architecture reveal and test results from reviewers - I love seeing how these technical aspects affect performance.",
      "I mea, the 7800XT can match the 6800XT despite having 12 fewer SM's. So it is possible.",
      "Sumilar raster, weaker rt.",
      "Sure cause we all know it's impossible to OC+UV new cards.",
      "A 7900 XT can do 2,9Ghz quite easily while gaming (will draw 380W tho) in synthetic benchmarks it breaks the 3ghz over 420W (air cooled) I‚Äôm still coping they bring at least a 9080 XT during Super release",
      "Clocks can't solely compensate for missing SM/SP. I'm hoping the node change/monolithic design adds something. The performance is definitely going to be between the 7900GRE & 7900xt. Hoping it's closer to the 7900xt.",
      "Isn‚Äôt the 7900xtx sufficient for native 1440p ultra wide? There‚Äôs no need for upscaling",
      "why would someone buy 7900xtx or 4800 super to play at 1080p? I think comparing at 4k is more relevant",
      "Are 7900xt/xtx even the right comparisons? These are the lower end of rdna4 reworked to be suitable stand-ins until udna. Aren‚Äôt they even monolithic like rdna2 and small rdna3?",
      "Not cheap anymore after 20 Jan.",
      "It's because if someone is paying $1000 or more for a gpu they'll just go Nvidia.¬† People on the mid and low end are more willing to go with amd because of the price to performance.",
      "Any idea how it might compare to a 6900xt? That's what I would be upgrading from.",
      "Also between the two for 4k, and we still have yet to see any verified independent benchmarks for either card. For me its gonna come down to how much value the 9070 xt is gonna have over the 5070 ti, and how FSR4 and DLSS4 compare to each other.",
      "2-7% faster depending on the outlet/games used.",
      "First of all isn't it basically what I said? The difference increases as the resolution does. 1080p Numbers for 4080s and XTX are the least useful numbers you could find.",
      "With you there, though never even considered 5070. I sold my XTX as I felt ML upscaling has become a requirement for high end gaming. \n\nI'm leaning towards 5070ti simply because I don't want to be left out of the show, again. But the 9070xt might just be such a good deal in comparison while still having good RT and upscaling that I'm still undecided. \n\nI'm at uw1440p so I'd assume if the leaks/rumors are just sorta right the 9070xt is gonna be a fantastic option. But id assume for very good RT performance the 5070ti is likely necessary, especially at my resolution."
    ]
  },
  {
    "brand": "amd",
    "generation": "7000",
    "tier": "top",
    "matched_keywords": [
      "7900 xtx"
    ],
    "title": "7900 XTX sometimes has worse performance than 6900 XT in VR gaming in benchmarks",
    "selftext": "",
    "comments": [
      "Probably drivers, same with the 180w power draw at idle. Feels like AMD just rushed the launch.",
      "Amd drivers: Everytime you think you're out, they pull you right back in.",
      "Clearly. Classic cash grab before the holidays. Though, I still bought one.",
      "I‚Äôm gonna bet that it‚Äôs a driver issue which can be fixed. Sucks they don‚Äôt have a solid driver run that Nvidia tends to have on launch day",
      "The issue goes wayyyy back, example from 2002:\n\nhttps://arstechnica.com/civis/threads/my-final-word-on-ati-and-driver-issues.796575/\n\nAnother from 2000 https://www.anandtech.com/show/536:\n\n>While the MAXX performed much more competitively than the Rage 128 at its release, and while the MAXX did come out in a reasonable time frame, **the solution was plagued by the usual ATI driver problems**\n\nAs they say, driver problems were the \"usual\" even in the year 2000, lol.",
      "Shareholders do",
      "Or they didnt want to be called liars for not launching in 2022.",
      "Why is it when I bring up AMD driver issues, everyone loses their minds... but I see AMD driver issues brought up here, and no one bats an eye?\n\nHere's let's try it RQ:\n\n**AMD GPU Driver's are the companies #1 hindrance on Windows PC's.**",
      "At least one of them is definitely incorrect - the OpenVR Benchmark for the 6900XT appears to be another run of the VRMark Blue Room Score... that, or somehow the 1% lows for the 6900XT are higher than the 4090... and man, 6000+ avg fps :D",
      "PC gamers: *have you tried updating the drivers?*\n\nAMD owners: *too scared.*",
      "What's the rush? Can't you just wait 5 years for Fine Wine‚Ñ¢ magic?",
      "with elite it's almost certainly drivers. the *6000* series has been broken for months due to driver issues. 7000 series for sure is also impacted.",
      "From 2001 - Radeon 8500:\n\n\"All of the specs pointed at a higher performing product, but in the end  \n we are limited by what has been ATI's Achilles' heel: drivers.\"\n\nhttps://www.anandtech.com/show/836/16",
      "The 6800/XT had similar VR issues two years ago at launch.  It took awhile for AMD to sort them out.",
      "This feels like a vega moment - card is power hungry, is underperforming, AMD's bet on new cache technology isn't showing true potential. Then there are drivers... \n\n\n100% rushed a product that isn't ready.",
      "If it's drivers yet again then all I can say is AMD needs to seriously look at the driver team and get some new talent in. It's obvious they got some old timers leading the teams who are not that good.",
      "What an excellent marketing gimmick when you think about it. \"Ah yes, but by the time your GPU is becoming obsolete... these babies will run smoooooth AF\"",
      "Vega 64 was destroyed by a GTX 1080 Ti for not much more money.\n\nAny 3x 8 pin power AIB 7900 XTX OC'd beats a 4080 OC'd AIB and the 4090 is a thousand dollars more than a 7900 XTX, at least in Europe.\n\nThe drivers definitely need improving but it's hardly a failure like Vega was, as it's competitive in performance which Vega 64 certainly wasn't.",
      "> AMD just rushed the launch\n\nHave they ever released a truly finished product? The fine wine technology is mostly AMD releasing unfinished products and completing them... over years",
      "Very disappointing.  Was looking at the XTX but as I play 90% VR it's a no go.\nMight end up sitting this gen out all together with the pricing of the Nvidia cards."
    ]
  },
  {
    "brand": "amd",
    "generation": "7000",
    "tier": "top",
    "matched_keywords": [
      "7900xtx"
    ],
    "title": "PC with 7900XTX red devil pulls 666 watts from the wall.",
    "selftext": "Recently upgraded from a 6700XT to 7900XTX. \n\nMy powersupply is 750W so I'm cutting it very close, but it's a new Seasonic focus gold, so I'm sure it's reliable. I'm just not going to overclock the card, this was worst case scenario with a Ryzen 7900X and GPU both maxed out.",
    "comments": [
      "Now you know why it's called a Red Devil.",
      "Is this a peak or sustained wattage?\n\nIn any case, 666 from the wall at around 90% efficiency means the PSU is supplying about 600W, so you have a 20% buffer.",
      "Ah gotcha, I appreciate the info! The card does recommend a 900W PSU minimum, but I should be good. \n\nThis was at peak load, realistically when gaming I'm only pulling like 450-580W depending on the game. Idle and basic tasks it's 110-170W (this is total PC usage). \n\nI know modern GPUs also have power spikes, but I haven't crashed or had any issues yet.",
      "Wait till the wires turns hot red and start to melt everything.",
      "Maybe that's why it's called the red devil.",
      "Might be time for an exorcist",
      "The old Seasonic Focus line was really bad at dealing with transients, so you are either lucky or have a newer model (or maybe Powercolor kept the transients low with this model, I haven't seen any proper review.)\n\n>This was at peak load\n\nYou mean like running a CPU and a GPU stress test at the same time?",
      "Correct, this was everything at 100% load. Which while gaming the Ryzen 7900X barely does anything, it's all the 7900XTX",
      "OP was playing Diablo 4 at that moment.",
      "They recomend higher to avoid liability. They don't know what the rest of your system is, so it's better to overestimate.\n\nI would still look at undervolting any card, less draw with no draw backs.",
      "Then wrap them around a can of Chef boyaRDee.",
      "So basically your PC is a bit of a demon ;)",
      "That seems about right, 13900K+4090 users report 650w peaks. A good 750w PSU is fine for that. I love posts like this to prove the 1000w gang wrong.",
      "I have a 4090 and 5800X3D and I've gone never gone above 600. Running a 750 watt, and the 4090 is slightly overclocked. 750 watt gang",
      "‚õß",
      ">then it'd consume 812W of power at the wall to supply that.\n\nAnd it would be rated to do so. PSU ratings are the sum of the DC rails, not the draw from the wall. A 750W PSU can supply 750W of DC power combined, it's just a matter of how efficiently it does it.",
      "Truly a red devil!",
      "Most efficient AMD GPU",
      "could try to undevolt, that can get 200~ watts and potentially higher clock speeds, or sacrifice 1-2 frames for lower power, I got a 7900 xt and a 850 watt but this pc is in my room so I would love it to not be a space heater.",
      "Plot twist he was also running Diablo 4"
    ]
  },
  {
    "brand": "amd",
    "generation": "7000",
    "tier": "top",
    "matched_keywords": [
      "7900 xtx"
    ],
    "title": "Is my brain working right? Is this what we're thinking in terms of performance for 7900 XTX? Assuming it is 1.5x-1.7x over a 6950 XT.",
    "selftext": "",
    "comments": [
      "No. This is right. This is what AMD claimed.\n\nWe can't tell how true the numbers are until we get to benchmark it ourselves, though. But it looks great.",
      "Use the Techspot / Hub chart instead. TPU tested with a 5800X which did cause some slight CPU bottlenecking at 4K with the 4090.\n\nTechspot had the 4090 scoring 144fps in the 4k 13 game average and the 6900XT scoring 77 fps. The 54% perf/watt claim was for a 7900XTX at 300W (sneaky bastards) so that gets us to 119fps @ 300W. The extra bit of wattage will allow higher clocks but I expect that causes the perf/watt to drop off (otherwise AMD would have just compared stock vs stock like in prior launches) so lets say that extra 18% power only increases performance by 10% (might be generous but I don't know). That gets us to 130 fps in Techspot charts. Their 6950XT scored 85 fps in those charts and 1.54x that is 131fps so it is close IMO.\n\nGiven that that would make the 4090 about 10% faster than the 7900XTX in raster.\n\nThe 4080 16GB in the NV slides was about 20% ahead (using fantastic eyeball maths!) of the 3090Ti. That card scored 91fps in the techspot chart so that puts the 4080 16GB at around 110 fps.\n\nSo stack will probably look as follows for raster\n\n* 4090        144 fps ($1,600)\n* 7900XTX  131 fps ($999)\n* 7900XT    115 fps ($899)\n* 4080 16   110 fps ($1,200)\n* 4080 12   90 fps ($900) - or whatever it renamed to\n\nFor RT it might be more like (I did raster * 0.65 for NV and raster * 0.5 for AMD here)\n\n* 4090       94 fps ($1,600) 66 fps with new scaling\n* 4080 16   72 fps ($1,200) 51 fps with new scaling\n* 7900XTX  65 fps ($999) 41 fps with new scaling\n* 4080 12   59 fps ($899) 41 fps with new scaling\n* 7900XT    55 fps ($899) 37 fps with new scaling\n\nSo if you want RT performance then 4080 16 is not terrible, about 10% or so more performance for 20% more money. If you want raster then 7900XTX or XT are both good. If you want both you spend the $$ and go for a 4090.\n\nEDIT. I went through and checked the RT scaling at 4K in the games techspot tested. 4090 came out at 0.46x and 6950XT came out at 0.31x. Assuming the 4080 and 7900XTX are similar to those numbers I have updated the numbers to reflect that. It pans out that perf/$ is looking to be about the same for RT performance between NV and AMD but AMD will hold the advantage in raster which might offset the features NV have for some people, time will tell.",
      "Remember they did not compare it with the 4090 on purpose very different form last time when they showed 3090 on the charts. The 70% improvement is likely very rare and in a select few games. Expect the averages around 40-60%.",
      "I think AMD has been pretty accurate in their performance claims these recent years. They also don‚Äôt shy away from showing negative results",
      "90% performance at ~85% power and ~$600 cheaper is still quite good tho.",
      "All the marketing bullshit aside its probably 1.5x. Still impressive fps/$.",
      "But the benches they showed were still accurate.\n\nJust like i  this they didnt show a 4090. But based on their claims we know it is right around a 4090 in perfor.ance (assuming it is accurate which is tbd)",
      "7700/7800 seem promising",
      "^By far the most reasonable comment on here, imo.",
      "Yeah, it's better to update the chart for those games they showed.\n\n* Cyberpunk the 6950 XT doesn't do too well [https://tpucdn.com/review/nvidia-geforce-rtx-4090-founders-edition/images/cyberpunk-2077-3840-2160.png](https://tpucdn.com/review/nvidia-geforce-rtx-4090-founders-edition/images/cyberpunk-2077-3840-2160.png)\n   * With 1.7x like they reported, we're looking more like 66.7 vs 71.2 for the 4090\n* Watchdog Legions [https://tpucdn.com/review/nvidia-geforce-rtx-4090-founders-edition/images/watch-dogs-legion-3840-2160.png](https://tpucdn.com/review/nvidia-geforce-rtx-4090-founders-edition/images/watch-dogs-legion-3840-2160.png)\n   * With 1.5x like they reported, we're looking more like 95.85 vs 105.2 for the 4090",
      "‚Ç¨uro prices \n\n2400‚Ç¨ for a 4090\n\nGuestimate prices for AMD 1200‚Ç¨ for the xtx and 1100‚Ç¨ for the xt",
      "fucking insane value compared to the overpriced 4090",
      "Slow down buddy lol. You've got 14-30 days to reconsider your purchase. I'm aware this is a pro-AMD subreddit, but there's no sense in making split decisions without knowing how these cards compare. With that said, you could use the money saved to invest in a full AMD build that'll surely out-pace a 4090 FE üëç",
      "Its not right. This benchmark is using a 5800x which bottlenecks the 4090 even at 4k. The other issue is that AMD only showed 6 games and said 'Up to 1.5x and 1.7x the 6950' this is the best case scenario, not the average one.\n\nIf the 7900 XTX was faster than a 4090 or even a bit slower AMD would've given us detailed performance benchmarks, but they completely avoided it, just like they avoided comparing Zen 4 to the 5800x3D.",
      "It wasn't 8k, it was like 7600x 2100, so 8k cut in half is what they showed.",
      "I hope the 7900XTX humiliates the 4080. On paper the 7900XTX should destroy the 4080 with ease. 12 billion more transistors, 20-30% more bandwidth, 4GB more memory.. Die size of the 4080 is just 380mm2. 7900XT is like 520mm2 with chiplets included.",
      "Yeah, I mean we're talking about a freaking $600 price difference. That's a whole ass 6900xt (current) price difference.\n\n&#x200B;\n\nI wish people had more sense than money.",
      "If you care about ray tracing a lot you should keep the 4090 order, a 60% RT gain over the 6950 XT won‚Äôt place the 7900 XTX anywhere near the 4090.\n\nIf RT isn‚Äôt a big concern however, it looks like AMD will be much better value at the top end.",
      "You are taking gaming average of many games and multiplying it with a \"up to\" claim, aka the best case scenario. It won't apply to average fps on many games.",
      "I mean that's not them being inaccurate, they just didn't make that comparison cause they didn't like it."
    ]
  },
  {
    "brand": "amd",
    "generation": "7000",
    "tier": "top",
    "matched_keywords": [
      "7900 xt"
    ],
    "title": "AMD Radeon RX 7900 XT is now available for $659",
    "selftext": "",
    "comments": [
      "Is 800‚Ç¨ where I live... why!!!",
      "Whenever there's news of an all time low price for a radeon GPU, there's always someone in the comments who says \"Would be great if it was $50 cheaper\"\n\nAnd when it's $50 cheaper after few months, there's already someone in the comments who says the same thing again.\n\nIt's almost a game for me at this point - am I quicker than the most generic reply guy.",
      "But are the rumours of RX 7000 overstock true, and if so, which GPUs are overstocked?\n\nIf every 7900XT and 7900XTX sells out at $899 and $999, then there would be no benefit to selling the same cards for less money. But if the cards are rotting on the shelves, then it could be argued that their price was too high.",
      "Eu VAT",
      "Here's a hot take: If AMD genuinely has a surplus of RDNA3 chips like rumoured and they want to shift them off shelves before Nvidia's next generation shows up, then they should price them according to performance in heavier ray tracing games. Basically the pricing strategy of Zen: according to the weakest performance category until competitive across the board.\n\nThis means pricing the RX 7900 XT in between RTX 4070 and RTX 4070 Super: 540-590 USD.  \nAnd the RX 7900 XTX in between RTX 4070 Super and RTX 4070 Ti: 590-720 USD.  \n\nThe RX 7800 XT at 470 USD is already near the midpoint price between RTX 4060 Ti and RTX 4070: 375-540 USD.  \n\nThey'd be in every tech round-up recommended section for Black Friday, Christmas, and until next generation shows up.",
      "Even with EU VAT, currently on Amazon it's sitting on 700‚Ç¨ atm.",
      "This isn't a hot take, it's the glacially cold take that's frequently shared in this and other tech subs (\"*AMD needs to undercut to increase market share this generation*\")",
      "Ngl it would be insane if the 7900 xt could go for around 600-620 on black friday.",
      "If there's actually too much stock, then it's the smaller Navi 33 dies (RX 7600 & 7600 XT). The prices for those cards are insane, so it's no wonder they're not selling.\n\nPeople here focus way too much on the high-end, considering how much lower the sales volume is for those vs mainstream cards.",
      "Only when you use Nvidia's pricing as an excuse for AMD's price hikes. The 7900 XTX is an 80 series competitor. Last generation, AMD's 80 series competitor (6800 XT) was $650. Maybe $700 is too generous in the climate of supply issues and production cost increases that happened leading into RDNA 3's launch, but Nvidia's price gouging with RTX 4000 isn't going to endear me when AMD's top card is more than 50% more expensive than its most direct performance predecessor.",
      "Next gen is upon us. The 7900 XT is soon equivalent power to midrange, just with more VRAM and less efficiency. $659 is not a steal; it'll undoubtedly go lower.",
      "Insane take, why would the 7900 xtx have to launch 500 dollars cheaper than the 4080? This is why they're exiting the high end.",
      "They‚Äôre ranking them by raytracing performance but yeah, the 7900xt is miles ahead of a 4070 super in like every other measurable aspect.",
      "I got it for like $700 a year ago, I‚Äôm still shocked I got that lucky on Amazon. Plus it was one of those Amazon pay over 6 months with easy payments and zero interest. Felt like I was playing football manager and amortizing a new signing for my squad (pc).",
      "Same here, 3 models available for ‚Ç¨700,- each at a different webshops. (Netherlands)\n\nwhich after removing VAT (21%) and converting (‚Ç¨578) to dollars is 640 dollars.",
      "I was going to buy a 7900xtx but 4080S was actually cheaper by a large margin. New for 750$ pretax after all the discounts and rebates. A shit tier 7900xtx was still 950$.\n\nWTF are you doing AMD.",
      "It's the store that refuses to discount old stock. AMD onyl sets a recommended price.",
      "AMd is probably not making any money on these cards at this point, this is why they wont do high end for a good while.",
      "Mine is dead silent (XFX Merc 319 6800 XT) really happy with that card, and looks great as well",
      "Quite a fucking lot) Even in RT scenarios just amount of brute force 7900XT packs will put it way higher in 99% of cases. So only thing to loose here is DLSS."
    ]
  },
  {
    "brand": "amd",
    "generation": "7000",
    "tier": "top",
    "matched_keywords": [
      "7900 xtx"
    ],
    "title": "Flagship RX 7900 XTX leaves RTX 4080 Super far behind in price/performance with current lowest-ever price",
    "selftext": "",
    "comments": [
      "Wonder what would have been if XTX started with this price of 850 USD. AMD makes solid GPUs, but with noticeably weaker RT and worse upscaling. Both is bound to be improved though, so let's see.",
      ">Wonder what would have been if XTX started with this price of 850 USD.\n\nAbsolutely different. AMD has noone to blame in whole RDNA3 stack selling worse than 4090 alone: pricing 7900XT at 900$? RX7600 at 270$? What a meme. Few price points were better, but none were actually *great*, most of the time it was NVidia raster for 50-100$ less and with worse featureset.\n\n7900XTX had a short benefit of actually being 200$ less than 4080. But at that pricepoint sane man WILL want all the features. And 4080S was a wrench in the cogs.",
      "7600 was soooo bad. Like 5% faster than the 6650 XT, which sold for like $220-230 at the time when the 7600 launched",
      "AMDs Marketing Team has been holding the company back since a good while.\n\nNot to mention that they burned a lot of good will with the community as a side effect to their poor decisions.\n\nAMD never was in a position to pull stunts like Nvidia in the GPU department, yet they tried to emulate them at every opportunity. And their market share is a result of this.\n\nThis price drop comes too late.\n\nThe 5000-Gen is around the corner and anyone wise enough will wait for them to launch, because it can be expected that prices will drop further.",
      "All that really means is that the buying public's reception to the XTX has been so unfavorable that AMD has had little choice but to keep dropping its retail price in order to clear the unsold stock clogging up distribution channels in advance of RDNA 4's pending launch in Q1 2025.  Not that any of the other RDNA 3 cards have fared any better, though...\n\nFor reference, the 4080 Super has a higher usage rate on the Steam Hardware Survey than the 7900 XT and XTX *combined* despite only debuting in Jan 2024 (as compared to Navi 31's Nov/Dec 2022 launch dates).",
      "I think the biggest issue is that the prices have just been unrealistic for months. Like before the price cuts the 7900 xt sat at 680 and the 7900 xtx was 880 dollars. Who wants these cards at these prices? Amd needs to be realistic. No one wants end of life generation products for a premium. There's a reason why these just sit on the shelves and no ones buying them. As a result, you need to make them more appealing by price dropping them significantly or otherwise nobody will buy them.",
      "AMD completely screwed the pooch with pricing this generation, despite Nvidia giving them every opportunity to yank away market share with a superior value proposition.\n\nIf the XTX had launched at $750-$800, the value proposition versus the 4080 would have been absolutely undeniable.  But instead they launched at $1,000, and at that point, people either spent a little more for the 4080, or a little less for a 7900XT/4070ti.",
      "I have a 6700XT and, being that Nvidia is an actively consumer-hostile corporation (as opposed to just another profits-come-first company), I'm not a fan. But I concur, I've been around since Poor Volta and Raja. AMD's marketing seems to be the only part of the company that's made zero attempt to improve at all. At least the GPU division *tried* with RDNA to some degree. \n  \nEdit: It appears I've angered those that love Nvidia. You all may not agree with how I view things because, while I realize a publicly traded company solely exists to make money, my worldview comes first. And in that, ethics is important and no entity is spared. If you want me to concede that jumping on an opportunity for monopolization and price gouging isn't consumer-hostile, I don't know what to tell you.",
      "Why would someone buy a 4070 in hopes that RT becomes a bigger thing after 3-4 years after launch. Probably 2 new Generations of cards in that time.\n\nYou should never buy for future proofing, except MAYBE vram if you plan on increasing your monitor Resolution.",
      ">¬†comparable RTX capabilities\n\nThat part is just not true btw. Resulting FPS can be comparable in extremely light loads, but the moment RT becomes even slightly meaningful - 7900XTX ends up behind. And the more there is - the worse 7900XTX will become compared to 4080 (or 4070Ti. Or, in some cases, even compared to 4070).",
      "First: 4090 is just plain strongest GPU in the world. That alone allows it to dictate its pricepoint. If you want strongest there is - you go for 4090 without choice.  \nSecond: 4090 actually provides noticeably better performance AND noticeably better featureset for higher price. For some this is enough to pay the premium.  \nThird: quite a few people bought 4090 not for, or not only for, gaming - it is the best GPU for many working tasks there is today, including modelling, AI ect.",
      "> Is that why 80% of all Steam players use Nvidia gpus because they love the hostility?\n\nMore because AMD repeatedly fumbled the opportunities they were given to do better. So, Nvidia can just get away with it.\n\n> If you think a company that creates products everyone wants and demands high prices for these products is being hostile to consumers, then you're capitalist hostile.\n\nIt is being hostile to consumers, and saying that is not being anti-capitalist.  \nThe capitalist solution to this problem is better competition. The fact that AMD isn't providing strong enough competition is the reason Nvidia gets away with it.",
      "Just picked one up for ¬£750 which is a steal",
      "Either way the consumer wins. These prices are absolutely ridiculous",
      "Should have been $799 from the start. AMD would have much more market share.",
      "Just so.\n\nThe cheapest 7900 XTX here (Sweden) has been more or less the same price since August. (The 4090 has gone up in price, meanwhile)",
      "Problem is: just being more performant in raster is not enough since 2018. It was already 2022 when they released those GPUs. It wasn't even their first gen of hardware RT supporting GPUs!\n\nBeing comparable or 5% faster in raster for 50$ less doesn't matter where you have far worse RT, far worse upscaler and no frame generation at hand.",
      "A) noone is bying top-level card to shave-off some performance by lowering setting. People are buying those cards SPECIFICALLY to achieve high performance while having those setting on.  \nB)FSR is not \"quite comparable\" to DLSS: even this video shows it very plainly. It can be on comparably usable levels IN BEST CASE SCENARIOS (Quality preset on 4K output), but the moment situation gets harsher: either need for lower preset or lower than 4K resolution: FSR becomes very obviously worse FAST. As for \"given it's open source it's likely to surpass DLSS at some point\" - not happening. No bias or anything - just absolutely technically impossible for it to even match DLSS, let alone surpass it. And considering they themselves are abandoning software solution for FSR4 - it is more than obvious.",
      "It's a sale in one country limited to one specific retailer.\n\n\nThis doesn't say much about AMD's intentions.",
      "Well, the cheapest xtx card is just slightly above 1100$ where I live, sad"
    ]
  },
  {
    "brand": "amd",
    "generation": "7000",
    "tier": "top",
    "matched_keywords": [
      "7900 xtx"
    ],
    "title": "NVIDIA RTX 4090 is 300% Faster than AMD's RX 7900 XTX in Cyberpunk 2077: Phantom Liberty Overdrive Mode, 500% Faster with Frame Gen",
    "selftext": "",
    "comments": [
      "It's absolutely a \"worst case scenario\" tightly packed together to shine on Nvidia, but damn, the delta on this is just ridiculous.  You can argue it's the same situation as Starfield but man, I've always been one of the people that says Starfield looks good for what it is while everyone else is shitting on it but it's certainly not doing anything that pushes graphics technology to help excuse what's going on there.\n\nI personally thought Cyberpunk was going to be the only AAA path tracing outlier using this tech available for a long time but now Alan Wake 2 is around the corner doing the same thing.",
      "It's really not even an nvidia thing as it is specifically a 4090 thing. I don't think anyone denies that the 4090 is amazing it is just wicked expensive. Like we know that card doesn't compare to the 4090 because the 4090 still commands that massive price difference.",
      "I am really curious if Amd is actually going to change directions and follow what Nvidia and Intel are doing in terms of leveraging AI and getting serious about RT.\n\nIt‚Äôs really clear with the results of RR that it‚Äôs the future.  And it feels like every year AMD falls further behind, not catching up.\n\nWith the newest showcase from Intel, Intel is going to really be bringing the heat very soon.  Things are heating up for AMD rapidly.",
      "I thought the comments on this thread were unusually harsh for r/hardware  . . . And then i saw i was in r/amd and everything made sense.",
      "The issue with the 4090 for me rn (as I‚Äôm in the middle of my build) is exactly that. At roughly $2500CAD it‚Äôs ~$1200CAD more than a 7900 XTX, and ~$1000CAD more than a 4080. Like ffs, it‚Äôs a good card, but when the next card below it in performance is nearly half the price, how can I justify it?\n\nI‚Äôd love to see a 4080ti, I feel like if they released that, it would be right in that sweet spot for me.",
      "It doesn't have AI cores. It has AI \"accelerators\" which just schedule the matrix tasks for the normal shader units in the GPU to compute using WMMA instructions. It's not the same as Tensor cores from Nvidia or the XMX cores from Intel which are dedicated cores specifically for matrix computations. AMD just throws the words AI Accelerators out there and it confuses people. They are not on the same level as Nvidia or Intel at all",
      "I think this is the most anti-AMD subreddit there is haha.",
      "Nvidia fan detected!\n\nJokes aside, there's no point in compared this Cyberpunk RT because it is designed for nvidia rt cores in mind. In scientific terminology, not all Turing Mchines are equal for a given computation! \n\nJust pick a generic RT title as Hardware unboxed, AMD is not far behind with their RT implementation. This is really impressive considering AMD approach is more universal and easier to adopt for future games. From a consumer pov, Nvidia approach is emblematic of capitalism corporate culture, they only thrive in monopoly situation.  They are forcing game studio to follow their own hardware black box standard so that they can easily implement anti-consumer strategy every new gen.",
      "I love how my 7900xt has AI cores and nothing uses them yet for gaming.",
      "That's cool, but the RTX 4090 is almost the same cost as my entire PC Build with a Radeon 6900XT so I will pass on the overdrive lol",
      "This was exactly my thinking. I‚Äôm Canadian too and went with the 7900xtx. AMD is just so much better value in Canada with our fucked dollar it doesn‚Äôt make any sense (imo) to go with nvidia just for the RT performance and LESS vram.",
      "It's a game sponsored by nvidia, specifically prioritized for nvidia gpus, especially in RT.\n\nThis is no different than starfields being prioritized for Xbox console and amd gpus",
      "Well it's a good thing AMD isn't trying to compete with the 4090 with the 7900 XTX.",
      "People aren't buying AMD cards for their RT performance.",
      "Just FYI, since everyone forgot. \n\nAMD said that they will be doing RT seriously, but not this gen. Basically, when they feel that it will have wide adoption by industry.\n\nSecond, they bought xilinx and a big part of that was to make a push in AI and its clear lately that they are serious about AI inference and such when it comes to servers.\n\nHere is the thing, though. The reason they might not compete in this area in the consumer discrete gpu market has less to do with capability and more to do with how much they care to prioritize the market segment in general. They money is clearly going to lie in servers and not consumer discrete GPUs. So my worry is that they are going to effectively bow out. I think it would be extremely stupid to do so because as Nvidia has shown, AI tech advancements in one segment goes hand in hand with advancements in other segments.",
      "Yes and no. Nvidia was deeply involved in the production of cyberpunk so this gap isn't unexpected. A better indicator of the future of ray tracing is Unreal 5 Lumen. Many studios are switching over to UE5 and Ray tracing parity between AMD and Nvidia is a lot closer on existing UE5 titles.",
      "Based on 3080ti and 2080ti I would doubt the value would be there either",
      "A mode designed with NV's tools and software stack in mind is excelling on NV's hardware.\n\nThat's unexpected news.\n\nIt's also \"the future\" green people are fantasizing about, get yourself an NV card to play game X, an AMD card to play game Y and intel card for game Z. Awesome. Can't wait.",
      "AMD performs horribly in high RT settings. This is nothing new",
      ">I hope they don't get serious about ray tracing because it's the most over rated gaming tech we have ever had. \n\nAnother reddit hot take from someone who doesn't know wtf they're talking about.\n\nRay tracing has been the dream of real-time rendering since the first spinning cube was drawn on the screen.  Not that long ago it was delegated to render farms that would take six to eighteen months to create two to four hours of video.  The fact that we're getting anywhere close at 60-100Hz now is goddamned amazing."
    ]
  },
  {
    "brand": "amd",
    "generation": "7000",
    "tier": "top",
    "matched_keywords": [
      "7900 xtx"
    ],
    "title": "Rx 7900 xtx based on slides is 10-15% slower than 4090 using 95 less watts and costs $600 less",
    "selftext": "AMD prices NVIDIA‚Äôs top card out of mainstream consumer market",
    "comments": [
      "Just needs to beat 4080 for $1000 and we are good",
      "4080 has 12 billion fewer transistors. That thing is going to get destroyed by the 7900XTX. I can't wait for the reviews. I bet even the 7900XT will beat it.",
      "Yup. Sounds like Nvidia will be unlaunching 2 4080 GPUs. Either that or they need to slash 4080's price by like 40%.",
      "100 watt and $600 less is a great trade off for RT performance.",
      "Nvidia needs to drop 4080 prices and this gen is gonna look exactly like last gen sales-wise.\n\nAs a european Im skipping this gen thanks to the shitty exchange rates + Inflated prices hit us with a double whammy.",
      "Yea for raster these cards are monsters, but RT performance looks like it's going to be pretty rough in comparison. Seems like top-end RDNA3 is going to be at high-end Ampere levels in that regard.",
      "Ray tracing still isn‚Äôt really as relevant as people make it out to believe, plus everyone praised the ray tracing performance of the 3000 series and 7000 series is same if not better so I don‚Äôt see an issue",
      "and don't forget the 7900 XTX doesn't have a 4\\*8 pin adapter that's been melting",
      ">\tRay tracing still isn‚Äôt really as relevant as people make it out to believe\n\nHonestly, *this argument* isn‚Äôt really as relevant anymore as people make it out to be. The people who buy a 4090 for gaming are absolutely enabling ray-tracing. That‚Äôs one of the biggest reasons for buying that level of card for gaming to begin with: all-out 4K gaming with all the bells and whistles. Anyone who needs more frames for competitive games can get it with much cheaper cards and just turning settings down, but for those who seek the absolute top-end graphical quality, there‚Äôs no shortcut. You get what you pay for, period. \n\nRay-tracing is here, and it‚Äôs not going anywhere. While maybe not a dealbreaker feature yet, pretending it isn‚Äôt a factor, especially for high-end GPUs, is either willfully ignorant or simply fooling yourself.",
      "If people pay an additional $600 for 15% more frames, NVIDIA will have zero reason to drop prices. And I think a ton of people are going to pay that premium. And NVIDIA does too.",
      "Not quite, Nvidia is still the king that people will buy regardless. AMD just needs to undercut them in price and match or over perform. Their past strategy of being the slower and cheaper option can only take them so far",
      "Nvidia is increasingly making products for fewer and fewer people thinking people will just buy it because its fast, making them big profits. Reality is starting to show that people dont care much about having the fastest thing if they dont need it and its just not very reasonable to choose that option.\n\nThe mining boom and covid craze really made nvidia draw flawed conusions i think.",
      "Or require a case upgrade in a lot of circumstances.",
      "Based on an AMD slide with 3 games. Thats a very big if.",
      "Come to Linux and you might see it happen!\n\nAMD's drivers for Linux are incredible!",
      "The 4090 will make sense for certain consumers being the 4k ray tracing card. The AMD cards are just offering too much value for the 4080, 4070, and 4060 to compete. Nvidia has them way too overpriced. And I know they havent been announced yet, but if the 4080 12 gb was any indication of their pricing plans, they got problems. A $900 4070 and $600 4060 are not going to be able to compete with AMD's pricing. Amd is looking like they will have a $300 7600, $500 7700, $700 7800. It's just a tier ahead of Nvidia at every level for less money down the entire stack.",
      "That was always going to be the case -- slightly less raster with worse RT but better RT than the 3000 series. For 60% the price that's huge value.",
      "I don‚Äôt know if you‚Äôve been watching but folks aren‚Äôt actually getting smarter out there.  Things have been REAL stupid recently.",
      "most nvidia guys only act like they buy high end. 4090 sold to many creators, only on reddit's bubble does it look like every gamer buys it. in real world, all the green customers are sad, crying, PRAYING for a reasonably priced 4060 and 4070. the whole chest beatinng \"i pays for da frames yo\" died once the average guy could no longer afford the top GPU. Yea, the 1080ti was the last \"i pay for da framesssszz\" generation. now thy sell the top card to artists and miners, gamers pray for a 60/70 card under $500,which they won't get this time. \n\nNvidia has raised the price period, they said ASP must reflect at least the price of a PS5. This is why Ampere has not, and will not return to MSRP, the new price for a 60 class card is $499.",
      "Do they though? Or will people buy it anyway for the RTX and DLSS?\n\nHonestly until the market proves it will buy AMD I see no reason for Nvidea to drop prices."
    ]
  },
  {
    "brand": "amd",
    "generation": "7000",
    "tier": "top",
    "matched_keywords": [
      "7900xt"
    ],
    "title": "My first ever build and my first ever OLED Monitor. Samsung G6 OLED 360hz | 7700x | 7900xt | 32GB 6000mhz",
    "selftext": "",
    "comments": [
      "Once you go oled you cant go back. Same with ultrawide",
      "Next step: Ultrawide oled haha",
      "Spending 800 on a monitor is insane for many people. Most people (at least around me) stick to 300 or less, with many going 200 or less.",
      "Be sure to hide your taskbar, that's the easiest things to burn in.",
      "Not that you'd have any real issues with the 7900xt but ultra wide hits performance surprisingly hard. I decided to return mine and get a 27 in 1440p instead",
      "Colors are coming out! Congratz on the build!",
      "Beautiful build. I have the same GPU model, monitor and RAM capacity/speed and I love it.",
      "> Same with ultrawide\n\nMy jaw fucking dropped after launching Forza Horizon on my curved ultrawide.",
      "Did you see the computer with all that white light ? That‚Äôs what i was referring to",
      "Pixel shift isn‚Äôt going to shift pixels enough to eliminate the task bar‚Äôs impact. The thing I recommend doing is setting a blank screen saver to go into effect after 1 minute if one doesn‚Äôt mind it. That‚Äôs been the compromise I‚Äôve been doing as I personally can‚Äôt stand the hidden task bar.",
      "That's some major cash",
      "Very quickly (like minutes in my case). I went from a 27\" flat to a 34\" ultrawide and couldn't be happier.",
      "I was rocking a 1660 super at the time lol. My 6700xt could probably handle ultrawide fine these days though, especially if I end up getting the 7900xtx after price drops.",
      "Gorgeous, mine set up looks simular, but in black üòÇ",
      "It‚Äôs such a perfect pairing, never without OLED again!",
      "> for 128 total.\n\nWho needs that?",
      "White is right",
      "Do you need to wear sunglasses everytime you use it? üòÇ\n\nJokes aside, very clean build, congrats",
      "You really have to go out of your way to burn in an OLED anymore.",
      "He‚Äôs not your buddy, pal"
    ]
  },
  {
    "brand": "amd",
    "generation": "7000",
    "tier": "top",
    "matched_keywords": [
      "7900xtx"
    ],
    "title": "Proof 7900XTX VR issues ARE due to a driver problem, not hardware (Linux v. Windows timing graphs)",
    "selftext": "",
    "comments": [
      "Thanks for generating Linux graphs. Will share will our VR perf team.\n\n--edit--\n\n(Wow‚Ä¶ did not expect a simple thank you to blow up)\n\nVR performance is a known issue on Windows. it was added to our release notes already... The Linux data is interesting only from a comparison standpoint.\n\nStay classy :)",
      "I'm a software engineer. I enjoy learning about things that would otherwise be walled off from me through building, fixing, contributing too, and honestly just playing with open source software.\n\nI got in to sim racing a while back, and there weren't drivers for my hardware, so I got to learn how to write simple kernel-level code. Then I upgraded my graphics card to account for the new game, and fan control didn't work, so I picked through the codebase and fixed it.\n\nThen I wanted to overclock, undervolt, etc. and that wasn't implemented for navi10 at that point, so I sat down and figured it out, and contributed it back upstream.\n\nSoftware has been cool to me since I was a kid because it was cheap to work on, and I built a career off the backs of those who built software systems that were open enough for me to tinker with, be inspired by, etc.\n\nNow, I still like it, but there's part of me that wants to keep propping up the open, usable, and explorable systems so that people in the future can have the same opportunities with that \"free\" learning experience that I had.\n\n**TL;DR** I enjoy and am inspired by open computing, and getting to help make sure that shit's still around in the future for the next kid to get inspired by is a pretty decent cherry on top.",
      "Forget Nvidia, the 7900XTX performs worse than the 6900XT in VR half the time: [https://www.reddit.com/r/Amd/comments/zlyyrf/7900\\_xtx\\_sometimes\\_has\\_worse\\_performance\\_than/](https://www.reddit.com/r/Amd/comments/zlyyrf/7900_xtx_sometimes_has_worse_performance_than/)\n\nIf the \"VR perf team\" isn't already urgently aware of how bad the VR perf on the 7000 cards are, I'd be pretty worried.",
      "At the risk of getting down-voted, the driver situation on Linux is *very* different from Windows. NVIDIA still relies on proprietary userspace drivers, whereas AMD has embraced \"the Linux way\" to handle their driver support.\n\nWhile it probably doesn't do the average consumer much good *directly*, what ends up happening is that when someone wants a feature, or cares enough to track down a fix to an issue, they *can do it on their own*. The code is open, so with some skill and some time, it's **possible** to fix the problem yourself.\n\nI won't argue that you *should* have to be fixing up your own drivers, but that's a *hell* of a lot better place to be in than just praying that someday, maybe someone at the company that's gatekeeping the access to the information required to solve it will care enough to take a gander at what *you* care about.\n\nIt takes time, but when your community knows enough about your stack to actually *help* and solve their own issues, you ultimately get a community that will end up helping get things to a mature state.\n\nIf I wanted to get the exact fan behavior out of my GF's NVIDIA card that I want, I'd be just SoL, but if I don't like how AMD's drivers do something, I'm free to just rip it up and make it do what I want.\n\n---\n\nWhat this has resulted in is that NVIDIA users have become a kind of second class citizen in the ecosystem. Developers of software and tools can't reallly help you if at the end of the day, they don't have the information necessary to determine whether the issue is with your black box driver(s), or their software, so the concerns of nvidia users get shrugged off.\n\nI'm not saying this is good, but it *is* how it is on the Linux side.\n\nI've had a couple bad experiences, so I'll admit to being hesitant to recommend AMD cards to my Windows-only friends, but it'll be a cold day in hell before I recommend someone support gatekeeping the information necessary to use their product effectively, when the community is more than willing to do the work.\n\n---\n\nTinkering people that give a damn for their own reasons is how cool things get made, and preventing them from even being able to explore their creativity in a space will eventually just stifle creativity and innovation, as it has done here.\n\nI don't fault them for makin' their dough on their product(s), but when it comes to my money, and ultimately my time, it'll be going to the guy who still knows that what a whole planet of collaboration can do with his platform is a hell of a lot cooler than nigh anything he could do on his own.",
      "Isn't this something AMD driver team should test b themselves? Hardly worried about, how testing on various Machines is done. Especially VR performance is lower than on Nvidia part's since ever.",
      "System configuration for the interested.\n\n* OS: Arch Linux\n* KERNEL: 6.2.0-rc1-2-rc\n* CPU: AMD Ryzen Threadripper 3960X 24-Core\n* GPU: AMD Radeon (gfx1100, LLVM 15.0.6, DRM 3.49, 6.2.0-rc1-2-rc) (*This is the 7900 XTX, mesa just doesn't have the marketing name in for it yet I assume*)\n* GPU DRIVER: 4.6 Mesa 22.3.1 (git-c36706142b)\n* RAM: 64 GB\n\nHeadset was a valve index, running @ 90Hz in both instances (I tried higher refresh rates as well on Windows to see if more load would even out the spikes due to power level not dropping, but it only got worse, and most things I play @ 90Hz for stability reasons).",
      "It's also been observed that the 7900XTX sometimes has considerably worse ray tracing performance than the 6900XT (not even the 6950XT).\n\nThis makes absolutely zero sense and clearly indicates that drivers need work.",
      "I can't speak on behalf of Linux, I'm a Windows developer :) yes we are well aware on Windows side...",
      "You think this is the guy to complain to about that? We should probably strive to not harass them out of here when we need them to see all the problems we are posting here",
      "Poolshark and myself are both VR users. Rest assured this is important to us as well, if that counts for anything.",
      "Tell me you don't use Linux without telling me you don't use Linux",
      "If you make windows driver as Open source, most of problem will be gone.",
      "Impossible. Windows would have to be open source, as our kernel driver adheres to the wddm (Windows driver development model, headers)",
      "Damn that's insane to read. It's like these two companies operate in vice versa directions: Nvidia has the best performance out the gate but neglects their current/past architectures as time goes on to puff up their newest release, while AMD seems to have horrible optimization issues at launch but by the end of the devices reign as the newest thing, it's super optimized and takes the lead. I saw this both with the GTX 780 I had that handedly beat a R9 290x at launch but by the end of their run was getting its butt whooped, and then again with the 1080 Ti doing extremely well vs the 5700 XT at it's launch only to see it lose repeatedly after a couple years.",
      "Driver work starts before we even get the cards back from factory, it is definitely not a last-minute thing.\n\nOur driver team is filled with a bunch of talented individuals , things just take time, and there's always unexpected issues that come up near the end of the release cycle.\n\nHappy holidays see you in the new year :)",
      "> NVIDIA still relies on proprietary userspace drivers, whereas AMD has embraced \"the Linux way\" to handle their driver support.\n\nThat nails it really. Some people can handle the nvidia way on Linux but I'm not one of them, it really is a division in the community.\n\n> I've had a couple bad experiences, so I'll admit to being hesitant to recommend AMD cards to my Windows-only friends, but it'll be a cold day in hell before I recommend someone support gatekeeping the information necessary to use their product effectively, when the community is more than willing to do the work.\n\nAs long as people understand that buying new hardware on Linux might sign you up as beta tester it's all good, for AMD GPU's the beta-period seems to be around a year. I wouldn't recommend a \"normal\" Linux user get the 7000 series yet but the 6000 series and earlier is in good shape IMO.",
      "you legend, people like you are the backbone of OSS",
      "It's not the consumers problem and it's why you should always buy what's on offer at the time rather than hoping fixes/improvements come in the future.\n\nFor AMD this really is a budget problem, they have had tiny budgets for these projects and only on the last few years have they increased allocation for the GPU side. They are competing with Nvidia who is significantly larger than it and only does GPUs whereas AMD is competing on both CPU and GPU side on a shoestring budget compared to both main competitors.\n\nIt's a shame really but if AMD could invest more money into the driver team (not that they don't work, just need more help) it would pay dividends as they do improve a lot after launch, because their launch state was just bad.",
      "It's a known issue in the driver\n\n> Some virtual reality games or apps may experience lower than expected performance.",
      "You know with big companies it is often not the teams but management fucking up. I am confident they knew about problems, reported and worked on them but management thought pre christmas release without good vr support is better than other options."
    ]
  },
  {
    "brand": "amd",
    "generation": "7000",
    "tier": "top",
    "matched_keywords": [
      "7900 xt",
      "7900 xtx"
    ],
    "title": "Radeon RX 9070 (XT) vs GeForce RTX 5070 Meta Review",
    "selftext": "- compilation of 14 launch reviews with ~8490 gaming benchmarks at 1080p, 1440p, 2160p\n- only benchmarks at real games compiled, not included any 3DMark & Unigine benchmarks\n- geometric mean in all cases\n- standard raster performance without ray-tracing and/or DLSS/FSR/XeSS\n- extra ray-tracing benchmarks (mostly without upscaler) after the standard raster benchmarks\n- stock performance on (usually) reference/FE boards, no overclocking\n- factory overclocked cards were normalized to reference clocks/performance, but just for the overall performance average (so the listings show the original performance result, just the performance index has been normalized)\n- missing results were interpolated (for a more accurate average) based on the available & former results\n- performance average is (some) weighted in favor of reviews with more benchmarks\n- all reviews should have used newer drivers for _all_ cards\n- power draw numbers based on a couple of reviews, always for the graphics card only\n- performance/price ratio (higher is better) for 1440p raster performance and 1440p ray-tracing performance\n- for the full results and some more explanations check [3DCenter's launch analysis](https://www.3dcenter.org/artikel/launch-analyse-geforce-rtx-5070-vs-radeon-rx-9070-xt)\n\nNote: Many testers have used heavily factory overclocked models for the 9070 (XT). This effect was of course deducted from the average performance values. For this reason, the average for 9070 & 9070XT is (some) lower than most of the individual values.\n\n&nbsp;\n\nRaster 2160p|4070|4070S|407TiS|5070|5070Ti|5080|79GRE|79XT|79XTX|9070|9070XT\n|:--|:--:|:--:|:--:|:--:|:--:|:--:|:--:|:--:|:--:|:--:|:--:|\n&nbsp;|Ada 12GB|Ada 12GB|Ada 16GB|Blackw. 12GB|Blackw. 16GB|Blackw. 16GB|RDNA3 16GB|RDNA3 20GB|RDNA3 24GB|RDNA4 16GB|RDNA4 16GB\nCBase|82.6%|96.6%|116.1%|_100%_|130.0%|149.2%|90.6%|109.6%|128.4%|106.0%|120.8%\nCowCL|78.5%|91.1%|116.5%|_100%_|127.8%|149.4%|93.7%|111.4%|132.9%|112.7%|126.6%\nHW&Co|80.8%|94.6%|115.1%|_100%_|129.7%|149.6%|92.3%|111.6%|130.5%|106.7%|125.6%\nIgor|-|96.2%|115.4%|_100%_|128.4%|148.3%|95.9%|113.5%|137.8%|119.0%|136.3%\nKitGuru|82.7%|96.9%|113.1%|_100%_|126.5%|149.3%|96.7%|118.4%|138.5%|116.2%|133.6%\nLinus|-|92.5%|111.3%|_100%_|128.3%|149.1%|98.1%|115.1%|135.8%|109.4%|124.5%\nQuasar|-|94.4%|111.0%|_100%_|126.9%|-|92.0%|108.2%|128.7%|106.7%|122.1%\nPCGH|-|-|111.2%|_100%_|128.1%|150.3%|-|115.6%|138.0%|109.8%|127.0%\nPurePC|78.2%|92.4%|108.4%|_100%_|127.7%|147.9%|88.2%|106.7%|126.9%|107.6%|119.3%\nSweCl|80.0%|-|-|_100%_|124.0%|146.4%|-|-|132.0%|113.6%|128.8%\nTPU|80.0%|92.3%|110.2%|_100%_|128.0%|148.7%|90.9%|109.1%|129.0%|106.8%|122.4%\nTS/HUB|83.3%|98.3%|115.0%|_100%_|125.0%|143.3%|93.3%|113.3%|136.7%|108.3%|123.3%\nTom's|82.0%|-|115.0%|_100%_|131.0%|-|-|115.4%|135.3%|111.8%|128.5%\nTweak's|80.1%|94.2%|109.6%|_100%_|125.9%|146.8%|93.7%|133.9%|132.3%|107.0%|125.0%\n**avg**|80.6%|94.7%|112.3%|_100%_|127.3%|148.6%|92.5%|112.1%|132.8%|108.1%|123.1%\nTDP|200W|220W|285W|250W|300W|360W|260W|315W|355W|220W|304W\nMSRP|$549|$599|$799|$549|$749|$999|$549|$899|$999|$549|$599\n\n&nbsp;\n\nRaster 1440p|4070|4070S|407TiS|5070|5070Ti|5080|79GRE|79XT|79XTX|9070|9070XT\n|:--|:--:|:--:|:--:|:--:|:--:|:--:|:--:|:--:|:--:|:--:|:--:|\n&nbsp;|Ada 12GB|Ada 12GB|Ada 16GB|Blackw. 12GB|Blackw. 16GB|Blackw. 16GB|RDNA3 16GB|RDNA3 20GB|RDNA3 24GB|RDNA4 16GB|RDNA4 16GB\nCBase|84.9%|97.5%|114.4%|_100%_|125.8%|140.9%|87.8%|109.0%|123.0%|105.2%|118.7%\nCowCL|80.7%|94.0%|108.4%|_100%_|120.5%|134.9%|92.8%|112.0%|125.3%|112.0%|122.9%\nHW&Co|84.3%|97.8%|115.0%|_100%_|124.9%|143.3%|95.3%|112.5%|127.7%|107.3%|123.9%\nIgor|-|97.2%|111.9%|_100%_|124.8%|141.0%|96.3%|111.3%|130.9%|115.4%|129.8%\nKitGuru|84.4%|98.7%|112.7%|_100%_|123.2%|142.5%|97.7%|117.4%|133.6%|115.2%|130.9%\nLinus|-|95.7%|111.8%|_100%_|123.7%|143.0%|102.2%|116.1%|132.3%|107.5%|121.5%\nQuasar|-|95.3%|109.4%|_100%_|122.5%|-|91.12%|107.1%|123.4%|105.9%|120.0%\nPCGH|-|-|110.5%|_100%_|123.8%|143.1%|-|115.2%|134.7%|108.0%|123.6%\nPurePC|80.7%|95.0%|107.6%|_100%_|123.5%|141.2%|89.1%|106.7%|123.5%|105.9%|116.0%\nSweCl|82.6%|-|-|_100%_|121.5%|138.0%|-|-|128.1%|111.6%|126.4%\nTPU|82.4%|95.0%|109.7%|_100%_|123.4%|139.2%|91.4%|107.2%|123.8%|105.6%|120.1%\nTS/HUB|85.7%|101.0%|114.3%|_100%_|120.0%|134.3%|94.3%|111.4%|129.5%|103.8%|113.3%\nTom's|84.0%|-|112.8%|_100%_|124.8%|-|-|112.9%|126.9%|107.7%|121.3%\nTweak's|85.1%|98.0%|110.8%|_100%_|123.5%|140.1%|96.2%|114.0%|127.1%|106.3%|123.3%\n**avg**|83.5%|96.9%|111.2%|_100%_|123.1%|140.5%|93.3%|111.5%|127.8%|106.8%|120.0%\nTDP|200W|220W|285W|250W|300W|360W|260W|315W|355W|220W|304W\nMSRP|$549|$599|$799|$549|$749|$999|$549|$899|$999|$549|$599\n\n&nbsp;\n\nRaster 1080p|4070|4070S|407TiS|5070|5070Ti|5080|79GRE|79XT|79XTX|9070|9070XT\n|:--|:--:|:--:|:--:|:--:|:--:|:--:|:--:|:--:|:--:|:--:|:--:|\n&nbsp;|Ada 12GB|Ada 12GB|Ada 16GB|Blackw. 12GB|Blackw. 16GB|Blackw. 16GB|RDNA3 16GB|RDNA3 20GB|RDNA3 24GB|RDNA4 16GB|RDNA4 16GB\nCowCL|83.0%|93.2%|105.7%|_100%_|114.8%|123.9%|93.2%|109.1%|117.0%|102.3%|115.9%\nIgor|-|97.1%|112.0%|_100%_|123.7%|136.2%|95.3%|108.1%|124.1%|112.5%|124.7%\nKitGuru|86.3%|99.8%|112.0%|_100%_|120.1%|137.3%|97.4%|115.3%|129.2%|113.6%|127.7%\nLinus|-|98.4%|111.0%|_100%_|121.3%|133.9%|101.6%|114.2%|128.3%|105.5%|118.1%\nQuasar|-|96.5%|107.9%|_100%_|119.0%|-|88.7%|104.5%|117.7%|104.9%|116.1%\nPCGH|-|-|109.5%|_100%_|120.4%|137.2%|-|112.6%|128.6%|106.0%|118.6%\nPurePC|81.8%|96.7%|106.6%|_100%_|120.7%|135.5%|89.3%|105.0%|119.0%|105.0%|114.0%\nSweCl|84.0%|-|-|_100%_|118.5%|131.9%|-|-|123.5%|109.2%|122.7%\nTPU|84.4%|96.1%|108.2%|_100%_|119.5%|131.6%|90.8%|105.3%|118.5%|103.9%|116.5%\nTom's|86.1%|-|109.8%|_100%_|118.1%|-|-|108.0%|118.6%|103.5%|113.5%\nTweak's|87.7%|99.6%|109.4%|_100%_|120.3%|134.5%|95.1%|112.0%|121.3%|105.7%|117.5%\n**avg**|84.9%|97.3%|108.8%|_100%_|119.7%|133.7%|93.1%|109.2%|122.5%|105.6%|117.4%\nTDP|200W|220W|285W|250W|300W|360W|260W|315W|355W|220W|304W\nMSRP|$549|$599|$799|$549|$749|$999|$549|$899|$999|$549|$599\n\n&nbsp;\n\nRayTr. 2160p|4070|4070S|407TiS|5070|5070Ti|5080|79GRE|79XT|79XTX|9070|9070XT\n|:--|:--:|:--:|:--:|:--:|:--:|:--:|:--:|:--:|:--:|:--:|:--:|\n&nbsp;|Ada 12GB|Ada 12GB|Ada 16GB|Blackw. 12GB|Blackw. 16GB|Blackw. 16GB|RDNA3 16GB|RDNA3 20GB|RDNA3 24GB|RDNA4 16GB|RDNA4 16GB\nCBase|86.9%|99.2%|127.0%|_100%_|141.3%|158.9%|84.1%|104.8%|120.4%|108.6%|125.7%\nCowCL|77.3%|90.7%|120.0%|_100%_|137.3%|162.7%|78.7%|96.0%|112.0%|96.0%|109.3%\nKitGuru|86.4%|100.3%|130.2%|_100%_|145.8%|173.6%|76.9%|95.6%|110.5%|103.4%|122.0%\nPCGH|-|-|128.0%|_100%_|142.7%|168.7%|-|98.2%|116.0%|104.8%|122.9%\nPurePC|78.7%|95.9%|113.1%|_100%_|135.2%|158.2%|63.9%|76.2%|91.8%|88.5%|102.5%\nTPU|82.4%|95.9%|137.4%|_100%_|155.1%|179.3%|79.6%|94.7%|110.2%|111.4%|132.7%\nTS/HUB|82.1%|97.4%|115.4%|_100%_|130.8%|156.4%|53.8%|64.1%|76.9%|71.8%|97.4%\nTom's|83.0%|-|121.4%|_100%_|134.3%|-|-|89.0%|104.7%|98.6%|117.3%\nTweak's|84.4%|99.6%|120.7%|_100%_|135.1%|159.4%|-|-|-|96.0%|116.7%\n**avg**|83.5%|97.9%|125.1%|_100%_|141.0%|165.3%|74.6%|91.1%|106.8%|98.8%|117.3%\nTDP|200W|220W|285W|250W|300W|360W|260W|315W|355W|220W|304W\nMSRP|$549|$599|$799|$549|$749|$999|$549|$899|$999|$549|$599\n\n&nbsp;\n\nRayTr. 1440p|4070|4070S|407TiS|5070|5070Ti|5080|79GRE|79XT|79XTX|9070|9070XT\n|:--|:--:|:--:|:--:|:--:|:--:|:--:|:--:|:--:|:--:|:--:|:--:|\n&nbsp;|Ada 12GB|Ada 12GB|Ada 16GB|Blackw. 12GB|Blackw. 16GB|Blackw. 16GB|RDNA3 16GB|RDNA3 20GB|RDNA3 24GB|RDNA4 16GB|RDNA4 16GB\nCBase|88.2%|101.8%|120.2%|_100%_|129.2%|144.0%|81.6%|102.2%|113.7%|106.9%|118.9%\nCowCL|75.6%|89.0%|111.0%|_100%_|124.4%|142.7%|74.4%|91.5%|100.0%|98.8%|112.2%\nHWCo|83.5%|100.1%|120.4%|_100%_|132.8%|154.5%|60.4%|71.6%|81.7%|84.0%|101.4%\nKitGuru|86.3%|100.3%|116.8%|_100%_|129.0%|151.6%|71.4%|86.3%|98.3%|94.0%|109.5%\nLinus|-|97.9%|116.7%|_100%_|133.3%|154.2%|62.5%|68.8%|83.3%|83.3%|97.9%\nQuasar|-|100.0%|113.2%|_100%_|123.6%|-|58.1%|68.2%|78.4%|89.9%|101.9%\nPCGH|-|-|115.0%|_100%_|125.4%|145.4%|-|91.9%|105.9%|96.6%|111.4%\nPurePC|80.5%|96.7%|111.4%|_100%_|128.5%|149.6%|62.6%|75.6%|88.6%|87.8%|100.0%\nTPU|84.3%|99.0%|114.6%|_100%_|127.5%|143.5%|70.1%|82.3%|94.2%|96.1%|111.5%\nTS/HUB|87.1%|101.4%|115.7%|_100%_|122.9%|142.9%|55.7%|67.1%|77.1%|84.3%|97.1%\nTom's|85.4%|-|117.9%|_100%_|126.8%|-|-|89.8%|104.7%|99.3%|115.9%\nTweak's|88.9%|101.5%|119.2%|_100%_|131.5%|151.2%|-|90.8%|103.4%|95.3%|113.4%\n**avg**|84.3%|98.8%|115.4%|_100%_|127.1%|146.8%|68.9%|82.8%|95.0%|92.6%|106.5%\nTDP|200W|220W|285W|250W|300W|360W|260W|315W|355W|220W|304W\nMSRP|$549|$599|$799|$549|$749|$999|$549|$899|$999|$549|$599\n\n&nbsp;\n\nRayTr. 1080p|4070|4070S|407TiS|5070|5070Ti|5080|79GRE|79XT|79XTX|9070|9070XT\n|:--|:--:|:--:|:--:|:--:|:--:|:--:|:--:|:--:|:--:|:--:|:--:|\n&nbsp;|Ada 12GB|Ada 12GB|Ada 16GB|Blackw. 12GB|Blackw. 16GB|Blackw. 16GB|RDNA3 16GB|RDNA3 20GB|RDNA3 24GB|RDNA4 16GB|RDNA4 16GB\nCowCL|80.2%|93.0%|107.0%|_100%_|120.9%|136.0%|73.3%|86.0%|95.3%|98.8%|109.3%\nKitGuru|87.2%|100.8%|114.2%|_100%_|125.2%|144.8%|71.1%|84.7%|94.8%|92.1%|104.9%\nLinus|-|71.0%|116.7%|_100%_|129.2%|147.2%|63.9%|72.2%|81.9%|84.7%|98.6%\nPCGH|-|-|113.2%|_100%_|121.2%|139.0%|-|92.6%|104.7%|97.1%|110.3%\nPurePC|81.5%|96.8%|109.7%|_100%_|125.0%|142.7%|64.5%|75.0%|86.3%|87.1%|98.4%\nTPU|84.6%|99.0%|112.7%|_100%_|122.8%|135.8%|69.9%|82.3%|93.3%|93.5%|108.7%\nTom's|92.7%|-|124.5%|_100%_|120.6%|-|-|95.8%|108.5%|104.7%|120.0%\nTweak's|89.1%|102.4%|116.5%|_100%_|128.0%|145.6%|75.0%|87.9%|98.5%|93.9%|110.6%\n**avg**|85.4%|99.5%|113.7%|_100%_|123.3%|139.7%|72.8%|85.5%|96.6%|93.5%|106.5%\nTDP|200W|220W|285W|250W|300W|360W|260W|315W|355W|220W|304W\nMSRP|$549|$599|$799|$549|$749|$999|$549|$899|$999|$549|$599\n\n\n&nbsp;\n\nRaster vs RayTracing|4K/2160p|WQHD/1440p|FullHD/1080p\n|:--|:--:|:--:|:--:|\nGeForce RTX 4070|71.8% vs 66.7% = **-7%**|75.0% vs 73.0% = **-3%**|78.0% vs 75.0% = **-4%**\nGeForce&nbsp;RTX&nbsp;4070&nbsp;Super|84.3% vs 78.2% = **-7%**|87.1% vs 85.6% = **-2%**|89.4% vs 87.5% = **-2%**\nGeForce RTX 4070 Ti|92.0% vs 86.9% = **-6%**|93.9% vs 93.7% = **¬±0**|95.8% vs 95.1% = **-1%**\nGeForce RTX 5070|89.0% vs 79.9% = **-10%**|89.9% vs 86.6% = **-4%**|91.9% vs 87.9% = **-4%**\nGeForce RTX 5070 Ti|113.4% vs 112.7% = **-1%**|110.7% vs 110.1% = **¬±0**|110.0% vs 108.4% = **-1%**\nGeForce RTX 5080|132.3% vs 132.1% = **¬±0**|126.3% vs 127.1% = **+1%**|122.8% vs 122.8% = **¬±0**\nRadeon RX 7900 GRE|82.4% vs 59.7% = **-28%**|83.8% vs 59.7% = **-29%**|85.5% vs 64.0% = **-25%**\nRadeon RX 7900 XT|99.8% vs 72.8% = **-27%**|100.2% vs 71.7% = **-28%**|100.4% vs 75.2% = **-25%**\nRadeon RX 7900 XTX|118.2% vs 85.4% = **-28%**|114.9% vs 82.3% = **-28%**|112.6% vs 84.9% = **-25%**\nRadeon RX 9070|96.3% vs 79.0% = **-18%**|96.0% vs 80.2% = **-16%**|97.0% vs 82.2% = **-15%**\nRadeon RX 9070 XT|109.6% vs 93.8% = **-14%**|107.9% vs 92.2% = **-15%**|107.9% vs 93.6% = **-13%**\n\nNote: all normalized to the GeForce RTX 4070 Ti Super at _100%_\n\n&nbsp;\n\nAt a glance|4070|4070S|407TiS|5070|5070Ti|5080|79GRE|79XT|79XTX|9070|9070XT\n|:--|:--:|:--:|:--:|:--:|:--:|:--:|:--:|:--:|:--:|:--:|:--:|\n&nbsp;|Ada 12GB|Ada 12GB|Ada 16GB|Blackw. 12GB|Blackw. 16GB|Blackw. 16GB|RDNA3 16GB|RDNA3 20GB|RDNA3 24GB|RDNA4 16GB|RDNA4 16GB\n2160p RA|80.6%|94.7%|112.3%|_100%_|127.3%|148.6%|92.5%|112.1%|132.8%|108.1%|123.1%\n1440p RA|83.5%|96.9%|111.2%|_100%_|123.1%|140.5%|93.3%|111.5%|127.8%|106.8%|120.0%\n1080p RA|84.9%|97.3%|108.8%|_100%_|119.7%|133.7%|93.1%|109.2%|122.5%|105.6%|117.4%\n2160p RT|83.5%|97.9%|125.1%|_100%_|141.0%|165.3%|74.6%|91.1%|106.8%|98.8%|117.3%\n1440p RT|84.3%|98.8%|115.4%|_100%_|127.1%|146.8%|68.9%|82.8%|95.0%|92.6%|106.5%\n1080p RT|85.4%|99.5%|113.7%|_100%_|123.3%|139.7%|72.8%|85.5%|96.6%|93.5%|106.5%\nTDP|200W|220W|285W|250W|300W|360W|260W|315W|355W|220W|304W\nReal&nbsp;P.D.|193W|221W|277W|230W|287W|311W|~255W|309W|351W|220W|302W\nE.Eff. 1440p&nbsp;RA|99%|101%|92%|_100%_|99%|104%|84%|83%|84%|112%|91%\nMSRP|$549|$599|$799|$549|$749|$999|$549|$899|$999|$549|$599\nRetail GER|~540‚Ç¨|~580‚Ç¨|~790‚Ç¨|~730‚Ç¨|~1000‚Ç¨|~1300‚Ç¨|~570‚Ç¨|~670‚Ç¨|~880‚Ç¨|~730‚Ç¨|~840‚Ç¨\nP/P GER 1440p&nbsp;RA|113%|122%|103%|_100%_|90%|79%|119%|121%|106%|107%|104%\nP/P GER 1440p&nbsp;RT|114%|124%|107%|_100%_|93%|82%|88%|90%|79%|93%|93%\nRetail US|~$550|~$600|~$800|~$650|~$900|~$1150|~$550|~$650|~$870|~$650|~$750\nP/P US 1440p&nbsp;RA|99%|105%|90%|_100%_|89%|79%|110%|111%|95%|107%|104%\nP/P US 1440p&nbsp;RT|100%|107%|94%|_100%_|92%|83%|81%|83%|71%|93%|92%\n\nNote: RA = Raster, RT = Ray-Tracing, EE = Energy Efficiency, P/P = Performance/Price Ratio\nNote: retail prices assuming real availability - for old SKUs, these are typically from the year 2024; corresponding assumptions were made for new SKUs, taking into account the current trend that the list price will hardly be reached in the near future\n\n&nbsp;\n\nList of hardware reviews evaluated for this analysis:\n\n- [ComputerBase](https://www.computerbase.de/artikel/grafikkarten/amd-radeon-rx-9070-xt-rx-9070-test.91578/)\n- [Cowcotland](https://www.cowcotland.com/articles/4479/dans-la-famille-tuf-je-demande-la-radeon-rx-9070-et-la-rx-9070-xt.html)\n- [Hardware & Co](https://hardwareand.co/dossiers/gpu/test-des-radeon-rx-9070-9070-xt-amd-de-retour-aux-affaires)\n- [Igor's Lab](https://www.igorslab.de/en/amd-radeon-9070xt-and-9070-in-the-test-clock-energy-with-crowbar-and-at-least-some-reason-as-a-counterpoint/)\n- [KitGuru](https://www.kitguru.net/components/graphic-cards/dominic-moass/amd-rx-9070-review-ft-sapphire/)\n- [Linus Tech Tips](https://www.youtube.com/watch?v=ptp5suRDdQQ)\n- [PC Games Hardware](https://www.pcgameshardware.de/Radeon-RX-9070-XT-Grafikkarte-281023/Tests/Preis-Test-kaufen-Release-Specs-Benchmark-1467270/)\n- [PurePC](https://www.purepc.pl/amd-radeon-rx-9070-test-recenzja-opinia-wydajnosc-cena-premiera-asus-tuf-gaming)\n- [Quasarzone](https://quasarzone.com/bbs/qc_bench/views/93906)\n- [SweClockers](https://www.sweclockers.com/test/40758-powercolor-radeon-rx-9070-hellhound-tyst-hund-biter-varst)\n- [TechPowerUp](https://www.techpowerup.com/review/sapphire-radeon-rx-9070-xt-nitro/)\n- [TechSpot](https://www.techspot.com/review/2962-amd-radeon-9070/) / [Hardware Unboxed](https://www.youtube.com/watch?v=gWIIA-a9Q9A)\n- [Tom's Hardware](https://www.tomshardware.com/pc-components/gpus/amd-radeon-rx-9070-xt-review)\n- [Tweakers](https://tweakers.net/reviews/13022/radeon-rx-9070-en-9070-xt-waar-nvidia-spartelt-overtuigt-amd.html)\n\n&nbsp;\n\nSource: [3DCenter.org](https://www.3dcenter.org/artikel/launch-analyse-geforce-rtx-5070-vs-radeon-rx-9070-xt)",
    "comments": [
      "Worth mentioning, that ray tracing includes black myth wukong, which is completely broken on AMD and is basically bruteforced, so it Heavily bricks the results for ray tracing on AMD cards. It's ~5-6% better average if you exclude it (since it's a huge outlier)",
      "This. Removing the statistical anomaly or highlighting it would be helpful for a more accurate understanding.",
      "I was planning to buy an RTX 5070 but everyone on the internet told me to wait for RX 9000.\n\nI bought a Gigabyte Gaming OC RX 9070 XT for 85 USD more than the cheapest RTX 5070 in my countryüôÇ\n\nThank you people. My RX 9070 XT demolishes the RTX 5070 where it matters. I believe the 5070 only beats it in path tracing and Black Myth Wukong.\n\nEdit : For those wondering here was my options in my terrible country (expensive GPUs, low wages, 3rd world)\n\nRTX 5070 : 85 USD cheaper than the RX 9070 XT\n\nRTX 5070ti : 195 USD more expensive than 9070 XT\n\nI'm very happy with my choice.",
      "Perhaps watch the DF video on Avatar?  It's one of the best implementations of GI and other RT features (bar the path tracing titles).\n\nIt runs well on AMD not because its RT is bad but probably because it favours AMD in raster and so when Heavy RT settings are used AMD GPU's have a bit more cushion for extra performance drop.",
      "Cant buy either for sane price in Europe",
      "Worth mentioning that Black myth wukong uses a specific Nvidia fork of unreal engine. Not a conspiracy to assume that Nvidia cards have primary focus on that engine.",
      "He's talking about Black Myth Wukong results being an outlier due to raytracing in that game being broken for AMD. Not the existence of raytracing games being an outlier.",
      "TLDR, just look at the average row for each set. It's normalized to a 5070, so if the average line for a card is 110%, that means it's 10% faster than a 5070.",
      "Test was done at very high RT. The usual usage of it, not PT level. For BMW and Alan wake it's PT, actually, that is why it is borked. In Alan wake both vendors die anyway, so having 20 fps on AMD or 25 on 5070 - who cares. Cyberpunk RT works great on both cards and that's what will be in future games.\n\nBMW on the other hand, is completely broken on AMD. Like, it's a sabotage at this point.",
      "No, but the RX 9070 XT beats the rtx 5070 (12GB) even in Ray TracingüòÇ Its path tracing where it falls flat on its face, but that's a super duper tiny Sacrifice I am willing to make. \n\nThe RX 9070 XT beats the RTX 5070 in Cyberpunk at 1440p Ray Tracing Ultra preset and basically anything that isn't path tracing I believe (besides Black Myth RT)\n\nI got significantly faster raster  , a little bit faster RT and 16GB VRAM for only 85 USD more. The RTX 5070ti (16GB)  is almost 200 USD more expensive than the RX 9070 XT I bought\n\nI love this card. I just finished undervolting the card. I am getting 230w avg power usage and -3.5% perf decrease",
      "This is many number, and I many stupid‚Ä¶\n\nIs there a TLDR?",
      "Games that rely on RT only like Indiana Jones and Metro Exodus work well on AMD cards so IDK what that guy is talking about. Wukong just runs badly on AMD.",
      "No, the game specifically is an outlier. Cyberpunk with path tracing on all other AMD cards before this performed similarly with the 7900xtx falling behind even the 3060 Ti, but performance is much better with the 9070 and 9070XT. The 9070 XT performs on par with a 4070 in path tracing in Cyberpunk now and heavy RT results across the board are miles better than last generation... But Wukong still performs like shit.\n\n5070 is 15-20% faster in Cyberpunk PT and 73% faster in Black Myth Wukong for some reason.",
      "Same situation in Australia. These companies only care about the American market.",
      "nice",
      "It's a huge outlier and statistics doesn't work that way.\n\n\nIf you keep the broken crap - the difference is 20%. If you ignore that one single crap - it's 10% or so. And that might be a very important thing for buying decision.\n\n\nSo yes, it is important to mention the outlier, so people can see that a make their decision correctly. Because in other RT games AMD is very competitive, like in cyberpunk or avatar or star wars.",
      "BM:W catching strays for no reason.",
      "Also don't forget access to FSR4 when choosing between 9000 and 7000 cards. It's apparently a night and day difference",
      "GNexus review kept BM:W out of the main averaging and still reported the NVIDIA as better in RT. But said 9070 XT was a good buy for MSRP.",
      "how do you come to that conclusion? the 9070 is faster, the 9070xt is faster than the 4070 super.\n\nIts faster than the super and the same price (or 9070 is less).\n\nVery bad TLDR"
    ]
  },
  {
    "brand": "amd",
    "generation": "7000",
    "tier": "top",
    "matched_keywords": [
      "7900 xtx"
    ],
    "title": "AMD Radeon RX 7900 XTX has been tested with Geekbench, 15% faster than RTX 4080 in Vulkan - VideoCardz.com",
    "selftext": "",
    "comments": [
      "No feels.\n\nThe drivers aren't out yet. Means nothing.",
      "Someone tell me how to feel about this‚Ä¶",
      "Wait for independent reviews.",
      "\"Update: New benchmarks have now been published within Geekbench 5 which showcase far better performance numbers. The RX 7900 XTX sits 8% below the RTX 4080 in OpenCL & 20% faster than the 4080 in Vulkan tests.\"\n\nEdit: Also the card only boosted to 2270 MHz which is a good bit below its rated speed of 2500 MHz.\n\n[Source.](https://wccftech.com/amd-radeon-rx-7900-xtx-graphics-card-opencl-vulkan-benchmarks-leak-out/)",
      "Tldr;\n\n>The RX 7900 XTX is visibly faster than RTX 4080 in Vulkan API (~15%), but it performs worse in OpenCL (~14%)\n\nRTX 4090 -> RX 7900XTX -> RTX 4080\n\nVulkan:\n\n219965 (100%) -> 179579 (82%) -> 154901 (70%)\n\nOpenCL:\n\n356406 (100%) -> 228647 (64%) -  266376 ( 75%)",
      "People forget that although AMD massively improved OpenCL performance by rewriting drivers, they're still technically behind there. \n\nThe Vulkan performance is more indicative of rasterization performance in general I'd wager\n\nEdit: Confused OpenCL with OpenGL my bad.",
      "You're confusing OpenCL (compute library) with OpenGL (graphics library). Similar names, completely independent things.\n\nAMD's OpenCL drivers are, and have always been, good.\n\nThe thing to consider here, too, is that nVidia earns even more performance when using CUDA instead of OpenCL. So for productivity nVidia still crushes AMD.",
      "Or at least benchmarks running with drivers.",
      "Seems bizarre they compare OpenGL and Vulkan and omit DX12, which people will use far more often.",
      "Some poor QA person tested a regression and the fix and forgot to not upload it haha",
      "Proper response.",
      "Waiting for the UserBenchmark review to find out if this card beats the GT 1030 lmao",
      "In Vulkan, a 4080 is 70% of the perf of a 4090, but both of those cards are already out and we already know that a 4080 in 4K gaming is 76% of a 4090.\n\nThat's a pretty big margin between these geekbench scores and actual gaming results. \n\nI think we all just still have to wait for the reviews.",
      "you can't run without drivers, if they are running benchmarks they have drivers.\n\nnow, the drivers may not be FINAL but you aren't going to see a quantum leap in the last 2 weeks before release.  3% here and 1% there, maybe a 5% improvement in a couple things at the outside, but, the lesson from the last 10 years of releases has been that driver quality doesn't massively change on launch day.",
      "The Nvidia fanboy brigade in here justifying why the 7900XTX AND XT are already dead before release. \n\nWait for proper driver support, proper testing and real world results. \n\nBenchmarks are synthetic, not really indicative of real world performance, any true PC enthusiast knows this, Sure they give a general idea, but every game is different, every application is optimized different, etc. \n\nIn a nutshell‚Äîlet‚Äôs wait and see.",
      "1.15\\*1.25=\\~1.44, but your general point stands.",
      "40% faster than the previous flagship for less money during a period of massive inflation isn‚Äôt bad imho. What‚Äôs the alternative? Spend $200 (20%) more for less performance?",
      "But is 15% lower in OpenCL. \n\nCard is very similar to the 4080. But 4080 has DLSS 3. \n\nIf, or more likely when, Nvidia drops the price of the 4080 to sub $1,000, it will greatly outsell AMD 7000 series. And Nvidia will feel vindicated and keep pumping up those prices cause we're all suckers.",
      "geekbench doesnt have a dx12 benchmark",
      "Have you ever stopped to think that AMD fans can get fed up with bad prices just as much as Nvidia fans? \n\nThere's no reason to believe that disgruntled folks are automatically \"Nvidia fanboys.\""
    ]
  },
  {
    "brand": "amd",
    "generation": "7000",
    "tier": "top",
    "matched_keywords": [
      "7900 xtx"
    ],
    "title": "[HUB] Radeon RX 7900 XTX Review & Benchmarks",
    "selftext": "",
    "comments": [
      "Tldr;\n\n16 Game Average FPS - \n\nAt 4k,\n\nRTX 4090 - 142 FPS\n\nRX 7900XTX - 113 FPS\n\nRTX 4080 - 109 FPS\n\nAt 1440p,\n\nRTX 4090 - 210 FPS\n\nRX 7900XTX - 181 FPS\n\nRTX 4080 - 180 FPS\n\nAt 1080p , \n\nRTX 4090 - 235 FPS\n\nRX 7900XTX - 221 FPS\n\nRTX 4080 - 215 FPS\n\nBoth the 7900XTX and the 4080 perform close to each other (within margin of error) in traditional rasterization . The 4080 wins on RT performance and efficiency (power consumption is lower for the 4080) while the 7900XTX is 200 dollars cheaper (for the same or a bit higher rasterizaton performance than the 4080)",
      "ill see you guys when 50xx and 89xx releases",
      "At $800 this card could have smashed, but over $1000 is no competition for Nvidia, they won't even bother with a price drop",
      "Both new gen series cards from AMD and Nvidia are ridiculously priced",
      "nowhere close to 50% performance improvement, wtf amd",
      "Ugh.. pretty bad showing. Maybe could have been salvaged if they launched at $700 and $900 respectively.",
      "Jeez thats worse than expected, it literally only just exactly matches the 4080 on average  in 4k while getting slaughtered in RT. I can't believe people were saying 90-95% of the 4090 at a much lower price before,\n\nAMDS marketing was definitely misleading now looking at the average uplift and the conclusion. people were expecting 50-70 percent more performance than the 6950XT but AMD lied out their ass.\n\nwith the average performance jump being 35% with many games below even that. They've definitely pumped their numbers before with every single GPU launch press but this is by far the worst one yet. it led to people having way too high expectations for this GPU, I guessed the average would be below 50% because of the small amount of games tested and cherry-picking and lack of 4090 comparisons but dang\n\n&#x200B;\n\none last edit: this also shows that time spy extreme is really accurate at predicting performance. that leak showed the 4080 and 7900xtx dead locked which is exactly what happens in real world games",
      "Lmao, who wasn‚Äôt expecting this?\n\nFanboys were saying AMD was going to save GPUs, completely ignoring how the 7000 prices were absurd.",
      "if you can get a 6800xt for 450-500 less, that's probably ideal",
      "48% faster than the 6900xt, 50w=15% higher power... lol @ 50% efficiency increase. they missed it by a mile.\n\nThis is why i say not to trust first party numbers, regardless of them being correct twice before. They promised 50%, they twisted the numbers to get 50%. that's what marketing does.",
      "Thanks amd for fuelling price increases and still releasing an inferior product. 1-2 grand is now going to be the norm for high end!",
      "Disappointing.\nHopefully, they will soon be forced to cut prices. \nCrypto Ponzis are collapsing, lockdowns are over, recession is looming...\nThis cards should be 799$ and 649$.",
      "Aaaaand another gen with the \"missed opportunity\" stamp... jesus christ amd.",
      "Got downvoted few months ago for suggesting this, AMD playing the same game as nvidia pricing 6950xt at $999 so the xtx doesn‚Äôt seem like a price jump when it never should‚Äôve been that much in the first place and then pricing the 7900XT insanely high to up sell to the XTX, similar to 4080 vs 4090. Always loved AMD and despise Nvidia but that‚Äôs the truth. Should‚Äôve been $799 for xtx, $649 for XT or something like that, would hurt rdna2 sales ofcourse but all nvidia has to do is drop 4080 a couple hundred dollars or Mayb not even that and it would seriously mess with the sales again",
      "both them and nvidias 2-4x performance, should be sued for false advertising",
      "We back to RDNA1 days with AMD not competing in performance at high end with 4090Ti and 4080Ti unreleased, except this time it's now at over $1000.\n\nEveryone got played.",
      "Thank the people buying it, not AMD or Nvidia.",
      "Moores law is dead and red gaming tech with their 2x 3x claims. Those clowns and their 'Sources'",
      "How much faster is the 7900xtx? I'm wondering if I should just grab a 6900xt at this point for 300 less",
      "RDNA4 is OK but honestly let's just wait for RDNA5 at this point! I know it just dropped but look at this leak and rumor, buying now would be stupid! \n\nComing to a reddit post near you circa 2024"
    ]
  },
  {
    "brand": "amd",
    "generation": "7000",
    "tier": "top",
    "matched_keywords": [
      "7900 xtx"
    ],
    "title": "the 7900 XTX (AIB models) has quite substantial OC potential and scaling. performance may increase by up to 5%-12%",
    "selftext": "",
    "comments": [
      "I will eat crow here. Turns out they do OC ‚Äúwell‚Äù it‚Äôs just that the power draw goes HIGH.",
      "My 650W PSU: Better luck next gen",
      "Yeah,RDNA 3 isn't efficient at all compared to nVidia. AMD just limited the power draw to market it as such",
      "It would be weird if AMD was more efficient, since they are on a slightly worse node and have chiplets, which will always incur a power penalty relative to monolithic.",
      "I think it may also be to make people like ASUS, MSI etc happy.\n\nWe saw the Nvidia EVGA stuff, I suspect AMD is trying to make the brands happy with them over Nvidia. The meta of not just the public but also the big brands having fights.\n\nThere must be a lot of politics going on that we never see.",
      "That's one suspicious review if I ever saw one.",
      "Non water cooled 4090s overclock between 4-5%, it comes almost maxxed out\n\nThe Asus 7900 XTX is getting close to 15%, a water cooled + unlocked BIOS one may reach over 20%\n\nAMD intentionally locked the card at 350W for... reasons.",
      "AIB's have different power systems and different cooling systems, so overclocking the stock AMD one is unlikely to reach the same performance, no?",
      "Tested with a 5900x, CPU limited, expecially for 4090",
      "PC world XFX speedster review also shows it matching/ beating 4090 for most of their test suite. \n\nhttps://www.pcworld.com/article/1433026/xfx-speedster-merc-310-7900-xtx-review.html",
      "How about power consumption? stock vs tuned OC ?",
      "~~Xfx merc pulled 560+, from oc3d~~ it was total system power, not isolated.",
      "Not surprising, I think this is why most of the AIBs added the third 8 pin. Clearly they saw some headroom that AMD left on the table.",
      "Did people forget you can OC nvidia cards? \nAnd OC isn't always stable in every game nor are the gains the same across the board. Just like every other gpu.",
      "are we really gonna do this again. A day after  reviews launched .",
      "Just make it a dedicated psu just for your graphics card",
      "The copium is strong",
      "10% is a pretty major difference...",
      "Didn't AMD said that the 7900xtx would compete with the 4080 üòÖ\n\nI don't know about this one marty",
      "I never expected it to be more efficient. This wasn't surprising at all."
    ]
  },
  {
    "brand": "amd",
    "generation": "7000",
    "tier": "top",
    "matched_keywords": [
      "7900 xtx"
    ],
    "title": "Joining Team Red for the first time with the 7900 XTX!",
    "selftext": "",
    "comments": [
      "I am on Team Red to. You can send the 3080 over and i am gonna take care of it.",
      "Hello I am friend",
      "I might sell the 3080 to a friend at a discounted price.",
      "I'm jealous of people who can just switch\n\n\\*cries in CUDA\\*",
      "This is the correct answer. You‚Äôre a good friend",
      "I went from a 1080 to a 7900xtx and it has been neat.",
      "You idiots with your fucking *teams*. They're mega corporations selling you a product.",
      "Quite a few companies are currently switching from CUDA to OpenAI's Triton. Nobody in the industry likes Nvidia's monopoly, they want competition and options. So CUDA's dominance in that sector is waning, but it's not because of AMD.",
      "I'm wondering what game you couldn't play with a 3080 in high settings?",
      "Some people just got lots of f*ck you money. Im not at that point yet. But as a 3080ti owner, it runs everything more than fine, there is no need to upgrade only wanting. I really want a 4090 but 2500$CAD is just too much, that‚Äôs not including a new case it can fit or a proper power supply.",
      "I mean, they've been developing it for years, and it's only now ramping up because AI is growing, and AMD want a piece of that pie. The issue you run into is if it just stays as a sort of translation layer for CUDA since that is so ingrained into the AI space and has been for years, you would lose a lot of performance compared to a native  CUDA GPU. I'm hoping they catch up, but I genuinely think it's their biggest hurdle against Nvidia, who update Cudatoolkit and CUDNN faster than AMD update ROCm.",
      "I‚Äôm going from a 1080Ti to a 7900 XTX \n\nWhat CPU you rocking? I went with a 13900K",
      "Went from 6700k + gtx 1070 to 7950x3d + 7900xtx\nTbh as long as you're not BIOSphobic it's really good",
      "I had no issues with my 3080. It's just that I play in 4k and need more frames.",
      "You do know the 4090 is objectively the better gpu right \nThe 7900xtx would be a downgrade",
      "Exactly . No teams. Get whatever you can afford",
      "Amd is developing it's own [ROCm](https://www.amd.com/en/graphics/servers-solutions-rocm) so in someday you probably can switch to amd",
      "I voted with my wallet. 7900 XTX was much cheaper than a 4080 in my country so I switched sides for now.",
      "How's the performance diff? 3080 10g? I'm in the same boat..it was my first Nvidia card ever of 20 years of pc gaming, and it will also be my last. Served me well in 2 years but it's clear that their rabid fan base allows them to get away with anything\n\nI hope intel figures things out",
      "The easiest option for AI development. Direct support in PyTorch, Tensorflow, MATLAB, etc"
    ]
  },
  {
    "brand": "amd",
    "generation": "7000",
    "tier": "top",
    "matched_keywords": [
      "7900xtx"
    ],
    "title": "AMD Monster Radeon RX 7900XTX Graphics Card Rumored To Take On NVidia RTX 4090",
    "selftext": "",
    "comments": [
      "The thing is, I know AMD will have good performance. I'm worried about pricing.",
      "Wait until the board partners come along and we will have a card called\n\nXFX 7900XTX THICCCC XXX ULTRA",
      "Funniest thing would be 7900XTX obliterating 4090 and then Lisa Su pricing it at $2k.",
      "Forbes pfft. If I need to see an uninformative rehash of stale rumors I'll get it from GamerMeld thank you very much!",
      "water edition:\n\nXFX RX 7900 XTX THICCC WET ULTRA",
      "\"Funny\"",
      "Why would anyone buy AMD if they price match Nvidia, if I wanted to pay that much I would just get Nvidia anyways.\n\nAmd has to play the value card without miner demand they have no leverage except value.",
      "All things considered I don't think AMD has that kind of leverage. Radeons are primarily gaming cards, meanwhile Nvidia has a pretty strong foothold in many industries and especially 3090/4090 are very attractive pieces to add to workstation by any 3D generalist. Although the golden choice for that were 3090 nonTi due to being able to pool memory via NVLINK for a whooping 48GB VRAM.",
      "This \\^\n\nFirst leaks also show the fixed power connector: https://preview.redd.it/5w6fou7aa4w91.jpg?width=960&crop=smart&auto=webp&s=c83d0d76d0dc283f2870bc3b47c396e574c73c96",
      "If the AMD cards use less power, generate less heat and are physically smaller while having similar rasterization performance, even if RT is not as good and the prices are the same I would lean AMD.\n\nThe advantages Nvidia currently holds over AMD don't matter to me personally as much as the advantages AMD holds over Nvidia, assuming those advantages maintain in RDNA3.",
      "https://i.imgur.com/WiGq8y0.jpg",
      "I can't wait to see what Sapphire is cooking up.",
      "This. I'll give up ray tracing and just max out every graphic. I'll also have a graphics card that won't catch fire and give AMD my money which will help further outpace nvidia down the line.",
      "LMAO",
      "Get ready for the 4090 ti",
      "Considering that AMD have been getting more and more competent over recent years it really wouldn't be a surprise if they could match the top tier Nvidia card. Assuming you don't have childlike obsession with shiny puddles they have been matching them for years already. The real question is whether they'll compete on price, and they probably won't.",
      "While RDNA has the capability, dethroning CUDA is going to be a long and arduous process. Companies don't tend to care about price and performance as much as compatibility with their existing workflow, so AMD is going to have to start convincing software companies to support AMD cards before most companies will even consider switching.",
      "You can't just quote shit and not put the actual source in your comment. The 6900 XT in pure rasterisation performance trades blows between the 3080 Ti and 3090 from what I've seen.",
      "He's quoting this article from Tom's hardware:\nhttps://www.tomshardware.com/features/geforce-rtx-3090-vs-radeon-rx-6900-xt\n\nHe's also leaving out that his paragraph is about the 3090 vs 6900XT in ray tracing only. From his own articles rasterization performance:\n\n>We'll start with the 4K results since that's the most demanding scenario, and CPU bottlenecks can come into play at lower resolutions. \nRTX 3090 takes a modest 8% lead, though the devil‚Äôs in the details. Of the 13 games, ten have the 3090 in front, leading by anywhere from 2% (Far Cry 5) to 25% (Strange Brigade). Three games (Assassin's Creed Valhalla, Borderlands 3, and Forza Horizon 4) end up favoring AMD, with Valhalla looking suspect at lower resolutions. Drop to 1440p, and the RTX 3090's lead shrinks to just 1%, effectively tied. \nThe RX 6900 XT now leads in six of the games, though several are basically tied. Valhalla meanwhile jumps to a 30% lead, and as an AMD-promoted game, that's an obvious concern. On the other hand, the 3090's biggest lead comes in Strange Brigade, which is also an AMD-promoted game. Finally, at 1080p, the 6900 XT takes the overall lead by 4%, still leading in half of the games but with very large margins in Valhalla and Horizon Zero Dawn.\n\nTL;DR the 3090 only really beats the 6900XT consistently at ray tracing, which everyone already knew.",
      "Why worry about pricing?  6900 XT traded blows with the 3090 for $1,000 vs $1,500.  I would expect a similar situation this time around as well."
    ]
  },
  {
    "brand": "amd",
    "generation": "7000",
    "tier": "top",
    "matched_keywords": [
      "7900 xt"
    ],
    "title": "AMD drops Radeon RX 7900 XT price to $749, ASRock and other models already $709.99 on Newegg",
    "selftext": "",
    "comments": [
      "\\>In the press release for the Radeon RX 7900 XT price cut,\n\nCan someone actually link that press release?",
      "I'd do $750 for an XTX. Probably not an XT, though.",
      "Not enough",
      "these cards are way too expensive for what they are. Even the 7700xt is too damn expensive",
      "The 4070TiS is about to match the 7900xt in raster performance for the same money.\n\nNow add RT, DLSS, Efficiency, and you can see why AMD has to drop prices.\n\nHeck $749 may not be enough. It has to go $700 levels or less.",
      "\"special promotional pricing program\" for select retail outlets this quarter\"\n\n\"AMD advised us that the program is being rolled out now with promotional prices to be reflected in the coming days\"\n\n&#x200B;\n\nmeh",
      "Would still take a 4070 Ti Super. They haven't dropped it enough",
      "not a price cut",
      "700$ for xtx and 600 for xt is good. Then they will clap nvidia basically.",
      "Still 100 dollars too much.",
      "They're going for $710 in the US currently and with the gap between the 4070S and 4070TiS price the 7900XT will fall somewhere between them as the 4070Ti was discontinued and eventually the $650-$750 range will be empty for Nvidia. \n\nDepending on the performance of the 4070TiS the 7900XT might have to drop further in price and I think it will because AMD typically sets MSRP optimistically and the cards end up selling below MSRP.",
      "Overpriced, because 4070 Ti Super.\n\n$90 more to get the same/better raster, way better RT, DLSS, better efficiency and more features (NVENC, Reflex, game filters, CUDA). \n\nWho is supposed to buy the 7900 XT? Who spending >700 on just the GPU would not spend another $90 to get all those advantages? The 7900 XT looks good at 650, but at 700 it's too close to the 4070 Ti Super.",
      "I honestly do not believe the folks saying that if AMD sold these card cheaper, they would them.  People want AMD to lower their prices, so Nvidia will lower prices.  Those people will still buy Nvidia.",
      "Ehh, at 750, nobody is going to buy an AMD card if the Nvidia equivalent is available at 50 bucks more expensive. Especially if they perform within 10%.",
      "US GPU pricing is a wet dream for the rest of us.",
      "4070 Ti Super has 16GB",
      "That‚Äôs not really a price cut",
      "Nowhere near enough. A ti super at $800 is the better buy than a $750 7900xt 10/10 times. IMO, the XTX needs to be 750-800 now to justify it over the 4080S, and the 7900XT needs to be around 650",
      "Didn't know, my bad! In that case I would go for the 4070 ti super duper too.",
      "Ton is subjective. Obviously they make good money, but that doesn't really matter if Nvidia sells 10 or 20 cards for each card AMD sells."
    ]
  },
  {
    "brand": "amd",
    "generation": "7000",
    "tier": "top",
    "matched_keywords": [
      "7900 xt"
    ],
    "title": "Family fight: AMD Radeon RX 7900 XT is up to 7% faster than RX 6950 XT but costs 28% more - VideoCardz.com",
    "selftext": "",
    "comments": [
      "Nice of AMD to literally say to not buy RX 7000 series. I thought those were some third party charts, but no, it's their own charts showcasing how shit value RX 7000 are. Weird marketing strat.",
      "That's why i am keeping my 6900xt for now",
      "You totally should. Upgrading every gen is never a good idea, unless you are moving from something like low-end to high-end. If you already have a last-gen high-end card, there is no point in upgrading to a high-end one this gen.",
      "It‚Äôs wild to me that people upgrade every year. I just built my first pc and I‚Äôm not touching it for at least 3 years",
      "Up to 7% is a lie. Takes a few second to find results that show far more than that.\n\nAnd costing 28% more well good luck finding that because i can't find a 6950xt that much cheaper than a 7900xt in my country.",
      "The only AMD marketing strat this gen had been buy AMD because AMD good Nvidia bad. And people listened because even thought a 7900xt doesn't anything for its price if you post that you bought one you get a slap in the back, if you buy a 4070ti all reditors go out of their dungeon to tell you how bad the 4070ti is.",
      "The problem is that (at least from what I can find) the 6950xt has been better priced. I missed out when 6800xt's were $550-650, so now a $700-750 6950xt is my best bet once I do have the money.",
      "Very few people do that tho. 3-5 years is typical.",
      "The strangeest part is that those are AMD's own benchmark. Showcasing worst gains than most third party reviewers.\n\nWell it's not strange because they picked up e-sport games where they are probably CPU limited, but that's a weird way to market your products.",
      "AMD says you're part of the ultra enthusiast if you buy the 7900 xt  \n[https://twitter.com/amdradeon/status/1618341553587494941/photo/1](https://twitter.com/amdradeon/status/1618341553587494941/photo/1)  \n\n\nSo you're actually paying premium to be part of their exclusive group.",
      "It's chip binning, nothing to do with the overheating issues.\n\nAll chip manufacturers do this. Intel doesn't actually produce loads of different CPUs. They make one product, the best performing get core i9 designation, next batch below are i7, then i5, then i3.  It's all about avoiding waste and minimizing production cost.",
      "The biggest con AMD & Nvidia has going is convincing consumers that the latest generation is worth what they're asking..",
      "The strategy of the 7900XT is to sell 7900XTX chips that have a manufacturing defect. That's the whole point of the chiplet technology.\n\nIt's like when AMD put out the 3300X: they just so happened to have a bunch of chiplets that had 4 good cores, so they slapped them onto a CPU and sold them until they ran out of stock. Or like the 4500, which is likely just a batch of leftover Zen 2 chiplets that had cache defects.\n\nThe 7900XT is both an attempt to recoup money on bad stock, as well as acting serving as the [\"decoy\"](https://www.businessinsider.com/how-medium-size-tricks-you-2014-5) to get you to either help AMD move more 7900XTX's (\"it's only $100-200 more!\") or clear old stock (\"the 6950XT is $200-300 less!\").",
      "https://cdn.videocardz.com/1/2023/01/RX7900-RX6000-FPS-PER-DOLLAR.png\n\nThat's just hilarious that AMD would use frame per USD like that. I mean I guess I respect the honesty?",
      ">Very few people do that tho. 3-5 years is typical.\n\ni did it every year simply because i could sell my old xx80 or similiar card and then buy the new xx80 for like 20-80‚Ç¨ on top \n\n&#x200B;\n\nbut yeah... a xx80 or similiar costs this gen from both companys WAY MORE.",
      "On here it seems like everyone has a 4090 but in reality they are the enthusiasts, and they're selling out everywhere because they barely make any. \n\nIt's good buzz and gets the \"Nvidia has the fastest cards\" mindset into the public discourse, even if it's not true for the price. It's the reason people buy a 3050 instead of the same price or cheaper 6600xt",
      "MSI 6800 XT occasionally comes around on NewEgg for around 540. Just got one two days ago.",
      "That 7% figure comes straight from AMD's own website, in case you didn't read the article. As does the 28% price gap.  \n\n\nIf you have results that show figures substantially better than 7%, I am sure AMD would be dying to see them.",
      "how is evaluating 90 class cards on 1080p fps/$ honest?   should have been 4k. Comparing 1080p is misleading, it's the same as using i9 and ryzen 9 cpus and run 4k performance, suddenly they are all the same.",
      "They are trying to sell all the RDNA2 stock I think."
    ]
  },
  {
    "brand": "amd",
    "generation": "7000",
    "tier": "top",
    "matched_keywords": [
      "7900 xtx"
    ],
    "title": "Rx 7900 XTX Just as bad value as RTX 4080",
    "selftext": "RTX 4080 has much better reference cooler , with AMD you‚Äôll give spending $1100 for half decent AIB cards.\nAnd considering the extra features of 4080 this card looks even worse . \nScary how such prices have normalized after the pandemic",
    "comments": [
      "if Nvidia was crucified for $1200 4080 then these AMD card deserve same energy\n\nYou know GPU space is screwed when best value of this gen is $1600+ GPU that is a halo product, PC gaming is becoming extremely expensive hobby that is less and less worth chasing\n\nseriously considering switching to console as I have less and less time for gaming",
      "Goodbye $700 high end GPU‚Äôs. Won‚Äôt this hurt both companies in the long run? If I‚Äôm paying over a thousand for a GPU, I don‚Äôt know about everyone else but I‚Äôm not going to be updating  that GPU until I really have to. Considering that GPU basics are a computing die with a pre made heat sink, I think they need to rethink their cost ratios.",
      "According to the rumors, AIB cards will cost the same as the 4080s. So it's even worse value, which is pretty fascinating, because 4080 is shit as well.",
      "so brave of you to not upgrade your very recent hardware.",
      "Yep agreed 100%, both shouldnt be more than $750",
      "You are correct. The inefficiency of the 7900XTX is scary, in Europe the 4080 will be the same effect ive price considering the Power draw during multi Monitor usage, gaming and Video Playback. And no, the multi Monitor part is confirmed to NOT be a Bug. PCGH asked AMD and this was their anwser:\n\n>The AMD RDNA3 architecture is optimized to ensure responsive performance with the highest refresh rates. The newest high-resolution and refresh monitors require significant memory bandwidth and initial launch on RX 7900 series cards gaming cards have been tuned to ensure optimal display performance. This may result in higher idle power and fan speeds with certain displays. We're looking into further optimizing the product going forward.\n\nSadly AMD did not respond to Computerbase on the Video Playback Power draw.",
      "Remember that you don't have to buy the new cards to get good performance. My 3080 will hopefully last me a while at least until the latter half of this gens console games.",
      "I am happy to wait. People need to stop supporting this crap from AMD and Nvidia. No purchases will force them to price correctly.",
      "Yeah, that is the true reason why gaming is a very cheap hobby.\n\nIt **can** be very expensive, but it doesnt ***have*** to be. Unlike many other hobbies you dont get a terrible experience if you are unable or unwilling to pay premium.",
      "This. It's so ridiculous to see people with AMD 6000 series or Nvidia 3000 series GPUs talking about upgrading, they are part of the reason companies are charging so much for these cards.\n\nUnless someone has a 6500xt/3050 level card they have an extremely powerful card capable of running the vast majority of games. \n\nGPUs aren't 2 year products no matter what anyone says.",
      "They will eventually lower prices. If they are basically selling out, who lower them so soon? From AMDs view they may as well make their money while they can. If you don‚Äôt like the cost, what are you gonna do? Buy an Xbox or PS5? Guess who wins again.",
      "Well thats me out ... AMD 150 watts to browse reddit? Joke of a generation",
      "They need to be at least $400 cheaper to be \"great\" cards",
      "Linus Tech Tip showed AMD was aware about the high power draw while idle and working on a fix that should be deployed soon (timestamp: 13:18 on the LTT newest video) Hopefully, it‚Äôs a driver issue and not a hardware one",
      "Both 4080 and 7900XTX would be great cards if both of them were $200 cheaper.",
      "> PC gaming is becoming extremely expensive hobby that is less and less worth chasing\n\nBut you can be frugal on all fronts and still have great value.",
      "Also remember that the used market isn't good everywhere. Not everyone lives in United States or somewhere in Europe.\n\nFinally, also remember that the stock for the old Gen isn't infinite either. It will eventually become out of stock, and it will never return, and then paying that value is the only way to have that level of performance.\n\nHere on Brazil it's quite hard already to buy a RX 6900 XT or RX 6950 XT new..\n\nIn other words: that argument doesn't work.",
      "Yep, value is dead ever since crypto fcked over the market, then pandemic+scalpers and ofc Crypto, \nGood thing Crypto died but the damage is done. This gen does not feel like progress.\nSince the old cards dont get replaced, but just higher tiers in the same product family got added.",
      "The 3000 series and the 6000 series were such a good series honestly. We‚Äôll see how the next gen does but man‚Ä¶‚Ä¶so many good cards came out of that generation and both were like neck and neck almost. Great values on each side too in that series.",
      "Yes, the dollar per frame comparison HUB did showed it to be basically the lowest cost per frame of any card from this or the last gen.\n\nPeople have now switched to saying the power consumption is too high based on the idle consumption which is high because of a driver bug AMD have already acknowledged.\n\nYou'll find threads on new card launches awash with people trying to explain away why they won't be buying one for some spurious reason when the truth is they were never going to buy one anyway.\n\nExpect to see \"hard pass on this one till they get X thing fixed, I'll be sticking with my Geforce 2 MX till the value proposition gets better\" type comments all over the place. Already seen someone with a 1080TI saying it isn't enough of an upgrade... like yeah bro, it's only 6 times faster..."
    ]
  },
  {
    "brand": "amd",
    "generation": "7000",
    "tier": "top",
    "matched_keywords": [
      "7900xt"
    ],
    "title": "AMD Radeon RX 7900XT rumored to feature 20GB GDDR6 memory - VideoCardz.com",
    "selftext": "",
    "comments": [
      "Ohh Boy we have 7950XT coming. Extra Points If They actually name it 7970XT\n\n&#x200B;\n\nWish 7900XT was actually using 384 bit bus like 7950XT.",
      "I think they are just gonna release the 7900xt and 7800xt. I have my doubts they will release a 7800 non-XT at all. I even have my doubts on whether the 7800xt will be a cut down N31...it might just be the full N32. And the 7950xt will probably come later on with faster memory and the full die. I think they are just waiting to see how Nvidia responds once RDNA3 is launched. Titan Lovelace was apparently cancelled or on hold because of power and heat issues.",
      "I still remember the 7870 XT I loved so dearly :) would be a nice surprise to a name like that again but I doubt it.",
      "Nvidia wins by default on popularity alone, not value. The 6900XT was $999 MSRP and the 3090 was $1499 and no one bought the 6900XT (according to Steam survey). Even during the shortages, it was around $1300 and people were still buying $1200 3070s.",
      "If AMD can price this thing around 1k USD Nvidia is toast",
      "Remember under promise but over deliver",
      "A full Navi 31 has 60% more compute than a full Navi 32.\n\nIn any case, it's extremely unlikely that Navi 32 is being released initially at all.  Only Navi 31 would be my presumption.\n\nThe real question is whether they'll release an uncut Navi 31 initially, or reserve that for a counter to nVidia's less-cut AD102 card (4090 Ti, most likely).\n\nSo 7900 XT and 7800 XT, with room for a 7950 XT later, is plausible.  Maybe a 7800 as well, but they'd have to sacrifice silicon to do that.  Not likely to be enough salvaged dies to do it normally.\n\nStill, my biggest concern is pricing.  The fact that old RDNA 2 stock is selling for as much as it is doesn't bode well.  Unless they simply plan to drop prices on those substantially after the announcement to keep it moving.  That's the only way to have the new RDNA 3 cards have sane prices.  Compared to the 6950 XT in particular, as even the lowest plausible card in the new lineup would be more than 50% faster than the 6950 XT, by reasonable estimates.",
      "From the original source: \n\n> The Full-Fat 24 GB & Top Navi 31 bin will be aimed at NVIDIA's full-Fat Ada die (the RTX 4090 Ti). AMD seems very confident that with 20 GB and a slightly cut-down MCM chip, they will sit in a comfortable position against the RTX 4090 and may even outperform it in pure rasterization performance while bringing a big jump in RT performance versus the existing RDNA 2 GPUs.\n\nI *still* have my doubts about this but usually when more and more people start saying the same things (Kimi first hinted it with his polls, then Greymon said it, and now WCCFTech)... well maybe there is a chance after all. But maybe just waiting for Nov 3rd is the best stance to take in this situation.",
      "Yeah I kind of wanted to get the 6950xt to meme on my old Radeon 6950.",
      "If this is true it is an unprecedented move from AMD. Their strategy for ages, has been to release the flagship chip in full fat form. 6900XT was full Navi 21, vega 64 was full 10, Fury X was full Fiji, 290X was full Hawaii, 7970 was full Tahiti, 6970 was full cayman and so on. The only time they brought a cut down chip was with Radeon VII but that was a special case, they did it because they wanted to avoid cannibalization of their own pro cards and that card was of limited scope anyway.\nDeciding to compete vs 4090 with a cut down chip shows A LOT of confidence.",
      "Yes",
      "Ah my baby, got destroyed from The Witcher 3.",
      "Knowing amd they will show charts of how 16 gb is not enough for 4k and you need 20 gb now.",
      "I‚Äôm expecting $1100. Then they can say a 6900XT crushes the 4080 for less money.",
      "The problem here as always is price. AMD probably could add HBM and then the GPU's costs more and everyone is angry.",
      "Chips are made out of ‚Äúwafers‚Äù, silicon discs that get ‚Äúcarved on‚Äù. Each wafer can be made into hundreds of chips but the production process isn‚Äôt flawless. Small particles or other factors can affect the tiny transistors in the surface of the wafer which can result in chips that don‚Äôt have all their units functioning. Instead of throwing these away, companies deactivate the affected areas and sell them in cut down configurations. In AMD case, a 6900XT was a fully functioning Navi 21 chip, 6800XT was a cut down version of the same chip that had some cores deactivated.",
      "I got a 6800 XT at launch myself! \n\nThere‚Äôs dozens of RDNA2 owners.  Dozens!",
      "Double 6950XT core performance, raise TDP, raise clock speed, raise memory speed and bandwidth. If they hit the goal again like RDNA2(6900XT is about exactly double the raw performance of their top RDNA1 card) a ~425W Navi 31 would absolutely at *worst* match a 4090, but *should* be slightly faster.\n\nEDIT: a 6900XT/6950XT has exactly double the specs of the 5700XT. The top Navi 31 die has actually more than double the cores of the 6900 cards(5120 -> 12,280 or something like that).",
      "Sure, but 'Nvidia is toast' just isn't something that's going to happen anytime soon.",
      "You make some really good points. It's also plausible that the reason RDNA2 is still priced where it is is because there isn't that much stock left, so they are trying to get the largest margins they can...unlike Nvidia who has a year's supply still. And yea, they could probably drop prices once RDNA3 is showcased.\n\nGuess we'll see in a couple weeks. I fully plan on buying a 7800xt or 7900xt...but I won't reward stupid pricing. I got the 6800xt  for MSRP because it was an *extremely* fair price for the performance you got from an 8 series. I'm hoping AMD can continue that. Otherwise I will pass."
    ]
  },
  {
    "brand": "amd",
    "generation": "7000",
    "tier": "top",
    "matched_keywords": [
      "7900 xt"
    ],
    "title": "bye nvidia hope and does not disappoint me 3060 ti to 7900 XT",
    "selftext": "",
    "comments": [
      "Make sure you wipe your Nvidia drivers with DDU to avoid clashes",
      "Same here my 3060 12gig oc edition is the last be a GPU on my own I have a Intel b580 but I'm loving it but I want a amd card now since I switched to Linux",
      "That sounds like a nice waste of time. I'd just uninstall the drivers.",
      "AMD is the best gpu for linux, the linux drivers are actually better than the windows drivers and blow the nvidia drivers out of the water",
      "it is actually the case deepcool ch560 digital",
      "7900 will not disappoint.",
      "Unlike Nvidia, Intel is making an attempt to have good drivers on Linux. Wouldn't be surprised if Intel ultimately becomes more usable than Nvidia on Linux.  That being said, AMD GPUs are the main ones you want to use if you run Linux.",
      "20gb is the way! Congrats! ü´°",
      "I just upgraded from GTX 770 to 7800XT too cheer!",
      "Don't need DLSS if you play in native",
      "i did this and it got rid of alot of problems that couldnt be explained ignore the downvotes",
      "Not really. You'll get a fresh system with that new GPU. Sometmes re-installing Windows is pretty good. I do this whenever I change my GPU.",
      "This getting upvoted and the guy above getting downvoted is the perfect example of reddit people being ignorant.",
      "Better yet, I would just reinstall Windows to have a fresh system",
      "lol This how I've been doing it for 20 years when either changing mobo or switching between AMD and nvidia.  I really only have to backup My Documents before I wipe my C: and I'm good.\n\nYeah, I'll \"waste\" half an hour to save myself any future trouble.  Also just gets rid of all the shit I'm not using anyway.",
      "Better drivers + raytracing and they'll have a customer of me next generation!",
      "Bruh just had to include that he has a 5090",
      "What is that little screen thing at the bottom right? Someone got a link to that? Looks neat :o ! thanks",
      "Congratulations on your new card, but why buy a 7900 XT just days before the new gen is announced?",
      "3060 Ti was my last NV GPU too. Lack of VRAM is the worst. Thankfully it was height of COVID so I sold the 3060 Ti for more than MSRP, then turned around and got my 6950XT (new) for a little bit more, and that had The Last of Us Part 1 included"
    ]
  },
  {
    "brand": "amd",
    "generation": "7000",
    "tier": "top",
    "matched_keywords": [
      "7900 xtx"
    ],
    "title": "The 7900 xtx w/ the 550w bios, even on air, is a terrifying beast.",
    "selftext": "",
    "comments": [
      "It makes sense why AMD said they *could have* made a 4090 competitor after playing with the 550W XTX. Hell, the out of the box clocks/perf at 480W stock is probably 15% faster than reference already.",
      "Hotspots were wild for me, UNTIL  \n\n\n* Replaced all pads with putty (upsiren u6) on front and back.\n* Retorqued all screws so that the GPU core's screws were first tightened to stop with just a tensy bit of turn after that, and the rest of the cooler's screws were just to the part of attached, but weren't to firm tight. I estimated that thermal expansion and the pads were causing the core to have less ideal contact, and it appears that was the case.\n* Replaced thermal putty with ptm 7958-sp. This was a paste I applied to the core, let cure for a few hours, and then reassembled the GPU.\n\nEven for this run, the hotspot was still in the 90s, but that's 550w of power being cooled on air (Heck, hwinfo reported like a 670w \"GPU Power Maximum\" at one point, holy shit, but I dunno if to believe that)\n\n&#x200B;\n\nAt 430w power limit I'm still sitting like 62/82. But even with that hotspot the card appears to be performing solidly, and the GPU fan is like 2000rpm, so it's like 60% fan speed too",
      "The price difference is insane. How‚Äôs the RT comparatively?",
      "What are your temps sitting at with it like that? I flashed mine to the 550w bios and am on water. But I‚Äôm fighting the hotspot temp",
      "It's OK. The 7900 xtx stock performs like a 3090 or 3090ti. As good as a 40 series? No. But the card I used in this costs less than 1K.",
      "Definitely not worth the extra $700 for some pretty lights lol",
      "Man thats a lot of power lol",
      "A higher end AIB 4090 would have cost me around 1.8-2K when I got my 7900 xtx for just about 1K. So, 60% cost for 65% performance, in a ray tracing benchmark, isn't too shabby. My raster benchmark vs the best 4090 with my CPU is 82% of performance.\n\n&#x200B;\n\nThe 4090 is the undisputed king. I almost bought a 4090, but just didn't feel comfortable spending that much on a GPU, so I decided to give the 7900 xtx a try (as I was exclusively on Nvidia GPUs from 2007-2022. An early radeon was such a bad experience I refused to use them for over a decade). I''ve been very happy with it.",
      "For the same test the top 4090 score looks to be 65% faster.  A lot of scores are around 50% faster.",
      "And cyberpunk is like \" Nvidia, the game\" so, no wonder it runs better in nvidia hardware.",
      "Same! RT still feels very gimmicky to me even at this point. I rarely ever use it and I can barely tell the difference when I do.\n\nI always thought it was something I'd be completely blown away by but just wasnt",
      "Thats only in cyberpunk and one other game",
      "He meant RT",
      "I feel like visuals have a very real diminishing return as far as performance.",
      "Yeah but they would have been laughed out of the room if they released a product like that.\n\nRDNA3 is already painfully ineficient vs Ada as is at stock clocks.",
      "I flashed my 7900xtx taichi with the aqua extreme bios and with some quick overclocking/undervolting i was getting like 3.3 to 3.4ghz on the core and 2750mhz on the vram. Now it was apparently pulling 600-700w and temps wise it was at like 80ish avg and 90-100 hotspot but for 600-700w thats not bad in my opinion also this was all on air so it probably would be better on water.",
      "The difference is what you'd expect between Gen 3 Raytracing cores and gen 2 Raytracing cores. But slightly better than the Gen 2 of Nvidia. So it'd be the rtx 4000 series is Gen 3 Raytracing cores while the rx7000 series is Gen 2.2 cores. \n\nOverall, you will be able to use Raytracing but not at max. Medium Raytracing basically",
      "I just ordered some upsiren. I‚Äôve been using ptm7950 and a kryosheet. I think you‚Äôre right about the barely tightening the screws. Because i put a clamp on the card while i was running. And I went from 43/95 to 42/63. So it‚Äôs def a mounting issue. I‚Äôm going to experiment some more and see what works too.",
      "You overestimate the 3000-series RT performance. I still have my old 3080 and if I run anything with RT on, it pretty much tanks the performance. Of course, it depends on the game but trying to play Portal RTX for example, absolutely wrecked my performance.",
      "How does this compare to a RTX 4090?"
    ]
  },
  {
    "brand": "amd",
    "generation": "7000",
    "tier": "top",
    "matched_keywords": [
      "7900 xtx"
    ],
    "title": "Cyberpunk 2077: 7900 XTX Pathtracing performance compared to normal RT test",
    "selftext": "",
    "comments": [
      "Fear not, the RX 8000 and RTX 5000 series cards will be much better at PT.\n\nRT is dead, long live PT!",
      "Very nice, now let's see Paul Allen's single digit FPS.",
      "You mean Nvidia is gonna release gtx-rtx-ptx cards? ptx 5060 starting at 1999.99 usd with 8gb vram.",
      "We know RTX 5000 will be great at PT. \n\nAMD is a coinflip but it would be about damn time they actually invest into it. In fact it would be a win if they improved regular RT performance first.",
      "AMD really needs to put out a driver for this but tbh I don't know how much more performance they'll be able to squeeze out with their current RT architecture.\n\nNvidia has highly optimized SER on RTX 40 and dedicated RT cores which greatly reduces stress and latency on the GPU's rendering pipeline when it has to do something as intensive as PT.\n\nHere's hoping with RNDA4 AMD finally releases chips with dedicated RT cores.",
      "I've heard that RT output is pretty easy to parallelize, especially compared to wrangling a full raster pipeline.\n\nI would legitimately not be surprised if AMD's 8000 series has some kind of awfully dirty (but cool) MCM to make scaling RT/PT performance easier. Maybe it's stacked chips, maybe it's a Ray Tracing Die (RTD) alongside the MCD and GCD, or atop one or the other. Or maybe they're just gonna do something similar to Epyc (trading 64 PCI-E lanes from each chip for C2C data) and use 3 MCD connectors on 2 GCDs to fuse them into one coherent chip.\n\nHopefully we get something exciting next year.",
      "Ah yes, I have figured out that I will not be running pt on my 6800xt.",
      "I was not impressed with RT in any games at all (Control, Metro EE, Cyberpunk RT). But this PT shit in Cyberpunk, it seriously looks good.",
      "Sounds like a skill issue. \n\nSimply run the game at 360p upscaled to 1080p with a 30 FPS cap, as was the traditional way of the elder gamers.",
      ">Cyberpunk's PT mode was made by Nvidia developers, not CDPR themselves\n\nYeah, sure. Can you provide any evidence of that being the case? Obviously SOME Nvidia engineers worked on this, but why would you even suggest that CDPR engineers weren't involved? It's an already deployed AAA game built on CDPR's custom in-house engine.\n\nNvidia would be completely in the dark without them.",
      "I wonder if the mortgage companies will catch on and start offering loans for future Nvidia hardware.",
      "Look at that subtle change in the 1% lows. The tasteful frametimes.\"\n\nHis face creases in horror.\n\n\"Oh my God. It even has room for 24fps cinematic goodness with DLSS3.\"",
      "It also helps nvidia that *they* are the trendsetter, meaning the resultant code will be designed with one primary hw in mind.\n\nNot saying AMD would do anything else in their place, of course.",
      "You aren't wrong but you also got to appreciate the performance levels here, a **4090** only just manages 60fps 4k with DLSS needed. \n\nNo console is ever going to be sold for ¬£1599+, the fact they even have raytracing present is really good as it was present enough to have it enabled for some games which means more games introduce low levels of it.\n\n\nYou also got to take into account that those with slower PCs are also holding us back (to a certain extent), the consoles today are quite powerful and yet lots of PC users still hanging on to low end 1000 series GPUs or rx480s.\n\nAs long as games come out with the options for us to use (like cyberpunk is right now) that's significant progress from what we used to get in terms of ports and being held back graphically. \n\nLet's pray we get significant advances in performance and cost per frame so the next gen consoles can also jump with it.",
      "Lmao PTX 5090",
      "I'm already budgeting for an RTX6090 in 2026 or so.",
      "PT is the ultimate RT. If they try to push PT early on obviously no consumer hardware can run it at all. Imagine if Metro actually have PT when it was released. Not even 2080ti can play it. Now 4090 is good enough to run it at playable frame rate.",
      "Ouch. Sad, really... A 3080 does much better : (\n\nReally, really, wish AMD had tensor cores equivalent components and would perform at least expressively better than the 3080 in Path Tracing with supposedly above tier cards such as 6900XT, 6950XT, 7900XT and 7900XTX.",
      "Everything I've seen online...shows path tracing being much better and nicer than rt psycho. All the videos and screenshots are pretty night and day when comparing.",
      "Think this is the most cope DLSS3 comment I've seen so far."
    ]
  },
  {
    "brand": "amd",
    "generation": "7000",
    "tier": "top",
    "matched_keywords": [
      "7900xtx"
    ],
    "title": "7900x & 7900xtx",
    "selftext": "",
    "comments": [
      "16 fans, super clean, please post specs if you don't mind, congrats and nice work!",
      "R9 7900x, Sapphire Nitro+ 7900xtx, asus x670e-a, 64gb of Corsair Vengeance ddr5 ram clocked at 6000mhz, kraken z73, 16 al120s, lian li strimmer plus v2 cables, 011 evo case, be quiet dark power 1000w psu",
      "Amazing looking! What are those cable extensions?",
      "Needs more fans",
      "Based on the pictures, you might have airflow issues. I would suggest getting some case fans.",
      "üí∏üí∏üí∏",
      "Half the budget was allocated to only fans.",
      "Lian li strimmer plus v2",
      "Because everything else here is a budget build lol.",
      "Definitely someone who doesn't care about electricity bills. 16 fans, why?",
      "So the poors know their place",
      "Sapphire should have made a white version of the 7900XTX, really need some white GPUs on the AMD side, OP really made something unique.",
      "Sapphire ü§§",
      "Did you spray paint the GPU? I have considered it too, but it looks like quite a hassle because of the thermal pads on the metal parts, let alone taking apart the whole card, losing warranty and reducing resale value. I think I will get a Gigabyte Aero 4080 instead.",
      "Now THAT‚ÄôS a beautiful build.",
      "Yes I did spray paint it",
      "It goes on the other side of the mainboard backplate in the O11 Dynamic Evo",
      "Fans don't use that much power.  Choice of GPU like a 450W 4090 instead would be more impactful.",
      "this pleases my ocd, so clean, love those fans!",
      "Not gonna lie, these naming schemes they have are confusing as fuck. I thought you meant you had a XT and XTX in the box at the same time."
    ]
  },
  {
    "brand": "amd",
    "generation": "7000",
    "tier": "top",
    "matched_keywords": [
      "7900 xtx"
    ],
    "title": "My first PC build after 7 years | Nitro+ RX 7900 XTX | i9-13900k",
    "selftext": "",
    "comments": [
      "That's my first PC Build in like 7 years, upgrading from an i7-6700k + GTX 1070. The performance is amazing! The GPU sits at \\~55¬∞c with a max hotspot temp of \\~77¬∞c. It clocks at 2900-3050mhz and fans max out at 2000rpm, being barely noticeable. (I made a custom fan curve) 3440x1440p is really enjoyable now! :D\n\n(P.S.: Uploaded a few days ago, but was taken down due to being posted at the wrong time (against the rules))",
      "That's a very clean build! I'm also upgrading from a 1700x and GTX 1080 to a 5800x3d + 7900xtx. Had to send my reference card back due to hotspot problems. \n\nNow i'm waiting for my 7900xtx Red Devil and a bigger case",
      "do you have to be so rude about it?",
      "Congratz on your upgrade! Same for me, my reference 7900 xtx had the 110c hotspot issue. Enjoy your new parts! :)",
      "Don't listen. That guy doesn't know shit. At the resolution you're playing you won't see a difference.",
      "Thanks! Yeah, I wasn't really paying attention to what's dropping next. However, I think I'll manage the next couple of years with the CPU :D",
      "So jealous of that card. Only seen them for scalper prices on Newegg and Amazon. Found a Gigabyte Aorus Elite XTX on Newegg at \"MSRP\" but still cost too much. Newegg doesn't offer returns on it...Now as I see a bunch of Red Devils and LE online at my local Microcenter for the first time since launch üò©",
      "Highest I've seen it go is 2900mhz, I just tested it in Warzone 2, fans go up to 1500rpm at stock.",
      "future station normal serious dime alleged spotted icky squeamish six\n\n *This post was mass deleted and anonymized with [Redact](https://redact.dev)*",
      "Agree while 75-100% cpu usage, but intel idles @ much lower watts (around 30 vs 50)\n\nSo average might end up being about the same (13900k vs 7950x)",
      "exactly, that's looks great, Enjoy playing",
      "Amd is not your friend",
      "At the time I purchased the 13900k it was cheaper than a 7950x. Also, I heard that the newest Ryzens tend to run kinda hot.",
      "what case is that?",
      "Lol that‚Äôs a 1070 there‚Äôs no way it‚Äôs‚Ä¶ oh yeah it‚Äôs been about 7 years. Damn.",
      "What does it boost to stock? I‚Äôm really curious, I have a red devil coming in a week.",
      "I want the XTX nitro so bad but it‚Äôs too expensive at the moment. Did you get yours on Newegg?",
      "I had my Red Devil boosting to 2.9GHz stock in some games.",
      "I got mine from Mindfactory (Germany), only been in stock twice so far though.. Kinda hard to get one of those rn I guess..",
      "The 7900 XTX was a bit cheaper than the 4080 and the 4090 was out of debate, since it would be overkill on my 3440x1440p monitor. Since I don't care that much about raytracing I took the AMD card which usually performs a bit better when it comes to rasterization. Also it has 8GB more memory :D"
    ]
  },
  {
    "brand": "amd",
    "generation": "7000",
    "tier": "top",
    "matched_keywords": [
      "7900 xtx"
    ],
    "title": "Started my first Mini ITX build today. 7900X3D w/ Sapphire Nitro+ 7900 XTX",
    "selftext": "",
    "comments": [
      "that mobo has one of the slowest post/reboot times for am5",
      "What‚Äôs that red mounting bracket for?",
      "Just went looking myself, without knowing what to search for!\n\nFound it though: \nThermalright ASF-RED AM5 CPU Holder, Corrective Anti-Bending Fixing Frame, AM5 Full-fit Fixed Non-Marking Mounter, AM5 Anti-Bending Contact Frame, CPU Cooler Standard.‚Ä¶ https://amzn.eu/d/7mGrjK9\n\nEdit: Cheaper here: https://www.amazon.co.uk/dp/B0BMX4671M\n\nAlso found this on my travels:\nhttps://www.overclockers.co.uk/thermal-grizzly-amd-ryzen-7000-cpu-guard-th-02r-tg.html\n\nNot sure if I want for my build or not.\nWaiting on 7800x3d, like I imagine a lot of people are.",
      "I have it too. Once you get your bios settings in order it isn't a big deal.",
      "Even 'dialled in' it's slower than the fastest by almost 300%. It's every MSI b650 though, not just the MPG. Steve @ hardware unboxed has done amazing coverage on all the B650s.",
      "Its a LGA frame replacement for AM5. And even though, it may only lead to very minor thermal improvements (like ~ 2c) via increasing contact pressure, the gains are very underwhelming on AM5 as AM5 doesn't have the same IHS bending issues as on the Intel platform. It's mainly for your own peace of mind to prevent thermal paste goo from leaking into the IHS from the holes on the sides of the IHS. There are no downsides to using one, so why not if it gives you less mess to deal with down the line each time you want to reapply thermal paste. I have one on mine as well and it looks cool too.",
      "Not sure why this misconception is still a thing? Is it ATX case manufacturer marketing? Is it a \"bigger=better\" mentality? People with ATX cases trying to justify their case choice? All of the above probably.\n\nJust as an example with your CPU: I'm cooling a 5800X3D with a 47mm tall heatsink and a Noctua fan at 1200rpm and getting 100% of the performance of a stock 5800X3D. Check the sffpc subreddit or forums and you'll see builds like these everywhere.",
      "More here: https://www.tomshardware.com/news/thermalright-reveals-amd-am5-2-in-1-secure-frame-and-thermal-paste-guard\n\nReading the comments, I think it‚Äôs a nope for me. \nThe foam thingy from Thermal Grizzly looks interesting though.",
      "Bro you might want to verify what words mean before you use them, especially when you're new to this.",
      "Have you tried the system out ? If so how is it running ?",
      "It's not.",
      ">2-3 minutes to post\n   \nHoly shit. I had Pentium III systems that boot faster.",
      "> takes 2-3 minutes to post every time. It‚Äôs so annoying. Initially when I bought it it didn‚Äôt support sleep mode or a boot menu at all.\n\nHow is that acceptable in 2023. Anything over 30s sucks imo given my AM4 system boots in c.10s.",
      "7900 levels of master race.",
      "There's a delta of 40 seconds between the fastest and slowest, I don't particularly fancy going back to a 1 minute boot time.",
      "GPUs extend below the PCIe slot.",
      "But look at it, it just pleases my eyes.",
      "Hey! I'm building an AM5 Mini ITX pc aswell. What's that motherboard? Does it have an optical audio interface? I'm looking for an AM5 mini itx motherboard that has it, my only current option is the Asus B650E-I.\n\nYour build is looking good. I'm going to settle with a 7800x3d and a 6950xt.\n\nThanks in advance.",
      "That‚Äôs so true. My msi b650m-A pro Wi-Fi takes 2-3 minutes to post every time. It‚Äôs so annoying. Initially when I bought it it didn‚Äôt support sleep mode or a boot menu at all. Theee was even a bios version when they first added sleep that secureboot could not be turned off. Needless to say I‚Äôm never buying msi again.",
      "I can attest that the 5800x3d is not hamstrung by a Noctua L9a inside a Velka-5 case. It stays quiet and cool during gaming and professional tasks."
    ]
  },
  {
    "brand": "amd",
    "generation": "7000",
    "tier": "top",
    "matched_keywords": [
      "7900 xt"
    ],
    "title": "AMD RX 7900 XT drops to $779, GeForce RTX 40 and Radeon 7000 series now available at or below MSRP - VideoCardz.com",
    "selftext": "",
    "comments": [
      "Too bad that MSRP itself is an inflated price...",
      "We are still expected to pay the mining ROI tax on all these cards despite mining having fucked off now.",
      "How about we are going to use EU prices....",
      "they're just selling at prices people are buying.\n\nPrices come down because sales are slumping - The whales have spent their disposable income on the fastest card they choose to buy. Now the prices will come down and we will be absolutely flooded with cards before the current generation with phenomenal price per frame costs.\n\n6800XT has been a great example of this in the second hand market already but even that price will drop as the 3080 gets cheaper (because for some reason people don't look at benchmarks or buy into brand loyalty.)\n\nI'm just over here wondering why mining cards haven't completely flooded the market and caused a total crash in GPU prices. It's almost like a ton of the sales were to gamers who also mined...",
      "This card shouldn't cost more than $600",
      "I checked the bigger store in my country (Komplett), prices for a 7900xt is between ‚Ç¨1060 and ‚Ç¨1355, with the cheapest models all sold out. It's fucking ridiculous. I paid some ‚Ç¨800 for my 6900XT and that was a \"bargain\". Especially compared to 6600/6700XTs being ‚Ç¨100-150 cheaper. 4070 Tis are just barely cheaper.",
      "Just bought a 7900 XT for ¬£799. Considering XTXs are still ¬£1050+ the XT is now at a better price:fps ratio and what it should have been priced at launch.",
      "> I'm just over here wondering why mining cards haven't completely flooded the market and caused a total crash in GPU prices. It's almost like a ton of the sales were to gamers who also mined...\n\nMining cards did flood the market. [New GPU sales are at a 20 year low.](https://www.tomshardware.com/news/sales-of-desktop-graphics-cards-hit-20-year-low) Nvidia and AMD are choosing to keep prices high and forego profits because they're hoping to reset pricing expectations. It won't work.",
      "Ppl act like cannibalisation isn‚Äôt a real concept. Don‚Äôt know why people would ever expect a 7900xt to drop below this sorta price when there is still ample supply of 6950xts at around the 600-650 mark. It‚Äôs also the same reason why AMD are so slow to launch the 7800xt and lower. Those price points are served by rdna2 and all launching the full rdna3 stack would do is hurt their own profits and piss retailers off by forcing rnda2 prices down even lower",
      "It‚Äôs really a 7800XT, so I‚Äôd accept $650-700. If you were talking about 7900XT.",
      "Jensen did the same thing the car industry did. I'm just gonna buy used until these CEOs stop their cocain and hookers party thanks to \"inflation\"",
      "Its a mix of people buying and AMD/NV not mass producing. They clearly did not expect the POS merge to take place last fall (but even the cryptomining industry thought that wasn't happening due to how often it was kicked down the road).\n\nThey still have mountains of 6000 and 30 series cards that they are trying to hawk off because crypto crashed in late 2021 and slowed the roll on that mining craze.",
      "AI is sorta weird.\n\nAn average consumer can't really make money off that. You can use it with StableDiffusion to make some fun pictures and memes but their monetary value is about $0. At higher grade - like, say, game development - you also don't really need any computer clusters for this, there are no streamlined tools and processes and output you get is kinda garbage. \n\nWhereas professional grade cards require specs way beyond any home class GPU. anyway Want to run GPT-4 locally? Well, a decent language model needs 400GB VRAM. As in - 5x A100 80GB cards for $12000 each.\n\nYou are a Radeon user? Well, screw you then, best you can have is ROCm with 30% increased memory consumption and 50% higher chance of crashing compared to Nvidia.\n\nBoth AMD and Nvidia have already \"secured\" their consumer grade cards from AI training, it's a completely different stock with significantly altered feature set - 20-24GB VRAM sounds like plenty for a consumer but for a datacenter this is woefully insufficient.\n\nPlus you can't really use any sort of AI by just renting an office room and shoving 50 GPU setup in there, a very common scenario in the mining era. Instead you would need to be a billion $ business with top of the line PhD researchers to advance your chosen field of study - be it sound synthesis, image generation, anomalies detect, medicine and whatnot. Barrier of entry to the lucrative part of the market is extremely high making it significantly different from mining.\n\nSo it doesn't explain any sort of rise in GPU pricing. Your usual home class card would never become a capable AI device - you would need major infrastructural changes. Sure, one can argue that you could just build these instead of consumer ones but... demand is also not as huge as you may imagine for now. There's also a severe shortage of skilled workers that can make any use of these which significantly limits growth (and it's probably why for instance you hear about Elon Musk whining that such development should be stopped for 6 months cuz he couldn't secure his piece of the cake yet).",
      "At least the 6000 cards got price reductions. 30 series is still charging above MSRP everywhere I've seen, let alone actually going below MSRP.",
      "ITS MY TURN TO SHILL FOR THE BILLION DOLLAR COMPANY!!!!!!!",
      "6800xt launch: 650$\n\n\nThey made it clear the 7900xtx is the top of the stack, nothing better than that in the pipes\n\nThat means the 7900xt is the 7000 series 7800xt, and the 7900xtx is the 7900xt\n\nThey can play games with names all that they want. Still 180$ over priced\n\nKeep the prices up till Battlemage launches, Radeon, and you'll see just how well received this Nvidia-esk gaslit marketing is by the gaming community",
      "yes and no, at 1440p maybe not would say a 7900xt is fast enough to run native and it looks better. For 4k no argument there dlss is a killer feature and quality should basically always be enabled. Mind you at 4k fsr quality is good enough to pass.",
      "Yeah..like 1200‚Ç¨ for a 4070ti or a 7900xt..",
      "If you think pricing the 7900xt at $779 is competing on all cylinders, then I shudder to think what you think true stagnation or price gouging looks like.\n\nThis entire generation is a slap to the face of all consumers and I'm not sure which company is worse: The dicks who raised the price beyond any modicum of reason (nvidia) or the assholes who decided that not rocking the boat of the newly established status quo was a good idea (AMD).\n\nThe ONLY reason they have to keep dropping the price on these cards from their original $899 is that nobody wants them and they are still trying to find the most absurd price that the market will allow them to be unloaded at.\n\nEDIT: And gaining market share? Get real. It's been almost six months and the RDNA3 cards still aren't showing in the steam hardware survey.",
      "It's the AI tax now not minig"
    ]
  },
  {
    "brand": "amd",
    "generation": "7000",
    "tier": "top",
    "matched_keywords": [
      "7900 xt"
    ],
    "title": "AMD Radeon RX 7900 XT price drops to $762, now 15% below MSRP - VideoCardz.com",
    "selftext": "",
    "comments": [
      "Also, the XTX finally hit the ‚Ç¨1000 mark in Europe.\n\n(Hellhound model @ mindfactory)",
      "Dude this *is* the 7800XT.\n\nAnd the 7900XTX is really the 7900XT, just with an extra X.\n\nAMD's naming schemes are dumb and inconsistent.",
      "It's really not *that* cheap even at $762. Though it's another step in the right direction. AMD usually gradually lowers its prices until they reach their sales target. Can be seen with 7000 series cpus, and all gpus. nvidia does not do this at all.",
      "Imagine if it's released at 699. It will probably be at that price in a month.\n\nThe amount of positive press coverage AMD would have got would have been incredible, a 35% performance increase for 50 dollars more would have been a great upgrade. Instead the card is saddled with poor reviews that is not even remotely indicative of its actual value.",
      "At this rate there won't be a 7800XT. They'll just drop the price of this one instead. \n\nNot that that would be a bad thing. Would sting for early adopters though.",
      "That's 150 euros below MSRP BTW. In Europe the taxes are included.",
      "Now we're getting somewhere.",
      "Finally someone gets it. This was just amd's version of launching two 4080 cards",
      "I guess earlier on they expected it to be faster and pitch fine as a 7900. But then they missed their performance targets, shrugged and just released it anyway to see what would happen. \n\nIn an ideal world they'd have renamed it a 7800XT and released at $700. But they didn't. \n\nNaming is meh anyway. If it gets to $700 though I wouldn't be surprised if we just don't see a 7800XT at all. Unless they pitch it at $550 ish and are about to pleasantly surprise us with a $250 7600XT leaving room in the middle for the 7700XT.",
      "I just got a Sapphire 7900XT for $800, guess I‚Äôll return it to save $38. \n\n^/s",
      "Still not good enough. This thing is only 35% faster than the 6800 XT - it should retail for the same MSRP.",
      "Ouch! I can definitely see how that hurts then!",
      "More like 80 below, but yeah.\n\nUpgrade time soon :)",
      "This is too expensive still I will wait for a larger drop.",
      "Meanwhile in Canada...\n\nHa ha.. hah... Ha...\n\nü´†",
      "Yeah the naming this gen for amd is off. Not to mention the xtx is a 80 series. The 7900xt is a 70 ti. \n\nSo instead of the 800xt fighting the 70(ti), its probably doing a tier lower to 60 ti",
      "Canada computers has an MSI 7900xt for 1089 (799usd) or 1329 for the xtx (976 usd)",
      "Same brother, but then i look at my game library, at the fact that i can play them at 60fps+ 1440p at great quality, newest games are no problem to run and i realize that i don't need more. Yes i would like more, but don't need it. You gotta be proud of your current gear.",
      "Noooo, sapphire better",
      "Lol the 7900XT should have MSRP of $500 or less, the only reason why it is so high is because AMD saw nvidia prices and said \"if they're price gouging, we will too. What are they gonna do, NOT buy?\" That's the thing, we have to stop being impressed with a 15% price reduction WHEN IT STILL COSTS TOO MUCH, and simply not buy."
    ]
  },
  {
    "brand": "amd",
    "generation": "7000",
    "tier": "top",
    "matched_keywords": [
      "7900 xtx"
    ],
    "title": "AMD Radeon RX 7900 XTX now available for $849, Radeon RX 7800XT drops to $449",
    "selftext": "",
    "comments": [
      "Still not cheap enough.",
      "7800 XT is well priced, though would've been great if it had been that at launch, when fewer people cared about RT",
      "Not in EU lol\n\nIts still 1100$ and 4080S 1200$.....",
      "Meh, the 6800 XT was already sub-$500 when the 7800 XT launched. For minimal performance gain and a 3-year release gap, being the same price was crap. 10% off a year later also sucks.",
      "Another week another AMD consumer end price cut, luckily the economy is doing great and they're a data center company now...\n\nRight ?",
      "Oh look, the Nvidia fanboys are here already claiming the cards are still too expensive.\n\nWeird that I don't see that for the 4080 selling at 1050-1200 still and the 4090 going above 2000 again.\n\nI wonder how much Nvidia pays in marketing lol",
      "I use two 7800xt in my ai home labs and they‚Äôre so, so good. \n\nWorth every penny.",
      "Always the same, US prices are without tax.",
      "I think it‚Äôs odd that there was a brief window to preorder a Sapphire 7900xtx for around $830 soon after launch (with rebate) when the 4080 was going for $1300.  And the 7800X3D cpus were everywhere at list price (or cheaper at Microcenter). \n\nNow after all this time the price -just- drops to $850? And the X3D is sold out selling for higher? This has been such a weird cycle. The only time when the smart value move was to buy a video card and CPU at launch instead of waiting. This is so messed up.",
      "Amd is just being too stingy with their price cuts. It's absurd to me that they would rather price drop the 7900 xt to 660 one day, then the next day they drop it to 650. They need to stop playing games and just give them reasonable price cuts instead of just moving the needle slightly every day. It doesn't surprise me that nobody wants to buy amd gpus at this price, just give us reasonable prices and people would be interested.",
      "These prices are still pretty ass ngl. We're at the end of a product cycle for amd gpus. Nobody is really gonna want a mid level previous gen card when they can just wait a few months to buy current gen and the 7900 xtx is way too overpriced. Realistically it needs to hit at least 750 if not around the 700 for people to consider.",
      "AMD shot themself in the foot in a way that not even Nvidia did by having the 6800 XT available at essentially the same price and performance of the 7800 XT new. The 4060 Ti was marginally worse than the 3070 but about $100 (20%) cheaper. Both suck because they‚Äôre not offering what‚Äôs worth an upgrade Gen over Gen but AMD was particularly shitty with the 7800 XT.",
      "People have been calling Nvidia cards overpriced since they launched. The 4090 at $2000 is just atrocious but at least it has value in ML applications. The 4080 super being $1200 is just shocking. \n\nThat doesn't stop the AMD cards also being overpriced also",
      "Exactly this.... Just that they are missing that Nvidia is restricting supplies to hike prices again üòÇüòÇüòÇ\n\nNvidia and discounts dont exist lol",
      "how much do you people think taxes are like srsly 849 x 1.2 is not $1100 and that's on the higher side of sales taxes üíÄ",
      "6800 XT is not available in most markets, it's been a clearance product for 2 years now",
      "Nvidia's bullshit isn't justification for AMD's. They can both eat crap for this generation.",
      "Well idk what they mean with not in the EU, because you can get a XTX for 880 euro in the Netherlands, which is 966 dollars, and that's with much higher taxes than in every US state.",
      "I'm not surprised that we got another price cut tbh. This is like the 3rd or 4th price cut this week. They have a lot of old inventory just sitting on the shelves that no one is buying. On top of zen 5 flop amd is desperate to sell people anything. Their 3rd and 4th quarter earnings for 2024 are gonna be horrendous.",
      "EOL is end of life - no more support. They will be supported for years. The term that you‚Äôre looking for is EOS - end of sale. Like the 6900 XT before it discounts will come until stock is gone. Time to make room for next gen."
    ]
  },
  {
    "brand": "amd",
    "generation": "7000",
    "tier": "top",
    "matched_keywords": [
      "7900 xt"
    ],
    "title": "[HUB] Reddit Users Expose Steve: DLSS vs. FSR Performance, GeForce RTX 4070 Ti vs. Radeon RX 7900 XT",
    "selftext": "",
    "comments": [
      "> As usual reddit was wrong\n\nThis tends to be the case, yes.",
      "Look at the bright side. No more upscaling for head to head reviews . Easier, less time consuming for HUB . I see this as an absolute win",
      "it's generous to expect professionalism from a reddit mod, they're usually the most cringe people on earth",
      "To make future apples-to-apples benchmarking more easily understood, they won't be using either DLSS or FSR upscaling, so 1440p and 4K will be native, even if that results in less practical framerates.  \nViewers can decide what upscaling tech they want to choose and numbers to compare, as any apples-to-oranges combos vary between games and resolutions/acceptable fps (though on average DLSS vs FSR gives the same fps on the same hardware and a slight edge to DLSS quality).  \nProduct release reviews will have upscaling testing sections.",
      "Once again, sound methodology beats rabid moronic conspiracy theorist  weak minded posters.",
      "Upscaling is not truely indicative of raw performance. Its a cheat.\n\nIts like saying for this 4k test we set the resolution to 1080p and set SMAA to 4x\n\nUPDATE: A lot of people think I'm saying that the technology is cheating, but it was in reference to benchmarks and other evaluative tests. For the end user experience they are a win-win with better frame rates and relative image quality.",
      "It was pretty harsh in /r/amd too. The moronic quote is a mod here...",
      "in last 2 week ago, response from /r/hardware and /r/nvidia was harsh. this bench proved How much they're deep at fanboy/clueless.\n\nNo matter what HUB will do, Anti-HUB always finds any excuse.",
      ">looks better, performs better\n\nit clearly does not perform better did you not watch the video?",
      "I once got banned from a mod cuz he had a different opinion",
      "The Reddit hivemind once again rears its ugly head",
      "Thank you for properly answering my question, this seems to be the one that actually makes sense. And i agree with this approach as Native benchmarking just like before is the mostly the safest and most neutral approach. I see no reason to change it and i am glad HUB followed that instead.",
      "TLDR is basically that many reddit users are clueless, which is unsurprising.",
      "I wouldn't expect any reviewer to do that\n\nThe majority of people won't manually change the DLSS version, they'll set and forget",
      "HUB did 7900xt vs 4070ti benchmark and used fsr on both cards for few games, reddit didn't like that. This is Steve response and shows that DLSS and FSR have pretty much same performance",
      "> rabid moronic conspiracy theorist\n\nBasically 80% people behaving online, regardless of topic. That is the new \"default\", everybody is \"attacking\" them, everybody has to constantly pledge alliance to a multitude of groups and \"camps\", there is nothing you can do, but \"knife out\" when you open the comment section. Sprinkled with low to zero knowledge about anything.",
      "Can anyone TLDR? Don't really have time to watch the entire thing.",
      ">No more upscaling for head to head reviews . Easier, less time consuming for HUB . I see this as an absolute win\n\nI think its fair. upscalers are separate from performance. Nvidia might not like it, they want to see the frame generation everywhere.",
      "Spoiler: he didn't. \n\nNot sure why it's so hard for someone to admit they were wrong.",
      "There's also a whole lot of not understanding the basic principles of experimental design. You can't cross compare GPUs and upscaling software in a GPU benchmark, because you're trying to measure one dependant variable with two independent variables. It's a complete joke from a science perspective, but I doubt most of the people here have done a college level science course to know that."
    ]
  },
  {
    "brand": "amd",
    "generation": "7000",
    "tier": "top",
    "matched_keywords": [
      "7900 xt"
    ],
    "title": "[HUB] $900 LOL, AMD Radeon RX 7900 XT Review & Benchmarks",
    "selftext": "",
    "comments": [
      "If they called it a 7800 xt, priced it at $699 thing would sell like hotcakes",
      "What a harsh and absolutely deserved title. AMD needs to catch a lot of negative Feedback for this whole Release.",
      "So the 7900xt *barely* beats the 6950xt overall and even *LOSES* to it in some cases? LOL",
      "But then they'd need to supply enough of them to meet market demand and would quickly run out, leaving money on the table.",
      "Maaaaaan, and I was fuckin waiting to buy one.\n\nWelp, see yall when RDNA4 releases",
      "There must be something seriously wrong, either with drivers or the HW, for ~~80 CU~~  84 CU 320 bit bandwidth RDNA3 to lose to 80 CU 256 bit bandwidth RDNA2.",
      "Fr, they literally did every scummy thing NVIDIA did but to a lesser extent and everyone‚Äôs treating them like saviours. RTX4080 12/16GB was a complete scum move, but the 7900xt and xtx is totally epic and not the same thing. And oh boy only $1000!",
      "AMD's problem isn't as much what they can produce/sell as much as it is hurting their reputation.  People complain about 'people will pick Nvidia anyways', but that's because Nvidia has built themselves a reputation of having the superior technology.  Which is *mostly* deserved.\n\nYou're right that if AMD is only ever going to produce a small amount of GPU's that they can get away with this, as they dont have a ton of stock they actually need to sell through, but if they are going to insist on GPU's only being some small part of their business without any plans to ramp it up with all the extra money AMD has nowadays, then I'd say that's worrying for Radeon department in general.  I mean, this will necessarily mean they get less funding as well, cuz why pour tons of R&D into a market you dont plan on making much money from, ya know?\n\nIf AMD aren't gonna play the value game, and aren't gonna try and compete on technology, then I simply cant blame anybody who 'goes with Nvidia anyways' at the end of the day.  I mean, fuck Nvidia right now and fuck anybody buying anything Nvidia at current prices, but just generally, I will not blame people for *wanting* Nvidia over AMD.  They're simply better products.",
      ">Welp, see yall when RDNA4 releases\n\nI bet that will also finally be the year of the Linux desktop.  /s",
      "Damn, a strong competitor for the 4080 in the \"worst value\" product category",
      "I remember rumours from MLID that the Navi 33 matching N21\n\nBasically the 7600xt matching the 6900xt\n\nNow its looking like the 7800xt will match the 6900xt.\n\n\nThat guys a fucking clown and anyone who believes him is a bigger one",
      "Tldr;\n\n16 Game Average FPS - \n\nAt 4k,\n\nRX 7900XTX - 113 FPS\n\nRTX 4080 - 109 FPS\n\n**RX 7900XT - 94 FPS**\n\nRTX 3090Ti - 90 FPS\n\nAt 1440p,\n\nRX 7900XTX - 181 FPS\n\nRTX 4080 - 180 FPS\n\n**RX 7900XT - 158 FPS**\n\nRTX 3090Ti - 145 FPS\n\nAt 1080p , \n\nRX 7900XTX - 221 FPS\n\nRTX 4080 - 215 FPS\n\n**RX 7900XT - 201 FPS**\n\nRTX 3090Ti - 180 FPS\n\nRT performance for heavier RT games like Cyberpunk and Control is below the RTX 3080 while lighter RT games like Far Cry 6 and Resident Evil Village has it perform above or on par the RTX 3090Ti . Games like Deathloop and Metro Exodus EE has it performing on par with the 3090 in RT\n\nPower Consumption while gaming is slightly below or on par with the 4080 depending on the game\n\nThe RT performance and power consumption figures are also taken from the [benchmarks done by TPU](https://www.techpowerup.com/review/amd-radeon-rx-7900-xt/)",
      ">Fr, they literally did every scummy thing NVIDIA did but to a lesser extent and everyone‚Äôs treating them like saviours.\n\nNobody is treating them like saviours. Reddit has been super negative since embargo lifted. Even the most positive reviews are at best recommending these cautiosly. Wtf is this take?",
      "It's simple folks, if you are looking for a high end 1440p GPU, just get an RX 6800 XT for less than $600 and just skip this shitshow.\n\nWhy pay at least extra $350 more for roughly 30%-35% more performance?",
      "You mean the RX 7800 review, right? Right?\n\nI can't wait to see the 7800 XT reviews, the whole masquerade will be complete and AMD exposed - little to no **perf/$** improvements compared to 6800 XT for all higher-end parts - just as on nVIDIA with the 3080 at 699$.",
      "Wow, so bad he told AIB partners not to bother sending any more in for him to review. Don't think I've ever seen a review that bad before.",
      "Fuck it I'm buying a used GPU",
      "You forgot the biggest part: that 6950XT beat it in like 1/4 of tests, for 2/3 the cost.",
      "Even worse, the 7900XT is 84 CU and each CU has double the power theoretically.",
      "Asking all Aib to not send their 7900 XT is something I never saw before. This card looks worse than 4080..."
    ]
  },
  {
    "brand": "amd",
    "generation": "7000",
    "tier": "top",
    "matched_keywords": [
      "7900xtx"
    ],
    "title": "My 7950X3D + 7900XTX Build",
    "selftext": "",
    "comments": [
      "HOW IS EVERYONE GETTING THESE 7950X3Ds they don‚Äôt fucking exist in any store",
      "Absolutely beautiful! Well done!",
      "I got lucky and snagged one from Amazon for MSRP on launch day.",
      "To make the computer go brrrrrrr",
      "It came with the GPU itself. Was a bit of a pain to install but has been working well.",
      "Wooo boy that‚Äôs clean!",
      "I had one of those In Stock Alert apps, the second it alerted me that it was back in stock in Newegg i was quick at buying it till my bank flagged it as a fraud then i immediately reordered and got lucky lmao still sold out up to this day",
      "Where did you get that anti sag bracket for the gpu? I'm looking for a good one like that for my 6800xt",
      "Been there, done that. I wanted to go back to the nice simplicity of air cooling, and this thing barely has to run to keep the CPU at a nice cool temp.",
      "Fractal Design Torrent (White RGB TG Clear)",
      "Classy ü§ù",
      "[This case was designed for air cooling. So no, it‚Äôs not.](https://www.fractal-design.com/products/cases/torrent/torrent-compact/white-rgb-tg-clear-tint/)",
      "Glad I'm not the only one who found it a bit annoying on the install lol",
      "Confirmed, got one to make computer go brrrrrr.",
      "Spray paint an old card‚Äôs shroud and buy badges off aliexpress‚Ä¶ post pics for points‚Ä¶ Nobody knows for sure.\n\nI knew a dude that changed his vanilla mustang into a cobra with badges and an exhaust. ü§∑‚Äç‚ôÇÔ∏è\n\nPS: That PC looks so sweet‚Ä¶ I‚Äôm jelly.",
      "Cause I got this GPU for $1030, and at the time I bought it, most 4090s on the market were $1800-$2000 or more. The 4090 isn't double the performance so it's not worth double the price for me.",
      "Probably a 3rd party scalper in their marketplace.",
      "Why? This case was primarily designed for air cooling. Depends a lot on which CPU is being used also.",
      "Looks incredible! Well done.",
      "XFX good damn choice"
    ]
  },
  {
    "brand": "amd",
    "generation": "7000",
    "tier": "top",
    "matched_keywords": [
      "7900 xt"
    ],
    "title": "AMD Radeon RX 7900 XT drops to $619 for the first time",
    "selftext": "",
    "comments": [
      "Not the first time, ASRock's Phantom Gaming OC was the same price a month and a half ago, and at that same time Sapphire PULSE was $5 more.\n\nAlso, weren't there rumors a while back were saying the best RDNA4 was supposed to have 4070ti/4080 performance?..\n\nThen again, RDNA3 was supposed to be a lot better than it ended up being, so who really knows...",
      "Both XT and XTX are becoming¬†quite attractive products, not gonna lie.",
      "Wow, its dropping to a price it should have launched on.",
      "It also really doesn't make sense to buy a high end gpu at the end of a product cycle. Not only that but black friday is in about 8 days anyways and it's almost guaranteed that the 7900xt will be below 600 dollars. For some reason if you really wanted a 7900xt instead of waiting for the next generation of gpus, you should just wait cause it makes no sense to buy now when in a week time it will be even cheaper.",
      "I bought a 7900xtx refurb for around 750 and can't say I'm mad to be honest. I use it on my htpc and game pretty much at 4k and it just rips.\n\n\nThose prices are what I like",
      "I picked up the 20gb 7900xt recently and I'm happy. I'd rather get this than spend an additional ¬£140 it would have cost for a 12gb 4070 S.**\n\nRT is not important enough for me to pay Nvidia ram tax!\n\n**Edit - it was a 16gb 4070 ti super.",
      "Also its been reported that AMD over produced this chip. Its the reason we got the 7900gre. So they can keep reducing that inventory. If there was some forethought. They would flood the holiday sales period with GRE's for $429",
      "if you think rtx 4000 and rx 7000 are 2 years old",
      "Nobody scalps Radeon. There‚Äôs not enough people who want Radeon GPUs for scalpers to take the risk.",
      "Please show me hard facts that that tariffs will be in place before the 5080 launches and show me where it's 1500 dollars guaranteed. There were rumors that the 4090 would be 2500 dollars back in 2022 and that it would consume 600 watts. None of these were correct. Until you can provide actual facts of these things occurring, you're just talking out of your ass.",
      "I wish these price changes actually had an impact globally but it only seems to be effective in US and what not. I just bought a 7900 XT like a week ago and with todays conversion rate it's about $850.",
      "Canadian here. Pay big money for everything.",
      "Worth buying a GRE on BF? I‚Äôm looking at replacing my 1080 and want to hedge against potential tariffs",
      "Oh. So you are also paying big money for gpus.",
      "I live in southeastern europe. Prices are like double that. Why do i even bother with these posts i wonder.",
      ">But buying into it today at this price is just not worth the saving\n\nI would disagree with this assessment but it depends on what you're doing with it. It's generally 4080-4090 levels of performance for 20-50% less money and with more VRAM than anything except a 4090 which is nice for loading large ML models if that's your bag.\n\nThere are other nice to haves as well. DisplayPort¬†2.1, USB-C so you can use PSVR2 without an adaptor, normal power connectors.\n\n>gimped RT performance¬†\n\nBe honest, how often are you playing a ray tracing game? In the very few games where RT adds anything the 7900XTX performs around [3080](https://www.techpowerup.com/review/cyberpunk-2077-phantom-liberty-benchmark-test-performance-analysis/6.html) to [3090ti ](https://www.techpowerup.com/review/avatar-fop-performance-benchmark/5.html)levels which is hardly 'gimped'.\n\n>the worst upscaling solution on the market\n\nIt supports TAA, TSR, IGTI, XeSS, FSR, and whatever other custom temporal upscalers exist. The only upscaler it doesn't support is NVIDIA's proprietary DLSS. Not that that matters much since FSR 3.1 is [very close in quality and performance](https://www.techspot.com/review/2860-amd-fsr-31-versus-dlss/) and we know AMD is [continuing to invest in FSR](https://www.tomshardware.com/pc-components/gpus/amd-plans-for-fsr4-to-be-fully-ai-based-designed-to-improve-quality-and-maximize-power-efficiency).\n\n>I bet you anything in the next two years, if you are targeting around 90fps, 4070 TiS will give you better visuals\n\nAnd I bet you that in two years time the limited 12GB VRAM on the 4070Ti will result in some sub-optimal gameplay experiences. Avatar already hits 12GB in 1080p Ultra, The Last of Us Part 1 hits 13GB at 1080p Ultra.\n\nThe 4070Ti Super with 16GB is much better off but even that's also going to start hitting walls in 2-3 years.\n\nIt's hard to have better visuals when you're running out of VRAM and have to drop settings.",
      "This card's price should've never been higher than $599~550 on release. it was the successor to the 6800 xt.",
      "Crazy to think the sales price is $619 lol",
      "bought 6950xt last BF.  \ncant say I am looking for an upgrade anytime soon even at 4k.",
      "I think the rumor was a $500 card to match the 7900XTX‚Ä¶we‚Äôll see if that happens."
    ]
  },
  {
    "brand": "amd",
    "generation": "7000",
    "tier": "top",
    "matched_keywords": [
      "7900xtx"
    ],
    "title": "Dear 7900xtx, I‚Äôm so sorry. ",
    "selftext": "\nSo for context I have a 13700k that I bought at the beginning of 2023 and a 7900xtx. Well unfortunately I suffered from the intel stability issue about a half of a year in that caused major instability, performance issues, and other problems that got worse over time. So earlier this year I had to finally RMA the chip as it finally just like gave out even on complete stock settings. So I get the new processor and I can finally use my computer like I wanted without crashing every couple hours and everything seems okay at face value until I start gaming. \n\nNow on not very demanding games such as Skyrim, Pathfinder games, Fallout 4, and the like it was running fine but anything newer than like 2022 was a hit or miss if it ran well on my computer. I was stumped, everyone seemed to having a grand ole time on specs equal and worse than mine. I wasn‚Äôt able to get through like 10 minutes without having unexplainable frame drops or hitching and stuttering during gaming. Turns out after a period of not gaming for awhile due to college I find the motherboard I upgraded to (Z790-F gaming WiFi), since presumably I bought it, had a broken PCIE slot which was limiting my card to PCIE x1 4.0 instead of x16 and wouldn‚Äôt change no matter the load.\n\nNeedless to say I was not happy after the discovery and my own ignorance. Ended up RMAing the motherboard and rebuilding and holy moly the rig works beautifully for like the first time in over a year. And hot diggity damn the 7900xtx is way faster than I ever thought it‚Äôs unreal. I can‚Äôt believe put up with that for like a year.\n\nCheck your PCIE speed people, don‚Äôt be like me. \n\nTLDR: had to RMA a faulty CPU due to stability and performance issues only for them to remain, find out it‚Äôs also the motherboard running at the wrong PCIE link speed cause the slot is broken.",
    "comments": [
      "I use GPUZ to check the slot is running at the advertised speed plus ReBAR is working",
      "Had a friend  running his 7800xt and complaining that it was stuttering all the time in light games like rocket league and after a bit of fiddleing i checked the AMD software and saw pcie 4.0 x 1. He had not properly inserted the GPU into the slot... After he fixed that everything ran smoothly.",
      "Definitely something I‚Äôve since downloaded, after my experiences I now have a sorta checklist to go through to troubleshoot now if anything happens similarly lol",
      "this is why we don't do intel",
      "FWIW I‚Äôm on a 9800X3D with a 7900XTX as well, but based on the motherboard design and my needs for storage, I have the card only running x8. Games still cruise at max raster settings on all kinds of stuff from CS2 to Satisfactory at well over 100 fps at 4K. The card is an absolute beast, and while I could move cards around to favor GPU slot data rate over storage rate, benchmarks suggest it wouldn‚Äôt make much difference going to x16, so I‚Äôm leaving it be for now.\n\n(My motherboard is a Gigabyte x870 variant.)",
      "Not me running to check my 7800xt because I sometimes get stuttering in Rocket League",
      "You would think Windows or the Adrenalin software might identify that and give you a notification that something might be wrong... at least it would be a good idea.",
      "What is that checklist?",
      "That's why when you get a new GPU you run a Furmark or any stress test it on your GPU and compare it with other people and see what they got.",
      "MicroCenter ftw",
      "Must be nice to have a 9800X3D",
      "Thanks for the feed back and warning\nAnd people always seem to accuse amd of having bad drivers...",
      "I had a 6700 XT slotted into the bottom PCI.E slot of the motherboard for 1 and a half years, not knowing it makes a difference. (first PC I built myself).\n\nI always had a feeling that I was underperforming in some games, but benchmark scores in 3D Mark, Unigine Superposition etc. were normal, so I thought it was all in my head.\n\nThen when a friend with identical specs and settings was getting 100 FPS more than me in CS 2 I was finally convinced something was up. I spent days trying to figure out what the problem was, reinstalling the game, the drivers, Windows, everything. I had given up. Until one day I was looking through my glass panel, and it finally hit me.\n\nWhen I switched to the correct slot, the gains I made in FPS felt as if I upgraded my GPU, like a free Christmas gift to myself.",
      "Honestly AMD software should have a pop-up \"WARNING YOU ARE RUNNING THIS CARD AT X PCI-E IF THIS IS YOUR ATTENT PROCCEED AT YOUR OWN RISK WITH NEGATIVE PREFORMANCE\" and it should not be able to press just skip cause dumb dumb users will just go huh Okei and then still complain but if it keeps popping up they will start asking around.",
      "1x is a far cry from still having 8 lanes of 4.0 is the same as pcie 3.0 16x which is barely bottlenecking stuff on the highest end in the last few years",
      "Well we are waiting was your PCI-E lock also not locked or was your PCI-E at 4.0 x 1, x 4, x 8?",
      "Im riding it out with a 5700x3d.  Didn't see a reason to jump off AM4.",
      "Yeah I kinda got lucky. The day of release I managed to cart one at MicroCenter near Towson, MD.",
      "RELEASE THE KRAKEN",
      "At least you didn't blame the drivers like most do."
    ]
  },
  {
    "brand": "amd",
    "generation": "7000",
    "tier": "top",
    "matched_keywords": [
      "7900xtx"
    ],
    "title": "‚ÄúThe Edison‚Äù 7800X3D / 7900XTX / 5000D Airflow",
    "selftext": "This build is replacing a 970GTX build from 2014, so I went (fairly) all out on creating my dream machine.\n\nThe lighting scheme was created to try and mimic the dim and warm glow of an Edison bulb, thusly matching the aesthetics of my home and creating a ‚Äúcozy‚Äù work/gaming atmosphere.\n\nCorsair 5000D Airflow w/ optional wood panels\nMSI MAG B650 Tomahawk\nAMD 7800X3D\nAMD 7900XTX Reference w/ Cooler Master Vertical GPU Mount V3\nG.Skill Trident Z5 NEO RGB 64GB 6000MHZ CL30\nSeasonic Vertex GX-1000\nEK Nucelus AIO CR360\nSamsung 990 Pro 2TB x2\nArctic P12 RGB 120mm x 7\n\nAnd since these peripherals are new as well:\nDell AW2723DF 27\" 1440p 240hz (280hz overclock) IPS x2\nRazer Basilisk Pro V3 w/ Mouse Dock Pro",
    "comments": [
      "Impressive build, m8 !!!  \n\nIf not already done, activate SAM (first in bios than with adrenaline drivers) and freesync pro in adreline too.\n\nEnjoy !",
      "Thanks for the kind words and tips. I've got freesync on, SAM isn't something I've heard of, I'll look into that!",
      "This is the kind of computer I dream of. I have a nice PC, but there's an elegance, a beauty, that I've never managed to replicate. A truly exceptional build.",
      "You definitely want sam enabled. Smart access memory. You can enable it in bios I think. Or in the adrenaline app. It's been awhile so I can't remember exactly. But it really helps.",
      "SAM is basically a system that allows your CPU to access the entirety of the GPU's VRAM in a single operation instead of taking a limited 256MB chunk.\n\nIn simpler words, it's free performance you get by flicking a switch in the adrenaline settings.\n\nEnjoy üòÅ\n\nAlso, sick build, it just became my favourite so far ü§©",
      "Looks like SAM was activated by default, so that's nice. Both in my bios and in the Adrenaline app!\n\nThanks for the kind words, I'm really happy you like it!",
      "Those fans üî•",
      "Wow thanks so much for the very kind words! I appreciate it a lot!",
      "Book stand link please",
      "Beautiful pc :3\nMay i ask what monitor u buy? I ordered  RX7900XTX and idk what monitor I should pick",
      "Deus Ex: Human Revolution vibes",
      "Right?! It was such a joy to work in, they really thought of everything in regards to air-flow and cable management.\n\nAnd believe it or not, it's actually quite a bit smaller than the case I was upgrading from LOL, a full tower reverse ATX Lian Li behemoth!",
      "Beautiful build mate",
      "I absolutely love this case, I never planned on getting one either, but while I was eating Chipotle after buying a 4080 I realized it wouldn't fit in my case so I walked my happy ass back into Best Buy and bought the biggest case in the vast selection of 5 whole cases (2 or 3 being 4000D Airflows) \n\nWouldn't have it any other way, it was great to build in, gigantic GPUs fit without any issue, and it looks incredible in white",
      "Hmmm interesting. You made me realize the reference xtx only uses 2 8pins. Curious why board partners use 3 if the performance isn't much different.",
      "Ty!",
      "At first I was really bummed when I saw how tinted the glass was, but it has quite grown on me. The PC is as understated as it is stylish, and I really love that balance.",
      "There is no such thing as overkill in computing. It's an overblown fallacy. Get the best thing you can afford and need/want and let it ride. \n\nAlso running 2x 1440p monitors (1x the 1yr older version of OPs) on my 4090.",
      "Thank you. I have that info in the original post:\n\n Dell AW2723DF 27\" 1440p 240hz (280hz overclock) \n\nI wanted an IPS panel, started with buying one of these, liked it so much, decided to buy   a 2nd one.",
      "I find 27‚Äù 1440p to be a sweet spot for my preferences. It has lasting power so I can get a long run out of my GPU before needing to upgrade. And at ultra on the games I play, I am struggling to even meet 240fps to truly take advantage of the 240hz. So I don‚Äôt think it‚Äôs overkill at all."
    ]
  },
  {
    "brand": "amd",
    "generation": "7000",
    "tier": "top",
    "matched_keywords": [
      "7900 xtx"
    ],
    "title": "AMD's RX 7900 XTX Matches an RTX 4090, While Using 700W of Power",
    "selftext": "",
    "comments": [
      "My room wasn't warm enough anyways",
      "only 700? nice!  /s",
      "It doesn't \"match\" a 4090 even with 700w, which is over twice the normal TBP.\n\n>**In terms of performance, the overclocked AMD Radeon RX 7900 XTX GPU scored 38,725 points in 3DMark Time Spy, 19,137 points in 3DMark Time Spy Extreme, 20,492 points in 3DMark Port Royal, and 7,690 points in 3DMark Speedway benchmarks. These are graphics points which matter more and based on the numbers, the GPU did come very close to the NVIDIA GeForce RTX 4090.**\n\nI guess it's kind of neat, but would be pretty unuseable under normal circumstances with that power draw and the setup that they had to rig up to achieve it.",
      "So it seems they used a normal waterblock, but a sub-ambient cooling solution, probably a chiller?\n\nEven if you don‚Äòt care about energy costs or the excess heat, condensation might prevent you from daily driving this. \n\nStill interesting experiment.",
      "A whole ass extra appliance, as far as my utility company is concerned, just for ray tracing and 4K.\n\nI want to move to Puerto Rico someday (stick with me its relevant) and am actually thinking I'll have to sell my PC if I want to live there. The power grid down there is all sorts of fucked and I can see a PC with a serious GPU knocking power out on the block lol",
      "Winter is coming soon enough",
      "that's the equivalent of running your microwave oven for as long as you game...\n\nThe electric bill's gonna be horrible.",
      "Likely not but honestly it is possible, especially away from the cities, and if I have to pick between the PC or the fridge...\n\nOr maybe I'll get a generator *just* for the PC. Hurricane comes, everyone in the neighborhood comes to my house because my generator is running. They get to my house and see spoiled food, lights turned off...and a sick ass RGB PC.\n\n\nOk it's too early and I haven't smoked yet.",
      "this is fine",
      "You can use humidity sensor tacked onto arduino or raspberry pi to control the chiller, not that hard to do. Noise from the chiller, on the other hand, is much harder to bear if you plan to daily it.",
      "No, that would be 690.",
      "So Mary, you're telling me there's a chance!",
      "Not too similar though, vega was very compute heavy which is why on paper it sounded good for games as it had a lot of power behind it but it had significant bottlenecks which meant this compute was wasted on games. \n\nRDNA being significantly cut down on this compute aspect meant the paper performance is at least closer to reality, a lot of it is down to optimisation in games this time round at least.",
      "RDNA3 has high FLOPS but only in theory - similar to Vega",
      "Tropical country people: *What's winter*\n\nOn where I live temps rises to like 34c regularly in the summer, 32c all year around except for late December - early March (which is around 28-30c) and I hate it because my 5.2 m2 room heats up a lot when I put a real load on... my 195W GTX 1070.",
      "Even a 250-350w GPU?",
      "Seems to me like this implies that AMD did hit the RDNA 3 architecture's goals except in power consumption. The fact that the card boosted up to 3467MHz is impressive. Of course the fact that it took 690W to do that is less impressive.\n\nIt will be interesting to see if AMD can provide a respin which reduces power consumption.",
      "Friendly reminder that 4090 is a significantly cut down AD102 chip. If Nvidia wanted to, tomorrow they could release a 4090ti/Ada Titan.",
      "If they can run a toaster they can run a GPU. So, uhh... ask about toasters I guess",
      "Aren't microwave ovens generally 900-1100W? The smaller ones used in college dorms may be 700 though."
    ]
  },
  {
    "brand": "amd",
    "generation": "7000",
    "tier": "top",
    "matched_keywords": [
      "7900 xtx"
    ],
    "title": "My new ‚Äûcase‚Äú, GPU will be connected to the loop too in a few months after testing my 7900 XTX RedDevil",
    "selftext": "",
    "comments": [
      "It took effort to make that, looks great.",
      "Eloops are life",
      "I hope you‚Äòve seen my sarcasm in my comment",
      "No, the Motherboard also got no space to breath at its back",
      "https://preview.redd.it/8rj4eu8zr3ja1.jpeg?width=4032&format=pjpg&auto=webp&s=7ac5b760f7a158be58a6027161c67b79ddd519d7\n\nJust for you",
      "i hope there's holes behind those radiators",
      "I remember thinking about doing this a few years ago, maybe I'll try to plan one again. ü§î (currently using a wall mounted Thermaltake P5)\n\nLooks good üëç",
      "Beyond S tier fans for pushing through rads. King at silence and air pressure.",
      "i did lol no worries",
      "I'm unfamiliar? Why are they so great?",
      "What do you mean? Testing my gpu for 1-2 months? I just want to make sure it‚Äòs not faulty in any way from the start.",
      "This was a thing quite a few years ago. Never took off too well from what I recall.\n\nA few months is like 2 years in tech.",
      "You can be sure that i planned this build for a whole month to be sure i thought about everything üòÖ",
      "What a madman, actually came through! Hords of ocd ridden people are silently celebrating a small victory and appreciate this reply.",
      "What about dust?  Is that in issue with these open builds?  Looks really cool though.",
      "I don‚Äôt know what you want to prove me? Just let me test my gpu for a month or two (besides the EK cooler for the RD will release at the end of March and because of that i can‚Äòt swap it to water rn anyways). What is so wrong about that??",
      "I dunno - we gonna need to see a pic for proof that these rads are venting :p",
      "3 rads and several feet of tubing, how is a single D5 pump doing? I don't know much about custom loops but is that sufficient flow? Just curious now because I've seen people use dual D5 Revo for less.\n\nPlus my dumb ass has been looking into custom loops and lately been wanting to do it but my mind keeps telling no you idiot, you don't need it.",
      "It is, a single d5 can handle this loop with ease and did it already in a case for 4 years\n\nEdit: That d5 is already 6 years old btw.\n\nEdit 2: Right now i have my d5 at 75%, when i get my gpu into the loop it will probably be around 80%",
      "Not that much of an issue tbh, for the radiators i used dust filters between the fans and radiators. For m hardware i use anti static brushes to clean them"
    ]
  },
  {
    "brand": "amd",
    "generation": "7000",
    "tier": "top",
    "matched_keywords": [
      "7900xtx"
    ],
    "title": "AMDs questionable Statement regarding the 7900XTX Hotspot Drama",
    "selftext": "",
    "comments": [
      "Just take refunds  and don't waste time on replacements they don't even have. Buy an AIB model instead or add a little and get yourself 4080 - if you're overspending in hundreds anyway.",
      "I bought a reference design from XFX and during benchmarks (unengine heaven) I'm getting a junction max temperature of 111¬∞c so I guess that I'm one of those who got defective cards :-(... Do you think that I should contact XFX or AMD in order to get a replacement?",
      "It is crazy how AMD is waiting for people who have problematic cards to contact them. I mean, it it not surprising since the problem seems to be outside of AMD's hands, but as a consumer you cannot be confident about the product whatsoever. Moreover, there are people who don't run metrics, don't check temperatures. They might be a small percentage when it comes to the high-end bracket of customers, but they are out there, and they will have no idea their cards are faulty as long as the cards can still work.  \n\n\nIn any event though, just don't buy AMD reference design cards. And if you have a faulty one, get a refund. AMD does not have inventory to replace faulty cards.",
      "I'm willing to believe AMD would rather leave it on the customer to decide.  So if you don't read up on the problem,  you're fucked.  Look at the 5700xt for example.  \n\nThis is coming from a company claiming *leadership* products and asking high prices, so it seems sleazy.",
      "Yes.",
      "It's not like this is some flagship premium product where you can expect premium customer support.\n\n\n...Oh wait...",
      "Imagine being a person that downvotes this.\n\nBest point. If they know how many cards and they know which cards are affected why are they not saying who needs to return their cards? To me that's either they don't know how many or which cards are affected or they don't care if people have this issue and want to keep the number of returns to a minimum.\n\nI get that the survey he referenced would be a small sample size but how can you say that you can give people replacements when 2/3 of the people who took the survey couldn't get one within 2 weeks.",
      "*Pay the minimum for production*\n\n*Pay the minimum for software*\n\n*Pay the minimum for customer service*\n\n*Watch as their shares slowly drop to single digit*",
      "Lots of AMD fanboys downvoting everything that is negative about AMD from driver issues to problems like this, AMD will never gain market share as long these issues exist and AMD does't respond right.\n\nJust imagine how EVGA would respond these problems, now look how how succesful they are, next imagine some one worse like Gigabyte with how they dealt with their power supply issues, yeah this is why you don't shove issues under a rug.\n\nBe like EVGA AMD, there probably lot of people losing their job soon at EVGA so AMD this might be good time to hire new talent and do the right thing as well.",
      "Or in some countries where aib 4080 and 7900xtx cost roughly the same you don't need to even think about it.",
      "it is extremely unprofessional of AMD to not release an official written statement on their own website regarding the recall/refund.\n\nalso, the previous statement AMD released via the media is very vague as well. they said they used the bad thermal solution (design problem), but then it is manufacturing defect since they said not enough water in the chamber in the interview, so which is which? \n\ni am very sure AMD is still hiding something and not being completely truthful here, which might explain the reluctant to release a proper statement on their own website.\n\nshame for those who bought the XTX....",
      "AMD defense league is out in full force today",
      "Yes. That's what I'm doing with mine.",
      "Man, with all the trouble Nvidia had with their 4080/90 price at launch, all AMD had to do was... release the thing without issue. It didn't have to even beat Nvidia, if priced well and stable.",
      "Please be aware that it may or may not be related to the hotspot issue. He even mentioned \"probably not\"",
      "I love when AMD says they learned from their mistakes, then make the same ones over and over again. They memed Nvidia at their presentation, made some... Interesting performance claims in their graphics and now this whole hotspot issue happens and they handle it horribly. \n\nI wonder why people are still skeptical and don't purchase their GPUs.  They turned their cpus around so I don't doubt they can do the same with gpus but maybe they need some new leadership or changes to be made.",
      "I can guarantee that there's going to be many who are effected by this cooler problem who won't ever be aware of it because most gamers don't even monitor temperatures really let alone hotspots. That's too bad.",
      "Not only downvotes, they straight up gaslight about driver issues no matter the evidence, like the people lying about the 7900xtx not having major driver problems. \n\nIt's a really bad look and it instantly tells me someone is not engaging in rational honest discussion..",
      "Can you give a single example where a manufacturer in the PC hardware space has ever directly contacted customers for a defect issue?\n\nIt is almost universally up to the customer to determine if they are affected and pursue RMA.",
      "For convenience, the German version is here: https://www.youtube.com/watch?v=qOwRuTu7AZw"
    ]
  },
  {
    "brand": "amd",
    "generation": "7000",
    "tier": "top",
    "matched_keywords": [
      "7900 xt"
    ],
    "title": "My new Build 7900X with 7900 XT and a bit of Noctua Love",
    "selftext": "",
    "comments": [
      "Please call it the 7900X^2 T",
      "All hail noctua and fractal design.",
      "Actually it would be 7900X(1 + T)",
      "Oh man that looks sexy! The Black Version of the U12A woulda worked so nicely here. But still, props on a clean build!",
      "That‚Äôs the full-size torrent, correct? Looks great btw. I like the gold fans accenting the heat sink.",
      "No it's the compact. i did buy forst a custom 7900 xt but it did not fit so i changed to the reference",
      "yeh i really feel the fresh breeze on my feet when i start gamin",
      "7900X(1+TX), 7900X(3D+T)...",
      "I am simple man. I see Fractal Torrent I upvote.",
      "What would you call it if it was a 7900X and a 7900XTX instead? What about a 7900X3D to pair with the GPUs instead?",
      "Don‚Äôt be a simp, run a second PCIE cable.",
      "The whole point is to have an optimum design for air cooling...",
      "It's the compact, full has fans on the bottom",
      "Awesome thank you. I‚Äôve got one coming and I was like, woah woah woah lol. Plenty of room in there!",
      "I have to get a fractal case.....nice!  Looks like we have the same Noctua fan/sink!  Works well, very quiet.",
      "Love the reference xt\n\nhttps://preview.redd.it/pgg1ghn351ma1.jpeg?width=3024&format=pjpg&auto=webp&s=eaac3228d439eadd5bdef8c4b009882a802871ea",
      "Steve",
      "Are both of your side panels solid? I bought the compact in black and both side panels were metal.",
      "it's that's the point of this case to move a lot air? ;)\n\nwell it was going okey. but sure don't had a lot of cables to move since now all SSD are m2.\n\njust had my old case where it was a real mess.. with fan control, HDDs and some DVD player XD",
      "The 7900X^2 T Fruity."
    ]
  },
  {
    "brand": "amd",
    "generation": "7000",
    "tier": "top",
    "matched_keywords": [
      "7900xtx"
    ],
    "title": "MBA 7900XTX RMA declined - 110degree Junction Temp",
    "selftext": "Hi everyone,\n\nAs we know so far, quite a lot people have problems with the 7900xtx reference cards, reaching 110 junction temps, 100% fan speed and still losing performance due to downclocking .\n\nI just got the reply of my RMA request (unchanged answer):\n\n‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî\n\nThank you for your email.\n\nThe temperatures are normal if you there is any issue please, contact us back.\n\nThanks for contacting AMD.\n\n‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî\n\n\nJust wanted to ask, if anybody got the RMA request approved or if it was also declined.\n\n\nEdit #2:\nAn AMD Employee just reached out to me to get this issue resolved. \nI will need to sent the graphic card from germany to canada, so they can do some investigation on the card itself.\n\nAnd I am choosing this route, rather than refunding the order under EU customer rights, because I will be without a GPU either way.\nSo if there is a chance, that they are able to pinpoint the problem and rollout a fix to everyone of you, who is affected by this problem, it will be worth it.\n\nAlso I want to thank everyone commenting and upvoting this post, also every suggestion from every one of you was very appreciated.",
    "comments": [
      "Just RMAd my 7900XTX as well. \n\nDont let them get away with such a flaw on a 1000+$ product, it‚Äôs unacceptable. \n\nThankfully consumer protection laws in Germany highly favour the buyer rather than the seller so you can RMA for 30 days without any reason given.",
      "\"The temperatures are normal\" - AMD",
      "Answer \"There IS an issue you twat!\"",
      "Yea‚Ä¶I wont open a 1000$ card, void my warranty and fix it myself. For the price the product should be functional at the very least.",
      "Refusing the RMA is ridiculous. AMD really trying to make the 10 to 1 of last gen look like nothing. Nvidia going to have 15+ to 1 after this.",
      "I ordered an 7900xtx from AMD directly and live in germany, the support rep declined the RMA with the reason given: \"Only unopened products can be returned within 30days\". Obviously wrote back to him that i insist on my 14day return policy and i withdraw from the contract. Never had any seller argue about the 14 day policy ever.",
      "Nothing pisses me off more than bad warranty treatment for customers from companies.",
      "Incredible what European consumers protection laws can do, right?",
      "So back when the 5950X launched, I had a working CPU for approximately a month and then the system wouldn‚Äôt post. Tried another CPU and it did. Tried another motherboard and it wouldn‚Äôt. \n\nSo I attempted to do a RMA which took almost 3 months of arguing and exchanges. They refused to believe me that my CPU could have died. \n\nThey had me show proof of the CPU sitting in the socket of two motherboards (causing me to have to rip my existing computers apart), and then after that they had me, a week later, do it again but this time holding my case number in the photo. Then they wanted all sorts of pictures in the box. \n\nThey tried to tell me that is user error or that my power supply had issues. It was the longest back and forth ever, sometimes of them repeating stuff I‚Äôve already done or sent. They kept trying to close the ticket!\n\nFinally they tried to make me pay shipping! \n\nThe whole process was absurd. I finally got it approved and shipped. Put the new CPU in when I got it after about 4 weeks (lol) and it worked great. \n\nI have never had such an awful experience. For context, I had an issue with an EVGA 3060 Ti that they RMAed no questions asked and I had it shipped with a new one at my door in 4 business days.",
      "Put more pressure. Tell them it‚Äôs thermal throttling really badly. You can give repasting a try. Many people got excellent results after some Kryonaut extreme repaste.",
      "I dont want to void my warranty, \nMaybe this is not voiding the warranty at all, but i dont want to get to court if AMD think otherwise",
      "One really shoudnt have to do that considering the cost‚Ä¶",
      "If you're in the US those warranty stickers are unenforceable\n\nhttps://www.ifixit.com/News/11748/warranty-stickers-are-illegal",
      "Opening the card won't void the warranty in most countries... unless, of course, you damage it.  HOWEVER, if you get permission from AMD in advance to attempt the repair yourself then they can be held liable for any unintentional damage you cause.\n\nI have had a couple OEMs accept responsibility when a customer damaged a system when asked to open it up by their tech support.  One incident was so bad we had to replace the motherboard, RAM, battery, bottom cover, and palmrest.  The user didn't shutdown the computer, and wasn't asked to, opened the bottom cover at the request of the OEM tech support, didn't manage to unscrew every screw and pried open the bottom, breaking the bottom cover and cracking the palmrest, he then disconnected the CMOS battery, not the main battery cable, then unscrewed the heatsink from the CPU while the system was hot and running, dropping the screw on the live board and shorting out the entire system, catching the battery cable on fire.\n\nI had to fight the OEM for all of five minutes to accept responsibility.  The tech support guy naturally said that if the end user wasn't comfortable doing it he shouldn't have, and I said tech support can't ask the end user to open their device without accepting the risk that the end user might inadvertently cause another issue.  The tech spoke to their higher level support and immediately accepted my position and sent out every part I requested.  Unfortunately, I wasn't the one that got to fix the system üòû",
      "Correction: if you're in the US, they can still refuse your RMA and then you'd have to open a lawsuit; they're banking on themselves being too big and you being too small to fight them.",
      "If you deal with it yourself and re paste is your warranty gone in the UK? I know in the states you're allowed to open them up.",
      "If history shows us anything it‚Äôs that AMD will happily launch products that aren‚Äôt ready to be launched.",
      "Lol just RMAd my 7900xtx for the same reason and bought an 4080. Had Nvidia for 15 years and never experienced such problems. Back to team green I go (sadly).",
      "They're saying the exact same thing they already said years ago.\n\nI don't know why people are expecting anything different. Hotspot issues aren't anything new.\n\nThey don't care that the card is downclocking and that it's screaming at you because the hotspot is melting, as long as you're not crashing/artifacting/etc it's \"within specs\" for them",
      "If it's downclocking below spec, the it isn't \"within specs\". AMD are already on thin ice with the performance they advertised."
    ]
  },
  {
    "brand": "amd",
    "generation": "7000",
    "tier": "top",
    "matched_keywords": [
      "7900xtx"
    ],
    "title": "Just upgraded to Sapphire nitro 7900XTX - ready for Star Citizen",
    "selftext": "",
    "comments": [
      "Problem is Star Citizen is not ready for you",
      "I remember when AMD was giving out Star Citizen for buying a R9 200 series.",
      "10 years early for SC lol but nice card",
      "Bold to state its purpose. You know we're the group to be ridiculed, right?!",
      "For a small donation of $10,000 you too can wait for star citizen",
      "Too early dude. Could have waited for 10900XTX.",
      "Holy fuck seriously? Damn SC is pretty ancient I‚Äôve never kept up with it",
      "This is how I own Star Citizen! I have some AMD sponsored racing ship in-game and that's it.\n\nGame was literally un-play-able on my R9 290 and FX CPU.",
      "Just as broken and boring as it has ever been. It is a glorified tech demo uses to sell gullible people jpeg ships",
      "But for a limited time you can buy this gigantic useless ship for only $500!!!!!",
      "Friend!\n\nA last man standing cross fire user!?\n\nHow is it these days?",
      "32 bucks for two games and 20years of guaranteed updates is great deal imo",
      "how is it nowdays, I kickstarted it, and played a little maybe 3-4 years ago, but havent tried it in a while.",
      ">sand caves with first alien creatures\n\n10 years later, \"first alien creatures\"...\n\nWhile most features are lack lusting, not working or simply absent.\n\n*If* your computer can handle it...\n\n*While* selling ships worth entire monthly salaries...\n\nStar Citizen feels like those game designers student projects where you can't control your urges to add this and that and this and that and meet no deadline, progress or simply well-rounded mechanics and thoughtful design choices.\n\nI'm so confused as to why this game manages to stay under the radar given how little progress seems to be done and  will be played correctly by your grandchildren.",
      "I play everyday past two years wdym",
      "You could actually resell that ship for about $250+ on the grey market.",
      "You mean you pay them to be their beta tester?",
      "Lots of misinformation and the usual snide comments here. You can tell when no one has any actual experience with something.\n\nStar Citizen's performance is not as bad as it used to be, nor is it as bad as people jeer about in comments.\n\nI'm on a 6900 XT, run at 1728 or 1800, and get upper 50's FPS on average. It's near enough to 60 that I have Chill enabled for the game because some areas will go above that. If I run at 1440p then the game's performance is generally smooth across the board unless the server is chugging hard.\n\n\\_\\_\\_\n\nRamble for more info, if you're interested:\n\nPresently what matters the most in Star Citizen is the CPU rather than the GPU. Think of it as an MMO in terms of performance behavior rather than a first person shooter and you'll know what the performance is like. Whether someone wants to classify it as an \"MMO\" or not is irrelevant, I'm just talking about performance. In this regard, if you get something like the 5800X3D (or a more recent equivalently performing CPU) then you're going to get significantly higher frame rates.\n\nPatch 3.18, which is currently on a separate additional test server, has the first iteration of the Gen 12 renderer which off-loads some of the CPU work onto the GPU. If someone is currently CPU bound in SC then 3.18 can improve their performance somewhat, though I haven't seen numbers to know exactly how much of an improvement this has been. Basically, they're moving away from the existing aging renderer to Vulkan for improved performance, visuals, and the option to add modern things like HDR, VR, et al.\n\nBut if you don't have access to 3.18 yet or you don't have a better CPU, then there are also numerous INI tweaks that can be done, as is typically the case with PC gaming. Just do a YouTube search for Star Citizen Performance Guide or the like and you'll find them. The one that says 3.17.2 FPS+++ in the thumbnail is my favorite because it doesn't waste too much time with fluff in the video and the description has the necessary info, but the others probably work fine. Follow it and the game doesn't look like poo, though you're obviously trading some visuals for performance, and it will run much better.\n\nWhat you're going to see in the comments are a lot of people who remember when no amount of hardware could push the game beyond 30 FPS. Some will claim this is still the case. Those people have no idea what they're talking about, or have really bad hardware, or refuse to do any INI tweaks because they feel like \"They shouldn't have to do that\". In a PC game. As though this has never been the case in PC gaming. üôÑ\n\nPersonally I get my aforementioned FPS without doing the INI tweaks and this is almost entirely because of the CPU.\n\nThere are some very real issues to complain about with SC but performance, if you've been gaming on the PC for any length of time and know how to edit a text file, really isn't one of those issues.",
      "I play everyday past two years idk what people on internet think",
      "Star citizen isn't dead, but it may as well be given the slow motion trainwreck of a development effort so far."
    ]
  },
  {
    "brand": "amd",
    "generation": "7000",
    "tier": "top",
    "matched_keywords": [
      "7900 xt"
    ],
    "title": "AMD Radeon RX 7900 XT GPU drops to $799 ($100 under MSRP) - VideoCardz.com",
    "selftext": "",
    "comments": [
      "just like god intended.\n\n***now do it again.***",
      "Another 150$ then maybe I'll consider it. After all this should've been the 6800XTs replacement.",
      "yeah. there was a huge drop at mindfactory as well. \nbasically from one day to the other the basic aib models from powercolor, sapphire dropped by 100‚Ç¨ to 899‚Ç¨\n\nand the powercolor reference model  is the cheapest at 849‚Ç¨",
      "Still expensive , It should have been 649$  \n\n\nAnd the 7900 XTX should have been 799$ \n\nIn my opinion ...",
      "Such a scummy move by AMD to name it 7900xt and 7900xtx, it's deliberately confusing naming to trick consumers. Although I guess Nvidia did it first with \"4080\"",
      "Yep. It was easily $200 over what it should have been... and that's my assessment humouring AMD/Nvidia's hopium that crypto has permanently inflated gpu prices.",
      "Wake me up after another $200",
      "I'm not the only one that saw through it, i guess a way to charge people $999 and $899\n\nThe prices would have been $650 and $799\n\nI do find it weird is the people that defend their price gauging though",
      "For the last decade AMD has used the same model number when talking about GPUs cut from the same chip, followed by a potential suffix (usually none, X, or XT) to denote how cutdown the chip is. Polaris and the top of RDNA2 are the odd ones out.  \n\n4080 12 GB and 4080 16 GB were two completely different chips sharing a model name.\n\n\n    Model       Chip        Core Config     Memory bus\n    RX 7900 XTX Navi 31     6144:384:192    384 bit\n    RX 7900 XT  Navi 31     5376:336:192    320 bit\n\n    RX 6900 XT  Navi 21     5120:320:128    256 bit\n    RX 6800 XT  Navi 21     4608:288:128    256 bit\n    RX 6800     Navi 21     3840:240:96     256 bit\n\n    RX 6700 XT  Navi 22     2560:160:64     192 bit\n    RX 6700     Navi 22     2304:144:64     160 bit\n\n    RX 6600 XT  Navi 23     2048:128:64     128 bit\n    RX 6600     Navi 23     1792:112:64     128 bit\n\n    ...\n\n    R9 290 X    Hawaii      2816:176:64     512 bit\n    R9 290      Hawaii      2560:160:64     512 bit\n\n    R9 280X     Tahiti      2048:128:32     384 bit\n    R9 280      Tahiti      1792:112:32     384 bit\n\nIf anything using 6900 XT and 6800 XT for the same chip is the misleading part since it would usually denote a bigger gap. Under previous generations the  three Navi 21 models would've been 6900 XT, 6900, and 6800 XT since they started cutting ROPs for the last one (RX 6800).\n\nEdit: added memory bus width.  \nEdit2: fixed 6700 memory bus width.",
      "> They're the only ones actually trying to advance tech in a way that makes stuff cheaper to make.\n\nHurray for AMD making more money! a win for AMD shareholders is a win for the consumer, right?!\n\n...",
      "Who cheered?\n\nEvery reviewer said the 7900XT pricing sucked and some clearly stated it was to push sales to the 7900XTX.",
      "Its not a 700$ card should be playing games in 8k.\n\nPeople forget flagships were 550 less than 5 years ago.",
      "By the time this reaches a fair price, the recession will be in full swing. No one's buying your overpriced shit. I bought refurbished and lots of my friends bought used.",
      "Vega 64 launched at $499, and while the XT has more VRAM, it's also a cut down chip which the 64 wasn't, so I think that's about the correct price point, let's give them $50 for inflation so $549.",
      "It will don't worry",
      "So only $200 too expensive now.",
      "So by your logic, after 10 years, the card will cost 10k as it will offer 200%+ performance increase than this gen, are you stupid or what??\n\nperformance increase is an incentive to buy a new card not a privilege to increase the price, if there is no performance increase, then why would anyone upgrade or buy a new card!!!!",
      "I was looking at a 7900 XT or XTX to replace my 1660 Super.  Ended up just getting a 6800XT for $550.   Couldn't be happier.",
      "If Nvidia tomorrow made all GPUs across-the-board cost $5000, would you still say it's okay for AMD to have theirs at $4500 citing that it's still competitive?\n\nPrice. Gouging. Is. Bad.",
      "AMD having money in the bank will do nothing for you by itself, no. Bulldozer era was because they made a few too many poor design decisions, it had nothing to do with their financials. their financials came about because of the poor design decisions. \n\nif your aim is for AMD to stockpile cash at the expense of consumers so that they can keep making mistakes without going out of business... i'd rather they fail outright. *that* is basic business."
    ]
  },
  {
    "brand": "amd",
    "generation": "7000",
    "tier": "top",
    "matched_keywords": [
      "7900 xtx"
    ],
    "title": "AMD Radeon RX 7900 XTX Failure Rates Reportedly At 11%, RMA's Piling Up But Users Not Receiving Cards",
    "selftext": "",
    "comments": [
      "As much as I see this being a pretty big problem for AMD, It seems like WCCFtech have pulled this ‚Äú11%‚Äù number out of thin air, then used Igors article about quality control as a bolster for the rest of the article. Zero sources mentioned for the 11%. Literally just says it in passing in one sentence then carries on talking about Igors article‚Ä¶. \n\nWait for better sources, if we get one. No one else is reporting this ‚Äú11%‚Äù number. \n\n~200,000 units (again if true) - 11% = 22,000 units defective. Somehow I don‚Äôt see that being correct. This would be a MUCH larger issue in the media and louder concern from consumers if that was true.",
      "For some perspective, the highest failure rates I've ever seen:\n\nASUS DirectCU II R9 280X **36%**\n\n*Corrupt ELPIDA vRAM straight from assembly*\n\nSeagate Barracuda 1.5TB (2011-2012 stock) **29%**\n\n*Lowered QA because floods in Thailand took out both WD and Hitachi, and global storage demand couldn't be met by Seagate and Toshiba alone without severely lowered standards*\n\nCorsair TX750 (2009) **18%**\n\n*Failing temperature sensor, flaky OCP*\n\n\nThese are from France, Germany, Norway and Sweden. So not a global estimate.",
      "11% is a pretty damned huge number to claim without sources!",
      "Wccftech...\nI'll wait until someone else reports it.",
      "> ASUS DirectCU II R9 280X\n\nOh god, I had a DCUII 290 and eventually had to downclock the ram a little to keep it from black screening. And it was the only aftermarket cooler that ran hotter and louder than the stock blower one!",
      "4090 launch was totally fine by comparison. The melting connectors was pretty limited by the sound of it and it came down to user error. 110C XTX cards from AMD is a significantly larger problem.",
      "Hi All,\n\nGot my RMA today.\n\n[https://i.imgur.com/A7oPcIS.jpg](https://i.imgur.com/A7oPcIS.jpg)\n\nRMA stock landed in European warehouse this week.\n\nAMD support were really helpful, even phoned me to let me know my new card was on the way and provided me prepaid shipping to send the faulty card back, DHL will come and pick up the faulty card on Monday.\n\nNew card works perfectly, no hotspot issue.\n\nAll in all , pretty good service from AMD support team here in Europe.\n\nWell done AMD.",
      ">Igor Wallossek, who has been in the industry for much longer than this writer, states that the AVC's (Asia Vital Components Co, Ltd.) quality assurance number is \"10,000 units,\" which is five times what this writer calculated. Again, I am not an industry professional but a reporter that writes about malfunctions and more for this news organization.\n\nSo his source is igor and in the same sentence he's tryin to avoid responsibility by claiming to not have industry knowledge because he is \"just a reporter\". Lmao typical wccf",
      "> Melting connectors does sound and look worse than someone describing 110C related power throttling.\n\nSure but in the end, it was 100% user error. So the 2 situations are not even remotely close to comparable really.  \nnVidia folllowed PCI-SIG's specifications, so even if it did become a big issue, it would be an industry wide problem, not an nVidia-specific one.  \nAnd say what you will about nvidia, but they did the right thing accepting RMAs no question asked.  \nNot only is it the better decision for customers, but it's the best decision to actually find out what the damn problem was.\nAMD built and sold faulty hardware, claimed that it was normal operation, refused RMAs until it became bigger news, and now lacks the stocks to complete RMAs.  \nIt's one fuckup after the other.",
      "0.05% by Nvidias numbers and 0.04% by Gns so pretty negligible tbh",
      "Not only did he not ask him any questions if you listen to their podcast all of them were apologists (the full nerd)\n\nI like that podcast but I had to shut it off they were saying well you know it's the holidays and people weren't working when Herkelman said they clearly were working.\n\nIf you don't want to work during the holidays do not release a unfinished product during the holidays.\n\nHe said he gives them a pass that's great because it's not his video card or affecting anybody he knows.\n\nUsually he's pretty good but on the interview and the podcast really sounded like he almost worked for AMD.\n\nI know that's not his typical spiel but that's the way it sounded.",
      "LOL",
      "What about Microsoft Xbox? Red ring of death. Microsoft reported a failure rate of 25% but a lot of news outlets did surveys and put it up more closer to 54%\n\nIn college, everyone's Xbox had the red ring of death eventually, it was literally a 100% failure rate between eight of us.",
      ">As much as I see this being a pretty big problem for AMD, It seems like WCCFtech have pulled this ‚Äú11%‚Äù number out of thin air\n\nAtleast on Mindfactory most 7900 models are on 1% RMA qoute or less\n\n[https://www.mindfactory.de/product\\_info.php/24GB-XFX-Radeon-RX-7900-XTX-MERC310-Black-Edition-DDR6--Retail-\\_1474344.html](https://www.mindfactory.de/product_info.php/24GB-XFX-Radeon-RX-7900-XTX-MERC310-Black-Edition-DDR6--Retail-_1474344.html)\n\n[https://www.mindfactory.de/product\\_info.php/24GB-Powercolor-Radeon-RX-7900-XTX-AMD-Edition-OC-DDR6--Retail-\\_1474340.html](https://www.mindfactory.de/product_info.php/24GB-Powercolor-Radeon-RX-7900-XTX-AMD-Edition-OC-DDR6--Retail-_1474340.html)\n\n0,58% here\n\n( Reklamationsqoute Bottom right )\n\n&#x200B;\n\nu/tobascodagama\n\nits so high because its \"Source trust me bro for views\"",
      "I can claim bigger numbers without sources too!",
      "Indeed. Read somewhere that Nvidias failure rate was in the ballpark of like 0.1%",
      "They told me 3 weeks ago they didn't have stock to replace, and they told me today they still don't have stock to replace. If this is such a small problem it would fall under normal RMA %'s and they should have stock. There could be other reasons I guess, but frankly, they make AMD look just as bad.\n\nEdit: For the record, this article is terrible and does not provide any info to back up it's 11% claim. Don't take my anecdotal information as support for this article, just as a counterpoint to saying this is below 1%.",
      "If you anticipate 2% failure rate in a year, and you have 5% due to a manufacturing defect, you will run out of stock for RMA very quickly.  They will likely have to order a new batch from the manufacturer, which will likely take months once they realized the RMA rate was higher than expected.  Manufacturing doesn't turn on a dime.",
      "The failure rate was 100% I think, it was a design flaw that guaranteed a bust. Microsoft made a cool recap for their anniversary: [https://www.youtube.com/watch?v=z2d6IMBS8oY](https://www.youtube.com/watch?v=z2d6IMBS8oY)",
      "People were warning against Seagate Barracudas years before the floods, they were always shite. I didn't know it was possible to lower the standards even further."
    ]
  },
  {
    "brand": "amd",
    "generation": "7000",
    "tier": "top",
    "matched_keywords": [
      "7900xtx"
    ],
    "title": "Joined team RE... Ehm I mean team what ever is cheaper and is best at running games I actually play. Red devil 7900xtx 13900k.",
    "selftext": "",
    "comments": [
      "And with a 13900K and a 7900xtx, I can see that you're very concerned with pricing üòÇ",
      "I guess op mixed up \"cheap\" with \"friendly to ones individual budget\". Or simply \"ripoff\" vs. \"less of a ripoff but still shit\".",
      "Yet you zip tie fans to a $1200 gpu",
      "You're kinda on point. It was cheap in a sense that i got almost all of it used and I needed beefy cpu to alleviate cpu bottleneck in tw attila. So it's not \"actually cheap\" cheap but cheap for my use case.",
      "Me, trying to figure out what a 13900k is cheaper than or better at: ü§®",
      "And allowed it to sag visibly.",
      "13900k vs 7950x 13900k is definitely better value here, and 7900xtx vs 4080 7900xtx wins value wise too. Whatever cheaper at the high end definitely checks out here.",
      "Which explains why they have a Noctua cooler with the optional Chromax kit and no Noctua fans in sight, plus the Phanteks Halo RGB rings on the two top fans... Because they focused on performance, and not looks?",
      "Did he leave the plastic peel on his io cover too? This build is a mess lol",
      "Idk to me when I buy something used that still has the peel I instantly think that they didnt care about the parts and that someone just built it for them without telling them how to take care of PC parts like cleaning it out etc\n\nThat usually leads me to think the parts aren't in the best condition. Also depending on the part the peel is on if it gets too hot that plastic will melt.",
      "Digging the case fans zap strapped to the GPU heatsink, all for the temps!",
      "Cheaper than a 13900kS\nBetter than a 7950x in a lot of games.\n\nOp is trying to make jokes. Pretty niche jokes. But jokes nonetheless.",
      "He was concerned about pricing or hed have got the KS model /s",
      "and a noctua cooler (already expensive) with purely cosmetic addon(+cost) heatpipe cover. lol OP is humble bragging at this point",
      "They sure do! But those are not them.",
      "You're missing some context, nh-d15 was bought used, it already came with shroud. Actually almost everything you see on the picture was bought used. Cpu, motherboard, gpu, cpu cooler, psu even some fans. And i got phanteks holos with the case (that I actually bought new).",
      "It's still nice to have 100w less dumping out of the box next to you most of the time.",
      "Definitely, tho in the 7950x defense it uses alot less power. But pure performance wise yeah the 13900k is better value. I'm curious to see what amd will bring to the laptop game now that we have 13th Gen Intel which are pretty good so far",
      "Performance > looks",
      "You completely missed the point of his post lol."
    ]
  },
  {
    "brand": "amd",
    "generation": "7000",
    "tier": "top",
    "matched_keywords": [
      "7900 xtx"
    ],
    "title": "PSA: If you have a reference 7900 xtx with 110c hotspot Temps send PowerColorSteven your info. They are collecting it for troubleshooting rmas for AMD. Link is his comment requesting info.",
    "selftext": "",
    "comments": [
      "/u/PowerColorSteven\n\nRip your inbox, chief. Haha",
      "I don't have powercolor but AMD said this to me:\n\nPlease could you provide GPU box image showing serial number clearly. Kindly provide GPU temperature screenshot (AMD Software) for verification. Once we receive all the information we will proceed with refund process.\n\n\nUpdate Dec 28th:\n\n\t\n\nDear xxxxxxxxx,\n\nThank you for ordering from AMD.com Online Store. A Return Order has been created for your refund request and the Return Reference Number is: xxxxxxxxxxxx.\n\nPlease note that this Return Order is valid for 29 days only. Once we have received the return product(s), your refund should be credited through your original payment method within 5-7 business days.",
      "I am so upset AMD decided to go ‚Äú nothing to see here you are just using it wrong. Btw no refunds‚Äù. They completely took a shit and here I was ready to ditch Nvidia",
      "They asked me if I wanted to rma and replace, then sent me a return label and told me I HAVE to pay to ship it for a return. Telling me they were out of stock after confirming there was stock to replace. Such a joke.",
      "Repeat after me.\n\n\"Huge corporations aren't your friends, they are only after your money\"\n\nThis includes obviously amd, nvidia and more.\n\nThe underdog just got incentives to be nice to get your money but after ryzens success amd also raised prices and more.",
      "I've never purchased Powercolor but MAD respect to any community manager who goes above and beyond like this. Steven said in that one post I know this isn't just a Powercolor problem but I'm gonna stand by my word because I in turn represent AMD with my company.\n\nI will strongly consider Powercolor in the future.",
      "jesussssssss",
      "They (Digital River) are a poor third party fulfillment company. It's a shame. AMD really should look into a new partner.",
      "It does and these are the type of experiences that make people red list companies and never purchase from them again.",
      "Yep RDNA3 launch was so bad that it went from me planning to get an XTX for an upgrade next year to now being completely off my radar and hoping that 4080 gets a price drop instead.",
      "i handle the sales for the us/can. what kind of sick person do you think i am to be a community manager. last 3 games i've no-lifed are prob apex destiny and lost ark.... and the way those guys get attacked on reddit....\n\nedit: dont you put that evil on me, ricky bobby.",
      "I don't think many people think AMD is our friend. Some of us were just counting on them being a smart underdog instead of a stupid one. I guess we bet wrong.",
      "You will take your 110C and like it.\n\n-\tprobably AMD",
      "They're absolutely not normal if the card goes into panic mode (immediately ramps fans to 100% and drops clocks by a ton) in order to save itself when you reach those temps. \n\n110C is the \"hey I'm dying here\" temp.",
      "They don't want to be the underdog anymore, despite their inability or unwillingness to actually be a proper competitor. So we're now in a situation where they're acting like Nvidia, but are making products like it's 2015 again.",
      "I mean... The 3080 fe also had 90-115c hot spots many of them died at random.\n\nI repadded mine and it runs at max 85c Hotspot and mem temp and didn't die yet.\n\nI mean let's be real here.\n\nTemps could be lower, the fix isn't expensive ( specially for a Manufacturer they can buy the pads in giant batches for cheap ). Why do people try to excuse a half assed cooling solution?",
      "damn that sucks",
      "We should give AMD and NVIDIA a big middle finger at the same time",
      "Honestly, no idea why AMD still bothers with the whole direct sales thing. It was something that made sense during shortages, but now it's pretty pointless.",
      ">I don't think many people think AMD is our friend. Some of us were just counting on them being a smart underdog instead of a stupid one. I guess we bet wrong.\n\nWhen i told here on the sub that amd will change after they aquired marketshare and blow intel out of the water during Ryzen 1000 and 2000 i got downvoted , hated on , and literarily told amd wont do that from fanatics."
    ]
  },
  {
    "brand": "amd",
    "generation": "7000",
    "tier": "top",
    "matched_keywords": [
      "7900 xtx"
    ],
    "title": "AMD rumored to launch Radeon RX 7900 XTX graphics card - VideoCardz.com",
    "selftext": "",
    "comments": [
      "I just want pricing and availability. Need to know if I'm going 7000 series or 6000 series.",
      "There is literally 0 zero leaks lol. The 7000 series GPU'S are completely shrouded in mystery. And it's less than 10 days left for reveal.\n\nLeakers - You have been disappointing.",
      "XFX RADEON RX 7900 XTX",
      "Bummed if the top end card isn't called the 7970.",
      "This! I am going 6900xt if the 7000 series price is shit.",
      "I mean, it‚Äôs pretty hard to beat a sub $700 6900xt. If you‚Äôre patient, wait it out. But initial availability and likely price will make the 6900xt look even sweeter I think",
      "And when Nvidia releases 4090 ti, AMD can counter it with 7970 Ghz edition.",
      "XFX BOOBA RX 7950 XTXH",
      "7970 3Ghz edition.",
      "It had been leaked that biggest of RDNA3 is a MCM chip, it had also been leaked that 2 different nodes are used in it.\n\nSizes of those chips were also leaked.\n\nAMD itself claims formidable perf/watt.",
      "The $1300 \"but but it's just as fast as the 4090 in some games\" edition.",
      "Nov 3rd is not launch, it's just the product reveal. That means we might not even get third-party benchmarks until mid-late November.",
      "I don't care what they call it, if it performs well and isn't grossly overpriced like everything else that has launched in recent years. The \"because we can\" tax is starting to wear very thin on me, and I'm happy sticking with used hardware until the heat death of the universe if they keep it up.",
      "XFX RX 7900 XT THICC IV XTREME-X",
      "Decent leaks but we are 10 days from launch where is the game performance leaksüò•.",
      "I personally couldn't care less. Let nvidia cost a million bucks, keep AMD prices down and give me max raster performance.",
      "My XFX 7970 just randomly died during war years ago  :,(\nStill sitting on my shelf.",
      ">Just give me a 7700xt with 12gb vram that's around or close to 6900xt performance for less than 600$ and I'll be happy.\n\nWhat an utterly depressing set of expectations. \n\nStop comparing to just the top, overpriced models.  \n\nA 6800XT was only like 5-10% slower than a 6900XT, while costing $650.  \n\nBasically, you'd be happy with a $599 GPU that performed similar or only slightly better(and had less VRAM) than a $649 GPU from *two years* before?  \n\nIt's sad how much consumers nowadays just seem to have lost all sight of what an actual generational advancement in value is supposed to look like.",
      "Just got mine for $550 shipped. Asrock Phantom Gaming",
      "Most??\n\n&#x200B;\n\nHardly.."
    ]
  },
  {
    "brand": "amd",
    "generation": "7000",
    "tier": "top",
    "matched_keywords": [
      "7900 xtx"
    ],
    "title": "Sapphire RX 7900 XTX NITRO+ pictured",
    "selftext": "",
    "comments": [
      "With it being 3.5 slots, looks like they expected folks buying this to vertical mount their GPU's. Hence the bottom RBG strip.   \nI hope in Trixx there is a way to selectively disable top and bottom.",
      "Backplate looks decent. Thats what 90% of users will see anyway",
      "Looks like a dollar store Radeon VII.",
      "How many cases allow for this card to vertical mount with that cooler? That seems ridiculous. My eclipse G500A couldn't fit this if it tried in the vert mount, and it's a massively oversized mid tower.",
      "I thought I was alone thinking that. These cards look ugly as heck.",
      "I guess I'm the only person who likes the design.\n\nIMO Powercolor's were way uglier but ASRock's Taichi might be my favorite out of all of the revealed cards.\n\nThe 6950 XT NITRO+ looked worse than this but the 6950 XT NITRO+ Pure looked so damn good.",
      "I personally love it. Clean aesthetic, imo a lot better than the super angular gamer focused ones, it's pretty and minimalistic. Not too keen on the massive RGB light bar, if that had been slimmed down or even entirely taken out it would be an improvement. Otherwise great looking card, would love to see more like this.",
      "Yeah i get windowed cases are predominate but i have a hard time understanding how looks are influential in the purchasing decision for computer internals.",
      "oof..",
      "Are these modelled after vhs cassettes?!",
      "Yes, that's a pretty boring silver box.",
      "are those fans performant? or did they go with a lower performing fan just to make it look \"good\"? looks bad to me",
      "The Red Devil definitely looks better, and if you want a simple design card then the Speedster Merc is a good choice.",
      "That is ridiculously ugly.",
      "It's 3.5 slots though, not 3.",
      "Actually already fed up with all the \"gamery\" design that AIBs put up. I love this sleek, minimalist, industrial design and for me a step in the right direction. Not just a fan of triple slot and up design as I prefer SFFPCs but I do understand given the more power it needs & transient peaks = more heat output = need better cooling. Hopefully it can fit in my Formed T1 V2. Sapphire is the only AIB I trust out of all AMD AIBs as their cooling is uncompromising & well thought out.",
      ">Yeah i get windowed cases are predominate but i have a hard time understanding how looks are influential in the purchasing decision for computer internals.\n\nFor me it is usually \"is the look going to annoy me after a while?\"  This and the stupid feature tiering is why I haven't owned a Asus motherboard in almost 20 years now.",
      "powercolor red devil better design now",
      "You're not alone. I think this is the best design in years, aside from asus strix gundam/eva. Ugliest one to me are asrock, power color. XFX is just uninspiring and I've had bad experience with them some 12 years ago, not gonna go near their stuffs. Gigabyte and Asus are okay.",
      "Sadly, this is likely as close as I will get to owning one."
    ]
  },
  {
    "brand": "amd",
    "generation": "7000",
    "tier": "top",
    "matched_keywords": [
      "7900xtx"
    ],
    "title": "My first all amd build. 5800X3D+7900XTX",
    "selftext": "Coming from a 3090 I have to say I‚Äôm extremely impressed.",
    "comments": [
      "Not enough fans.",
      "Do you think I should add more? I‚Äôm thinking about replacing the gpu with more fans",
      "The red devil is a beast! Temps have been great but I have noticed coil whine. I‚Äôd say it‚Äôs a little less noticeable than my previous rog strix card.",
      "How do you like the red devil? How are thermals on it? Any coilwhine?",
      "Yup, I think more for front intake‚Ä¶temp must be scorching",
      "definitely.",
      "Only 9 fans? Lol.",
      "Price to performance isn‚Äôt worth it for me yet honestly. When I notice a significant increase I‚Äôll make the switch.",
      "And not enough RGB",
      "Super nice component combination, and I should know. üòú",
      "Unfortunately I‚Äôve used my allowance for the month I‚Äôll have to wait",
      "Did you not know rgb increases performance?",
      "The difference between 5800x3d and the next gen isn't that large anyway. Definitely a reasonable choice to stick with a more mature platform at a lower cost.",
      "RGBae",
      "5800x3d was the best gaming proccesor about a month ago. It still is amazing for the price compared to what am5 cost with everything factored in.",
      "Thank you, I feel like some people still don‚Äôt realize this. I‚Äôll take the reliability any day of the week lol.",
      "Because the current gen is still very wonky, not to mention overpriced.",
      "I just got a rx 6800 red devil and it's damn quiet. Gets a little louder on the OC bios but i also have a small mATX case with not great airflow. I actually had to reroute my USB plugin because the gpu was so much bigger than my ASUS TUF gpu.   \n\n\nNo coil whine that i could perceive on my unit but that's a gamble i'd imagine.",
      "Hello fellow 5800x3d and 7900xtx enjoyer!",
      "I have the same card paired with a r9 7900x and mine always crashes anywhere from 30 to 40 mins into games. I can't deal with it I'm going to have to return it."
    ]
  },
  {
    "brand": "amd",
    "generation": "7000",
    "tier": "top",
    "matched_keywords": [
      "7900 xt",
      "7900 xtx"
    ],
    "title": "Megathread for questions about 7900 XTX/7900 XT cards, availability, boasting about getting one and complaining about not getting one",
    "selftext": "Earlier today AMD launched the RADEON RX 7900 XTX and RADEON RX 7900 XT, as with previous GPU launches in recent years, availability on day-1 is very sketchy, varies wildly by retailer/region and you contend with many scalpers and bots.\n\nRather than having hundreds/thousands of different posts asking about these cards, availability or boasting about getting one or complaining about not getting one, please use this thread instead.\n\nOver the next few days, submissions may be restricted at times when there are high levels of low-effort posts.",
    "comments": [
      "Ordered my new GPU from OverclockersUK yesterday, and paid a not insignificant extra for delivery by midday today (in 30 mins)\n\nOverclockersUK have not even begun processing the order, per my Order page.\n\nWill be seeking my delivery fee back, suggest others who did the same also check their Orders.\n\nUpdate: Finally got through on the phone to OCUK after nearly an hour on hold...\n\nMan on the phone said they know full well they won't deliver most orders, but have no intention of informing customers at this time. Just turned orders (with guaranteed delivery) into preorders that could take \"days weeks or month\" to arrive.\n\nShady AF business practices (possibly breach of Consumer Law).\n\nCancelled and won't use OCUK again ü§∑\n\nFurther update: On their forum they now banned me for asking where my order is, and the \"OC staff\" member replying is 'liking' insults from other users thrown at people pointing out their orders arent arriving. Fuck that company.\n\n\"You have been banned/suspended for the following reason: Negative towards OcUK\" for asking why I haven't received an order.",
      "People are scalping the xtx at same price as a 4090 on eBay lmao. What a joke",
      "Is this the right place for me to boast about NOT getting one?",
      "Report this, clear breach of consumer law and if they go bust your money is gone. Happened to infinite computing earlier this year and a lot of people lost a lot of money.",
      "Got my Hellhound 7900XT today (paid MSRP) and finally retired my aging GTX 980. Wasn't getting an XTX anyways - [my case is on the smaller side, this is basically a perfect fit as it is](https://media.discordapp.net/attachments/249112416854474752/1052717313406799993/PXL_20221214_223133303.jpg) (there's about an inch of space between the front case fan)\n\nDid a bit of tuning, decided to stop for now at 2650MHz core & memory on a -50mV undervolt (with power limit +15% so peaking around 360W). I may try pushing it further later. So far only real test outside Time Spy (which got about 26400, ie beating the reference XTX) was [Cyberpunk ultra settings + medium RT + quality FSR 2.1 which sits at almost 70 fps average at 1440p](https://media.discordapp.net/attachments/249112416854474752/1052746875909984286/image.png). This is way outdoing my expectations but reading around sounds like I may have won the silicon lottery.\n\nEdit: Also tried Elden Ring now. It's admittedly 60fps capped, but got it to run that stable with all settings maxed out.\n\nOne snag I've run into - was [trying to get a run of Stable Diffusion](https://github.com/nod-ai/SHARK/blob/main/shark/examples/shark_inference/stable_diffusion/stable_diffusion_amd.md) but it doesn't look like the RDNA3 driver supports MLIR/IREE yet so no dice :( (garbage output in fp16 mode, IREE compiler error in fp32 mode). Sure enough the last MLIR/IREE driver was a month ago and only 5000/6000 cards. Will try with DirectML (which is *much* slower) tomorrow.\n\nEdit2: Did in fact get DirectML Stable Diffusion working [following this guide](https://gist.github.com/averad/256c507baa3dcc9464203dc14610d674),\n\n    12152022-145016 - Model: C:\\Users\\LordAlfredo\\Stable Diffusion\\model\\stable_diffusion_onnx Scheduler: PNDMScheduler\n    12152022-145016 - Inference Steps: 64 Guidance Scale: 10 Width: 512 Height: 512\n    12152022-145131 - Seed: 277436425 - Gen Time: 40.4030237197876s\n\nCaps out at 768x768 generation (at that point I'm at full VRAM usage). Really caps out 640x640 or 704x704 depending on parameters, pushing too hard gets garbage out. This thing is a fp16 compute *beast*, 50 iteration 512x512 image generation finishes in ~30-40 seconds!\n\nEdit 3: Finally hit an OC instability crash in 2 hours of Cyberpunk w/ a second monitor running. Dialed back to 2600 @ 1060mV (the clock reduction is to maintain lower power and temps at the higher voltage) and no issues since.",
      "Just got my 7900xtx home and started doing some benchmarks, noticed some bugs I wanted to share.\n\nUsing Adrenalin software I‚Äôll often see cpu core reporting 2900-3100mhz, but benchmark validation shows performance degradation in the 30% range. Any movement on the voltage slider for example core clocks shoot up but scores go way down. Temps and power are both normal.\n\nThis tells me the core speed reports are wrong, and I suspect this is true for other users and reviewers as well. I‚Äôve seen several reviewers today talk about ~3100mhz core clocks.\n\nSurprised I haven‚Äôt seen this reported else where, but wanted to make everyone aware, when you‚Äôre messing with overclocking ALWAYS validate performance number move relative.\n\nThis exact bug existed at the 6900xt launch.",
      "I GOT THE 7900 XTX, BEEN WAITING OVER 2 YEARS NOW TO GO NEXT GEN WITHOUT GETTING SCALPED AND IN A FEW DAYS I FINALLY GET TO TAKE PART. GOOD LUCK TO EVERYONE, I HOPE YOU ALL EXPERIENCE MY JOY ASAP!!!",
      "I‚Äôm extremely jealous of anyone who lives near a Microcenter.",
      "Columbus Microcenter just got a late shipment. https://i.imgur.com/WXO14s4.jpg\n\nSeveral 7900 XTs and PowerColor XTXs in stock right now.",
      "Fuck that launch. If I can find a 6950 under $650, I‚Äôll buy that instead. Looking to upgrade my 5700XT",
      "seriously no one going to buy it when you can buy 4080 for cheaper",
      "Anybody know when AMD.com orders ship?",
      "If everyone just waits it out.. The best case scenario happens .. People still think we're in crypto times.. FOMO is gonna hurt a lot of people pockets..",
      "I intend to - presumably trading standards are the correct body?\n\nWasn't going to spend the time, but having insults to me for asking about my order on their forum 'liked' by a member of their staff has annoyed me enough (yes, maybe I'm petty) to do so.",
      "4080's are in stock for ¬£1150 in the UK, why buy a 7900XTX with very limited stock for ¬£1049, AMD pricing with this generation of cards and CPU's/Motherboards is stupid.",
      "Hi, it's a me. Your girlfriend.",
      "Got a merc xtx off newegg here is advice that helped me from someone else. \n\n1. Get newegg phone app set it up to where u can apple pay fast. \n\n2. Search 7900 xtx leave it open on your phone on newegg phone app. \n\n3. Go to youtube and there is a live feed with bots that monitor all the sites restock. Restockwatch.com feed on youtube. \n\n4. Monitor closely and when xtx gets restocked open phone and quickly pull down refresh click buy now and applepay.",
      "Sometimes I think online threads like this seem alarming because people are more likely to go online to report problems than normal operation.\n\nI've had my AMD reference 7900 XTX in for a few days now. Still testing, but so far temps have been fine and there's absolutely zero coil whine. Performance seems within margin of reported numbers.",
      "Love how they are all sold out and on ebay for 5 grand. I hope all scalpers get chronic constipation.",
      "It‚Äôs really easy. Anything that looks like the reference design in the photo is a reference card. All reference cards come from the same place; they‚Äôre just resold by different brands. \n\nIf it‚Äôs not reference, it‚Äôll have some kind of other name in the title, like ‚Äúred Devil‚Äù or ‚Äúnitro+‚Äù or ‚Äúpulse‚Äù or ‚Äúhellhound‚Äù. And it‚Äôll look very different from the reference design."
    ]
  },
  {
    "brand": "amd",
    "generation": "7000",
    "tier": "top",
    "matched_keywords": [
      "7900 xtx"
    ],
    "title": "Will AMD disrupt the graphics market with RDNA 3 and RX 7900 XTX?",
    "selftext": "",
    "comments": [
      ">What's clear is that the reality of AMD's products did not live up to the pre-launch hype delivered by leakers who clearly were not in possession of much in the way of actual facts. Talk of 2x performance boosts and 'almost 4GHz GPUs' clearly let down some fans and rather unfairly, took the sheen away from AMD's actual achievements, which are highly impressive in many ways.\n\nSame thing every time. The rumor mill surrounding AMD is always toxic as fuck.",
      "No $1,000 GPU will disrupt the market, the lower SKUs may though however, but that's yet to be seen.",
      "No they won't Nvidia has too strong of a brand power,i had friends on my school who didn't even know AMD made cards \n\nThere are people paying more for a 3050 over a 6600",
      "What moron thought they were hitting 4GHz?",
      "Doubt it. Nvidia still has the mindshare even with all the negative press recently.",
      "Nobody, it's just strawman arguments concocted by people like MLID so they could say:\n\n\"The fanboys who are claiming 3x performance and 4GHz clock speeds are way off the mark. It's actually 2x performance and 3GHz clock speeds\"\n\nNobody seriously thought Navi 31 would hit 4GHz - the sensible speculation saw it around 3.2GHz before overclocking, and up to 1.8x perf. Way off, but still nowhere near 4GHz.\n\nLikewise, the only people who said Lovelace's RT perf would be 3x or 4x the 3090 Ti's was Nvidia. The leaks all suggested 2x-2.5x. Even they were off - it's about 1.8x on average at 4K, it looks like.",
      "$1000+ GPUs dont disrupt anything regardless of brand, most people are interested in <$500 GPUs.",
      "It's a shame that AMD hasn't found a way to leverage their massive marketshare into good press.\n\nHow many RDNA2 GPU's are chugging away in Xboxes and Playstations? Lots and lots and lots. AMD has proven they know how to make good GPU's -- most people just don't know it.",
      "They should stay in school.",
      "I unfortunately doubt it. Walk into a store trying to sell budget gaming pre-builts and count the 3060s and the 6600 XTs. The biggest reason that Steam has the 3060 as now the most popular GPU series is because of pre-builts.",
      "Releasing a 330 USD 8 core processor against a competitor who was selling 340 USD 4 core and 1100 USD 8 core processors was disruptive. The competitor promptly dropped their next 8 core processor to 600 USD.  \nFollowing up with a 16 core processor at 1000 USD against the competitor's 1000 USD 10 core and 1200 USD 12 core was disruptive.\n\nReleasing a 1000 USD graphics card targeted against the competitor's 1200 USD graphics card is a small discount from the company that is perpetually perceived as number 2. It'll have better raster performance (?), worse ray tracing performance (?), and the FSR3 and \"frame interpolation\" features won't arrive until sometime next year.  \n\nDisruptive would've been a 4090 competitor below the 4080 price point of 1200 USD, or a 4080 competitor below the \"4070\" 12 GB price point of 900 USD.\n\nPeople will debate which product to buy based on use case, but it will settle in right next to Nvidia's offerings rather than disrupt anything.",
      "People bought Fermi over HD5000, Nvidias worst Vs AMD's best, ever. \n\nNvidia won. There's no hope for the market, because no matter what they do people will buy their crap. They can literally shit in a box, call it exclusive and people will pay 2000$ for it",
      "Apparently this guy: [https://twitter.com/9550pro/status/1571834170900623360](https://twitter.com/9550pro/status/1571834170900623360)",
      "Maybe they've never had GPU discussions before, because I find it hard to believe a group of people can discuss GPUs without someone at least mentioning an AMD card. But then again people these days are ignorant beyond belief.",
      "With those prices? Naw.",
      "In that case they're just idiots",
      "Back when I was in school it was ATI or nothing!",
      "Man you can blame mlid for what you want. But if you actually watch his video he never really hyped 3Ghz. He was almost saying best case 2x performance. He was one of the more down to earth when it comes to raster. He also said RT best case will be land in between ampere and Lovelace but most likely March ampere.",
      "No, $1k is still a high asking price but people are happy including myself because its alot less tha Nvidia, if it was priced at $700 then it would indeed disrupt the market.\n\nSo we have no option but just bite the bullet and accept these prices",
      "Exactly because like 95% of people using a console don't even know what hardware is inside, which is fine it's just a more casual demographic. Typically if you tend to care about PC hardware on an enthusiast level you're much more likely to get into PC gaming vs console.\n\nEven at the ultra-enthusiast level where people know AMD is a good option Nvidia dominates. I think when you get to this level of people paying $1000+ for a graphics card the mindset is they want the absolute best they can get which tends to be Nvidia. That's why you see heavily discounted 6900XTs and the like right now because AMD is having a hard time getting enthusiasts to buy them.\n\nObviously they need to have products at the high end of their product stack but I think they need to more aggressively market to the mid and low end markets looking to buy GPUs."
    ]
  },
  {
    "brand": "amd",
    "generation": "7000",
    "tier": "top",
    "matched_keywords": [
      "7900 xtx"
    ],
    "title": "AMD Radeon RX 7900 XTX flagship RDNA3 GPU is now available for less than $882 - VideoCardz.com",
    "selftext": "",
    "comments": [
      "They could simply say its available for $881 lol.",
      "The price is still too high if you ask me.",
      "I always read these articles and the look at the prices in my country and they are like 50% more expensive\n\nFor reference, In Finland this costs about $1280 at the cheapest",
      "Because not everybody has been gaslit into believing graphics cards are worth that much.",
      "I guess AMD has successfully cleared enough excess 6000 series stock, so they can now move towards their actual target prices for 7000",
      "Meanwhile in Europe..\n\n‚Ç¨20 off, it's ‚Ç¨1070 now for the Phantom Dick gaming model.",
      "yeah, just because it's cheaper than nvidia does not mean it's cheap. \n\namd will always be cheaper than nvidia",
      "Great deal, FPS per $ looks extremely strong with this card. Not saying it‚Äôs cheap but it‚Äôs 4070ti ballpark prices for something faster than a 4080 and the same amount of ram as a 4090. Hard to argue with that. But I‚Äôm sure someone will still be upset,",
      "Overall for hardware I agree. Compared to the 1200 dollar Nivida equivalent? Its good.",
      "Great, wait around for your $400 high end GPU and let us know when it ships.",
      "I can assure that AMDs would love to sell these for msrp but no one is buying them üòÇ",
      "People were paying this for a 3060Ti during the pandemic.",
      "80 class competitor was 650$ last gen from AMD.",
      "1100 vs 881 for 2% on average frames. Unless your going heavy RT in 4k it's not worth it",
      "Yeah I don‚Äôt get these comments. The 6950xt is widely considered a steal at $600, but this card with even better fps per $, more ram, and better RT support is considered overpriced? Delusional.",
      "I paid $2k for a 6900xt Liquid Devil. \n\n\nI just try not to think about it.",
      "\"The other guy is worse,\" is never a good justification.",
      "Yep, top comments are already complaining that AMD isn't pricing their flagship card for this generation at a midrange GPU price from 5-10 years ago.",
      "People who can afford to throw money at any computer parts they want can‚Äôt see things from the lens of people who have to think about things like price vs. performance vs. longevity. We‚Äôre supposed to just lick corporate boots and stop complaining.\n\nOn a side note, I love how people bring up inflation as if it isn‚Äôt something not already taken into account. Even including inflation, the prices of high end GPUs as a whole are outrageous.",
      "Asrock Phantom D 7900XTX."
    ]
  },
  {
    "brand": "amd",
    "generation": "7000",
    "tier": "top",
    "matched_keywords": [
      "7900 xtx"
    ],
    "title": "AMD Radeon RX 7900 XTX Review & GPU Benchmarks: Gaming, Thermals, Power, & Noise",
    "selftext": "",
    "comments": [
      "This should have been the XT, and the 7900 XT should have been the 7800 XT.",
      "Most reviewers -- us included -- post separate reviews for them because the time cost is enormous to make even 1 review, let alone try and compact all of it into one for 2 cards. It wouldn't be financially viable. That's not \"ignoring.\" That's how we always do it.",
      "Those cards are 200$ too much, it's that simple. Actually disappointing, what a horrible generation from both nvidia and AMD... maybe we'll be luckier in two years... ?",
      "ill just get a 6950XT Red Devil",
      "this card isn‚Äôt worth $1k IMO.",
      "Has anyone ever seen a **$1,000 card with a cooler from that of a $500 card** in previous generations?\n\nForreal, **massive disappointment in AMD**. They clearly developed the 7900 XTX in the same vein as the 6900 while not anticipating the massive jump between Nvidia 3000 and 4000 series. So while the previous X900 segment, the **6900 was close to 3090 with 6950 matching 3090ti, now it can only match the 4080 in raster. And light years away from 4090.**\n\nMeanwhile, everybody knew to expect worse off RT but the gap is 30%-40% worse in RT + only matching 4080 in raster + a barely okay cooler that gets **84C memory temps under load in open air test bench**. $200 doesn't justify this, it needs to be much cheaper and not just a little cheaper, and AIB coolers will fix this but at $60-$100 price jump which makes the value proposition a joke.\n\nThe 7900 XTX offers no real value compared to 4080 when you factor in same raster + RT + crappy barely okay cooler. And buying AIB 7900 XTX (@ $1050-1100) is just insane when you can spend a little more over AIB models to get even better thermals from 4080 Fe (specc'd for 650 watts) and vastly superior RT.\n\nThe 7900 XTX is really more like 7800XT and should be price at $800.\n\nAMD clearly saw their competitor increase their prices and took the opportunity to do the same even though their **product segmentation is vastly inferior, slipping from 3090ti competitor to 4080 competitor**. They saw their chance to increase their prices and they did while claiming to offer value, but if you consider the RT difference and the cooler difference, the value isn't there. It needs to be even more cheaper to offer real value.\n\nThe 4080 FE's insane cooler designed for 650 watt 4090 runs at low rpms even under load, meanwhile the 7900 XTX with Gamer's Nexus testing hits 84C memory temp on a open air test bench.\n\nIf you are spending close to $1100 for AIB RX 7900 XTX then there's no reason for you not to spend $100 more to get 40% better RT from 4080 FE and even better thermals than AIB 7900 XTX as I doubt even $1100 AIB cards will have coolers specc'd for 650 watts.",
      "Rather disappointing. I don't see how 7800xt could have any significant edge over 6800xt if the rumors about lesser cu count are true",
      "Under-delivered massively imo, and fairly power inefficient compared to the 4080. No idea where the GPU market is going from here on out; I guess buying previous gen is the move at the moment until prices calm down.",
      "I'm not buying a 1000$ GPU and not use freaking RT. Fuck AMD and fuck Nvidia.",
      "It won't. AMD just pulled off an nVIDIA at this point, albeit at a lower scale.\n\n7900 XT should have been the 7800 XT - more than obvious now after seeing the reviews.",
      "People who value raytracing and other NVIDIA features are dissatisfied .\n\nThose who expected better based on AMD‚Äôs marketing projections as dissatisfied as well.",
      "Well I guess my 3060ti stays in my PC for a few more years. Planned to buy it to be replaced by a higher end card, but will be fine for now.",
      "Welp, now I know why AMD didn't seem particularly excited during the RDNA3 announcement and this is really upsetting to me as I wanted to go with a Radeon card and offload my current Nvidia cards.\n\nTL;DW - 4080 Rasterization Performance (give or take a few percent depending on the game)\n\n3090 / Ti - RT Performance\n\n8GB more VRAM than the 4080\n\nHigher power draw than 4080\n\nDecent cooler contact, but not perfect\n\nHigh transient power spikes\n\nLoudest coil whine I've personally ever heard on a card\n\nSo when you factor in feature sets in their entirety, not just gaming, as well as power draw to performance as well as pricing the 7900XTX and 4080 basically cancel each other out.",
      "Well, 4080 by itself is insanely overpriced, so I'm not that surprised.",
      "You know that a new release didn't go well when the top thread is about trading offers for the last generation",
      "For something that's trading blows with 4080 in raster and \"decent\" RT, it's fine, I guess. \n\nIs it, on the other hand, $1000 fine? Debatable, but that's the way it is.\n\n&#x200B;\n\nThat coil whine, though üòñ",
      "Anyone that can shell out $1000 on gaming gpu, will want to have RT. The same people will pay a slightly more for a much better RT.",
      "It is a real thing but only for high-end cards and still won't leave raster in the past until the next gen of consoles, who should be able to do RT much better than the current ones - and they dictate the market, basically.\n\nMost RT games barely have any significant visual impact (implementations like in FarCry 6 do not count), and the ones who do (Cyberpunk-like) need a significant drop in resolution/FPS to achieve it on anything below 4080 - which you may or you may not take - up to a point it's debatable and depends on each individual.\n\nIt's disappointing from a 999$ part, nonetheless, **but the raster performance of just equaling the 4080 is much more disappointing than the RT one** if you ask me.",
      "I've been waiting on this review to pull the trigger on a new card. I'm still on a EVGA 8GB 1070ti, which has performed valiantly over the years. I've been trying to push it into 1440p gaming but it's limping along at this point.\n\nReading the other replies and I feel like I'm missing something. At 1440p/RT/Ultra on the worst title benchmarked (CyberPunk) it ran close to 80fps. And neither 4080 nor 7900xtx can hit the 120fps with these settings so consistent/high 60fps+ seems like the best you can do at the price tier. As a 1440p gamer, that looks good to me. Not to mention it'll trade blows with 4080 on raster going forward. \n\nOthers are saying it's not worth $1000 tag, but at that price what is a better value? Why would I spend extra $200 just for an nvidia brand at this point? I get that $1000 is a large sum of money in the absolute but in the GPU market comparing with what else is available I'm probably still going with this one over the 4080 or the older gen 3090.",
      "Duopoly at its finest, unfortunately.\n\nHopefully Intel sticks around and brings us something much closer in its second iteration."
    ]
  },
  {
    "brand": "amd",
    "generation": "7000",
    "tier": "top",
    "matched_keywords": [
      "7900 xtx"
    ],
    "title": "AMD Radeon RX 7900 XTX/XT sales booming in China due to RTX 4090 import ban - VideoCardz.com",
    "selftext": "",
    "comments": [
      "Trying to hamper Chinese AI development. It's not just the 4090 that is banned, a lot of higher end professional / datacenter cards that Nvidia makes have also been banned.",
      "Think it was due to them being used for AI purposes.",
      "Let's hope that the 7800xt and lower doesn't get affected  as it could increase prices for average gamers",
      "I'm a little lost but why did they ban the 4090 anyway",
      "Possibly yes, the regulations are not specific to model position in lineup, there are quantitative performance attributes that cause a card to be regulated.",
      "And not just Nvidia, some AMD Instinct products are also banned. At the moment, 7900 XTXs likely stand as the fastest non-banned compute cards.",
      "US being scared. Like, okay next generation there will be lower end cards being better than 4090. Are they going to ban those as well? And the generation after that even lower end cards will be even better, what about then? So dumb.",
      "That could actually set China back. A successful conquest of Taiwan could come at the cost of ruining TSMC. Either through accidental attacks on TSMC assets or intention sabotage by a losing Taiwan.",
      "Mixed feelings.\n\nSure, this will create some scarcity on these parts, but it will also give a boost to AMD use in the compute side, which can benefit benefit the ROCm ecosystem.\n\nCompute being a monopoly (NVIDIA) only benefits NVIDIA themselves.",
      "Lol. As if you can only use CUDA for AI. It's reasons like this that China and Tencent are pushing for more apps to use [NCNN](https://github.com/Tencent/ncnn) (which uses Vulkan compute shaders) for all of their deep learning needs.",
      "It is measured by the number of FLOPS (floating points operations per second) and if the card can perform higher than a cutoff, it's banned.\n\nIt has nothing to do with it's position within a brand's product line up or generations.",
      "The fabs would not survive a successful Chinese invasion, and even if they did once the machines stop working China is screwed\n\nBut the bigger thing is that a Chinese invasion would fail",
      "Thank god I just got one, and in my preferred model!\n\n (Powercolor Hellhound, I swear in quiet mode it‚Äôs one of the quietest active cooling cards ever! It measures at 20.8 Decibels making it quiter than even the Noctua cards!)\n\nEdit: miss remembered the number, it was 23 decibels, still the rest holds true. Here‚Äôs the link to the test\n\nhttps://www.techpowerup.com/review/powercolor-radeon-rx-7800-xt-hellhound/36.html",
      "Another reason is because 7900xtx costs 6299rmb in china.",
      "How does that work, made in China but banned in China?",
      "It‚Äôs not about that.  It‚Äôs about the US staying ahead.",
      "You keep saying I‚Äôm lying. I‚Äôm not. You‚Äôve offered nothing to your argument other than just accusing me of lying.  I‚Äôm old enough to know how these interactions go, I‚Äôll post something, you‚Äôll move the goalposts, and so on.  \n\nThis is the last response you‚Äôll receive from me. I don‚Äôt have time to argue with people on the internet or run a full benchmark suite to watch you move the focus elsewhere.  Besides HuB did the work for us and you can see for yourself.\n\nhttps://youtu.be/l6vn6Cpd4Yc?si=k603hpj3F6L8VpW6\n\nCliff notes: 1440p is about 12% faster for 4090 to 4080. (This is the resolution I play at). 4k is about 23% faster.\n\nAn updated 7900xtx to 4080 comparison can be found here:\n\nhttps://youtu.be/YbKhxjw8EUE?si=sEClLYbKNhyjcZ24\n\nCliff notes: 7900xtx is about 4% at 1440p and 7% at 4k than a 4080.\n\nSo by your own logic that 7900xtx is around a 4080 (which is true, but is indeed faster), then napkin math indicates it would be 8% slower than a 4090 at 1440p and 16% at 4k. Which directly aligns with my general observations of about 10%. \n\nI cannot offer a direct comparison of my cards because, again, the 4090 is dead due to a well know design flaw in the cards. So this will have to do.  I hope you feel better and can move on. Cheers and happy holidays.",
      "squeeze label office steep summer trees enter groovy dinner rinse\n\n *This post was mass deleted and anonymized with [Redact](https://redact.dev/home)*",
      "Oh please, America's doing the same thing",
      "Please no."
    ]
  },
  {
    "brand": "amd",
    "generation": "7000",
    "tier": "top",
    "matched_keywords": [
      "7900 xt"
    ],
    "title": "AMD Radeon RX 7900 XT is now available for 799 EUR in Germany (24% below MSRP) - VideoCardz.com",
    "selftext": "",
    "comments": [
      "Ah yes.. let's come up with some ridiculous MSRP, then make a discount to make it look like a good value, even though the price after \"discount\" is still overpriced",
      "still long way for prices to normalize",
      "This card should been $650 and the xtx $750-$800",
      "And also, let's get lambasted by reviews as overpriced at launch. Just to double dip on the shittiness",
      "that's never going to happen unless nvidia drops prices. The 4080 is now already more than 50% more expensive for a 14% avg perf increase in gaming.",
      "Why would you want to \"support\" billion dollar corporations?",
      "If anyone else is curious: \n\n1 EUR = 1.07 USD\n\n799 EUR = 854.93 USD\n\nGerman VAT = 19%\n\n854.93 USD / 1.19 = 718.43 USD",
      "Meh, this should be a price of 7900 XTX",
      "The thing is that while nvidia cards continue to sell and hold the MSRP, AMD are the ones dropping their prices. Clearly the \"follow Nvidia\" plan isn't working out too well for Radeon.",
      "\"Small startup AMD needs our support to fight the evil multibillion empires of Nvidia and Intel\"  \n\nIf this was about consoles I'd chalk it up to 13 year olds being dumb but the sad part is that these spaces are full of grown adults because custom PCs are way too expensive for kids.",
      "Nah it should have been even cheaper\n\n700$ at best\n\nThis card is a 7800XT disguised as a 7900XT\n\nJust like the 4080 12gb",
      "This strategy just confirms who's AMD target audience is.  \nNot consumers or reviewers, but scumbag investor's.  \n\n\nLooks like it's more profitable to appeal to investor's, than actually make a good product and sell it to consumers.",
      "> The 6800XT card cost around ‚Ç¨800 when it was released \n\nLaunch price was ‚Ç¨669, not that it was very available but if you were lucky you could get it directly from AMD\n\nBut if you compare it to the 6900XT the ‚Ç¨799 for the 7900XT is an ok price. But GPU prices have been whack since the mining craze",
      "Oh, definitely. Executives get paid based on stock price. Stock price is only very loosely linked to how the company is actually performing. It is more linked to how investors think the company will perform in the next few quarters. \n\nSo to maximize your earnings as an executive, the best thing to do is to make investors think you are going to perform very well in the short term.",
      "Still too high. AMD and NV alike really overdid it this generation. I hope both will sit on their garbage cards (performance to price ratio is horrific for everything except the 4090 if it's on sale) until they catch some mold.",
      "It's an interesting strategy, launch at a price you know few will stomach, and then lower the price steadily, capturing people along the way that find the current price fair.\n\nAnti consumer as hell, but I suppose shareholders like it?",
      "You answered your own question, the 7800 XT is the 7900 XT, the only problem is that it's too expensive.",
      "I assume the XTX is selling and the XT isn't, therefore the XT gets the price drops.",
      "I've got a feeling that this card will be discounted to half its MSRP in a year or two",
      "How dare people purchase GPUs based on their needs and wants! They should buy based on bus width!\n\nEveryone knows the rx vega 64 has a 2048bit bus and so is far better than the xtx or 4090!"
    ]
  },
  {
    "brand": "amd",
    "generation": "7000",
    "tier": "top",
    "matched_keywords": [
      "7900 xt",
      "7900 xtx"
    ],
    "title": "Radeon RX 7900 XTX drops to ¬£799 for the first time in the UK, Radeon RX 7900 XT now at ¬£599",
    "selftext": "",
    "comments": [
      "If this happened at Black Friday, I'd own one. Now, I might as well ride this generation out and see the pricing of the new stuff. After COVID and mining made RX 6000 a mess for consumers (and AMD, since supply restrictions kept then from meeting demand), it really feels like AMD hamstrung Radeon with high prices this generation.\n\nOn both sides, AMD and Nvidia, I don't know anyone with a current-gen card. Most everyone got priced out of real upgrades or had their interest in DIY severely diminished by how GPUs rocketed upmarket this generation.",
      "Would have sold like hotcakes if priced like that at launch.",
      "I have a 6950XT at the moment that really only plays League of Legends and 10+ year old titles, so realistically I don't need another card. But for the right price, I'd get a 7900XTX for a second ITX computer I'm working on right now so I can keep my 6950XT on my current rig and give it to my girlfriend.",
      "Too little too late. That is the Radeon motto after all.",
      "still 800+ bucks for a 7900xt here in the \"amazing\" region of europe,\n\nwish i lived anywhere but here. just nothing but price gaughing everywhere.",
      "Yeah well that's still a pipe dream. Nvidia would have also price cut the 4080. The 4090 is just so far ahead of the 4080 that realistically 4080 should have been a $800 GPU and Nvidia could have priced it there if they wanted.",
      "imagine if those were the launch prices",
      "To anyone on the fence GET THESE GPU's for that price! That is an amazing price for how powerful the 7900XTX is. And their Saphire brand too!",
      "6900xt here with a similarly underutilized use case. The release and continual improvements to AFMF basically reset the lifespan of this card for me, but man, the upgrade bug is really itchy sometimes for literally zero reason lol.",
      "I believe the most fun part of PC gaming is the building process. I've been designing and budgeting a \"no compromise\" ITX build for like a year now. I've done so much research on cases alone. \n\nAt my age, I rarely get to play games. So having something nice is what I really love. If you can afford it, buy it. That's my ideology.",
      "738‚Ç¨ in Germany",
      "I remember when I got a vega 56 many years ago, some friends questioned why I didn't just get a GeForce.",
      "They don‚Äôt have perfect bug free drivers, just like NVIDIA doesn‚Äôt either. There are, however, more times where devs have to fix AMD specific issues the NVIDIA cards don‚Äôt have. I rarely see a dev post a patch addressing NVIDIA GPU problems while it happens more regularly for AMD.",
      "The 2080ti is not even close to the 1080ti was for it‚Äôs generation.",
      "I think we have a misunderstanding. I don't recommend that people needlessly buy things and create e-waste. Also never get into debt buying things you cannot afford.\n\nWhat I am saying that if you have reasonable financial standing and want to buy something for yourself, you dont need to bend over backwards justifying it.\n\nPersonally I keep everything I own until I can't use it anymore, and I have repaired and rescued so much used hardware. Same with vehicles, appliances, clothes, and even my shoes. But sometimes I want to buy myself something nice, and I do. Simple.",
      "AMD... AMD never changes.\n\nJokes aside, I feel like I've seen this type of thread for every single Radeon release since the RX480.",
      "This hardware cycle has been all about the upsell 100%. So many iffy products and terrible price-points designed to push people up a tier or two.",
      "> I believe the most fun part of PC gaming is the building process.\n\nI would have agreed with this a month ago, before I tried to build my first SFF system and nearly stroked out. Why do we do this to ourselves? My next system is going to be an mATX board in something like a Y60, or maybe its own baby barn. I swear to god.\n\n> If you can afford it, buy it. That's my ideology.\n\nThis is my philosophy too, when it comes to these things. I'm in a few hardware sales subreddits and it's so frustrating to see people eternally \"waiting for next gen\" just hoping to save $50 on this-or-that. I get it. It makes sense in some situations. But the way I look at it is, if I buy it now, versus six months from now (assuming it goes on sale) - will six months of enjoyment with it be worth $50? I think it is. 28 cents a day? That's a fair trade, I think.\n\nI hope that made sense.",
      "This is more or less how I feel. Even with a real desire to replace my 1080ti I just hate the options right now. Considering my lack of a console I'd almost rather buy a PS5 Pro when it comes out than a new video card right now.",
      "And by now most of the potential buyers got the 4080s, 4080, 4070 ti super or 4070 ti."
    ]
  },
  {
    "brand": "amd",
    "generation": "7000",
    "tier": "top",
    "matched_keywords": [
      "7900xt"
    ],
    "title": "Powercolor RX 7900XT(X?) cooler reveal",
    "selftext": "",
    "comments": [
      "Should I get this satanic-themed video card? Or an XFX tits & ass themed card? Tough choice!",
      "If It is then it's sick, I love It.",
      "Would be nice if they can keep it at about 32 cm.",
      "The good ol' THICC ultra",
      "do tell me more about this ass themed card 0.0",
      "not with that attitude",
      "XFX sometimes uses suggestive names for their cards e.g. XXX, DD, THICC. No actual ass on the card though.",
      "Definitely, because Powercolor makes so many Nvidia models",
      "There used to be cartoon ass on video cards",
      "ah yes, powercolour, my favourite nvidia gpu maker",
      "Looks to be about 3 slots based on the input end. Looks like it will be a bit over if this was modelled accurately, as the shroud goes above the case mount bits.",
      "oled tv i guess",
      "I‚Äôm fine with them going crazy on their top tier models, as long as there is still a good msrp model too.",
      "Probably because the Red Devil is their top air cooled OC model, so likely a triple 8 pin pushing past 400W. Just look at the 6900 XT Red Devil for reference.",
      "Since I got my first Devil card the design has made it seriously hard to consider going Nvidia. Nothing quite matches it on their end.",
      "3.5 unfortunately",
      ">No actual ass on the card though.\n\n***COWARDS!***",
      "Any TV tbf. Using PC's for couch gaming and other media entertainment seem to be getting more and more popular. \n\nI have mine hooked up to both a monitor on my desk, and my living room TV.",
      "What will the Red Devil end up being priced? 1,249?",
      "Only thing I want to know if there are two HDMI ports."
    ]
  },
  {
    "brand": "amd",
    "generation": "7000",
    "tier": "top",
    "matched_keywords": [
      "7900xtx"
    ],
    "title": "First PC build. 7900XTX Sapphire Nitro + in white",
    "selftext": "MSI Pano 100r\nProject zero b650 mono\n7 9800x3d\n64g ram 6000mt\nSapphire nitro 7900xtc\n\nHitting 70fps on monster hunter wild with texture pack on high settings in native 4k",
    "comments": [
      "how are you just going to casually drop a flex like painting your nitro+ and not give us close up pictures!?!",
      "Try making blue in whatever software you use for me at least playing around with the color wheel in the blue area gave me the \"white\" i wanted instead of the actual white",
      "The yellowish ram must be annoying",
      "I painted it",
      "Unfortunately yeah a little any other color it matches good. Just white that‚Äôs off",
      "any videos of you completing this master piece?",
      "There‚Äôs a white nitro +?\n\nOr did you custom painted it?",
      "Tutorial? I would love to do this but i know i‚Äôd fuck it up.",
      "That painting is actually awesome!",
      "Yeah I did. Wasn‚Äôt pretty easy taking it apart",
      "yeah, it's because the white balance for all the different software is different.\nCan be quite annoying, even the rest of the 'white' case light in the picture isn't white, but slightly blue/cold.",
      "Maaaan first builds are a lot different these days than 20 years ago.",
      "10/10 paint job",
      "I personally would've went with less cable combs and maybe even white ones but nonetheless, it looks good!",
      "c l e a n",
      "I think they are reverse blades",
      "Used automotive paint. Basically prepped it like you would a bumper. Nothing special really",
      "You painted that card ?",
      "looks amazing!",
      "Cleanest! ü´°"
    ]
  },
  {
    "brand": "amd",
    "generation": "7000",
    "tier": "top",
    "matched_keywords": [
      "7900xt",
      "7900 xt"
    ],
    "title": "Hoping for AMD to stir the pot with the 7900XT(X)",
    "selftext": "This is a short and sweet post but honestly looking at the reviews for the 4080, I'm hoping the 7900 XT(X) really hits the nail on the head. For some of the numbers, I've watched from reviewers like LTT, GN, and J2C all the 7900 series cards need to just perform at least 1.3x the performance of the 6950XT to equal or outperform the 4080 in everything. 1080 to 4k rez. I do think a 30% uplift is possible be it AMD says they can get up to a 67% bump in performance with recent charts. Time will tell but I think I'm becoming a full AMD boy by next month. (BTW This is all super simple look at numbers and then multiply by 1.3x) Damn, I love competition.\n\nEdit: (12/12) Circling in back to this post since the benchmarks are out. Raster performance looks to be on average compared to the 4080 which is great! Sometimes higher sometimes lower. Obviously RT is hurting bad and I don't see that performance getting a crazy uplift so it seems AMD will always be 1-2 gens behind with RT. All we can hope is the drivers are stable and constantly updated as well. I do believe that Nvidia will drop the 4080 to $999. I cant see a future where they don't so it'll then become a battle between team green or team red. AMD IS STIRING THE POT!",
    "comments": [
      "Let's just hope they bring competitive pricing too. The XTX is priced well for a flagship, but I'm wary of the XT being $900. We'll see what everything ends up being.",
      "By \"7800xt\" you mean the real 7700xt? Right? Because AMD is doing the same thing Nvidia did with RTX 4080 12GB. Higher price point for the lower tier card so they switch the names around.\n\nRX 7900 XT should have been called RX 7800 XT.",
      "If AMD's official benchmarks are close to reality, which it should be.\n\n7900XT should more or less match 4080.  XTX should be within 10% of 4090.  This is traditional performance only of course.  We will be one full generation behind on ray tracing.  DLSS is better than FSR too.\n\nObviously AMD doesn't want to compare against 4090 directly because XTX loses in every metric except price, but overall it should be a strong alternative.\n\nIf you look at Steam, 3070 and up vs 6700 and up, Nvidia has 10 to 1 lead in hardware survey.  I hope AMD can close the gap to something like 4 to 1 or even 3 to 1, one year from today on 4000 vs 7000.",
      "The issue is that Nvidia has so much mindshare, it might not even matter.  \nI see so many people on discord and other social spaces only looking at the new nvidia cards and complaining about prices without even considering getting an AMD card instead.",
      "Honestly, if the XTX is within 10% of 4090 perf while costing $600 less, that IS a win for AMD.",
      "Nvidia is being greedy and planning for an inevitable 4080 Ti to bridge that performance gap. The gap between the 3080 and 3090 was much smaller, but it also meant that people didnt buy the 3080 Ti.",
      "You'll also see lots of people on Reddit lambasting Nvidia and claiming they're going AMD, only to just go ahead and buy Nvidia anyway.",
      "I think many people aren't aware of the fact that AMD is already the better dollar per performance option and still not dominating for various reasons. I can't think of a reason why this gen would 8nherently change this",
      "Provided the 7800xt is similar price to last gen I'll be happy",
      "It's just longtime fans who are still stuck in the Underdog frame of mind. \n\nAMD has been a raw raster *and* price value king for the last two generations, and it resulted in practically no change in their market share. The 3060 alone outsold all of RDNA2, for example. \n\nIt's not enough to just be cheaper and comparably performant at regular raster performance. There's so much more that AMD need to catch up on before casual gamers start taking them seriously. \n\nRT for example. This sub can shit on it all they want, but regardless of whether someone intends to turn on RT or not, they'll still want a GPU that won't shit the bed on the off chance they decide to try it out. And right now, Nvidia is basically double the performance of AMD in that space; I can see why some might go Nvidia despite higher prices because of that.\n\nThink about it; if you have Nvidia card A and AMD card A, and you wanted something cheaper but still RT-performant, you could just go down one tier to Nvidia card B, and *still beat the RT performance of AMD card A while spending less than both Nvidia card A and AMD card A.* All while still having access to stuff like DLSS, NVENC, CUDA etc in the rare off chance you decide to exploit those features.",
      "I'm just saying, RX 6800 XT is the same GPU class as 6900 XT and 6950 XT.\n\nRX 7800 XT will NOT be the same GPU class as 7900 XT and 7900 XTX. It's pretty obvious what has been done here but nobody is raising alarms because it's AMD so they get a pass for something that is literally the same as what Nvidia did to the point where Nvidia had to \"unlaunch\" their 4080 12GB due to backlash.",
      "Everyone acts like their friends and family will rush to buy a 1k GPU on here lol. Even if it‚Äôs competitive it won‚Äôt matter in the grand scheme of the market. Nvidia and AMD most profitable GPUs are the midrange. There‚Äôs over 5xs the amount of 3060 over 3080 and the 3080 was $700. Thinking that a 1k GPU will somehow turn the market is being delusional. These 1k+ cards won‚Äôt even break 1% of the market share.",
      "All they want from AMD is to get them to lower Intel and Nvidia prices. At least on the cpu side, AMD are firmly established as a equal quality product after the 5000 series.",
      "It realistically wont be though. It will maybe get there or even match the 4090 in some games, but some others will get demolished. People are doing all kinds of mental gymnastics but the reality is that when you start averaging a large amount of game all with their engines and bottlenecks (cpu or otherwise) the average performance goes down. Even the 4090 is not well represented because the faster you are the more bottlenecked you get.",
      "Same. If the performance uplift from 6700xt to 7700xt is trash then I'll just get a 6800/xt. I'm tired of these normalized prices/upsell tactics.",
      "It's amazing how people are already jumping to conclusions months in advance with zero knowledge.",
      "That too yeah.  \nKinda like people saying they will boycott a popular new game and still buy it on release.",
      "Yes, as was the whole 5000 series line. I have no idea what they‚Äôre talking about. I bought my 5600x at full price and I know several others who did too, it was a great value at the time.",
      "I won't even consider a 4080 because of the massive cooler sizes. And I would rather get Nvidia at comparable prices. But I will seriously look at AMD this generation.",
      "If that's the case I'll prolly just go with 6800xt"
    ]
  },
  {
    "brand": "amd",
    "generation": "9000",
    "tier": "mid",
    "matched_keywords": [
      "rx 9070 xt",
      "9070 xt",
      "9070",
      "rx 9070"
    ],
    "title": "RTX 4070 TI or RX 9070 XT",
    "selftext": "i am using 3060 12g rn, and after i updated my monitor to 1440p, its been struggling on high-ultra settings. now im thinking about getting 4070ti or 9070 xt, but im kinda sceptical about 9070 xt cuz i've been using nvidias gpus all my life, and dont know should i switch to amd instead.\nfeel free to tell me everything you think, i really need some advice\n\nmy pc specs:\ngigabyte b560m\ni7 12700\n32 gb ram\ngigabyte 3060 12g (oc ed)",
    "comments": [
      "9070 XT",
      "How is this even a question?",
      "I love my 9070xt it dominates everything I throw at it on ultra and does not run hot for the watts it pulls",
      "4070 ti or 4070 ti super? Since the 9070 xt is around the 5070 ti in raster and 4070 ti super in rt. So, the 9070 xt is just overall a better option than the 4070 ti super. And if you're comparing it to the non super, it's not even close.",
      "Gaming-only, go for 9070XT. If you work with AI, 3D Modelling/Rendering, Nvidia is still king there.",
      "I just switched to 1440p with a 9070xt. Haven't seen less than over 100 fps on anything I've played, yet, with high settings. This is my first Ryzen and Radeon",
      "If the price is right then the 9070xt, even an entry level will dominate the 4070ti",
      "Don't even think about the ti, unless you find a 5070ti for around the same price as the 9070 xt. 9070 xt all day I love mine",
      "Amd had better performance in raster, same or a bit better vs 4000 in raytracing and it has more vram (an important detail in future games).   \n\nOnly benefit of 4070ti is cuda if you need it (i did), need physX (only old games) and DLSS which amd doesn‚Äôt support, though many has FSR so not the most important.   \n\nGet the 9000 if you don‚Äôt need CUDA",
      "9070 XT runs great no reason to be worried.",
      "9070xt all the way. Dont support Nvidia any longer. They have fooled us all for years. The 10 series was the last time they had our best interests at heart.",
      "I‚Äôm gonna say the 9070XT unless the 4070ti is at least 30% cheaper.",
      "Hey, if you got the money and don't want to think, then just get what you usually get. No thinking required.\n\nJust get Nvidia like most sheep. You'll be fine most of the time, until Nvidia decides to harvest you to the slaughter house and charge an arm and a leg for whatever they are selling while you don't notice that the products are getting worse and worse with more defective software.\n\nI'm just venting. This is a rant, so you can ignore my comments.\n\nThe target pricing for the public is in the 300 to 700 range. If you think you are getting good value, then get whatever you prefer, just don't complain about it later if you find out you screwed up.\n\nMost critics don't like that many video cards are priced over 700 dollars, which is why I don't consider most of them for the average user. Both the RX 9070 and the RTX 4070 (all variants) are all overpriced by more than 100 dollars.",
      "The 9070 XT performs around the same as a 5070 Ti (overall), the 5070 Ti is a better 4070 Ti Super and that one is way better than a 4070 Ti since it has 16GB of VRAM instead of 12GB, the 9070 XT is considerably better than a 4070 Ti, if they both cost the same go for the 9070 XT",
      "Depends on the price. The 9070xt is better in 1440p and can also handle 4k.\n\nI have a 4070ti (non super) myself and it can handle any game on 1440p ultra settings above 100fps.\n\nYou don't really need a better GPU if you game at 1440p.\n\nYou'll only be able to get it used at a reasonable Price though I think.\n\nSo it really just depends on price. If you can get a 4070ti cheaper and don't plan on gaming at 4k, get it.\nIf not go for the 9070xt.",
      "If the question were between the 9070 XT and the 5070 TI, I'd say whichever you can find at closer to MSRP. The 9070 XT is better value on paper, but the 5070 TI has better frame gen and tends to be slightly faster. When everything is scalped, though, it just boils down to whichever you can find at a more reasonable price.\n\nThe 4070 ti is still a solid card, but I personally wouldn't buy it unless I were getting an amazing deal on it. Most offerings I see for it are $1000 or more which is simply not worth it.",
      "If you don't want rendering videos or images and ray tracing and dlss 3 , frame generation, AMD is better and faster without AI enhancement",
      "I love my 4070 ti. \n\nI play on 4k/60fps for non competitive games and its been a dream.",
      "personally i would go NVIDIA (but not the older 4070 TI, the 5070 TI) for story games and AMD for competitive games",
      "9070 XT is a better GPU in every aspect.\n\nMore vram, better RAY TRACING, yes it's ray tracing is on par with 4070Ti Super and it's a proper high end card and considering the current market, both of these cards should be at a similar price. Even if you have to pay 150-200$ extra for the 9070 XT just do it, you won't be thinking about those 200$ after 2 years, but you will surely be thinking about the extra 4gb vram"
    ]
  },
  {
    "brand": "amd",
    "generation": "9000",
    "tier": "mid",
    "matched_keywords": [
      "rx 9070 xt",
      "9070 xt",
      "9070",
      "rx 9070"
    ],
    "title": "Rtx 4070 or rtx 5070 or rx 9070 xt",
    "selftext": "Which is a better deal \nRx 9070xt  is 800‚Ç¨\nRtx 5070 is 630 ‚Ç¨\n\nRtx 4070 is 700 ‚Ç¨\nI am kinda on a budget, which should i choose ,(the cpu is a amd ryzen 7 7070)\n",
    "comments": [
      "The 4070 is 23% slower than the 5070 while being more expensive. So, thats obviously a no. The 9070 XT is 27% more expensive but 30% faster than the 5070. 9070 XT does have more VRAM and will be more future proof.\n\nNot sure what you meant by being on a budget. The price range is pretty high here. I would say grab the 5070 because i‚Äôm assuming you want the cheapest card.",
      "Thank you",
      "Bro, I'm talking about the cards he mentioned. For most single player games, which are often not well optimized, having way more FPS doesn't really make much difference.¬†In CS2, with a 5070 he'll get around 350 FPS, so there's no point in spending a lot more to get a 9070XT.",
      "I agree, but OP didn't ask about 5070ti, so all Anything58 was guilty of is 'answering the question as asked'.",
      "Just get the RTX 5070. It‚Äôs all you need for 1440p gaming with everything set to ultra. The 9070 XT is faster, but in many games it only gives you around 15 more FPS. Sure, in some titles you might see a 30‚Äì50 FPS boost, but does it really matter if you‚Äôre already getting 120 or 160 FPS?",
      "Don‚Äôt go for the 4070. If you want a cheaper option with better upscaling and ai features, get the 5070. If you want a faster card with more VRAM, get the 9070xt",
      "It does, ever played counter strike?",
      "Thank you",
      "Thanks for the advice, think imma do that",
      "9070xt so u have same perf of 5070ti, fuck Nvidia glazers"
    ]
  },
  {
    "brand": "amd",
    "generation": "9000",
    "tier": "mid",
    "matched_keywords": [
      "rx 9070 xt",
      "9070 xt",
      "9070",
      "rx 9070"
    ],
    "title": "The Radeon RX 9070 XT is Not $600",
    "selftext": "",
    "comments": [
      "First its the crypto era then the ai era and now the fake msrp era. It feels like the gpu market is just forever fucked",
      "This will never stop, because there are peoples who will still buy them beyond MSRP prices. That's why I did my self a favor and stopped waiting and nabbed a used asus tuf rx 6800xt for 280$.",
      "The 6800 xt at that price is insane price-to-performance.",
      "At Memory Express and Canada Computers you can routinely find the Gigabyte RX 9070 XT Gaming OC in stock for $959.99, in-store and online. The cheapest 5070 Ti I can find currently that is *somewhat* in stock is $1229.99. Pretty decent gap. Not that either prices are great, but it's considerably different than what HUB mentioned about Newegg.",
      "Amd made a point of saying that *they* were going to sell cards at msrp, *unlike* nvidia (literally one of their big talking points during the presentation of the 9070s). The cheapest 9070xt I can find rn is 820‚Ç¨ so hey, good on you on your (overpriced still) 9070xt but when a corporation makes a big show of \"nah mate we're not shitheads like *those guys*\" only to turn around and do *the exact same thing* idk, maybe they should be blasted to hell and back rather than \"what, you guys want to pay msrp for these cards? Have I never heard of such a silly proposition\", wouldn't you think?",
      "I nabbed a 5070 FE at $550 from Nvidia, but I'm sending it back for the $730 9070XT I found. \n\nMSRP is so hard to come by, it's a sad day to be a PC gamer. :(",
      "MSRP was a lie, it was a limited time early adopter fee that AMD had to rebate stores with because they wanted to sell it at $750 and once the 5000 series prices dropped AMD panicked.\n\nI wanted a 9070xt I spent over a month trying to find a $600 card after only finding overpriced $800 cards I bought a 5070ti for MSRP zero regrets its a better card for cheaper than what the 9070xt was, AMD once again fucked up a GPU launch.",
      "In any sane market, this card would have been $499, and it would have held that price consistently.",
      "Because they lied about the 599$ MSRP. It was there to create positive reception. Meanwhile they actually sold the GPU package to retailers at higher price, while offering rebates at launch, so some models can hit 599$. After that AMD keep selling high, rebates were over and retailers even if they wanted to be good guys and sell close to MSRP couldn't. And let's not even talk about the whole AMD marketing around 9070. The famous Azor promising things will get better and we will get those MSRP prices only for it not to happen\n\nIf AMD should be spared from this flak, so should have Nvidia, but they took all the flak. Kudos to the lucky few who managed to buy one at MSRP or close to one.",
      ".....no\nThey straight up made a fake MSRP to get better reviews.  That MSRP only existed because they were crediting retailers back.  It's a fake MSRP so that YouTubers would give it a better review.",
      "I got my 9070xt xfx model from best buy for 600$.  It's hard and AIBs are practically scalpers now.",
      "Outlet discord sniped cards don't count. It's not like everyone can click and order 9070XT in EU for such price, street price is around 750EUR. Those 650EUR 9070XTs are single units gone in less than 5 min after alert.\n\nhttps://imgur.com/a/oczVfBJ",
      "Paid 650‚Ç¨ for my 9070 XT 2 weeks ago, that's spot on MSRP (599$ + 23% VAT), so no it's not a lie, it's just US market that's fucked by scalpers and dumb politicians combined with lack of supply in rest of the world.",
      "Because the 600 dollar msrp is a lie. Amd gave out rebates to retailers to make it a 600 dollar card on launch day only. There are no more rebates and these arent being sold to retailers for 600 bucks. The msrp is deliberately a lie from amd. The 9070 xt is not a 600 dollar card and it was never meant to be.",
      "He went with Newegg for Canada, but their prices are pretty rough. Memory Express and Canada Computers are usually the better options.",
      "Good for you. Don't see how that's relavant though, when the video clearly shows most people can't buy them at MSRP. So yeah, they lied.",
      "I am waiting for the price to come down. I won‚Äôt buy above MSRP.",
      "AMD for sure made bad demand forecasting as always, but one of the factors is that there is no reference cards for MSRP",
      "600‚Ç¨ is not $600, official MSRP in Germany including VAT is 689‚Ç¨, so 750‚Ç¨ is 60‚Ç¨ above official MSRP in Europe. If we did actual currency conversion, $600 without VAT would be 535‚Ç¨, add 20% and you get to around 640‚Ç¨. Basically, official European MSRP is already inflated and actual market prices are much higher than even that inflated MSRP. A 9070 XT at 750‚Ç¨ is about the same value for money as a 500‚Ç¨ 7800XT, with actual 7800XT prices starting at 470‚Ç¨. AMDs newest generation is much worse value than their previous gen cards.",
      "Exactly the same boat here. When I saw the MSRP 5070 Ti (described by AMD as a more powerful card) next to $800+ 9070 XT, there was no longer any point in considering the latter."
    ]
  },
  {
    "brand": "amd",
    "generation": "9000",
    "tier": "mid",
    "matched_keywords": [
      "rx 9070 xt",
      "9070 xt",
      "9070",
      "rx 9070"
    ],
    "title": "ASRock reveals Radeon RX 9070 XT Taichi concept GPU in white, features built-in LCD",
    "selftext": "",
    "comments": [
      "This will just increase the price of the card for no good reason.",
      "This feels like we are seeing this approach a lot to various parts. Put a screen or RGB on a part and then up price it. I am not saying people cannot want these extras but how about offering a product without the extra. Give us the bare bones pure functionality products at lower prices.",
      "I can‚Äôt believe that [automotive trimflation](https://www.theautopian.com/trimflation-explaining-why-automakers-raised-prices-so-much-in-the-pandemic/) comes to GPU too ü§Ø\n\n*Reject AIB cards, return to reference card.*",
      "Meanwhile me with a metal side panel and PC under my desk saving money on all this more fragile aesthetic nonsense.",
      "They are doing the same things with AIOs now. They put a screen on it and then they charge 350$ for something that should cost 150$.",
      "AMD made a mistake in not offering a reference card this generation. Such a bad move for consumers.",
      "Combination of white plastic shroud and RGB always looks like some cheap plastic toy for me. And i don't get overall appeal of \"all white\" builds - every part has different shade of \"white\" and it looks awful aswell.",
      "I have 7900XTX white taichi. That was worth the price but 9070XT nope especially with some extra LCD screen on a mid range card costing probably then up to 5070Ti price.",
      "Honestly, not even $150. Arctic and Thermalright offer pretty much the best stuff available for less."
    ]
  },
  {
    "brand": "amd",
    "generation": "9000",
    "tier": "mid",
    "matched_keywords": [
      "9070",
      "rx 9070"
    ],
    "title": "YESTON launches dual-slot Radeon RX 9070 GRE/XT GAEA graphics cards",
    "selftext": "",
    "comments": [
      "Yeston does what others dont even dare to do.\n\nIts kinda refreshing to see\n\nbut im really curious how a dual slot, two fan design holds up vs the tripple fan, tripple slot models that came to be standard this generation.\n\nSure the 9070 (non XT) has 100W less power and its possible to cool 220W with a dual slot design.\n\nA tripple slot design for 300-360W for the 9070XT is good. Its big but many people value silence and temps a lot. My Pulse roughly reaches 55C core and 78C Hotspot while the memory is cooking at 90C.   \nHow much metal can you shave off a tripple slot design before it gets too loud/annoying or the memory/hotspot temp get too high?  \nI dont know. With 2 8Pins and a boost clock auf 2970Mhz it seems to be a 300W Powerlimit, but maybe its factory undervolted to reach something like 280W?\n\nEither way interesting GPU, but it might not perform as expected in the tight cases that would benefit from a two slot, two fan design",
      "looks pretty sweet actually. Nice and simple.",
      "No waifu?? Oh the betrayal, Yeston!",
      "Powercolor Reaper 9070XT is dual-slot. I have one and of course it's a bit louder with a smaller cooler but it's not a problem at all if you put the card in efficiency/quiet mode. It still uses up to 300W but keeps the fans down at the expense of higher temps and slightly lower clocks. Which is fine by me, I didn't buy it to squeeze every last fps out of it. So, these new cards from Yeston should do well in that regard.\n\nIt also looks like the Reaper is narrower than these new cards from Yeston so the Reaper may be a better choice if you are trying to fit one in a SFF case. And Alphacool just came out with a water block for the Reaper, that might also weigh in on your decision if you ever want to water cool it.",
      "Yo but WhereTF is the anime waifu art?",
      "58 mm is too thick for SFF",
      "The article is somewhat wrong, Yeston has launched the 9000 series cards worldwide. The issue is limited distribution and of course scalpers. Believe me, I was beaten once by scalpers and almost beaten a second time. But I did manage to score my 9070XT on the second try.\n\nThat said I wish they'd made the 9070XT waifu cards two-slot instead of the three-and-a-half slot monstrosity that came out.",
      "No waifu? No deal!",
      "while Yeston is known for their Waifu cards, if you ever go on their site to look at their track record, they will often also have a [very basic and boring model next to their unique models](https://yestonstore.com/collections/rtx-50-series).",
      "I got so excited for a second :c  \nOnly the GRE model is gonna be 2-slot but I'm never buying less than 16gb VRAM ever again.",
      "With the way GPU card sizes are trending, I don't think SFF is going to be viable much longer. Either that, or SFF cases are going to have to get a bit bigger across the market. Cuz the days of mini cards are rapidly reaching an end.",
      "That's quite subjective by ear. What is too loud for one person, another person might not even notice. But I did find this comparison that shows that under full load and stock settings the Reaper is 15dB louder than the quietest card. [Tweakers.net 9070XT roundup](https://tweakers.net/reviews/13234/11/13x-radeon-rx-9070-xt-mega-round-up-de-slimste-koop-is-niet-de-duurste-geluid-en-temperatuur.html) (Sorry, it's in dutch)\n\nA 10dB difference is considered twice as loud. And I can confirm that you don't want to run it at stock settings, just keep it in quiet mode. As for fan RPM, no idea, I haven't checked.",
      "Why are you GAEA?",
      "Sorry.\n..no waifu, no purchase.",
      "> that came to be standard this generation.\n\nHasn't it been standard since about the RTX 3000 / Radeon 6000 generation? IIRC it really shifted heavily toward bigger cards then.\n\nImo I'd love more smaller cards designs, every GPU targeting something like 55-60C temps is slightly annoying when they can run fine at 75-80C.\n\nBut it's not really a value add for many people to have a small card since no one uses expansion cards anymore, so they just make bigger cards that make them look better in reviews.",
      "Off the top of my head the R9 290X hit 290W TDP with a 2 slot *blower* cooler. It's definitely doable.",
      "maybe im not bad at expressing my point but this card making the case more clearly. the 980 ti is a 601mm chip, a giant chip by any measure. That means you have way more area to transfer thermal load to the heatsink. so the bigger the dye is the easier it is too cool it while using the same power. \n\nMeaning a 600mm 300watt dye will be much easier to cool then a 300mm 300watt dye because it does not have the surface area to transfer the heat as efficiently as the larger dye can",
      "~~YES! This should actually fit in the build I'm trying to do. Now I have to find a way to be able to buy this XT model if it doesn't get sold locally.~~\n\nEdit: Nvm, it looks like only the GRE model is 2-slot üòî",
      "Not what I was expecting from this vendor.  Not bad actually.",
      "VC left out the most important part while writing the article. Is this intentional? YESTON sold the 9070XT GAEA for online pre-order at 4999CNY (=599\\*1.13USD, yes, Chinese VAT) at the same time as the release, and resellers are also maintaining the same price range. AMD is still trying to sell MRSP."
    ]
  },
  {
    "brand": "amd",
    "generation": "9000",
    "tier": "mid",
    "matched_keywords": [
      "rx 9070 xt",
      "9070 xt",
      "9070",
      "rx 9070"
    ],
    "title": "Sapphire adopts ASUS GC-HPWR connector for Radeon RX 9070 XT NITRO and motherboards",
    "selftext": "",
    "comments": [
      "oh great, more horrible replacements for the pcie 8pin.\n\ndontcha just love a gpu that requires specialty motherboards to work at all and also has the ability to collateral half your system if something breaks.",
      "Looks like a big busbar to me, so no balancing issues between wires. This should be allot better than the 12vhpwr we have now.¬†\n\n\nAnd it may be proprietary now, if enough other companies join in, it will become the defacto standard. The same thing happened with front panel connectors, USB headers, etc.",
      "> This connector links the GPU to the motherboard and can be detached, allowing users to fall back on standard cabling if their board lacks support.\n\nGuys, literally in the article.\n\nIt can be detached.",
      "let us triple power, because we can otherwise make it work.  wee.",
      "The pins are not really the issue. Its what behind them and how the power is distributed. This seems fine.",
      "Kind of ironic that they did this on the one GPU that already hides the power cable better than any other GPU on the market lol.\n\nI do like this though. Hopefully it has better load balancing and protection than 12v-2x6. \n\nI'd love to see Buildzoid get his hands on a sample motherboard and GPU with this feature and do a PCB/power componet breakdown video.",
      "this getting wildly adopted would instantly kill every ITX motherboard and case ever made, plus driving mobo prices up in general, alongside obsoleting a ton of perfectly usable hardware, for literally no benefit.\n\ni pray this connector dies horribly.",
      "Except it would be really easy to create a card that can accept both. I've already seen pictures of cards where the back connector is retractable or detachable.",
      "\"This connector links the GPU to the motherboard and can be detached, allowing users to fall back on standard cabling if their board lacks support.\"\n\nSounds good to me.\n\nAnd also, from early this year:\n\n[https://www.tomshardware.com/pc-components/gpus/asus-gpu-power-connector-delivers-1-000w-for-cableless-builds-gc-hpwr-has-a-retractable-design](https://www.tomshardware.com/pc-components/gpus/asus-gpu-power-connector-delivers-1-000w-for-cableless-builds-gc-hpwr-has-a-retractable-design)\n\n\"The BTF-style power connector is an optional deployment on BTF 2.0-branded graphics cards. BTF 2.0 graphics cards can run on BTF-supported and traditional motherboards without the proprietary power connector, a feat that was not achievable with first-generation BTF Asus GPUs.\"",
      "I'm looking forward to needing to buy a new motherboard because mine doesn't support enough pcie power for my new GPU",
      ">Hopefully it has better load balancing and protection than 12v-2x6.\n\nWe still have to deal with 12V-2x6, but now it's on the motherboard. Since Sapphire did no load balancing on the 9070XT Nitro, I doubt they will do it on the motherboard.",
      "600W through a pcb is a non-issue. The SXM and OAM sockets already provide more than that.",
      "Sooo we're switching to an even smaller power connector after melting all those 12 pins?",
      "i would've thought that seeing this comment \n\n>The pins are not really the issue. Its what behind them and how the power is distributed. This seems fine.\n\nwould make you do furthur research on how the connector works and why those that caught fire did so in the first place. but nah lets circle jerk and double down on the logic that had been rebuttaled.",
      "I dont know what I think about 600W (potentially) going through the PCB of the motherboard - where the hell will they put all the copper for that?",
      "Why would it hurt ITX?\n\nThey can still put the connector on ITX boards.  \n\nIt also doesn‚Äôt have to be on the board.  You could just have an adapter on a cable to run next to your PCIe riser.\n\nThe only dumb thing about this connector is that the other end is 12VHPWR.",
      "They‚Äôre already detachable.  If they want to attach it to ITX that version will just attach differently.  It‚Äôll look dumb, but you won‚Äôt see it anyway.\n\nBut the cable/adapter option isn‚Äôt a bad option either.\n\nHonestly I hope this connector is popular enough that it replaces 12VHPWR completely.",
      "its not an asus video card",
      "I know but I have also seen another one where the connector is on a slider and can be retracted into the card.",
      "You know, extra VRAM chips on large gpus actually tend to fail as GPUs bend, so they're also points of failure. Nvidia out here doing everyone a solid by preventing their gpus from dying"
    ]
  },
  {
    "brand": "amd",
    "generation": "9000",
    "tier": "mid",
    "matched_keywords": [
      "rx 9070 xt",
      "9070 xt",
      "9070",
      "rx 9070"
    ],
    "title": "ASUS Radeon RX 9070 XT TUF OC Review",
    "selftext": "",
    "comments": [
      "Fantastic performance(noise,cooling), terrible/awful pricing.",
      "You can't even find these in stores anywhere. It's been like a paper launch for the TUF gaming Radeon GPUs."
    ]
  },
  {
    "brand": "amd",
    "generation": "9000",
    "tier": "mid",
    "matched_keywords": [
      "9070",
      "rx 9070"
    ],
    "title": "Alphacool launches waterblocks for 21 Radeon RX 9070 (XT) models, price starts at $199",
    "selftext": "",
    "comments": [
      "awesome they do it, but 200‚Ç¨ / $ for an 800‚Ç¨/$ card is... debatable, since they sold the water blocks for the more expensive, harder to cool 6900xt for around 150‚Ç¨/$\n\nstill, I'm tempted. their stuff just works",
      "Seems a little unnecessary",
      "That perfectly sums up custom loops.",
      "EK is dead. The biggest market leader is gone. It's up the rest to take up their mantle and hopefully not in a bad way.",
      "tons of people were complaining about their stuff not shipping and are still in dispute with EKWB about their orders from months ago. You can just look at the subreddit for EKWB. Yes, some orders did arrive, but when you have non-delivery rates this high after costumers have paid in full upfront, something is fucked with the company itself.",
      "Watercooling in general is a little unnecessary.",
      "my guy, custom loops are never good value. you do a custom loop because you want to do a custom loop. custom loops are highly individual and unique, no custom loop is the same as the other. heres a better comparison. why do people buy lego if they can just buy action figures or model cars? building is half the fun and the same goes for custom loops. nobody buys custom loops for the performance, i have a custom loop myself and havent even changed any settings on the gpu regarding clocks or voltage.",
      "Instead of spending 200$ to watercool a 9070 XT, invest 200$ to get a better GPU instead.",
      "Of course it‚Äôs fun but it‚Äôs also unnecessary 99% of the time. Nothing wrong with that",
      "I agree with this so far, I've not done a lot of testing but the card seems to manage its heat very well as is.",
      "not yet, but people are complaining about orders never shipping or very low quality product for their ridiculously high prices (400$ blocks with tooling marks and scratches)...so not technically dead, but basically dead.",
      "Eh. I don't know. So far my 9070XT runs like at 65¬∞C. The only \"hotspot\" is on the vram at +90¬∞C. But i don't think that justifies this purchase.",
      "Lower temp has never been a main factor for me with watercooling.",
      "I can assure you that while liquid cooling is high cost and high maintenance, it is also objectively the highest cooling power you can get for 24/7. Tuning boundaries pushed out a bit; it's fun",
      "It also really makes sense only for flagship hardware. Buying a $600 card and slapping a $200 waterblock on it when you could have just purchased a $800 card that's faster makes zero sense.",
      "uh. do you realize that this is just a block, right? this isnt an aio, its a block. if you buy that block and put it in your pc, your gpu wont work. it needs radiators, it needs fittings, it needs a pump and a reservoir, it needs a coolant mix, it needs tubes.\n\na custom loop will you usually cost you around a thousand bucks. \n\nofc theyre not value oriented, few build custom loops for the raw cooling performance, its a luxury thing to have. its like having an aquarium with fishes at home instead of just a normal dog as pet.",
      "Yes and no. The performance benefit isn't noteworthy, but it's fun to run a fully watercooled PC.",
      "problem is, theyre the only manufacturer so far offering blocks for the 9070 xt and they have quite a variety of cards, i mean 21 models is quite a lot. even if others follow, its unlikely theyll do all 21 models like alphacool.\n\nthey more or less will have a monopoly on 9070 xt blocks, maybe barrow or bykski will have one and bring down prices but i wouldnt count on it.",
      "on any computer component for that matterüòÇ.",
      "Custom water cooling does have much lower temperatures for a graphics card, but the main reason people use it noise.  You can use big radiators with big slow fans, which are much quieter than any air-cooled graphics card."
    ]
  },
  {
    "brand": "amd",
    "generation": "9000",
    "tier": "mid",
    "matched_keywords": [
      "rx 9070 xt",
      "9070 xt",
      "9070",
      "rx 9070"
    ],
    "title": "VASTARMOR launches Radeon RX 9070 XT Super Alloy Ultra featuring all the colors",
    "selftext": "",
    "comments": [
      "looks like a temu mouse",
      "That thing's ugly as sin. \n\nWhoever designed it and whoever approved it need to reconsider their career path.",
      "The card looks horrendous",
      "I do quite like it just because it reminds me of the crazy use of colors in the late 90‚Äôs/ early 00‚Äôs when I was a kid.",
      "They will launch with 100 units and then dribble 10 each month after that.",
      "I‚Äôm only buying this if it‚Äôs being released for close to MSRP",
      "This is complaining at a high level.",
      "I'd put this in my system and go full rgb hell",
      "I like it, reminds me of the older Windows XP/Vista era designs where it was just a blower motor design w/ graphics printed on lol.",
      "Looks like they just used a randomizer...",
      "It covers 340% of male perceived color palette and only 65% of female perceived color palette.",
      "That is an.... inspired design",
      "/puke. But, offer it to me for $600 and sold! \n\nThen again i've never heard of the company, so probably wouldnt buy it anyway. But if any of the normal players want to offer me a puketastic 9070 xt( < 3 slot cooler) for $600, sold!",
      "made by ai lol",
      "‚ÄúI told you, those are both blue‚Äù",
      "no silly, it was killed in a 1v1 against the orange man. now people are hired based on \"competence\"",
      "I hate to be that dude but jesus that‚Äôs a bit much. I don‚Äôt mind some RGB but having the actual card coloured ain‚Äôt my thing. Too rainbow for me",
      "Is DEI still a thing?"
    ]
  },
  {
    "brand": "amd",
    "generation": "9000",
    "tier": "mid",
    "matched_keywords": [
      "9070",
      "rx 9070"
    ],
    "title": "AMD Radeon RX 9060 XT to feature higher game clock than RX 9070 boost clock, PCIe 5.0x16 specs mentioned",
    "selftext": "",
    "comments": [
      "If true, the PCIe 5.0 x16 interface is intended to mitigate insufficient VRAM. If the GPU runs out of VRAM, it will need to constantly access the system memory.",
      "This helps with edge cases.\n\nIf the game needs 8.5GB VRAM, this solution might be sufficient.\n\nIf the game needs 12GB VRAM, this solution will not work.",
      "It's like the PS2. You don't have 4MB of VRAM. You have 4MB + bus throughput per frame of VRAM! (nvidia: note that down, we'll call it \"effective VRAM\")",
      "Of course it works. You just need to run multi-multi-frame generation off of your iGPU. /s",
      "By the time you're running out of VRAM performance will absolutely tank even with¬†PCIe 5.0 x16. You might get 9 FPS instead of 5 FPS but it will still be unplayable.",
      "Perhaps, but that wasn‚Äôt the actual reason.\n\nThe real reason is that the 9070XT and 9060XT reused a bunch of the design and gate layout directly to save on engineering costs and floor planning. \nDie savings of doing a x8 PHY and a reduced data path are not worth the extra engineering costs of doing a whole second synthesis and gate layout. \n\nX16 Gen5 PCIe also doesn‚Äôt mean that the internals of the GPU fabric can saturate it.\n\nBuilding your fabric for x16 gen4 BW can be smart and then include x16 Gen5 PHY so that you can run x8 Gen5 or x16 Gen4 and get full BW.",
      "I welcome PCIe16x. And it makes 100% sense there are lot of people still on PCIe 3 systems today that would welcome a budget GPU (f.e. Ryzen 5xxx if you happened to upgrade on b350 b450 a 520 mobo).",
      "The GeForce RTX 5060 Ti has 51% of the shaders that the GeForce RTX 5070 Ti has.\n\nIf the Radeon RX 9060 XT runs into a wall, it's more likely because of insufficient memory bandwidth.",
      "I wonder how much money is saved by downgrading from x16 to x8 and x4.\n\nThere seems to be more and more attempts to use the newer PCI-e standards as a substitute for the full 16 lanes. Is this a way to get people to buy new motherboards?",
      "Isn't it like half the die and shaders of a 9070 XT? I'd hope they'd be able to clock that thing higher, only way to squeeze some decent performance out of it.",
      "or you know having a competitive advantage against nvidia ? Because there are lot of people with PCIE 3.0 systems (shit AMD is still selling and making CPUs and chipset with only PCIE 3 support) where 8x lanes is not enough but 16x will work fine - and nVidia has only 8x offering in this budget segment.",
      "That's for the VRAM but when it runs out is the problem which it has to fetch from the RAM which goes through the PCI-E and being able to transfer it twice as fast will mean that it won't be as slow when it has to fetch from RAM, reducing the impact of having such a small amount of VRAM. For systems with PCI-E 5.0 it won't be as impactful but it will make a lot of difference for those on 3 or 4.",
      "The main reason we usually get x8 on this tier of cards is because they‚Äôre used in laptops and running a narrower link saves energy. Then the same chip is used on the desktop and we get stuck with it. Yes it saves mm2 die space, but it isn‚Äôt the main reason.\n\nAlso: AMD has done this for 10 years now. It only became news because cards got expensive so buyers who would never look at the low-end before are now considering it.",
      "ComputerBase did testing with the GeForce RTX 5060 Ti 8GB.\n\nGoing from PCIe 5.0 x8 to PCIe 4.0 x8, some games went from \"severe impairment (just playable)\" to \"unplayable\". \n\nI imagine that PCIe 5.0 x16 helps games in those edge cases.\n\nhttps://www.computerbase.de/artikel/grafikkarten/nvidia-geforce-rtx-5060-ti-8-gb-test.92401/seite-2#abschnitt_pcie_40_vs_pcie_50",
      "It seems AMD is using the full PCIe 5.0 x16 interface, most likely to help mitigate the effects of the 8GB model running out of VRAM.",
      "TechPowerUp has tested the GeForce RTX 5060 Ti 16GB with PCIe 5.0 x8, PCIe 4.0 x8, and PCIe 3.0 x8.\n\nThe difference is small for the 16GB model.\n\nhttps://www.techpowerup.com/review/nvidia-geforce-rtx-5060-ti-pci-express-x8-scaling/",
      "TechPowerUp has tested the GeForce RTX 5060 Ti 16GB with PCIe 5.0 x8, PCIe 4.0 x8, and PCIe 3.0 x8.\n\nThe difference is small for the 16GB model.\n\nhttps://www.techpowerup.com/review/nvidia-geforce-rtx-5060-ti-pci-express-x8-scaling/",
      "I will believe 16x PCIe only if it's official. 16x doesn't make much sense at the low end.",
      "It definitely is a problem today. Just watch benchmarks. And I am definitely keeping GPUs atleast 2 years - ussually 3.",
      "The 9070 XT is already clocked very high on it's V/F curve. There's a reason most overclocking results are discussing the 9070 non-XT, because the XT doesn't really have much headroom.\n\nAs for performance, it will likely be quite good, definitely more than half a 9070 XT"
    ]
  },
  {
    "brand": "amd",
    "generation": "9000",
    "tier": "mid",
    "matched_keywords": [
      "rx 9070 xt",
      "9070 xt",
      "9070",
      "rx 9070"
    ],
    "title": "AMD Radeon RX 9070 XT is not available at MSRP for over 2 months",
    "selftext": "",
    "comments": [
      "nevermind retail, i havent seen one in stock locally since release week.  dafuq.",
      "$699 USD is the real price. You won't see $599 9070xts again as AMD literally had to give out vouchers to retailers to sell it at $599 on launch day, so the retailers didn't lose money on the sales. It was a fake MSRP. The review videos are all based on this fake value of the 9070xt, which is a W for AMD as those videos still exist glazing how good the card is, though the price isn't the same anymore.",
      "Seems a US problem, many other countries they are available, but still 100-150 over MSRP.",
      "Tried buying a 9070 XT Reaper on launch day for $599. No luck.\n\nI was \"able\" to purchase the powercolor reaper earlier this week on Amazon for $750. Initially, I was stoked. The next day, I came to my senses and cancelled the order. \n\nThey are out of their god damn mind by charging $150-200 over MSRP. \n\nThe next card I purchase will be at MSRP. I dont give two shits if it's an NVIDIA card at this point.",
      "Take this information with a grain of salt.\n\nApparently those are EU prices and they \"averaged\" it.\n\nSome countries in Europe sell it for E1000 while others sell it for E750, hence the average is higher across the board.",
      "Might aswell buy a 5070 Ti then",
      "Because MSRP was a lie, AMD always intend to it be around $700-$750 and only did last minute store rebates for $600 when they saw the price of the 5000 series, it was a limited early adopter fee.\n\nI was there with 4 websites open the second they launched and they got cleaned out by bots in 30 seconds for the $600 and within 5 mins for all of the models.\n\nI intended to do a full upgrade to AM5 system(Mobo, Ram, Cpu) so I wanted a cheaper GPU but after a month of checking the only regular restocks were $800+ 9070xts hell with that nonsense, a 5070ti popped into stock at MSRP so I went Nvidia, I imagine I'm not the only customer AMD lost over not enforcing MSRP.",
      "That should be illegal.",
      "In Germany Msrp is 689‚Ç¨ iirc.\nCheapest card i could find was just about 750‚Ç¨ so 60‚Ç¨ above msrp.\nVat included for prices of course.",
      "$800 is not the standard price. I‚Äôm still holding AMD to their word & will only purchase this card @ $599. \n\nIf it happens, great. If I‚Äôm unable to find the card at its advertised price‚Ä¶.even BETTER. This is not a necessity for me & I‚Äôm better off saving my money or giving it NVIDIA instead.",
      "\"Manufacturer suggested retail price\" is purely a marketing number, there's no legal obligation for anyone to sell it at that price. It's annoying though.",
      "Especially funny after all the fake MSRP drama for nvidia.",
      "Let‚Äôs say we use your lower end of 750, is that MSRP?",
      "Whose fault is that? I'm in another hobby where the manufacturer caps the price their products can be sold by partners, break that agreement and they can cut you off and stop you selling their products. I find it strange watching Nvidia and AMD allowing their partners/retailers to freely do what they do with their pricing.\n\nI had a look out of curiosity last night at some GPUs to see if prices had settled at all and the cheapest 9070XT I could find is the Sapphire Pulse at ¬£650. I'm not currently looking to upgrade my GPU so it doesn't really affect me, but I try to keep up with the prices none the less for when I do a new build.",
      "The difference is AMD is not providing the end completed product, they supply the GPU, so they cannot control the price the same way. Each board partners product is theirs uniquely.",
      "The Microcenter in Denver has them in stock more often than not lately.  They have 6 models in stock right now.  They still tend to go quick, but it seems like every other day or two they get more in, and they're usually around for a couple of days.  The 5080's have been in stock for a while, and the 5090's even make appearances once or twice a week.  They're all way over MSRP, though.\n\nI'm unsure about Best Buy since I never have a reason to go there, but I think we're on the verge of seeing them in stock more often.  Just don't expect them at MSRP.",
      "Newegg has 9070xt for 5070ti minus $50, you might be right on that one.  Microcenter has it for $150 less.  But for either one, you have a more stable driver experience with AMD.",
      "Considering micro center has the reaper listed for $800 now that $750 wouldn't have been completely terrible if you really needed the upgrade.",
      "Probably just a US thing because here in Canada they've been in stock pretty much everywhere for the past while and not running out, though not MSRP. The cheapest model I can find is $949.99 (\\~$687.33 USD). Most models go are in the low $1000+ mark.",
      "Then the price difference becomes only 13% instead of the 25% @ MSRP that the tech influencers based their ‚Äúgreat value‚Äù verdict on. Suddenly that value proposition becomes quite different."
    ]
  },
  {
    "brand": "amd",
    "generation": "9000",
    "tier": "mid",
    "matched_keywords": [
      "9070",
      "rx 9070"
    ],
    "title": "Is anyone looking to buy an Rx 9070 steel legend",
    "selftext": "I bought an 4070 to for my editing and it's just been sitting here and I only used it for 3 days  still works as seen if I can help one of you get a deal and not pay scalper prices and get rid of this card so it's not just sitting here  a win is a win  DM me with a offer to ensure your safety I will just it on eBay send you the link and let you buy off there so there is no scam ",
    "comments": [
      "Sold already my apologies",
      "Well yes now they are it was not the case upon release sold out immediately and went upwards to 1k especially the special colored ones",
      "600",
      "XT or just base 9070?",
      "DM",
      "Just the base xt steel legend I wasn't paying 1k for an xt I won't lie",
      "It‚Äôs only like 800 tho",
      "All good how much did you end up selling it for?",
      "only 700 flat regularly on newegg"
    ]
  },
  {
    "brand": "amd",
    "generation": "9000",
    "tier": "mid",
    "matched_keywords": [
      "rx 9070 xt",
      "9070 xt",
      "9070",
      "rx 9070"
    ],
    "title": "I Flashed An AMD RX 9070 XT BIOS Onto My RX 9070...",
    "selftext": "",
    "comments": [
      "Kind of wondering why it seems no other youtuber tried or even reported about it. The only other video I could find is some low effort AI dubbed one.",
      "This guy used a dual bios card for that reason, mess up one and you can just switch to the other",
      "My 9070 can already hit 275w anyway.  Going from 245w-275w adds like 3% performance for a LOT more power.  Probably not worth it, plus cooling could be more of an issue.\n\n[https://www.reddit.com/r/radeon/comments/1jjovu0/9070\\_ocefficiency\\_data/](https://www.reddit.com/r/radeon/comments/1jjovu0/9070_ocefficiency_data/)",
      "...because if you bricked it, you are SOL and can't even buy another one",
      "It's actually not common as you think, it's usually reserved for the higher end versions. The reference and mid levels rarely have dual bios",
      "Watched this yesterday; the summary is that the alternative bios cranked the power from 200-ish to 300-ish watts and gave a fair amount more fps. Pretty sure this is only for use as a trick for people who make a living doing tech videos and not for typical gamers.",
      "You don't know it but when you buy two R7 9700X, you can build a R9 9950x :)",
      "Quite a lot of modern GPUs have VBIOS switch, performance and silence mode. So in theory you can use the other one if your current is bricked right?",
      "I suspect the AIB engineers may not have specced the power delivery parts of the card to handle 150% continuous load so it's unlikely the official flashing software would ever allow it.",
      "Yes, but if you take the 16GB of your graphics card and solder it under your processor,  \nyou will have a furious 3D v-cache :)",
      "Dawid doesn't get enough credit. That dude deserves a wider audience. He's hilarious.",
      "FYI - I'm not the dude in the video",
      "The ones trying to make a living making YouTube videos often have to be careful not to offend the companies they review products for, or they'll stop getting free, advance-shipped products to review.\n\nShowing people how to circumvent the product segmentation is probably a good way to not get free cards in the mail.",
      "This is the first time I‚Äôve seen someone physically flash a bios with an external device. I almost thought he was going to resolder the chip altogether\n\nIt was pretty cool what he did, wish he ran more benchmark numbers. Props to this David guy on YouTube",
      "No sir, you built an INTEL not an AMD :)",
      "This. Dual vbios is rare even for Nvidia. And given how ludicrous prices are becoming for both brands, expecting most people to pay another premium for dual vbios is asking a *lot* of the consumer base.",
      "Dawid did get the power up over 300 watts but you all forget it also shot up 300+ MHz increase in speed. So an extra $2 a month in power to achieve 9070XT results. Nuff said.",
      "More like one R7 9800X3D and a 9700X",
      "We know.",
      "Isn't this straight up false? I keep hearing legit PC modders talk about how you can easily restore the original BIOS by using either a second GPU or the iGPU of your CPU."
    ]
  },
  {
    "brand": "amd",
    "generation": "9000",
    "tier": "mid",
    "matched_keywords": [
      "rx 9070 xt",
      "9070 xt",
      "9070",
      "rx 9070"
    ],
    "title": "ComputerBase - RX 9070 XT from PowerColor in the test: Red Devil and Hellhound vs Asus, Sapphire vs Asrock vs XFX",
    "selftext": "",
    "comments": [
      "The Hellhound looking really good.\nShave off a pound of aluminium, half a slot and an 8pin with nothing lost.",
      "PowerColor is doing a great job these last few gens, the Hellhound was also considered the best model for the 7800XT in many reviews.\n\nReally appreciate the fact that they don't have a massively big cooler, clean design and still has amazing temperatures and it's one of the most quiet 9070XT you can buy.",
      "If you are using google Chrome it should be translating automatically, if not you can click on the top right corner to do so.  \nPretty much says that PowerColor delivered a great set of models, that are the most quiet of all brands while keeping temperatures low, XFX has lower memory temperature but the editor found that it's the most noisy model of all brands.",
      "Edge should automatically translate the page to English.\n\nOther browsers likely have a similar feature.",
      "True that, I have a 7800XT Hellhound and it's my favorite card I had in a long time. The reason why I bought it was that I've seen a couple reviews (Techpowerup and Hwunboxed) and the Hellhound cooler was better than the Nitro+",
      "Need a translation",
      "What browser are you using? Major ones have been auto translating pages for many years now.",
      "that's not how these cards work. it's not \"clock headroom\", it's what it clocks in this workload with this power, voltage, and temperature. it can clock up to 3450 mhz in lighter loads like adrenalin stress test, because 3450 is the default max of all xt models. listed boost clock is the estimated clock speed in a specific work load. neither the hardware nor the software have that listed boost clock anywhere in practice",
      "it's  3-year warranty for powercolor red devil in Uk.",
      "Hell Bau Bau is doing a great job",
      "I just bought one not too long ago and haven't had any fan issues.",
      "Agreed. Historically was a Saphire guy, but last few gens have me more impressed with Powercolor.",
      "I bought a Powercolor 9070 and with a total length of over 34cm I'd say it does have a rather beefy cooler. I love that it's a true 2-slot card, but it's one hell of a squeeze on my case.  \nThat being said, it is extremely silent. Eerily so, where on some games I had to check if it was overheating due to broken fan control or something. Impressive card for sure.",
      "Brb 3450 furmark donut 800W",
      "3450 furmark is a joke, but the idea behind it is not. With no power limits, these chips can be much faster. The factory limits are for reliability. 7900 XTX doesn't run 3200 average clock, either, but mine has done it for for two years because it can. Same thing applies for the 9070 XT. Throw an Alphacool block onto whichever model has the best VRM, then EVC or shunt it (per buildzoid's trick) and you're in business.\n\n9070 XT(X) is a hero's journey",
      "power increases have diminishing returns. there's a big dropoff around 330w. there was barely any point running 374w over my stock 340w. the difference between 304w (msrp default) and 374w (max without shunt mod) was about 3% for me only in benchmarks. 2% of that came from 304w -> 330w. lol\n\n\nI just think you and other people are mistaken that they are artificially limited. at first I wondered why the top 2 brands went with 330w default, but now I know\n\n\nyou're free to waterblock yours, but I think you'll find it's nothing special. you'd be better off with a 5080 than waterblocking a 9070 xt",
      "9070 XT with a block and power mod is still cheaper than 5080 and you get to be a cracked nerd instead of a consumer",
      "powercolor seem very good\n\nhas the fan issue on the reaper been solved? it's the cheapest model here but I am scared to get one with that problem",
      "Freq_GET of only ~2700 wow\n\nLiterally 20% clock headroom left in some workloads",
      "idk why all reviews have mercury oc magnetic air and don't consider comparing noise levels to the one without. magnetic air has horrible noise and all these reviews have tricked people into thinking the normal mercury oc model is crazy noisy too"
    ]
  },
  {
    "brand": "amd",
    "generation": "9000",
    "tier": "mid",
    "matched_keywords": [
      "9070 xt",
      "9070"
    ],
    "title": "Picked up am XFX Quicksilver Magnetic Air 9070 XT for ¬£599, time to sell the 9070!",
    "selftext": "",
    "comments": [
      "I can do 5¬£ , deal?",
      "Not massively but I thought the price was too good to pass up",
      "Username checks out üòÇ",
      "It was on the Ebuyer eBay store with a 10% code which brought it to ¬£604 then I had a ¬£5 voucher which brought it to ¬£599",
      "Can't sell it just yet, I need to buy a bigger case for this new behemoth card since it won't fit in my existing one - thought I might be able to squeeze it but nope.",
      "gotta change it üíÄ",
      "Nice :)",
      "Where did you find it at that price?",
      "How much you want for the 9070?",
      "Is the XT really that a difference?",
      "I'd like to know as well!",
      "Slick stuff bro‚Ä¶. W‚Äôs in chat",
      "Ebuyer eBay sale"
    ]
  },
  {
    "brand": "amd",
    "generation": "9000",
    "tier": "mid",
    "matched_keywords": [
      "9070",
      "rx 9070"
    ],
    "title": "PowerColor reveals black & white Radeon RX 9070 REVA GPU series",
    "selftext": "",
    "comments": [
      "We don't want more models, we do want models at MSRP",
      "Looks clean hopefully doesnt have a furro girl behind."
    ]
  },
  {
    "brand": "amd",
    "generation": "9000",
    "tier": "mid",
    "matched_keywords": [
      "9070 xt",
      "9070",
      "rx 9070"
    ],
    "title": "Rx 9070 vs RTX 5070",
    "selftext": "So in the last month I was about to test out the Sapphire Pure 9070 and the Gigabyte Eagle OC Ice 5070. The performance surprised me by Nvidia. As we all know the Rtx 50 series are not receiving that much love due to all the issues we have hear. BUT! I overclocked it (300+ core and +2000 memory) and man it‚Äôs almost all the games I play it was performing better than the 9070 overclocked as well‚Ä¶. I have a 9800x3d on a asrock b650 motherboard with 64gb of ddr5 6000mhz quad channel ram. The nvidia card does run a little hotter but temps are reasonable. On the 9070 it was sitting at 50-55c gaming with very high/ultra settings and the 5070 60-65c with the same settings. Both cards are amazing, both cards have its favors in games. For streaming the nvidia card is way better of course, always have been. In conclusion, get either card and you can‚Äôt go wrong. Just make sure you don‚Äôt spend 200$+ the msrp. Max to spend I would say is 650 on either card. But when prices normalize, if they do, go with the 9070 xt for sure. But that post will be at a later time‚Ä¶. 9070 xt vs 5070 ti :) Hope this helps with your gpu purchase ",
    "comments": [
      "I think the 5070 would be seen as a great card if the 40 series didn‚Äôt exist‚Ä¶‚Ä¶ the issue wasn‚Äôt the cards performance, it was the rise in price and lack of performance uplift compared to its predecessor.",
      "Whichever you get at a lower price tbh. The 9070 performs better on average but not so much that you should choose it over a 5070 if you find the 5070 to be priced consistently lower, which in my area I tend to find them at MSRP quite often",
      "10% is a huge performance uplift that most certainly does not come from a driver and apply to all games across the board. That‚Äôs game to game basis at best, and ones that already performed worse",
      "Cyberpunk is less intense on vram than Indiana jones, but you can get both games to use more than 12gb of vram at 1440p in my experience. 9070 falls behind in rt which will hurt it in Indiana jones, but as far as I‚Äôm aware the amd cards actually do decent in cp ray tracing this gen.",
      "To be honest I wouldn't listen to a thing you said after you said the mod requires a dual bios, something it doesn't \n\nalso I refer your statement back to you\n\n>   \nHoly crap read you baboon\n\nAs what I said are valid critics on you claiming you are over clocking and pushing both cards... are you really in any country where overclock voids your warranty so will bios flashing... in any country where it doesn't it will not. \n\nSo long story short for the person who actually isn't reading ... it is no more unsafe than overclocking meaning it is worth the same same to do if you can. By not doing it you aren't have a true apples to apples test. This gives the Nvidia an unfair advantage. You should admit that instead of saying, \"AAAAAAAGAIN I WOULDN\"T DO IT.\" because while you may not by ignoring the fact you are actively lying to people through omission that you preformed a fair and balanced test.",
      "Depending on the kind of games one runs, as well as the resolution, the 5070 is often crippled by the insufficient vram. It's not a bad card, but it has limits in one particular aspect and is often held back by poor design. Nvidia has more mature upscaling and other features (fgen, mfg stand out) that use non-insignificant amounts of vram. So naturally, green cards that normally suffer from vram amounts are held back even more.",
      "‚ÄúJust make sure you don‚Äôt spend 200$+ the msrp.‚Äù Great advice.",
      "I've had my 5070 for almost 2 months and have no issues with it. On my 1440p 240hz OLED monitor , with DLSS and Frame gen, I hit 224 FPS locked on everything I ever throw at it , with my temps being below 65 C. Smooth ,quiet and beautiful on that OLED",
      "But you are not wrong there. especially the 40 super series",
      "In the most recent driver update the 50 series did get another 10% performance uplift. We just need to wait and see if the reviews revisit the 50 series in the next couple of months.",
      "I didn't run to any. Maybe because I haven't played games like Indian Jones or Cyberpunk because I don't own those games.",
      "5070ti is really a different card than the 5070 and worth it if you find at msrp. Very few 9070xt are going for anywhere near msrp so the pricing is pretty close. The 4070 was also a disappointment for the most part.",
      "I don't play in 4k. You try it and let me know how it goes.",
      "I was playing with my 5070 on my G9 57\"... 7680x2160...only in Warthunder, but I usually run max detail sans RT and 120fps with DLSS on balanced was no issue at all. It was using about 50w more power than my 4090 at the same settings though. VRAM didn't max out either.\n\nWas perfectly playable.\n\nDid some FH5 also at the same res, all set to ultra, again with DLSS and it was perfectly usable.\n\n5070Ti arrives today to play with, let's see how it is. Should hopefully be a good FG card as thats its main purpose for me.",
      "They honestly don‚Äôt remember..I read their stupid comments everyday and remind them that a 4080 was $1199 msrp with the same performance as a $750 5070ti",
      "Thx. I want to get the 9070 but the 5070 is consistently much cheaper",
      "Cyberpunk won't run into any VRAM issues even with PT",
      "Just wait for a 9070 it will be worth it",
      "Thanks üôè for games I didn‚Äôt text others are helping out with that üòÅ lol so this helps lol",
      "Yes the 5070 is an amazing card for 1440 gaming"
    ]
  },
  {
    "brand": "amd",
    "generation": "9000",
    "tier": "mid",
    "matched_keywords": [
      "rx 9070 xt",
      "9070 xt",
      "9070",
      "rx 9070"
    ],
    "title": "Vastarmor launches Radeon RX 9070 XT Alloy GPU",
    "selftext": "",
    "comments": [
      "Vastamor is a Chinese brand, focussing on China. So the majority of Reddit users won't buy it.",
      "Excellent. More cards nobody can‚Äôt get.",
      "It's a pretty nice looking card, gotta say. I like the little mecha helmet icons on the fans.",
      "Good to see they are sticking with triple 8 pins.",
      "Also credit for using a black retention bracket. Love to see that match the rest of the theme rather than just being silver all the time."
    ]
  },
  {
    "brand": "amd",
    "generation": "9000",
    "tier": "mid",
    "matched_keywords": [
      "9070",
      "rx 9070"
    ],
    "title": "Acer mistakenly lists Radeon RX 9070 GRE XT NITRO graphics card",
    "selftext": "",
    "comments": [
      "They should have just named it 9070 GRE AT, as least we'll know it's great.",
      "XFX XD AMD RX AI 9070 GRE XT ULTRA MAX+",
      "This happens with every other card launched in the last 10 years. At this point, its not a mistake but marketing.",
      "Forgot Ultra...",
      "Strategic tease after nvidia gpu release. Well done amd, hurry up",
      "Needs FURY before the Max, as a callback to the older ATI cards.",
      "As long as AMD don't release anything better than the 9070 xt I bought this year I don't mind lol",
      "9070 Frosties Edition.",
      "You are wrong then. Acer's Nitro branded laptops were already a thing prior to 2014, while Sapphire only started the Nitro line with the 300 series in 2015. It is literally factual context to the comment above, but it seems the Sapphire fanboys can't take it lmao.",
      "Bring back RAGE while we're at it.",
      "Leaking cards that haven't been announced yet, but yet they still haven't released their 9070 / 9070 XT cards. Powerplay move right there üòÜ",
      "Sadly I imagine these 9070 GRE cards will end up selling at $550-600 since there are absolutely zero 9070 / 9070 XT cards available for those original MSRP prices. A few will trickle out at lower price, whatever the GRE MSRP price is, but just at launch then gone.",
      "Are they trying to steal some Sapphire customers? Can't rly see a good reason to use Nitro name as well",
      "‚ÄúMistakenly lists‚Ä¶‚Äù - no such thing in marketing",
      "Can we please get some sub 280mm cards?\nI don't even need full ITX just more compact cards for my smaller cases please",
      "*Featuring Dante from the Devil May Cry series*",
      "Tbf companies were showing off the 9070xt months before the official release lol",
      "havent seen a single acer 9070 xt yet",
      "And here I am waiting for a MSRP 9070XT, which fits nicely in my budget.\n\n\nI guess I will hold onto my RTX 2060 6GB a little longer.",
      "9070 GRE XT XTX RX TI Super Duper"
    ]
  },
  {
    "brand": "amd",
    "generation": "9000",
    "tier": "mid",
    "matched_keywords": [
      "9070",
      "rx 9070"
    ],
    "title": "RX 9070 fans stop and game briefly pauses...",
    "selftext": "As the title says, every once in a while (I'd say once every 20-30 minutes) while gaming the fans on my RX 9070 completely stop and the game pauses for 1-2 seconds then it resumes as if nothing happened and the fans fire up again.\n\nI'm not a gamer, and the only game I play is Chivalry 2 online but these random pauses often end up with me getting killed so it's sufficiently annoying.\n\nSystem is a 9700x / 9070 (not-XT) / 32GB / 2TB Sandisk NVME (OS and game drive) / 850W Thermaltake PSU... all software (including the bios) are updated. Card is the Gigabyte 9070 OC edition.\n\nIs this behavior normal? Is there a way to make it so the fans just stay fired up while gaming through Adrenalin? This never happened with Chiv 2 on my older RTX 3060 12GB, but overall the performance difference is night and day (1440P ultra at 150+ FPS on the 9070, had to really turn things down just to get 80FPS on the 3060).",
    "comments": [
      "There may be a problem with the power supply. Can you give information about the cable connection?",
      "Obviously it's not a normal thing, but at the same time it's such an uncommon behavior it can be difficult to track down why it's happening.",
      "my 6650xt stops its own fans when not working at over 55%. I never touched anything, but maybe there is some option to turn off this thing and make it spin non stop. Maybe yours have the same thing applied, and you should turn it off. I have no clue how this option is called tho, in adrenaline. It's some option to save energy while not using the gpu over a certain percentage.",
      "I'm using separate connectors (not pig-tailed). Someone DMd me saying I probably had zero RPM mode enabled in the drivers. I think they're right, I'm going to try turning that off which should keep it from shutting off the fans mid-game.",
      "Makes sense. Try and see the results."
    ]
  },
  {
    "brand": "amd",
    "generation": "9000",
    "tier": "mid",
    "matched_keywords": [
      "9070",
      "rx 9070"
    ],
    "title": "AMD to launch Radeon RX 9060 XT on May 18th, RX 9070 GRE pushed back to Q4",
    "selftext": "",
    "comments": [
      "OK, but when are they launching the 600 USD RX 9070 XT?",
      "I'll give you an even better idea, AMD: nuke the 8GB version from orbit and pretend it never happened.",
      "Or price it incredibly well. For like 200 bucks, it could be a low end hero GPU.",
      "That's perhaps the non-XT work. Taking into account that Intel Arc B570 and B580 already offer 10GB and 12GB of RAM and a level of performance roughly equivalent to a 6700 and 6700XT, $200 is the only place left for an 8GB card unless they want to be rightfully clowned on as much (or more) as Nvidia has just been.",
      "goodluck with that dude",
      "Inb4 underpowered 8GB card unobtainable at MSRP",
      "I want 300-400$ cad midrange gpu\n\nI should probably start working on my time machine",
      "lol are both the deleted comments yours? Uncivil language indeed! XD\n\nAnyway those shouldn't be an excuse for those of us outside the USA.",
      "Thanks!",
      "They did it literally last gen, and one before than, and one before that. It's better to offer a 256 bit and 256 bit option (9070 / 9070 XT) rather than 192 and 256 bit options (7700 XT / 7800 XT)",
      "wtf have I really just found the first big sub moderated by republicans lmao",
      "Why they just refuse to give a middle ground between 128 bit and 256 bit cards? 192 bit 12GB cards for the mid range makes the most sense",
      "Filtering an accurate, broadly relevant term like that is *quite* absurd.",
      "Waiting how AMD respond with price, 5060 Ti 8GB at 380$ already tested by HWU and its disaster performance compared to 16GB version\n\n  \nHow AMD will sell this, dont say they still follow 50$ less than AMD tactic again",
      "As soon as tar\\*\\*fs are lifted. Automod seems to dislike that I mention that word, but it's true.",
      "I like how the leaked $750 MSRP that AMD assured us was false (even though we had extensive documentation of) turned out to be true. I haven't seen one lower than that since launch.\n\nThen meanwhile the 5070Ti as of this month can usually be had for MSRP as long as you're willing to wait a few days for stock. I ended up getting it, and it was literally cheaper than the 9070 XT (which I was interested in) next to it in the same stores.",
      "8GB = DOA",
      "The B580 fits the bill but has the CPU overhead issues. The 9060 XT 16GB will probably be around $450 CAD.",
      "So what? They also never offered mid-range cards with 16 GB of memory until the RDNA rebrand, does that mean that we should never get cards with 16 GB? What a stupid arguement. 8GB is not enough.",
      "Yep, in europe it should be like 630 euro, considering 20% vat"
    ]
  },
  {
    "brand": "amd",
    "generation": "9000",
    "tier": "mid",
    "matched_keywords": [
      "rx 9070 xt",
      "9070 xt",
      "9070",
      "rx 9070"
    ],
    "title": "AMD RX 9070 XT Update: Transition to Samsung GDDR6 Memory for Improved Thermal Performance",
    "selftext": "",
    "comments": [
      "Honestly just run a slightly higher fan curve and undervolt. I reduced my memory temps by 10C bringing them down to mid 70s.\n\nEdit: forgot to add: reduce power level by 10-15 percent. I still go up to 3100 MHz with 250-270W power instead of 320W and more heat.",
      "I just bought a Sapphire 9070xt Nitro+ from Newegg last week. How do I know if I got the spicy one?",
      "Install GPU-Z software and look at the \"Memory type\" field",
      "Interesting.   \n  \nThe high memory temps have bothered me, reaching 95-98¬∞C under full load. But I have seen higher temps with other cards in the past, so I'm not sure if I should worry about it. \n\nI was able to shave off 10 degrees with some undervolting and by running a more aggressive fan curve.",
      "Unless the product did not work as advertised, the consumers were not \"ripped off\".",
      "At least I got mine at MSRP, so even with the \"worse\" vram I don't feel that scammed tbh",
      ".....\nOkay, but can we get them close to MSRP?",
      "I'll check it out once I get everything built. Was gonna use a 9700x I had picked up a while back but after learning that it can be cooled effectively with a 240mm radiator I opted for a 9800x3D, which shows up tomorrow.",
      "Seems like those who bought the first batch of goods were ripped off.",
      "My Red Devil has the Hynix memory and gets up to about 82c under full load with Furmark. I'll keep an eye on it while gaming this evening.",
      "Same model, I checked and it's samsung memory, bought 1-2 weeks ago",
      "It really doesn‚Äôt matter. 85c isn‚Äôt a problem",
      "An upgrade to 24 Gbps VRAM would also be a welcome improvement, as the increased bandwidth could improve performance in 4K gaming and inference tasks.",
      "It's crazy the original GDDR6 modules were getting that hot. Meanwhile with OCed GDDR6X the hottest I think I've seen is like 78C and that's rated for even higher temps than regular GDDR6.",
      "Typical early production batch I would say. These products get better as production gets more mature.\n\nAnd no, no one is getting ripped off.",
      "GDDR6x had PAM4 signal probably has to run at lower temps for signal integrity while GDDR6 dont need so Hynix just uses a very old node becuase they are a bunch of cheap asses",
      "Unless the memory temperatures reach the triple digits, you're fine.",
      "Many years ago, the Vega cards performed better with Samsung HBM2 versus the Hynix HBM2.",
      "Mine goes up to 92 for some reason :/",
      "Woah, I feel special now :)"
    ]
  },
  {
    "brand": "amd",
    "generation": "9000",
    "tier": "mid",
    "matched_keywords": [
      "rx 9070 xt",
      "9070 xt",
      "9070",
      "rx 9070"
    ],
    "title": "AMD Radeon RX 9070 can be BIOS modded with XT firmware, surpasses reference RX 9070 XT when overclocked - VideoCardz.com",
    "selftext": "",
    "comments": [
      "It surpassed the NON-XT variant, still slower than the XT variant, you didn't read the article before posting op lol why are you posting without reading like that and making a liar out of yourself ?\n\n\n\nEdit: \n\nthe first line literally says : \n\n>the card has scored 15%-20% higher than stock RX 9070 non XT. This is of course with overclocking not out of the box experience after flashing. However the important detail is that this is already at or near trx 9070 xt level\n\nThe pictures from the forum post shows almost 500 points below a reference 9070 xt. While being unstable and crashing constantly.\n\nThe ''with some optimization it can beat a reference XT card'' is something the author added in as a (stupid) opinion, it's not shown in the test they did, nor on the ''source'' forum post. The card is faster with the bios but become unstable and you void your warranty. Dumb idea.",
      "Wow that's crazy that someone would do that here",
      "Flashing ATi Radeon 9700 to 9700 Pro (If I'm remembering correctly)\n\nFlashing 4GB reference RX480s to 8GB models.\n\nFlashing Vega 64 bios on a Vega 56.\n\nNow this. The bios flashes that keep on giving.",
      "Classic AMD  üëë",
      "OP is amd fanboy and just spams anything amd related",
      "Me when I post AMD content in the AMD subreddit",
      "yes, it's crazy because there should be a difference between r/AMD and r/AyyMD",
      "HD 6950 to HD 6970 BIOS flash.",
      "Not to mention the flashing of 5700 XT bioses to some 5700s.",
      "No, it doesn‚Äôt.",
      "\\*classic Radeon.  Bringing back the days of the 9700 non-Pro.",
      "This is the real OG. Software locked cores",
      "That's an opinion. The ''source'' of this bios flash had overclocked the card and couldn't reach 9070 xt performance. OP's magically going to improve the performance with magic I guess ?\n\nThe facts is even with the bios flash it's not only unstable but also slower than a 9070 xt.",
      "rx480 owners downloading vram",
      "Oh now this is the stuff",
      "There is, ayyMD is a circlejerk, there's nothing wrong with posting anything AMD related here.",
      "Could be patched and it'll void your warranty because if you have issues and RMA it, you most likely can't flash back the correct BIOS and when they see the wrong BIOS in the repair process ... Either you pay for the repair or they won't do it and you're out of a card.\n\nEdit: also OP is clickbaiting it's slower than an XT even with that he didnt read the article",
      "you can EASILY flash the original vBIOS if you save it, which you should at all times when doing vBIOS fuckery.\n\nBut yes, it's obviously still slower than the XT, OP's stupid.",
      "Yeah, I'm not gonna do this to my Prime 9070. It performs well enough for me as-is.",
      ">you didn't read the article before posting op lol why are you posting without reading like that and making a liar out of yourself ?\n\nyou can't post in this subreddit articles/pages modifying the title in any way, even just to shorten it, so OP just linked the original title applying the rule\n\n\n\n**rule is: When submitting content to** [r/AMD](https://www.reddit.com/r/AMD/), **you must directly link the article, video or content as a link post, not a discussion post or not as an image or screenshot of an article, video, Tweet etc... You must also use the suggested Reddit title or copy and paste the title of the original link, video, article, Tweet etc. Posts with altered titles will be removed.**"
    ]
  },
  {
    "brand": "amd",
    "generation": "9000",
    "tier": "mid",
    "matched_keywords": [
      "rx 9070 xt",
      "9070 xt",
      "9070",
      "rx 9070"
    ],
    "title": "I need help with choosing",
    "selftext": "The RX 9070 XT is $200 cheaper than the 5070 Ti where I live. I'm not very knowledgeable in this area, so i want to know if the 5070 Ti's DLSS worth the extra cost? Does the 9070 XT have ray tracing, and will its performance be similar? Will the 9070 XT's FSR the same as dlss? ",
    "comments": [
      "Definitely not. At a fifty dollar difference it's a hard choice but there is no major feature difference is just like dlss is a little better then FSR.",
      "Go with the 9070 XT, I usually recommend 5070Ti over 9070 XT because both of them are very closely priced these days in the market but with a 200$ difference 9070XT is a no brainer",
      "FSR is fine. Amd drivers are fine. Give it a go and enjoy it for the return period at least.",
      "Received my 9070XT today\n\n  \nCould not be happier. Beast of a GPU"
    ]
  },
  {
    "brand": "amd",
    "generation": "9000",
    "tier": "mid",
    "matched_keywords": [
      "9070",
      "rx 9070"
    ],
    "title": "ASRock Radeon RX 9070 Steel Legend OC Review",
    "selftext": "",
    "comments": [
      "worse cooler than the other higher end models around 5C, but the power limit is so low and the cooler so oversized that it doesn't matter at all.\n\nBuy whatever fits physically and aesthetically and whatever is in budget. Every model performs around the same anyways.",
      "I have this exact card.  It's bonkers good.",
      "> worse cooler than the other higher end models around 5C, but the power limit is so low and the cooler so oversized that it doesn't matter at all.\n\nI bought the 9070xt steel legend when these were almost impossible to get - newegg randomly had them in bundle deals with the matching power supply. They also sometimes had the nitro and the pulse cards, but I really didn't like the aesthetic of the pulse card. Soo....\n\nUltimately, I think the thing that hurts these cards is that they cost like $100 less than the nitro. With a 2x8pin setup, they also don't OC much (if at all). \n\nSo what? It's a 10% difference in performance (on a good day) for way more power, more heat and wear.. ehh... \n\nAnd the steel legend has one thing none of the other 9070xts have. **RGB Fans**. It's funny because the old Nitros were always available with them (usually called Nitro SE+)."
    ]
  },
  {
    "brand": "amd",
    "generation": "9000",
    "tier": "mid",
    "matched_keywords": [
      "rx 9070 xt",
      "9070 xt",
      "9070",
      "rx 9070"
    ],
    "title": "PowerColor preparing Radeon RX 9070 XT Red Devil with custom backplates",
    "selftext": "",
    "comments": [
      "so sick that i get to learn about shit like this on the web before even any internal communication",
      "I hope they plan on shipping more cards BEFORE these ~~silly~~ extremely necessary back plates hit the market.",
      "Oof, not a fan of those backshots",
      "Pause",
      "They had em for the XTX too. I want one but I can't find any lol",
      "Wish they would've spent a little more time and effort on getting good quality fans for the Reaper cards but I guess people want these $900 cards with special backplates",
      "Damn right I want my special back plates. But seriously I‚Äôm sorry about the fans",
      "With glue and some magnets probably",
      "Ok.  That just made me snarf my drink out my nose ü§£",
      "Yeah, too tacky IMO",
      "what region are you in",
      "The US. The red glass type one is sick",
      "email me [steven.sun@powercolor.com](mailto:steven.sun@powercolor.com)",
      "Cool now can you get a card yet?",
      "alright that's sick",
      "wish they would offer a watercooled oc - liquid devil - version...",
      "What's wrong with the Reaper fans?",
      "Yeah but these are magnetized. How are you going to 3D print that?",
      "Some of them make this annoying ringing/rattling sound.",
      "You may be thinking of the RTX 5070 which apparently isn't selling in Europe. I'm trying to get a base model RX 9070xt which has a list price of $600 US and is nowhere to be found."
    ]
  },
  {
    "brand": "amd",
    "generation": "9000",
    "tier": "mid",
    "matched_keywords": [
      "9070",
      "rx 9070"
    ],
    "title": "Mesa 25.2 RADV Merges Ray-Tracing Improvements For Radeon RX 9070 Series / RDNA4",
    "selftext": "",
    "comments": [
      "Why is it strange? There's lots of really specific tuning that can improve performance on any other shader, why not RT shaders?\n\nAnd AMD generally don't remove old paths immediately when implementing new features - so you can still treat rdna4's RT unit the same as previous generations, just you won't get much uplift as the 2x ray intersection rate requires a slightly different BVH node format, for example.\n\nThere's still plenty of performance left on the table comparing radv to amdvlk, much likely due to other hardware features unused on the radv side.",
      "Damn, coolio.",
      "will this make it perform more similar to a 5070 ti once it drops ?",
      "I find it a bit strange that RT performance is so dependent on drivers.",
      "RADV performs much worse RT than the proprietary driver as far as I know. I think Nvidia's support in general is even worse tbh."
    ]
  },
  {
    "brand": "amd",
    "generation": "9000",
    "tier": "mid",
    "matched_keywords": [
      "rx 9070 xt",
      "9070 xt",
      "9070",
      "rx 9070"
    ],
    "title": "RX 9070 XT ‚Äì RDNA4 Transistor Secrets",
    "selftext": "",
    "comments": [
      "Yes, it's just Nvidia propaganda. Depending on the game, even Blackwell has performance losses of well over 50% with RT/PT on.",
      "[PowerColor Radeon RX 9070 Hellhound Review - Ray Tracing | TechPowerUp](https://www.techpowerup.com/review/powercolor-radeon-rx-9070-hellhound/37.html)\n\n  \nAMD and Nvidia lose between 30-60% performance with RT turned on when the game doesn't have Nvidia's hand in it.",
      "I just said that the table he showed doesn't make sense.",
      "But that wasn't his point right? He just said that nvidia is currently the best option for rt or did I hear something wrong?",
      "I appreciate the guy who made the video, but the title was kinda clickbait. I watched to try and find the secret. Why is Navi48 so much more dense than Blackwell (it's almost equivalent to a node shrink). He basically admits he doesn't know. I will have a guess: the 64mb of cache in both designs are not quite the same. Nvidia uses L2 which is typically higher performing - and to get the L2 transistors to perform higher the 'library/design' won't be as dense. L3 cache is typically a little slower (latency), and hence the transistor design can be a little more aggressive/denser. This doesnt explain the whole difference, but possibly a chunk of it.",
      "[https://youtu.be/u8cfrJTdo0E?t=1193](https://youtu.be/u8cfrJTdo0E?t=1193)\n\nThat part is a big lie, it almost made me laugh. ![gif](emote|free_emotes_pack|facepalm)",
      "But nvidia is still best option for rt, that is what he said, right?",
      "Ah ok, I was talking about what he said at the timestamp",
      "It's also something that nvidia have done before and it's not beyond the realm of thought that they would do so again \nThey have been pushing shitty practices for years \nBenchmarks that instantly add performance ce if you happen to be using a nvidia gpu \nAnd purposely withholding vram on gpus to force upgrades",
      "You sure?",
      "A lot of AMD sponsored games (aka, no Nvidia involved) are notorious for either having very low resolution RT or none at all. \n\nBelieving Nvidia deliberately nerfs Radeon RT performance in their sponsored games is bordering on tinfoil hat conspiracy theorizing."
    ]
  },
  {
    "brand": "amd",
    "generation": "9000",
    "tier": "mid",
    "matched_keywords": [
      "9070",
      "rx 9070"
    ],
    "title": "AMD Radeon RX 9070 GRE reviews are in: RTX 5070 performance",
    "selftext": "",
    "comments": [
      "Wow, apparently its literally a 7900 GRE.",
      "RTX 5060ti 16gb is 3799rmb at cheapest in China that I can see right now, not 3599rmb. RTX 5070 is 4589rmb. \"If\" the RX 9070GRE 12gb becomes available at 4199rmb then it is cheaper than this new test comparison by 380rmb only.",
      "Which I wouldn't mind if it was priced 400$"
    ]
  },
  {
    "brand": "amd",
    "generation": "9000",
    "tier": "mid",
    "matched_keywords": [
      "rx 9070 xt",
      "9070 xt",
      "9070",
      "rx 9070"
    ],
    "title": "How big will be the bottleneck of a I3-12100f on a RX 9070 XT?",
    "selftext": "As the title says, I'm thinking of running a 9070 XT with my i3-12100. Is the bottleneck going to be a big issue?",
    "comments": [
      "Pretty big",
      "You won‚Äôt maximize the performance of the 9070xt. But you can always upgrade down the line. Not a huge deal.",
      "For 4k gaming? Not a lot. For 1080p? A lot.   \n\nCpu bottleneck is more seen at high frame rates as the CPU will have to provide new info to the gpu more often and a slower cpu will do that (surprise) slower.   \n\nDepending on the monitor it might not make a huge difference, but perhaps consider a 7800xt/5060ti also.  \n\nBut it‚Äôs not exactly bad [but check out this YouTube.](https://youtu.be/2mE4YEm2L-g?si=iOHB63PwWZu2Wh9p) just remember that the bottleneck is more prevalent on high end gpu‚Äôs so take it with s grain of salt",
      "If you're playing on 1080p, a LOT, 4K not really - obviously 1440p is somewhere in between those. I'd suggest upgrading the CPU with the GPU in this case though.",
      "Your good as long you stay with 60 fps",
      "I was just thinking of the same thing and fuck it we ball",
      "It‚Äôs comparable to a 3700x and 10600k in gaming. So i think you‚Äôll be surprised by its performance. \n\nPlus it doesnt matter anyways because you already know you‚Äôre getting a 9070xt. Just plop it in with the i3 and use it",
      "Anything over 60fps it will be."
    ]
  },
  {
    "brand": "amd",
    "generation": "9000",
    "tier": "mid",
    "matched_keywords": [
      "9070",
      "rx 9070"
    ],
    "title": "Gigabyte RX 9070 owners - are you experiencing thermal gel leaks, as RTX 50xx owners do?",
    "selftext": "Title says it all - I've just ordered my Gigabyte RX 9070 Gaming OC, and I've since discovered that Gigabyte's been using the same gel on the 9070 series, which got me a bit worried if it's also that bad with RX.\n\nSince the Internet is covering mostly the RTX issues, I wanted to ask the users directly to gather some observations after weeks of using your GPUs. \n\nI'll have mine installed horizontally, and i'd rather not wish to RMA it, so appreciate all the responses!",
    "comments": [
      "Are there actually any reports of gel \"leaking\"?  There are lots of pics of gigabyte cards with gel visible around the edges of the vram/vrm modules, but that could easily be explained by excessive application at the factory.  Had anyone actually documented before and after images of cards getting more and more visible gel over time from gravity and/or thermal cycling?\n\nThe stuff isn't conductive, so while it might be unsightly, having it smear around the pcb is not a problem.  The only issue here is if regular use can somehow cause  the thermal gel to migrate away from the contact areas of otherwise degrade,  resulting in overheating components.",
      "Have an Aorus Elite 9070 XT vertically mounted in my son's build. No leaking yet. Been checking frequently after seeing these reports.",
      "I think you are skipping past my point.  Before I can excuse, or chastise, gigabyte for \"it.\" We first have to determine what \"it\" is.\n\nSo far I have seen: (1) headlines about leaking gel, (2) pictures of cards with gel visible from the sides, around the vrm and vram modules, and (3) a statement from gigabyte saying that some cards have excessive gel, but that it should not affect performance or longevity.\n\nI certainly don't claim to know the truth, but all of those datapoints do not add up neatly. If the gel leaks out after thermal cycling and exposes components to thermal damage, that would be really bad (almost as bad as gigabytes exploding PSUs). But if it is just excessive gel from an OEM deciding that a little too much was safer than a little too little on the manufacturing line, and the cards all work as advertised and don't have an atypical failure rate, then is it really a big deal at all?",
      "Have a gaming oc 9070xt. The card definitely has excessive gel everywhere, but no issues with it. Haven't seen memory or hotspot temps go above 80c.",
      "Same here. Runs at 58 load with OC and 107 % power. Cool customer here.",
      "It's your card man. Based on the comments, what do you think? Unless you have a better alternative for the same price, I would stick to this one, as there's nothing really against that model, that would suggest it's faulty (unlike their RTX). Unfortunately, my order was cancelled due to being out of stock and now the cheapest is for around $780, so i'm holding off for a little longer until I can get one closer to $750, Either this, or i'm considering ASRock Steel Legend / PowerColor Reaper (both XTs).",
      "I had not seen any of those images previously, and some of them certainly do look more like displaced thermal paste than excess squeezed out during manufacturing. So now we just need more data points.",
      "No leaking but I had vram errors running stock on the gigabyte gaming 9070 xt which was fixed by repasting. \n\nLeaking would have been better bc it would mean too much tim applied.",
      "I have had a Gigabyte Aorus 9070 XT Elite for a few weeks now and haven‚Äôt noticed anything yet. Will be keeping an eye on it.",
      "Same card for me, also vertically mounted. Nothing put of the ordinaty, but keeping an eye on thd card as well.",
      "I was skeptical at first because it was all based on one user report, but seeing all the extra images and posts that have since come out has convinced me it is sliding out from under chips. Especially because I noticed it is leaving residue behind. The strangest thing to me is how the gel/putty manages to slide out so cleanly despite it stretching out and tearing when removing the heatsink. It kind of sucks because it seems like they were the one AIB actually pumping cards out for both AMD & Nvidia.\n\nHere's a couple pictures. I've seen more, but I'm not gonna spend my time looking:\n\nhttps://imgur.com/a/7WwSjCK\n\nThe pictures are from these two sources:\n\nhttps://videocardz.com/newz/gigabyte-reputation-melts-alongside-thermal-gel-more-cases-of-rtx-50-gel-spill-issue\nhttps://www.reddit.com/r/gigabyte/comments/1kkxs1b/5070ti_aorus_master_leaking_thermal_putty/#lightbox",
      "Did it happen right when you got it? If so this is really poor QC by Gigabyte.",
      "Man, mine still has yet to arrive in the mail. Should I just cancel it?",
      "I was experiencing early thermal putty sag in my Gigabyte 9070 XT and I contacted support in the UK. this was their response: https://imgur.com/a/d1jotyu",
      "Nothing with the oc gaming ü•≥",
      "No stres needed with the radeon cards from gigabyte. It is a nvidea thing ü§£ those where all the first batches",
      "Still nomad 9070dt running below 50 on GPU and 67 ram didn't notice anything",
      "So there‚Äôs a chance it can leak into PCIE slot? Vertically mounted",
      "Same card, not vertically mounted but would you mind sharing temperatures? Mine is around 60 for global, 86 for hotspot and 87 for memory",
      "Lol, what a nothing burger they served you...\n\nAnd in the meantime I've just ordered myself a PowerColor Hellhound 9070xt, despite all the noise I made with my post, haha ![gif](emote|free_emotes_pack|money_face)But to be honest, that bad boy was like $45 more than the Gigabyte 9070 model, and I was also urged a little bit by the impatience of the buyer of my current GPU, so I bit the bullet, hopefully won't regret it!\n\nWish me luck, as i'll be trying to jam that into my MSI Forge 100M, all powered by 750w 80+ bronze PSU ![gif](emote|free_emotes_pack|sweat_smile)"
    ]
  },
  {
    "brand": "amd",
    "generation": "9000",
    "tier": "mid",
    "matched_keywords": [
      "rx 9070 xt",
      "9070 xt",
      "9070",
      "rx 9070"
    ],
    "title": "AMD \"Reference\" Radeon RX 9070 XT graphics card tested, features graphene sheet for GPU",
    "selftext": "",
    "comments": [
      "The same one that was used on the Radeon VII?  I remember that shit being a pain to clean off lol",
      "What's with these wattage figures? It's a dual 8-Pin card, those 400w+ numbers can't be right."
    ]
  },
  {
    "brand": "amd",
    "generation": "9000",
    "tier": "mid",
    "matched_keywords": [
      "9070",
      "rx 9070"
    ],
    "title": "AMD Radeon RX 9070 GRE reviews are in: RTX 5070 performance at similar price",
    "selftext": "",
    "comments": [
      "Its genuinely such an awful thing nowadays we have to hope gpus wont be THAT overpriced above msrp\n\nDear god the gpu market sucks",
      "perf equal to 5070\n\nit's all about price\n\nmaybe this one won't be that overpriced over MSRP like 9070 and 9070XT",
      "Amazing, this card does very well in \"Alan Killer II\"!",
      "*7900gre performance*",
      "Flying over right now",
      "The 9070 is one of the most efficienct cards in the market right now.\n\nIf the 9070 GRE is slightly less efficient; it can still be considered very efficient.",
      "You can find 9070 and 9070XT cards within 10% MSRP over here in the Netherlands, seems reasonable to me",
      "9070 is more efficient than most Nvidia cards.  That was in the reviews.",
      "> No, MSRP is ‚Ç¨600.\n\nMaybe in the US, but in the EU the communicated retail price was ‚Ç¨695. You can't take the US $ price and convert it to ‚Ç¨. The US price is without VAT.",
      "No, it is better.",
      "9070 GRE is around **25% faster** on average than 5060 Ti according to multiple reviews.",
      "Poor Alan!",
      ">average calculated is 245W, the peak in the recorded data can be up to 317WÔºõ\n\nDepending on the model, about the same or slightly higher than the 9070. So, worse efficiency.",
      "Barely better is still better\n\nBut that's not even the main selling point; it is the 16GB vram over the 12GB that makes it a more obvious choice to choose 9070.",
      "~~it should be compare with 7700XT~~\n\n~~48cu vs 48cu~~\n\n~~price...~~\n\n~~who remember the price of 7700xt?~~\n\nforget it.",
      "As long as people keep buying them and bragging that they got it \"for not too far above MSRP,\" then nothing will change. Prices only ever come down if sales are too low to justify their inflated price. \n\nThe fact that AMD announced \"unprecedented demand\" even though only a small chunk of their launch supply was MSRP means that the inflated prices are justified.",
      "The dutch prices include 21% tax.\n\nSo they will always be more expensive compared to US prices even if it is close to 'MSRP'",
      "Yeah just looked it up, but barely, about 8% better in raster.",
      "GRE has always been the slowest in its tier bracket.",
      "Isn't the MSRP 680‚Ç¨? That would be almost exactly 10% above."
    ]
  },
  {
    "brand": "amd",
    "generation": "9000",
    "tier": "mid",
    "matched_keywords": [
      "9070",
      "rx 9070"
    ],
    "title": "ASUS unveils Radeon RX 9070 GRE ATS Megalodon graphics card",
    "selftext": "",
    "comments": [
      "ASUS Radeon RX 9070 GRE ATS Megalodon Seafoam Rptide Ocean Scent Beached Whale edition graphic card.",
      "Brought to you by Old Spice.",
      "I think AMD regrets releasing the 7900 GRE as good as it was.",
      "If this card was 16GB, it would be perfect.",
      "Too bad Gawr Gura is \"graduating\" - she would have been perfect for a marketing collab on this card.",
      "So Asus goes from birds (Strix), then jumps straight to space (Astral) and then goes backwards into dinosaurs or I guess ancient sharks? Why the fuck would you go back? For any naming scheme you go birds then to prehistoric/dinosaurs and then space and you NEVER go back. That's going down the tier list of cool names to use as a product line stack.",
      "Even then it's only 6% faster than the 7900 GRE",
      "I assumed it was, weird to remove 4gb vram",
      "Astral refers to the stratospheric price range of the average 5090.",
      "The amount of RAM a video card can have is dictated by the width of the memory bus, capacity of available chips, and use of \"clamshell\" (having memory chips above & below the PCB) setups.  The 9070 GRE has the memory bus cut down to 192 bits (compared to the 256 bits in the higher end models), so 12 GB or 24 GB in clamshell mode would be the only options with the biggest GDDR6 chips available.  Cutting the bus down to 192 bits lets AMD harvest chips that have partially defective memory controllers and still be able to sell them.",
      "> So Asus goes from birds (Strix), then jumps straight to space (Astral) and then goes backwards into dinosaurs\n\nBirds *are* dinosaurs (theropods)",
      "> the card will probably be 500 or less \n\n  theoretically\n\n  of course, AFAIK there's no indication it's coming to the US to begin with",
      "Wasn't it just a little bit better than a 7800XT for a little more money? That doesn't seem like it is \"too good\" to repeat",
      "The 7900 GRE launched for 550 USD though. Considering the card will probably be 500 or less (if it's exactly 75% the performance it can't go over 450 and should be lower) that's a more acceptable gen on gen improvement in value.",
      "This almost killed me.",
      "r/nvidia is full of utter normies though which contributes to their sub moving faster. Half of their posts are \"look at my build\" or \"is getting a 5060 a good upgrade from a 3060\"",
      "This is being listed as $577usd (4199rmb) according to the preorders found for the article. There's a couple of sales placeholders on Taobao at 9999rmb, getting ready for stock I assume.\n\nIs it a value purchase at $577usd?\n\nI have a 6750GRE12g and it was definitely value for money at the time of purchase.  Now it's missing modern features that this newer card will provide, if they're worth the money.  I use Lossless Scaling.",
      "Slow news day or is the sub on lock?",
      "for my actual needs, 12gb may be enough, i'd prefer 16gb as well, but it's still better than 8.\n\n220 tdp is very appealing for me, my only problem is that in my country, the price will be almost the double of the suggested one..",
      "I've actually been shocked at how few posts actually get made on this sub these last couple months. I feel like I barely have to scroll the front page and the post dates are already 1-2 weeks old. \n\n/R/Nvidia by comparison has new posts multiple times per day."
    ]
  },
  {
    "brand": "amd",
    "generation": "9000",
    "tier": "mid",
    "matched_keywords": [
      "rx 9070 xt",
      "9070 xt",
      "9070",
      "rx 9070"
    ],
    "title": "Is this a bigger upgrade.",
    "selftext": "I want to get a better video card that‚Äôs white and will last a long time, I use a OLED 4k monitor and give my card to my brother as a gift. \n\nI was thinking about the \n\nPowerColor Red Devil Spectral White AMD Radeon RX 9070 XT 16GB GDDR6\n\nI currently use \n\nASUS ROG Strix LC NVIDIA GeForce RTX 3080 Ti OC\n\nI have a 9800X3D\n",
    "comments": [
      "It‚Äôll be a decent sized upgrade. It‚Äôs in the top 10 cards currently in performance. The big thing for you is you might have to do a fresh windows install to change from Nvidia to amd. Ddu is great, but doesn‚Äôt always work.",
      "I have a power color spectral white 7900xt and it‚Äôs been great.",
      "Techpowerup puts it at a 32% performance uplift. Decent upgrade and the 9070XT has more VRAM",
      "Its actually in the top 5 probably, only cards that beat it are 5090, 4090, 5080.. and even then nvidias 80 class cards barely beat it right now, and amds own 7900 xtx is not beating it by much either, its a great card i love it",
      "The 5070ti, 7900xtx, 4080, 4080s, 4090, 5080, and 5090 are all better. So 8th best currently. It‚Äôs a great card and no one should have reservations or regrets buying it.",
      "I would say it‚Äôs better than the XTX but that‚Äôs splitting hairs. I know the raw performance is a bit weaker, but the feature set is significantly better. If you told me I could have one of the two for free, I‚Äôd take the 9070xt."
    ]
  },
  {
    "brand": "amd",
    "generation": "9000",
    "tier": "mid",
    "matched_keywords": [
      "rx 9070 xt",
      "9070 xt",
      "9070",
      "rx 9070"
    ],
    "title": "Is the Radeon RX 9070 XT even that good?",
    "selftext": "",
    "comments": [
      "At MSRP, sure. At $900+, not really.",
      "Please stop repeating this overly used platitude; there absolutely are bad products (see Gigabyte's exploding PSUs or NZXT's risers that literally caught on fire).",
      "People are giving their opinion, but no one actually clicked the video and discussing the video lol. (Not saying people are missing what they said, just funny that everyone is giving opinion based on the title, not what was said in the video)",
      "Well i bought a 2nd hand 3070 for 400 euros, and now i bought a 9070xt new for 818 euros, for roughly 2x perf.\n\nI am pretty happy with that.",
      "Good option atm if you're in the market for an upper midrange GPU looking to upgrade but as they said that says more about the state of the market than the 9070 XT being amazing in a vacuum.\n\nFor me would basically be a sidegrade/downgrade, wish AMD hadn't bailed on the high end this gen. Something like a 9080 XT that exceeds a 5080 in performance for $800-$900 MSRP would've been very appealing.",
      "THIS! \nThere are no bad products, only bad prices.",
      "You should be more respectful of internet wisdom/s",
      "Sure. You somehow got 140 higher FPS than all the reviewers.  I dunno why ppl make up shit when benchmarks from hundreds of sources are public.",
      "If the frame we're using is \"if things were different\" then the conversation is immediately pointless because things aren't different and market realities indicate they're not going to be different for a long time.\n\nThere are too many people who spend too much time navel gazing about what an acceptable generational uplift should be and therefore what it should cost when those evaluations are completely different based on each person's particular circumstances.\n\nIf you think that a fair generational uplift should be 50% or better, don't buy a generation that doesn't have that. If you don't think that the price that is being charged is fair value, don't buy the card. If none of these things appeal to you, don't buy anything until a card reaches whatever your personal requirements are.\n\nAMD delivered a card (9070 XT) that is either slightly behind its nearest competitor (5070 TI) for meaningfully less money, or well ahead of its nearest competitor (5070) for slightly more money. They've mostly closed the gap on raytracing workloads that don't use Nvidia-specific stuff, and largely equalised upscaling with FSR4 all while having fewer hardware faults and more robust drivers. That feels like a good deal to me, and apparently a bunch of people agree with that since they're outselling their competition by a fairly considerable margin atm.\n\nAll of the alternate universe BS where for some reason AMD released this exact card at this exact price despite every other circumstance being different and AMD charging head first into stepping on a rake anyway is a complete waste of time.\n\nEvaluate the market you're in. AMD did fine, probably did their reputation in the market a world of good, will probably gain some market share in this segment. Hopefully for the health of the market, the 9060s do well and they maintain a good position to be able to produce something great with their next major release.",
      "I would like to nitpick that video a little.\n\nWas FSR4 an improvement over FSR3? Reviewers seem to think so. I haven't seen a single one say it wasn't. Or that it was luikewarm improvement.\n\nWas Raytracing improvements massive compared to 7000-series? Yes, the numbers talk for themselves.\n\nWhat is interesting to me, is the number of graphics cores on 9070 XT is something like 20 cores less. Yet, it matches or beats the previous gen. 64 compute units compared to 84 on the 7900 XT for example. That is more than 20% less CUs. In other words, massive gains per CU.\n\n[https://www.youtube.com/watch?v=3XrX2yef7Vg](https://www.youtube.com/watch?v=3XrX2yef7Vg)\n\nOnly thing letting that card down is the scalping going on, including from the retailers, in my book.",
      "I jumped from 3070 to 9070XT myself. Initially, I was thinking of 5080 but after weighing the price, availability, and ROPs missing fiasco, I decided to purchase 9070 XT and sold my 3070 to make up the purchase cost.\n\nI'm happy with it as well.",
      "I would consider any product that was designed in a way to have an unacceptable rate or method of failure as a \"bad product.\"\n\nWe dont have to be nice here, the PSU doesn't have feelings.",
      "The explosive Gigabyte PSUs say hi",
      "Some people enjoy eating crayons. Just let them, there is no reasoning with them.",
      "It's the same old \"runs fine for me\" you always hear, where they either never specify what \"fine\" means, or they completely make up what numbers they're actually getting. \n\nThere's no way a 9070 XT is getting 140fps at 4K unless it's a VERY visually simple game, or they're *heavily* using FSR upscaling (and at that point is it even 4K because of how bad FSR looks)",
      "Nah, there are bad products, this isn‚Äôt one of them but there are bad products at any price.",
      "why?",
      "Apparently they want the name of the company to be Nvidia instead...",
      "Chess 3D?",
      "Because this is a discussion about the video lol. I just found it funny no one actually discussed anything from the video."
    ]
  },
  {
    "brand": "amd",
    "generation": "9000",
    "tier": "mid",
    "matched_keywords": [
      "rx 9070 xt",
      "9070 xt",
      "9070",
      "rx 9070"
    ],
    "title": "AMD's Radeon RX 9070 XT Records 10x Higher Sales Than NVIDIA's RTX 5080 At MindFactory, Showing Team Red's Dominance",
    "selftext": "",
    "comments": [
      "Imagine if it were available at MSRP...",
      "That‚Äôd be nice, wouldn‚Äôt it?\n\nThe GPU market is trash right now‚Ä¶",
      "Good, now it's time to show dominance with software support, FSR 4 adoption and driver improvements.",
      "Its been trash for years it feels like.",
      "And then we find out that Nvidia sold 10,000 5080s in OEM PC's where AMD continues to have no presence in. \n\nMindfactory was showing a 50/50 split for AMD at a time when NV had 90% market share in sales.",
      "It‚Äôs been a while since I left Nvidia but honestly I‚Äôm quite confused every time people say that software/driver have issues or need to be improved. I found software support way better on AMD than Nvidia back in the day (wow, it‚Äôs been 4 years ago)",
      "I'm so glad I got mine as MSRP. I actually got it for like $20 under because it was an open box. Get this, Canada Computers recommended the card to a guy and he returned it 3 days later saying \"Nvidia is better\" and paid $1400 for a 5070ti üòÇ. Works for me",
      "It's been trash since the RTX 3000-series launch.",
      "Lmao what a fool",
      "Correct me if I'm wrong, but mindfactory missed the launch due to insolvency/restructuring?\n\nIf not, they would probably have better sales.",
      "Take a look at older but still popular games, do a driver optimization pass and help / incentive developers to implement FSR4. That's all I'm asking for and this is what their competition is doing. So my expectations are pretty grounded",
      "Prices went way up \"due to COVID\" and then just somehow stayed there forever.",
      "No, they're an indication of the European DiY sales and nothing more. A very small percentage overall.",
      "Oh, I see. But in my modest opinion 9070 XT works super great even at 4K so, for me, right now FSR4 is a style exercise. Obviously I‚Äôm not playing competitive games nor fast peacing titles so I can understand every needs.",
      ">~800‚Ç¨\n\nIf you convert the US MSRP to euros and add VAT, it's no more than ~670‚Ç¨ in any EU country.",
      "1 5000 vs 10 9070.\n\n\nI haven't seen any in a while. Only a couple of gigabytes with 1.5k$ price tag for non XT.",
      "All I know is my god damn 9070xt launch drivers are crashing from UE üòÇ hopefully updated soon",
      "Thank god I was able to get mine at MSRP. What an amazing card at the MSRP price point.",
      "710 right now in Germany. They already hit msrp basically. Go go AMD",
      "I remember people trashing on the 2000 launch too."
    ]
  },
  {
    "brand": "amd",
    "generation": "9000",
    "tier": "mid",
    "matched_keywords": [
      "rx 9070 xt",
      "9070 xt",
      "9070",
      "rx 9070"
    ],
    "title": "A PC I built for my friend's son",
    "selftext": "Friend's son was having some great results at school recently so he decided to reward him with a brand new gaming PC. This is a second PC I built for him. The previous one I built was based on Ivy Bridge i5, more than a decade ago... \n\nI must say I was very positively surprised at how well designed this Sapphire GPU is. The idea of hiding the power connected under a magnetic backplate, and then routing it towards the motherboard is absolutely brilliant. \n\nAlso have I mentioned how absolutely massive this GPU is? I think it's even larger than my RX7900XT... \n\n* Ryzen 7 9800X\n* ASUS TUF GAMING X870-PLUS WIFI\n* Kingston FURY Beast Black 64GB 6000MT/s DDR5 CL30\n* Fractal Design North Charcoal\n* Noctua NH-D15 G2\n* CORSAIR RM850x\n* Sapphire NITRO+ AMD Radeon RX 9070 XT\n* Crucial T500 4TB NVMe",
    "comments": [
      "My god, that GPU is sexy",
      "An absolute unit. I need to tell him to buy a better GPU bracket tho",
      "9800x3d, sorry",
      "This PC makes me want to go back to school and get better grades.",
      "9800x? You meant 9700x? Or 9800x3d?",
      "I love the Noctua fans with the wood case",
      "U must be a friend of my dad's, where's my pc",
      "They are using the one that comes with the GPU already.",
      "Get a sag bracket",
      "Looks nice, really like that case",
      "get the sag fixed ASAP but I hope my eyes is just deceiving me",
      "It glows all pretty-like too. Have the same one.",
      "The brown and copper is so **buttery**",
      "In that case looks really nice",
      "Are you sure? I have seen pics of this same build on a few posts. It looks sweet though.",
      "Well done.  I hope the kid appreciates it. I built one for my wife's niece. She enjoys it, plays it all weekend long. Same case.  I love Fractal North.",
      "I hope this kid appreciates the work of art you built for him.",
      "Very nice, very tasteful. Your friend‚Äôs son is lucky.",
      "Your son will have less good results now üòä",
      "what wonders pictures do if you take them at the perfect angle"
    ]
  },
  {
    "brand": "amd",
    "generation": "9000",
    "tier": "mid",
    "matched_keywords": [
      "9070",
      "rx 9070"
    ],
    "title": "AMD launches Radeon RX 9070 GRE in China, officially 6% faster than RX 7900 GRE",
    "selftext": "",
    "comments": [
      "RX 9070 -6% performance for RX 9070 - 2% price. With 4GB less VRAM. Meeeeh.",
      "Its for AMD to get rid of bad yield i guess",
      "Yeah I dont see who this is for.",
      "no clue what demographic this card is caters towards to but this card just seems meh in general",
      "Definitely Garbage Radeon Edition for that price",
      "Should they launch this global it will probably be $500.  Back to the Nvidia -$50 strategy it seems ü•≤",
      "This is pretty much it, 9070 doesn't help AMD sell any GPUs with defective memory/cache. 9070 GRE makes more sense from a manufacturing standpoint for a cut down model.",
      "> I made a long list of games with performance problems and they didn't even approve the post...I think that's extremely negative.\n\nPost it again here. People at AMD do read this sub. I have watched the sub say \"mountain be over there\" and lo it moves.",
      "https://i.redd.it/eg69fkzh2lxe1.gif\n\nUnfortunately, my experience was similar. Despite having good intentions, my post was blocked. AMD needs to get serious about software issues, especially now that Nvidia is slipping...\n\n[List of games with abnormally bad performance on AMD to be fixed. : r/Amd](https://www.reddit.com/r/Amd/comments/1j5oskh/list_of_games_with_abnormally_bad_performance_on/)",
      "Waste not, want not! - AMD",
      "They should simply focus on optimizing more games for RDNA4, pushing the 9070XT to 5080 level in more titles.\n\n\nCS2, Wukong, Indiana, Silent Hill are just a few titles that have obvious software problems and need AMD's focus. I made a long list of games with performance problems and they didn't even approve the post...I think that's extremely negative.",
      "Probably for people who can only afford sub $500 GPUs, and want a next gen card. If this is priced well, let's say 400-450, that would be a 5060ti competitor price wise, but absolutely destroys it in raster. The 5060ti doesn't even beat a 7700xt convincingly.\nSo a 9070 gre 6% faster than the 7900gre is something similar to a 5070 lool, and with also overclock potential could be crazy value for money. Even with just 12gb, this would sell like hot cakes at 400-450.",
      "The reason its China only is propably because they dont have as many defective dies to launch it worldwide.  Selling fully functional 9070xt dies as this would make no sense considering there is shortage of 9070 anyway.\n\n So nah 9060 xt is a different chip.",
      "It's not 400-450 tho. It's essentially 540.",
      "Folks love Nvidia -$50 strategy.",
      "China",
      "Chinese internet cafes and pre-builts? Those usually put the 60 tier Nvidia cards at the top of the Steam hardware survey.",
      "This isnt 7900gre replacement. Its more like 7700xt replacement.",
      "Just let hope it drops down to 400 like the 7700 XT does",
      "This is why we can't be happy for Nvidia fucking up too much, all it does is make AMD get greedy. There should be a balance. Thanos was right üíÄ"
    ]
  },
  {
    "brand": "amd",
    "generation": "9000",
    "tier": "mid",
    "matched_keywords": [
      "rx 9070 xt",
      "9070 xt",
      "9070",
      "rx 9070"
    ],
    "title": "Replacing Radeon RX 5700 50th anniversary",
    "selftext": "I'd like to upgrade my pc with a new gpu, currently I have a Radeon RX 5700. I am looking somewhere in the range of RX 7900 XTX or RX 9070 XT but can't decide. Might also switch to NVIDIA. I don't need a 5090 though. Any recommendations appreciated.",
    "comments": [
      "9070 XT or 5070 Ti",
      "AMD said most folks spend 700 or less so they've targeted that market. With the 5090 costing 2k+ they've decided to leave that bit of the market for now. Most I've spent is ~¬£660 on an RTX 2080 and my next purchase will probably be a 9070XT or 5070ti",
      "If you have some patience, I recommend waiting for the flagship of the 90 series to come out, and be quick on the draw. If you go 9070, get the xt, or do like me and get a 7900xtx, and be happy.",
      "Thank you for your advise! I am also not willing to spend much more than 1k, but the performance gain coming from the RX5700 is now worth the upgrade I feel. I play DayZ, GTA V mostly and would obviously also like to play GTA VI without upgrading again.",
      "7900xtx has the highest performance (in regards to price and just raw performance) a 5080/5070ti super are ok choices but I'd say the xtx or 9070xt",
      "DOOM edition ! Nvidea",
      "I don't think there's gonna be high-end AMD 90 series cards. They said the 9070XT was gonna be the top end as most buyers don't spend much more on GPUs.",
      "Ugh. The 1-1.5k gpu is about the absolute limit  for me. 1k on a 3090ftw3, 1k for a 7900xtx sapphire nitro+, no more"
    ]
  },
  {
    "brand": "amd",
    "generation": "9000",
    "tier": "mid",
    "matched_keywords": [
      "rx 9070 xt",
      "9070 xt",
      "9070",
      "rx 9070"
    ],
    "title": "New build: rtx 5070 to or Rx 9070 xt",
    "selftext": "(Correction because I can't edit the headline: rtx 5070 ti Vs Rx 9070 xt)\n\nI am in the process of building my first gaming pc and need to decide which graphic card I want to use. I am currently deciding between those two at the top, but because I am new in that matter, most articles confuse me, so maybe you can help out.\n\nThe rx 9070 xt is ‚âà200‚Ç¨ cheaper in my country, so there's that.\n\nWhat's really important to me is how future proof the card is. I wanna use it for as long as possible before switching it. I wouldn't label myself as a hardcore gamer, but if I play I want good graphics. My main games currently are dbd, baldours gate 3 and graphic novels like the life is strange series, but I don't wanna limit myself with the new card.\n\nAny help and opinions are appreciated (especially if they are written in simple terms and without too much Technical language).\n\n(I had a gaming laptop until now with a GeForce rtx 1060, so I am a bit more used to that although I never altered things or tinkered with my settings.)",
    "comments": [
      "How is a 9070xt cheaper than a 5070? 9070xt obviously.",
      "9070 XT 100%",
      "9070 xt is neck and neck with the 5070ti. It outperform the 5070 significantly.",
      "9070 xt is almost 20 percent faster and 33 percent more vram. no brainer",
      "Same your situation a month ago,  this time i have choose with brain instead heart. I have spent a lot of money more, about 300 euro but this time i have put in my pc a 5070ti after a lot of amd, last one a nitro 7800xt. No regrets, if i don't think to money üòâ . Best card, best tecnologies, finally RT/PT always on in every game and forget problems, no problem with driver, no memory hot spot at 100  degrees. This time i'm very happy.  Next one? Again nvidia? Return to amd? Buh?",
      "9070 xt or non xt 150% over 5070.",
      "Idk. But the Rx is about 850‚Ç¨ and the rtx is around 1000-1100‚Ç¨ at the moment. But the nvidias are mostly sold out everywhere, so maybe that's why they are so expensive.",
      "From what I've seen they both have 16 GB Vram?",
      "Does that mean your previous AMD card made problems with overheating and driver software?",
      "oh woops I didn't see ti. the 5070 ti is like 5 percent faster in raster and is def worth extra money but 200 is a bit much.\n\nIf u are okay with giving up pathtracing then I would go with the 9070 xt",
      "Primary driver problem, one is good, one is a continuous crash, rollback to the first one, everything is fine. 2 moth after same story. Then Hotspot and vrm temperature, my 7800xt was a nitro, IMHO one of the best one in the market but after 3-5 month Hotspot delta temperature reach 30 degrees over gpu temperature, probably paste pump out, 50 euro of putty and ptm and problem solved, but 50 euro... At the end, every amd have great performance in raster and brutal force but in 2025 raster is nothing the future is ray tracing, dlss, upscaling tecnologies mandatory for always more games, amd is back on this. But is cheaper this is good. Performance price ratio? Amd always. Performance, no problem and future proof? Nvidia.",
      "Yeah, i meant the ti, my auto correct made \"to\" out of it. But I edited it in the description. The rtx 5070 (without ti) is still starting at 800‚Ç¨ where I live.",
      "I don't know how important pathtracing is for me. I'll probably never play shooter games like call of duty or racing games if that helps. (I am really a noob at PC terms XD)\nThe most important aspect for me is being able to use the card very long with nice graphics.",
      "Okay, thank you! That helps a lot!",
      "Then it just depends on how much you value the NV feature set, they‚Äôre roughly the same performance. I would personally go for the 5070ti if its within 150 of the XT, both are fine choices tho. \n\nAlso none of the games you listed are particularly demanding, you could‚Äôve easily gotten away with a cheaper card if those are all you play.",
      "i mean the 5070 ti will def age better bc it is straight up the bettter card, however, u need to decide if the perf and feature gap is worth paying",
      "Thank you. I know I could use a lower card for those games, but I want some games that aren't released yet and have pretty high demands (and as i said I wanna Future-Proof my build a bit).\nIt's good to know that there isn't too much of a difference üëç",
      "Thank you!",
      "Are you sure you didn‚Äôt get the names mixed up? There‚Äôs no way a 5070 could go for 1000-1100, maybe its the 5070ti?\n\nFor reference 9070XT‚Äôs MSRP is 599USD and 5070 is 549USD, in Europe there‚Äôs tax but your prices are completely out of whack."
    ]
  },
  {
    "brand": "amd",
    "generation": "9000",
    "tier": "mid",
    "matched_keywords": [
      "9070",
      "rx 9070"
    ],
    "title": "Sapphire introduces white B650M PURE motherboard, matches Radeon RX 9070 PURE design",
    "selftext": "",
    "comments": [
      "that's one beautiful board, reminds me of aorus ice models. too bad its china exclusive",
      "Sapphire makes motherboards? Damn.\nIf they make a nitro one ( think 9700xt or 7900) I'm buying. At least if they are better than aorus",
      "You can maybe find it somewhere on aliexpress or something sometime soon. Lots of Chinese goods are sold there. You‚Äôll have to sift through garbage to find it though",
      "ASRock still has you covered, albeit at full ATX:\n\n\nhttps://www.asrock.com/mb/AMD/B650%20LiveMixer\n\n\n/s kinda",
      "They do, but the drivers are apparently impossible to find outside of the great firewall. Also matx only.",
      "Just a copy from Chiiinnnaaah",
      "What happened to the B850 chipset?¬†\n\n\nI thought at this point the 600 series was discontinued.",
      "Since it can do PCIe5.0, it is rather a B650E.",
      "You can still make your own at least!",
      "Maybe they just got a sweet b650 chipset deal. Not that surprising tho considering it's chinese wizards and their excess capacity... Even x99 boards are still produced.",
      "sapphire goated???? beautiful board",
      "if nitro made a $1000 board I'd probably get it tbh. im so sick and tired of shitty MB brands, its like the last fault point of my pc it feels like lol -- idc if its new or has kinks as long as customer service is good, i get a good product by well know QA teams, and wow i didnt realize thats all i want is a good product lol. Pop off nitro! \n\nWEN US MARKET?!  \n  \nedit: I literally will pay whatever premium, whatever tarriff whatever ANYTHING (more or less lmao) for a highest of end thats possible for them to achieve build quality but in a usa market so i can GET AWAY from Gigabyte, Asus, ASrock, MSI, and whatever other one (not EVGA, EVGA was good). i just dont want to buy on alibaba and want a USA official market seller. Have paid $500+ for motherboards that shit the bed more than once -- I'd be beyond willing to spend $1200+ on a reputable brand with good RMA and customer service.",
      "With the latest BIOS, literally the only difference is the top M.2 slot on B850 getting PCIe 5.0.\n\nEverything else is the same now, including RAM compatibility and PCIe 5.0 to the graphics card slot."
    ]
  },
  {
    "brand": "amd",
    "generation": "9000",
    "tier": "mid",
    "matched_keywords": [
      "rx 9070 xt",
      "9070 xt",
      "9070",
      "rx 9070"
    ],
    "title": "AMD Radeon RX 9070 XT reference PCB design leaks out, mirrors Sapphire PULSE",
    "selftext": "",
    "comments": [
      "While it is a rumour as AutoMod pointed out. I remember reading somewhere that Sapphire designed a few reference PCBs for Radeon Cards in the past. So it is reasonable to assume the Pulse is basically the AMD reference for all intentents and purposes.",
      "Sapphire has long been the primary partner for AMD reference design.",
      "Sapphire has long been the EVGA of AMD Radeon cards",
      "sapphire has long since usually been the one that also manufactured BBA (built by ATI) gpus too.",
      "Sapphire has long been the Smokey to AMD‚Äôs Bandit.",
      "I feel like this leak has been leaking for like a week now. I've seen this news numerous times now.",
      "And anyone who's used AMD/ATi cards for a long time basically knew this already",
      "Is the GPU being rectangular new? I don't think i've seen something like this before. I thought most were square?",
      "The Shaggy to AMD's Scooby.",
      "WHAT? AMD reference design is built in collaboration with their biggest and most well regarded partner? Say it ain't so!\n\nLove me some sapphire. Bought a lot of vapour chamber designs from them back in the day, when AMD(ATI) was still competing at the VERY high end.",
      "They're definitely stringing it out as thin as they can.",
      "It really depends on the designs. Some GPUs and CPUs are perfectly square, some others, rectangular. And some are square but at an angle, compared to the rest of the PCB.",
      "And even then sapphire has replaced multiple r9 290s for me",
      "Makes sense since Sapphire has been the most trustworthy for more than a decade now. I still remember buying a R9 295x2 second hand and it worked up until I got a 1080 ti.",
      "Ehhh, EVGA had killer Customer service but occasional build issues.\n\nSapphire is 'to hell with customer service, build that thing to the nines, they won't need it then'.",
      "I think the idea was that AMD took the 9060 die and mirrored it to make the 9070 die, which is why it's so long",
      "I'm really liking the aesthetics at any rate. Look like something out of the movie [2001 A Space Oditty](https://en.wikipedia.org/wiki/2001%3A_A_Space_Odyssey)",
      "It's actually PC Partner Group who makes the reference cards and does customs for Sapphire.",
      "Look at that beautiful small card. Make some sub 250mm, 2.5 slot cards for smaller cases.",
      "Have a pulse, seems far higher quality than thr \"budget\" option it's sold as \nThis may be why it overclocks so well"
    ]
  },
  {
    "brand": "amd",
    "generation": "9000",
    "tier": "mid",
    "matched_keywords": [
      "9070 xt",
      "9070",
      "rx 9070"
    ],
    "title": "Absolutely Absurd RX 9070 Video Cards: Every 9070 XT & 9070 So Far",
    "selftext": "",
    "comments": [
      "+perfume XD",
      "Gonna get a waifu-ish card from China when I go there next month. Look like all out of stock atm though, finger crossed. \n\nEven in China 9070/XT sold out, this has been a huge lunch for AMD. China historically is very Nvidia inclined, people on buy AMD at last resort , 9070 sold out this fast is another sign how bad the GPU supply has been for the last few years.",
      "We need better-designed coolers ***NOT*** bigger and bigger coolers.\n\nNVIDIA has shown that it's possible to cool 600W with a dual-slot design.\n\nI hope that AIBs copy NVIDIA's Double Flow-Through design",
      "Yeah I don‚Äôt think I like any of the AIB designs this gen. Rdna3 cards looked much better. In addition to looking weird this Gen, I‚Äôm also annoyed that the xfx cards are still just too damn thick and long even for a midrange card. Overall the Gigabyte Gaming and especially Powercolor Reaper have the least gimmicks and are the most compact form factor and the reaper is msrp. I would say I like the Asus prime one too, but fuck Asus\n\nEdit: hellhound looks nice, I always liked the blue inside the fans, but unfortunately not as close to msrp as I‚Äôd like unless Im mistaken",
      "Wouldn't be yeston's first time...",
      "Nvidia stopped production on 40 series to make more of their AI chips. They said it was for 50 series, but we now know they allocated like 1% of the capacity. Maybe.",
      "And here I am hoping that we get another decent $300-500 range card that fits in a case that can only accommodate 27cm-long GPUs.",
      "So keen on the Reaper but it's gonna be impossible to get",
      "I mean most of last year was fine, there were plenty of Ada refresh and RDNA 3 cards with some good sales toward the end of production. It's just been maybe November to now that's been absolute shitshow. Most of it due to Nvidia's paper launch.",
      "I just got my hellhound and I think it‚Äôs in the same category of not being overdone and not super thick like the reaper",
      "Pinned comment on YouTube says a pricing video is coming",
      "Yeah, totally. Why sell for 1-2k when you can sell for 10k each with 8+ figure contracts",
      ">We need better-designed coolers NOT bigger and bigger coolers.\n\nSFF builders and people with all kinds of PCIe cards need smaller coolers. I would like to see a competitive dual slot option available for AMD customers (like the 5090FE), but I would hate to see that become the predominant style that‚Äôs available. The FE cooler would be a waste of money for someone like myself, who has the space for a bigger cooler, doesn‚Äôt need the extra slots, and might want to buy a waterblock one day (now I have daughterboards for no reason).\n\nNot defending any of the designs that are much thicker than 3 slots though; that‚Äôs excessive in my opinion, and I don‚Äôt want to worry about it sagging.",
      "Yeah I wouldn‚Äôt classify nvidia as a graphics card company at this point. It‚Äôs an ai card company that makes some graphics cards .",
      "Probably worse. When the crypto bubble imploded, we at least got many cards in the used market pushing prices down. With AI, there's no end in sight, and at the end of it, we will have just electronic waste.",
      "I have the Midnight black 6800XT and it's the coolest looking design ever IMO. Not too over designed but has a nice flair to it. \n\nIt's super annoying that we have no reference cards for the 9070 cards because I think AMD's reference designs tend to be the best and most classy.",
      "This was really funny",
      "[The Hellhound is actually accented in blue as opposed the Red Devil.](https://www.powercolor.com/Upload/202501/product_feature_2025010613325402.webp)",
      "Maybe they got seeded the one Lisa Su was holding at launch",
      "It's just the cryptoboom all over again."
    ]
  },
  {
    "brand": "amd",
    "generation": "9000",
    "tier": "mid",
    "matched_keywords": [
      "9070",
      "rx 9070"
    ],
    "title": "First AMD Radeon RX 9070 GRE graphics cards leaked, 12GB memory confirmed",
    "selftext": "",
    "comments": [
      "The downclocked memory is going to hurt if true, but I do wonder how much of the speed you could get back with an overclock.",
      "Presumably because last gen's GRE was a 900/80 series equivalent so it commanded the extra complimentary RAM if I had to guess.",
      "Why would they have less ram than last generation's GRE?",
      "Less powerful version",
      "It's just lack of consistency in AMD's naming. In either case the GRE is the third most powerful GPU of the series. \n\nThe 7900 series should've probably been called the 7900 and the 7900 XT rather than the XT and XTX.",
      "Probably not much if they lock it down like they've done for other cut down models",
      "Interesting. \n\nSo the 9070 GRE is a worse version of the base 9070, whereas the 7900 GRE was a worse version of the 7900 XT. Am I getting that right?\n\nI feel like that's a bit confusing, no? One would have expected the 9070 and 9070 GRE to have their names swapped.",
      "It has 50% more RAM than the RX 7650 GRE though. (Lol yes I know you mean the other last gen GRE card, the 7900 GRE).  More seriously though, AMD uses the GRE branding for oddball bins of its chips that are mainly focused on the Chinese market (though the 7900 GRE did get a global release of course).",
      "It was Golden Rabbit Edition, but then AMD changed it to Great Radeon Edition after people bugged them about the name no longer making sense.",
      ">get close to the regular 9070.\n\nLol, you are daydreaming. \n\n9070 GRE will not only have 15% fewer ALUs, it also has 33% fewer ROPs, 48MB Infinity $ and much less bandwidth.\n\nThat 33% missing ROPs alone would be impossible to compensate with just overclocking.",
      "Utter FAILURE in product naming!\n\nPostpone 9060 launch and rebrand/name those SKU's to 9050 and 9050XT, then rebrand and rename the 9070GRE to 9060XT.   \nResult: 256bit 16x pci-e 16Gb 9070(XT) > 192bit 16x pci-e 12Gb 9060XT, 128bit 8x pci-e 8Gb 9050(XT).\n\nBack to basics like when RDNA1 was released: 256bit 16x pci-e 8Gb 5700(XT), 192bit 16x pci-e 6Gb 5600XT, 128bit 8x pci-e 4/8Gb 5500XT. \n\nThis is the only logical naming approach AMD that makes sense, also from a marketing perspective and possible a legal perspective!",
      "It doesn‚Äôt sound like that great of a card tbh",
      "anything over 400 usd and it‚Äôs not worth",
      "‚ÄúGreat Radeon edition‚Äù for the worst sku in the lineup. Great job amd marketing!",
      "I mean there are some 9070 models you could get to XT level with a bit of tweaking, but we'll see.",
      "The 7900 GRE used the same Navi 31 die as the 7900 XTX and 7900 XT, but with the memory bus cut down to 256-bit (from 384-bit on the fully enabled XTX and 320-bit on the less cut-down XT).\n\nThe 9070 GRE is a Navi 48 like the 9070 and 9070 XT, but with its memory bus cut from 256-bit to 192-bit, which means that it can do 12 GB of memory or 24 GB if they clamshell it.\n\nAs for why they're cutting it down instead of leaving it at 256-bit to match the 7900 GRE, it's because the product presumably exists largely for the sake of using dies that have faults that prevent that from being possible.",
      "It also stands for Golden Rabbit Edition as it was a China release during the year of the rabbit. GRE ended up sticking apparently since that was a few years ago.",
      "Bro AMD likes to rename and change naming schemes of gpu like every 2 to 3 generations :-D",
      "Note that the XTX was the flagship before, XT is the flagship now.",
      "Ah I see ty"
    ]
  },
  {
    "brand": "amd",
    "generation": "9000",
    "tier": "mid",
    "matched_keywords": [
      "9070",
      "rx 9070"
    ],
    "title": "Rtx 5070 or RX 9070",
    "selftext": "Is a 70 dollar price increase worth it to get a RX 9070 non xt or keep the 70 dollars and get a rtx 5070? \n I play 1080p but will definitely go to 1440p and i mostly play competitive games like war zone,cs2,Fortnite. Is the 4gb+ vram worth in the rx 9070 worth the extra 70 dollars and how good is the features the cards come with\n\nEdit:100 CAD less for the rtx 5070",
    "comments": [
      "The internet is going to tell you to get a 9070, while some will upsell you to get a xt or ti but my advice is get whatever is at msrp",
      "what i did. 5070 on the way",
      "The 9070 is far better than the 5070 and they are available (unlike the 5000 series paper launch).\n\nThat being said dlss is still far better than fsr, so if you can get your hands on a cheap 5070 (if that is even possible) It maybe worth It, though It seems that AMD is fanally catching Up to Nvidia with FSR 4.",
      "9070, that 4gb of vram makes a difference.",
      "The 9070 is better by a good margin, but I'd suggest 5070 on this one, as 9070 is supposed to be a super budget friendly card but clearly it isn't as of now.",
      "5070 is better apart from the vram",
      "because $50 diff is only real in the US. it many markets, at MSRP the difference is closer to $100. and only for more consuption and ~10% difference in fps.",
      "Then i guess it‚Äôs really dependent on your upgrade cycle. If you don‚Äôt upgrade frequently id go for more vram. If you do grab the 5070 it should do a good job",
      "In the UK the 5070 is quite readily available at ¬£539.99. Personally the 12gb vram is a hard sell when you can get a 9070 for similar money with more vram, better raster performance and what looks to be decent RT performance and a software stack that is almost at parity.¬†\n\n\nUltimately it comes down to how available either are and what you specific use case is.¬†\n\n\nAMD drivers are not as bad as many make out and their adrenalin software is better than the Nvidia App in my opinion.",
      "I‚Äôd wait until you could get them at msrp. I have seen some 5070s for $550 but honestly if you‚Äôre playing at 2k or above i wouldn‚Äôt justify such a big purchase on a GPU with 12gb of vram. It‚Äôs precisely why I‚Äôm getting rid of my 4070ti. I got it for $675 and it‚Äôs been fantastic but at 3440x1440 it‚Äôs starting to worry me.",
      "9070 is significantly better than the 5070 get the 9070",
      "Xt and ti way too expensive imo so i want to stick to the regular versions",
      "Yea i think ima go with the rtx 5070 due to being able to get it at msrp unlike the rx 9070 and the vram wont really limit me in the games i play.",
      "100 dollars increase worth it?",
      ">what are u talking about the 5070 is the only card with decent avalability at msrp. The only day the 9070 have better stock was the day of launch.\n\nBecause there was actually a real stock of the 9070's, unlike the 5000's.\n\nAnd i dont know where do you live, but in my country there are no 5070 at MSRP, they all cost as much as 9070 while being considerably worse.\n\n>the cheapest 9070 costs over 20 percent more than the cheapest 5070 rn while not giving even 10 percent more perf on average.\n\nThe 9070 gives way more than 10 percent more perf than the 5070, which is one of the reasons both the 9070 and the xt are selling like hotcakes.",
      "I don't really trust pcpartpicker prices since it includes scalpers. I have personally seen the 9070 & 5070 in stock at $550 usd, and I would pick the 9070 over that, but I don't know how supply is doing in the canadian market. For me personally, I would not get a gpu with 12gb of vram",
      "Absolutely 100% 9070 has more vram and performance and not driver issues compared to the 50 series black screening",
      "Definitely will jump to 1440p",
      "Those kind of \"paper comparisons\" are useless, because at the end of the day the only thing that matters is real usage performance, and only benchmarks shows that, and in benchmarks the regular 9070 destroys the 5070 while also being considerably cheaper, the only thing the 5070 is better is in dlss 4, but AMD is catching Up to Nvidia with fsr4, and ray/pathtracing.\n\nHere i drop you a benchmark of al 9070's VS 5070's, but you can look for more of you want:\n\nhttps://youtu.be/aWOBTszuXxI?si=6DbpeOsELEy2qGAB",
      "There are literally hundreds of videos in YouTube about the 9070 vs 5070, pick whichever you want, i only sent you that one because It was literally the first one Who appeared in my search.\n\nAnd as i said, what a \"reputable company\" says is irrelevant, the only thing that matters is how the card performs, and the only way of knowing that for sure before buying are with benchmarks."
    ]
  },
  {
    "brand": "amd",
    "generation": "9000",
    "tier": "mid",
    "matched_keywords": [
      "rx 9070 xt",
      "9070 xt",
      "9070",
      "rx 9070"
    ],
    "title": "My 1st AMD GPU : Sapphire Nitro+ 9070 XT",
    "selftext": "Salam Aidilfitri to all Muslim that celebrated.\n\nWTShare my latest A3 build üò∏\n\nIntel¬Æ Core‚Ñ¢ i7-14700 Processor\nSapphire Nitro+ AMD Radeon‚Ñ¢ RX 9070 XT\nNZXT Kraken Elite 360 RGB White \nCorsair Vengeance DDR5 16GB x 4 5200Mhz White\nROG Loki SFX-L 850W White\nLian Li A3-mATX\nLian Li Uni Fan TL Wireless 120 x 4\nSamsung Evo 970 Plus 1TB + 500GB NVME M.2\n\ngpu finally arrived today (gpu-less since sept 2024) jumpship from Nvidia (Strix 3070) to AMD (Nitro+ 9070 XT) ü´£\n\n95% finished for now? the cabling need some fixing later ü§£",
    "comments": [
      "why is she trapped inside?",
      "Who's the lady?",
      "So clean and smooth you want to put a can of soda in there. Welcome!\n\n![gif](giphy|py1QeWtxdRzxK)",
      "I'll do you one better. Where's the lady?",
      "I think the 9070xt Nitro + is probably the coolest looking video card I've seen. I'm strongly considering trading/selling my 5080FE for one and take the small fps hit.",
      "Not related to your build at all but you can turn your watermark off in your camera setting, btw",
      "LiSA, a japanese singer üòÜ",
      "in Japan üòÜ",
      "I‚Äôll do you one better. Why is the lady?",
      "The goat of anime openings.",
      "Agree, best looking AIB card I‚Äôve ever seen 100%. I have a soft spot for NVIDIA FE cards but no AIB comes close to this Sapphire card in looks imo.",
      "Not related to your build at all but you can turn your watermark off in your camera setting, btw",
      "my fav singer ü§£",
      "im aware üòÇ i just dont mind it",
      "have you seen power rangers? thats Zordon's cousin!",
      "Who‚Äôs the lady?",
      "But still just turn it off",
      "üíØ üî•",
      "I had a nitro+ on the way, but cancelled it because 1) I vertical mount and this card not really made for that and 2) was worried how it would look in my all white build. Gotta say, it looks super clean here in your white build. I like it!",
      "Btw please deactivate the Xiaomi branding on the photos."
    ]
  },
  {
    "brand": "amd",
    "generation": "9000",
    "tier": "mid",
    "matched_keywords": [
      "rx 9070 xt",
      "9070 xt",
      "9070",
      "rx 9070"
    ],
    "title": "RX 9070 XT Flagship Fight: Nitro+ vs Red Devil",
    "selftext": "",
    "comments": [
      "Red devil getting slightly higher temps here than the other reviews I've seen, but performance is a wash anyways and Sapphire's industrial design can't be beat imo. Given how overbuilt even the \"cheap\" XTs are, though, it's hard to justify paying more than MSRP.",
      "Red devil has 0 noise. It's crazy. Even when running 100% usage, and undervolted with 3300 mhz.",
      "My Red Devil 7900XTX on the other hand, literally screams at me like the actual devil in certain situations. That boy got some coil whine. I love it though lol",
      "TLDR:   \nPerformance is almost identical between the 2 models   \n       \n- Sapphire Nitro+ RX 9070XT: Removable magnetic back plate cover, 3.2 slot, 330.8(L)X 128.5(W)X 65.68 (H)mm, 1591 gr (1898 gr with cover), support bracket included, **12V-2x6 power connector**, no Dual BIOS, consumes more power (346.5 W vs 327.7 W)    \n- PowerColor Red Devil RX 9070XT: 3.5 slots, 340(L)X 132(W)X 69(H)mm, 1538 gr, GPU holder included, 3x 8-pin power connectors, Dual BIOS, OC BIOS runs slightly hotter (62 vs 59 degrees), slightly more quiet",
      "I guess when some other brands push AMD power limits there's very not much benifit. It seems that PowerColor was aware of that and preffer to opt for much more silent operation rather than pushing the fan to operate at high speed just to get 1 or 2 frames per second. Props to PowerColor for that.\n\nFrom my understanding, PowerColor has their OC bios, 330W where Taichi is 340W and Sapphire 340W? not sure if anyone can confirm those.",
      "I love the Nitro+ but now im afraid of the 12V power connector because of Nvidia.",
      "I was going for the Nitro+ but it sold out in the 5 minutes it took me to drive to the store and they only had the red devil so I got it instead.\n\nWhile the aesthetic is certainly better on the nitro+ I still think, the red devil performs incredibly well, it is practically silent with no fan noise and no coil whine, exactly what I wanted.",
      "Cable is fine when 600 watts aren‚Äôt running through it.",
      "Crazy because mine doesn't make any noise.",
      "My Sapphire 9070XT reports as 330W. Can only increase power 10%, so 363W is maximum. The card itself reports its own power spikes in HWINFO, and I've seen as high as 575W (likely 1ms) under \"GPU Power Maximum.\" I like info like that.",
      "I have the nitro + it is a nice card. I also have the Gigabyte Aorus Elite coming as I got a killer deal on it. I'll try it out and see which one undervolts / OC better. So far for real world stability the Nitro + can only sustain -60mv underclock or it does driver crash in Helldivers 2 after a while.",
      "Yeah this seems like proper usage of the connector. Even with brief spikes it should be within tolerance. \n\nStill I wouldn't want it personally.",
      "Has to be Sapphire.",
      "The 9070xt Red Devil Limited Edition comes with a metal keycap for your enter key that has little fans that spin when you brush your finger across it.  For that alone, Red Devil wins for me because it is an amazing fidget spinner.",
      "The Nitro+ only draws 330w, around half of what the 12v cable is rated for.",
      "Not sure about the Nitro+ but my Taichi has had 6 near consecutive hours on full load several times with no connector issues so far. Swapping my old PSU with 12v horsepower to a new one with ATX 3.1 compatibility soon so hopefully nothing comes up with that.",
      "Can't wait to hear how you compare the Aorus Elite to the Nitro+. Also, nice to hear people being honest about their \"stable\" undervolts. So many people with \"yeah I'm 100% stable at -120mv and 2850 fast timings\" and it's like, 1. Your memory OC will crash in two minutes of memtest vulkan and 2. Your \"stable\" undervolt will crash under real world gaming conditions and probably in the boss battle.",
      "Seen somewhere that PowerColor Red Devil are 330W, which is just 10W less than Taichi I believe at 340W. It's interesting to see they actually had more power phases VS Sapphire, it's always a good thing for reliablity.\n\nLove the Red Devil design, had a couple from previous gens and they were always cool & super quiet.",
      "I could probably use my AQUA's coil whine as a midi speaker, just program each key to set a max fps and put on the fuzzy donut üç©",
      "Aorus Elite next"
    ]
  },
  {
    "brand": "amd",
    "generation": "9000",
    "tier": "mid",
    "matched_keywords": [
      "rx 9070 xt",
      "9070 xt",
      "9070",
      "rx 9070"
    ],
    "title": "RX 9070 XT or 5070 ti",
    "selftext": "Hello community I am overthinking a bit which card would be better for 1440p AAA gaming. \nSapphire Nitro+ RX 9070 XT for 888,90‚Ç¨\nAsus Prime 5070 Ti for 1044,90‚Ç¨\n\nI am not sure if that \"150‚Ç¨\" premium is worth it for basically only better RayTracing performance.\n\nThx for your ideas",
    "comments": [
      "Rx 9070xt is the better choice from what I‚Äôve seen. They are pretty comparable in performance and the 9070 is cheaper",
      "It still comes down to the same considerations since last gen. \nOnly the differences are smaller then before as AMD has caught up a lot on both ray tracing and upscaling/frame generation.\n\nA) Is the great raster performance of AMD enough for you?\n -Buy AMD.\n\nB) Do you want to use ray tracing/path tracing a lot and also upscaling/ frame generation?\n -Buy Nvidia.\n\nIf you don't play the kind of games that you will find on digital foundry's best graphics of the year awards on youtube, you will probably not miss anything this generation by buying AMD. \n\nIf you want to play those high fidelity high end games, maxed out, you will still be better off with Nvidia. (Watch digital foundry's latest video about 9070xt performance on path tracing).\n\nEdit: moved one paragraph up",
      "I have the nitro its a phenomenal card with little overclocking im getting near 5080 performance",
      "As someone with a 9070xt, get the 5070ti for 1440p, Nvidia features are that good.",
      "Yes but I also compare valur of the model. Lowest 9070 xt is for 730e and in that case the price diff is 300e",
      "As someone who switched from nvidia, I am pleasantly surprised at how good amd‚Äôs software is, especially with the new fsr4 mod by optiscaler. I can even play some games with dlss inputs, converted into fsr4. \n\nThis is possible because of amd making fsr open source I believe, which nvidia would never do. And the software from amd has been great so far, with way more features than nvidia.",
      "The 5070 ti has about 9% better performance when not using ray tracing. It also has better upscaling. To me, that puts them at roughly equal value at their respective MSRPs. Both are good choices. Do you want better performance or lower cost?",
      "Why the hell would u want a 9070xt if u have the money for a 5070ti\nGet a 9070xt if u don't want ray tracing but who doesn't? U only live once if u have the money. And Reddit is 90% amd and want Nvidia to fail for some schizophrenic reason.\n\nNvidia is popular",
      "Ah if you have it already idk. Personally I'd just stick with the 9070xt at that point haha.",
      "[https://i.imgur.com/THNe9lq.png](https://i.imgur.com/THNe9lq.png)\n\nFSR is open source. Not to mention, the creator of Linux, Linus Torvalds also hates nvidia, and has openly criticized how difficult it was to work with them. And nvidia's software is actually horrible. It doesn't even let you use the software without creating a nvidia account. Do I need to explain why that is a bad thing?\n\nNot to mention how the overlay and geforce apps hurt performance, with many features being hit or miss in many games. AMD's software includes features like overclocking, monitoring, etc. and there is zero effort in using it (Especially no account creation needed). So no, Nvidia's software is not miles ahead, it's behind in many ways.\n\nDLSS4 might be good, but FSR4 comes very close, and looks like it will only get better with time, just like DLSS did.\n\nEdit: Oh, and regarding your point about game support for optiscaler, if you had just read the huge note that is mentioned, in bold, at the top of the compatibility list, you may have found that the list isn't complete, as Optiscaler FSR4 just got released and is in alpha  -\n\n\"**This is**¬†`not`¬†**a complete list of games supported by OptiScaler.**\n\nOptiScaler is compatible with most games that support¬†`DLSS 2+`,¬†`FSR 2+`¬†or¬†`XeSS`.  \nThe list below includes games and configuration options shared by our community members.\"",
      "Digital foundry on YouTube, latest video on the 9070 path tracing performance. 50 seconds in. 1080p native , no upscaling, no frame generation full ray tracing with path tracing in Cyberpunk 2077. 37fps. Not exactly smashing it out of the park, according to me.\n\nEdit: it's the 9070xt with 37fps. To be clear.",
      "If it's the same money get the 5070ti, rt is faster. It all depends on the price. Where I am from 5070 at launch was more expensive than 9070xt by 300 euro. Now they are similarly priced and that makes the 9070xt a better choice, though both are horrible priced. The 5070ti is even worse. Honestly at 1100 dollars like you said you have them, they are both horrible priced. That gpu is worse than the 1000 dollars 4080 super, and you pay more for it.",
      "Not just better raytracing. Dlss4 is still better quality than FSR4 and better game support (yes optiscaler, but native support is betterer). Mfg actually looks pretty compelling, reviews are decent",
      "I own a 5070ti and for that price just go with the 9070XT, it's very very close to 5070ti basically it's a tie. They both outperform each other depending upon the title. But I must say after coming from a 7800XT, the ray tracing and path tracing feels next level with dlss but then again it's not worth the extra 150$ in my opinion, maybe extra 50$ at max",
      "Honestly might be one of the best takes I‚Äôve seen on the situation.\n\nI‚Äôve been feeling bad about my purchase of a 5070 with all the hate going around but the performance gaps seem so neglible for casual gaming and I‚Äôm very much the type of person to crank on all the graphics settings so the game looks pretty.\n\nWith how I play I‚Äôd rather path tracing over higher fps",
      "Not to mention Nvidia's stinginess with VRAM, which limits the lifespan of most of their more expensive cards for said high fidelity games.",
      "This is a great explanation for why one should buy one or the other. I personally bought a 9070 (non xt) but I did because of what this man said. I don't do AAA gaming and I wanted the extra vram for more future proofing. Either way op goes though, I hope he is happy",
      "Derbaur recommends undervolting the card and increasing the power target, effectively boosting clock speeds - giving about a 10% boost over stock... üëç",
      "This is the opinion I value the most..someone with both AMD and NVIDIA experience.",
      "Thats the case I am also looking at it money wise. I wanna know if nearly 300e difference for base models is fair price diff. I used to have 7900xt and before 6900xt so not using RayTracing so extensively is not a big loss for me bht from what I have tested Rtx is pretty solid even on this 9070xt. But PT is tragic thats for sure.\n\nIf only there were msrp 5070ti ...I would take it right away :D"
    ]
  },
  {
    "brand": "amd",
    "generation": "9000",
    "tier": "mid",
    "matched_keywords": [
      "rx 9070 xt",
      "9070 xt",
      "9070",
      "rx 9070"
    ],
    "title": "OC3D -WHITE DEVIL! Powercolor Devil RX 9070 XT Spectral White Ltd Edition",
    "selftext": "",
    "comments": [
      "yakub will not be happy",
      "lol white devil",
      "so this actually got through a bunch of marketing people without any concerns?"
    ]
  },
  {
    "brand": "amd",
    "generation": "9000",
    "tier": "mid",
    "matched_keywords": [
      "rx 9070 xt",
      "9070 xt",
      "9070",
      "rx 9070"
    ],
    "title": "ASRock to start selling Radeon RX 9070 XT Steel Legend Dark edition in early April",
    "selftext": "",
    "comments": [
      "Seems like April is when we will get a major influx of either new SKUs being available, or better stock of current ones",
      "Stock has been steadily improving most places outside North America throughout the month so wouldn't be surprised. Here in the Netherlands cheapest 9070 XT price has been decreasing from ~950 soon after launch to 810 today.",
      "\"The dark shouldn't be much more expensive. In fact, it should cost more.\"\n\nGTFOH",
      "Where's the MSRP cards.",
      "So, is this basically a rerelease of an existing car at a higher MSRP?",
      "I have no interest in any card more than $50 above MSRP, but it‚Äôs sad there‚Äôs so many people with no problem paying a premium",
      "Back in time about a month. You will never see a 9070xt at msrp again.",
      "fuck these journos that rationalize this bullshit",
      "here in Portugal we have one being sold for 800‚Ç¨ (after an initial price of 700). then everything else is closer to 900.",
      "I want more colors, but not waifus. I thought the Cute Pet line from Yeston was more exciting than more random anime girls.\n\nReally, I wish OEMs would cut back to a couple of cooler SKUs that users can customize, then see them sell alternative backplates and fans and shrouds. That'd at least give us some reason for spending more on these cards than just asinine markups for nothing.",
      "Can we get more colorful and waifu design cards in the west? Getting tired of all the grays, blacks, white and gunmetal",
      "For 1k$",
      "I've been waiting on an available Nitro+ SKU OR anything for ASrock. Hoping April will be it, I'm getting impatient lol",
      "We'll see. I would imagine it keeps the same price as the existing variant, which already increased by $70 after the fake MSRP launch.",
      "Yeah, MSI restocked some of their 5070Ti shadow at $750 yesterday. Probably better than a 9070xt at $720",
      "Fun fact, it actually does! That card in particular can draw up to 380W, with transient spikes above 400W. We've seen melting on 4080s with similar power draw.\n\nSimilar to the Nvidia cards, both 9070 XT models that use the 2x6 pin connector lack the ability to load balance between the individual 12V wires, resulting in the ability of >30A traveling through a single wire at worse case!\n\nYou better hope your cables and pins for your power supply, all connectors, and your card are perfectly made and perfectly installed to make perfect contact, else you're risking a melty connector. Best of luck!",
      "I agree and wish we had more from the manufacturers (like the Asrock LiveMixer line has been fantastic). \n\nBut you can always get a new backplate at v1tech or make something yourself with a bit of acrylic, paint and elbow-grease. Lots of inspiration in /r/pcmods if you feel like making something truly custom.",
      "starting to see 5070 + ti at msrp even online sometimes, I'd just get a ti if 9070s arent at MSRP",
      "This looks dope. It's what I need actually, my build is all black non-RGB and without fancy stuff.",
      "Yeah I feel like I'm going crazy seeing so many people on this sub saying stuff like \"I actually got a great deal, I only paid 25% over MSRP!\" or something like that. \n\nLike, for a subreddit that touts itself as the champion of \"value,\" they sure seem willing to buy into the same price bullshit that they claim Nvidia pushes. \"I'll only buy it if it's MSRP and no higher,\" and then a week later \"it was only $190 over MSRP so of course I had to get it!\"\n\nAbsolute hypocrisy."
    ]
  },
  {
    "brand": "amd",
    "generation": "9000",
    "tier": "mid",
    "matched_keywords": [
      "rx 9070 xt",
      "9070 xt",
      "9070",
      "rx 9070"
    ],
    "title": "[phoronix] AMD Radeon RX 9070 + RX 9070 XT Linux Performance",
    "selftext": "",
    "comments": [
      "\"The Radeon RX 9070 series Linux experience was stable (I didn't encounter a single hang / kernel oops or any other problems like that!) and was smooth from desktop to gaming. It was a very pleasant initial AMD RDNA4 experience on Linux. This was a great at-launch experience using the upstream and open-source driver support from AMD. The one thing though... There's room left for performance optimizations. The main downside of my initial Linux testing was that the performance wasn't as great as what's been reported under Windows 11 with the official Radeon Windows driver. Relative to the Radeon RX 7900 series on Windows, the RX 9070 performance on Linux was less enticing right now.\"",
      "You don't typically \"update drivers\" in Linux. You update the kernel.\n\nFrom the article:\n\n\"What you're probably wanting to know first up as a Linux gamer/enthusiast... All of the Radeon RX 9070 series support is upstream in the Linux kernel and Mesa.¬† \\[...\\]\n\nOn the kernel side, Linux 6.12 LTS and newer is what's recommended for the Radeon RX 9070 series. Linux 6.12 is last year's Long Term Support kernel version and fortunately the RX 9070 series support should be \"good enough\" for those using that version. But as is typically the case with new hardware support at launch, the newer the kernel the better. So if able to, using Linux 6.13 stable is recommended and the Linux 6.14 kernel will be out later this month. For my testing I was using Linux 6.14 Git to enjoy the most up-to-date AMD open-source driver support available.\n\n\\[...\\]\n\nAMD has tested the Radeon RX 9070 series to be working out-of-the-box on the likes of Fedora 41 or with Ubuntu 25.10 as well when fetching the latest AMDGPU firmware files. The needed RX 9070 / RDNA4 firmware files are all upstream in linux-firmware.git, so make sure you have those bits as well if planning to buy a Radeon RX 9070 series graphics card.\"\n\nSo find a distro with the kernel version you need and/or update Mesa as per the instructions in the article. Or wait for kernel updates on the distro you're using.",
      "Is it possible/easy to update drivers in linux? Or are we just stuck with what the distro gives us?\n\nEdit: why the downvote? I'm asking because I honestly don't know and want to know.",
      "I'm all for including newer games that can be fully automated and benchmark friendly, but unfortunately there aren't too many of them. And then the ones that there are, sometimes break like a number of the now-older Feral game ports not working nicely on modern distros. Occasionally Proton (Steam Play) causing issues for some Windows games, etc.\n\nSolutions used by some Windows reviewers like Auto Hot Keys and the like unfortunately don't work on Linux especially with X11/Wayland differences, complications around Proton, etc.\n\nIn turn I am also relying on what the game / game engine exposes for performance data and do show frame times where exposed and the like with some of the overlay/external reporting not always working out accurately/reliably on Linux I prefer to source just from the game engine...\n\nTLDR: if there is any newer games that work on Linux that are automated/benchmark friendly, I am more than happy to incorporate them but they are rare. That's also in part why many of the Linux GPU driver developers just rely on repeating shader runs and the like but aren't realistic there either for not executing the game logic, etc.",
      "As much as I appreciate the work Larabel does in general, I don't know how much relevance his gaming hardware testing has to real-world gaming. A large portion of these benchmarks are synthetic and he still chooses to use average/min/max framerates rather than average/1% low. At least he stopped including Xonotic...",
      "Maybe it keeps the numbers more comparable to older reviews?",
      "I can't find these results in [openbenchmarking.org](http://openbenchmarking.org)\n\n\n\nUnrelated but how the hell is 6800XT is performing better than 7800XT?",
      "Thanks for the thoughtful reply. While the following suggestion is still a synthetic benchmark and thus doesn't really address my concern, Decay might be worth including to represent Godot Engine.\n\nI wonder if it'd be worth mentioning this to developers of native Linux games while they're still in early access; many might not realize this is a desirable feature to build into their games. I'm sure that there are at least a few who would be motivated to do so if it gave them a good shot at being featured on Phoronix. Maybe reach out to Alderon Games and/or Kerzoven?",
      "As for Godot benchmarks, I have been closely monitoring their work for years. They do have some suitable benchmarks but alas not the type of benchmarks gamers would want to see...\n\ne.g. [https://benchmarks.godotengine.org/](https://benchmarks.godotengine.org/)  \n[https://github.com/godotengine/godot-benchmarks](https://github.com/godotengine/godot-benchmarks)\n\nLooking more at the primitive engine performance and would be likely more criticized then Xonotic or other open-source games but not modern...\n\nFor game developers I do interact with, I do passionately promote for better benchmarking support to encourage testing by reviewers / more likely to be tested by IHVs and ISVs / etc. Sadly though the investment by the game developers in working on such capabilities typically doesn't pan out for them in a quantifiable manner.",
      "I wonder if we‚Äôre going to get a Radeon Pro RDNA 4.",
      "7800xt has less cores and less ROPs. And is MCD which is bit tricky especially with early Linux drivers IIRC.\n\nBasically the amd 7000 and Nvidia 4000 were both massive scams where tiers were upshifted in branding names. For example the 7800 is one die lower than the 7900s, while the 6800 was the sane die as the 6900s.\n\nNgl I got a 6800xt for 300GBP and I'm still on the fence about if 9070xt is even worth it right now.",
      "I'd include it in mine and maybe still will but I'm also targetting 360 fps on a GT 640 (the testing machine, an i5-2400 desktop, is sitting right next to me), so it's also kind of meaningless.",
      "Someone has probably suggested MangoHUD to you before; I find it quite useful for monitoring performance and framerate limiting, though I haven't used it as a proper benchmark tool. If you've tried using MangoHUD for this purpose, I'd be interested in hearing why you decided not to go with it. If you haven't tried it yet, perhaps it would be a good thing to test.",
      "MangoHUD can take care of performance metrics (there were some issues with Wayland/X11 and accuracy, but that's been I think a few years since I heard about any issues or at least aside from compositor bugs) but that still doesn't take care of automating the game/execution logic for being able to automatically launch and replay a desired scene for reliably ensuring given settings are applied and reproducible scene/etc are used (where AutoHotKeys is used by some Windows reviewers for similar games paired with FRAPS or other programs). It can work for a couple select games (and I used a similar approach for some now-obsolete UE4 benchmark demos with an overlay) but it unfortunately doesn't really help in any large manner.",
      "Each distro provides online repositories that are constantly updated with drivers and other software. The experience on most distros is much like under Windows: Just click the Update-Button in the update tool or enable auto updates."
    ]
  },
  {
    "brand": "amd",
    "generation": "9000",
    "tier": "mid",
    "matched_keywords": [
      "rx 9070 xt",
      "9070 xt",
      "9070",
      "rx 9070"
    ],
    "title": "My Anti-RGB 9070 xt build!",
    "selftext": "Specs:  \nGPU - rx 9070 xt  \nCPU - i5-14600kf  \nPSU - 850W Gold Gigabyte  \nRAM - 32GB ddr5 corsair vengance  \nSSD - 2tb crucial p.3 nvme  \n",
    "comments": [
      "now do some anti cable",
      "Just spend five minutes on cablemanagement bro",
      "He posted a picture. Aestetics is the whole point of it.",
      "Clean off the lens on the camera, retake some pics, and resubmit. Looks clean otherwise.",
      "That is not the point of the post, nor my comment.",
      "I mean, yay? but like bro please cables dawg",
      "Wireless PSU when? :D",
      "Who wired that‚Ä¶stevie wonder",
      "just be honest and say youre on a budget",
      "Cable management. A lesson of love!",
      "If cable management is just for aesthetics, I think they should start selling cases without glass again",
      "Already told you that that XFX light is ruining it :(",
      "Not everyone likes the teenage boy gamer aesthetics of RGB lighting",
      "If you want to go all \"black\" have a look at \"be quiet\" coolers.",
      "huh?",
      "I like it, it's understated and not obnoxious like RGB.",
      "gave you an upvote because i'm a lazy ass and dgaf about cables",
      "I've started to notice that the \"anti-RGB\" crowd is just as insufferable as the RGB centric crowd. That's not necessarily directed at OP here. But some of these comments here and certainly many other posts and comments are reaching \"I'm a vegetarian\" levels of cringe.",
      "Long live anti rgb",
      "Have done, new picture awaiting moderator approval. Build looks much cleaner now thanks."
    ]
  },
  {
    "brand": "amd",
    "generation": "9000",
    "tier": "mid",
    "matched_keywords": [
      "rx 9070 xt",
      "9070 xt",
      "9070",
      "rx 9070"
    ],
    "title": "AMD DID IT...Sorta - Radeon RX 9070 XT & RX 9070 Review",
    "selftext": "",
    "comments": [
      "MSRP Tomorrow and I Buy.",
      "Which online retailers should I be looking at tomorrow? First time buying a card on launch day!",
      "I am assuming all the normal retailers... best buy, new egg, amazon.... but Really wish they were on there before tommorow....",
      "> Just buy a 7900xt and get more vram for less\n\nWhere?",
      "HUB swears they will, after informing with stores.",
      "Indeed.",
      "According to Techspot, AMD is actually subsidizing some cards to actually reach MSRP with 50$ rebate:\n\n[https://www.techspot.com/review/2961-amd-radeon-9070-xt/](https://www.techspot.com/review/2961-amd-radeon-9070-xt/)\n\nSeems disingenuous if after some time cards will actually be more expensive.",
      "Thats what MLID says, buy at release. They will get more expensive afterwards.",
      "My local microcenter said there is a lot of supply.   He does not expect supply to run out day 1.  You just might not get the one you want, as the day goes on.",
      "Hey OP ‚Äî /r/AMD is in manual approval mode, this means **all submissions are automatically removed and must first be approved before they are visible to others**. This is done to prevent spam, scams, excessive self-promotion and other rule-breaking posts.\n\nYour post will be approved, provided it follows the subreddit [rules](https://www.reddit.com/r/Amd/about/rules/).\n\n**Posts regarding purchase advice, PC build questions or technical support will not be approved.** If you are looking for purchasing advice, have a PC build question or technical support problem, please visit the [Q1 2025, PC Build Questions, Purchase Advice and Technical Support Megathread](https://www.reddit.com/r/Amd/comments/1hqs820/pc_build_questions_purchase_advice_and_technical/).\n\n\n*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/Amd) if you have any questions or concerns.*",
      "Same, really excited!",
      "Yeah, I‚Äôm stoked. First build in like ten years! I did have a prebuilt in between but that‚Äôs not as fun",
      "It's basically a 7900xt with better raytracing and upscaler but for $600 instead of $900 which was that card price at launch. Though it seems better than that depending on the game, specially with RT it's more of a 4070ti which has an msrp of $800.\n\nAll of this while you can't get an nvidia card on the same tier under 1k.",
      "\"under 1k\"‚Ä¶ if you can get it at all.",
      "With us pricing, they can just blame tariffs",
      "quite dissapointing the video app benchmarks, probably need more drivers work....",
      "Yep. I'm heading to Microcenter a few hours before open to see if I can get one",
      "But at what time?",
      "I got myself a 7900xt a week ago for 550$, but i would prefer a 9070xt tbh. No reason to change or regrets tbh, but if I'd pick now, I'd get a 9070xt",
      "It's above a 7900xt and the games depends but overall it's above"
    ]
  },
  {
    "brand": "amd",
    "generation": "9000",
    "tier": "mid",
    "matched_keywords": [
      "rx 9070 xt",
      "9070 xt",
      "9070",
      "rx 9070"
    ],
    "title": "AMD CEO: Radeon RX 9070 XT first week sales 10x higher than previous generations",
    "selftext": "",
    "comments": [
      "Turns out all you have to do is bank on your main competitor absolutely shitting the bed and releasing a product that doesn't catch on fire.",
      "Who would have known that making a good product at a great price is going to sell well... But good game AMD!",
      "A little bit surprising, but not by a huge amount. Nvidia's pricing and supply issues along with the ROPs scandal's been hitting them, and meanwhile AMD put out something almost as good but MUCH cheaper, so for once, GPU buyers have noticed and are switching sides.\n\nNow AMD just has to maintain this momentum and keep executing to grow their marketshare. And improve their marketing and branding. While it's not Apple cult levels of loyalty, Nvidia fans really love the brand. Mindshare and \"coolness\" matter.",
      "Nvidia just left a gap in the consumer segment, which AMD filled. Nvidia doesn't care about gamers right now, the big money is in the datacenter segment.",
      "The fact that Amazon has/had a platform and couldn't capitalize to take even 5% of marketshare shows buffoonery levels of incompetence.",
      "Well.. the last ones didn't suck as well.\nIt's just NVIDIA sucking really hard on so many levels.",
      "[AMD Reportedly Shipping 200,000 RDNA 3 \"Navi 31' GPUs For Radeon RX 7900 XTX & RX 7900 XT In Q4 2022](https://wccftech.com/amd-shipping-200000-rdna-3-navi-31-gpus-for-radeon-rx-7900-xtx-rx-7900-xt-in-q4-2022/)\n\nFor comparison.",
      "turns out releasing a good product to an almost almost fair price works for the consumer :O",
      "Yeah if they can not fuck up the 9060/9060xt they could be in for some real market share.\n\nI dont know if they have a 9080/9080xt at all. But man one can hope.",
      "Is that the right comparison? 3 months vs first week?",
      "Yup same thing that happened vs intel with the 9800x3d. It's a good product but not really light years ahead of the 7800x3d",
      "Imagine if they had stock for more than a couple days!",
      "Well, I don't care if they let them take it or if AMD conquered it. What I care is: do I get good parts for a better price? Thats all that matters if you are not an employee or a major investor.\n\nBtw, \"not caring enough\" is not an excuse for these recent mistakes. If you are in the market offering a solution, your solution must be good and have quality, no matter how relevant it is for your company. Cables reaching 150¬∞C and melting psu, cable and gpu is more than being indiferent to gaming market.",
      "Amazon had a platform?",
      "Yup, the guy in charge of it for 2 years gave up because every market analysis showed Steam destroying them in every way",
      "In Europe, the cheapest cards (around 800 euros) means they are still 20% over MSRP + TAX\n\nAnd people are lapping them up. We are setting the new MSRP's ourselves.",
      "Yeah, but the idea is that after a certain price point (which I'd say it's around \\~$1K) the potential buyers pretty much want the absolute best and can pay for it so just having \"the 2nd best\" or \"close to the best but with compromises\" no longer cuts it. The best example is how the 4080 sold extremely poorly at $1200 but as soon as it was re-released as the 4080 Super at $1000 it suddenly started sellling well: basically the customers that had $1200 to spare could go up to $1600 for a 4090 and beyond with no problem, and this is what would have happened to a hypothetical 9080 card at >$1000 (because the die size would have been ridiculously big and the yields, potentially mediocre).",
      "Steam is doing a LOT more than just providing a platform to download games.\n\nLike, dude.",
      "People told them to work on raytracing and their upscale tech and they did. Do the same next gen to match Nvidia and watch the money flow.",
      "I got a 7900xtx for like $900 over a year ago, and this card is pretty much matching or exceeding performance and has access to FSR4 for a lower cost point. I only got it because 4090s we're 2x the MSRP and a 4080 was nearly identical performance but also higher cost than the xtx.\n\n9070xt is better than AMDs \"top-of-the-line\" card. Of course it's going to sell well.\n\nI just wish AMD could make a real \"high performance\" card to offer an NVIDIA alternative. I know they'd never take over that market but just having the option would be nice."
    ]
  },
  {
    "brand": "amd",
    "generation": "9000",
    "tier": "mid",
    "matched_keywords": [
      "rx 9070 xt",
      "9070 xt",
      "9070",
      "rx 9070"
    ],
    "title": "RTX 5070 vs RX 9070 vs RX 9070 XT- The Ultimate Comparison!!!",
    "selftext": "",
    "comments": [
      "Whichever you can buy at MSRP is the best. Change my mind",
      "Hey OP ‚Äî /r/AMD is in manual approval mode, this means **all submissions are automatically removed and must first be approved before they are visible to others**. This is done to prevent spam, scams, excessive self-promotion and other rule-breaking posts.\n\nYour post will be approved, provided it follows the subreddit [rules](https://www.reddit.com/r/Amd/about/rules/).\n\n**Posts regarding purchase advice, PC build questions or technical support will not be approved.** If you are looking for purchasing advice, have a PC build question or technical support problem, please visit the [Q1 2025, PC Build Questions, Purchase Advice and Technical Support Megathread](https://www.reddit.com/r/Amd/comments/1hqs820/pc_build_questions_purchase_advice_and_technical/).\n\n\n*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/Amd) if you have any questions or concerns.*",
      "There are 7900xtx going for 850‚Ç¨ here from time to time, I would say just get one of them, should be better performance and about as expensive if not even cheaper."
    ]
  },
  {
    "brand": "amd",
    "generation": "9000",
    "tier": "mid",
    "matched_keywords": [
      "rx 9070 xt",
      "9070 xt",
      "9070",
      "rx 9070"
    ],
    "title": "PowerColor Radeon RX 9070 XT Red Devil Spectral White leaks out",
    "selftext": "",
    "comments": [
      "Shouldn't they have just called it \"White Devil\" or something?",
      "Unavailable Devil",
      "![gif](giphy|BcPLSlLg1w3ja)",
      "Holy Devil. üòÇ",
      "Premium on RX 7800 XT cost an extra $50-60 for most OC models.  $80 more for the \"Limited Edition\" Red Devil which was numbered.  Now premiums are +$200 and up for the same tier card one generation later.",
      "That is what chinese call westerners ... well at least in some old kung fu movies.",
      "The premium on the red devil is bs",
      "Bumblebee Tuna",
      "Proshop has it listed for \\~800 USD (without VAT). Out of stock and no estimated stocking date.\n\nWhat I want to know is if it's a white LED like the Spectral White Hellhound or ARGB like the regular Red Devil that just defaults to white instead.",
      "Let‚Äôs call it Gweilo",
      "Even better",
      "The premium on everything is. I think the Hellhound is only listed at $20, at some retailers ($780 vs. $800).",
      "While not confirmed I would assume ARGB as it‚Äôs going to be otherwise the exact same as the regular Red Devil. Kinda like how all the regular Red Devil pics show the LED as red but it can do ARGB.",
      "White Angel edition üëÄ",
      "![gif](giphy|4VBCbxmJuAFC8)\n\n‚ÄúWe‚Äôve got Guano!‚Äù",
      "Paper Devil",
      "‚ÄúRed Devil -Fallen Angel-‚Äú would have been a cool name for it.",
      "Isn't every 9070xt technically limited edition right now?",
      "the devil is already a fallen angel, just angel would be more fitting.",
      "Yes of course this would get released after getting the black version üò≠"
    ]
  },
  {
    "brand": "amd",
    "generation": "9000",
    "tier": "mid",
    "matched_keywords": [
      "rx 9070 xt",
      "9070 xt",
      "9070",
      "rx 9070"
    ],
    "title": "ASRock Radeon RX 9070 XT Taichi OC Review - Excellent Cooling",
    "selftext": "",
    "comments": [
      "This card is awesome! Mine consistently boosts a ove the rating and stays icy while doing it. It's crazy.",
      "At first, I was going to limit the boost clock speed since adrenalin is known to boost over the advertised speeds. However, my card boosts over 3100MHz occasionally and no crashes. I stress tested the card in 3D mark, in game benchmarks, and flawless experience for me.\n\nI was skeptical at first moving from NVIDIA to AMD again since the 5700xt was a nightmare experience with nothing but crashes. \n\nSmooth experience for me with ASRock Taichi 9070XT.",
      "still missing 9070 non XT from the charts",
      "Ive got the sapphire nitro+ and on the strongest stress test i couldnt get its core temp to go above 56¬∞c.  It really has good cooling. My old 2080ti would easily hit 75¬∞c in an instant.",
      "The weird thing about 9070 XT in general is that the core GPU temps are very low while hotspot temps are comparable to previous generations.\n\nIn stress testing my XFX Mercury also tops out around 55C but the hotspot hit 79 C.  I'm not worried about 79 C hotspot but that is a large delta from the GPU temp reading.\n\nTo me it seems like the sensors for GPU temp are not comparable to previous generation, perhaps they are polling the average temperature from cooler parts on the chip compared to previous generations. While hotspot still reports the same because it's just the hottest sensor available.",
      "Not exactly rocket science to cool 300+W",
      "Ironically it's been Nvidia drivers crashing and causing nightmares with black screens for two months now, despite multiple hotfixes. The forums have been getting lit up. You switched just in time to avoid a fiasco. I have 2 boxes with 7800XT's, zero issues. The one with the 4070Ti Super, I couldn't get into windows at all. I had to reset my secure boot and uninstall in safe mode to have any chance. As bad as the first half of 2019 drivers were on RDNA1 this Nvidia fiasco is even worse.",
      "I really like the design of having the middle fan spinning in reverse so where the fan blades meet they aren't causing turbulence. My gigabyte 5700 XT had that feature and I think the other manufacturers sleep on it.",
      "You'd be surprised. Their 6800XT Taichi was surprisingly hot, even after correcting their absolutely terrible factory thermal paste job.",
      "Yeah that is the case for me too. I did think that. Weird. \nAt least it got me an achievement on 3d mark to keep temps below 55c lol.",
      "Just locked one down, picking it up tomorrow thank christ",
      "fair point.and -100 uv puts it at over 3400mhz",
      "For sure! The highest boost I've seen was around 3220 ish. I'm really impressed with the card.",
      "The point of getting more performance for less power and less \"wear\" on the chip due to lower voltage?  Seems like a no brainer if it's stable.",
      "Lol i thought mine was an outlier it consistenly boosts to 3,280 during gaming no crashes yet",
      "What's the hotspot temp during gameplay",
      "Ok yeah that's typical with a relatively low fan speed curve",
      "Got a Gigabyte Rx 9070 xt gaming OC coming from newegg. It shipped today!",
      "yeah mines hitting over 3300 mhz at stock settings. i did mess around with oc and undervolt and got good results, but just dont see the point to, so set it back to standard.",
      "But playing Black Ops 6 at 4k Ultra peaking at 61C with the fans going to 0rpm mode between matches?"
    ]
  },
  {
    "brand": "amd",
    "generation": "9000",
    "tier": "mid",
    "matched_keywords": [
      "rx 9070 xt",
      "9070 xt",
      "9070",
      "rx 9070"
    ],
    "title": "AMD continues runaway sales of RX 9070 XT as gap widens to Nvidia, according to large retailer",
    "selftext": "",
    "comments": [
      "My local Memory Express had a pretty decent 9070 XT drop at the start of the day. They're all gone now. I'm still seeing plenty of 5070's (regular and Ti) currently in stock, not moving.",
      "Yup, snagged my 9070xt at the se YYC location, happy to go from a gtx1080",
      "The 9070 beats the 5070 with ease, 9070XT is only slightly behind the 5070ti for much cheaper.",
      "Mindfactory underwent restructuring and just started selling the Radeon RX 9000 series and the GeForce RTX 5000 series.",
      "I got a 9070 XT from Memory Express two days ago. coming from an RTX 3060 this thing is a beast. A bit loud on the coil whine side of things but nothing I can‚Äôt get used to. I am amazed at how powerful this card is and how versatile Adrenalin is. Totally surpassed all my expectations",
      "Doesn't surprise me. Between the initial low stock, high price tags, bad reviews, and the silicon lottery regarding whether its missing ROPS the Nvidia's 5070 series isn't a good buy which is really helping the Radeon 9070 series. Does make me wonder if we'll see a small increase in market share for AMD this generation.",
      "Maybe people are just tired of Nvidia‚Äôs bullshit?",
      "In my country the shops are still putting models up by 20-50-100$ every few days. It's a joke. 9070xt is now $1300-1500 AUD. They even put the effing reaper base model up by $100.",
      "Okay but where are people buying these in the US? I'm looking for a Sapphire Nitro+ and I can't find them anywhere.",
      "Wow, that's a huge jump. Congrats man, I got my 9070 XT recently from B&H Photo. They have wait list and I got notifications like a day after I signed up upgrading my PC from 3070 and I'm loving it.",
      "Relative performance of XT vs Ti is 5-7%\n\nhttps://www.techpowerup.com/review/sapphire-radeon-rx-9070-xt-pulse/34.html\n\nIn Australia, XT's were as low as $1150 but closer to $1200 now, and Ti's are $1500+\n\n25%+ more for 7% performance? That's a hard no for me\n\nOf course it's up to the individual if they care about FSR/DLSS, etc. and what premium they're willing to pay for it",
      "Clearly isn't properly optimised then, and you're using one game to make a definite statement that all games will perform like that, despite other 2025 releases showing the 9070xt being just shy of the 5070ti and the 9070 comfortably ahead of the 5070",
      "I would have bought one if they were on sale at msrp",
      "They narrowly avoided bankruptcy and them now selling these cards is all over their website",
      "You are the target demographic for Nvidias magic features and blatant lies.",
      "I went from a rx470 to a 9070xt and I can't believe it. Plus I'm only on 1080p 60fps locked at moment. The Card doesn't even start fans and in some games on ultra barely 25% usage because of my vsync at 60",
      "At those prices I hope they rot on the shelves.",
      "6800 xt had nearly 4090 performance in COD and 6700 had better performance than 3080 in Far Cry. Imagine using a single title as your reference point, lmao.",
      "Click the gaming tab, then click the graphics tab, scroll down the \"Video Upscale\" and click enable on the toggle.\n\nNot difficult \n\nFsr4 is between DLSS 4 transformer and CNN quality levels with advantages in some areas, and disadvantages in others, it is completely fair to describe fsr4 as being on a par with dlss4",
      "It's funny to me when ppl screaming for competition, but when it actually happens they still try so hard to lock in their \"best option\". And then they continue screaming they getting robbed by companies.\n\nAs for the performance, in raster the xt beat 5070, and come close to 5070ti. In ray tracing, ok the 5070 may beat it in some titles, but ray tracing with 12gb of vram? Unless in 1080p, but then you spend this much money on gpu to play on 1080p display?\n\nBut whatever, it's your money, just don't spread false information."
    ]
  },
  {
    "brand": "amd",
    "generation": "9000",
    "tier": "mid",
    "matched_keywords": [
      "rx 9070 xt",
      "9070 xt",
      "9070",
      "rx 9070"
    ],
    "title": "All team Red build, Asrock RX 9070 XT Steel Legend",
    "selftext": "",
    "comments": [
      "Looks white to me",
      "https://i.imgur.com/WW0sx6h.jpeg",
      "looks like a fractal ridge",
      "Sleekt build, what case is that?",
      "No it is a fan",
      "What feet are you using?",
      "Smooth build! I usually have a hard time liking asrock because I feel they always have a slight cheap look to them",
      "Looks like the same I put on my Lian Li tu150\n\n[Audiocrast 4X HiFi Speaker Spikes Isolation Stand Feet Pad Aluminum 40x20mm](https://www.amazon.com/dp/B08CRK31S2?ref=cm_sw_r_cso_cp_apan_dp_AXA8GE44BVAF8ADFB6Q0&ref_=cm_sw_r_cso_cp_apan_dp_AXA8GE44BVAF8ADFB6Q0&social_share=cm_sw_r_cso_cp_apan_dp_AXA8GE44BVAF8ADFB6Q0)",
      "Pretty simple and straightforward, biggest issue is it does need low temperature components or blow through video card to best utilize the flow design",
      "Yes it does. I can see thermal pad on the backside of where vram resides. And during gaming, it's pretty hot on the plate\n\nhttps://i.redd.it/k4osj240wbpe1.gif",
      "is it coming with gen5 riser now?",
      "No, I don't think Fractal has said anything about an update either. It's not an issue on current cards, at least.",
      "Oddly, my board is B650, yet gpu-z showed PCIe 5.0",
      "which is that keyboard??",
      "Cute mini keyboard.",
      "Sweet looking build. Out of curiosity, how did the build process go with that case? It looks cool and reminds me a lot of the computers you can see in the first Portal game, but also looks like it could be a PITA to deal with.",
      "Anyone else had to do a double check on that title? lol",
      "When you buy a mechanical keyboard like that, does it come with instructions suggesting it be in the background of any photos you take of the PC?  It seems like any time I see a photo of a new PC build, if a keyboard is shown, it‚Äôs a mechanical keyboard like that.",
      "Yes, that's it",
      "How is the noise on it?"
    ]
  },
  {
    "brand": "amd",
    "generation": "9000",
    "tier": "mid",
    "matched_keywords": [
      "rx 9070 xt",
      "9070 xt",
      "9070",
      "rx 9070"
    ],
    "title": "AMD Radeon RX 9070 XT & 9070 (RDNA4) Availability, Buying & Bragging Megathread",
    "selftext": "Today AMD launched the AMD Radeon RX 9070 XT & 9070 (RDNA4) GPUs.\n\nAs with previous GPU launches in recent years, these cards will be in high-demand for the foreseeable future.\n\nPlease use this thread to discuss availability, hints & tips on retailers that have stock, brag if you've ordered one and complain if you couldn't order one.",
    "comments": [
      "European here, immediately out of Stock or 300 EUR over MSRP. Lost cause",
      "Scalpers are already selling their hits on ebay for 899‚Ç¨",
      "Why is it always a shit show?\n\nOrdered from Newegg. First one was out of stock before I could complete my order. 2nd choice worked, only for me to get this email a few minutes later:  \n\n\n>We regret to inform you that your order(s): 54817xxxx was voided due to insufficient stock.",
      "Immediately out of stock, never stood a chance",
      "My local micro center had enough stock for everyone in line",
      "Sapphire Nitro+ sold out within the first ten minutes on NewEgg.\n\n*Aww, shit, here we go again.*",
      "They are not coming in at $599 after today.",
      "Hold strong, wait another week. Local stores seem to have good stock. These cards should not be hard to get in the coming weeks.",
      "availability my ass. good luck if you dont have a microcenter in your town... honestly",
      "I fucking hate scalpers.\n\n**Update**: The two (above msrp) cards that I was successfully able to order were cancelled by Newegg due to \"insufficient stock\" within 10mins the confirmation emails. \n\nI guess my 6800xt will have to keep truckin for a while yet.",
      "Do you remember the times when you could just buy a GPU at MSRP? ![gif](emote|free_emotes_pack|sob)",
      "Also, Newegg completely removed the listings for the Powercolor Reaper models after they sold out. Only the above-msrp models are listed now.",
      "Best Buy is claiming sold out but they're waiting for their deal period to end and they can sell their MSRP card for a markup. Never going to Best Buy unless it's a store closing sale now.",
      "I'm having RTX 30-series PTSD flashbacks.\n\n* Newegg: You might get an order in, but we'll cancel it a few minutes later and keep your money for 3 to 5 days.\n* Bestbuy: All models went from \"coming soon\" to \"sold out\", with no in-between\n* Amazon: Can't be arsed to even list them or have them show up in a search. They'll get around to it someday.",
      "Did the MSRP cards ever even come in stock for Amazon and Bestbuy? I've been refreshing for 45 minutes",
      "UK, immediately out of stock\n\nor websites repeatedly crashing\n\nalso saw some initially listed at 569, then immediately jumped up in price to 669\n\nUPDATE#1\n\nI got a Gigabyte 9070XT OC from Amazon UK\n\ntoday I also see that my Overclockers + Amazon Pay order went through as well for a Powercolor 9070XT Reaper\n\nI guess I'm getting 2 cards...",
      "Well, thanks for nothing",
      "Anddddd it‚Äôs gone.",
      "So.... all of the 599$ cards were gone within one millisecond. This is so fucking stupid. The amount of technology we have yet we can't find a way around scalpers? \n\nI thought I had a asus PRIME but i got a notification AFTER checking out that it was canceled due to low stock.\nI ended up getting a non xt power cooler red devil for 659 and wondering if that was good or not",
      "Bruh my order got cancelled cuz of insufficient stock"
    ]
  },
  {
    "brand": "amd",
    "generation": "9000",
    "tier": "mid",
    "matched_keywords": [
      "rx 9070 xt",
      "9070 xt",
      "9070",
      "rx 9070"
    ],
    "title": "Here to Save The Day - RX 9070 XT + RX 9070 Review and Benchmarks",
    "selftext": "",
    "comments": [
      "Good to have a review with thermals for PowerColor Reaper!",
      "Reaper is hot and loud.. so sapphire pulse then, near two times bigger cooling for same price",
      "Sure ain't saving and money though being sold for $850-1000."
    ]
  },
  {
    "brand": "amd",
    "generation": "9000",
    "tier": "mid",
    "matched_keywords": [
      "rx 9070 xt",
      "9070 xt",
      "9070",
      "rx 9070"
    ],
    "title": "PowerColor Radeon RX 9070 XT Red Devil white edition set to launch on April 8th",
    "selftext": "",
    "comments": [
      "Why are they not calling it the White Devil?",
      "![gif](giphy|iXV2i4kQOPpfTfQs7A|downsized)",
      "it could offend the white race",
      "im white and i want white devil",
      "Needed to be ‚ÄòDiablo Blanco‚Äô",
      "It's $600 but only 1 card per store, afterwards back to $999.",
      "easy there, white chocolate",
      "For $600 right?\n\nRight?",
      "SHIKAKA!",
      "https://i.redd.it/p6sbbpia40re1.gif",
      "And for China only: the gweilo edition.",
      "Trademark infringement with the Nation of Islam.",
      "MAGA edition",
      "I read somewhere white paint actually reduces a heatsink's performance slightly. \n\nNot sure if someone just made that up though.  Maybe it lowers the spacing slightly but wouldn't any paint do that. \n\nAnyone know anything about this?",
      "Thats Butter Boy to you!",
      "Equinsu Ocha Equinsu Ocha.    \nLet me guess.... He said white devil white devil?",
      "There are definitely problems with white specifically, because Noctua sells black heatsinks however, they ditched the white fans a while ago. \nI don't think they addresed exactly why, but common consensus is performance issues (which would take too long/be too costly to fix)",
      "should call it \"green angel\"",
      "![gif](giphy|wORSHzN5sGpRS)\n\nWhite Devil eh?",
      "Probably going to have a $200 up charge"
    ]
  },
  {
    "brand": "amd",
    "generation": "9000",
    "tier": "mid",
    "matched_keywords": [
      "rx 9070 xt",
      "9070 xt",
      "9070",
      "rx 9070"
    ],
    "title": "AMD Radeon RX 9070 XT Review",
    "selftext": "",
    "comments": [
      "Interesting part:\n\nFinally, we have some concerns about how \"real\" the $600 MSRP actually is. After some investigation, it appears that AMD is providing retailers with a $50 rebate to achieve the $600 pricing. This strongly suggests the intended MSRP was actually $650, and AMD is temporarily subsidizing models to hit the lower price point.\n\nFor example, XFX confirmed that the 9070 XT Mercury ‚Äì a model featured in this review ‚Äì will not cost $650. In fact, it won't even cost $700. Instead, the official MSRP is $770, and due to tariffs, its on-shelf price is expected to be $850 ‚Äì which would be tragic if true.\n\nFrom what we've gathered, it seems AMD is starting to play Nvidia's pricing game. This means that while some 9070 XT models may be available at $600 initially, most will likely be priced higher, and restocks at that price may be limited or infrequent. A lot will depend on how sales perform. AMD has a large stock of Radeon 9070 GPUs, so if demand slows after launch, we expect them to continue offering rebates to keep pricing competitive. However, we will have to wait and see how that plays out.",
      "The rebate could also just be covering the increased cost for the tariffs and that 600 is indeed the intended price.\n\nSo we could see prices go up in the US if tariffs don't go away.",
      "something is wrong with their setup because there are huge inconsistencies between 2k and 4k for all games",
      "lol above $800 the card would be DOA",
      "I like the Taichi card the best aesthetically, it looks really nice. But the premium on it is kinda yikes. the spreadsheet says 740 for the taichi so an extra $140. Not sure thats worth it. DEFINITLY dont buy the asus ones imo. Asus is just a crappy company that has been doing some shady and even illegal stuff with not honoring warranties and such. The premiums on their cards is also outrageous.",
      "The mining boom already proved that when no cards are available that people will pay over MSRP to get SOMETHING. Whatever they end up selling for, it won't be anything close to what Nvidia gpus are going for right now. Saw a 5070 ti get listed for $1250 on eBay and sold almost immediately this morning",
      "The spreadsheet says that the taichi will be 740. If thats true im still not sure I really like that price, 140$ is a lot to ask for on a card that has an MSRP of 599. It does have the 3100 boost clock though and the other AIB cards that have the 3100 boost clock have higher premiums than this card has, if the spreadsheet is right.",
      "esa madre deberia costar 12 mil pesos mexicanos y vale 25 mil XD se pasan de lanza los revendedores.",
      "It's interesting HUB maintain the standpoint of \"Reviewers should always test using best CPU to remove any potential bottleneck in GPU benchmarks\" (see their B580 performance using midrange CPUs video, where viewers questioned testing using 9800x3D on midrange cards).\n\n\nBut their test benches always use pretty mediocre SSD. This time it's MSI SPATIUM M470, PCIe 4.0 drive that barely beats PCIe 3.0 ones, even slower than Crucial P5 at times. Last year they used TeamGroup Cardea A440, also a pretty average drive.",
      "Its going to be 750-850 depending on model.  On the scalped market its going to be $1200-1400.  Its going to be the same price as the 5070 Ti with slightly less performance.  I have been through this multiple times, the price will not be competitive.",
      "Being able to buy the card is key. I feel it'll be sold out in < 10 seconds everywhere. I mean if you want to stand out in line at a microcenter then so be it.",
      "Bingo."
    ]
  },
  {
    "brand": "amd",
    "generation": "9000",
    "tier": "mid",
    "matched_keywords": [
      "9070",
      "rx 9070"
    ],
    "title": "AMD's next 12GB GPU leaks online with a list of specs, here's how it compares to the current RX 9070 series",
    "selftext": "",
    "comments": [
      "This is just an article about the Videocardz article that came out earlier this week."
    ]
  },
  {
    "brand": "amd",
    "generation": "9000",
    "tier": "mid",
    "matched_keywords": [
      "9070 xt",
      "9070",
      "rx 9070"
    ],
    "title": "Incredibly Efficient: AMD RX 9070 GPU Review & Benchmarks vs. 9070 XT, RTX 5070",
    "selftext": "",
    "comments": [
      "Can't wait to undervolt",
      "now the wait for street pricing...here in Singapore..not that I'm buying now anyways lol",
      "As much as people like to knock the 9070 in favor of the XT, I like it.\n\n* I game on a 1080p at 60fps. The 9070 seems plenty powerful enough for that.\n* Video suggests (@ 25:56) it's one of the top power-efficient GPUs on the market.\n* It fits my current 650W power supply with only two 8-pin plugs. I'd have to spend $150+ more on another to use the XT.",
      "I undervolted 9070XT (-60mV right now, so far so good) and power limited to 165. Lost only 5 - 7% performance in Kingdom Come. Seems to depend on the game a bit.",
      "Was looking up 9070 benchmarks to feel better about having to settle for the non-XT, after having my XT cancelled by Newegg after getting order confirmation, only to have that one cancelled too. Fuck this.",
      "165 watts? For performance that is still a few % above a stock 9070? That's some serious perf/W right there",
      "Lower temps and less power usage",
      "They're not so much knocking the GPU which is, as you say, a perfectly good one, as the pricing.",
      "My current GPU is an EVGA 1060.\n\nI want its replacement to also last for a long time. It might be a bit overkill for now, but in a few years I hope it will still be capable of running the newest stuff at that framerate. Also not currently a fan of Nvidia.",
      "cant get it in Europe anyway. seems like none of these big tech companies want my money I guess.",
      "Yes! The undervolt allows the GPU clock to stay around 2200 - 2400 Mhz. But it depends on the game/workload. I just tried Path of Exile 2, and its performance hit from stock is about 11%, whereas Medieval Dynasty only lost about 2%.\n\nI was really curious about this when I bought it - reviewers did not do much undervolting. Almost went with the 9070 because I was afraid of the heat in my ITX case, but it's totally a non-issue.",
      "I wonder later on if it‚Äôs possible, like in the past with AMD GPUs such as the 5700 (which could have its BIOS flashed to a 5700 XT or even AMD Vega 56 to 64), to perform a similar BIOS flash on the AMD 9000 series GPUs since they're the same die. Majority of the AMD 9070 has 2x8 PCIE and some model has 3x8 PCIE which is unusual for a card that's power efficient, maybe the power is locked via software?",
      "its really efficient. Mine is using 0 watts.",
      "I tried to get an XT but they sold out quickly, 9070 was going in and out of stock a lot and then I saw the price jump from ¬£525 to ¬£539 and they came back in stock and I said, F it, and pulled the trigger. \n\nClose enough to MSRP to be happy, like under 15 quid difference. \n\nHad been wanting a 7800 XT or 7900 GRE for a while now which the 9070 handily beats both of and if I got the XT version I would have probably had to upgrade my PSU too which I really wanted to avoid.",
      "Is there any real reason for a 9070 at 1080p/60 FPS though? I guess heavy RT content might warrant it, but I feel like you could have gotten into one of several RTX 3000 and newer models for that performance bracket.",
      "For a drastic decrease in power (what, 50%?) I believe this is an excellent tradeoff still. 11% to stay cool and silent is okay, not to mention energy bills and, oh yeah, eco friendliness.",
      "I just got a 9070. Couldn't get and XT . UK... 520 POUNDS.",
      "System runs cooler",
      "I'm just waiting for someone to randomly tell you they have a bunch at their local MicroCentre after you clearly said Singapore.",
      "I managed to grab a Gigabyte Radeon RX 9070 Gaming OC from OCUK at MSRP today. Very much looking forward to receiving it. Was originally planning on getting a 4070 super but they have never come back down.\n\nIt's by far the most energy efficient 16GB card on the market."
    ]
  },
  {
    "brand": "amd",
    "generation": "9000",
    "tier": "mid",
    "matched_keywords": [
      "9070",
      "rx 9070"
    ],
    "title": "AMD Radeon RX 9070 GRE to feature 3072 cores and 12GB memory, further specs leaked",
    "selftext": "",
    "comments": [
      "Graduate Record Examinations edition. The driver has a special feature with a reminder that you still need to study when you start gaming on it.",
      "actually doesn't the GRE stands for golden rabbit edition where AMD released the card in the rabbit year? so shouldnt it be Steel Snake Edition this year? \n\n9070 SSE",
      "Great Radeon Edition",
      "Solid snake edition üóøüóø",
      "Based on those specs this thing might be 10-15% faster than 5060Ti 16GB but with less VRAM, this has to be below $400 but I doubt that.",
      "![gif](giphy|OrFmkOFx7PVK)",
      "id imagine itd be priced at 450$ (where the 7700XT originally sat also with 12gb vram), and the 9060XT 16 slotted under it at 400$.(higherish end of the price target)",
      "If this thing was around 350 it would sell like hot cakes",
      "They are using the nvidia strategy of 5060 ti 16gb having more vram than 5070",
      "Why on earth does the RX 9070GRE have less VRAM than the rumored RX 9060xt?",
      "I thought it was Global Release Edition, because of the sanctions put on China, that the GRE was allowed to be released globally.",
      "$400 for the 60XT is way too much. Even $350 is too much, unless the architecture is way more efficient at lower CU counts, which I doubt",
      "400 is really damn high for a 170mm die and from amd,The GRE will be a damn good 7700xt replacement if they price it at 400",
      "Probably has a little to do with market segmentation, a little to do with memory ICs getting more and more dense so you have to use way less of them to get to the same total memory capacity, a little to do with why a lot of other previously highly parallel things in computing became less and less parallel and eventually serial, just easier to manage and you can get higher clocks if you have less data lanes to synchronize up, meaning those higher speeds are partially due to having narrower memory buses. Though, the 5090 does have a 512-bit one... that's nothing compared to the PS2's 2560-bit one, though.",
      "No! That is not Solid Snake!",
      "I'm calling it the 9700 LE like God intended.",
      "Should at least have a wider memory bus than it.",
      "Why does it have less vram than last gen‚Äôs GRE models?",
      "I mean, it was getting hard to find anything else to take from them.",
      "Without GDDR7 support, they can basically do 6GB, 12GB, or 24GB. Maybe 18GB, by annoying some driver or firmware devs. With a 192-bit bus, GDDR6, and no GTX 550 Ti shenanigans, the amount will match up some low 3*2^n value, like 3, 6, 12, or 24."
    ]
  },
  {
    "brand": "amd",
    "generation": "9000",
    "tier": "mid",
    "matched_keywords": [
      "rx 9070 xt",
      "9070 xt",
      "9070",
      "rx 9070"
    ],
    "title": "Tearing Down Sapphire's RX 9070 XT Pulse: Thermals, Fan Response, & Noise",
    "selftext": "",
    "comments": [
      "source? The Pulse/Pure (same cooler) have done amazingly in Computerbases review.",
      "My source? My eyes lmao. it's the same  exact card, just in white and with rgb.\n\nhttps://pics.computerbase.de/1/1/6/3/1/4-32a9535ba2093fb6/4-1080.e4838cfd.jpg\n\nhttps://pics.computerbase.de/1/1/6/3/1/4-32a9535ba2093fb6/2-1080.cef8c64a.jpg",
      "what is that supposed to tell me? There's no comparison of any kind here?",
      "> See the full video and do your assignment. \n\nLooking at the teardown in the video, it fits perfectly.\n\n>There are other sources in which Reaper runs 10C cooler.\n\nYou do know that you can't compare temperature results between completely different reviews with different environments, right? Do you have a source that compares the Reaper and Pulse in the same environment?",
      "> But its jot common in different sources all come to the same conclusion that Pulse is running hotter than other gpus under normal/stock defaults.\n\nwhich sources? can you link the sources, showing that the Pulse is running hotter than the Reaper?",
      "Wrong. I've personally had both at the same time, the reaper is louder and runs hotter. Both cards keep extremely low average temperatures, but the 9070 xt in general has quite high hotspot/memory temps. The pulse is slightly better at cooling the hotspot and memory than the reaper.",
      "I don't think it's anything more than a very minor aesthetic issue either way.",
      "One thing to note, as I said earlier average temps are negligible in difference, as both are more than adequately low. The main difference between the two is hotspot and memory temps where the pulse slightly outperforms.  \nMemory on pulse maxes at 84c on stock settings and reaper at 92c. Hotspot hovers around 80c at max load on the pulse (don't have hotspot max for my reaper and I no longer own the card). At idle the reaper averaged around 40c with 52c hotspot with the pulse averaging around 34c and 40c hotspot in my rig (ncase T1 v2.5).  \nI did turn off zero RPM mode on both cards, as in my case it would simply choke out the cards at idle due to the constraints of the case I built in.  \n  \nEDIT: I'd like to note one more thing, these numbers are solely from gaming and gaming benchmarks, max temperatures in synthetic benchmarks are likely higher.",
      "Is that uh, heatsink sag not as big of an issue when the card is in a normal, horizontal position?",
      "They‚Äôre the same card‚Ä¶",
      "Hey OP ‚Äî Your post has been removed for not being in compliance with Rule 8. \n\nBe civil and follow Reddit's sitewide rules, this means no insults, personal attacks, slurs, brigading or any other rude or condescending behaviour towards other users.\n\nPlease read the [rules](https://www.reddit.com/r/Amd/about/rules/) or message the mods for any further clarification.",
      "Thats more clear and good to know.",
      "Post your results. Have you guys seen videos from UK?  Most are saying Pulse runs hotter. Upload your tests",
      "I know that perfectly. But its not common in different sources all come to the same conclusion that Pulse is running hotter than other gpus under normal/stock defaults.",
      "Its not the same card! See the full  video and do your assignment. You asked for source. Thats the source. There are other sources in which Reaper runs 10C cooler. Find it!!!  A 3d render image all the same but different shroud doesnt means are the same card. Components and desingn may be different. A simple picture its not evidence. Evidence is by real tests. I work from a high end manufacturing servers. I know what in saying.",
      "Share the source please. Pure has better cooling system than Pulse afaik.",
      "https://www.youtube.com/watch?v=_OGfWRTJ7w8",
      "And I sold my 9070XT Reaper to get 9070XT Pulse two days ago. Im totally regret it!  Apparently Reaper runs 10C cooler and its slimmer and looks very nice."
    ]
  },
  {
    "brand": "amd",
    "generation": "9000",
    "tier": "mid",
    "matched_keywords": [
      "rx 9070 xt",
      "9070 xt",
      "9070",
      "rx 9070"
    ],
    "title": "Tearing Down Sapphire's RX 9070 XT Pulse: Thermals, Fan Response, & Noise",
    "selftext": "",
    "comments": [
      "Yeah maybe in 2005. Any competent partner engineers the products cooler so that it is completely transparent to the user. No one should be having to modify fan profiles beyond quiet/performance bios toggles.",
      "great card but bad fan behaviour",
      "That's more of a Creation Engine issue than a card issue. Creation engine games have physics tied to your fps so if you go over 60 things get a bit messy",
      "I have the 7900xtx, just tweak the fan curve. It was the only AIB model I tried that didn't have obnoxious coil whine.",
      "Not true with the 9070 xt. I've had the opportunity to tune both a powercolor reaper and sapphire pulse, both can have zero fan toggled on with a custom fan curve (in adrenaline)",
      "Yeah lol, like basically every other video posted here has insane coil whine, I'd literally go insane with that sound constantly piercing my head. Fan curve takes 5 minutes to tweak and you forget about it for years. Yes it's an oversight from AIB, but it's far from the worst.",
      "Gotta love that Bethesda jank",
      "Because it takes like 2 seconds to create a custom fan curve and it's something that everyone should do anyway for every fan inside a pc.\n\nLike the most MOBO sets the case Fans at like 450% speed at idle. Which is insanely loud for a 140mm fan, even a noctua/be quiet. \n\n\n.",
      "Every Sapphire card has horrific fan behavior. Still can't wrap my head around the praise their cards get.",
      "even with the high fps fix mod?",
      "I concur. My first GPU ever was 5700xt pulse. To put it bluntly, fucking jet engine, at that point give me a blower design. I don't care nowadays, I use a console like case and de shroud my GPUs, 7800xt was quieter than the 5700xt but I give a damn, 3000rpm are still acoustics of such rpm, my fans didn't improve the thermals BUT even at 100% they move only a Max of 2000rpm waaaay quieter.",
      "That is exactly what I used and capped the fps at my monitor's max frequency in the .ini file, great results, thanks !",
      "It's not true for the 7000 series either and i can't be sure about the 6000, but i don't see why they wouldn't be able to use zero fan with a cutom curve...",
      "I was wondering how could FO76 possibly brick a PC or a console at its release, but I kinda get it now.",
      "Before the user Eric's suggestion, yeah, \"messy\" is how I would put it, it led to complete pc freeze then to a driver crash. Windows didn't BSOD but it wasn't pleasant to run into such issues with a brand new card.\n\nEspecially since now I have that .. I can run RDR2, Space Marine 2, etc. in full ultra settings without a single problem.",
      "So are you guys running the default fan curves of your mobo/cooler too? That's insane to me, they are always terrible.\n\nI aggree that a product should be better fine tuned out of the box, but I've never seen a product with a good stock fan curve.",
      "All of MSI's GPU's have nice fan curves. They are probably the least intrusive in terms of behavior (no start up rattle, low starting RPM, no aggressive changes, etc).",
      "You should be running a custom fan curve tailored to your PC's specific acoustic and performance needs.\n\nThe stock one just is there to get you started",
      "the problem customizing the curve is that you loose the zero fan feature that's annoying",
      "My biggest problem with this card is that Fallout 4 becomes quite unstable at 330 fps."
    ]
  },
  {
    "brand": "amd",
    "generation": "9000",
    "tier": "mid",
    "matched_keywords": [
      "rx 9070 xt",
      "9070 xt",
      "9070",
      "rx 9070"
    ],
    "title": "Final specifications of AMD Radeon RX 9070 XT and RX 9070 GPUs leaked",
    "selftext": "",
    "comments": [
      "I am looking for a AMD gpu that is as or less power hungry than the 7800xt - the RX 9070 looks very promising.",
      "The price is way higher than a 7800 XT though according to recent News: \"MicroCenter lists Radeon RX 9070 series: RX 9070 XT starting at $699, RX 9070 at $649\"  \n[https://videocardz.com/newz/microcenter-lists-radeon-rx-9070-series-rx-9070-xt-starting-at-699-rx-9070-at-649](https://videocardz.com/newz/microcenter-lists-radeon-rx-9070-series-rx-9070-xt-starting-at-699-rx-9070-at-649)\n\nThe increase from 499 USD MSRP for the 7800 XT to 699 USD MSRP for its successor the 9070 XT is quite heavy to say the least. And i actually wonder why the drastic price change? The 7800 XT got a total die size of 346mm2. This is just slightly smaller than the 9070 XT's die size of 357 mm2. \n\nThis smells like AMD trying to play in the same profit ballpark as Nvidia at the expense of PC gamers once again. When will this insanity stop? It is like a ongoing nightmare from covid, over crypt to now AI.",
      "I doubt these prices are accurate, doesnt make sense for 9070 to be only 50 dollar cheaper when it should be about 20% slower.",
      "Welcome back, Vega 64",
      "A lot of price points of rdna 3 didn't make sense either but look what happened. 7900 xt at 900 and 7700 xt at 450 and both were doa.",
      "The same then applies to choosing the 9070 XT over the $50 more expensive 5070 Ti at $749.\n\nWith AMD trying to upsell prospective 9070 buyers to a 9070 XT, they've subsequently upsold those prospective buyers to NVIDIA's 5070 Ti, lol.\n\nHopefully these numbers are bs placeholders and not a legitimate leak.",
      "With the leaked price of them being a $50 msrp difference(if true), why on earth would anyone choose the 9070 over the 9070 xt?",
      "AMD knows they made a mistake with these, as confirmed by recent public interviews from CES. If they do this again then WTF.",
      "That's normal. The 5070ti has the same as the 5080. They still count the defective/lasered off transistors.",
      "Check his profile he bought a 5080, he‚Äôs trying to cope with his $1500.00 purchase.",
      "And short lived just like Vega, until next year when udna comes",
      "The Radeon branch doesn't seem to learn though so would that truly be shocking? They've made the same mistakes multiple times in the past.\n\nThe only thing that would truly be shocking out of this hardware cycle is if AMD made no unforced errors or major mistakes.",
      "The \"nvidia-50\" amd special followed by marketshare loss and heavy discount in the following 12 months. If these are real they are idiots.",
      "It really does have Vega 56 / 64 vibes this launch\n\nThe two units even have 56 / 64 compute units and 56 / 64 ray accelerators",
      "These are obviously at least a little wrong, they have the same transistor count but different CU counts.",
      "At $649 it's DOA",
      "I stand corrected. I was pretty sure of myself for some reason.",
      "RX 9070XT = 304W vs RX 9070 = 220W\n\nVega 64 = 295W vs Vega 56 = 210W\n\nCUs and cores identical between architectures\n\nSame VRAM for both SKUs within each family.",
      "That makes the same mistake AMD has made repeatedly. You only get one public launch, and people generally only review stuff once. Even if stuff gets re-reviewed customers do not generally look for those. \n\nLook at how RDNA2 and RDNA3 price cut over time, did it help their reputation any? Not one bit outside of niche subreddits and the mindfactory/microcenter customer bases. \n\nA bad launch review clings to a product. It also makes the assumption that Nvidia won't have stock of lower SKUs to dump into channels just to embarrass AMD. Nvidia has turned around numerous times and out-maneuvered AMD when they thought they were being clever. \n\nAMD needs to nail the launch, not play the same bullshit games they've been playing for a decade now.",
      "5070ti is not 750.  Even when it's in stock the \"base\" models are 900.  The 750 models don't actually exist.\n\n  \nCurrent MSRPs are a joke.\n\n  \nI'm fairly sure, in the current market where the local Microcenter has literally 0 gaming gpus over 400 dollars on the shelves, the 9070 xt at 700 bucks, on shelves, will sell out.  Instantly."
    ]
  },
  {
    "brand": "amd",
    "generation": "9000",
    "tier": "mid",
    "matched_keywords": [
      "rx 9070 xt",
      "9070 xt",
      "9070",
      "rx 9070"
    ],
    "title": "AMD Radeon RX 9070 XT confirmed as 304W card, RX 9070 non-XT is 220W",
    "selftext": "",
    "comments": [
      "Seems pretty reasonable. I bet you can get some serious undervolts on the XT.",
      "You can't compare the process size just based on the power efficiency. The XTX has a 529mm2 die size while the 9070XT has a 390mm2. The XTX has a 6144 shading unit the 9070XT has a 4096 (33% less). If they have similiar performance this is actually a really decent uplift and not just a nvidia +10%.",
      "Definitely enough, I had my 6950XT running on a 750w psu before, with 7800X3D.",
      "If they increased efficiency only 15% going from chiplet 5+6nm RDNA3 to mono 4nm RDNA4, then reference 307W 9070XT means reference 7900 XTX perf out of the box.\n\nAs we can see with Blackwell, if you don't increase efficiency then your only option for more performance is more power.",
      "I just wonder if my 850wat power supply will still be good for this I have a 9800x3D already üôÇ",
      "If the XT card is actually good, then as a 6800xt owner, colour me intrigued.",
      "I'm still of the opinion that it'll be closer to a 7900 XT than an XTX. Still positively impressive considering a gigantic decrease in die size and CUs. Should be massively cheaper for them to make so they can sell it for better margins OR at lower prices.",
      "I ran a 4090 on a 750W power supply for 2 years without ever tripping OCP. Quality of the PSU matters though.",
      "I don't get people that think it'll be close to an xtx.\n\nWhen the hell did they say that? In the *official* information they even expressly said it won't be competing with the 4080, 4090 or xtx.",
      "Fuck nvidia. Also I use Linux.",
      "Isn't the 6800xt still a great GPU for 1440p gaming? I'm sure you're getting way over 60fps in most games on a 1440p monitor, yes?",
      "If 9070XT is about 7900GRE powerful at the same watt and costs 700 dollars, why would people buy it? There is no reason imo, unless the FSR4 is something magical.",
      "Ive been running a 3080 on an EVGA 650 for several years myself. No issues here!",
      "I‚Äôm assuming it will beat the XTX in ray tracing and be less performant in raw raster, so it depends on the game and settings.  We‚Äôll know soon enough.",
      "People like setting expectations so high that AMD fails (in their mind) no matter what they deliver, that way they have pre-excused their Nvidia purchase.",
      "Some of the AIB partner cards have three 8-pin power connectors. I guess the AIBs plan to be at a higher power than the reference model?",
      "Top tier PSU. You're ok.",
      "Anything less than the performance of a 5090 and priced more than a 4060 is a total failure! ^^/s",
      "304  is too much for me\n\nmore interesting th 9070 220w but the jump from my 230w RX6800 won't be that huge maybe 1.5x\n\nI mean, i paid 580$ 5 years ago for that",
      "6900XT was the same. 300W card with most AIB's having 3 8-pins"
    ]
  },
  {
    "brand": "amd",
    "generation": "9000",
    "tier": "mid",
    "matched_keywords": [
      "rx 9070 xt",
      "9070 xt",
      "9070",
      "rx 9070"
    ],
    "title": "1080TI to RX 9070 XT?",
    "selftext": "I haven't paid much attention to GPUs in a while. Previously had been team green, but really not liking the 5000 series. \n\nThoughts on this upgrade for 1440p gaming? Essentially looking for a small to moderate performance bump and RT capability. \n\nEdit: Thanks for the insights, all. It seems like the 9070 is expected to bring me a major bump in performance. I had read a few things recently that suggested the 1080TI was still relatively in the same league with the 4070 in terms of 1440p performance without RT, so I'm happy to hear the boost should be more than I was expecting. \n\nI'm hoping my old OC'd i7-7700K won't bottleneck it too much. I'll be upgrading to something with more than 8 threads in the future. ",
    "comments": [
      "If you're going from 1080ti to 9070 XT you can easily expect a 200% performance increase in every aspect.",
      "9070XT",
      "The upgrade from a 1080 to 50 series nividia or 90 series amd will be huge.",
      "I went from 1080 to 7800XT, the performance bump is insane in 1440p. Go for it.",
      "Use both in same time and make fusion",
      "I went from 1660super to a 3080ti.\nI avoided 40 series for the firetrap connector and the 50 series is just... Awful.\n\nI was hoping therr would be a higher end battlemage that was going to come out later this year but seeing that the 9070xt charted against thr 3090 directly I'll go to that for sure.\n\n#Team8Pin",
      "2-3% gain at most :/\n\nJk. That shits gonna level up.your system like a mofo\n\nThat legendary 1080ti still can do a nice job but for a little bit older games and lower rez",
      "Unless the bottleneck from the CPU",
      "It's still doing good on some new games. I'm playing Kingdom come deliverance 2 at 1440p at 90-120 fps on medium settings with the 1080ti. But still I also want to upgrade for other more demanding games.",
      "from AMD slides, they show it is about 90% of that of a 5070 ti in 4k ray tracing performance and about the same in native 4k",
      "Mandatory is a stretch and a half, plenty of people out there couldn't care less about RT and would prefer greater fps",
      "It will be more than a small bump, but I don't know about RT.",
      "Any upgrade from an older card like that will be massive. \n\nMight find yourself CPU bound tho. \n\nI‚Äôd wait for independent benchmark tests on the new AMD cards before making a decision",
      "Look the 1080 TI was a great card it was for many years you could keep using it that time has passed. \nI'm sure you can still ring some performance out of it but at that point you are using an extremely dated piece of technology and there's going to be a lot of things that it struggles with.",
      "The jump in performance will be night and day but it might end up CPU bound",
      "I did a bit of upgrading recently.\n\nA 3080 was double a 1080\nA 5080 was tripple to quadruple a 1080.",
      "You‚Äôre going to be blown away. Absolutely worth it coming from a 1080TI.",
      "You are gonna have your mind blown",
      "If you're looking for a small to moderate performance bump, you might be barking up the wrong tree. I upgraded from a 1080ti to a 7800XT, which is most likely significantly slower than a 9070XT, and the jump in performance was absolutely massive.",
      "That‚Äôs goin to be a great jump in performance."
    ]
  },
  {
    "brand": "amd",
    "generation": "9000",
    "tier": "mid",
    "matched_keywords": [
      "rx 9070 xt",
      "9070 xt",
      "9070",
      "rx 9070"
    ],
    "title": "MicroCenter lists Radeon RX 9070 series: RX 9070 XT starting at $699, RX 9070 at $649 - VideoCardz.com",
    "selftext": "",
    "comments": [
      "Looks like nvidia -$50 lives on for another 2 years.",
      "lock lush afterthought profit safe childlike sugar attractive money plant\n\n *This post was mass deleted and anonymized with [Redact](https://redact.dev/home)*",
      "Amd is being a dumbass lesssgoooo",
      "\"Most gamers pay under $700\" well 699 is under $700 so nvidia -50 unfortunately",
      "Atleast it's not $700",
      "Can‚Äôt wait for these to be $500 in 4 months",
      "The amount of people simping for high prices playing the mental gymnastics is hilarious.",
      "I've noticed this the last few days, it's been exceedingly slow.",
      "This has to be fake why would anyone buy a 9070 when you can get a 9070XT for $50 more?",
      "Congratulations to all of you that begged AMD to raise the price of their 70XT tier from $349 the last two generations to a street price of $900 this generation. lol Hopefully that means we'll stop seeing people complaining about prices.",
      "Same thing as RX 7700 XT vs 7800 XT. It wasn't until the 7700 XT was heavily discounted that it was sort of worth a look in.",
      "I don‚Äôt care about Nvidia‚Äôs artificial scarcity and both vendors‚Äô gouging on the 80 class, and I don‚Äôt care about hype cycles. The only thing that matters is whether this midrange product is 30% better per dollar than last generation‚Äôs best midrange product - say, a $499 RX 7800 XT. Everything else is just noise.",
      "Can't wait for GN to tear it to shreds",
      "Nope. They rejected my post within an hour.",
      "I‚Äôve seen so effing many people spawn into existence that weren‚Äôt here over the last 3 months demanding they price it at 700 and call anyone saying 600 or less a clown. It‚Äôs like amd hired a pr team to damage control perception or this is all some kind of coping mechanism",
      "Oh that's way scummier.",
      "UGHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHH",
      "So that is why the subreddit feels extremely dead? Like literally one topic posted each day other than news. They just don't approve majority of the topics?",
      "Amd will have a nonexistent reference card ans one model that is 699.",
      "remember 60cu 7800xt is 499msrp\n64cu 699 XD\nLets go nvidia -50 ."
    ]
  },
  {
    "brand": "amd",
    "generation": "9000",
    "tier": "mid",
    "matched_keywords": [
      "rx 9070 xt",
      "9070 xt",
      "9070",
      "rx 9070"
    ],
    "title": "Navi 48 with OC & UV review: Overclocking & Undervolting on the Radeon RX 9070 XT",
    "selftext": "",
    "comments": [
      "I did a -10% on power delivery, 2614 on memory and -65mv offset and my xfx swift boosts to 3k-mhz with 273watt power draw and I'm quite happy with the results, with power draw +10% the watts go to 334 and fps gains are under 5 fps totally not worth it imo.",
      "FYI: \"kmhz\" (Kilo Mega Hertz) is GHz",
      "The other way to look at it is the manufacturing process is consistent enough to drive every chip close to the limit without yield issues.",
      "'I'll pay you ten thousand pennies to fuck off.'",
      "\\#1 on steel nomad  dx12\n\n-120mv core / 2816mhz gddr / +10 power\n\nhttps://www.3dmark.com/sn/4451970",
      "It means that AMD is pretty much maxing out the GPU on their behalf. There's only small margins left for us. OC'ing is dead.",
      "Pretty obvious from the boost clocks that they juiced the XT so it can compete with 5070Ti. Honestly it was good call IMO. Better out of the box performance for a bit more power and less OC headroom, which 99% of end users won't care about anyway.",
      "How low can voltage go? \n\nI ran my 6600XT at 670mV/1800Mhz and got incredible efficiency. I'm curious how this generation does.",
      "1st, Sapphire Pulse:\n\n-75mV, -20% power limit = 240W power draw and boost around 3050mhz. I tried increasing vram clock but it would only give a few FPS in games and was not worth it imo.\n\nI returned the Pulse as i got an ASUS Prime OC.\n\n2nd, Asus Prime OC:\n\n-75mV, -20% power limit = 250W power draw and boost between 3000-3200mhz. Did not even bother with vram on this one.\n\nBoth cards would boost even over 3.300mhz with +10% power limit but the increase in performance/power drawn is not even worth considering, yea seeing 3.300mhz is cool and all but we're talking ~5FPS.\n\n\nThe temps are around the same, the Asus vram temp runs a bit higher (82-84¬∞C) than the Pure (80-82¬∞C). Hotspot both were around 75¬∞C and ambient 55¬∞C.",
      "I unfortunately had to return mine to MC, was hoping driver update would fix crashing but looks like I got unlucky this time. I‚Äôll keep checking for restocks, manager even let me know that they‚Äôll personally message me even they get stock.",
      "Why return the sapphire pulse?",
      "Other than slight tweaking, the cards are maxed out for... Over 10 years now I guess. Boost algorithms are really good nowadays. You basically get what you pay for.\n\nI still still think that undervolting is king. If you get 5% more performance in the same power package or same performance at 15% less power consumption - that's really nice.",
      "Asrock 9070XT Steel Legend:\n\nUndervolting stability varies from game to game.\n\nGoing -75mV or more, some games run fine, but Cyberpunk Pathtracing crashed and AC Shadows introduces some really bad frame time spikes.\n\n -50mV seems to be the sweet spot for me. +10% power limit, the cards hits 3300mHz and runs at ~330W, ~65¬∞C and 30% fan speed. The card is super quiet.\n\nThe card actually beats my old 7900XTX in all 3D Mark Benchmarks I've tested. AC Shadows and MHW performance is pretty much identical.",
      "85-95 for the memory temps, a bit toasty, but nothing I worry about. The default fan curve with 30% is quite conservative, I might make my own to bring temps down a bit.",
      "I undervolt my pulse 9070XT to about -100mV (any lower, it start crashing) and it draw about 260W. If it push max power to +10%, it draw about 335 at 3250MHz.",
      "You are number 1 for 9070 xt + 7950x3d.  [This is the current #1 9070 XT](https://www.3dmark.com/sn/4518708)",
      "![gif](giphy|c2C2RyuXSizTO)",
      "I got the Asus at the same price, it matches my pc better and it's smaller in case i wanna swap cases in the future.",
      "Nvidia seems to have decent OC headroom on 50 series cards. [HUB tested the MSI Vanguard 5080](https://www.youtube.com/watch?v=D_sVNuOg74c&t=605s) and with some OC on top it's pushing really close to 4090 performance.",
      "Not surprised that it varies game to game. Mine varies setting to setting. In cyberpunk even a -10mV undervolt crashes my card at ultra RT if i enable XeSS. But now that FSR4 is working with optiscaler, it is seemingly stable at -60mV...\n\nOf course that is whishfull thinking as I know it isnt stable due to it crashing with XeSS, so i think I just got a dud as far as undervolting goes."
    ]
  },
  {
    "brand": "amd",
    "generation": "9000",
    "tier": "mid",
    "matched_keywords": [
      "9070 xt",
      "9070",
      "rx 9070"
    ],
    "title": "AMD Radeon RX 9070 / 9070 XT review: Nvidia gets some big next-gen competition",
    "selftext": "We're so happy, that we didn't upgrade our setups yet.\n\nMy wife and I will get 2x 9070xt for almost the price of 1 single 5070ti in our country.\n\nFirst time team Red for us since 2006, we're almost as excited as were back then as lil kids getting our new PC.",
    "comments": [
      "oh no! a 599 USD card is not faster than the 1500 USD last gen card!",
      "Now they just need to reduce the non XT price by $30-50 and add another more cut down variant like GRE for $400 and that's it.",
      "üßÇüßÇüßÇ salty üßÇüßÇüßÇ",
      "There was no paywall upon me posting this.",
      "Damn! Which country?",
      "Omg you're so cool.\n\nEdit: yikes, triggered much?",
      "I feel cautiously optimistic and a bit disappointed. Price for price **Right Now** the 9070Xt is a no brainer and it's amazing, but at MSRP the value proposition falls a bit when the 5070ti is only 150$ more expensive yet has 20% better RT perf and better software.\n\nOne thing is for sure the 5070 is dead, specially at today's prices",
      "With Nvidia is reported to have 90% of the discrete GPU market share, add in this apologist take towards Nvidia will do us PC gamers no good if the capitalism-backed \"competition is good\" ethos is no longer with us. \n\nActions such as rescinding support for 32-bit PhysX bears no consequences from the community for Nvidia, and i believe that's a dangerous precedent to set given it's not exactly an old technology. Further more, they have the capability to open-source it for the community to modify it. \n\nEither way, this highly competitive GPU from AMD if sold and found at MSRP will be one of many stings that would finally make Jensen Huang care about gamers again. Don't forget this 5000 series uses the same TSMC 4nm lithography as the 4000 series from two years ago, all gains are superficial and scales linearly with transistor count, cuda cores, and power consumptions, etc.",
      "why even link the paywall content?",
      "Might also be Windows acting up. I encountered several BOSD after the Jan update, but for some reason they are gone now.",
      "Your comment has been removed, likely because it contains trollish, antagonistic, rude or uncivil language, such as insults, racist or other derogatory remarks.\n\n*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/Amd) if you have any questions or concerns.*",
      "Good Times.  I went 5700xt to 7800xt.  Same Watts, more frames, less heat. Invictus!?",
      "last-gen\\*",
      "The author didn't notice much of a difference between FSR 3/4 in Horizon?\n\nHe should try pressing a direction on the controller",
      "Better software? You haven't seen my 3080 after the latest drivers. Before i never got blue/black screen or games crashing now it's everyday.",
      "You're not finding a 5070ti at msrp",
      "Not right now, but Nvidia controls their partners. If the 9070xt starts to hit their sales they can just force the MSRP to make it more competitive\n\n\nActually checking prices now the 9070xt is never going to be at MSRP either after a few weeks. Unless amd has a better plan",
      "No one really cares about fake frames, if thry removed that shit and put in more power instead I'll be happier.",
      "I guess the thousands of people using LossLess Scaling don't exist? MFG, which is better, is great for single player games specially if you don't care about latency, which is most people. Don't comment on something you haven't even used ü§∑‚Äç‚ôÇÔ∏è",
      "Ok mostly. Dlss4 and MFG are genuinely great, and reflex 2 looks promising. FSR has been behind dlss for a while now and FSR4 isn't looking to be better than nvidias transformer model"
    ]
  },
  {
    "brand": "amd",
    "generation": "9000",
    "tier": "mid",
    "matched_keywords": [
      "rx 9070 xt",
      "9070 xt",
      "9070",
      "rx 9070"
    ],
    "title": "Radeon RX 9070 XT vs. GeForce RTX 5070 Ti, 55 Game Benchmark  / Hardware Unboxed",
    "selftext": "",
    "comments": [
      "I watched it this morning before work. Short version is at  both MSRP and average real world prices AMD is offering a better value and in some cases similar performance. Even in many RT titles it holds up pretty well. One disadvantage is how limited FSR4 support is right now. \n\nBut which one makes more sense really depends on what you can actually find in stock. A lower priced 5070 Ti may make more sense than a higher priced 9070 XT. \n\nEither way AMD is actually competitive this gen. Which is good to see.",
      "As I said elsewhere, AMD should be updating games with older versions of FSR (FSR 2+) to FSR 4, and Optiscaler has already shown that it is possible.\n\nAMD should first work with game developers to update games with FSR 4, but as a last resort, AMD should upgrade games to FSR 4 if the game developers have no intention to do so.",
      "the 70 series tier isn't low end.",
      "Only in raster. This gen they've upped their game on raytracing and upscaling which was the biggest advantage Nvidia had. Nvidia is still ahead but nowhere near as much.",
      "> Competitive is a strong word when its still slower than a 5070 ti and nowhere near competing against a 5080 or 5090.\n\nwtf? Performance isn't the only way it can be competitive.",
      "AMD was competitive last gen too? XTX forced them to come out with a 4080 Super because it spanked the 4080 while being much cheaper",
      "Sure, that‚Äôs true for any card receiving driver updates.",
      "A $600 card is not low-end, you got to get off that Nvidia crack-pipe.\n\n\nA $2,000+ GPU is absolutely ridiculous.¬† A $1,000+ GPU is still ridiculous.\n\n\nIn 1440p, a 9070XT is within spitting distance of a 5080.¬† At 1440p...17% slower in Black Myth: Wukong, 5% slower in Starfield, 15% slower in Dragon's Dogma 2?",
      "Pretty sure you can forget about it, even Optiscaler itself doesn‚Äôt work for all FSR2/3 games. The main issue are the custom interfaces that stopped being a thing with FSR 3.1. Not to mention the QA they would need to verify it all working properly. \n\nIMO AMD should spend more time on helping devs integrate or update to FSR 3.1, so they can do the driver-sided FSR4 upgrade before the SDK releases in 2H 2025 and devs can hopefully start implementing FSR4 itself.",
      "Price sure isn't, that's for damn sure",
      "There's nothing low end about the 9070XT",
      "5090 is halo tier and 5080 is high. Have we really allowed marketing to skew our expectations this much? Back when I bought my 2070S the hot debate was whether or not it was mid or high tier. Now you ¬†want me to believe it was actually low tier all along?",
      "Raster is probably 90%+ of the market. But , yes, ‚Äúonly‚Äù in raster.",
      "Sorry but outside of reddit people care a lot about upscaling, AMD's big steps on improving FSR via FSR4 and their improvements to RT is a big selling point. There's a reason why NVIDIA outsold the 7000series by an absolute metric ton.",
      "If i understand correctly, playstation upscaler PSSR will be fsr4 in the future(I think Mark Cerny said something like that). Which will hopefully get more developers use fsr 4 for cross platform games, so automatically they will be more widespread on PC.",
      "A chance, sure. But that'll go for any of the GPU vendors. Last generation, Nvidia actually got more of a performance boost from drivers over time, the RTX 4080 went from being slightly behind the 7900 XTX at launch of the XTX to being slightly ahead now.",
      "Virtually all new AAA titles have raytracing. You cannot claim you are running \"everything on ultra\" if you have raytracing off.",
      "More mid tier, they just aren't competing on the high end. And personally I think that seems like the right choice. People spending that kind of money don't want to make compromises. \n\nUntil AMD can actually match or beat Nvidia in features and raytracing they're better off focusing on the low-mid tier cards.",
      "Would be cool if the thing wasn't ‚Ç¨900 minimum over here",
      "As a 7900xtx owner no one was buying one over a 4080 super that was either the same price or an extra 100 bucks. It's only in the last month the sentiment has changed."
    ]
  },
  {
    "brand": "amd",
    "generation": "9000",
    "tier": "mid",
    "matched_keywords": [
      "9070 xt",
      "9070",
      "rx 9070"
    ],
    "title": "Overclockers UK sold around 5,000 units of the Radeon RX 9070/9070 XT on launch day",
    "selftext": ">We do have several deliveries due today and next week, so we might have more available later.\n\n>We have sold around 5000 units now, warehouse is working very hard to get them all shipped out today. :)\n\nSource: https://forums.overclockers.co.uk/threads/ocuk-guide-to-ordering-your-amd-9070-graphics-card-today-at-14-00.18999857/page-96#post-37697274",
    "comments": [
      "You can't say it's a paper launch with 5k units sold.\n\nThat's one store in the UK.\n\nI'll just wait a couple of months and decide what to do.",
      "For anyone wondering about restocking at OCUK\n\n>We have 400 due Monday/Tuesday this should cover all the back orders. We are expecting another 500-1000 within next couple of weeks. :)\n\nhttps://forums.overclockers.co.uk/threads/ocuk-guide-to-ordering-your-amd-9070-graphics-card-today-at-14-00.18999857/page-95#post-37697218\n\nEDIT: That's for the Nitro+ model only.",
      "Interestingly, Overclockers UK has a private area where it sold the Radeon RX 9070/9070 XT to longtime forum members thereby potentially avoiding scalpers.",
      "This is the biggest launch for OCUK since the launch of the GeForce RTX 3080\n\nhttps://forums.overclockers.co.uk/threads/ocuk-guide-to-ordering-your-amd-9070-graphics-card-today-at-14-00.18999857/page-97#post-37697311",
      "They sold the launch models, and then increased the price by 50-100 pounds üôÑ",
      "To be clear with the above, that's the Nitro XT model (sold out now).",
      "Amazon had a lot of stock. It was just chaotic and hard to find. Hellhound and red devil was still available 40mins after launch. I got mine from amazon after newegg cancelled my order.\n\nActually just checked. I order 7:11am pst on Amazon. It was still in stock for at least 20mins after I ordered too.",
      "They didn't sell any exclusively to forum users, the only thing that happened was they announced drops a few mins beforehand, but it was relatively useless anyway since the bots were buying up everything instantly as soon as the pages refreshed.",
      "Don‚Äôt know how they managed to sell a single one considering all you got was a 503 error when trying to load the site.",
      "Admittedly I overpaid for my 9070 XT TUF, but this is very good news. We absolutely need better competition in the low-mid-high end.\n\nIf things work out well, they might soon be back to undercutting each other. That would be glorious.",
      "I have an account from 2007 with 1000+ posts on the OCUK forums, I can access all parts of the forum. There is no private area where these cards were offered to forum members directly.\n\nYou can see in the main threads that people did ask for them but were declined by Gibbo. OCUK has only ever offered exclusive deals later on after GPUs launch.",
      "It's easy to locate the cards if you use the AMD landing page on Amazon\n\nhttps://www.amazon.com/stores/page/82752559-325B-4E7C-A917-5EA1396602E2",
      "1.04 safety factor is absolute insanity.",
      "It's a little safer when you have a 1.8x safety margin (Nitro 9070 XT, 330W) instead of a 1.04x one (RTX 5090, 575W)",
      "Good old OCUK (Caseking)!",
      "Thank you! Holy shit is Amazon's search so bad, trying to find the cards by searching was impossible half of the time. This is so much better.",
      "With 28 Microcenter and an average of 500-600 per store \n\nThey sold atleast 15000 9070XTs",
      "The fact that some Spanish retailers have restocked non-XT MSRP models (Sapphire Pulse and Powercolor Reaper) for 700‚Ç¨, so around 60‚Ç¨ above the promo price and they're holding and not sold out yet means people are sending the correct message. Let's hope AMD hears.",
      "There were about 900 cards at the Dallas microcenter alone, there are 28 microcenters nationwide.",
      "They didn't sell to real people, their traffic mismanagement favored bots because of the sheer amount of attempts they put through in comparison to human input. I doubt more than 10% of those sales went to real people who will put genuine use in to the product."
    ]
  },
  {
    "brand": "amd",
    "generation": "9000",
    "tier": "mid",
    "matched_keywords": [
      "rx 9070 xt",
      "9070 xt",
      "9070",
      "rx 9070"
    ],
    "title": "AMD's unreleased Radeon RX 9070 XT \"reference\" design shows up in China",
    "selftext": "",
    "comments": [
      "AMD reference designs always look beautiful",
      "I have the 6800 XT ref and she's a beauty.\n\nRadeon VII was absolutely beautiful as well.\n\n![gif](giphy|1Zp10Q8RS3WDIZDaPn)",
      "imo they peaked with the Radeon VII and runner up as the 6800xt reference. Sublime cards. VII probably the best looking gpu of all time imo",
      "If they actually released a reference design, they would've had a better handle on pricing. Now the 50 series is starting to rise in Amazon sales rankings and their pricing PR isn't much better.",
      "There was always 100% going to be a reference model made. You could see it in the 9070 xt slide in ces. They intentionally didn't release it at the same time as the other models so less supply of msrp cards, which is kind of sad but perfectly logical from a business standpoint.",
      "I have the midnight black 6800XT. Gorgeous card",
      "Radeon VII is without a doubt the most beautiful GPU ever built. Got my vote.",
      "Unfortunately thats the whole reason why they didn't release the reference model. More people buying reference models means less people buying other aib cards. Less money for amd and less money for partners so no reference model.",
      "Don't forget the similar Vega Frontier Edition (16GB) in its lovely anodized blue shroud, as well as the liquid cooled variant (which is far more... gaudy).\n\n[https://www.techpowerup.com/gpu-specs/radeon-vega-frontier-edition.c2958](https://www.techpowerup.com/gpu-specs/radeon-vega-frontier-edition.c2958)\n\n[https://www.techpowerup.com/gpu-specs/radeon-vega-frontier-edition-watercooled.c2982](https://www.techpowerup.com/gpu-specs/radeon-vega-frontier-edition-watercooled.c2982)\n\nHidden Cooler Master bits.\n\n[https://pcper.com/2017/07/the-amd-radeon-vega-frontier-edition-16gb-liquid-cooled-review/](https://pcper.com/2017/07/the-amd-radeon-vega-frontier-edition-16gb-liquid-cooled-review/)",
      "SFF fans rejoice regardless. Now we have 3 choices",
      "5700XT is my favorite. Love that it's dented right out of the factory, loved the dent even more after someone explained that it was functional.",
      "People are buying like 20% over MSRP anyway. So after the reference model sold out, the AIB will sold out then. No difference.",
      "The Radeon VII is such a sleek design, so industrial and professional, it would fit so well in a cheese grater Mac pro, if only we don't have similar case for diy market.",
      "Isn‚Äôt the goat 9070xt for sff the power color reaper?",
      "Censoring serial number in text but not the bar code, lol",
      "I mean ass is beautiful and they look ass so sounds about right",
      "just checked, looks like forgettable generic trash to me lol versus the ViI",
      "Distribution, packaging, manufacturing, retail, RMA/warranty, support, etc,. AMD don't even run their online store, refunds or payment processing, they contract it.\n\nIt's way easier to just ship all the chips directly to someone's door and let them worry about everything else.",
      "I don't know what board partners have against just giving us plain, boxy cards.",
      "The Fury X looked beautiful to me, sadly it was a horrible platform because it had so little vram"
    ]
  },
  {
    "brand": "amd",
    "generation": "9000",
    "tier": "mid",
    "matched_keywords": [
      "rx 9070 xt",
      "9070 xt",
      "9070",
      "rx 9070"
    ],
    "title": "Rx 9070 XT vs Rx 7900 XTX",
    "selftext": "Alright now that everything has been revealed what is everyone opinions on rx 9070 xt, do you think is worth over the rx 7900 xtx ?",
    "comments": [
      "Yes. Unless you use massive mod packs and need the 24bg vram",
      "Better price value if you can find it at msrp. But 7900xtx with 24gb vram is the better card"
    ]
  },
  {
    "brand": "amd",
    "generation": "9000",
    "tier": "mid",
    "matched_keywords": [
      "rx 9070 xt",
      "9070 xt",
      "9070",
      "rx 9070"
    ],
    "title": "Upgrade Path: Old to New",
    "selftext": "Here's my rig: \n\nCPU: Intel Core i7-11700  \nCooler: Be Quiet Shadow Rock Slim 2   \nMOBO: ASUS PRIME Z590-P  \nRAM: 32GB DDR4  \nGPU: MSI GTX 1080 Ti GAMING X  \nPSU: Be Quiet 750W  \nMON: LG Ultragear 32\" 2560x1440 165Hz\n\nThe GPU could use an upgrade. I had issues running Hellblade at 1080p. The vast majority of games play fine. No complaints. \n\nBut my 1080Ti is long in the tooth. I'd like to bump up the res to 1440 with high settings. I've spent some time researching and getting angry at the GPU inflation spiral. I've never splurged on the highest of the high end, but I do have a healthy budget. And I also have a strict low noise requirement. \n\nSo, I'm now looking at:\n\nASUS TUF Gaming GeForce RTX ‚Ñ¢ 5070 Ti 16GB $999  \nASUS TUF Gaming Radeon RX 9070 XT OC 16GB $1193\n\nBoth shine (not on price!) on dB levels. \n\nI will also need to replace my PSU with a Be Quiet 1000W. \n\nMy question: which way do you recommend I go? \nOr is there a third way you'd recommend?",
    "comments": [
      "I just bult a new rig with a 5070ti, can confirm that it will crush games at 1440p. So performance wise 5070ti's perform better in every area over the 9070 xt. 9070xt performs fantastically at 1440p just want to say tho. But 1k is a good price for a 5070ti and 1.1k is terrible price for a 9070xt! All the good and bad hyp about this generation of gpu's come from price  gouging and low supply. 50 series all perform amazingly, and so do the 90 series amd cards. You just gotta find the closest to msrp that you can get!",
      "At that price you could also ask the question of 7900xtx since it outperforms the 9070 xt in aspects",
      "Get the 5070 ti. If you can really snag it for that price.",
      "9070xt doesn't make sense if it isnt cheaper.",
      "I've seen 5070ti's for 900 or less looking at zotac and MSI sites and microcenter.\n\nEven a 5060ti would be a huge upgrade for you, or a used 6800xt.",
      "Zotec 5070ti  is only $824 right now on NewEgg",
      "Fsr 3 is crap and ai upscaling is the future.",
      "Buy a console"
    ]
  },
  {
    "brand": "amd",
    "generation": "9000",
    "tier": "mid",
    "matched_keywords": [
      "rx 9070 xt",
      "9070 xt",
      "9070",
      "rx 9070"
    ],
    "title": "XFX Radeon RX 9070 XT Mercury OC Magnetic Air Review",
    "selftext": "",
    "comments": [
      "Yeah, xfx seems like made a flop this gen. Very expensive and not so competitive vs other ls aibs",
      "Not sure if I'd call it a flop but their factory tuning seems to favor getting the hot spot temp down at the expense of noise",
      "I wonder why this model is so chonky but seems to be one of the louder ones. \n\nI hope with a custom fan curve it gets more manageable\n\nIf anyone has a Mercury card, how do you find it to be?",
      "Xfc merc has vapor chamber. Check jayz2cents for teardown",
      "It is loud, but as i could see the temps are very good, the hot spot around 70C. You can just adjust the fan curve and let the hot spot up to 85C like nitros. On base setting these cards are 36 dba, while nitors around 26.\n\nI am planning to buy this one, when some experience coming from the market. :D",
      "I managed to snag this model on launch day, waiting for it to be delivered. \n\nI hope that it's not too noisy if we allow the temps to go up a bit. I can't imagine why such a thicc card would be that loud",
      "for one of the most expensive aib cards you'd expect no compromises. Cheaper options can deliver on both noise levels and temperatures",
      "I agree with the take, my copium is that maybe XFX just tuned it more aggressively for lower temps because if you look at the comparisons, the hot spot temp is a good 10-15¬∞C lower than other models that run quieter. \n\nSo my thought is that with a custom fan curve it could all be gucci",
      "der8auer posted video today where he is comparing red devil to xfx card.\n\nOriginally I was aiming for XFX until I saw the card design which really put me off. On top of that you've got high price and VRAM temps\n\n[https://www.youtube.com/watch?v=BtQ8jF3I0Zw](https://www.youtube.com/watch?v=BtQ8jF3I0Zw)",
      "Xfx has always had some insane fan curves. The 6950 xt merc i had before, fan curve coupled to hotspot, got instantly loud like a jet engine. With a custom fan curve it stayed cool and quiet though",
      "It's..special. \n\n  \nI don't know if anyone else experiences this but mine has a very weird noise coming through the middle fan (doesn't matter which fan I place in the middle, it's the same noise). Sounds like you're in a car when it's moving and you have the window down. Starts happening at like 40% fan speed.\n\n  \nIt's also got terrible coil whine that gets better with undervolting to -50mV",
      "yes they are and confirmed",
      "I think it will be good, keep me updated. :D i am a temperature fan, so to me it is awesome. 70c hot spot with an oc card.\n\nI had to push the fans to oblivion on my nitro 7800 xt to achieve 78.",
      "I feel you. I'm travelling atm so I'll only get to test it in around 5-6 weeks. Currently I'm scouring the web for some reviewers or other people to talk about the noise levels and if it can be mitigated well enough",
      "How much money for this X070 series? Assuming into X080/90 territory?",
      "Got a pulse but i wonder if I should‚Äôve taken this",
      "Used magnetic fans before‚Ä¶.loud as fuck",
      "OK, this may sound like a stupid question but after plugging in the 3 x 8pin connectors for power, where do you plug the other 4 pin connector that came with the card into the motherboard? I take it that this is to control the RGB on the card. I got the white version, looks really nice and goes with my white Y70 setup. Just can't believe this card came with no wiring digram, just a simplistic card that looks generic, not even for this specific card.",
      "Your comment has been removed, likely because it contains trollish, political, rude or uncivil language, such as insults, racist or other derogatory remarks.\n\n*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/Amd) if you have any questions or concerns.*",
      "I paid 800‚Ç¨ but I've heard reports of the price going up due to rebates ending"
    ]
  },
  {
    "brand": "amd",
    "generation": "9000",
    "tier": "mid",
    "matched_keywords": [
      "9070 xt",
      "9070",
      "rx 9070"
    ],
    "title": "AMD RX 9070 & 9070 XT GPU Prices, Specs, & Release Date",
    "selftext": "",
    "comments": [
      "AMD actually did it.",
      "Happy to have alliteration again with the 9800x3d and 9070 XT.",
      "Tons of people still on 3xxx series cards. They are trying to capture that group.",
      "They missed the opportunity to miss an opportunity",
      "Considering both Linus AND Steve had to tag team on this one, something good had to happen.",
      "That's splendid news for me. Will get a 9070 XT as soon as it's available. Finally leaving greener gra$$ for redder pastures .. uhh ..",
      "I don't understand why AMD was comparing the cards to the 30 series. I could understand comparing them to the 40 series, seeing as there was very little generational uplift, but the 30 series is just weird to me.",
      "You know the market sucks when people view a 600 dollar mid-range card for 600 dollars is \"a steal\". In the current scheme of things it's not bad, specially if stock is there, but I wouldn't call it a steal. Competitive likely, but not a steal.",
      "I'm surprised that they haven't for some ungodly reason switched to roman nume...\n\n\\**Vega VII*\\*: Bonjour!\n\n...nevermind.",
      "The $599 MSRP RX 9070XT is great but the RX 9070 really needed to be in the $499-529 range. It is an obvious upsell that is going to be met with meh reviews which like GN said in their previous video, will stick around way after the price drops.",
      "They certainly have my attention.\nI don't buy GPUs every time. 50 Series just doesn't look appealing at all.",
      "Underrated broken clock correct twice post",
      "9070 has the same MSRP as 5070. The 9070XT on the other hand blows the 5070ti out the water pricing wise. If stock and performance is there, that‚Äôs a solid opportunity not missed.",
      "I could see it mostly being bought up by system integrators where they can obfuscate the price difference to the xt",
      "*9070 XT\n\n9070 will not impress",
      "Same, coming from a 3060ti I'm ready for something new and the 50 series just isn't it (for the price premium it has).",
      "Rx 9070 about to impress a lot of people.",
      "So people constantly nagging regarding pricing and prominent media outlets applying pressure actually worked. Who would have thought? :P\n\nThis is also why it's important to have independent tech press that isn't reliant on mindlessly shilling stuff to make money.",
      "Still weird it's not 9700XT but w/e",
      "Well it's correct. I bought a 1070gtx many years ago for 550‚Ç¨"
    ]
  },
  {
    "brand": "amd",
    "generation": "9000",
    "tier": "mid",
    "matched_keywords": [
      "9070",
      "rx 9070",
      "rx9070"
    ],
    "title": "4070 SUPER vs RX 9070",
    "selftext": "Hello,\n\nI have the option to sell my current 4070S for a decent price. I bought it for very cheap a few months ago. With the money or that sell I can buy a RX9070. Is it worth it?\n\nI have a Ryzen 5 3600 (OC) and 32GB of DDR4 @ 3200MHz. I am using a 1TB M.2 SSD. I am planning to switch to an AM5 CPU soon and DDR5.",
    "comments": [
      "Keep 4070S",
      "The 9070 is 11.11% faster ar 1440p, 16.3% at 4k.\n\nIt depends on how much you can sell the 4070s and buy the 9070 for.\n\nIt is a small upgrade, but if you can sell the 4070s for more, get the 9070 for less, and save money on top of getting a faster gpu, the 9070 is worth it.",
      "just wondering where you get this information from, I went to [technical.city](http://technical.city) (cus userbenchmark sucks) and saw differently, Im looking for better places to get benchmarks tho",
      "Toms hardware gpu Hierarchy is a good overall list. Or use tech powerup reviews",
      "thank you very much!"
    ]
  },
  {
    "brand": "amd",
    "generation": "9000",
    "tier": "mid",
    "matched_keywords": [
      "rx 9070 xt",
      "9070 xt",
      "9070",
      "rx 9070"
    ],
    "title": "RX 9070 XT: Undervolting Is Impressive, but OC Is Completely Broken",
    "selftext": "",
    "comments": [
      "I'm surprised he does not know why this happens. With ECC (error correcting memory), you will hit performance degradation instead of crashes with memory overclocking. That's because the GPU will stall waiting for the correct data while the memory controller keeps retrying until it is able to fetch correctly. Without ECC, it just returns the garbage making the program crash if the corruption hits a sensitive data piece (or until then, you will see visual artifacts). I'm oversimplifying here, but that's the gist.\n\nIt's a great feature that avoids most data corruption, but it does make it much harder to see if your new memory settings are fine during stress tests or not.",
      "I really expected a guy like derbauer to know about memory correction at too high clocks. Kinda disappointing",
      "I'm surprised he was surprised about the memory oc performance degradation. How long has it been since we had mem oc artifacts?",
      "FWIW, a commenter pointed this out to him and he saw it and replied with, I think, \"Makes sense. Thanks.\" So, he knows now, at least.",
      "4k native. Watch the video maybe?",
      "He wasn't trying to match anything. That was just the performance of the card when overclocked.\n\nMaybe watch the video before making assumptions.",
      "Mine takes -155mV and +10% power for a nice 3330 MHz clock, nearly 9% boost. Some one else here got 3400 MHz.\n\nEdit: Crashes in some games, had to back off to -70mV for stability.\n\nVRAM clock could take a boost to 2760MHz easily though!",
      "Me gusta explanatione!",
      "No, he's not. People just need to stop thinking that any kind of critique is an emotional response.",
      "Yup, memory correction has been a thing since GDDR5 iirc\n\nI wanted to say GDDR3 but I couldn't find any info on that having it.",
      "No, the ECC on regular DDR5 is not nearly good enough to correct for errors from running it too fast. \n\nFCLK on AMD AM5 platform is though and it'll show signs of errors instead of failing outright, like audio stutters and performance drops.",
      "Supposedly, his OC matched a 5080 in Cyberpunk.    Maybe he just had a golden sample though or just that 1 game.",
      "Plus not calling the undervolt with higher power limit overclocking is something",
      "Unfortunately, data shows that they get more views when they use that type of thumbnail. Too much brain rot in society.",
      "AMD had ECC on the RX 6000 series already.",
      "10% extra performance and lower temperatures through undervolting. Feel free not to comment on something you‚Äôve no clue about. Would make Reddit a better place.",
      "Not everyone bases their GPU purchases off RT. A $600 GPU that matches a $1,000 GPU in anything it still noteworthy.",
      "Im curious if that happens with regular ddr5 too. It has bit correction but does it degrade performance ? I believe none of the memory tests show if ddr5 stick itself correct anything or not. And would it cause weird erratic ssd read speed variances.",
      "I thought -125mV was stable on mine because it ran time spy without issues, but when I was playing some other games, I saw instability issues. I then tried Steel Nomad and saw driver crashes. I had to die it down to -80mV before the crashes stopped.",
      "People spend 100s for that extra performance and it‚Äôs free. You utter ü§°"
    ]
  },
  {
    "brand": "amd",
    "generation": "9000",
    "tier": "mid",
    "matched_keywords": [
      "rx 9070 xt",
      "9070 xt",
      "9070",
      "rx 9070"
    ],
    "title": "Radeon RX 9070 (XT) vs GeForce RTX 5070 Meta Review",
    "selftext": "- compilation of 14 launch reviews with ~8490 gaming benchmarks at 1080p, 1440p, 2160p\n- only benchmarks at real games compiled, not included any 3DMark & Unigine benchmarks\n- geometric mean in all cases\n- standard raster performance without ray-tracing and/or DLSS/FSR/XeSS\n- extra ray-tracing benchmarks (mostly without upscaler) after the standard raster benchmarks\n- stock performance on (usually) reference/FE boards, no overclocking\n- factory overclocked cards were normalized to reference clocks/performance, but just for the overall performance average (so the listings show the original performance result, just the performance index has been normalized)\n- missing results were interpolated (for a more accurate average) based on the available & former results\n- performance average is (some) weighted in favor of reviews with more benchmarks\n- all reviews should have used newer drivers for _all_ cards\n- power draw numbers based on a couple of reviews, always for the graphics card only\n- performance/price ratio (higher is better) for 1440p raster performance and 1440p ray-tracing performance\n- for the full results and some more explanations check [3DCenter's launch analysis](https://www.3dcenter.org/artikel/launch-analyse-geforce-rtx-5070-vs-radeon-rx-9070-xt)\n\nNote: Many testers have used heavily factory overclocked models for the 9070 (XT). This effect was of course deducted from the average performance values. For this reason, the average for 9070 & 9070XT is (some) lower than most of the individual values.\n\n&nbsp;\n\nRaster 2160p|4070|4070S|407TiS|5070|5070Ti|5080|79GRE|79XT|79XTX|9070|9070XT\n|:--|:--:|:--:|:--:|:--:|:--:|:--:|:--:|:--:|:--:|:--:|:--:|\n&nbsp;|Ada 12GB|Ada 12GB|Ada 16GB|Blackw. 12GB|Blackw. 16GB|Blackw. 16GB|RDNA3 16GB|RDNA3 20GB|RDNA3 24GB|RDNA4 16GB|RDNA4 16GB\nCBase|82.6%|96.6%|116.1%|_100%_|130.0%|149.2%|90.6%|109.6%|128.4%|106.0%|120.8%\nCowCL|78.5%|91.1%|116.5%|_100%_|127.8%|149.4%|93.7%|111.4%|132.9%|112.7%|126.6%\nHW&Co|80.8%|94.6%|115.1%|_100%_|129.7%|149.6%|92.3%|111.6%|130.5%|106.7%|125.6%\nIgor|-|96.2%|115.4%|_100%_|128.4%|148.3%|95.9%|113.5%|137.8%|119.0%|136.3%\nKitGuru|82.7%|96.9%|113.1%|_100%_|126.5%|149.3%|96.7%|118.4%|138.5%|116.2%|133.6%\nLinus|-|92.5%|111.3%|_100%_|128.3%|149.1%|98.1%|115.1%|135.8%|109.4%|124.5%\nQuasar|-|94.4%|111.0%|_100%_|126.9%|-|92.0%|108.2%|128.7%|106.7%|122.1%\nPCGH|-|-|111.2%|_100%_|128.1%|150.3%|-|115.6%|138.0%|109.8%|127.0%\nPurePC|78.2%|92.4%|108.4%|_100%_|127.7%|147.9%|88.2%|106.7%|126.9%|107.6%|119.3%\nSweCl|80.0%|-|-|_100%_|124.0%|146.4%|-|-|132.0%|113.6%|128.8%\nTPU|80.0%|92.3%|110.2%|_100%_|128.0%|148.7%|90.9%|109.1%|129.0%|106.8%|122.4%\nTS/HUB|83.3%|98.3%|115.0%|_100%_|125.0%|143.3%|93.3%|113.3%|136.7%|108.3%|123.3%\nTom's|82.0%|-|115.0%|_100%_|131.0%|-|-|115.4%|135.3%|111.8%|128.5%\nTweak's|80.1%|94.2%|109.6%|_100%_|125.9%|146.8%|93.7%|133.9%|132.3%|107.0%|125.0%\n**avg**|80.6%|94.7%|112.3%|_100%_|127.3%|148.6%|92.5%|112.1%|132.8%|108.1%|123.1%\nTDP|200W|220W|285W|250W|300W|360W|260W|315W|355W|220W|304W\nMSRP|$549|$599|$799|$549|$749|$999|$549|$899|$999|$549|$599\n\n&nbsp;\n\nRaster 1440p|4070|4070S|407TiS|5070|5070Ti|5080|79GRE|79XT|79XTX|9070|9070XT\n|:--|:--:|:--:|:--:|:--:|:--:|:--:|:--:|:--:|:--:|:--:|:--:|\n&nbsp;|Ada 12GB|Ada 12GB|Ada 16GB|Blackw. 12GB|Blackw. 16GB|Blackw. 16GB|RDNA3 16GB|RDNA3 20GB|RDNA3 24GB|RDNA4 16GB|RDNA4 16GB\nCBase|84.9%|97.5%|114.4%|_100%_|125.8%|140.9%|87.8%|109.0%|123.0%|105.2%|118.7%\nCowCL|80.7%|94.0%|108.4%|_100%_|120.5%|134.9%|92.8%|112.0%|125.3%|112.0%|122.9%\nHW&Co|84.3%|97.8%|115.0%|_100%_|124.9%|143.3%|95.3%|112.5%|127.7%|107.3%|123.9%\nIgor|-|97.2%|111.9%|_100%_|124.8%|141.0%|96.3%|111.3%|130.9%|115.4%|129.8%\nKitGuru|84.4%|98.7%|112.7%|_100%_|123.2%|142.5%|97.7%|117.4%|133.6%|115.2%|130.9%\nLinus|-|95.7%|111.8%|_100%_|123.7%|143.0%|102.2%|116.1%|132.3%|107.5%|121.5%\nQuasar|-|95.3%|109.4%|_100%_|122.5%|-|91.12%|107.1%|123.4%|105.9%|120.0%\nPCGH|-|-|110.5%|_100%_|123.8%|143.1%|-|115.2%|134.7%|108.0%|123.6%\nPurePC|80.7%|95.0%|107.6%|_100%_|123.5%|141.2%|89.1%|106.7%|123.5%|105.9%|116.0%\nSweCl|82.6%|-|-|_100%_|121.5%|138.0%|-|-|128.1%|111.6%|126.4%\nTPU|82.4%|95.0%|109.7%|_100%_|123.4%|139.2%|91.4%|107.2%|123.8%|105.6%|120.1%\nTS/HUB|85.7%|101.0%|114.3%|_100%_|120.0%|134.3%|94.3%|111.4%|129.5%|103.8%|113.3%\nTom's|84.0%|-|112.8%|_100%_|124.8%|-|-|112.9%|126.9%|107.7%|121.3%\nTweak's|85.1%|98.0%|110.8%|_100%_|123.5%|140.1%|96.2%|114.0%|127.1%|106.3%|123.3%\n**avg**|83.5%|96.9%|111.2%|_100%_|123.1%|140.5%|93.3%|111.5%|127.8%|106.8%|120.0%\nTDP|200W|220W|285W|250W|300W|360W|260W|315W|355W|220W|304W\nMSRP|$549|$599|$799|$549|$749|$999|$549|$899|$999|$549|$599\n\n&nbsp;\n\nRaster 1080p|4070|4070S|407TiS|5070|5070Ti|5080|79GRE|79XT|79XTX|9070|9070XT\n|:--|:--:|:--:|:--:|:--:|:--:|:--:|:--:|:--:|:--:|:--:|:--:|\n&nbsp;|Ada 12GB|Ada 12GB|Ada 16GB|Blackw. 12GB|Blackw. 16GB|Blackw. 16GB|RDNA3 16GB|RDNA3 20GB|RDNA3 24GB|RDNA4 16GB|RDNA4 16GB\nCowCL|83.0%|93.2%|105.7%|_100%_|114.8%|123.9%|93.2%|109.1%|117.0%|102.3%|115.9%\nIgor|-|97.1%|112.0%|_100%_|123.7%|136.2%|95.3%|108.1%|124.1%|112.5%|124.7%\nKitGuru|86.3%|99.8%|112.0%|_100%_|120.1%|137.3%|97.4%|115.3%|129.2%|113.6%|127.7%\nLinus|-|98.4%|111.0%|_100%_|121.3%|133.9%|101.6%|114.2%|128.3%|105.5%|118.1%\nQuasar|-|96.5%|107.9%|_100%_|119.0%|-|88.7%|104.5%|117.7%|104.9%|116.1%\nPCGH|-|-|109.5%|_100%_|120.4%|137.2%|-|112.6%|128.6%|106.0%|118.6%\nPurePC|81.8%|96.7%|106.6%|_100%_|120.7%|135.5%|89.3%|105.0%|119.0%|105.0%|114.0%\nSweCl|84.0%|-|-|_100%_|118.5%|131.9%|-|-|123.5%|109.2%|122.7%\nTPU|84.4%|96.1%|108.2%|_100%_|119.5%|131.6%|90.8%|105.3%|118.5%|103.9%|116.5%\nTom's|86.1%|-|109.8%|_100%_|118.1%|-|-|108.0%|118.6%|103.5%|113.5%\nTweak's|87.7%|99.6%|109.4%|_100%_|120.3%|134.5%|95.1%|112.0%|121.3%|105.7%|117.5%\n**avg**|84.9%|97.3%|108.8%|_100%_|119.7%|133.7%|93.1%|109.2%|122.5%|105.6%|117.4%\nTDP|200W|220W|285W|250W|300W|360W|260W|315W|355W|220W|304W\nMSRP|$549|$599|$799|$549|$749|$999|$549|$899|$999|$549|$599\n\n&nbsp;\n\nRayTr. 2160p|4070|4070S|407TiS|5070|5070Ti|5080|79GRE|79XT|79XTX|9070|9070XT\n|:--|:--:|:--:|:--:|:--:|:--:|:--:|:--:|:--:|:--:|:--:|:--:|\n&nbsp;|Ada 12GB|Ada 12GB|Ada 16GB|Blackw. 12GB|Blackw. 16GB|Blackw. 16GB|RDNA3 16GB|RDNA3 20GB|RDNA3 24GB|RDNA4 16GB|RDNA4 16GB\nCBase|86.9%|99.2%|127.0%|_100%_|141.3%|158.9%|84.1%|104.8%|120.4%|108.6%|125.7%\nCowCL|77.3%|90.7%|120.0%|_100%_|137.3%|162.7%|78.7%|96.0%|112.0%|96.0%|109.3%\nKitGuru|86.4%|100.3%|130.2%|_100%_|145.8%|173.6%|76.9%|95.6%|110.5%|103.4%|122.0%\nPCGH|-|-|128.0%|_100%_|142.7%|168.7%|-|98.2%|116.0%|104.8%|122.9%\nPurePC|78.7%|95.9%|113.1%|_100%_|135.2%|158.2%|63.9%|76.2%|91.8%|88.5%|102.5%\nTPU|82.4%|95.9%|137.4%|_100%_|155.1%|179.3%|79.6%|94.7%|110.2%|111.4%|132.7%\nTS/HUB|82.1%|97.4%|115.4%|_100%_|130.8%|156.4%|53.8%|64.1%|76.9%|71.8%|97.4%\nTom's|83.0%|-|121.4%|_100%_|134.3%|-|-|89.0%|104.7%|98.6%|117.3%\nTweak's|84.4%|99.6%|120.7%|_100%_|135.1%|159.4%|-|-|-|96.0%|116.7%\n**avg**|83.5%|97.9%|125.1%|_100%_|141.0%|165.3%|74.6%|91.1%|106.8%|98.8%|117.3%\nTDP|200W|220W|285W|250W|300W|360W|260W|315W|355W|220W|304W\nMSRP|$549|$599|$799|$549|$749|$999|$549|$899|$999|$549|$599\n\n&nbsp;\n\nRayTr. 1440p|4070|4070S|407TiS|5070|5070Ti|5080|79GRE|79XT|79XTX|9070|9070XT\n|:--|:--:|:--:|:--:|:--:|:--:|:--:|:--:|:--:|:--:|:--:|:--:|\n&nbsp;|Ada 12GB|Ada 12GB|Ada 16GB|Blackw. 12GB|Blackw. 16GB|Blackw. 16GB|RDNA3 16GB|RDNA3 20GB|RDNA3 24GB|RDNA4 16GB|RDNA4 16GB\nCBase|88.2%|101.8%|120.2%|_100%_|129.2%|144.0%|81.6%|102.2%|113.7%|106.9%|118.9%\nCowCL|75.6%|89.0%|111.0%|_100%_|124.4%|142.7%|74.4%|91.5%|100.0%|98.8%|112.2%\nHWCo|83.5%|100.1%|120.4%|_100%_|132.8%|154.5%|60.4%|71.6%|81.7%|84.0%|101.4%\nKitGuru|86.3%|100.3%|116.8%|_100%_|129.0%|151.6%|71.4%|86.3%|98.3%|94.0%|109.5%\nLinus|-|97.9%|116.7%|_100%_|133.3%|154.2%|62.5%|68.8%|83.3%|83.3%|97.9%\nQuasar|-|100.0%|113.2%|_100%_|123.6%|-|58.1%|68.2%|78.4%|89.9%|101.9%\nPCGH|-|-|115.0%|_100%_|125.4%|145.4%|-|91.9%|105.9%|96.6%|111.4%\nPurePC|80.5%|96.7%|111.4%|_100%_|128.5%|149.6%|62.6%|75.6%|88.6%|87.8%|100.0%\nTPU|84.3%|99.0%|114.6%|_100%_|127.5%|143.5%|70.1%|82.3%|94.2%|96.1%|111.5%\nTS/HUB|87.1%|101.4%|115.7%|_100%_|122.9%|142.9%|55.7%|67.1%|77.1%|84.3%|97.1%\nTom's|85.4%|-|117.9%|_100%_|126.8%|-|-|89.8%|104.7%|99.3%|115.9%\nTweak's|88.9%|101.5%|119.2%|_100%_|131.5%|151.2%|-|90.8%|103.4%|95.3%|113.4%\n**avg**|84.3%|98.8%|115.4%|_100%_|127.1%|146.8%|68.9%|82.8%|95.0%|92.6%|106.5%\nTDP|200W|220W|285W|250W|300W|360W|260W|315W|355W|220W|304W\nMSRP|$549|$599|$799|$549|$749|$999|$549|$899|$999|$549|$599\n\n&nbsp;\n\nRayTr. 1080p|4070|4070S|407TiS|5070|5070Ti|5080|79GRE|79XT|79XTX|9070|9070XT\n|:--|:--:|:--:|:--:|:--:|:--:|:--:|:--:|:--:|:--:|:--:|:--:|\n&nbsp;|Ada 12GB|Ada 12GB|Ada 16GB|Blackw. 12GB|Blackw. 16GB|Blackw. 16GB|RDNA3 16GB|RDNA3 20GB|RDNA3 24GB|RDNA4 16GB|RDNA4 16GB\nCowCL|80.2%|93.0%|107.0%|_100%_|120.9%|136.0%|73.3%|86.0%|95.3%|98.8%|109.3%\nKitGuru|87.2%|100.8%|114.2%|_100%_|125.2%|144.8%|71.1%|84.7%|94.8%|92.1%|104.9%\nLinus|-|71.0%|116.7%|_100%_|129.2%|147.2%|63.9%|72.2%|81.9%|84.7%|98.6%\nPCGH|-|-|113.2%|_100%_|121.2%|139.0%|-|92.6%|104.7%|97.1%|110.3%\nPurePC|81.5%|96.8%|109.7%|_100%_|125.0%|142.7%|64.5%|75.0%|86.3%|87.1%|98.4%\nTPU|84.6%|99.0%|112.7%|_100%_|122.8%|135.8%|69.9%|82.3%|93.3%|93.5%|108.7%\nTom's|92.7%|-|124.5%|_100%_|120.6%|-|-|95.8%|108.5%|104.7%|120.0%\nTweak's|89.1%|102.4%|116.5%|_100%_|128.0%|145.6%|75.0%|87.9%|98.5%|93.9%|110.6%\n**avg**|85.4%|99.5%|113.7%|_100%_|123.3%|139.7%|72.8%|85.5%|96.6%|93.5%|106.5%\nTDP|200W|220W|285W|250W|300W|360W|260W|315W|355W|220W|304W\nMSRP|$549|$599|$799|$549|$749|$999|$549|$899|$999|$549|$599\n\n\n&nbsp;\n\nRaster vs RayTracing|4K/2160p|WQHD/1440p|FullHD/1080p\n|:--|:--:|:--:|:--:|\nGeForce RTX 4070|71.8% vs 66.7% = **-7%**|75.0% vs 73.0% = **-3%**|78.0% vs 75.0% = **-4%**\nGeForce&nbsp;RTX&nbsp;4070&nbsp;Super|84.3% vs 78.2% = **-7%**|87.1% vs 85.6% = **-2%**|89.4% vs 87.5% = **-2%**\nGeForce RTX 4070 Ti|92.0% vs 86.9% = **-6%**|93.9% vs 93.7% = **¬±0**|95.8% vs 95.1% = **-1%**\nGeForce RTX 5070|89.0% vs 79.9% = **-10%**|89.9% vs 86.6% = **-4%**|91.9% vs 87.9% = **-4%**\nGeForce RTX 5070 Ti|113.4% vs 112.7% = **-1%**|110.7% vs 110.1% = **¬±0**|110.0% vs 108.4% = **-1%**\nGeForce RTX 5080|132.3% vs 132.1% = **¬±0**|126.3% vs 127.1% = **+1%**|122.8% vs 122.8% = **¬±0**\nRadeon RX 7900 GRE|82.4% vs 59.7% = **-28%**|83.8% vs 59.7% = **-29%**|85.5% vs 64.0% = **-25%**\nRadeon RX 7900 XT|99.8% vs 72.8% = **-27%**|100.2% vs 71.7% = **-28%**|100.4% vs 75.2% = **-25%**\nRadeon RX 7900 XTX|118.2% vs 85.4% = **-28%**|114.9% vs 82.3% = **-28%**|112.6% vs 84.9% = **-25%**\nRadeon RX 9070|96.3% vs 79.0% = **-18%**|96.0% vs 80.2% = **-16%**|97.0% vs 82.2% = **-15%**\nRadeon RX 9070 XT|109.6% vs 93.8% = **-14%**|107.9% vs 92.2% = **-15%**|107.9% vs 93.6% = **-13%**\n\nNote: all normalized to the GeForce RTX 4070 Ti Super at _100%_\n\n&nbsp;\n\nAt a glance|4070|4070S|407TiS|5070|5070Ti|5080|79GRE|79XT|79XTX|9070|9070XT\n|:--|:--:|:--:|:--:|:--:|:--:|:--:|:--:|:--:|:--:|:--:|:--:|\n&nbsp;|Ada 12GB|Ada 12GB|Ada 16GB|Blackw. 12GB|Blackw. 16GB|Blackw. 16GB|RDNA3 16GB|RDNA3 20GB|RDNA3 24GB|RDNA4 16GB|RDNA4 16GB\n2160p RA|80.6%|94.7%|112.3%|_100%_|127.3%|148.6%|92.5%|112.1%|132.8%|108.1%|123.1%\n1440p RA|83.5%|96.9%|111.2%|_100%_|123.1%|140.5%|93.3%|111.5%|127.8%|106.8%|120.0%\n1080p RA|84.9%|97.3%|108.8%|_100%_|119.7%|133.7%|93.1%|109.2%|122.5%|105.6%|117.4%\n2160p RT|83.5%|97.9%|125.1%|_100%_|141.0%|165.3%|74.6%|91.1%|106.8%|98.8%|117.3%\n1440p RT|84.3%|98.8%|115.4%|_100%_|127.1%|146.8%|68.9%|82.8%|95.0%|92.6%|106.5%\n1080p RT|85.4%|99.5%|113.7%|_100%_|123.3%|139.7%|72.8%|85.5%|96.6%|93.5%|106.5%\nTDP|200W|220W|285W|250W|300W|360W|260W|315W|355W|220W|304W\nReal&nbsp;P.D.|193W|221W|277W|230W|287W|311W|~255W|309W|351W|220W|302W\nE.Eff. 1440p&nbsp;RA|99%|101%|92%|_100%_|99%|104%|84%|83%|84%|112%|91%\nMSRP|$549|$599|$799|$549|$749|$999|$549|$899|$999|$549|$599\nRetail GER|~540‚Ç¨|~580‚Ç¨|~790‚Ç¨|~730‚Ç¨|~1000‚Ç¨|~1300‚Ç¨|~570‚Ç¨|~670‚Ç¨|~880‚Ç¨|~730‚Ç¨|~840‚Ç¨\nP/P GER 1440p&nbsp;RA|113%|122%|103%|_100%_|90%|79%|119%|121%|106%|107%|104%\nP/P GER 1440p&nbsp;RT|114%|124%|107%|_100%_|93%|82%|88%|90%|79%|93%|93%\nRetail US|~$550|~$600|~$800|~$650|~$900|~$1150|~$550|~$650|~$870|~$650|~$750\nP/P US 1440p&nbsp;RA|99%|105%|90%|_100%_|89%|79%|110%|111%|95%|107%|104%\nP/P US 1440p&nbsp;RT|100%|107%|94%|_100%_|92%|83%|81%|83%|71%|93%|92%\n\nNote: RA = Raster, RT = Ray-Tracing, EE = Energy Efficiency, P/P = Performance/Price Ratio\nNote: retail prices assuming real availability - for old SKUs, these are typically from the year 2024; corresponding assumptions were made for new SKUs, taking into account the current trend that the list price will hardly be reached in the near future\n\n&nbsp;\n\nList of hardware reviews evaluated for this analysis:\n\n- [ComputerBase](https://www.computerbase.de/artikel/grafikkarten/amd-radeon-rx-9070-xt-rx-9070-test.91578/)\n- [Cowcotland](https://www.cowcotland.com/articles/4479/dans-la-famille-tuf-je-demande-la-radeon-rx-9070-et-la-rx-9070-xt.html)\n- [Hardware & Co](https://hardwareand.co/dossiers/gpu/test-des-radeon-rx-9070-9070-xt-amd-de-retour-aux-affaires)\n- [Igor's Lab](https://www.igorslab.de/en/amd-radeon-9070xt-and-9070-in-the-test-clock-energy-with-crowbar-and-at-least-some-reason-as-a-counterpoint/)\n- [KitGuru](https://www.kitguru.net/components/graphic-cards/dominic-moass/amd-rx-9070-review-ft-sapphire/)\n- [Linus Tech Tips](https://www.youtube.com/watch?v=ptp5suRDdQQ)\n- [PC Games Hardware](https://www.pcgameshardware.de/Radeon-RX-9070-XT-Grafikkarte-281023/Tests/Preis-Test-kaufen-Release-Specs-Benchmark-1467270/)\n- [PurePC](https://www.purepc.pl/amd-radeon-rx-9070-test-recenzja-opinia-wydajnosc-cena-premiera-asus-tuf-gaming)\n- [Quasarzone](https://quasarzone.com/bbs/qc_bench/views/93906)\n- [SweClockers](https://www.sweclockers.com/test/40758-powercolor-radeon-rx-9070-hellhound-tyst-hund-biter-varst)\n- [TechPowerUp](https://www.techpowerup.com/review/sapphire-radeon-rx-9070-xt-nitro/)\n- [TechSpot](https://www.techspot.com/review/2962-amd-radeon-9070/) / [Hardware Unboxed](https://www.youtube.com/watch?v=gWIIA-a9Q9A)\n- [Tom's Hardware](https://www.tomshardware.com/pc-components/gpus/amd-radeon-rx-9070-xt-review)\n- [Tweakers](https://tweakers.net/reviews/13022/radeon-rx-9070-en-9070-xt-waar-nvidia-spartelt-overtuigt-amd.html)\n\n&nbsp;\n\nSource: [3DCenter.org](https://www.3dcenter.org/artikel/launch-analyse-geforce-rtx-5070-vs-radeon-rx-9070-xt)",
    "comments": [
      "Worth mentioning, that ray tracing includes black myth wukong, which is completely broken on AMD and is basically bruteforced, so it Heavily bricks the results for ray tracing on AMD cards. It's ~5-6% better average if you exclude it (since it's a huge outlier)",
      "This. Removing the statistical anomaly or highlighting it would be helpful for a more accurate understanding.",
      "I was planning to buy an RTX 5070 but everyone on the internet told me to wait for RX 9000.\n\nI bought a Gigabyte Gaming OC RX 9070 XT for 85 USD more than the cheapest RTX 5070 in my countryüôÇ\n\nThank you people. My RX 9070 XT demolishes the RTX 5070 where it matters. I believe the 5070 only beats it in path tracing and Black Myth Wukong.\n\nEdit : For those wondering here was my options in my terrible country (expensive GPUs, low wages, 3rd world)\n\nRTX 5070 : 85 USD cheaper than the RX 9070 XT\n\nRTX 5070ti : 195 USD more expensive than 9070 XT\n\nI'm very happy with my choice.",
      "Perhaps watch the DF video on Avatar?  It's one of the best implementations of GI and other RT features (bar the path tracing titles).\n\nIt runs well on AMD not because its RT is bad but probably because it favours AMD in raster and so when Heavy RT settings are used AMD GPU's have a bit more cushion for extra performance drop.",
      "Worth mentioning that Black myth wukong uses a specific Nvidia fork of unreal engine. Not a conspiracy to assume that Nvidia cards have primary focus on that engine.",
      "Cant buy either for sane price in Europe",
      "He's talking about Black Myth Wukong results being an outlier due to raytracing in that game being broken for AMD. Not the existence of raytracing games being an outlier.",
      "TLDR, just look at the average row for each set. It's normalized to a 5070, so if the average line for a card is 110%, that means it's 10% faster than a 5070.",
      "Test was done at very high RT. The usual usage of it, not PT level. For BMW and Alan wake it's PT, actually, that is why it is borked. In Alan wake both vendors die anyway, so having 20 fps on AMD or 25 on 5070 - who cares. Cyberpunk RT works great on both cards and that's what will be in future games.\n\nBMW on the other hand, is completely broken on AMD. Like, it's a sabotage at this point.",
      "No, but the RX 9070 XT beats the rtx 5070 (12GB) even in Ray TracingüòÇ Its path tracing where it falls flat on its face, but that's a super duper tiny Sacrifice I am willing to make. \n\nThe RX 9070 XT beats the RTX 5070 in Cyberpunk at 1440p Ray Tracing Ultra preset and basically anything that isn't path tracing I believe (besides Black Myth RT)\n\nI got significantly faster raster  , a little bit faster RT and 16GB VRAM for only 85 USD more. The RTX 5070ti (16GB)  is almost 200 USD more expensive than the RX 9070 XT I bought\n\nI love this card. I just finished undervolting the card. I am getting 230w avg power usage and -3.5% perf decrease",
      "This is many number, and I many stupid‚Ä¶\n\nIs there a TLDR?",
      "Games that rely on RT only like Indiana Jones and Metro Exodus work well on AMD cards so IDK what that guy is talking about. Wukong just runs badly on AMD.",
      "No, the game specifically is an outlier. Cyberpunk with path tracing on all other AMD cards before this performed similarly with the 7900xtx falling behind even the 3060 Ti, but performance is much better with the 9070 and 9070XT. The 9070 XT performs on par with a 4070 in path tracing in Cyberpunk now and heavy RT results across the board are miles better than last generation... But Wukong still performs like shit.\n\n5070 is 15-20% faster in Cyberpunk PT and 73% faster in Black Myth Wukong for some reason.",
      "Same situation in Australia. These companies only care about the American market.",
      "nice",
      "how do you come to that conclusion? the 9070 is faster, the 9070xt is faster than the 4070 super.\n\nIts faster than the super and the same price (or 9070 is less).\n\nVery bad TLDR",
      "BM:W catching strays for no reason.",
      "Also don't forget access to FSR4 when choosing between 9000 and 7000 cards. It's apparently a night and day difference",
      "It's a huge outlier and statistics doesn't work that way.\n\n\nIf you keep the broken crap - the difference is 20%. If you ignore that one single crap - it's 10% or so. And that might be a very important thing for buying decision.\n\n\nSo yes, it is important to mention the outlier, so people can see that a make their decision correctly. Because in other RT games AMD is very competitive, like in cyberpunk or avatar or star wars.",
      "GNexus review kept BM:W out of the main averaging and still reported the NVIDIA as better in RT. But said 9070 XT was a good buy for MSRP."
    ]
  },
  {
    "brand": "amd",
    "generation": "9000",
    "tier": "mid",
    "matched_keywords": [
      "rx 9070 xt",
      "9070 xt",
      "9070",
      "rx 9070"
    ],
    "title": "AMD introduces $599 Radeon RX 9070 XT and $549 RX 9070 RDNA4 GPUs - VideoCardz.com",
    "selftext": "",
    "comments": [
      "There it is. Now vote with your wallet and dont even entertain the idea of the rubbish 5070 and 5070ti.",
      "Mark my words people are still gonna but more RTX 5070s, people just can't understand (not all, but clearly a good majority) the importance of voting for with your wallet.",
      "Some people were also just asking for lower prices from AMD so that Nvidia responds and they can buy a 5070Ti/TI Super cheaper",
      "looks good, but waiting for reviewers is a pretty important step to buying new gpu",
      "I will purchase one at that price if it's in stock.",
      "Its an up-sale tactic.   \n\"only 50 more, I can afford that\" type beat",
      "We need price in Europe",
      "Good price for the 9700XT and a terrible one for the 9700. It's such a \"I don't want to sell this\" price.",
      "Own a NVIDIA RTX 2060, first time ive felt swayed towards AMD with the 9070 XT, What are peoples thoughts?   \n  \nShould the trigger on a purchase be pulled?",
      "While this it true nvidia historically will not touch its prices, we will only see a shift if amd is successful in clawing back the market. It‚Äôs a 90-10 split.. they have a lot of work to do.",
      "You have no real reason to consider nvidia this go round.¬† The average 5070ti is $900.¬†\n\n\nEven if you're afraid to lose dlss, I wouldn't call a $300 dlss tax reasonable.",
      "9070 XT looks pretty compelling since it offers close to XTX raster and better RT performance than it, it also deals with 5070 Ti really well overall.\n\n9070 at 549$ seems like a big fail, but while customers will hate the price, one also should understand that:\n\n\\* N4 yields are very good right now, so AMD doesn't want you to get the non XT cards anymore\n\n\\* Unlike 7700 XT/7900 XT, 9070 has the same memory subsystem as the XT, so it also costs almost as much to make.",
      "There always seems to be some excuse to buy Nvidia for some people. It sometimes gets tiring having to defend my decision to buy AMD when people respond to comments questioning why the hell I didn't buy Nvidia, as if to them the idea of not automatically buying Nvidia no matter the price or usefulness of feature set is unfathomable.\n\n(in terms of gaming only, I can't speak to uses outside of that where Nvidia does perform better in other applications)",
      "If the 5070 outsells this, it's the consumers that are the problem. The 9070XT is like one and a half tiers up in terms of performance and has 4GB extra VRAM for $50 more.",
      "$599 should be around 699‚Ç¨ (20% tax included)",
      "Welp..  The price actually looks good.\n\nTime to strap in for another painful week while we wait for 3rd party benchmarks....\n\nLooks like I can easily dump my 3070 on Facebook marketplace for around $300.  The question remains...  Can I even get the 9070XT?  And will it really be $599?",
      "Make it 729-749‚Ç¨ for those above 20% (23% in my country). Meanwhile 5070ti is 900‚Ç¨-1000‚Ç¨.",
      "It‚Äôs also manufacturing, they don‚Äôt want to sell a ton of binned 9070s because their yields are good enough that they would have to artificially bin fully functioning chips to meet the demand if they sold it at a cheaper price.",
      "They also caved to the backlash of the \"4080 12GB\" and renamed it to 4070 TI with a price drop.",
      "Lol my favorite excuse is the one where they go \"yea but Nvidia has CUDA\" and when I respond and ask them \"what is CUDA and what do you use it for\" I immediately get crickets."
    ]
  },
  {
    "brand": "amd",
    "generation": "9000",
    "tier": "mid",
    "matched_keywords": [
      "9070",
      "rx 9070"
    ],
    "title": "AMD announces AMUSE 3.0 AI software update with speed optimizations for Radeon RX 9070, Ryzen AI (Max) series",
    "selftext": "",
    "comments": [
      "I've been playing around with it.  Really fast on my 9070XT and high quality.  Though the model likes to have 6 fingered hands or weird things with hands.  I can specify 5 fingers to make it mostly behave.",
      "It's lightning fast on a RX 7800 XT compared to Fooocus using DirectML.",
      "Any chance you have a sense of how long it takes to generate a 1024x1024 image using Flux?",
      "So I tried it with Flux.1 Dev model and it runs but compared to Zluda - Comfyui it is so slow. Also a heavy in built filter that can't be changed is odd I can't write a sign with any words I want because of the filter is crazy.",
      "It lists Flux Schnell for 7900XTX and Flux dev only for W7900 class cards?\n\nFlux dev under WSL2 under ROCm under Comfy UI uses around 19GB VRAM in 1024x1024 and run in around 60 seconds. Under linux native people report around 45s inference time. [The catch is that it's hardcore to get ROCm to accelerate pytorch.](https://github.com/OrsoEric/HOWTO-7900XTX-Win-ROCM)\n\nI wonder if AMD were conservative with their settings, or if there is still an enormous penalty with ONNX runtime. When I tried AMUSE last time it had an incredible penality, it had around 1/20th of the performance compared even with ROCm+Zluda+Comfy UI.\n\nWhen i get around to it I'll try it.\n\nI really wish AMD picked ONE stack, and focused on that working fine. If AMD want to focus on ONNX, it's fine with me, just make that acceleration seamless, and make reliable binaries for pytorch.",
      "So is there a way to get uncensored images using the latest version? Deleting the content filter doesn't work. Seems like there's very few options for AMD if you want a GUI that's simple to use and fast.",
      "Dreamshaper Lightning model 18.1s from first load.  This model fits completely in GPU memory.\n\nFlux1-schnell model (as installed inside Amuse) 45.2s from first load.  This model needs GPU + RAM.  \n\nThe Dreamshaper model looks more photorealistic by default than Flux.  A neat trick is you can add a camera save file name to the prompt to get models to output more photorealistic images.  I add DSCF1234 which is a Fuji camera image file.",
      "DirectML was incredibly slow when I tried it a while back.\n\nWhat generation time are you getting with Flux Shnell an Flux dev? at 1024px?",
      "I tried running on Linux thru Wine (Fedora 41, Wine64) with installation going without notice.  Running the app produced the splash screen and nothing else.\n\nBriefly, how did you get installed on native linux?",
      "Yes. Just install, select a model and type what you want to see",
      "So, i gave it a go.\n\nI downloaded Amuse 3.0. Installed it and run it. I clicked on the \"expert\" button, then \"model manager\" and then i clicked on \"download model\". I chose the Stable Diffusion tab and downloaded the one named \"SD3.5 (AMDGPU)\". It's a hefty download weighing at 18.5GB. (i went to expert and try to chose a model because Amuse would prompt to download the DS3.5 Medium model and after reading a bit i realised that its output quality isn't as good as the Large model)\n\nIt's a bit slow on my 9070 XT (i guess, haven't done this again). It took almost 5 minutes to generate this image.\n\nhttps://i.redd.it/m5eowavkggve1.gif\n\nEdit: That time is with 40 steps.",
      "> \n> \n> I really wish AMD picked ONE stack, and focused on that working fine.\n\nGood lord this is so painfully true.\n\n\"but why focus on one thing if we can abandon twenty\" --amd, probably",
      "I'm on native windows running ubuntu under WSL2\n\nAmuse is more like a windows thing. Under linux ROCm works better",
      "And this is with 100 steps and a prompt that should give a more photorealistic result.\n\nhttps://i.redd.it/ab8zcw4hmgve1.gif\n\nIt's a cool thing to play around.",
      "Thanks for the numbers. In case it's of use, I just tried a Flux1-schnell run with Comfy UI Zluda using the built-in workflow at 1024x1024 and it took 28.27 seconds on my 7900 XTX.",
      "I don't know anything about how AI programs are used.\n\nWill i be able to use this with ease? Is this a one-click-install with an interface i can use with my utter ignorance?",
      "It seems like a lot of people aren't too knowledgeable about locally installed image generators. Tbh, i'm not an expert myself but i've been doing a lot of testing and found out a lot of things and how it works through trial and error. I'm personally most interested in photo realistic photos it can generate. FLux and AMD SD3.5 (Large) are usually the ones providing the best results. Flux i find tends to make skins a bit too smooth, i'll still need to investigate more with that, i'm sure there's a way around it. But essentially the exact prompts you use, guidance scale, even inference steps matter a lot. Even slight changes especially in the prompt section can dramatically change the output photo. I have an AMD 9800X3D CPU, 64 GB RAM and AMD 9070 XT GPU. I will show a photo i generated below (note - quality of the image i have is a lot better than what you see, for some reason, i can only upload gifs so i had to convert it to that file which lowered the quality).\n\nYou will also notice a seed number, this number is generated at random at the end of processing the image and is kind of like a unique tag. Thankfully if you save the image, that seed number is part of the image file name. Only thing so far that i don't like about amuse is i don't believe theres a way to say the exact prompts used in the metadata of the image, or at least generate some text file. As i mentioned, seed number is important if you want to generate similar images, but if you want very similar images, you will need the seed number and also your exact prompts used. I used prompts and negative prompts to generate this image (Negative prompts are basically prompts you add to tell the model what not to generate in the image, such as blurry photos, incorrect anatomy etc.)\n\nI cannot stress enough, prompts have to be exact, even if you remove say a full stop at the end of your prompt, that will generate a slightly different image, even with the same seed number used. In other words, if i gave you my exact prompts used, Guidance level, inference steps and seed number, you will be able to generate this exact image below.  Unfortunately because it doesn't record your prompts used, or even the model used to generate the image, all this information is lost unless you record it yourself, for now i create a folder with the best images and then add a text file along with it, recording things like prompts, Guidance level, inference steps etc, so i know the exact variables i used, so if i want to go back and generate the same image and then change variables slightly to get the same image, then i have the ability to do so (the eact layout resolution you use matters too so something to remember).  seed number itself won't be enough if you want to generate images that look very close to an existing image.\n\nIf anyone has any questions, let me know and i'll try to assist.\n\n\n\nhttps://i.redd.it/lo5itzjobsve1.gif",
      "Yea I tried it, seems you can't easily load other SD models than the ones they allow you to download, and the filtering is so insane, it'll hit random prompts  and just give you a blurred mess, if it said 'detected \"X\"' or something where it could tell you why that might help, but just getting a blurred image and you having to search for why something isn't working is a bad UI experience. Meanwhile SD.Next works great.",
      "Any success importing your own models? All my old safetensors LORA could fix this :X",
      "The future of humans, six fingered we will be."
    ]
  },
  {
    "brand": "amd",
    "generation": "9000",
    "tier": "mid",
    "matched_keywords": [
      "rx 9070 xt",
      "9070 xt",
      "9070",
      "rx 9070"
    ],
    "title": "AMD's Radeon VP calls RX 9070 XT demand 'unprecedented' ‚Äî RDNA 4 launch 'milestone event'",
    "selftext": "",
    "comments": [
      "Give wide support for fsr4 now. Plx",
      "Given that Optiscaler can add FSR 4 to games with DLSS 2+/FSR 2+, AMD has no excuse.",
      "I think what people want is hardware support for older GPUs with fsr4, which optiscaler doesn't change.\n\nAnd there's no way AMD will go anywhere near supporting hooking into the DLSS interface themselves. They'll get legally turbofucked.",
      "Wish I could find the lower end XT models for MSRP. Everything here when available is 200-300 CAD over MSRP.",
      ">I think what people want is hardware support for older GPUs with fsr4, which optiscaler doesn‚Äôt change.\n\nThe hardware doesn‚Äôt support it. It‚Äôs not AMD deliberately not supporting FSR 4 on older hardware\n\n>And there‚Äôs no way AMD will go anywhere near supporting hooking into the DLSS interface themselves. They‚Äôll get legally turbofucked.\n\nThe Supreme Court said that it is legal.\n\nGoogle v. Oracle",
      "I mean. That's your opinion. But value is subjective. Relative price / performance vs competition puts the price higher atm. Supply / demand / performance.\n\nDo I want to buy the card at MSRP? Yes. Am I pissed due to limited supply pushing up the prices? Yes. Doesn't change the fact that everything is relative.",
      ">McAfee and AMD affirm that when supply returns for RX 9070 XT, it will be accessible at the starting price point of $599.\n\nI'll believe it when I see it, so far literally every card in Europe starts 200-300 above EU (Post-tax) MSRP.",
      "...nvidia's 50 series drivers absolutetly arent better than AMD's current drivers lmao",
      "Same. It seems its like that all over. Stores scalping their customers.\n\nI can see that even 7900XTX has increased 170 euro in price.",
      "Imagine a dystopian future where gamers must buy NVIDIA video cards because games only use NVIDIA-specific APIs.",
      "Even though it's legal I think AMD's well founded concern is whether Nvidia will choose to litigate, to call AMD going up against Nvidia a David vs Goliath situation would be an understatement with Nvidia being worth over 15 times what AMD is. Risking litigation here could also potentially yield a different ruling which would make the things that end users are doing illegal as well, so with small fish assuming the risk AMD gets the benefit of having it available for the initiated and not having to stick their neck out in case Nvidia gets litigious. \n\nOther projects like ZLUDA were actually taken down at the request of AMD themselves before, citing legal concerns as the reason for their requests for removal, so it's obvious that AMD does not want to poke this bear. To that end, I'd suggest it's very unlikely that AMD would ever proceed forward with something that hooks into Nvidia's libraries to offer FSR 4, legal or not.",
      "LOL, that is actually true.\n\nAMD hasn‚Äôt had the black screen issue since the Radeon RX 5000 Series",
      "Please don't fuck it up. This could potentially be your Ryzen moment (or at least a Polaris one).",
      "If AMD can make GPU's today they will convert Nvidia users, this is the chance!\n\nI hope AMD dont mess up, kick out GPU's while Nvidia has eyes on Dater Center sales and win gamer harts.",
      "9070XT isn't worth a single cent over MSRP. Until you bring back MSRP cards, I'm not buying.",
      "Why imagine a future? They've been trying to do it already with things like Raytracing and well before now with things like Physx. But this wasn't the original argument, you want AMD to fight dirty without thinking how it could negatively affect them and that could very arguably lead to this dystopian future you're outlining by way of them drowning in litigation. My recognizing the objective state of affairs AMD is finding themselves in is not mutually exclusive of my hope that they find a way to succeed in the GPU market, I can face reality while also hoping it changes.",
      "I can understand the premium models costing more (OC editions etc). But a basic Gigabyte card is 200+ over MSRP right now and AMD not having any reference models available just compounds the issue.",
      "It's not \"fighting dirty\": it's trying to fight on an even ground.\n\nNVIDIA is pushing AMD out of the market by getting developers to use NVIDIA-exclusive APIs. \n\nNVIDIA is a monopoly (which in the US is considered to be >70% market share).\n\nYou keep saying that there are consequences to challenging NVIDIA, buy ***you are NOT considering that there also consequences to NOT challenging NVIDIA\".***",
      "> better drivers overall\n\nThat's an oft-repeated fallacy. nvidia has a lot of technical debt in their drivers (and hardware design, but that's another story), and it's catching up with them. You can kind of see it leaking out with the control panel.",
      "It will be $599...\n\n...when the GeForce RTX 5070 Ti is $749"
    ]
  },
  {
    "brand": "amd",
    "generation": "9000",
    "tier": "mid",
    "matched_keywords": [
      "9070",
      "rx 9070"
    ],
    "title": "AMD's RDNA4 Architecture - RX 9070 Series",
    "selftext": "",
    "comments": []
  },
  {
    "brand": "amd",
    "generation": "9000",
    "tier": "mid",
    "matched_keywords": [
      "9070",
      "rx 9070"
    ],
    "title": "Out with the old and in with the new! [XFX QICK RX 6750 XT ‚Üí SAPPHIRE PULSE RX 9070]",
    "selftext": "",
    "comments": [
      "I can't tell if you're being serious or not üòÇ it's a massive upgrade. \n\nIt's like 80% faster on average and doesn't even compare in RT and FSR 4.",
      "The GPU got smaller!",
      "Yet quieter and cooler!\n\nVery efficient card.",
      "It was from Overclockers UK. The Nitro+ model looks great, it's a beast.\n\n9070 is a best in general! Managed to get it on launch day for ¬£539.",
      "I just ordered my NITRO+ today! The waiting paid off üí™üèº",
      "Oooh! Newegg? I‚Äôd love to get my hands on a Nitro+ ü§§",
      "i do have an question, is all the 9070 non xt come with 3 fans configuration ? i though at least the pulse from sapphire came in two fans....\nMy case is limited to 280mm max...",
      "It does, that's the Sapphire Pulse you're seeing in the third picture, the 3 fan card below it is my old XFX 6750 XT.\n\nThe Sapphire Pulse 9070 280mm long, it's a great card...quiet, cool and efficient. Great for 1440p/4K.",
      "Sweet!\n\nBeen loving this thing, it's made me jump back into gaming again. Wait till you see FSR 4, it's incredible. \n\nAlso idk if you've heard or seen it, but there is a mod called OptiScaler which allows you to inject FSR 4 into games that only support FSR 2/3. \n\nI was playing with it in AW2, check out the difference.\n\n[https://youtu.be/070vbz\\_Eu\\_A](https://youtu.be/070vbz_Eu_A)"
    ]
  },
  {
    "brand": "amd",
    "generation": "9000",
    "tier": "mid",
    "matched_keywords": [
      "9070 xt",
      "9070",
      "rx 9070"
    ],
    "title": "RX 9070 / 9070 XT: AMD‚Äôs Best GPU in Years? Perf, Ray Tracing & FSR 4 Tested!",
    "selftext": "",
    "comments": [
      "Best buy has them up (not for sale yet, just the listings).\n\nOnly one model is $599 and it appears to have been 'subsidized'  w/ a sale to meet that price. Otherwise regular price for it is $729 (and likely lower inventory).\n\nRest are $749, $819, $829, and $849.\n\nSo is Nvidia in trouble? No.\n\nAre consumers in trouble? Yes.",
      "If they would actually sell at MSRP it'd be the best gpu launch in years.\n\nUnfortunately retailers are pricing them higehr than 7900XTX's and are destroying AMD's potential at taking up marketshare. 0% chance I'm getting one for these ridiculous prices.",
      "I feel like we‚Äôve been getting the same headlines since terascale. As long as prebuilts exclusively ship with nvidia nothing is going to change",
      "Nvidia is not in trouble. what might happen is they lower their prices. If Nvidia sets prices so it's AMD+50 or Nvidia -50, they win just like they did before.",
      "Lol. Tldr:No \n\nIf they think they are threatened, they'll simply ship more gpus and destroy AMD's GPU business. \n\nIt feels like at this point they are just trying to prevent getting looks from the antitrust folks.",
      "Nvidia doesn‚Äôt care about the gamer market",
      "Exactly...it's pretty crazy.",
      "I got a 9070xt taichi for 730 and its so freaking quit I cannot hear it at all, while being a few percent faster\n\n\nAtleast there are benefits with the higher price\n\n\ngoing past 730 seems like a waste though"
    ]
  },
  {
    "brand": "amd",
    "generation": "9000",
    "tier": "mid",
    "matched_keywords": [
      "rx 9070 xt",
      "9070 xt",
      "9070",
      "rx 9070"
    ],
    "title": "Sapphire Radeon RX 9070 XT Nitro+ Review - Beating NVIDIA",
    "selftext": "",
    "comments": [
      "FSR4 has good first impressions.\n\n\n Good overall performance. No-brainer if you can find it close to 600 bucks",
      "Nitro+ has always been the most expensive card",
      "730$...130$ overhead.\n\nooooof.\n\nI was super excited about the Nitro+ since should have been mid range and should have had mid range pricing with maybe 100$ max of premium. \n\nNow I am just whelmed because of the pricing.",
      "but for something like the 7800xt it was only 50$ extra... \n\nThe 9070xt is in the same class, but it costs 130$.",
      "Why would you sell a 4080 Super anyway? That makes zero sense unless you want to buy a 5090.",
      "They mentioned on last page expect this particular card to be 22% higher at $730\n\n\nUp to you you decide if the extra OC, etc worth it",
      "Well they know 5070ti is 950+ for similar models so it‚Äôs still cheap.",
      "Nah, I'd rather get the cheaper cards",
      "They finally fix the idle power consumption seen on the 7900s. 20W for multiple monitors is very good.",
      "It‚Äôs 8% slower than the 5070Ti in RT. Get out of here. They have caught up basically.",
      "Yea... I was ready for $75 more, I would have been unhappy but swallowed it at $100, but I'm not doing $130.¬†\n\n\nWish we had the pricing for everything else before tomorrow to know how out of line it is though...",
      "Really commenting on every thread are we ?¬†\n\n\nJensen does not need your help",
      "I wonder if the $730 dollars is before or after the 20% tariffs. Seems like the latter to me.\n\nEdit: I'm dumb. It's likely the former as it's an AIB. Damn this shit gonna be expensive.",
      "I actually have that one. What about the xtx?\n\nIdk bro light their hq on fire or something",
      "I bought for 850$ after taxes. Sold it for 1000$. Made 150$ profit. \n\nIf I can sidegrade to a gpu of similar performance but at 600$, then I basically bought a 450$ gpu.",
      "Given that this seems to be the most premium looking 9070 XT out there, I get the $130 up charge, but... Yah I don't think so for me Sapphire. I'll probably be chasing down either a Pulse, or an XFX model of some kind this go around.",
      "XFX model is slated for $750. AIBs are out of their minds charging these premiums.",
      "When the same NV models cost 300 more it very well might",
      "Sapphire is the closest thing to EVGA on the AMD side",
      "lol?\n\nIf I have 100 gpus in my inventory pre-tariff, and widely publicized tariffs are put in place, I will raise my prices immediately on all stock...even pre-tariff inventory. \n\nEven if the tariffs are put in place for a day, a week, a month....maybe only 6 hours, maybe they aren't put in place at all, but they are threatened but it hits the news and I know that the tariff may come back into play at any moment and impact my cost on future supply, I'm just going to jack my prices. \n\nThe consumer will blame the tariffs and the government, not me. \n\nYou don't know how pricing works. I'm out here trying to make a profit. \n\nIt isn't like you ONLY pass on the cost of tariffs when you pay them. Don't you know that the executive branch can give exemptions to individuals or business unilaterally? Let's say Best Buy gets an exemption....they are still increasing the price, they are just making more profit. \n\nMaybe they have to give a kickback to the executive branch (POTUS). \n\n\nThis is how crony capitalism is born. Wait, it was born a while ago...this is how crony capitalism enters manhood."
    ]
  },
  {
    "brand": "amd",
    "generation": "9000",
    "tier": "mid",
    "matched_keywords": [
      "rx 9070 xt",
      "9070 xt",
      "9070",
      "rx 9070"
    ],
    "title": "PowerColor Redefines Gaming Excellence with the New AMD Radeon‚Ñ¢ RX 9070 XT and RX 9070 Graphics Card",
    "selftext": "",
    "comments": [
      "Reaper XT is advertised as a two slot card, makes that pretty appealing for me.",
      "For me it's the fact that it seems to be the only card under 315mm (except the acer one maybe, but I find zero info on that one)\n\nThat red devil looks sweet though",
      "If you do a lot of RT, then possibly, but most likely no. High VRAM is very important at 4k and beyond but right now 24GB is just future proofing. The most intense VRAM games right now can use around 20GB. \n\nRight now, the only cards that firmly beat the 7900XTX, are the 5080, 4090, and 5090. If you want to upgrade, I would look at them.",
      "Only if you can get good money for the XTX and your most desirable gaming target is 1440p RT stuff.",
      "I would be waiting for UDNA/rtx 6000 with that card.",
      "As a fellow XTX boi, no, not really.\n\nmaaaaybe i'll return mine and get the 9070XT depending on how things turn out but that's a definite maaaaybe\n\nrealistically speaking i'd wait for at least UDNA or UDNA2 to come out in a year or two because AMD said they'd do flagships on that again (UDNA is the succesor to RDNA4)",
      "I'm curious to see how the Hellhound performs, the RDNA 3 version was crazy good.\n\nIf I'm upgrading this gen that migh actually be the one.",
      "Yeah man, I got the Hellhound 7900XT for like $710 back in 2023 and it's hands down the best card variant I've ever used, AMD OR nVidia. I live in a hot tropical country but it runs so unbelievably cool and quiet. \n\nI love to pop open my cards and repasted and tinker around but haven't touched this ever since I got it since I don't wanna mess up whatever magic it's running. \n\nNext card will almost certainly be a Hellhound as well, and it's a stark difference from the Asus Strix I had before.",
      "There is an XFX 2 fans 2 slot design but it seems to be China only",
      "when i said return i literally meant return as i only got it last week and it's still within the 30 day return window.\n\nthat being said, the better RT isn't going to be much a factor for me as i have like 600+ games in my backlog and i doubt many of them even have FSR or RT support whatsoever (i guess doom eternal probably does, but eternal is so stupidly well optimized that it's basically irrelevant to a 7900XTX anyway)\n\npersonally i consider RT a gimmick until the performance drop vs raster is negligable. its annoying thats its going to be the new standard before we've even come close to that point (especially when game devs apparantly cannot be assed to implement older shadow tech that might not be as accurate or pretty but just works like alan wake 2 apparantly just not having character shadowcasting on objects at all when you dont have RT on???)",
      "These things look way cooler than the competition's gaudiness.",
      "I have my eyes on the hellhound. My son has the RX6600 hellhound and it is a very good looking card",
      "always skip a generation or 2 and then upgrade, especially if you have a top card. point being that next gen of cards is not a big enough jump in performance to warrant spending more money.",
      "Powercolor has definitely become a contender. I've had their Red Devil 6900 XT for a few years. Across all the gaming I've gotten under my belt this whole time, I don't think I've ever actually heard the fans. It's an incredibly quiet cooling system. I'm seriously considering the Red Devil version of their 9070 XT, if I can get my hands on it, and if the price is reasonable. It has really good specs, particularly that third 8-pin power connector. Add the quality of the PCB and the size of the cooler, and there could be a lot of OC headroom.",
      "I'm tempted to vote with my wallet and get a 9070XT, but even I don't really have a reason to at 1440P with my 7900XT. Also the Hellhound runs quiet and cool, I'll prolly get a high-ish end UDNA 1/2 of the same variety. \n\n(This was more said to myself to convince myself lol, the 9070 series is very exciting)",
      "Im getting the 9070xt. Dont ‚Äúupgrade ‚Äú if you already have an XTX . 9070 xt is just a XTX with better Ai n RT . Amd is investigating releasing a version of fsr4 to last gen high ends. The XTX may have enough Ai cores to support fsr4 (maybe limited). Plus AMD has unrestricted yields from TMSC , so they‚Äôll have stock flowing more regularly.",
      "Damn nvidia and their high end cards. If only supplies aren‚Äôt an issues. \n\nThanks for responding!",
      "Yep you‚Äôre good .",
      "They were discussing it [here](https://www.reddit.com/r/sffpc/comments/1j0cbcc/xfx_2slot_9070xt/)",
      "Yep."
    ]
  },
  {
    "brand": "amd",
    "generation": "9000",
    "tier": "mid",
    "matched_keywords": [
      "rx 9070 xt",
      "9070 xt",
      "9070",
      "rx 9070"
    ],
    "title": "Early RX 9070 XT benchmark compared to 6800 XT and it's almost 4x faster",
    "selftext": "",
    "comments": [
      "This sounds like the similarly misleading junk that some rags were touting in their RTX 5070 \"preview\" articles yesterday.\n\nWhat the cited tweet actually says:\n\n>263% faster than 6800xt in wukong benchmark cinematic RT + frame gen fsr50%\n\n1. It's in a single RT benchmark with frame generation, the same marketing BS that Nvidia did to say the 5070 was bringing 4090 performance.\n\n2. It's comparing a leaked benchmark from one unknown source to the tweeter's own benchmark.\n\n3. Even past that trash, the article is rounding up an extra 10% in performance to call it \"almost 4x.\"\n\nSo, we've got two different data sources that aren't using identical setups being pumped up by frame gen, then getting a second pumping from the article author's rounding crap.",
      "stupid post",
      "‚Äúin wukong benchmark cinematic RT + frame gen fsr50%‚Äú",
      "crazy we get these posts when AMD already released performance numbers. The 9070XT is around 65-70% faster than the 6800XT ü§¶‚Äç‚ôÇÔ∏è\n\n4x faster.. that is about as dumb as nvidia claiming the 5070 is faster than the 4090 üòÇ",
      "Framegen just invalidates the result lol",
      "AMD doesn't have multiframegen tho, which was the biggest reason 5070 fps was exaggerated to be 4x the actual",
      "At this point, I don't care for rumors. Reviews are live tomorrow, and a lot of the reviews I've seen so far for the 5070 have said we should keep an eye out so I'm interested in RT. I know raster will be good.",
      "If framegen gets that high, base fps is what 120?",
      "9070xt uses basically same boosts than 6800xt, but they are comparing ray tracing performance, on which 6800xt is pretty much unusable so it's relatively easy to quadruple the fps",
      "No, it's an Apple-like comparison",
      "....\n\nPretty misleading title as they picked a game that's RT heavy and run it against 6800xt.",
      "The GN video today made the 5070 MF claim look way worse. Its not even close.",
      "I need to know what the rt numbers look like tho.",
      "What a load of BS!\n\nIf the 9070XT is 4x faster than the 6800XT that means it will be the fastest GPU in the world, surpassing the 5090 by a significant margin \n\nWhen you want to lie, at least make it doable",
      "Why? What's stopping 6800 XT from using exactly the same framegen?\n\n\nLol indeed. Someone clearly doesn't know anything about critical thinking.\n\n```\nRX 6800 XT under the same settings\n```",
      "Hell yeah, shame OP, shame!",
      "\"The[¬†leaked benchmarks](https://x.com/GawroskiT/status/1896838352844026103)¬†seem to come from the Chinese forum Chiphell but were posted on X by tech enthusiast Tomasz Gawro≈Ñski, who showed the RX 9070 XT reportedly being 263% faster, delivering 69 FPS compared to just 19 FPS on the RX 6800 XT under the same settings. **The test was conducted at 4K resolution with** ***cinematic ray tracing*****, frame generation, and FSR set to 50%, making it a demanding scenario that favors the**¬†[**improved ray tracing of RX 9000 series GPUs**](https://www.pcguide.com/news/significant-gen-over-gen-gains-in-rt-titles-amd-claim-2x-rt-performance-in-9000-series-gpu-lineup/)**.\"**\n\nIt's with RT on. It's just expected.\n\nhttps://i.redd.it/50b4biez1qme1.gif",
      "Exactly, and unlike Nvidia, AMD never claimed this",
      "based on steve's review from GN on the 5070, everyone should wait a day before making a decision and he kept referencing how the 7900XT was beating the 5070 in too many situations even some with RT but who knows what that was about.",
      "Yeah, my criticism isn't with AMD, it's the author of the article."
    ]
  },
  {
    "brand": "amd",
    "generation": "9000",
    "tier": "mid",
    "matched_keywords": [
      "rx 9070 xt",
      "9070 xt",
      "9070",
      "rx 9070"
    ],
    "title": "Nvidia in Trouble? The RX 9070 XT has great potential",
    "selftext": "",
    "comments": [
      "\"abysmal\" => 400fps",
      "Def glad AMD has improved the RT performance so much.",
      "Bro the cats are adorable",
      "This would be a huge, huuuuuuuge increase from a 6700 xt",
      "Imagine what a 9090 XTX could have been (could be?)",
      "It's an obvious driver bug. No way it can be lower than GRE version",
      "Definitely would've bought a 9090 XT for like $1000. Sucks that AMD picked a bad time to dip out of the high end GPU market. 9070 XT is nice but basically a side grade  from my current card or even a downgrade in some aspects. A 9090 XT with raster better than 5080 and RT close at $1000 would've done well in the current market.",
      "Lol",
      "My guess is UDNA does high end next year, and they also keep 9070XT and lower going.  That'll be 4nm 9070XT and lower, with UDNA series being 3nm and top end.  Just a guess.",
      "Big difference between the edge and hotspot temp on that XFX card (25c). It will be interesting to see if that's normal for this gen. I don't recall any reviewers complaining about instability so it's probably fine but just something to note.\n\nGood to see AMD offering a more rounded gaming package with this GPU. Fingers crossed that stocks are good and many people have a good experience with it.\n\nEdit: Update: It looks like that difference between edge and hotspot is normal. Hardware unboxed had some different models in their review and they ranged from 18-25c difference.",
      "On new GPU architectures outliers on embargo day are pretty common. They are technically pre release drivers after all.\n\nMost likely this will be fixed on a possible day one driver or in the following week.",
      "If it's an obvious outlier, it will likely be fixed via drivers.",
      "Maybe this guy should check European prices before declaring Nvidia in trouble. 900$ for 9070 in Norway and Nitro + only 70$ cheaper then 5070ti. Not even 9070xt fucking ordinary 9070 that were suppose to be 549 plus tax.",
      "Developing high end parts costs money that they may not recoup. I think they're able to price the midrange parts aggressively due to forgoing the high end ones. It sucks but it is what it is.",
      "AMD has had plenty of potential past 2 generations.",
      "Praying they make high end if this gen gets well received",
      "Screw it. I‚Äôm buying a 9070 XT tomorrow and putting it in my new build. Then when (if) the 5090 issues are resolved and stock is available I‚Äôll buy one and put that in the new build.\n\nThen the 9070 XT will go in my old build to replace the 3080 and become my bedroom 4k TV gaming rig.",
      "Huh? The release is today? So you're saying the drivers they have had are different than drivers actual players get today? And were this the case, it's not to blame AMD?",
      "I mean I made the comment at like 2pm on embargo day lol. But it's definitely a scope thing, amd can't be expected to hit the mark on 100% sable drivers in every game.\n\nAnd I was just speculating, typically a driver release happens day one of purchase. So \"pre release\" isn't untrue.\n\nI'm not saying they aren't to blame but you kinda just have to look at the bigger picture of \"new GPU architecture, millions of games\" picking up what I'm laying down?",
      "Yes it's possible that game might have something related to their drivers.\n\nI meant, that say they give reviewers a week to do their tests, then as the release is one day after the reviews are out, 8 days is not really much time to improve the drivers."
    ]
  },
  {
    "brand": "amd",
    "generation": "9000",
    "tier": "mid",
    "matched_keywords": [
      "9070",
      "rx 9070"
    ],
    "title": "AMD Radeon RX 9070 (XT) \"RDNA4\" Graphics Cards Review Roundup",
    "selftext": "",
    "comments": [
      "Hey OP ‚Äî /r/AMD is in manual approval mode, this means **all submissions are automatically removed and must first be approved before they are visible to others**. This is done to prevent spam, scams, excessive self-promotion and other rule-breaking posts.\n\nYour post will be approved, provided it follows the subreddit [rules](https://www.reddit.com/r/Amd/about/rules/).\n\n**Posts regarding purchase advice, PC build questions or technical support will not be approved.** If you are looking for purchasing advice, have a PC build question or technical support problem, please visit the [Q1 2025, PC Build Questions, Purchase Advice and Technical Support Megathread](https://www.reddit.com/r/Amd/comments/1hqs820/pc_build_questions_purchase_advice_and_technical/).\n\n\n*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/Amd) if you have any questions or concerns.*"
    ]
  },
  {
    "brand": "amd",
    "generation": "9000",
    "tier": "mid",
    "matched_keywords": [
      "rx 9070 xt",
      "9070 xt",
      "9070",
      "rx 9070",
      "rx9070",
      "rx9070xt"
    ],
    "title": "Introducing the ASUS Radeon RX 9070 XT and RX 9070 TUF Gaming and Prime Graphics cards with Phase Change Thermal Pads, HDMI/Display Port 2.1, Triple Axial Fans, Dual-BIOS Performance/Quiet Profiles and GPU Tweak III",
    "selftext": "https://preview.redd.it/rd50e2ifrvle1.png?width=1920&format=png&auto=webp&s=07a9a0bdf823e033da1e308433fe615be7fa0f0d\n\nThe latest generation of AMD graphics cards is now upon us. If you've recently upgraded your motherboard to one of our new X870 or recently launched B850 or B840 motherboards, you might feel like it's time to continue the AMD trend and upgrade your graphics card.¬†\n\nFor those who are less familiar with the new cards, here are the new main features:¬†¬†\n\n* The new RDNA 4 architecture¬†¬†\n* 16GB GDDR6 VRAM¬†\n* Next-gen HYPR-RX tech delivers ultra-fast gaming¬†¬†\n* New AMD AI-powered technologies, including an improved experience with ray-tracing.¬†\n* Machine-learning based super resolution mode compatible with select FSR 3.1 games provide an incredible balance of detailed images and fluid frame rates.¬†\n* DisplayPort 2.1 outputs give users massive bandwidth for going big on resolution while supporting high-end refresh rates¬†\n\nOn the ASUS side, we've implemented a number of new changes to our cooling design, PCB design, and optional software:\n\n**Phase-Change Thermal Pads Provide a Long-Lasting Cooling Experience**¬†\n\nOne new change for our graphics cards this year is that we're switching from standard thermal paste used on the GPU and thermal module to phase-change thermal pads.¬†\n\nWhen transferring heat, the electrically non-conductive pad is a solid at room temperature but liquifies as it heats up. As it melts, it fills the microscopic gaps between the GPU and thermal module, providing superior thermal conductivity and enhanced heat dissipation, ensuring optimal performance, even for sustained, heavy GPU workloads.¬†¬†¬†\n\nAdditionally, the phase-change thermal pads offer exceptional longevity. They outlast traditional pastes by a significant margin, even for graphics cards that see heavy workloads on a regular basis.¬†¬†\n\n**ASUS GPU Tweak III Software** \\- Some gamers prefer to tune their graphics cards for all-out performance, while others insist on quiet operation. A physical Dual BIOS switch lets users choose between performance and quiet modes without installing additional software. For more performance-tuning options, easy hardware monitoring and granular control of fan behavior, users can download the free ASUS GPU Tweak III software.¬†\n\n**ASUS GPU Guard & Bracket\\*** \\- ASUS GPU Guard applies adhesive to secure all four corners to reduce the risk of cracks, while a GPU bracket helps ensure uniform mounting pressure and extra stability.¬†\n\n**Protective PCB Coating\\*** \\- A protective conformal coating envelops the circuit board to help protect against short-circuits caused by moisture, dust or debris.¬†\n\n\\*Available only on the TUF Gaming Radeon RX 9070 XT and RX 9070 cards¬†\n\n**TUF Gaming Radeon RX 9070 XT OC Edition and TUF Gaming Radeon RX 9070 OC Edition**¬†\n\nhttps://preview.redd.it/4zxtc3j5nvle1.jpg?width=4160&format=pjpg&auto=webp&s=12bb410662c4cb748df61dacfc3650076364fd11\n\nTUF Gaming graphics cards utilize an unassuming style that fits in easily with just about any components on the market. For the TUF Gaming Radeon RX 9070 XT and RX 9070, ASUS has retained the classic ruggedized aesthetic of the series. An illuminated TUF Gaming logo on the corner of the card provides a touch of personalization, and it supports ASUS Aura Sync so users can coordinate its lighting with the rest of their compatible gear.¬†\n\nThe TUF Gaming design for this series delves deep into the standard excellent cooling that a TUF Gaming card provides and makes sure that gamers are well equipped in case they want to adjust their cooling or performance characteristics.¬†¬†\n\nThese cards sport the typical metal exoskeleton for structural rigidity that the TUF Gaming cards are known for. Wide vents on the aluminum backplate allow heat to exhaust into the main airflow channel of your chassis. It wouldn't be a TUF Gaming card if it didn't include military-grade components for solid power delivery and long lifespan, or a PCB coating to protect it against short-circuits caused by moisture, dust, or debris.¬†¬†\n\nTUF Gaming Radeon RX 9070 XT and RX 9070 cards feature:¬†\n\n* 3.125-slot design with a vented exoskeleton and massive fin array optimized for airflow from three Axial-tech fans¬†\n* Three eleven-blade Axial-tech fans maintain a steady high-pressure stream of cooling through a massive airflow-optimized fin array.¬†¬†\n* Dual-ball fan bearings last up to twice as long as conventional sleeve-bearing designs.¬†\n* 0dB technology allows the fans to turn off at low workloads and effectively become silent.¬†\n* Dual BIOS switch to toggle between Performance and Quiet BIOS profiles.¬†\n* ASUS GPU Guard and bracket secure the GPU, reducing the risk of cracks and ensuring stable mounting¬†\n* Subtle RGB lighting on the TUF Gaming logo on the corner of the card can be configured through Aura Sync¬†\n* GPU Tweak III software is free to monitor and configure your graphics card. The software now integrates the HW Info plug-in so you can keep an eye on your graphics card and just about anything else in your system.¬†\n\nhttps://preview.redd.it/bl4k27m3nvle1.jpg?width=7344&format=pjpg&auto=webp&s=8d3dabfa8757cbdf56a0956b720844daa9aae3c0\n\n**Pricing and Availability -**¬†\n\nPricing ‚Äì \n\n* TUF Gaming Radeon RX 9070 XT OC Edition 16GB GDDR6 - $799.99\n* TUF Gaming Radeon RX 9070 OC Edition 16GB GDDR6 - $709.99\n\nAvailability ‚Äì On-Shelf March 6 at 6AM PT¬†\n\nProduct Page - ¬†\n\n* TUF Gaming Radeon RX 9070 XT OC Edition 16GB GDDR6 - [https://asus.com/motherboards-components/graphics-cards/tuf-gaming/tuf-rx9070xt-o16g-gaming/](https://asus.com/motherboards-components/graphics-cards/tuf-gaming/tuf-rx9070xt-o16g-gaming/)¬†\n* TUF Gaming Radeon RX 9070 OC Edition 16GB GDDR6 - [https://asus.com/motherboards-components/graphics-cards/tuf-gaming/tuf-rx9070-o16g-gaming/](https://asus.com/motherboards-components/graphics-cards/tuf-gaming/tuf-rx9070-o16g-gaming/)¬†\n\n**ASUS Prime Radeon RX 9070 XT OC Edition and Prime Radeon RX 9070 OC Edition**¬†\n\nhttps://preview.redd.it/vl3o6xsmnvle1.jpg?width=7667&format=pjpg&auto=webp&s=a22553134cc5d2da72fe23dcaf8c3c3da05ef4ee\n\nASUS Prime graphics cards were a new addition to our lineup last year. Packing performance and cooling into a compact 2.5 slot frame, these cards help ensure compatibility with more cases. Building a card this size that can handle the demands of long hours of gaming requires attention to a number of important details.¬†\n\nTo make sure they offer excellent cooling performance compatible with a number of compact cases, Prime series cards use three Axial-tech fans, similar to the fans we use on our top-end graphics cards - but use a smaller fan hub that allows for longer fan blades. We then surround the fans in a barrier ring to increase downward pressure. The card also features:¬†\n\n* Dual-ball fan bearings last up to twice as long as conventional sleeve-bearing designs.¬†\n* 0dB technology to turn the fans off below 50C, and turn the fans back on at 55C with a speed curve optimized for cooling and noise.¬†\n* Phase-change GPU thermal pads for optimal heat transfer and long-term reliability.¬†\n* 2.5-slot design allows for greater build compatibility while maintaining cooling performance¬†\n* Dual-BIOS switch that allows you to switch fan profiles between Performance and Quiet BIOS profiles.¬†\n* Aluminum protective backplate to protect the card and provide structural integrity¬†\n* GPU Tweak III software is free to monitor and configure your graphics card. The software now integrates the HW Info plug-in so you can keep an eye on your graphics card and just about anything else in your system.¬†\n\nhttps://preview.redd.it/qm8x0o43ovle1.png?width=2400&format=png&auto=webp&s=c3638dcb9517bb2e28579474545c0b38d415acbe\n\n**Pricing and Availability -**¬†\n\nPricing ‚Äì \n\n* ASUS Prime Radeon RX 9070 XT OC Edition - $719.99\n* ASUS Prime Radeon RX 9070 OC Edition - $659.99\n\nAvailability ‚Äì On-Shelf March 6 at 6AM PT¬†\n\nProduct Page - ¬†\n\n* ASUS Prime Radeon RX 9070 XT OC Edition - [https://asus.com/motherboards-components/graphics-cards/prime/prime-rx9070xt-o16g/](https://asus.com/motherboards-components/graphics-cards/prime/prime-rx9070xt-o16g/)¬†\n* ASUS Prime Radeon RX 9070 OC Edition - [https://asus.com/motherboards-components/graphics-cards/prime/prime-rx9070-o16g/](https://asus.com/motherboards-components/graphics-cards/prime/prime-rx9070-o16g/)¬†\n\nFAQ -¬†\n\nQ. Will there be other models than TUF Gaming and Prime?  \nA. No plans to offer additional models at this time.\n\nQ. Where will we be able to purchase these cards?  \nA. Although we don‚Äôt yet have final confirmation of Day 1 availability, these are the locations that are expected to have the cards:¬†¬†\n\n* US ‚Äì Amazon, Newegg, Microcenter, ASUS eShop, Central Computer¬†\n* CA ‚Äì Canada Computers, Best Buy (CA)¬†\n\nThis is what we can share for now, as we'll update pricing and availability when they become available. Let us know what you think.¬†\n\n  \nEdit (3/6) - Added card pricing.",
    "comments": [
      "how can we let you know what we think when you've yet to provide pricing",
      "I still remember that Asus was the highest official scalper during the pandemic, if there is an option this is the brand I'd never buy again in my life.\n\n[https://imgur.com/a/Tb8l9Sc](https://imgur.com/a/Tb8l9Sc)",
      "Fair enough, but the pricing isn't available for me to post yet. The post will be updated as soon as I receive it.",
      "You forgot to add the ASUS tax. They haven't posted the pricing yet because they're still trying to figure out what they can get away with.",
      "LMAO price TBD, so with an MSRP $150 cheaper than the 5070 ti, watch all the AIBs fuck this up and price the 9070 XT similar to the prices of 5070 ti at $800 +",
      "With Asus antics with the 50 series cards. I'll not be buying any cards from Asus.\n\n\nThey are one of the reasons everything is so inflated.",
      "Great point. I still haven't finished my first cup of coffee. Overall:\n\n1x HDMI 2.1 and 3x DP2.1a ports for all cards.\n\nhttps://i.redd.it/0yra55jrxvle1.gif",
      "If it's the usual Asus outrageously above MSRP we'll just buy another brand. You think you can at least keep these reasonably priced?",
      "You can always bet on Asus being the most expensive of the bunch",
      "What's the advantage of GPU Tweak III when I can do the tweaking in the actual AMD Adrenaline software?",
      "They don't receive the GPUs at MSRP lol. They receive them cheaper so they can sell them at MSRP, unless it's some special edition.",
      "Asus won‚Äôt charge this price. They have to worry about materials+R&D for their own coolers, overclocks, etc.",
      "bro, but the offer code discount! /s",
      "have you looked at the 5000 series prices?  theyre charging almost +75% for the 5090 astral LC cards ($3400).  asus pricing for this gen are out of this world.",
      "All those pics and none of the io...",
      "In fairness, our ProArt designs make a lot of products look like they could use some improvement, so I understand where you're coming from there.",
      "True, they're the ones that ended up in the \"is it an MSRP model or not?\" mess before the 5070 Ti launched.",
      "No Strix, no Asus.",
      "why u wanna pay abhorrent prices for maybe 1% extra performance?",
      "Yeah they are coming in with inflated price, then others aib follows. F off asus!"
    ]
  },
  {
    "brand": "amd",
    "generation": "9000",
    "tier": "mid",
    "matched_keywords": [
      "rx 9070 xt",
      "9070 xt",
      "9070",
      "rx 9070"
    ],
    "title": "Got a 9070 XT and decided to upgrade everything else to AM5",
    "selftext": "Last two pictures are my old build with a 4070 and 5800X3D\n\nUpgrades:\n\nASRock Steel Legend RX 9070 XT\n\nASUS Prime X670E-PRO WiFi\n\nRyzen 7 9800X3D\n\nTEAMGROUP T-Force Delta DDR5 32GB 6000MHz CL30 RAM",
    "comments": [
      "While im happy for you op, that doesn't seem like the kind of upgrade worth spending that much money on by a long shot",
      "Have you noticed a big performance upgrade? I keep thinking about doing this if I ever find a 9070XT",
      "Not op but I had a 7800xt and I sold it because at 1440p It was bottlenecking my fps in my favorite game rn which is helldivers 2. When I upgraded, my cpu is now the bottleneck (5800x3d). I actually\nUsed to get occasional frame hitching on my 7800xt but now it‚Äôs completely gone with the new card",
      "I just did a similar update except I already had my GPU and it was worth it. Selling off the old AM4 parts will recoup cost.",
      "That's probably in like another 3 years though.",
      "honestly the CPU upgrade IS worth it since the 9800X3D is just *that* good\n\nwait, do 40 series GPU's go for MSRP used? that's insane",
      "I went from zen 2 (3900x) to zen 4 x3d (7950x3d) huge jump for me without a GPU upgrade for productivity.",
      "I've noticed a very big difference going 5800X3D to 9800X3D don't forget the change is also moving from DDR4 to DDR5. You are also looking at like a 40% increase in Single threaded performance.",
      "If he sells the CPU, GPU and motherboard he will probably make up for most of what he spent on the upgrade. 40 series GPU's go for about MSRP right now and the 5800x3d is about $300. Good X570 boards also sell for a pretty penny as well",
      "Makes sense, I noticed a lot of improvement going strictly from 6900 XT to 9070 XT.  Still on the 5800 X3D.",
      "I did 6800xt to 7900xtx which was about a 50% performance improvement and should be similar with your jump i felt that also on the 5800X3D it was nice.",
      "I guess that would depend on how long you've been due for an upgrade? Can you play the games you want to play or basically use your computer the way you want to? I'm upgrading after like 7-8 years.",
      "Awesome dude! I did something very similar.  Sold my 5700x3d 4070super mini itx pc for $250 more than it cost me to build 5 months ago and just built a mini itx am5 ryzen 7500f with 9070xt for Less than what I sold my old pc for.",
      "tbh i mostly meant the GPU in OP's case, pretty much anything that isn't a 7800X3D is worth upgrading to a 9800X3D given the latters performance hardly even bottlenecks a 5090",
      "So I was actually thinking about switching to AM5 in the next couple months; Is that gonna be worth my time/investment if AM6 is three years out? Should I just wait? I very rarely make huge upgrades to my rig beyond switching out GPU, RAM, etc. A new motherboard and processor is a big purchase for me.",
      "Doesn‚Äôt matter the far end is gonna be heavy so better safe than sorry",
      "gpu market is completely fucked nowadays. I saw someone selling 1 year 4080 super for 1.2k euros in EU, before they removed them from stores it costed \\~1.4k",
      "Didn‚Äôt know the steel legend looked this clean",
      "Rich! Millionaire! \n\nGood looking build",
      "I did the same and spent 5 hours building it and ended up my system not going post‚Ä¶ apparently my cpu socket was damaged‚Ä¶"
    ]
  },
  {
    "brand": "amd",
    "generation": "9000",
    "tier": "mid",
    "matched_keywords": [
      "rx 9070 xt",
      "9070 xt",
      "9070",
      "rx 9070"
    ],
    "title": "ASUS implements another price hike for GeForce RTX 5090 cards, RX 9070 XT now stars at $720",
    "selftext": "",
    "comments": [
      "This is why you don't buy ASUS. I had an opportunity to buy an ASUS XT at $600 and steered clear toward another vendor.",
      "Simple solution, buy anything but Asus atp",
      "When buying amd  card, only buy from sapphire, xfx and powercolor...",
      "asrock is fine",
      "Don't you mean ROG (Republic of Greed)",
      "Another fall of a once great Republic (of Gamers), RIP",
      "You can't stop me from buying Yeston",
      "Ripping off gamers",
      "Their bloatware crap that you have to use programs to remove or manually investigate the registry is asinine. \n\nI‚Äôll never buy another Asus product.",
      "Waifu cards are the best cards",
      "Has any economist done a writeup on the discrete GPU market? \n\nit's wild how expensive the top of the market has gotten while the bottom of the market has virtually disappeared.\n\nBy all accounts most consumers still appear to be price conscious, but prices keep running away even while there is more competition than ever.",
      "This is what happens when manufacturers finds out people will pay whatever for something. The prices most likely will go up even more and people will still buy ALL GPUs.",
      "They are literally all doing it, because in the US‚Ä¶ TARIFFS! And then they use that as an excuse to charge everyone high prices",
      "Bought an asrock steel legend cause that‚Äôs all microcenter had in stock at msrp by the time I got in. It‚Äôs such a good card. I was pleasantly surprised.",
      "HDMI was a mistake. I wish we had replaced it with DP a long time ago. At least it's caught up enough in bandwidth now though that they're both mostly interchangeable.",
      "Yeah. Why would your GPU need iCue?",
      "> iCue doesn't have integration for either of those. Or for AMD in general.\n\nOkay and?",
      "Well, as annoying as this may seem. From a business standpoint. If their inventory sells out completely with each wave they release. Why would they not? \n\nI'm just playing devils advocate here. If their focus is making profit. Then why would they not do this?",
      "And of course, the real reason is because $700+ for a 9070 and $800+ for a 9070 XT is still gonna be sold out for months.\n\nThe biggest issue is that B100 is sold out through 2025 and beyond and it uses the same die space/node process (IIRC) as a 5090.\n\nShort of Nvidia or AMD releasing some kind of 3nm refresh of their cards this year that doesn't ALSO slam into a different datacenter AI card (or a metric truckload of Apple orders), I'm not sure we have a good solution for this problem. Everyone is fighting for the same die space and one use case has 10-30x the retail value as the others.",
      "I think its because for as much as they can make on the low end, the high end is where the biggest profit margins are. For every $2000 card they sell it probably brings in more money than 10 $400 cards do. And since scalpers will always buy stuff up to resell for more, they dont care. I think eventually this won't be able to be sustained, and we will see a considerable readjustment. But while the money is flowing, they will keep selling at these huge prices."
    ]
  },
  {
    "brand": "amd",
    "generation": "9000",
    "tier": "mid",
    "matched_keywords": [
      "9070",
      "rx 9070"
    ],
    "title": "AMD reportedly preparing Radeon RX 9070 GRE - VideoCardz.com",
    "selftext": "",
    "comments": [
      "The GRE nomenclature feels like a weird meme that AMD hasn't quite realized is played-out.",
      "This product doesn't make sense. The 9xxx series is selling just fine as it is. Or is this just a tactic to break into the Chinese market, which is far more intertwined with Nvidia than the rest of the world? \n\nIt doesn‚Äôt make sense either; Nvidia isn‚Äôt supplying enough stock, and AMD would sell out just as easily there.",
      "I assume that, at some point, the market will be saturated with the Radeon RX 9070/9070 XT.\n\nAMD can then sell the Radeon RX 9070 GRE as the cheaper equivalent to the GeForce RTX 5070.",
      "Should be Golden Snake Edition for 2025!",
      "> 12 GB up against 5060 Ti 16 GB will be a joke.\n\nThe GeForce RTX 5070 also has 12 GB VRAM.",
      "The way the world is going, this is a very distant future.",
      "Is there enough room between a 9060 xt and a 9070 for another product?  there's not pricing space in-between the 9070 and 9070 xt.\n\nWould this just be navi 48 dies that didn't make the cut as 9070 vanillas?  That would say pretty bad things about AMD's yield.",
      "I mean, the 7900GRE got a lot of mindshare, it makes sense for them to keep the name",
      "It's about cutting down the memory controller too when damaged.  Those defective dies get to be reused and return a profit instead of thrown away into into the silicon recycling bin.  This has been done with so many generations now I don't understand how you think this is anything new.",
      "Instead however AMD changed it to mean \"Great Radeon Edition\" Instead, no joke, that's what they did to justify keeping GRE naming.",
      "Since AMD typically offers a 20% discount to NVIDIA, and the GeForce RTX 5070 is priced at $549, I estimate that the Radeon RX 9070 GRE will be approximately $439 (if AMD decides to release it).\nÔªø\nÔªøThis is, of course, excluding tariffs.",
      "I don't think it's as far as people fear. The Micro Center closest to me (3+ hours away) went through all of its hundreds of 9070 cards at launch. There was one model that restocked about half a dozen units a couple of weeks ago, and they lasted at least a few hours.\n\nThis week, XFX restocked a couple of their models, which are all unbelievably overpriced (starts at $830). The 6 cards they got in ($850 Swifts in white) didn't even sell out. 5 of them moved that first day. The next day, the site listed that last Swift and 1 Quicksilver ($890, also in white) in stock. Those TWO cards lasted most of the day.\n\nIt's clear that the demand for these overpriced models has already diminished notably. Even some of the $700-750 models aren't disappearing from online restocks immediately, and there are some of those crappy Newegg bundles that last 1-2 days.",
      "But apparently it's the Wood/Green Snake year, not Metal or Earth element years.",
      "There's gonna be a massive gap in AMD's lineup between the 9070 and 9060 XT, price-wise. This would help fill it.",
      "The supply of 9070 is apparently low due to good 9070 XT yields, so what's the point of this card? 12 GB up against 5060 Ti 16 GB will be a joke.",
      "In my country, 9070 XT cheapest is 962‚Ç¨ and 5070 Ti cheapest is 1003‚Ç¨. 5070 Ti makes more sense in my country and people are buying 5070 Ti over 9070 XT considering the price difference. Don‚Äôt think a single 9070 XT has been sold so far and stock is there. 3 of my friends so far bought 5070 Ti over 9070 XT.",
      "Is that because of the name or because it just happened to be a good value sku?",
      "This generation is likely to last two years.\n\nDemands for the Radeon RX 9070/9070 XT will likely be met by then.",
      "The irony of saying someone's dishonest for giving a piece of information, while providing no additional information whatsoever, is so preposterously stupid that I don't even know how to take it seriously.\n\nAll you said was it's foolish to cite Micro Center, then call it dishonest when I add Best Buy and Newegg...all while saying nothing yourself. I'm thinking maybe you're the dishonest one and just being a pedantic contrarian because it's the only way you can find anything to say.",
      "They're great cards at $600 but I'd pick a 5070ti if it's within $100 of the 9070XT.  A case can be made for the $700-$750 models but I don't think the $800+ models make sense."
    ]
  }
]