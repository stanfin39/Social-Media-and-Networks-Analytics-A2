{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e6aa74aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 1\n",
    "%aimport redditClient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "283f4b1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "\n",
    "from redditClient import redditClient\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "959dc6c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "nvidiaFileName = \"nvidia.graphml\"\n",
    "amdFileName = \"amd.graphml\"\n",
    "intelFileName = \"intel.graphml\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8373f667",
   "metadata": {},
   "outputs": [],
   "source": [
    "client = redditClient()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "4cfecdc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "subreddits_nvidia = client.subreddit(\"nvidia+graphicscard+gpu+buildapc\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "5333030f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# gpu_keywords_nvidia = {\n",
    "#     \"rtx 4060\": (\"nvidia\", \"low\"),\n",
    "#     \"rtx 4070\": (\"nvidia\", \"mid\"),\n",
    "#     \"rtx 4070 super\": (\"nvidia\", \"mid\"),\n",
    "#     \"rtx 4070 ti super\": (\"nvidia\", \"mid\"),\n",
    "#     \"rtx 4080\": (\"nvidia\", \"high\"),\n",
    "#     \"rtx 4090\": (\"nvidia\", \"high\")\n",
    "# }\n",
    "\n",
    "# search_phrases_nvidia = []\n",
    "# for gpu in gpu_keywords_nvidia.keys():\n",
    "#     search_phrases_nvidia += [f\"{gpu} review\", f\"{gpu} launch\"]\n",
    "\n",
    "from itertools import product\n",
    "\n",
    "gpu_keywords_nvidia = {\n",
    "    \"rtx 4060\": (\"nvidia\", \"low\")\n",
    "#     \"rtx 4070\": (\"nvidia\", \"mid\"),\n",
    "#     \"rtx 4070 super\": (\"nvidia\", \"mid\"),\n",
    "#     \"rtx 4070 ti super\": (\"nvidia\", \"mid\"),\n",
    "#     \"rtx 4080\": (\"nvidia\", \"high\"),\n",
    "#     \"rtx 4090\": (\"nvidia\", \"high\")\n",
    "}\n",
    "\n",
    "contexts = [\"\", \"review\", \"launch\", \"performance\", \"benchmarks\", \"gaming\", \"issues\", \"worth it\", \"upgrade\", \"vs\"]\n",
    "\n",
    "search_phrases_nvidia = [f\"{gpu} {ctx}\".strip() for gpu, ctx in product(gpu_keywords_nvidia.keys(), contexts)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "fa648b4d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['rtx 4060',\n",
       " 'rtx 4060 review',\n",
       " 'rtx 4060 launch',\n",
       " 'rtx 4060 performance',\n",
       " 'rtx 4060 benchmarks',\n",
       " 'rtx 4060 gaming',\n",
       " 'rtx 4060 issues',\n",
       " 'rtx 4060 worth it',\n",
       " 'rtx 4060 upgrade',\n",
       " 'rtx 4060 vs']"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "search_phrases_nvidia"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d9ff494",
   "metadata": {},
   "source": [
    "## Nvidia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "4896dcc6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç Processing search: rtx 4060\n",
      "üîç Processing search: rtx 4060 review\n",
      "üîç Processing search: rtx 4060 launch\n",
      "üîç Processing search: rtx 4060 performance\n",
      "üîç Processing search: rtx 4060 benchmarks\n",
      "üîç Processing search: rtx 4060 gaming\n",
      "üîç Processing search: rtx 4060 issues\n",
      "üîç Processing search: rtx 4060 worth it\n",
      "üîç Processing search: rtx 4060 upgrade\n",
      "üîç Processing search: rtx 4060 vs\n",
      "‚úÖ Graph saved with 5521 nodes and 9587 edges.\n"
     ]
    }
   ],
   "source": [
    "replyGraph = nx.DiGraph()\n",
    "dSubCommentId = {}\n",
    "seen_ids = set()\n",
    "\n",
    "for phrase in search_phrases_nvidia:\n",
    "    print(f\"üîç Processing search: {phrase}\")\n",
    "\n",
    "    for submission in subreddit.search(query=phrase, sort=\"relevance\", time_filter=\"all\", limit=20):\n",
    "        if submission.id in seen_ids or not submission.author:\n",
    "            continue\n",
    "        seen_ids.add(submission.id)\n",
    "\n",
    "        author_name = submission.author.name\n",
    "        replyGraph.add_node(author_name, subNum=1)\n",
    "        dSubCommentId[submission.id] = author_name\n",
    "\n",
    "        try:\n",
    "            submission.comments.replace_more(limit=None)\n",
    "            all_comments = submission.comments.list()\n",
    "\n",
    "    \n",
    "            sorted_comments = sorted(\n",
    "                [c for c in all_comments if c.author],\n",
    "                key=lambda x: x.score,\n",
    "                reverse=True\n",
    "            )[:200]\n",
    "\n",
    "            # First pass: index authors\n",
    "            for comment in sorted_comments:\n",
    "                dSubCommentId[comment.id] = comment.author.name\n",
    "\n",
    "            # Second pass: add edges\n",
    "            for comment in sorted_comments:\n",
    "                parent_id = comment.parent_id.replace(\"t1_\", \"\").replace(\"t3_\", \"\")\n",
    "                if parent_id in dSubCommentId:\n",
    "                    src = comment.author.name\n",
    "                    tgt = dSubCommentId[parent_id]\n",
    "\n",
    "                    if src not in replyGraph:\n",
    "                        replyGraph.add_node(src, subNum=0)\n",
    "                    if tgt not in replyGraph:\n",
    "                        replyGraph.add_node(tgt, subNum=0)\n",
    "\n",
    "                    if replyGraph.has_edge(src, tgt):\n",
    "                        replyGraph[src][tgt]['replyNum'] += 1\n",
    "                    else:\n",
    "                        replyGraph.add_edge(src, tgt, replyNum=1)\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Skipped submission {submission.id} due to error: {e}\")\n",
    "\n",
    "        time.sleep(3)  # Avoid rate limit\n",
    "\n",
    "# --- Save graph ---\n",
    "nx.write_graphml(replyGraph, \"search_reply_graph_4.graphml\")\n",
    "print(f\"Graph saved with {len(replyGraph.nodes)} nodes and {len(replyGraph.edges)} edges.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "7994f340",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2ND ONE \n",
    "\n",
    "from itertools import product\n",
    "\n",
    "gpu_keywords_nvidia = {\n",
    "#     \"rtx 4060\": (\"nvidia\", \"low\")\n",
    "#     \"rtx 4070\": (\"nvidia\", \"mid\"),\n",
    "#     \"rtx 4070 super\": (\"nvidia\", \"mid\"),\n",
    "    \"rtx 4070 ti super\": (\"nvidia\", \"mid\")\n",
    "#     \"rtx 4080\": (\"nvidia\", \"high\"),\n",
    "#     \"rtx 4090\": (\"nvidia\", \"high\")\n",
    "}\n",
    "\n",
    "contexts = [\"\", \"review\", \"launch\", \"performance\", \"benchmarks\", \"gaming\", \"issues\", \"worth it\", \"upgrade\", \"vs\"]\n",
    "\n",
    "search_phrases_nvidia_1 = [f\"{gpu} {ctx}\".strip() for gpu, ctx in product(gpu_keywords_nvidia.keys(), contexts)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "a6657daf",
   "metadata": {},
   "outputs": [],
   "source": [
    "del replyGraph \n",
    "del dSubCommentId"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "bada116a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç Processing search: rtx 4070 ti super\n",
      "üîç Processing search: rtx 4070 ti super review\n",
      "üîç Processing search: rtx 4070 ti super launch\n",
      "üîç Processing search: rtx 4070 ti super performance\n",
      "üîç Processing search: rtx 4070 ti super benchmarks\n",
      "üîç Processing search: rtx 4070 ti super gaming\n",
      "üîç Processing search: rtx 4070 ti super issues\n",
      "üîç Processing search: rtx 4070 ti super worth it\n",
      "üîç Processing search: rtx 4070 ti super upgrade\n",
      "üîç Processing search: rtx 4070 ti super vs\n",
      "‚úÖ Graph saved with 4517 nodes and 7570 edges.\n"
     ]
    }
   ],
   "source": [
    "replyGraph = nx.DiGraph()\n",
    "dSubCommentId = {}\n",
    "seen_ids = set()\n",
    "\n",
    "for phrase in search_phrases_nvidia_1:\n",
    "    print(f\"üîç Processing search: {phrase}\")\n",
    "\n",
    "    for submission in subreddit.search(query=phrase, sort=\"relevance\", time_filter=\"all\", limit=20):\n",
    "        if submission.id in seen_ids or not submission.author:\n",
    "            continue\n",
    "        seen_ids.add(submission.id)\n",
    "\n",
    "        author_name = submission.author.name\n",
    "        replyGraph.add_node(author_name, subNum=1)\n",
    "        dSubCommentId[submission.id] = author_name\n",
    "\n",
    "        try:\n",
    "            submission.comments.replace_more(limit=None)\n",
    "            all_comments = submission.comments.list()\n",
    "\n",
    "            # Sort comments by score, descending, and take top 300\n",
    "            sorted_comments = sorted(\n",
    "                [c for c in all_comments if c.author],\n",
    "                key=lambda x: x.score,\n",
    "                reverse=True\n",
    "            )[:200]\n",
    "\n",
    "            # First pass: index authors\n",
    "            for comment in sorted_comments:\n",
    "                dSubCommentId[comment.id] = comment.author.name\n",
    "\n",
    "            # Second pass: add edges\n",
    "            for comment in sorted_comments:\n",
    "                parent_id = comment.parent_id.replace(\"t1_\", \"\").replace(\"t3_\", \"\")\n",
    "                if parent_id in dSubCommentId:\n",
    "                    src = comment.author.name\n",
    "                    tgt = dSubCommentId[parent_id]\n",
    "\n",
    "                    if src not in replyGraph:\n",
    "                        replyGraph.add_node(src, subNum=0)\n",
    "                    if tgt not in replyGraph:\n",
    "                        replyGraph.add_node(tgt, subNum=0)\n",
    "\n",
    "                    if replyGraph.has_edge(src, tgt):\n",
    "                        replyGraph[src][tgt]['replyNum'] += 1\n",
    "                    else:\n",
    "                        replyGraph.add_edge(src, tgt, replyNum=1)\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"‚ö†Ô∏è Skipped submission {submission.id} due to error: {e}\")\n",
    "\n",
    "        time.sleep(3)  # Avoid rate limit\n",
    "\n",
    "# --- Save graph ---\n",
    "nx.write_graphml(replyGraph, \"search_reply_graph_5.graphml\")\n",
    "print(f\"‚úÖ Graph saved with {len(replyGraph.nodes)} nodes and {len(replyGraph.edges)} edges.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "e8dd8e94",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3rd ONE \n",
    "\n",
    "from itertools import product\n",
    "\n",
    "gpu_keywords_nvidia = {\n",
    "#     \"rtx 4060\": (\"nvidia\", \"low\")\n",
    "#     \"rtx 4070\": (\"nvidia\", \"mid\"),\n",
    "#     \"rtx 4070 super\": (\"nvidia\", \"mid\"),\n",
    "    \"rtx 4070 ti super\": (\"nvidia\", \"mid\")\n",
    "#     \"rtx 4080\": (\"nvidia\", \"high\"),\n",
    "#     \"rtx 4090\": (\"nvidia\", \"high\")\n",
    "}\n",
    "\n",
    "contexts = [\"\", \"review\", \"launch\", \"performance\", \"benchmarks\", \"gaming\", \"issues\", \"worth it\", \"upgrade\", \"vs\"]\n",
    "\n",
    "search_phrases_nvidia_2 = [f\"{gpu} {ctx}\".strip() for gpu, ctx in product(gpu_keywords_nvidia.keys(), contexts)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "de555e2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "del replyGraph \n",
    "del dSubCommentId"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "9f72320c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç Processing search: rtx 4070 ti super\n",
      "üîç Processing search: rtx 4070 ti super review\n",
      "üîç Processing search: rtx 4070 ti super launch\n",
      "üîç Processing search: rtx 4070 ti super performance\n",
      "üîç Processing search: rtx 4070 ti super benchmarks\n",
      "üîç Processing search: rtx 4070 ti super gaming\n",
      "üîç Processing search: rtx 4070 ti super issues\n",
      "üîç Processing search: rtx 4070 ti super worth it\n",
      "üîç Processing search: rtx 4070 ti super upgrade\n",
      "üîç Processing search: rtx 4070 ti super vs\n",
      "‚úÖ Graph saved with 4513 nodes and 7561 edges.\n"
     ]
    }
   ],
   "source": [
    "replyGraph = nx.DiGraph()\n",
    "dSubCommentId = {}\n",
    "seen_ids = set()\n",
    "\n",
    "for phrase in search_phrases_nvidia_2:\n",
    "    print(f\"üîç Processing search: {phrase}\")\n",
    "\n",
    "    for submission in subreddit.search(query=phrase, sort=\"relevance\", time_filter=\"all\", limit=20):\n",
    "        if submission.id in seen_ids or not submission.author:\n",
    "            continue\n",
    "        seen_ids.add(submission.id)\n",
    "\n",
    "        author_name = submission.author.name\n",
    "        replyGraph.add_node(author_name, subNum=1)\n",
    "        dSubCommentId[submission.id] = author_name\n",
    "\n",
    "        try:\n",
    "            submission.comments.replace_more(limit=None)\n",
    "            all_comments = submission.comments.list()\n",
    "\n",
    "            # Sort comments by score, descending, and take top 300\n",
    "            sorted_comments = sorted(\n",
    "                [c for c in all_comments if c.author],\n",
    "                key=lambda x: x.score,\n",
    "                reverse=True\n",
    "            )[:200]\n",
    "\n",
    "            # First pass: index authors\n",
    "            for comment in sorted_comments:\n",
    "                dSubCommentId[comment.id] = comment.author.name\n",
    "\n",
    "            # Second pass: add edges\n",
    "            for comment in sorted_comments:\n",
    "                parent_id = comment.parent_id.replace(\"t1_\", \"\").replace(\"t3_\", \"\")\n",
    "                if parent_id in dSubCommentId:\n",
    "                    src = comment.author.name\n",
    "                    tgt = dSubCommentId[parent_id]\n",
    "\n",
    "                    if src not in replyGraph:\n",
    "                        replyGraph.add_node(src, subNum=0)\n",
    "                    if tgt not in replyGraph:\n",
    "                        replyGraph.add_node(tgt, subNum=0)\n",
    "\n",
    "                    if replyGraph.has_edge(src, tgt):\n",
    "                        replyGraph[src][tgt]['replyNum'] += 1\n",
    "                    else:\n",
    "                        replyGraph.add_edge(src, tgt, replyNum=1)\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"‚ö†Ô∏è Skipped submission {submission.id} due to error: {e}\")\n",
    "\n",
    "        time.sleep(3)  # Avoid rate limit\n",
    "\n",
    "# --- Save graph ---\n",
    "nx.write_graphml(replyGraph, \"search_reply_graph_6.graphml\")\n",
    "print(f\"‚úÖ Graph saved with {len(replyGraph.nodes)} nodes and {len(replyGraph.edges)} edges.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8edf04f",
   "metadata": {},
   "source": [
    "# AMD\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "5de78f9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "subreddits_amd = client.subreddit(\"radeon+graphicscard+gpu+buildapc\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "175a6a83",
   "metadata": {},
   "outputs": [],
   "source": [
    "gpu_keywords_amd = {\n",
    "    \"rx 6500 xt\": (\"amd\", \"low\")\n",
    "#     \"rx 7600\": (\"amd\", \"mid\"),\n",
    "#     \"rx 7900 xt\": (\"amd\", \"high\")\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "5631b66d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2ND ONE \n",
    "\n",
    "from itertools import product\n",
    "\n",
    "\n",
    "contexts = [\"\", \"review\", \"launch\", \"performance\", \"benchmarks\", \"gaming\", \"issues\", \"worth it\", \"upgrade\", \"vs\"]\n",
    "\n",
    "search_phrases_amd_1 = [f\"{gpu} {ctx}\".strip() for gpu, ctx in product(gpu_keywords_amd.keys(), contexts)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "d956d0c8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['rx 6500 xt',\n",
       " 'rx 6500 xt review',\n",
       " 'rx 6500 xt launch',\n",
       " 'rx 6500 xt performance',\n",
       " 'rx 6500 xt benchmarks',\n",
       " 'rx 6500 xt gaming',\n",
       " 'rx 6500 xt issues',\n",
       " 'rx 6500 xt worth it',\n",
       " 'rx 6500 xt upgrade',\n",
       " 'rx 6500 xt vs']"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "search_phrases_amd_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "a7226d4d",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'replyGraph' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[137], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mdel\u001b[39;00m replyGraph\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mdel\u001b[39;00m dSubCommentId \n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mdel\u001b[39;00m seen_ids\n",
      "\u001b[1;31mNameError\u001b[0m: name 'replyGraph' is not defined"
     ]
    }
   ],
   "source": [
    "del replyGraph\n",
    "del dSubCommentId \n",
    "del seen_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "419b212a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç Processing search: rx 6500 xt\n",
      "üîç Processing search: rx 6500 xt review\n",
      "üîç Processing search: rx 6500 xt launch\n",
      "üîç Processing search: rx 6500 xt performance\n",
      "üîç Processing search: rx 6500 xt benchmarks\n",
      "üîç Processing search: rx 6500 xt gaming\n",
      "üîç Processing search: rx 6500 xt issues\n",
      "üîç Processing search: rx 6500 xt worth it\n",
      "üîç Processing search: rx 6500 xt upgrade\n",
      "üîç Processing search: rx 6500 xt vs\n",
      "‚úÖ Graph saved with 1638 nodes and 2339 edges.\n"
     ]
    }
   ],
   "source": [
    "replyGraph = nx.DiGraph()\n",
    "dSubCommentId = {}\n",
    "seen_ids = set()\n",
    "\n",
    "for phrase in search_phrases_amd_1:\n",
    "    print(f\"üîç Processing search: {phrase}\")\n",
    "\n",
    "    for submission in subreddits_amd.search(query=phrase, sort=\"relevance\", time_filter=\"all\", limit=20):\n",
    "        if submission.id in seen_ids or not submission.author:\n",
    "            continue\n",
    "        seen_ids.add(submission.id)\n",
    "\n",
    "        author_name = submission.author.name\n",
    "        replyGraph.add_node(author_name, subNum=1)\n",
    "        dSubCommentId[submission.id] = author_name\n",
    "\n",
    "        try:\n",
    "            submission.comments.replace_more(limit=None)\n",
    "            all_comments = submission.comments.list()\n",
    "\n",
    "            # Sort comments by score, descending, and take top 300\n",
    "            sorted_comments = sorted(\n",
    "                [c for c in all_comments if c.author],\n",
    "                key=lambda x: x.score,\n",
    "                reverse=True\n",
    "            )[:200]\n",
    "\n",
    "            # First pass: index authors\n",
    "            for comment in sorted_comments:\n",
    "                dSubCommentId[comment.id] = comment.author.name\n",
    "\n",
    "            # Second pass: add edges\n",
    "            for comment in sorted_comments:\n",
    "                parent_id = comment.parent_id.replace(\"t1_\", \"\").replace(\"t3_\", \"\")\n",
    "                if parent_id in dSubCommentId:\n",
    "                    src = comment.author.name\n",
    "                    tgt = dSubCommentId[parent_id]\n",
    "\n",
    "                    if src not in replyGraph:\n",
    "                        replyGraph.add_node(src, subNum=0)\n",
    "                    if tgt not in replyGraph:\n",
    "                        replyGraph.add_node(tgt, subNum=0)\n",
    "\n",
    "                    if replyGraph.has_edge(src, tgt):\n",
    "                        replyGraph[src][tgt]['replyNum'] += 1\n",
    "                    else:\n",
    "                        replyGraph.add_edge(src, tgt, replyNum=1)\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"‚ö†Ô∏è Skipped submission {submission.id} due to error: {e}\")\n",
    "\n",
    "        time.sleep(3)  # Avoid rate limit\n",
    "\n",
    "# --- Save graph ---\n",
    "nx.write_graphml(replyGraph, \"search_reply_graph_amd_1.graphml\")\n",
    "print(f\"‚úÖ Graph saved with {len(replyGraph.nodes)} nodes and {len(replyGraph.edges)} edges.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "eee58f1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "gpu_keywords_amd = {\n",
    "#     \"rx 6500 xt\": (\"amd\", \"low\")\n",
    "    \"rx 7600\": (\"amd\", \"mid\")\n",
    "#     \"rx 7900 xt\": (\"amd\", \"high\")\n",
    "}\n",
    "\n",
    "\n",
    "from itertools import product\n",
    "\n",
    "\n",
    "contexts = [\"\", \"review\", \"launch\", \"performance\", \"benchmarks\", \"gaming\", \"issues\", \"worth it\", \"upgrade\", \"vs\"]\n",
    "\n",
    "search_phrases_amd_2 = [f\"{gpu} {ctx}\".strip() for gpu, ctx in product(gpu_keywords_amd.keys(), contexts)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "7aa6e187",
   "metadata": {},
   "outputs": [],
   "source": [
    "del replyGraph\n",
    "del dSubCommentId \n",
    "del seen_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "20891203",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç Processing search: rx 7600\n",
      "üîç Processing search: rx 7600 review\n",
      "üîç Processing search: rx 7600 launch\n",
      "üîç Processing search: rx 7600 performance\n",
      "üîç Processing search: rx 7600 benchmarks\n",
      "üîç Processing search: rx 7600 gaming\n",
      "üîç Processing search: rx 7600 issues\n",
      "üîç Processing search: rx 7600 worth it\n",
      "üîç Processing search: rx 7600 upgrade\n",
      "üîç Processing search: rx 7600 vs\n",
      "‚úÖ Graph saved with 1897 nodes and 2694 edges.\n"
     ]
    }
   ],
   "source": [
    "# amd 2 \n",
    "replyGraph = nx.DiGraph()\n",
    "dSubCommentId = {}\n",
    "seen_ids = set()\n",
    "\n",
    "for phrase in search_phrases_amd_2:\n",
    "    print(f\"üîç Processing search: {phrase}\")\n",
    "\n",
    "    for submission in subreddits_amd.search(query=phrase, sort=\"relevance\", time_filter=\"all\", limit=20):\n",
    "        if submission.id in seen_ids or not submission.author:\n",
    "            continue\n",
    "        seen_ids.add(submission.id)\n",
    "\n",
    "        author_name = submission.author.name\n",
    "        replyGraph.add_node(author_name, subNum=1)\n",
    "        dSubCommentId[submission.id] = author_name\n",
    "\n",
    "        try:\n",
    "            submission.comments.replace_more(limit=None)\n",
    "            all_comments = submission.comments.list()\n",
    "\n",
    "            # Sort comments by score, descending, and take top 300\n",
    "            sorted_comments = sorted(\n",
    "                [c for c in all_comments if c.author],\n",
    "                key=lambda x: x.score,\n",
    "                reverse=True\n",
    "            )[:200]\n",
    "\n",
    "            # First pass: index authors\n",
    "            for comment in sorted_comments:\n",
    "                dSubCommentId[comment.id] = comment.author.name\n",
    "\n",
    "            # Second pass: add edges\n",
    "            for comment in sorted_comments:\n",
    "                parent_id = comment.parent_id.replace(\"t1_\", \"\").replace(\"t3_\", \"\")\n",
    "                if parent_id in dSubCommentId:\n",
    "                    src = comment.author.name\n",
    "                    tgt = dSubCommentId[parent_id]\n",
    "\n",
    "                    if src not in replyGraph:\n",
    "                        replyGraph.add_node(src, subNum=0)\n",
    "                    if tgt not in replyGraph:\n",
    "                        replyGraph.add_node(tgt, subNum=0)\n",
    "\n",
    "                    if replyGraph.has_edge(src, tgt):\n",
    "                        replyGraph[src][tgt]['replyNum'] += 1\n",
    "                    else:\n",
    "                        replyGraph.add_edge(src, tgt, replyNum=1)\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"‚ö†Ô∏è Skipped submission {submission.id} due to error: {e}\")\n",
    "\n",
    "        time.sleep(3)  # Avoid rate limit\n",
    "\n",
    "# --- Save graph ---\n",
    "nx.write_graphml(replyGraph, \"search_reply_graph_amd_2.graphml\")\n",
    "print(f\"‚úÖ Graph saved with {len(replyGraph.nodes)} nodes and {len(replyGraph.edges)} edges.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "a323829e",
   "metadata": {},
   "outputs": [],
   "source": [
    "del replyGraph\n",
    "del dSubCommentId "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "3f7ddcb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "gpu_keywords_amd = {\n",
    "#     \"rx 6500 xt\": (\"amd\", \"low\")\n",
    "#     \"rx 7600\": (\"amd\", \"mid\")\n",
    "    \"rx 7900 xt\": (\"amd\", \"high\")\n",
    "}\n",
    "\n",
    "\n",
    "from itertools import product\n",
    "\n",
    "\n",
    "contexts = [\"\", \"review\", \"launch\", \"performance\", \"benchmarks\", \"gaming\", \"issues\", \"worth it\", \"upgrade\", \"vs\"]\n",
    "\n",
    "search_phrases_amd_3 = [f\"{gpu} {ctx}\".strip() for gpu, ctx in product(gpu_keywords_amd.keys(), contexts)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "570555f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç Processing search: rx 7900 xt\n",
      "üîç Processing search: rx 7900 xt review\n",
      "üîç Processing search: rx 7900 xt launch\n",
      "üîç Processing search: rx 7900 xt performance\n",
      "üîç Processing search: rx 7900 xt benchmarks\n",
      "üîç Processing search: rx 7900 xt gaming\n",
      "üîç Processing search: rx 7900 xt issues\n",
      "üîç Processing search: rx 7900 xt worth it\n",
      "üîç Processing search: rx 7900 xt upgrade\n",
      "üîç Processing search: rx 7900 xt vs\n",
      "‚úÖ Graph saved with 4218 nodes and 7037 edges.\n"
     ]
    }
   ],
   "source": [
    "# amd 2 \n",
    "replyGraph = nx.DiGraph()\n",
    "dSubCommentId = {}\n",
    "seen_ids = set()\n",
    "\n",
    "for phrase in search_phrases_amd_3:\n",
    "    print(f\"üîç Processing search: {phrase}\")\n",
    "\n",
    "    for submission in subreddits_amd.search(query=phrase, sort=\"relevance\", time_filter=\"all\", limit=20):\n",
    "        if submission.id in seen_ids or not submission.author:\n",
    "            continue\n",
    "        seen_ids.add(submission.id)\n",
    "\n",
    "        author_name = submission.author.name\n",
    "        replyGraph.add_node(author_name, subNum=1)\n",
    "        dSubCommentId[submission.id] = author_name\n",
    "\n",
    "        try:\n",
    "            submission.comments.replace_more(limit=None)\n",
    "            all_comments = submission.comments.list()\n",
    "\n",
    "            # Sort comments by score, descending, and take top 300\n",
    "            sorted_comments = sorted(\n",
    "                [c for c in all_comments if c.author],\n",
    "                key=lambda x: x.score,\n",
    "                reverse=True\n",
    "            )[:200]\n",
    "\n",
    "            # First pass: index authors\n",
    "            for comment in sorted_comments:\n",
    "                dSubCommentId[comment.id] = comment.author.name\n",
    "\n",
    "            # Second pass: add edges\n",
    "            for comment in sorted_comments:\n",
    "                parent_id = comment.parent_id.replace(\"t1_\", \"\").replace(\"t3_\", \"\")\n",
    "                if parent_id in dSubCommentId:\n",
    "                    src = comment.author.name\n",
    "                    tgt = dSubCommentId[parent_id]\n",
    "\n",
    "                    if src not in replyGraph:\n",
    "                        replyGraph.add_node(src, subNum=0)\n",
    "                    if tgt not in replyGraph:\n",
    "                        replyGraph.add_node(tgt, subNum=0)\n",
    "\n",
    "                    if replyGraph.has_edge(src, tgt):\n",
    "                        replyGraph[src][tgt]['replyNum'] += 1\n",
    "                    else:\n",
    "                        replyGraph.add_edge(src, tgt, replyNum=1)\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"‚ö†Ô∏è Skipped submission {submission.id} due to error: {e}\")\n",
    "\n",
    "        time.sleep(3)  # Avoid rate limit\n",
    "\n",
    "# --- Save graph ---\n",
    "nx.write_graphml(replyGraph, \"search_reply_graph_amd_3.graphml\")\n",
    "print(f\"‚úÖ Graph saved with {len(replyGraph.nodes)} nodes and {len(replyGraph.edges)} edges.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f16545d4",
   "metadata": {},
   "source": [
    "## intel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "033c48e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "subreddits_intel = client.subreddit(\"intelarc+graphicscard+gpu+buildapc\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "2f3d4af7",
   "metadata": {},
   "outputs": [],
   "source": [
    "gpu_keywords_intel = {\n",
    "    \"arc a380\": (\"intel\", \"low\")\n",
    "#     \"arc a750\": (\"intel\", \"mid\"),\n",
    "#     \"arc b580\": (\"intel\", \"high\")\n",
    "}\n",
    "\n",
    "\n",
    "\n",
    "from itertools import product\n",
    "\n",
    "\n",
    "contexts = [\"\", \"review\", \"launch\", \"performance\", \"benchmarks\", \"gaming\", \"issues\", \"worth it\", \"upgrade\", \"vs\"]\n",
    "\n",
    "search_phrases_intel_1 = [f\"{gpu} {ctx}\".strip() for gpu, ctx in product(gpu_keywords_intel.keys(), contexts)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "ed4b9c64",
   "metadata": {},
   "outputs": [],
   "source": [
    "del replyGraph\n",
    "del dSubCommentId "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "0e2ab66a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç Processing search: arc a380\n",
      "üîç Processing search: arc a380 review\n",
      "üîç Processing search: arc a380 launch\n",
      "üîç Processing search: arc a380 performance\n",
      "üîç Processing search: arc a380 benchmarks\n",
      "üîç Processing search: arc a380 gaming\n",
      "üîç Processing search: arc a380 issues\n",
      "üîç Processing search: arc a380 worth it\n",
      "üîç Processing search: arc a380 upgrade\n",
      "üîç Processing search: arc a380 vs\n",
      "‚úÖ Graph saved with 821 nodes and 1279 edges.\n"
     ]
    }
   ],
   "source": [
    "# intel 1 \n",
    "replyGraph = nx.DiGraph()\n",
    "dSubCommentId = {}\n",
    "seen_ids = set()\n",
    "\n",
    "for phrase in search_phrases_intel_1:\n",
    "    print(f\"üîç Processing search: {phrase}\")\n",
    "\n",
    "    for submission in subreddits_intel.search(query=phrase, sort=\"relevance\", time_filter=\"all\", limit=20):\n",
    "        if submission.id in seen_ids or not submission.author:\n",
    "            continue\n",
    "        seen_ids.add(submission.id)\n",
    "\n",
    "        author_name = submission.author.name\n",
    "        replyGraph.add_node(author_name, subNum=1)\n",
    "        dSubCommentId[submission.id] = author_name\n",
    "\n",
    "        try:\n",
    "            submission.comments.replace_more(limit=None)\n",
    "            all_comments = submission.comments.list()\n",
    "\n",
    "            # Sort comments by score, descending, and take top 300\n",
    "            sorted_comments = sorted(\n",
    "                [c for c in all_comments if c.author],\n",
    "                key=lambda x: x.score,\n",
    "                reverse=True\n",
    "            )[:200]\n",
    "\n",
    "            # First pass: index authors\n",
    "            for comment in sorted_comments:\n",
    "                dSubCommentId[comment.id] = comment.author.name\n",
    "\n",
    "            # Second pass: add edges\n",
    "            for comment in sorted_comments:\n",
    "                parent_id = comment.parent_id.replace(\"t1_\", \"\").replace(\"t3_\", \"\")\n",
    "                if parent_id in dSubCommentId:\n",
    "                    src = comment.author.name\n",
    "                    tgt = dSubCommentId[parent_id]\n",
    "\n",
    "                    if src not in replyGraph:\n",
    "                        replyGraph.add_node(src, subNum=0)\n",
    "                    if tgt not in replyGraph:\n",
    "                        replyGraph.add_node(tgt, subNum=0)\n",
    "\n",
    "                    if replyGraph.has_edge(src, tgt):\n",
    "                        replyGraph[src][tgt]['replyNum'] += 1\n",
    "                    else:\n",
    "                        replyGraph.add_edge(src, tgt, replyNum=1)\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"‚ö†Ô∏è Skipped submission {submission.id} due to error: {e}\")\n",
    "\n",
    "        time.sleep(3)  # Avoid rate limit\n",
    "\n",
    "# --- Save graph ---\n",
    "nx.write_graphml(replyGraph, \"search_reply_graph_intel_1.graphml\")\n",
    "print(f\"‚úÖ Graph saved with {len(replyGraph.nodes)} nodes and {len(replyGraph.edges)} edges.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90fc7752",
   "metadata": {},
   "source": [
    "## intel 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "4cfce697",
   "metadata": {},
   "outputs": [],
   "source": [
    "gpu_keywords_intel = {\n",
    "#     \"arc a380\": (\"intel\", \"low\")\n",
    "    \"arc a750\": (\"intel\", \"mid\")\n",
    "#     \"arc b580\": (\"intel\", \"high\")\n",
    "}\n",
    "\n",
    "\n",
    "\n",
    "from itertools import product\n",
    "\n",
    "\n",
    "contexts = [\"\", \"review\", \"launch\", \"performance\", \"benchmarks\", \"gaming\", \"issues\", \"worth it\", \"upgrade\", \"vs\"]\n",
    "\n",
    "search_phrases_intel_2 = [f\"{gpu} {ctx}\".strip() for gpu, ctx in product(gpu_keywords_intel.keys(), contexts)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "09a2b20a",
   "metadata": {},
   "outputs": [],
   "source": [
    "del replyGraph\n",
    "del dSubCommentId "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "1e5cceb6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç Processing search: arc a750\n",
      "üîç Processing search: arc a750 review\n",
      "üîç Processing search: arc a750 launch\n",
      "üîç Processing search: arc a750 performance\n",
      "üîç Processing search: arc a750 benchmarks\n",
      "üîç Processing search: arc a750 gaming\n",
      "üîç Processing search: arc a750 issues\n",
      "üîç Processing search: arc a750 worth it\n",
      "üîç Processing search: arc a750 upgrade\n",
      "üîç Processing search: arc a750 vs\n",
      "‚úÖ Graph saved with 1029 nodes and 1921 edges.\n"
     ]
    }
   ],
   "source": [
    "# intel 1 \n",
    "replyGraph = nx.DiGraph()\n",
    "dSubCommentId = {}\n",
    "seen_ids = set()\n",
    "\n",
    "for phrase in search_phrases_intel_2:\n",
    "    print(f\"üîç Processing search: {phrase}\")\n",
    "\n",
    "    for submission in subreddits_intel.search(query=phrase, sort=\"relevance\", time_filter=\"all\", limit=20):\n",
    "        if submission.id in seen_ids or not submission.author:\n",
    "            continue\n",
    "        seen_ids.add(submission.id)\n",
    "\n",
    "        author_name = submission.author.name\n",
    "        replyGraph.add_node(author_name, subNum=1)\n",
    "        dSubCommentId[submission.id] = author_name\n",
    "\n",
    "        try:\n",
    "            submission.comments.replace_more(limit=None)\n",
    "            all_comments = submission.comments.list()\n",
    "\n",
    "            # Sort comments by score, descending, and take top 300\n",
    "            sorted_comments = sorted(\n",
    "                [c for c in all_comments if c.author],\n",
    "                key=lambda x: x.score,\n",
    "                reverse=True\n",
    "            )[:200]\n",
    "\n",
    "            # First pass: index authors\n",
    "            for comment in sorted_comments:\n",
    "                dSubCommentId[comment.id] = comment.author.name\n",
    "\n",
    "            # Second pass: add edges\n",
    "            for comment in sorted_comments:\n",
    "                parent_id = comment.parent_id.replace(\"t1_\", \"\").replace(\"t3_\", \"\")\n",
    "                if parent_id in dSubCommentId:\n",
    "                    src = comment.author.name\n",
    "                    tgt = dSubCommentId[parent_id]\n",
    "\n",
    "                    if src not in replyGraph:\n",
    "                        replyGraph.add_node(src, subNum=0)\n",
    "                    if tgt not in replyGraph:\n",
    "                        replyGraph.add_node(tgt, subNum=0)\n",
    "\n",
    "                    if replyGraph.has_edge(src, tgt):\n",
    "                        replyGraph[src][tgt]['replyNum'] += 1\n",
    "                    else:\n",
    "                        replyGraph.add_edge(src, tgt, replyNum=1)\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"‚ö†Ô∏è Skipped submission {submission.id} due to error: {e}\")\n",
    "\n",
    "        time.sleep(3)  # Avoid rate limit\n",
    "\n",
    "# --- Save graph ---\n",
    "nx.write_graphml(replyGraph, \"search_reply_graph_intel_2.graphml\")\n",
    "print(f\"‚úÖ Graph saved with {len(replyGraph.nodes)} nodes and {len(replyGraph.edges)} edges.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68e321c7",
   "metadata": {},
   "source": [
    "## intel 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "914ad695",
   "metadata": {},
   "outputs": [],
   "source": [
    "gpu_keywords_intel = {\n",
    "#     \"arc a380\": (\"intel\", \"low\")\n",
    "#     \"arc a750\": (\"intel\", \"mid\"),\n",
    "    \"arc b580\": (\"intel\", \"high\")\n",
    "}\n",
    "\n",
    "\n",
    "\n",
    "from itertools import product\n",
    "\n",
    "\n",
    "contexts = [\"\", \"review\", \"launch\", \"performance\", \"benchmarks\", \"gaming\", \"issues\", \"worth it\", \"upgrade\", \"vs\"]\n",
    "\n",
    "search_phrases_intel_3 = [f\"{gpu} {ctx}\".strip() for gpu, ctx in product(gpu_keywords_intel.keys(), contexts)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "135528c4",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'replyGraph' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[172], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mdel\u001b[39;00m replyGraph\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mdel\u001b[39;00m dSubCommentId\n",
      "\u001b[1;31mNameError\u001b[0m: name 'replyGraph' is not defined"
     ]
    }
   ],
   "source": [
    "del replyGraph\n",
    "del dSubCommentId "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "c42794c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç Processing search: arc b580\n",
      "üîç Processing search: arc b580 review\n",
      "üîç Processing search: arc b580 launch\n",
      "üîç Processing search: arc b580 performance\n",
      "üîç Processing search: arc b580 benchmarks\n",
      "üîç Processing search: arc b580 gaming\n",
      "üîç Processing search: arc b580 issues\n",
      "üîç Processing search: arc b580 worth it\n",
      "üîç Processing search: arc b580 upgrade\n",
      "üîç Processing search: arc b580 vs\n",
      "‚úÖ Graph saved with 2140 nodes and 4139 edges.\n"
     ]
    }
   ],
   "source": [
    "# intel 1 \n",
    "replyGraph = nx.DiGraph()\n",
    "dSubCommentId = {}\n",
    "seen_ids = set()\n",
    "\n",
    "for phrase in search_phrases_intel_2:\n",
    "    print(f\"üîç Processing search: {phrase}\")\n",
    "\n",
    "    for submission in subreddits_intel.search(query=phrase, sort=\"relevance\", time_filter=\"all\", limit=20):\n",
    "        if submission.id in seen_ids or not submission.author:\n",
    "            continue\n",
    "        seen_ids.add(submission.id)\n",
    "\n",
    "        author_name = submission.author.name\n",
    "        replyGraph.add_node(author_name, subNum=1)\n",
    "        dSubCommentId[submission.id] = author_name\n",
    "\n",
    "        try:\n",
    "            submission.comments.replace_more(limit=None)\n",
    "            all_comments = submission.comments.list()\n",
    "\n",
    "            # Sort comments by score, descending, and take top 300\n",
    "            sorted_comments = sorted(\n",
    "                [c for c in all_comments if c.author],\n",
    "                key=lambda x: x.score,\n",
    "                reverse=True\n",
    "            )[:200]\n",
    "\n",
    "            # First pass: index authors\n",
    "            for comment in sorted_comments:\n",
    "                dSubCommentId[comment.id] = comment.author.name\n",
    "\n",
    "            # Second pass: add edges\n",
    "            for comment in sorted_comments:\n",
    "                parent_id = comment.parent_id.replace(\"t1_\", \"\").replace(\"t3_\", \"\")\n",
    "                if parent_id in dSubCommentId:\n",
    "                    src = comment.author.name\n",
    "                    tgt = dSubCommentId[parent_id]\n",
    "\n",
    "                    if src not in replyGraph:\n",
    "                        replyGraph.add_node(src, subNum=0)\n",
    "                    if tgt not in replyGraph:\n",
    "                        replyGraph.add_node(tgt, subNum=0)\n",
    "\n",
    "                    if replyGraph.has_edge(src, tgt):\n",
    "                        replyGraph[src][tgt]['replyNum'] += 1\n",
    "                    else:\n",
    "                        replyGraph.add_edge(src, tgt, replyNum=1)\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"‚ö†Ô∏è Skipped submission {submission.id} due to error: {e}\")\n",
    "\n",
    "        time.sleep(3)  # Avoid rate limit\n",
    "\n",
    "# --- Save graph ---\n",
    "nx.write_graphml(replyGraph, \"search_reply_graph_intel_3.graphml\")\n",
    "print(f\"‚úÖ Graph saved with {len(replyGraph.nodes)} nodes and {len(replyGraph.edges)} edges.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcc42e07",
   "metadata": {},
   "source": [
    "# Insights into the graphs \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b401d50b",
   "metadata": {},
   "source": [
    "### nvidia_tier_1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c70e0a0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "import pandas as pd\n",
    "\n",
    "def compute_centrality_from_graphml(graphml_path, output_name=\"graph\"):\n",
    "    \"\"\"\n",
    "    Load a .graphml file and compute centrality metrics.\n",
    "\n",
    "    Parameters:\n",
    "    - graphml_path: Path to the .graphml file\n",
    "    - output_name: Filename prefix for CSV output\n",
    "\n",
    "    Returns:\n",
    "    - DataFrame of centrality metrics\n",
    "    \"\"\"\n",
    "    # --- Load graph ---\n",
    "    print(f\"üìÇ Loading graph from {graphml_path}...\")\n",
    "    graph = nx.read_graphml(graphml_path)\n",
    "\n",
    "    # --- Compute metrics ---\n",
    "    degree = nx.degree_centrality(graph)\n",
    "    betweenness = nx.betweenness_centrality(graph)\n",
    "    eigenvector = nx.eigenvector_centrality(graph, max_iter=1000)\n",
    "    closeness = nx.closeness_centrality(graph)\n",
    "\n",
    "    # --- Combine into DataFrame ---\n",
    "    df = pd.DataFrame({\n",
    "        \"User\": list(degree.keys()),\n",
    "        \"Degree\": list(degree.values()),\n",
    "        \"Betweenness\": list(betweenness.values()),\n",
    "        \"Eigenvector\": list(eigenvector.values()),\n",
    "        \"Closeness\": list(closeness.values())\n",
    "    })\n",
    "\n",
    "    # --- Sort and save ---\n",
    "    df = df.sort_values(\"Degree\", ascending=False)\n",
    "    out_csv = f\"{output_name}_centrality_metrics.csv\"\n",
    "    df.to_csv(out_csv, index=False)\n",
    "    print(f\"‚úÖ Exported metrics to {out_csv} with {len(df)} users.\")\n",
    "\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "94294093",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìÇ Loading graph from search_reply_graph_4.graphml...\n",
      "‚úÖ Exported metrics to search_reply_graph_6_centrality_metrics.csv with 5521 users.\n",
      "                    User    Degree  Betweenness  Eigenvector  Closeness\n",
      "150          Nestledrink  0.270109     0.155000     0.755477   0.339070\n",
      "167            KARMAAACS  0.027899     0.027595     0.065919   0.219100\n",
      "1256       Stiven_Crysis  0.025000     0.000000     0.052341   0.214730\n",
      "3123               m_w_h  0.022826     0.021181     0.102509   0.181626\n",
      "0        PralineGold6868  0.020471     0.007616     0.000279   0.132300\n",
      "789           nukleabomb  0.018659     0.007052     0.083937   0.216952\n",
      "2357            Fraga500  0.014493     0.006091     0.011858   0.181844\n",
      "368       rW0HgFyxoJhYka  0.013587     0.016981     0.037329   0.213066\n",
      "5143  Certain_Active7773  0.013587     0.000875     0.013932   0.191666\n",
      "4372         SadSpot8656  0.013587     0.012829     0.058302   0.207819\n"
     ]
    }
   ],
   "source": [
    "df = compute_centrality_from_graphml(\"search_reply_graph_4.graphml\", output_name=\"search_reply_graph_6\")\n",
    "print(df.head(10))  # Show top 10 users\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a0079bd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "\n",
    "def calculate_centralities(graph_path):\n",
    "    # Load the GraphML file\n",
    "    G = nx.read_graphml(graph_path)\n",
    "\n",
    "    # Ensure it's a directed graph if needed\n",
    "    if not isinstance(G, nx.DiGraph):\n",
    "        G = nx.DiGraph(G)\n",
    "\n",
    "    # Calculate different centralities\n",
    "    degree_centrality = nx.degree_centrality(G)\n",
    "    in_degree_centrality = nx.in_degree_centrality(G)\n",
    "    out_degree_centrality = nx.out_degree_centrality(G)\n",
    "    closeness_centrality = nx.closeness_centrality(G)\n",
    "    betweenness_centrality = nx.betweenness_centrality(G, normalized=True)\n",
    "    eigenvector_centrality = nx.eigenvector_centrality(G, max_iter=1000)\n",
    "    katz_centrality = nx.katz_centrality_numpy(G, alpha=0.1, beta=1.0)\n",
    "    pagerank = nx.pagerank(G)\n",
    "\n",
    "    # Combine results\n",
    "    centralities = {}\n",
    "    for node in G.nodes():\n",
    "        centralities[node] = {\n",
    "            'degree': degree_centrality.get(node, 0),\n",
    "            'in_degree': in_degree_centrality.get(node, 0),\n",
    "            'out_degree': out_degree_centrality.get(node, 0),\n",
    "            'closeness': closeness_centrality.get(node, 0),\n",
    "            'betweenness': betweenness_centrality.get(node, 0),\n",
    "            'eigenvector': eigenvector_centrality.get(node, 0),\n",
    "            'katz': katz_centrality.get(node, 0),\n",
    "            'pagerank': pagerank.get(node, 0)\n",
    "        }\n",
    "\n",
    "    return centralities\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "df4eca0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User: Nestledrink\n",
      "  degree: 0.2701\n",
      "  in_degree: 0.2652\n",
      "  out_degree: 0.0049\n",
      "  closeness: 0.3391\n",
      "  betweenness: 0.1550\n",
      "  eigenvector: 0.7555\n",
      "  katz: 0.8107\n",
      "  pagerank: 0.1096\n",
      "User: nukleabomb\n",
      "  degree: 0.0187\n",
      "  in_degree: 0.0172\n",
      "  out_degree: 0.0014\n",
      "  closeness: 0.2170\n",
      "  betweenness: 0.0071\n",
      "  eigenvector: 0.0839\n",
      "  katz: 0.0778\n",
      "  pagerank: 0.0152\n",
      "User: KARMAAACS\n",
      "  degree: 0.0279\n",
      "  in_degree: 0.0259\n",
      "  out_degree: 0.0020\n",
      "  closeness: 0.2191\n",
      "  betweenness: 0.0276\n",
      "  eigenvector: 0.0659\n",
      "  katz: 0.0838\n",
      "  pagerank: 0.0136\n",
      "User: it_is_im\n",
      "  degree: 0.0085\n",
      "  in_degree: 0.0076\n",
      "  out_degree: 0.0009\n",
      "  closeness: 0.1946\n",
      "  betweenness: 0.0053\n",
      "  eigenvector: 0.0200\n",
      "  katz: 0.0279\n",
      "  pagerank: 0.0106\n",
      "User: MajesticFunction8453\n",
      "  degree: 0.0105\n",
      "  in_degree: 0.0100\n",
      "  out_degree: 0.0005\n",
      "  closeness: 0.1740\n",
      "  betweenness: 0.0005\n",
      "  eigenvector: 0.0049\n",
      "  katz: 0.0205\n",
      "  pagerank: 0.0099\n"
     ]
    }
   ],
   "source": [
    "results = calculate_centralities(\"search_reply_graph_4.graphml\")\n",
    "\n",
    "# Print top 5 nodes by PageRank\n",
    "top_pagerank = sorted(results.items(), key=lambda x: x[1]['pagerank'], reverse=True)[:5]\n",
    "for node, metrics in top_pagerank:\n",
    "    print(f\"User: {node}\")\n",
    "    for k, v in metrics.items():\n",
    "        print(f\"  {k}: {v:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f016c411",
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "import numpy as np\n",
    "\n",
    "def average_centrality(G, metric='degree'):\n",
    "    \"\"\"\n",
    "    Compute the average centrality of a graph.\n",
    "\n",
    "    Parameters:\n",
    "        G (networkx.Graph): The graph to analyze.\n",
    "        metric (str): The centrality metric to use. Options:\n",
    "                      'degree', 'closeness', 'betweenness', 'eigenvector', 'katz'\n",
    "\n",
    "    Returns:\n",
    "        float: The average centrality value across all nodes.\n",
    "    \"\"\"\n",
    "\n",
    "    if metric == 'degree':\n",
    "        centrality = nx.degree_centrality(G)\n",
    "    elif metric == 'closeness':\n",
    "        centrality = nx.closeness_centrality(G)\n",
    "    elif metric == 'betweenness':\n",
    "        centrality = nx.betweenness_centrality(G)\n",
    "    elif metric == 'eigenvector':\n",
    "        centrality = nx.eigenvector_centrality(G, max_iter=1000)\n",
    "    elif metric == 'katz':\n",
    "        # Katz requires an alpha less than 1 / largest eigenvalue\n",
    "        try:\n",
    "            centrality = nx.katz_centrality(G, alpha=0.1, beta=1.0, max_iter=1000)\n",
    "        except nx.NetworkXException as e:\n",
    "            print(f\"‚ö†Ô∏è Katz centrality error: {e}\")\n",
    "            return None\n",
    "    else:\n",
    "        raise ValueError(\"Unsupported metric. Choose from 'degree', 'closeness', 'betweenness', 'eigenvector', 'katz'.\")\n",
    "\n",
    "    return np.mean(list(centrality.values()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "id": "3132e28d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Degree Centrality: 0.0006\n",
      "Closeness Centrality: 0.0459\n",
      "Betweenness Centrality: 0.0003\n",
      "Eigenvector Centrality: 0.0019\n",
      "Katz Centrality: 0.0041\n"
     ]
    }
   ],
   "source": [
    "G = nx.read_graphml(\"search_reply_graph_4.graphml\")\n",
    "\n",
    "metrics = ['degree', 'closeness', 'betweenness', 'eigenvector', 'katz']\n",
    "\n",
    "for m in metrics:\n",
    "    avg = average_centrality(G, metric=m)\n",
    "    if avg is not None:\n",
    "        print(f\"{m.capitalize()} Centrality: {avg:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f8d3510",
   "metadata": {},
   "source": [
    "## Nvidia_tier_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "id": "558afbae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìÇ Loading graph from search_reply_graph_5.graphml...\n",
      "‚úÖ Exported metrics to search_reply_graph_6_centrality_metrics.csv with 4517 users.\n",
      "                    User    Degree  Betweenness  Eigenvector  Closeness\n",
      "0            Nestledrink  0.158547     0.144581     0.660567   0.308881\n",
      "783   Arthur_Morgan44469  0.035651     0.033496     0.252679   0.218913\n",
      "3182           bilal_hcg  0.023029     0.012721     0.032711   0.198023\n",
      "646          kikimaru024  0.022365     0.021075     0.045208   0.215412\n",
      "1587     Various_Ad_8448  0.021479     0.015342     0.063604   0.184011\n"
     ]
    }
   ],
   "source": [
    "df = compute_centrality_from_graphml(\"search_reply_graph_5.graphml\", output_name=\"search_reply_graph_6\")\n",
    "print(df.head(5))  # Show top 10 users\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "id": "8879db6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "del results "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "id": "26eff040",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User: Nestledrink\n",
      "  degree: 0.1585\n",
      "  in_degree: 0.1499\n",
      "  out_degree: 0.0086\n",
      "  closeness: 0.3089\n",
      "  betweenness: 0.1446\n",
      "  eigenvector: 0.6606\n",
      "  katz: 0.6949\n",
      "  pagerank: 0.0693\n",
      "User: JayomaW\n",
      "  degree: 0.0016\n",
      "  in_degree: 0.0011\n",
      "  out_degree: 0.0004\n",
      "  closeness: 0.2029\n",
      "  betweenness: 0.0002\n",
      "  eigenvector: 0.0194\n",
      "  katz: 0.0208\n",
      "  pagerank: 0.0307\n",
      "User: Ajxtt\n",
      "  degree: 0.0213\n",
      "  in_degree: 0.0210\n",
      "  out_degree: 0.0002\n",
      "  closeness: 0.2606\n",
      "  betweenness: 0.0004\n",
      "  eigenvector: 0.1464\n",
      "  katz: 0.1548\n",
      "  pagerank: 0.0230\n",
      "User: mtbhatch\n",
      "  degree: 0.0004\n",
      "  in_degree: 0.0002\n",
      "  out_degree: 0.0002\n",
      "  closeness: 0.1661\n",
      "  betweenness: 0.0000\n",
      "  eigenvector: 0.0025\n",
      "  katz: 0.0058\n",
      "  pagerank: 0.0130\n",
      "User: Voodoo2-SLi\n",
      "  degree: 0.0142\n",
      "  in_degree: 0.0122\n",
      "  out_degree: 0.0020\n",
      "  closeness: 0.2391\n",
      "  betweenness: 0.0201\n",
      "  eigenvector: 0.1245\n",
      "  katz: 0.1189\n",
      "  pagerank: 0.0111\n"
     ]
    }
   ],
   "source": [
    "results = calculate_centralities(\"search_reply_graph_5.graphml\")\n",
    "\n",
    "# Print top 5 nodes by PageRank\n",
    "top_pagerank = sorted(results.items(), key=lambda x: x[1]['pagerank'], reverse=True)[:5]\n",
    "for node, metrics in top_pagerank:\n",
    "    print(f\"User: {node}\")\n",
    "    for k, v in metrics.items():\n",
    "        print(f\"  {k}: {v:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "id": "8ff1ee90",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Degree Centrality: 0.0007\n",
      "Closeness Centrality: 0.0492\n",
      "Betweenness Centrality: 0.0004\n",
      "Eigenvector Centrality: 0.0026\n",
      "Katz Centrality: 0.0062\n"
     ]
    }
   ],
   "source": [
    "G = nx.read_graphml(\"search_reply_graph_5.graphml\")\n",
    "\n",
    "metrics = ['degree', 'closeness', 'betweenness', 'eigenvector', 'katz']\n",
    "\n",
    "for m in metrics:\n",
    "    avg = average_centrality(G, metric=m)\n",
    "    if avg is not None:\n",
    "        print(f\"{m.capitalize()} Centrality: {avg:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "122908a7",
   "metadata": {},
   "source": [
    "## Nvidia_tier_3 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "id": "c6e828aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìÇ Loading graph from search_reply_graph_6.graphml...\n",
      "‚úÖ Exported metrics to search_reply_graph_6_centrality_metrics.csv with 4513 users.\n",
      "                    User    Degree  Betweenness  Eigenvector  Closeness\n",
      "0            Nestledrink  0.156472     0.143059     0.647564   0.309595\n",
      "782   Arthur_Morgan44469  0.036126     0.033029     0.277132   0.219178\n",
      "3177           bilal_hcg  0.023271     0.012692     0.033454   0.197298\n",
      "636          kikimaru024  0.022385     0.020865     0.045187   0.215636\n",
      "850          Bossman1086  0.021498     0.023815     0.131326   0.217248\n"
     ]
    }
   ],
   "source": [
    "df = compute_centrality_from_graphml(\"search_reply_graph_6.graphml\", output_name=\"search_reply_graph_6\")\n",
    "print(df.head(5))  # Show top 10 users\n",
    "\n",
    "df = compute_centrality_from_graphml(\"search_reply_graph_6.graphml\", output_name=\"search_reply_graph_6\")\n",
    "print(df.head(5))  # Show top 10 users\n",
    "‚Äã\n",
    "üìÇ Loading graph from search_reply_graph_6.graphml...\n",
    "‚úÖ Exported metrics to search_reply_graph_6_centrality_metrics.csv with 4513 users.\n",
    "                    User    Degree  Betweenness  Eigenvector  Closeness\n",
    "0            Nestledrink  0.156472     0.143059     0.647564   0.309595\n",
    "782   Arthur_Morgan44469  0.036126     0.033029     0.277132   0.219178\n",
    "3177           bilal_hcg  0.023271     0.012692     0.033454   0.197298\n",
    "636          kikimaru024  0.022385     0.020865     0.045187   0.215636\n",
    "850          Bossman1086  0.021498     0.023815     0.131326   0.217248\n",
    "del results \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "id": "66ec0939",
   "metadata": {},
   "outputs": [],
   "source": [
    "del results "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "id": "ba3a8fbb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User: Nestledrink\n",
      "  degree: 0.1565\n",
      "  in_degree: 0.1478\n",
      "  out_degree: 0.0086\n",
      "  closeness: 0.3096\n",
      "  betweenness: 0.1431\n",
      "  eigenvector: 0.6476\n",
      "  katz: 0.6886\n",
      "  pagerank: 0.0677\n",
      "User: Ajxtt\n",
      "  degree: 0.0211\n",
      "  in_degree: 0.0208\n",
      "  out_degree: 0.0002\n",
      "  closeness: 0.2606\n",
      "  betweenness: 0.0002\n",
      "  eigenvector: 0.1424\n",
      "  katz: 0.1541\n",
      "  pagerank: 0.0349\n",
      "User: JayomaW\n",
      "  degree: 0.0011\n",
      "  in_degree: 0.0009\n",
      "  out_degree: 0.0002\n",
      "  closeness: 0.2029\n",
      "  betweenness: 0.0000\n",
      "  eigenvector: 0.0184\n",
      "  katz: 0.0203\n",
      "  pagerank: 0.0299\n",
      "User: Voodoo2-SLi\n",
      "  degree: 0.0142\n",
      "  in_degree: 0.0122\n",
      "  out_degree: 0.0020\n",
      "  closeness: 0.2393\n",
      "  betweenness: 0.0201\n",
      "  eigenvector: 0.1212\n",
      "  katz: 0.1185\n",
      "  pagerank: 0.0110\n",
      "User: bilal_hcg\n",
      "  degree: 0.0233\n",
      "  in_degree: 0.0206\n",
      "  out_degree: 0.0027\n",
      "  closeness: 0.1973\n",
      "  betweenness: 0.0127\n",
      "  eigenvector: 0.0335\n",
      "  katz: 0.0635\n",
      "  pagerank: 0.0104\n"
     ]
    }
   ],
   "source": [
    "results = calculate_centralities(\"search_reply_graph_6.graphml\")\n",
    "\n",
    "# Print top 5 nodes by PageRank\n",
    "top_pagerank = sorted(results.items(), key=lambda x: x[1]['pagerank'], reverse=True)[:5]\n",
    "for node, metrics in top_pagerank:\n",
    "    print(f\"User: {node}\")\n",
    "    for k, v in metrics.items():\n",
    "        print(f\"  {k}: {v:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "id": "907348ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Degree Centrality: 0.0007\n",
      "Closeness Centrality: 0.0492\n",
      "Betweenness Centrality: 0.0004\n",
      "Eigenvector Centrality: 0.0026\n",
      "Katz Centrality: 0.0063\n"
     ]
    }
   ],
   "source": [
    "G = nx.read_graphml(\"search_reply_graph_6.graphml\")\n",
    "\n",
    "metrics = ['degree', 'closeness', 'betweenness', 'eigenvector', 'katz']\n",
    "\n",
    "for m in metrics:\n",
    "    avg = average_centrality(G, metric=m)\n",
    "    if avg is not None:\n",
    "        print(f\"{m.capitalize()} Centrality: {avg:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b93b8121",
   "metadata": {},
   "source": [
    "## Amd_tier_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "id": "76b9dd7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìÇ Loading graph from search_reply_graph_amd_1.graphml...\n",
      "‚úÖ Exported metrics to search_reply_graph_amd_1_centrality_metrics.csv with 1638 users.\n",
      "               User    Degree  Betweenness   Eigenvector  Closeness\n",
      "564   FlyingNipplez  0.089188     0.005818  2.284611e-03   0.060119\n",
      "214          jecowa  0.065363     0.015269  4.921453e-05   0.039278\n",
      "720        J_Echoes  0.063531     0.004665  9.572044e-06   0.057451\n",
      "0            Uhmm69  0.051924     0.010488  9.550582e-09   0.050324\n",
      "958  FantasticHydra  0.040929     0.000454  6.970269e-01   0.020300\n"
     ]
    }
   ],
   "source": [
    "df = compute_centrality_from_graphml(\"search_reply_graph_amd_1.graphml\", output_name=\"search_reply_graph_amd_1\")\n",
    "print(df.head(5))  # Show top 10 users\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "id": "14fa3548",
   "metadata": {},
   "outputs": [],
   "source": [
    "del results "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "id": "466c7124",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User: FlyingNipplez\n",
      "  degree: 0.0892\n",
      "  in_degree: 0.0733\n",
      "  out_degree: 0.0159\n",
      "  closeness: 0.0601\n",
      "  betweenness: 0.0058\n",
      "  eigenvector: 0.0023\n",
      "  katz: 0.3002\n",
      "  pagerank: 0.0422\n",
      "User: ZeroPaladn\n",
      "  degree: 0.0305\n",
      "  in_degree: 0.0287\n",
      "  out_degree: 0.0018\n",
      "  closeness: 0.0461\n",
      "  betweenness: 0.0006\n",
      "  eigenvector: 0.0000\n",
      "  katz: 0.1063\n",
      "  pagerank: 0.0293\n",
      "User: jecowa\n",
      "  degree: 0.0654\n",
      "  in_degree: 0.0501\n",
      "  out_degree: 0.0153\n",
      "  closeness: 0.0393\n",
      "  betweenness: 0.0153\n",
      "  eigenvector: 0.0000\n",
      "  katz: 0.2068\n",
      "  pagerank: 0.0252\n",
      "User: J_Echoes\n",
      "  degree: 0.0635\n",
      "  in_degree: 0.0556\n",
      "  out_degree: 0.0079\n",
      "  closeness: 0.0575\n",
      "  betweenness: 0.0047\n",
      "  eigenvector: 0.0000\n",
      "  katz: 0.2030\n",
      "  pagerank: 0.0251\n",
      "User: HamsterOk3112\n",
      "  degree: 0.0367\n",
      "  in_degree: 0.0330\n",
      "  out_degree: 0.0037\n",
      "  closeness: 0.0685\n",
      "  betweenness: 0.0049\n",
      "  eigenvector: 0.0000\n",
      "  katz: 0.1211\n",
      "  pagerank: 0.0196\n"
     ]
    }
   ],
   "source": [
    "results = calculate_centralities(\"search_reply_graph_amd_1.graphml\")\n",
    "\n",
    "# Print top 5 nodes by PageRank\n",
    "top_pagerank = sorted(results.items(), key=lambda x: x[1]['pagerank'], reverse=True)[:5]\n",
    "for node, metrics in top_pagerank:\n",
    "    print(f\"User: {node}\")\n",
    "    for k, v in metrics.items():\n",
    "        print(f\"  {k}: {v:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "id": "63d5273b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Degree Centrality: 0.0017\n",
      "Closeness Centrality: 0.0081\n",
      "Betweenness Centrality: 0.0002\n",
      "Eigenvector Centrality: 0.0030\n",
      "Katz Centrality: 0.0210\n"
     ]
    }
   ],
   "source": [
    "G = nx.read_graphml(\"search_reply_graph_amd_1.graphml\")\n",
    "\n",
    "metrics = ['degree', 'closeness', 'betweenness', 'eigenvector', 'katz']\n",
    "\n",
    "for m in metrics:\n",
    "    avg = average_centrality(G, metric=m)\n",
    "    if avg is not None:\n",
    "        print(f\"{m.capitalize()} Centrality: {avg:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5332d5f1",
   "metadata": {},
   "source": [
    "## Amd_tier_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "id": "747a209c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìÇ Loading graph from search_reply_graph_amd_2.graphml...\n",
      "‚úÖ Exported metrics to search_reply_graph_amd_2_centrality_metrics.csv with 1897 users.\n",
      "                     User    Degree  Betweenness   Eigenvector  Closeness\n",
      "969                jecowa  0.055907     0.040932  6.825584e-01   0.050438\n",
      "196            apmspammer  0.053270     0.055266  2.222596e-04   0.076035\n",
      "585  StardustNovaSynchron  0.045886     0.001790  1.719201e-07   0.062629\n",
      "331        introvertpanda  0.032173     0.022924  4.359061e-04   0.065433\n",
      "394             AtaliX_MC  0.031118     0.036257  4.284675e-04   0.071324\n"
     ]
    }
   ],
   "source": [
    "df = compute_centrality_from_graphml(\"search_reply_graph_amd_2.graphml\", output_name=\"search_reply_graph_amd_2\")\n",
    "print(df.head(5))  # Show top 10 users\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "id": "275147e7",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'results' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[203], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mdel\u001b[39;00m results\n",
      "\u001b[1;31mNameError\u001b[0m: name 'results' is not defined"
     ]
    }
   ],
   "source": [
    "del results "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "id": "7f78fc59",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User: StardustNovaSynchron\n",
      "  degree: 0.0459\n",
      "  in_degree: 0.0432\n",
      "  out_degree: 0.0026\n",
      "  closeness: 0.0626\n",
      "  betweenness: 0.0018\n",
      "  eigenvector: 0.0000\n",
      "  katz: 0.1734\n",
      "  pagerank: 0.0327\n",
      "User: apmspammer\n",
      "  degree: 0.0533\n",
      "  in_degree: 0.0522\n",
      "  out_degree: 0.0011\n",
      "  closeness: 0.0760\n",
      "  betweenness: 0.0553\n",
      "  eigenvector: 0.0002\n",
      "  katz: 0.2096\n",
      "  pagerank: 0.0227\n",
      "User: jecowa\n",
      "  degree: 0.0559\n",
      "  in_degree: 0.0427\n",
      "  out_degree: 0.0132\n",
      "  closeness: 0.0504\n",
      "  betweenness: 0.0409\n",
      "  eigenvector: 0.6826\n",
      "  katz: 0.2043\n",
      "  pagerank: 0.0213\n",
      "User: StandingEggs\n",
      "  degree: 0.0264\n",
      "  in_degree: 0.0232\n",
      "  out_degree: 0.0032\n",
      "  closeness: 0.0644\n",
      "  betweenness: 0.0017\n",
      "  eigenvector: 0.0002\n",
      "  katz: 0.1091\n",
      "  pagerank: 0.0162\n",
      "User: AtaliX_MC\n",
      "  degree: 0.0311\n",
      "  in_degree: 0.0269\n",
      "  out_degree: 0.0042\n",
      "  closeness: 0.0713\n",
      "  betweenness: 0.0363\n",
      "  eigenvector: 0.0004\n",
      "  katz: 0.1209\n",
      "  pagerank: 0.0154\n"
     ]
    }
   ],
   "source": [
    "results = calculate_centralities(\"search_reply_graph_amd_2.graphml\")\n",
    "\n",
    "# Print top 5 nodes by PageRank\n",
    "top_pagerank = sorted(results.items(), key=lambda x: x[1]['pagerank'], reverse=True)[:5]\n",
    "for node, metrics in top_pagerank:\n",
    "    print(f\"User: {node}\")\n",
    "    for k, v in metrics.items():\n",
    "        print(f\"  {k}: {v:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "id": "4ea5f92d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Degree Centrality: 0.0015\n",
      "Closeness Centrality: 0.0110\n",
      "Betweenness Centrality: 0.0009\n",
      "Eigenvector Centrality: 0.0025\n",
      "Katz Centrality: 0.0203\n"
     ]
    }
   ],
   "source": [
    "G = nx.read_graphml(\"search_reply_graph_amd_2.graphml\")\n",
    "\n",
    "metrics = ['degree', 'closeness', 'betweenness', 'eigenvector', 'katz']\n",
    "\n",
    "for m in metrics:\n",
    "    avg = average_centrality(G, metric=m)\n",
    "    if avg is not None:\n",
    "        print(f\"{m.capitalize()} Centrality: {avg:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da6b747d",
   "metadata": {},
   "source": [
    "## Amd_tier_3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "id": "c810db18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìÇ Loading graph from search_reply_graph_amd_3.graphml...\n",
      "‚úÖ Exported metrics to search_reply_graph_amd_2_centrality_metrics.csv with 4218 users.\n",
      "                      User    Degree  Betweenness  Eigenvector  Closeness\n",
      "135                Buksa07  0.036993     0.027759     0.671213   0.144906\n",
      "2481     Few_Landscape1035  0.029405     0.028266     0.025561   0.195001\n",
      "1203    Interceptor__Prime  0.028219     0.020374     0.026685   0.150023\n",
      "1078  MysteriousSilentVoid  0.025848     0.029917     0.027838   0.173160\n",
      "2211              Forazehy  0.025373     0.011678     0.016186   0.170252\n"
     ]
    }
   ],
   "source": [
    "df = compute_centrality_from_graphml(\"search_reply_graph_amd_3.graphml\", output_name=\"search_reply_graph_amd_2\")\n",
    "print(df.head(5))  # Show top 10 users\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "id": "1b60b4fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "del results "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "id": "6ba86a52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User: FastRemigiusz\n",
      "  degree: 0.0223\n",
      "  in_degree: 0.0221\n",
      "  out_degree: 0.0002\n",
      "  closeness: 0.1493\n",
      "  betweenness: 0.0002\n",
      "  eigenvector: 0.0148\n",
      "  katz: 0.0978\n",
      "  pagerank: 0.0133\n",
      "User: MaikyMoto\n",
      "  degree: 0.0005\n",
      "  in_degree: 0.0002\n",
      "  out_degree: 0.0002\n",
      "  closeness: 0.1282\n",
      "  betweenness: 0.0000\n",
      "  eigenvector: 0.0020\n",
      "  katz: 0.0182\n",
      "  pagerank: 0.0110\n",
      "User: Forazehy\n",
      "  degree: 0.0254\n",
      "  in_degree: 0.0247\n",
      "  out_degree: 0.0007\n",
      "  closeness: 0.1703\n",
      "  betweenness: 0.0117\n",
      "  eigenvector: 0.0162\n",
      "  katz: 0.1299\n",
      "  pagerank: 0.0107\n",
      "User: J_Echoes\n",
      "  degree: 0.0247\n",
      "  in_degree: 0.0218\n",
      "  out_degree: 0.0028\n",
      "  closeness: 0.1751\n",
      "  betweenness: 0.0339\n",
      "  eigenvector: 0.0137\n",
      "  katz: 0.1324\n",
      "  pagerank: 0.0102\n",
      "User: HamsterOk3112\n",
      "  degree: 0.0192\n",
      "  in_degree: 0.0175\n",
      "  out_degree: 0.0017\n",
      "  closeness: 0.1650\n",
      "  betweenness: 0.0167\n",
      "  eigenvector: 0.0045\n",
      "  katz: 0.1017\n",
      "  pagerank: 0.0099\n"
     ]
    }
   ],
   "source": [
    "results = calculate_centralities(\"search_reply_graph_amd_3.graphml\")\n",
    "\n",
    "# Print top 5 nodes by PageRank\n",
    "top_pagerank = sorted(results.items(), key=lambda x: x[1]['pagerank'], reverse=True)[:5]\n",
    "for node, metrics in top_pagerank:\n",
    "    print(f\"User: {node}\")\n",
    "    for k, v in metrics.items():\n",
    "        print(f\"  {k}: {v:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "id": "4afce0ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Degree Centrality: 0.0008\n",
      "Closeness Centrality: 0.0408\n",
      "Betweenness Centrality: 0.0005\n",
      "Eigenvector Centrality: 0.0020\n",
      "Katz Centrality: 0.0117\n"
     ]
    }
   ],
   "source": [
    "G = nx.read_graphml(\"search_reply_graph_amd_3.graphml\")\n",
    "\n",
    "metrics = ['degree', 'closeness', 'betweenness', 'eigenvector', 'katz']\n",
    "\n",
    "for m in metrics:\n",
    "    avg = average_centrality(G, metric=m)\n",
    "    if avg is not None:\n",
    "        print(f\"{m.capitalize()} Centrality: {avg:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe8bf94b",
   "metadata": {},
   "source": [
    "## intel_tier2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "id": "08b63673",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìÇ Loading graph from search_reply_graph_intel_2.graphml...\n",
      "‚úÖ Exported metrics to search_reply_graph_intel_2_centrality_metrics.csv with 1029 users.\n",
      "                   User    Degree  Betweenness  Eigenvector  Closeness\n",
      "233              jecowa  0.102140     0.003109     0.000030   0.078615\n",
      "63      IntelArcTesting  0.077821     0.058488     0.500002   0.161370\n",
      "496           6im6erbmw  0.052529     0.039383     0.066548   0.157772\n",
      "77   Distinct-Race-2471  0.042802     0.041175     0.166093   0.148058\n",
      "42           alvarkresh  0.041829     0.056261     0.162944   0.159689\n"
     ]
    }
   ],
   "source": [
    "df = compute_centrality_from_graphml(\"search_reply_graph_intel_2.graphml\", output_name=\"search_reply_graph_intel_2\")\n",
    "print(df.head(5))  # Show top 10 users\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "id": "8b183d50",
   "metadata": {},
   "outputs": [],
   "source": [
    "del results "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "id": "4c7730f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User: jecowa\n",
      "  degree: 0.1021\n",
      "  in_degree: 0.0788\n",
      "  out_degree: 0.0233\n",
      "  closeness: 0.0786\n",
      "  betweenness: 0.0031\n",
      "  eigenvector: 0.0000\n",
      "  katz: 0.2157\n",
      "  pagerank: 0.0442\n",
      "User: 6im6erbmw\n",
      "  degree: 0.0525\n",
      "  in_degree: 0.0457\n",
      "  out_degree: 0.0068\n",
      "  closeness: 0.1578\n",
      "  betweenness: 0.0394\n",
      "  eigenvector: 0.0665\n",
      "  katz: 0.1412\n",
      "  pagerank: 0.0182\n",
      "User: Admirable-Raise-4942\n",
      "  degree: 0.0029\n",
      "  in_degree: 0.0019\n",
      "  out_degree: 0.0010\n",
      "  closeness: 0.1184\n",
      "  betweenness: 0.0000\n",
      "  eigenvector: 0.0133\n",
      "  katz: 0.0287\n",
      "  pagerank: 0.0173\n",
      "User: akiionely\n",
      "  degree: 0.0302\n",
      "  in_degree: 0.0263\n",
      "  out_degree: 0.0039\n",
      "  closeness: 0.1132\n",
      "  betweenness: 0.0018\n",
      "  eigenvector: 0.0117\n",
      "  katz: 0.0808\n",
      "  pagerank: 0.0171\n",
      "User: IntelArcTesting\n",
      "  degree: 0.0778\n",
      "  in_degree: 0.0477\n",
      "  out_degree: 0.0302\n",
      "  closeness: 0.1614\n",
      "  betweenness: 0.0585\n",
      "  eigenvector: 0.5000\n",
      "  katz: 0.2428\n",
      "  pagerank: 0.0164\n"
     ]
    }
   ],
   "source": [
    "results = calculate_centralities(\"search_reply_graph_intel_2.graphml\")\n",
    "\n",
    "# Print top 5 nodes by PageRank\n",
    "top_pagerank = sorted(results.items(), key=lambda x: x[1]['pagerank'], reverse=True)[:5]\n",
    "for node, metrics in top_pagerank:\n",
    "    print(f\"User: {node}\")\n",
    "    for k, v in metrics.items():\n",
    "        print(f\"  {k}: {v:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "id": "727b5ef8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Degree Centrality: 0.0036\n",
      "Closeness Centrality: 0.0506\n",
      "Betweenness Centrality: 0.0011\n",
      "Eigenvector Centrality: 0.0105\n",
      "Katz Centrality: 0.0262\n"
     ]
    }
   ],
   "source": [
    "G = nx.read_graphml(\"search_reply_graph_intel_2.graphml\")\n",
    "\n",
    "metrics = ['degree', 'closeness', 'betweenness', 'eigenvector', 'katz']\n",
    "\n",
    "for m in metrics:\n",
    "    avg = average_centrality(G, metric=m)\n",
    "    if avg is not None:\n",
    "        print(f\"{m.capitalize()} Centrality: {avg:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ca4c88c",
   "metadata": {},
   "source": [
    "## intel_tier_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5a2f8039",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìÇ Loading graph from search_reply_graph_intel_1.graphml...\n",
      "‚úÖ Exported metrics to search_reply_graph_intel_1_centrality_metrics.csv with 821 users.\n",
      "              User    Degree  Betweenness  Eigenvector  Closeness\n",
      "116         jecowa  0.132927     0.036404     0.017409   0.065803\n",
      "624  AutoModerator  0.058537     0.002923     0.000149   0.082519\n",
      "378      6im6erbmw  0.057317     0.030967     0.186287   0.108147\n",
      "25      alvarkresh  0.048780     0.070633     0.437162   0.091952\n",
      "0        JayIsLoco  0.040244     0.020733     0.327637   0.088305\n"
     ]
    }
   ],
   "source": [
    "## intel \n",
    "\n",
    "df = compute_centrality_from_graphml(\"search_reply_graph_intel_1.graphml\", output_name=\"search_reply_graph_intel_1\")\n",
    "print(df.head(5))  # Show top 10 users\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9d2f288f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User: jecowa\n",
      "  degree: 0.1329\n",
      "  in_degree: 0.1012\n",
      "  out_degree: 0.0317\n",
      "  closeness: 0.0658\n",
      "  betweenness: 0.0364\n",
      "  eigenvector: 0.0174\n",
      "  katz: 0.3119\n",
      "  pagerank: 0.0518\n",
      "User: jackrabbit1994\n",
      "  degree: 0.0293\n",
      "  in_degree: 0.0220\n",
      "  out_degree: 0.0073\n",
      "  closeness: 0.0957\n",
      "  betweenness: 0.0070\n",
      "  eigenvector: 0.0062\n",
      "  katz: 0.0766\n",
      "  pagerank: 0.0338\n",
      "User: 6im6erbmw\n",
      "  degree: 0.0573\n",
      "  in_degree: 0.0476\n",
      "  out_degree: 0.0098\n",
      "  closeness: 0.1081\n",
      "  betweenness: 0.0310\n",
      "  eigenvector: 0.1863\n",
      "  katz: 0.1660\n",
      "  pagerank: 0.0304\n",
      "User: Corentinrobin29\n",
      "  degree: 0.0159\n",
      "  in_degree: 0.0146\n",
      "  out_degree: 0.0012\n",
      "  closeness: 0.0412\n",
      "  betweenness: 0.0000\n",
      "  eigenvector: 0.0001\n",
      "  katz: 0.0580\n",
      "  pagerank: 0.0177\n",
      "User: cclambert95\n",
      "  degree: 0.0037\n",
      "  in_degree: 0.0024\n",
      "  out_degree: 0.0012\n",
      "  closeness: 0.0926\n",
      "  betweenness: 0.0026\n",
      "  eigenvector: 0.0013\n",
      "  katz: 0.0476\n",
      "  pagerank: 0.0149\n"
     ]
    }
   ],
   "source": [
    "# del results \n",
    "\n",
    "results = calculate_centralities(\"search_reply_graph_intel_1.graphml\")\n",
    "\n",
    "# Print top 5 nodes by PageRank\n",
    "top_pagerank = sorted(results.items(), key=lambda x: x[1]['pagerank'], reverse=True)[:5]\n",
    "for node, metrics in top_pagerank:\n",
    "    print(f\"User: {node}\")\n",
    "    for k, v in metrics.items():\n",
    "        print(f\"  {k}: {v:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ce67098d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Degree Centrality: 0.0038\n",
      "Closeness Centrality: 0.0215\n",
      "Betweenness Centrality: 0.0010\n",
      "Eigenvector Centrality: 0.0096\n",
      "Katz Centrality: 0.0312\n"
     ]
    }
   ],
   "source": [
    "G = nx.read_graphml(\"search_reply_graph_intel_1.graphml\")\n",
    "\n",
    "metrics = ['degree', 'closeness', 'betweenness', 'eigenvector', 'katz']\n",
    "\n",
    "for m in metrics:\n",
    "    avg = average_centrality(G, metric=m)\n",
    "    if avg is not None:\n",
    "        print(f\"{m.capitalize()} Centrality: {avg:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cab6f4a8",
   "metadata": {},
   "source": [
    "## intel_tier_3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "id": "12e39ab5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìÇ Loading graph from search_reply_graph_intel_3.graphml...\n",
      "‚úÖ Exported metrics to search_reply_graph_intel_3_centrality_metrics.csv with 2140 users.\n",
      "                    User    Degree  Betweenness  Eigenvector  Closeness\n",
      "914            kylinblue  0.056568     0.000000     0.003549   0.204699\n",
      "73   ExcitementGrand2663  0.053296     0.038682     0.707995   0.125138\n",
      "275        MyHonestViews  0.048621     0.017060     0.025861   0.220335\n",
      "650           apmspammer  0.047218     0.000393     0.001152   0.180540\n",
      "584          DeathDexoys  0.036933     0.030068     0.007953   0.197114\n"
     ]
    }
   ],
   "source": [
    "df = compute_centrality_from_graphml(\"search_reply_graph_intel_3.graphml\", output_name=\"search_reply_graph_intel_3\")\n",
    "print(df.head(5))  # Show top 10 users\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "id": "13bcbc75",
   "metadata": {},
   "outputs": [],
   "source": [
    "del results "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "id": "dece043a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User: apmspammer\n",
      "  degree: 0.0472\n",
      "  in_degree: 0.0463\n",
      "  out_degree: 0.0009\n",
      "  closeness: 0.1805\n",
      "  betweenness: 0.0004\n",
      "  eigenvector: 0.0012\n",
      "  katz: 0.1446\n",
      "  pagerank: 0.0400\n",
      "User: Helpful-Option-3047\n",
      "  degree: 0.0360\n",
      "  in_degree: 0.0355\n",
      "  out_degree: 0.0005\n",
      "  closeness: 0.1997\n",
      "  betweenness: 0.0004\n",
      "  eigenvector: 0.1207\n",
      "  katz: 0.1602\n",
      "  pagerank: 0.0226\n",
      "User: SmartHost7823\n",
      "  degree: 0.0304\n",
      "  in_degree: 0.0281\n",
      "  out_degree: 0.0023\n",
      "  closeness: 0.2048\n",
      "  betweenness: 0.0323\n",
      "  eigenvector: 0.0075\n",
      "  katz: 0.1296\n",
      "  pagerank: 0.0215\n",
      "User: Ledot3\n",
      "  degree: 0.0009\n",
      "  in_degree: 0.0005\n",
      "  out_degree: 0.0005\n",
      "  closeness: 0.1605\n",
      "  betweenness: 0.0000\n",
      "  eigenvector: 0.0168\n",
      "  katz: 0.0270\n",
      "  pagerank: 0.0189\n",
      "User: MyHonestViews\n",
      "  degree: 0.0486\n",
      "  in_degree: 0.0477\n",
      "  out_degree: 0.0009\n",
      "  closeness: 0.2203\n",
      "  betweenness: 0.0171\n",
      "  eigenvector: 0.0259\n",
      "  katz: 0.2026\n",
      "  pagerank: 0.0187\n"
     ]
    }
   ],
   "source": [
    "results = calculate_centralities(\"search_reply_graph_intel_3.graphml\")\n",
    "\n",
    "# Print top 5 nodes by PageRank\n",
    "top_pagerank = sorted(results.items(), key=lambda x: x[1]['pagerank'], reverse=True)[:5]\n",
    "for node, metrics in top_pagerank:\n",
    "    print(f\"User: {node}\")\n",
    "    for k, v in metrics.items():\n",
    "        print(f\"  {k}: {v:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "id": "eebb682d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Degree Centrality: 0.0018\n",
      "Closeness Centrality: 0.0512\n",
      "Betweenness Centrality: 0.0007\n",
      "Eigenvector Centrality: 0.0031\n",
      "Katz Centrality: 0.0163\n"
     ]
    }
   ],
   "source": [
    "G = nx.read_graphml(\"search_reply_graph_intel_3.graphml\")\n",
    "\n",
    "metrics = ['degree', 'closeness', 'betweenness', 'eigenvector', 'katz']\n",
    "\n",
    "for m in metrics:\n",
    "    avg = average_centrality(G, metric=m)\n",
    "    if avg is not None:\n",
    "        print(f\"{m.capitalize()} Centrality: {avg:.4f}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
